{"pageProps":{"questions":[{"id":"ar8PkvmOIZYWauURSQqh","exam_id":13,"unix_timestamp":1622886960,"isMC":true,"answers_community":["B (100%)"],"choices":{"B":"Lack of model retraining","D":"Incorrect data split ratio during model training, evaluation, validation, and test","C":"Too few layers in the model for capturing information","A":"Poor data quality"},"question_text":"You built and manage a production system that is responsible for predicting sales numbers. Model accuracy is crucial, because the production model is required to keep up with market changes. Since being deployed to production, the model hasn't changed; however the accuracy of the model has steadily deteriorated.\nWhat issue is most likely causing the steady decline in model accuracy?","answer_ET":"B","question_images":[],"answer_images":[],"topic":"1","timestamp":"2021-06-05 11:56:00","question_id":46,"answer":"B","answer_description":"","url":"https://www.examtopics.com/discussions/google/view/54595-exam-professional-machine-learning-engineer-topic-1-question/","discussion":[{"poster":"esuaaaa","comment_id":"374981","content":"B. Retraining is needed as the market is changing.","upvote_count":"31","timestamp":"1622886960.0","comments":[{"poster":"sensev","upvote_count":"11","content":"I also think it is B - who is giving the \"correct\" answers to the questions? I feel like 4 out of 5 of them are incorrect.","timestamp":"1626946200.0","comment_id":"411512"}]},{"poster":"NickHapton","timestamp":"1640571060.0","comment_id":"509950","comments":[{"upvote_count":"1","content":"So what do you suggest the answer is ?","poster":"desertlotus1211","timestamp":"1729442940.0","comment_id":"1300584"}],"upvote_count":"16","content":"the biggest issue of this website is `all correct answers` are wrong"},{"comment_id":"1277319","poster":"ZhengWeiNg","content":"Selected Answer: B\nModel is not updated to current sales trends.","upvote_count":"1","timestamp":"1725343200.0"},{"timestamp":"1722634200.0","poster":"jsalvasoler","upvote_count":"1","content":"Selected Answer: B\nB naturally","comment_id":"1260049"},{"comment_id":"1225147","timestamp":"1717650240.0","upvote_count":"2","poster":"PhilipKoku","content":"Selected Answer: B\nB) You require model monitoring to identify changes and at the right time retrain the model with new data to avoid model drift."},{"content":"Selected Answer: B\nThe market can be dynamic, Sales trends, customer preferences, and even competitor strategies might evolve over time but our model hasn't changed since the deployment so our model can adapt with these changes by retraining only\nDegradation Over Time: Without retraining to adapt to these changes, the model's predictions become less accurate as the real world diverges from the data it was trained on.","comment_id":"1187091","upvote_count":"1","poster":"Azhar10","timestamp":"1711928580.0"},{"upvote_count":"1","content":"As the consistent changes in the Market data, the Model in Production should regularly retrain for better results. Option B is the right choice","comment_id":"1129347","poster":"97a158e","timestamp":"1706000580.0"},{"timestamp":"1701436200.0","comment_id":"1085225","poster":"fragkris","upvote_count":"1","content":"Selected Answer: B\nKeeping the model up to date is crucial. So - B."},{"comment_id":"1070461","timestamp":"1699971300.0","upvote_count":"1","poster":"Sum_Sum","content":"Selected Answer: B\nB because the environment is changing and the model only captures past performance"},{"timestamp":"1688880600.0","upvote_count":"2","comment_id":"946899","content":"Selected Answer: B\nSituation : model trained long before.\nQ : why accuracy of the model has steadily deteriorated.\n\nA. Poor data quality : Model perfomance depens on trained model only. Quality issue should be taken care by pipeline and it do not much affect the model to cause a performance slow down over time\nB. Lack of model retraining : Very obvious\nC. Too few layers in the model for capturing information : If so model wpould not have been deployed at first stage due to low performance on unseen data\nD. Incorrect data split ratio during model training, evaluation, validation, and test : This is relevant only at training when model deployed at first place, We have way passed that. Not not the reason.","poster":"harithacML"},{"comment_id":"892690","upvote_count":"1","content":"Selected Answer: B\nWent with B","poster":"M25","timestamp":"1683608220.0"},{"content":"Selected Answer: B\nB is correct. Model needs to keep up with the market changes, implying that the underlying data distribution would be changing as well. Hence retrain the model.","timestamp":"1679471520.0","upvote_count":"1","comment_id":"846787","poster":"niketd"},{"timestamp":"1678201020.0","comment_id":"832033","upvote_count":"1","content":"Selected Answer: B\nThe questions says the model is required to keep up with market changes, hence retraining needed.","poster":"tavva_prudhvi"},{"upvote_count":"1","poster":"Ade_jr","comment_id":"754152","content":"B is the correct answer","timestamp":"1671795300.0"},{"comment_id":"746508","content":"Selected Answer: B\nANS: B","poster":"wish0035","upvote_count":"1","timestamp":"1671138780.0"},{"comment_id":"725250","content":"Selected Answer: B\nData distribution changes over time and so should do the model, so B is the correct answer","poster":"EFIGO","timestamp":"1669219680.0","upvote_count":"1"},{"upvote_count":"1","timestamp":"1660566780.0","comment_id":"647183","poster":"GCP72","content":"Selected Answer: B\nCorrect answer is \"B\""},{"comment_id":"581736","content":"Selected Answer: B\nB for sure","upvote_count":"3","poster":"morgan62","timestamp":"1649238360.0"},{"content":"Selected Answer: B\nCommunity vote","comment_id":"557801","upvote_count":"2","poster":"caohieu04","timestamp":"1646016240.0"},{"timestamp":"1642550280.0","comment_id":"527078","poster":"ESP_SAP","content":"Selected Answer: B\nB. Retraining is needed as the market is changing. its how the Model keep updated and predictions accuracy.","upvote_count":"2"},{"timestamp":"1641773460.0","poster":"sid515","upvote_count":"1","comment_id":"520542","content":"Selected Answer: B\nIts B. No doubt about it."},{"timestamp":"1641242580.0","comment_id":"516037","upvote_count":"1","content":"Selected Answer: B\nUndoubtedly B","poster":"coderpk"},{"content":"why is D still an officially correct answer? Should be changed to B immediately.","comment_id":"500085","poster":"ashii007","upvote_count":"2","timestamp":"1639321800.0"},{"timestamp":"1639219320.0","content":"What is logic for it to be D as solution ?","comment_id":"499340","poster":"radhikah","upvote_count":"1"},{"poster":"alphard","comment_id":"495894","timestamp":"1638874680.0","upvote_count":"1","content":"Selected Answer: B"},{"content":"Selected Answer: B\nANSWER B","comment_id":"491983","upvote_count":"1","poster":"aj2aj2","timestamp":"1638398880.0"},{"upvote_count":"1","timestamp":"1638137460.0","poster":"Sneg42","comment_id":"489438","content":"Selected Answer: B\nAnswer B"},{"content":"Selected Answer: B\nexamtopics says D.Please add annotation why its D ?","upvote_count":"1","poster":"santy79","timestamp":"1637416140.0","comment_id":"482573"},{"timestamp":"1634581680.0","comment_id":"464258","poster":"mousseUwU","upvote_count":"1","content":"Certain that is B"},{"upvote_count":"3","content":"B, obviously.","comment_id":"444274","timestamp":"1631584200.0","poster":"Y2Data"}]},{"id":"fJAfE8E4PflInvVPnRpw","answer":"A","question_text":"You work for a retailer that sells clothes to customers around the world. You have been tasked with ensuring that ML models are built in a secure manner. Specifically, you need to protect sensitive customer data that might be used in the models. You have identified four fields containing sensitive data that are being used by your data science team: AGE, IS_EXISTING_CUSTOMER, LATITUDE_LONGITUDE, and SHIRT_SIZE. What should you do with the data before it is made available to the data science team for training purposes?","isMC":true,"timestamp":"2022-12-13 18:54:00","discussion":[{"comment_id":"1365498","content":"Selected Answer: C\nAnswer A will strip out the ordinal or numerical relationships present in the data, which can be crucial for model performance","upvote_count":"1","timestamp":"1741193220.0","poster":"desertlotus1211"},{"content":"Selected Answer: C\nAGE into Quantiles:\n • Age is a continuous variable and highly sensitive. Converting it into quantiles (e.g., age ranges) reduces granularity and protects individual privacy while preserving utility for modeling.\n • Rounding LATITUDE_LONGITUDE:\n • Latitude and longitude provide precise location information, which can lead to privacy risks. Rounding to single precision (e.g., reducing decimal places) anonymizes the data while retaining geographical relevance for modeling.\n 2. Existing Fields:\n • IS_EXISTING_CUSTOMER and SHIRT_SIZE:\n • These fields are already coarse and unlikely to reveal sensitive information directly (e.g., boolean for IS_EXISTING_CUSTOMER and categorical for SHIRT_SIZE), so no further processing is required.","comment_id":"1329494","upvote_count":"1","poster":"phani49","timestamp":"1734703800.0"},{"poster":"b7ef5e3","content":"Selected Answer: C\nBetween A and C, however A would not work well for linear data like age and long/lat. By hashing you are creating discrete categories rather than linear ones, making it difficult to find trends from other data. A may be more practical of a decision if they incorporated binning or something beforehand.","upvote_count":"1","comment_id":"1314112","timestamp":"1731953340.0"},{"timestamp":"1717666740.0","poster":"bobjr","content":"Selected Answer: C\nThe best approach is C. Coarsen the data by putting AGE into quantiles and rounding LATITUDE_LONGITUDE into single precision. The other two fields are already as coarse as possible.\n\nHere's why:\n\nPreserves Utility: Coarsening the data reduces its sensitivity while retaining some of its informational value for modeling. Age quantiles and approximate location can still be useful features for certain types of models.\nMinimizes Risk: By removing the exact age and precise location, you significantly reduce the risk of re-identification or misuse of sensitive information.\nPracticality: Coarsening is a relatively simple technique to implement and doesn't require complex transformations or additional model training.\n\npen_spark","comment_id":"1225336","upvote_count":"3"},{"timestamp":"1700221320.0","content":"Selected Answer: D\nThis approach involves not providing the sensitive fields (AGE, IS_EXISTING_CUSTOMER, LATITUDE_LONGITUDE, and SHIRT_SIZE) to the data science team for model training. Instead, the team can focus on building models using non-sensitive data. This helps to mitigate the risk of exposing sensitive customer information during the development and training process.\n\nWhile options A, B, and C propose different methods of obfuscating or transforming the sensitive data, they may introduce complexities and potential risks. Tokenizing with hashed dummy values (option A) may not be foolproof in terms of security, and PCA (option B) may not effectively retain the necessary information for accurate modeling. Coarsening the data (option C) might still retain some level of identifiable information, and it may not be sufficient for ensuring the privacy of sensitive data.","poster":"pico","comment_id":"1073266","upvote_count":"1","comments":[{"comment_id":"1162688","poster":"LFavero","timestamp":"1709217060.0","upvote_count":"2","content":"why would you remove potential important features from the training?"}]},{"upvote_count":"3","comment_id":"894134","content":"Selected Answer: A\nWent with A","timestamp":"1683733920.0","poster":"M25"},{"upvote_count":"1","comments":[{"poster":"tavva_prudhvi","timestamp":"1690477440.0","upvote_count":"1","comments":[{"comment_id":"1073264","timestamp":"1700221260.0","content":"But in option A, Hashing can result in information loss. While the original values are hidden, the hashed values might not retain the same level of information, which can impact the effectiveness of the machine learning models.","upvote_count":"1","poster":"pico"}],"comment_id":"964925","content":"Removing all sensitive data fields (Option D) would likely limit the effectiveness of the machine learning model, as important predictive variables would be excluded from the training process. It is important to balance privacy considerations with the need to train accurate models that can provide valuable insights and predictions."}],"content":"Selected Answer: D\nD. Remove all sensitive data fields, and ask the data science team to build their models using non-sensitive data. This is the best approach to protect sensitive customer data. Removing the sensitive fields is the most secure option because it eliminates the risk of any potential data breaches. Tokenizing or coarsening the data may still reveal sensitive information if the hashed dummy values can be reversed or if the coarsening can be used to identify individual customers. PCA can also be a useful technique to reduce dimensionality and protect privacy, but it may not be appropriate in this case because it is not clear how the sensitive fields can be combined into a single PCA vector without losing information.","timestamp":"1678191540.0","comment_id":"831855","poster":"TNT87"},{"comment_id":"811878","timestamp":"1676638620.0","content":"Selected Answer: A\nB -> possible in general but not suitable in this case since you don't know AGE, IS_EXISTING_CUSTOMER, LATITUDE_LONGITUDE, and SHIRT_SIZE are the first components in PCA.\nC -> You are changing data which could be highly correlated with the output\nD -> like C explanation \n\nAnswer 'A' uses hashing so you encript the data without losing relevant information","upvote_count":"4","poster":"Scipione_"},{"upvote_count":"4","comment_id":"763795","timestamp":"1672670880.0","poster":"ares81","content":"Selected Answer: A\nHashing --> A"},{"upvote_count":"3","timestamp":"1672132020.0","content":"Selected Answer: A\nAnswer A","poster":"TNT87","comment_id":"758296"},{"content":"Selected Answer: A\nA (by experience)","comment_id":"753173","poster":"hiromi","comments":[{"comment_id":"755997","upvote_count":"4","timestamp":"1672000920.0","poster":"hiromi","content":"https://cloud.google.com/blog/products/identity-security/take-charge-of-your-data-how-tokenization-makes-data-usable-without-sacrificing-privacy"}],"timestamp":"1671703140.0","upvote_count":"3"},{"poster":"mymy9418","upvote_count":"2","comment_id":"748588","content":"Selected Answer: A\nI think hash should be better","timestamp":"1671334680.0"},{"poster":"mil_spyro","upvote_count":"3","content":"Selected Answer: D\nRemoving the sensitive data fields is the safest and most effective way to ensure that customer data is not used in the training of your models.","comments":[],"comment_id":"744330","timestamp":"1670954040.0"}],"exam_id":13,"topic":"1","question_images":[],"answer_ET":"A","answer_description":"","answer_images":[],"answers_community":["A (63%)","C (20%)","D (17%)"],"url":"https://www.examtopics.com/discussions/google/view/91478-exam-professional-machine-learning-engineer-topic-1-question/","choices":{"A":"Tokenize all of the fields using hashed dummy values to replace the real values.","C":"Coarsen the data by putting AGE into quantiles and rounding LATITUDE_LONGTTUDE into single precision. The other two fields are already as coarse as possible.","D":"Remove all sensitive data fields, and ask the data science team to build their models using non-sensitive data.","B":"Use principal component analysis (PCA) to reduce the four sensitive fields to one PCA vector."},"question_id":47,"unix_timestamp":1670954040},{"id":"piBWC441sSPAyaAohqMb","answer":"C","answer_ET":"C","isMC":true,"unix_timestamp":1672131960,"answer_description":"","answers_community":["C (62%)","B (35%)","3%"],"timestamp":"2022-12-27 10:06:00","topic":"1","url":"https://www.examtopics.com/discussions/google/view/92951-exam-professional-machine-learning-engineer-topic-1-question/","question_id":48,"question_images":[],"exam_id":13,"answer_images":[],"question_text":"You work for a magazine publisher and have been tasked with predicting whether customers will cancel their annual subscription. In your exploratory data analysis, you find that 90% of individuals renew their subscription every year, and only 10% of individuals cancel their subscription. After training a NN Classifier, your model predicts those who cancel their subscription with 99% accuracy and predicts those who renew their subscription with 82% accuracy. How should you interpret these results?","discussion":[{"poster":"TNT87","timestamp":"1672131960.0","upvote_count":"7","content":"Selected Answer: C\nAnswer C","comment_id":"758295"},{"poster":"desertlotus1211","upvote_count":"1","comment_id":"1365502","content":"Selected Answer: B\nBecause 90% of subscribers renew, a simple baseline that always predicts \"renew\" would achieve 90% accuracy overall. In your model, while the cancellation (minority class) accuracy is high at 99%, the accuracy for renewals (the majority class) is only 82%. This means that when predicting the renewals, the model is doing significantly worse than the baseline of always predicting renewal.","timestamp":"1741193340.0"},{"content":"Selected Answer: B\nCorrect Answer: This is not a good result because the model is performing worse\nthan a simple heuristic of predicting that everyone will renew.\n Why?\n• A simple heuristic (predicting all renewals) achieves 90% accuracy.\n• The model’s 82% accuracy for renewals is worse than this baseline, meaning it\nadds no real value.\n• The 99% accuracy for cancellations is misleading, likely due to severe class\nimbalance.\n• Alternative metrics (precision, recall, F1-score) would provide a clearer picture of\nactual performance.","upvote_count":"1","comment_id":"1364725","poster":"Amer95","timestamp":"1741062780.0"},{"poster":"phani49","comment_id":"1329516","content":"Selected Answer: B\nOption B: \"This is not a good result because the model is performing worse than predicting that people will always renew their subscription.\"\n\nNote: In practice, you'd also consider precision, recall, and business objectives. For example, if your business goal is to identify and retain canceling customers before they leave, a model with higher recall for cancellations might be beneficial despite the lower overall accuracy. But within the context of the given multiple-choice answers and the question's framing, B is the correct interpretation.","upvote_count":"1","timestamp":"1734706680.0"},{"comment_id":"1324039","upvote_count":"1","content":"Selected Answer: B\nB) - Saying \"good result\" is premature: no precision, recall, F1 was given\n- High accuracy over the minority could be overfitting\n- If the model predicted always renewal, it would achieve 90% accuracy. \n- 82% accuracy for renewals shows it isn't much better than a naive prediction.","timestamp":"1733747880.0","poster":"lunalongo"},{"comment_id":"1311677","timestamp":"1731549600.0","content":"Selected Answer: C\nC. The goal of the model is to predict CANCELLATIONS, not renewals","poster":"f084277","upvote_count":"1"},{"content":"Selected Answer: B\nHere's the reasoning:\n\nThe overall renewal rate is 90%, meaning that if the model simply predicted that everyone would renew, it would have an accuracy of 90%. The model's accuracy for predicting renewals (82%) is lower than this baseline accuracy.\nThe model's accuracy for predicting cancellations is high (99%), but this could be misleading. If only 10% of individuals cancel their subscription, a model that predicts no cancellations at all would still have a high accuracy of 90%. Therefore, the high accuracy for cancellations may not be very informative.\nIn summary, the model is not performing well, especially when compared to a simple baseline of always predicting renewals.","upvote_count":"3","comment_id":"1073272","timestamp":"1700221740.0","comments":[{"timestamp":"1718103840.0","upvote_count":"1","content":"if we suppose the case where the model simply predicted that everyone would renew, the renewals rate should be always higher than the cancellations. Therefore, This case means that the model made some asumptions about how a cancellation looks like and misled some of the renewals cases (it could make some wrong asumptions because there are few data)","comment_id":"1228405","poster":"ccb23cc"},{"content":"C suggests that predicting cancellations is more difficult due to less data for this group. While it's true that imbalanced datasets, where one class is underrepresented, can pose challenges for machine learning models, the key issue here is that the model's accuracy for predicting renewals is lower than the accuracy for predicting cancellations.\n\nIn this scenario, the imbalance alone does not explain the lower accuracy for renewals. The model should ideally perform well on both classes, and the fact that it doesn't, especially when compared to a simple baseline of always predicting renewals (which would have an accuracy of 90%), suggests that there's a problem with the model's performance.\n\nTherefore, option B is a more appropriate interpretation, highlighting that the model is performing worse than a basic strategy of always predicting renewals.","poster":"pico","timestamp":"1700221800.0","upvote_count":"2","comment_id":"1073274"}],"poster":"pico"},{"poster":"tavva_prudhvi","upvote_count":"2","content":"Selected Answer: C\nsince there is less data for this group. While the accuracy for predicting subscription renewals is lower, it is still above chance and may still be useful. Additionally, the high accuracy for predicting cancellations is promising, as this is the group of interest for the publisher. However, it would still be important to assess the model's precision and recall to fully evaluate its performance.","comment_id":"944870","timestamp":"1688663400.0"},{"comment_id":"908468","upvote_count":"4","content":"Selected Answer: C\nWent with C: This is a good result because predicting those who cancel their subscription is more difficult, since there is less data for this group\n My Reason: \"You have been tasked with predicting whether customers will cancel their annual subscription.\" And in that task you are getting 99% of accuracy","poster":"Voyager2","timestamp":"1685266440.0"},{"timestamp":"1685126640.0","comment_id":"907548","upvote_count":"2","poster":"ShePiDai","content":"Selected Answer: B\nTask is to predict whether customer will cancel subscription, so both renew and cancel predictions are important. The overall accuracy is 99% x 10% + 82% x 90% = 83%, while guessing always renew has 90% accuracy."},{"comment_id":"894135","upvote_count":"2","content":"Selected Answer: B\n#ResponsibleAI, predicting the majority class (imbalanced data) topic: “the model [82% accuracy for renew] is performing worse than predicting that people will always [90% accuracy] renew their subscription”.\nhttps://developers.google.com/machine-learning/crash-course/classification/check-your-understanding-accuracy-precision-recall\n“A deadly, but curable, medical condition afflicts .01% of the population. An ML model (…) predicts (…) with an accuracy of 99.99%. (…) After all, even a \"dumb\" model that always predicts \"not sick\" would still be 99.99% accurate.“","poster":"M25","timestamp":"1683733980.0"},{"poster":"lucaluca1982","upvote_count":"1","comment_id":"879122","comments":[],"content":"Selected Answer: B\nThe 82% accuracy for renewals is lower than a naive model that always predicts renewals (which would have a 90% accuracy).","timestamp":"1682319240.0"},{"timestamp":"1676638380.0","upvote_count":"3","comment_id":"811874","poster":"Scipione_","content":"Selected Answer: C\nI think C is the only way"},{"poster":"John_Pongthorn","upvote_count":"2","content":"Selected Answer: C\nWe can consider it as follows reasonably.\nA: it doesn't make any sense, given that cancel=99% but renew =82%, how did you make renew class (82%) beat the Cancel class(99%), it must be 100% accuracy ( bullshit)\nB: Cancel class have more accuracy than renew (99%>82%)\nD: You can justify, both are good 80% if we have a balance class.\n\nSo it left us with C. This model predicts well upon imbalanced class circumstances.\ntarget class =10 samles meanwhile the another =90 samples","comment_id":"809068","timestamp":"1676432760.0"},{"upvote_count":"2","comment_id":"763787","content":"Selected Answer: C\nLogically, it should be C.","timestamp":"1672669980.0","poster":"ares81"},{"timestamp":"1672246440.0","comments":[{"poster":"John_Pongthorn","upvote_count":"1","comment_id":"810327","content":"I think C is the most likely. we are experiencing an imbalanced dataset and the target class is canceled. \nActually this case we have to use other metrics like F1 and precision/recall\nIf you want to get ReNew accuracy higher than CAncel, you have to make it greater than 99% as compared to another. it is hard to archive.","timestamp":"1676528640.0"}],"poster":"Dataspire","comment_id":"760118","upvote_count":"1","content":"Selected Answer: A\nSince 90% of dataset represent customer who will renew subscription, accuracy should have been greater than 82%"}],"choices":{"C":"This is a good result because predicting those who cancel their subscription is more difficult, since there is less data for this group.","A":"This is not a good result because the model should have a higher accuracy for those who renew their subscription than for those who cancel their subscription.","B":"This is not a good result because the model is performing worse than predicting that people will always renew their subscription.","D":"This is a good result because the accuracy across both groups is greater than 80%."}},{"id":"xeQvkzc2R4V3pJ2y5kpe","unix_timestamp":1670954520,"choices":{"B":"Containerize the PySpark transformation step, and add it to your pipeline.","D":"Deploy Apache Spark at a separate node pool in a Google Kubernetes Engine cluster. Add a ContainerOp to your pipeline that invokes a corresponding transformation job for this Spark instance.","A":"Remove the data transformation step from your pipeline.","C":"Add a ContainerOp to your pipeline that spins a Dataproc cluster, runs a transformation, and then saves the transformed data in Cloud Storage."},"url":"https://www.examtopics.com/discussions/google/view/91483-exam-professional-machine-learning-engineer-topic-1-question/","topic":"1","answer":"C","isMC":true,"discussion":[{"upvote_count":"7","poster":"mil_spyro","timestamp":"1670954520.0","content":"Selected Answer: C\nThis will allow to reuse the same pipeline for different datasets without the need to manually preprocess and transform the data each time.","comment_id":"744338"},{"upvote_count":"6","timestamp":"1688663220.0","content":"Selected Answer: C\nSince the data is stored in Parquet format, it's more efficient to use Spark to transform it. Containerizing the PySpark transformation step and adding it to the pipeline may not be the optimal solution since it may require additional resources to run this container. Deploying Apache Spark at a separate node pool in a Google Kubernetes Engine cluster and adding a ContainerOp to invoke a corresponding transformation job for this Spark instance is also a possible solution, but it may require more setup and configuration.\n\nUsing Dataproc can simplify this process since it's a fully managed service that simplifies running Apache Spark and Hadoop clusters. A ContainerOp can be added to the pipeline to spin up a Dataproc cluster, run the transformation using PySpark, and save the transformed data in Cloud Storage. This solution is more efficient since Dataproc can scale the cluster based on the size of the data and the complexity of the transformation.","comment_id":"944867","poster":"tavva_prudhvi"},{"poster":"momosoundz","timestamp":"1687985880.0","upvote_count":"2","content":"Selected Answer: B\nyou can conteinerize the transformation and then save to google storage","comments":[{"timestamp":"1690474860.0","comment_id":"964889","upvote_count":"1","content":"it is not the most efficient and scalable solution when working with big data in the context of Google Cloud.","poster":"tavva_prudhvi"}],"comment_id":"937136"},{"content":"Selected Answer: C\nhttps://kubeflow-pipelines.readthedocs.io/en/stable/source/kfp.dsl.html#kfp.dsl.ContainerOp\nhttps://medium.com/@vignesh093/running-preprocessing-and-ml-workflow-in-kubeflow-with-google-dataproc-84103a9ef67e","upvote_count":"1","timestamp":"1683733980.0","comment_id":"894137","poster":"M25"},{"poster":"TNT87","upvote_count":"2","comment_id":"831835","content":"Selected Answer: C\nC. Add a ContainerOp to your pipeline that spins a Dataproc cluster, runs a transformation, and then saves the transformed data in Cloud Storage.\n\nThe recommended approach to parametrize the model training in Kubeflow Pipelines would be to add a ContainerOp to the pipeline that spins up a Dataproc cluster, runs the PySpark transformation step, and saves the transformed data in Cloud Storage. This approach allows for easy integration of PySpark transformations with Kubeflow Pipelines while taking advantage of the scalability and efficiency of Dataproc.","timestamp":"1678190520.0"},{"comments":[{"comment_id":"1311680","poster":"f084277","content":"The doc you linked literally says to use ContainerOp in the documentation. The answer is C.","upvote_count":"1","timestamp":"1731549900.0"}],"poster":"chidstar","upvote_count":"6","comment_id":"823006","timestamp":"1677449700.0","content":"Selected Answer: B\nAll the wrong answers on this site really baffle me...correct answer is B... you must containerize your component for Kubeflow to run it.\n\nhttps://www.kubeflow.org/docs/components/pipelines/v1/sdk/component-development/#containerize-your-components-code"},{"content":"Selected Answer: C\nAnswer C","comment_id":"758294","timestamp":"1672131960.0","poster":"TNT87","upvote_count":"2"}],"answer_images":[],"answer_description":"","answers_community":["C (69%)","B (31%)"],"question_id":49,"question_text":"You have built a model that is trained on data stored in Parquet files. You access the data through a Hive table hosted on Google Cloud. You preprocessed these data with PySpark and exported it as a CSV file into Cloud Storage. After preprocessing, you execute additional steps to train and evaluate your model. You want to parametrize this model training in Kubeflow Pipelines. What should you do?","timestamp":"2022-12-13 19:02:00","answer_ET":"C","exam_id":13,"question_images":[]},{"id":"jT9v15UlTuAv2PJ0YEYG","timestamp":"2023-02-22 23:41:00","answer_ET":"A","question_id":50,"answers_community":["A (100%)"],"url":"https://www.examtopics.com/discussions/google/view/100436-exam-professional-machine-learning-engineer-topic-1-question/","question_text":"You have developed an ML model to detect the sentiment of users’ posts on your company's social media page to identify outages or bugs. You are using Dataflow to provide real-time predictions on data ingested from Pub/Sub. You plan to have multiple training iterations for your model and keep the latest two versions live after every run. You want to split the traffic between the versions in an 80:20 ratio, with the newest model getting the majority of the traffic. You want to keep the pipeline as simple as possible, with minimal management required. What should you do?","answer_description":"","unix_timestamp":1677105660,"answer_images":[],"discussion":[{"upvote_count":"8","content":"Selected Answer: A\nA. Deploy the models to a Vertex AI endpoint using the traffic-split=0=80, PREVIOUS_MODEL_ID=20 configuration.\n\nThe recommended approach to achieve the desired outcome would be to deploy the ML models to a Vertex AI endpoint and configure the traffic splitting using the traffic-split parameter. The traffic-split parameter enables you to split traffic between multiple versions of a model based on a percentage split. In this case, the newest model should receive the majority of the traffic, which can be achieved by setting the traffic-split parameter to 0=80. The previous version of the model should receive the remaining 20% of the traffic, which can be achieved by setting the PREVIOUS_MODEL_ID parameter to 20.","poster":"TNT87","timestamp":"1694080680.0","comment_id":"831828"},{"comment_id":"1200036","content":"Selected Answer: A\nVertex AI Traffic Splitting: Vertex AI natively supports traffic splitting between deployed models through the traffic-split parameter. This allows you to specify the desired traffic distribution (80% to the newest model, 20% to the previous one) during deployment.","poster":"fitri001","timestamp":"1729584720.0","upvote_count":"1"},{"timestamp":"1699638840.0","content":"Selected Answer: A\nWent with A","comment_id":"894139","upvote_count":"2","poster":"M25"},{"upvote_count":"4","poster":"FherRO","comment_id":"818503","timestamp":"1692736860.0","content":"Selected Answer: A\nI think is A because traffic can be split across different versions when using Endpoints https://cloud.google.com/vertex-ai/docs/general/deployment#models-endpoint.\nThe --trafic-split flag does exist, but in the question the syntax is incorrect, it should be \"--traffic-split = [MODEL_ID_1=value, MODEL_ID_2=value]\" as explained in https://cloud.google.com/sdk/gcloud/reference/ai/endpoints/deploy-model"}],"topic":"1","choices":{"C":"Wrap the models inside a Cloud Run container using the REVISION1=20, REVISION2=80 revision configuration.","D":"Implement random splitting in Dataflow using beam.Partition() with a partition function calling a Vertex AI endpoint.","B":"Wrap the models inside an App Engine application using the --splits PREVIOUS_VERSION=0.2, NEW_VERSION=0.8 configuration","A":"Deploy the models to a Vertex AI endpoint using the traffic-split=0=80, PREVIOUS_MODEL_ID=20 configuration."},"exam_id":13,"answer":"A","question_images":[],"isMC":true}],"exam":{"isBeta":false,"provider":"Google","isMCOnly":true,"isImplemented":true,"numberOfQuestions":304,"name":"Professional Machine Learning Engineer","lastUpdated":"11 Apr 2025","id":13},"currentPage":10},"__N_SSP":true}