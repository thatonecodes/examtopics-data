{"pageProps":{"questions":[{"id":"U4pTCDZ5po7tGPwXujs7","answers_community":["AD (91%)","9%"],"timestamp":"2021-06-18 02:23:00","answer_images":[],"answer_description":"","url":"https://www.examtopics.com/discussions/google/view/55546-exam-professional-machine-learning-engineer-topic-1-question/","unix_timestamp":1623975780,"answer":"AD","isMC":true,"question_id":201,"discussion":[{"poster":"ralf_cc","content":"AD - please weigh in guys","timestamp":"1641819420.0","upvote_count":"40","comment_id":"403282"},{"upvote_count":"26","content":"A. Use the interleave option for reading data. - Yes, that helps to parallelize data reading.\nB. Reduce the value of the repeat parameter. - No, this is only to repeat rows of the dataset.\nC. Increase the buffer size for the shuttle option. - No, there is only a shuttle option.\nD. Set the prefetch option equal to the training batch size. - Yes, this will pre-load the data.\nE. Decrease the batch size argument in your transformation. - No, could be even slower due to more I/Os.\n\nhttps://www.tensorflow.org/guide/data_performance","timestamp":"1652210640.0","poster":"danielp14021990","comment_id":"475809"},{"upvote_count":"1","poster":"PhilipKoku","timestamp":"1733498460.0","comment_id":"1225533","content":"Selected Answer: AD\nA) and D) are the right answers!"},{"content":"Selected Answer: AD\nA and D : https://www.tensorflow.org/guide/data_performance , interleave and prefetch","poster":"harithacML","comment_id":"949655","timestamp":"1705060620.0","upvote_count":"2"},{"comment_id":"892705","content":"Selected Answer: AD\nWent with A & D","poster":"M25","timestamp":"1699513320.0","upvote_count":"2"},{"comment_id":"749674","upvote_count":"1","content":"Selected Answer: AD\nyes AD","poster":"MithunDesai","timestamp":"1687160040.0"},{"timestamp":"1677591780.0","poster":"OJ42","upvote_count":"1","content":"Selected Answer: AD\nYes AD","comment_id":"653464"},{"timestamp":"1676473020.0","upvote_count":"1","poster":"GCP72","content":"Selected Answer: AD\nYES.....AD - agree with danielp1","comment_id":"647206"},{"content":"Selected Answer: AD\nAD - agree with danielp1\n\nBy the way, this is handy to understand the significance of shuffle buffer_size: https://stackoverflow.com/a/48096625/1933315","upvote_count":"2","comment_id":"635278","timestamp":"1674411660.0","poster":"u_phoria"},{"poster":"onku","timestamp":"1673505300.0","comment_id":"630285","upvote_count":"1","content":"Selected Answer: DE\nI think D & E are correct."},{"timestamp":"1672697700.0","poster":"Xrobat","content":"AD should be the right answer.","comment_id":"626298","upvote_count":"3"},{"comment_id":"618519","timestamp":"1671431400.0","upvote_count":"1","poster":"eddy1234567890","content":"Answers?"},{"upvote_count":"2","comments":[{"comment_id":"551740","timestamp":"1660988760.0","content":"D is not correct answer. Instead of decrising batch size, incrising may help. (https://cloud.google.com/tpu/docs/performance-guide - \"TPU model performance\" section)","upvote_count":"1","poster":"klemiec","comments":[{"comment_id":"1224924","content":"you mean E, not D, right?","timestamp":"1733430780.0","upvote_count":"1","poster":"Goosemoose"}]}],"comment_id":"465625","poster":"93alejandrosanchez","timestamp":"1650529560.0","content":"For me it should be D and E as well. Prefetching will help reading data while training is performed, which helps with the bottleneck, D is for sure right. I think decreasing batch size would help too, because less records will be read in each training step (reading a lot of records would lead to the bottleneck described, as reading data is costly).\n\nI'm not 100% sure on A, personally I don't think processing many input files concurrently would help in this case because the reading operation is precisely the problem. However, I'm no expert in this topic so I might be wrong."},{"content":"I think it should be DE. I found this article https://towardsdatascience.com/overcoming-data-preprocessing-bottlenecks-with-tensorflow-data-service-nvidia-dali-and-other-d6321917f851","comment_id":"410381","timestamp":"1642700880.0","poster":"gcp2021go","upvote_count":"3"}],"question_images":[],"answer_ET":"AD","choices":{"A":"Use the interleave option for reading data.","B":"Reduce the value of the repeat parameter.","E":"Decrease the batch size argument in your transformation.","D":"Set the prefetch option equal to the training batch size.","C":"Increase the buffer size for the shuttle option."},"topic":"1","question_text":"You are training a Resnet model on AI Platform using TPUs to visually categorize types of defects in automobile engines. You capture the training profile using the\nCloud TPU profiler plugin and observe that it is highly input-bound. You want to reduce the bottleneck and speed up your model training process. Which modifications should you make to the tf.data dataset? (Choose two.)","exam_id":13},{"id":"k7Bwv5URCn4N8mr6yZLS","answer":"B","timestamp":"2024-02-19 15:20:00","topic":"1","unix_timestamp":1708352400,"exam_id":13,"answer_ET":"B","answers_community":["B (100%)"],"question_id":202,"discussion":[{"comment_id":"1168837","upvote_count":"7","timestamp":"1725795960.0","poster":"Yan_X","content":"Selected Answer: B\nB\n'Different version of feature engineering and model training', so enable cache can help to reuse results of previous run.\nGuess not be C, as it mentioned 'end-to-end' MLOps, if delegate to BigQuery, it is not 'end-to-end' now."},{"upvote_count":"1","poster":"omermahgoub","timestamp":"1728805740.0","content":"B, and here's why:\n1. Caching directly addresses the issue of redundant computations, especially for frequently used feature engineering versions\n2. End-to-End\" MLOps, Kubeflow Pipelines handle all stages, including feature engineering, maintaining your desired \"end-to-end\" workflow.","comment_id":"1194764"},{"poster":"JG123","upvote_count":"1","comment_id":"1166919","timestamp":"1725589620.0","content":"Answer is C"}],"isMC":true,"answer_description":"","question_images":[],"url":"https://www.examtopics.com/discussions/google/view/134190-exam-professional-machine-learning-engineer-topic-1-question/","question_text":"You are using Kubeflow Pipelines to develop an end-to-end PyTorch-based MLOps pipeline. The pipeline reads data from BigQuery, processes the data, conducts feature engineering, model training, model evaluation, and deploys the model as a binary file to Cloud Storage. You are writing code for several different versions of the feature engineering and model training steps, and running each new version in Vertex AI Pipelines. Each pipeline run is taking over an hour to complete. You want to speed up the pipeline execution to reduce your development time, and you want to avoid additional costs. What should you do?","answer_images":[],"choices":{"A":"Comment out the part of the pipeline that you are not currently updating.","D":"Add a GPU to the model training step.","C":"Delegate feature engineering to BigQuery and remove it from the pipeline.","B":"Enable caching in all the steps of the Kubeflow pipeline."}},{"id":"uKqkSbtrJJ9vzUyODYBc","answer":"B","url":"https://www.examtopics.com/discussions/google/view/134191-exam-professional-machine-learning-engineer-topic-1-question/","question_images":[],"discussion":[{"poster":"guilhermebutzke","comment_id":"1153999","timestamp":"1708352700.0","upvote_count":"9","content":"Selected Answer: B\nMy Answer: B\n\n“You need to propose a workflow that performs analytics, creates features, and hosts ”:  Ingest the Avro files into BigQuery to perform analytics\n\n“workflow that performs analytics, creates features”: Dataflow pipeline to create the features\n\n“and hosts the features that your ML models use for online prediction”:store them in Vertex AI Feature Store for online prediction"},{"timestamp":"1729963740.0","poster":"carolctech","content":"Selected Answer: B\nB) BigQuery is designed for large-scale analytics, while Spanner (options A and C) is not, since it is more suited for transactional workloads. The Dataflow pipeline should be used to transform the Avro files into Parquet before ingesting it into BigQuery and is also optimal for feature engineering tasks. Vertex AI Feature Store is specifically designed for online feature management and serving, while storing features in BigQuery is not the best option for online prediction, due to potential latency.","comment_id":"1303355","upvote_count":"1"},{"comment_id":"1242972","upvote_count":"1","poster":"AzureDP900","content":"B is right \nThe original audio recordings have an 8 kHz sample rate, which is sufficient for speech recognition.\n\nUsing the Speech-to-Text API with synchronous recognition would require your application to wait for the transcription process to complete before proceeding. This could lead to performance issues and delays in processing large volumes of audio data.\n\nAsynchronous recognition, on the other hand, allows your application to continue processing without waiting for the transcription process to complete. The transcribed text can be retrieved later when needed.","timestamp":"1720205760.0"},{"timestamp":"1719669480.0","content":"Selected Answer: B\n\"performs analytics\" = Bigquery\n\"hosts the features\" = Vertex AI Feature Store\"","upvote_count":"1","poster":"VinaoSilva","comment_id":"1239310"},{"upvote_count":"2","poster":"emsherff","comment_id":"1192693","timestamp":"1712723580.0","content":"Selected Answer: B\nVertex AI Feature Store is designed for managing and serving features for online prediction with low latency."},{"upvote_count":"1","timestamp":"1712421540.0","comments":[{"upvote_count":"4","poster":"b2aaace","timestamp":"1713097080.0","comment_id":"1195493","content":"FYI BigQuery supports the Avro format. Please check your facts"}],"content":"Selected Answer: A\nI think the answer is A because BigQuery does not support Avro format but CloudSpanner does.","comment_id":"1190509","poster":"MultiCloudIronMan"}],"question_text":"You work at a large organization that recently decided to move their ML and data workloads to Google Cloud. The data engineering team has exported the structured data to a Cloud Storage bucket in Avro format. You need to propose a workflow that performs analytics, creates features, and hosts the features that your ML models use for online prediction. How should you configure the pipeline?","answer_ET":"B","exam_id":13,"unix_timestamp":1708352700,"topic":"1","timestamp":"2024-02-19 15:25:00","answer_images":[],"question_id":203,"answer_description":"","answers_community":["B (93%)","7%"],"isMC":true,"choices":{"C":"Ingest the Avro files into Cloud Spanner to perform analytics. Use a Dataflow pipeline to create the features, and store them in BigQuery for online prediction.","A":"Ingest the Avro files into Cloud Spanner to perform analytics. Use a Dataflow pipeline to create the features, and store them in Vertex AI Feature Store for online prediction.","D":"Ingest the Avro files into BigQuery to perform analytics. Use BigQuery SQL to create features and store them in a separate BigQuery table for online prediction.","B":"Ingest the Avro files into BigQuery to perform analytics. Use a Dataflow pipeline to create the features, and store them in Vertex AI Feature Store for online prediction."}},{"id":"4lPc12Y1RJc04V4Tna61","timestamp":"2024-02-12 09:24:00","url":"https://www.examtopics.com/discussions/google/view/133596-exam-professional-machine-learning-engineer-topic-1-question/","question_images":[],"answers_community":["B (64%)","D (36%)"],"answer_images":[],"question_text":"You work at an organization that maintains a cloud-based communication platform that integrates conventional chat, voice, and video conferencing into one platform. The audio recordings are stored in Cloud Storage. All recordings have an 8 kHz sample rate and are more than one minute long. You need to implement a new feature in the platform that will automatically transcribe voice call recordings into a text for future applications, such as call summarization and sentiment analysis. How should you implement the voice call transcription feature following Google-recommended best practices?","topic":"1","unix_timestamp":1707726240,"answer":"B","discussion":[{"content":"Selected Answer: D\nI went with D.\n\"following Google-recommended best practices\"\nhttps://cloud.google.com/speech-to-text/docs/optimizing-audio-files-for-speech-to-text#:~:text=We%20recommend%20a%20sample%20rate%20of%20at%20least%2016%20kHz%20in%20the%20audio%20files%20that%20you%20use%20for%20transcription%20with%20Speech%2Dto%2DText","poster":"CHARLIE2108","timestamp":"1711019760.0","upvote_count":"9","comment_id":"1179148"},{"content":"Selected Answer: B\nWe have longer than minute, 8KHz recordings.\n\nhttps://cloud.google.com/speech-to-text/docs/best-practices-provide-speech-data\n\"avoid re-sampling. For example, in telephony the native rate is commonly 8000 Hz, which is the rate that should be sent to the service.\"\n-> 8KHz\nhttps://cloud.google.com/speech-to-text/docs/sync-recognize\n\"Synchronous speech recognition returns the recognized text for short audio (less than 60 seconds). To process a speech recognition request for audio longer than 60 seconds, use Asynchronous Speech Recognition.\"\n-> asynchronous\n\nSo, the correct answer is B.","poster":"asmgi","comment_id":"1249851","timestamp":"1721237940.0","upvote_count":"6"},{"comment_id":"1326616","timestamp":"1734211320.0","upvote_count":"1","poster":"Pau1234","content":"Selected Answer: B\nAccording to the documentation: If possible, set the sampling rate of the audio source to 16000 Hz. Otherwise, set the sample_rate_hertz to match the native sample rate of the audio source (instead of re-sampling).\n\nhttps://cloud.google.com/speech-to-text/docs/best-practices-provide-speech-data"},{"content":"Selected Answer: B\nLower sampling rates may reduce accuracy. However, avoid re-sampling. For example, in telephony the native rate is commonly 8000 Hz, which is the rate that should be sent to the service.\n\nhttps://cloud.google.com/speech-to-text/docs/best-practices-provide-speech-data","upvote_count":"1","poster":"Omi_04040","timestamp":"1733767620.0","comment_id":"1324166"},{"upvote_count":"1","content":"Selected Answer: D\nWhile you can use the original 8 kHz sample rate, upsampling to 16 kHz is likely to improve transcription accuracy.","timestamp":"1732719540.0","comment_id":"1318733","poster":"AB_C"},{"comment_id":"1303351","timestamp":"1729962900.0","content":"Selected Answer: D\nThe correct answer is D because the Google Cloud Speech-to-Text API recommends a sample rate of 16 kHz for optimal performance. While it can handle 8 kHz, the accuracy will be significantly lower. Synchronous recognition means the API waits for the entire audio file to be processed before returning a result. This is fine for short audio clips, but for recordings longer than a minute (as specified), it's highly inefficient and could lead to timeouts or delays in the application. Asynchronous recognition allows the API to process the audio in the background, returning a notification when the transcription is complete. This is much better suited for longer audio files and doesn't block the application.","poster":"carolctech","upvote_count":"1"},{"timestamp":"1726347660.0","content":"Selected Answer: B\nAgree on B. If you read carefuly the documentation pointed will come to the conclusion that there is no need to upsample voice","poster":"wences","comment_id":"1283778","upvote_count":"3"},{"comment_id":"1228852","poster":"PhilipKoku","upvote_count":"4","timestamp":"1718171640.0","content":"Selected Answer: B\nB) Use original sampling rate and use asynchronous recognition...\n\"If possible, set the sampling rate of the audio source to 16000 Hz. Otherwise, set the sample_rate_hertz to match the native sample rate of the audio source (instead of re-sampling).\"\nhttps://cloud.google.com/speech-to-text/docs/best-practices-provide-speech-data#sampling_rate"},{"timestamp":"1716349740.0","content":"Selected Answer: B\nAccording to google recommandation on Sampling rate: \"If possible, set the sampling rate of the audio source to 16000 Hz. Otherwise, set the sample_rate_hertz to match the native sample rate of the audio source (instead of re-sampling).\"\nSo we should match the native sample (8kHz) in the question.","comment_id":"1215381","poster":"livewalk","upvote_count":"3"},{"comment_id":"1199602","upvote_count":"2","poster":"pinimichele01","content":"Selected Answer: B\nhttps://cloud.google.com/speech-to-text/docs/best-practices-provide-speech-data: Capture audio with a sampling rate of 16,000 Hz or higher. Lower sampling rates may reduce accuracy. However, avoid re-sampling. For example, in telephony the native rate is commonly 8000 Hz, which is the rate that should be sent to the service.\n\n\nhttps://cloud.google.com/speech-to-text/docs/optimizing-audio-files-for-speech-to-text#sample_rate_frequency_range: It's possible to convert from one sample rate to another. However, there's no benefit to up-sampling the audio, because the frequency range information is limited by the lower sample rate and can't be recovered by converting to a higher sample rate. \n\n\n-----> B, not D","timestamp":"1713695700.0"},{"timestamp":"1713636180.0","upvote_count":"2","comment_id":"1199300","poster":"SahandJ","content":"Selected Answer: B\nAccording to the documentation, it's best to have 16 KHz sample rate, however one should avoid up-sampling and rather use the native sample rate"},{"content":"Selected Answer: B\nFollowing best practices, the easiest choice is B","comment_id":"1196115","upvote_count":"2","poster":"ludovikush","timestamp":"1713196680.0"},{"upvote_count":"1","poster":"omermahgoub","comment_id":"1194769","content":"Selected Answer: D\nUpsample to 16 kHz and Use Asynchronous Speech-to-Text Recognition","timestamp":"1712994840.0"},{"comment_id":"1186230","poster":"tavva_prudhvi","timestamp":"1711820520.0","content":"Selected Answer: D\nUpsampling to 16 kHz:\nThe Speech-to-Text API recommends an audio sample rate of 16 kHz for optimal transcription accuracy. Upsampling the 8 kHz recordings to 16 kHz will improve the quality of the transcription.\n\nAsynchronous Recognition:\nAsynchronous recognition is suitable for longer audio recordings (more than one minute). It allows you to submit the audio file and receive the transcription results later, which is more efficient for batch processing.\n\nhttps://cloud.google.com/speech-to-text/docs/best-practices-provide-speech-data","upvote_count":"4"},{"upvote_count":"2","comment_id":"1154008","timestamp":"1708353000.0","content":"Selected Answer: B\nMy Answer: B\n\n- Not necessary upsampling (exclude C and D)\n- Asynchronous means executing different tasks with no sequential order. Therefore, is preferred over synchronous recognition for longer audio recordings as it allows for more efficient processing, especially when dealing with larger volumes of data.","poster":"guilhermebutzke"},{"comment_id":"1147897","timestamp":"1707726240.0","content":"Selected Answer: B\nB\n\nhttps://cloud.google.com/speech-to-text/docs/speech-to-text-requests#:~:text=Synchronous%20recognition%20requests%20are%20limited,periodically%20poll%20for%20recognition%20results.","poster":"Yan_X","upvote_count":"3"}],"choices":{"C":"Upsample the audio recordings to 16 kHz, and transcribe the audio by using the Speech-to-Text API with synchronous recognition.","A":"Use the original audio sampling rate, and transcribe the audio by using the Speech-to-Text API with synchronous recognition.","B":"Use the original audio sampling rate, and transcribe the audio by using the Speech-to-Text API with asynchronous recognition.","D":"Upsample the audio recordings to 16 kHz, and transcribe the audio by using the Speech-to-Text API with asynchronous recognition."},"question_id":204,"exam_id":13,"answer_ET":"B","answer_description":"","isMC":true},{"id":"WDG6KJJWVjxf5qJiBANS","answers_community":["C (100%)"],"url":"https://www.examtopics.com/discussions/google/view/134192-exam-professional-machine-learning-engineer-topic-1-question/","exam_id":13,"question_id":205,"choices":{"A":"Create a Vertex AI Workbench notebook instance. In the notebook, extract sentences from the documents, and train a custom AutoML text model.","B":"Use Google Translate to translate 1,000 phrases from Spanish to English. Using these translated pairs, train a custom AutoML Translation model.","D":"Create a Vertex AI Workbench notebook instance. In the notebook, convert the Spanish documents into plain text, and create a custom TensorFlow seq2seq translation model.","C":"Use the Document Translation feature of the Cloud Translation API to translate the documents."},"unix_timestamp":1708353240,"topic":"1","answer_ET":"C","answer_images":[],"answer_description":"","question_text":"You work for a multinational organization that has recently begun operations in Spain. Teams within your organization will need to work with various Spanish documents, such as business, legal, and financial documents. You want to use machine learning to help your organization get accurate translations quickly and with the least effort. Your organization does not require domain-specific terms or jargon. What should you do?","discussion":[{"comment_id":"1154012","poster":"guilhermebutzke","upvote_count":"5","content":"Selected Answer: C\nMy Answer: C\n\nThis option provides a straightforward solution for translating various types of documents (business, legal, financial) quickly and with minimal effort. It leverages Google's Cloud Translation API, which is designed specifically for tasks like this and eliminates the need for manual training or customization.\n\nhttps://cloud.google.com/translate/docs","timestamp":"1708353240.0"},{"content":"Selected Answer: C\nThe Document Translation feature of the Cloud Translation API is the quicker solution, and it will lead to the least effort as required in the statement. Since your organization does not require domain-specific terms or jargon, no custom solution is needed in this case, which confirms C as the best option.","poster":"carolctech","comment_id":"1303350","timestamp":"1729962660.0","upvote_count":"2"},{"upvote_count":"2","comment_id":"1239316","content":"Selected Answer: C\n\"translations quickly and with the least effort\" = Cloud Translation API","poster":"VinaoSilva","timestamp":"1719669900.0"},{"upvote_count":"2","content":"Selected Answer: C\nCloud Translation API - Document Translation: This pre-built service is specifically designed for translating large volumes of documents while preserving the document structure and formatting. It supports various languages, including Spanish, and offers high accuracy for general-purpose translations without domain-specific requirements.\nLeast Effort: Cloud Translation API requires minimal setup. You can directly submit your Spanish documents to the API and receive translated versions in English. There's no need for custom model training or data preparation.","comment_id":"1196433","timestamp":"1713252120.0","poster":"fitri001"},{"timestamp":"1712994960.0","poster":"omermahgoub","comment_id":"1194772","content":"Selected Answer: C\nLeverage Document Translation in Cloud Translation API","upvote_count":"1"}],"timestamp":"2024-02-19 15:34:00","question_images":[],"isMC":true,"answer":"C"}],"exam":{"provider":"Google","isImplemented":true,"lastUpdated":"11 Apr 2025","numberOfQuestions":304,"isMCOnly":true,"id":13,"name":"Professional Machine Learning Engineer","isBeta":false},"currentPage":41},"__N_SSP":true}