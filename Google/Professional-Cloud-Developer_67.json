{"pageProps":{"questions":[{"id":"HpA1iczmBycDr3c0csEs","choices":{"C":"Use rolling updates deployment","A":"Use canary deployment","D":"Use A/B testing with traffic mirroring during deployment","B":"Use blue/green deployment"},"discussion":[{"timestamp":"1645278000.0","comment_id":"550939","upvote_count":"8","content":"D due to \"full production load\"","poster":"Ksamilosb"},{"upvote_count":"1","content":"Selected Answer: D\nA/B Testing with Traffic Mirroring: This approach allows you to send a portion of your live production traffic to both the new and existing versions of your application simultaneously. This provides a realistic test environment with real-world load, allowing you to gather performance metrics for both versions side-by-side. Traffic mirroring ensures that the new version is tested under the same conditions as the existing version, providing a more accurate comparison.","poster":"thewalker","comment_id":"1250340","comments":[{"timestamp":"1721302380.0","comment_id":"1250341","upvote_count":"1","poster":"thewalker","content":"A. Canary Deployment: While canary deployment is useful for gradual rollouts and testing, it primarily focuses on testing the new version in a limited environment. It doesn't necessarily provide a full production load test.\nB. Blue/Green Deployment: Blue/green deployment involves switching traffic between two identical environments. While it allows for zero downtime deployments, it doesn't provide a way to test both versions simultaneously with live traffic.\nC. Rolling Updates Deployment: Rolling updates gradually replace instances with new versions. This approach doesn't offer a way to test both versions with live traffic simultaneously."}],"timestamp":"1721302380.0"},{"content":"Selected Answer: D\nCanary will only redirect a small portion of the traffic, while A/B with mirroring will test the new version in full load","timestamp":"1700499060.0","comment_id":"1075613","poster":"Aeglas","upvote_count":"2"},{"content":"Selected Answer: D\nA/B testing with traffic mirroring during deployment. This technique allows you to divert a portion of the live production traffic to the new application version while still serving the majority of the traffic to the existing version. By comparing the performance metrics of both versions under real-world conditions, you can assess the impact of the new deployment on your applicationâ€™s performance and stability.","upvote_count":"2","comment_id":"1011974","poster":"__rajan__","timestamp":"1695190740.0"},{"comment_id":"795151","timestamp":"1675257420.0","upvote_count":"3","content":"Selected Answer: D\n\"You need to test against the full production load prior to launch\" It's impossible with canary. \n\"A/B testing with traffic mirroring during deployment\" is the only one possibility we have to test the entire traffic before the roll out.","poster":"Foxal"},{"upvote_count":"1","comment_id":"752544","poster":"zellck","content":"Selected Answer: D\nD is the answer.","timestamp":"1671638160.0"},{"upvote_count":"1","comment_id":"684569","poster":"[Removed]","content":"D, the question requires more than just \"a load\" rather the \"full load\" the only strategy where this happens is A/B testing","timestamp":"1664677920.0"},{"timestamp":"1660975200.0","upvote_count":"2","poster":"tomato123","content":"Selected Answer: D\nD is correct","comment_id":"649262"},{"content":"Selected Answer: D\nAfter giving a deliberate thought, I think it's option D. \nThe keyword here is 'gather performance metrics,' and as everyone must know A/B testing's whole purpose is to gather performance metrics.","timestamp":"1659675900.0","comment_id":"642735","poster":"akshaychavan7","upvote_count":"1"},{"comment_id":"629912","poster":"nehaxlpb","timestamp":"1657527300.0","content":"Selected Answer: A\nCorrect Answer is Shadow test pattern, as it is not in the option selected D \nhttps://cloud.google.com/architecture/application-deployment-and-testing-strategies#shadow_test_pattern","upvote_count":"2"},{"content":"D is my answer","poster":"szl0144","upvote_count":"2","comment_id":"603063","timestamp":"1652828340.0"},{"content":"Selected Answer: A\nVote A","timestamp":"1651121100.0","upvote_count":"1","poster":"nqthien041292","comment_id":"593526"},{"poster":"dishum","content":"Full production - A/B testing, option D","comment_id":"579540","timestamp":"1648819980.0","upvote_count":"1"},{"content":"Canary can test live production traffic on production (Answer A) https://cloud.google.com/architecture/application-deployment-and-testing-strategies#key_benefits_4","poster":"htakami","comments":[{"timestamp":"1654587240.0","content":"is it possible that right answer is not present. To me the answer is \"Shadow Test Pattern\" https://cloud.google.com/architecture/application-deployment-and-testing-strategies#shadow_test_pattern. Do you agree ?","poster":"plaffoniera","upvote_count":"1","comment_id":"612625"}],"timestamp":"1648257180.0","comment_id":"575317","upvote_count":"2"},{"comment_id":"559153","content":"Correct answer is A:\n\nCanary deployment is a technique to reduce the risk of introducing a software update in production by slowly rolling out the change to a small subset of users before making it available to everybody. \n\nThis deployment technique is one where the SRE of an application development team relies on a router or load balancer to target individual routes. They target a small fragment of the overall user base with the newer version of the application. Once this new set of users are have used the application important metrics will be collected and analyzed to decide whether the new update is good for a full scale rolled to all the users or whether it needs to be rolled back for further troubleshooting.","poster":"ESP_SAP","upvote_count":"2","timestamp":"1646190180.0"},{"poster":"GCPCloudArchitectUser","timestamp":"1645834380.0","upvote_count":"3","comment_id":"556327","content":"Selected Answer: D\nyou want to use live traffic to gather performance metrics for both new and existing applications"},{"timestamp":"1642768020.0","upvote_count":"1","content":"Agree with Option A","poster":"Blueocean","comment_id":"529126"},{"timestamp":"1641724200.0","upvote_count":"1","content":"I vote A","comment_id":"520114","poster":"scaenruy"}],"timestamp":"2022-01-09 11:30:00","url":"https://www.examtopics.com/discussions/google/view/69738-exam-professional-cloud-developer-topic-1-question-92/","answer_images":[],"unix_timestamp":1641724200,"exam_id":7,"question_text":"You are designing a deployment technique for your new applications on Google Cloud. As part of your deployment planning, you want to use live traffic to gather performance metrics for both new and existing applications. You need to test against the full production load prior to launch. What should you do?","answer":"D","isMC":true,"answers_community":["D (83%)","A (17%)"],"question_id":331,"topic":"1","answer_ET":"D","question_images":[],"answer_description":""},{"id":"MCB1gjDVwxwBuJjUp5M2","choices":{"B":"Retry each failure at a set time interval up to a maximum number of times.","A":"Retry the failures in batch after a set number of failures is logged.","D":"Retry each failure at decreasing time intervals up to a maximum number of tries.","C":"Retry each failure at increasing time intervals up to a maximum number of tries."},"answer_images":[],"discussion":[{"comment_id":"1075614","upvote_count":"1","content":"Selected Answer: C\nExponential backoff with limit","timestamp":"1732121520.0","poster":"Aeglas"},{"comment_id":"821534","poster":"Pime13","timestamp":"1708869240.0","upvote_count":"1","content":"Selected Answer: C\nexponential backoff algorithm retries"},{"content":"Selected Answer: C\nC is the answer.\n\nhttps://cloud.google.com/storage/docs/retry-strategy#exponential-backoff\nTruncated exponential backoff is a standard error handling strategy for network applications in which a client periodically retries a failed request with increasing delays between requests.\n\nAn exponential backoff algorithm retries requests exponentially, increasing the waiting time between retries up to a maximum backoff time.","timestamp":"1703173980.0","comment_id":"752536","upvote_count":"1","poster":"zellck"},{"comment_id":"649263","upvote_count":"2","poster":"tomato123","content":"Selected Answer: C\nC is correct","timestamp":"1692511260.0"},{"comment_id":"529127","poster":"Blueocean","content":"Agree with Option C","timestamp":"1674304080.0","upvote_count":"4"},{"poster":"scaenruy","comment_id":"520118","content":"I vote C\nhttps://cloud.google.com/storage/docs/retry-strategy","upvote_count":"3","timestamp":"1673260500.0"}],"isMC":true,"url":"https://www.examtopics.com/discussions/google/view/69739-exam-professional-cloud-developer-topic-1-question-93/","answers_community":["C (100%)"],"topic":"1","exam_id":7,"question_id":332,"answer_ET":"C","question_text":"You support an application that uses the Cloud Storage API. You review the logs and discover multiple HTTP 503 Service Unavailable error responses from the\nAPI. Your application logs the error and does not take any further action. You want to implement Google-recommended retry logic to improve success rates.\nWhich approach should you take?","question_images":[],"unix_timestamp":1641724500,"answer_description":"","answer":"C","timestamp":"2022-01-09 11:35:00"},{"id":"nseAKf51BJSlTeRmbj6s","answer_description":"","isMC":true,"unix_timestamp":1641706920,"url":"https://www.examtopics.com/discussions/google/view/69715-exam-professional-cloud-developer-topic-1-question-94/","timestamp":"2022-01-09 06:42:00","topic":"1","choices":{"D":"Create one Pub/Sub topic per authentication service. Create one pull subscription per topic to be used by one audit service.","A":"Create one Pub/Sub topic. Create one pull subscription to allow the audit services to share the messages.","C":"Create one Pub/Sub topic. Create one push subscription with the endpoint pointing to a load balancer in front of the audit services.","E":"Create one Pub/Sub topic per authentication service. Create one push subscription per topic, with the endpoint pointing to one audit service.","B":"Create one Pub/Sub topic. Create one pull subscription per audit service instance to allow the services to share the messages."},"answers_community":["A (79%)","7%","7%"],"question_images":[],"question_text":"You need to redesign the ingestion of audit events from your authentication service to allow it to handle a large increase in traffic. Currently, the audit service and the authentication system run in the same Compute Engine virtual machine. You plan to use the following Google Cloud tools in the new architecture:\nâœ‘ Multiple Compute Engine machines, each running an instance of the authentication service\nâœ‘ Multiple Compute Engine machines, each running an instance of the audit service\nâœ‘ Pub/Sub to send the events from the authentication services.\nHow should you set up the topics and subscriptions to ensure that the system can handle a large volume of messages and can scale efficiently?","question_id":333,"answer_images":[],"answer":"A","answer_ET":"A","discussion":[{"timestamp":"1643124540.0","comment_id":"532233","upvote_count":"12","poster":"gfr892","comments":[{"poster":"akshaychavan7","comment_id":"642745","upvote_count":"1","content":"This seems to be a smart answer and follows the logic with which I was thinking.","timestamp":"1659676860.0"}],"content":"https://cloud.google.com/pubsub/docs/subscriber\n\"Multiple subscribers can make pull calls to the same \"shared\" subscription. Each subscriber will receive a subset of the messages.\"\nResponse is A.\nWith C and D you can't scale efficiently, because you have to create a topic for each new instance of the authentication service."},{"poster":"telp","timestamp":"1673615400.0","upvote_count":"5","comment_id":"774512","content":"Selected Answer: A\nA is correct. This is the most flexible way to scale, allowing the authentication and audit services to be sized independently according to load.\nB is incorrect. This will cause messages to be duplicated, one copy per subscription.\nC is incorrect. This will allow the system to scale, but push subscriptions are less suited to handle large volumes of messages.\nD is incorrect. This will allow the system to scale, however each audit service will listen to all subscriptions.\nE. is incorrect. This will allow the system to scale, however it will require each audit service to listen to all subscriptions. Also push subscriptions are less suited to handle large volumes of messages."},{"poster":"dneves","content":"Selected Answer: B\nAnswer B. One topic, one pull subscription per audit service:\n\nEven distribution of messages\nNo message duplication\nScales horizontally\nEach instance gets unique messages","timestamp":"1734888540.0","comment_id":"1330494","upvote_count":"1"},{"content":"Selected Answer: C\nThe best approach here is C. Create one Pub/Sub topic. Create one push subscription with the endpoint pointing to a load balancer in front of the audit services.\n\nHere's why:\n\nScalability: A single Pub/Sub topic allows you to centralize all audit events. This makes it easy to scale the authentication services by adding more instances without needing to change the Pub/Sub configuration.\nLoad Balancing: Using a push subscription with a load balancer in front of the audit services ensures that the incoming messages are distributed evenly across the available audit service instances. This prevents any single instance from becoming overloaded.\nEfficiency: Push subscriptions are more efficient than pull subscriptions for high-volume scenarios. This is because the Pub/Sub service actively pushes messages to the subscribers, reducing the need for the audit services to constantly poll for new messages.","upvote_count":"1","poster":"thewalker","comments":[{"content":"Why other options are less ideal:\n\nA. Create one Pub/Sub topic. Create one pull subscription to allow the audit services to share the messages. This would create a bottleneck at the single pull subscription, as all audit services would need to compete for messages.\nB. Create one Pub/Sub topic. Create one pull subscription per audit service instance to allow the services to share the messages. This would be less efficient than push subscriptions and could lead to uneven message distribution.\nD. Create one Pub/Sub topic per authentication service. Create one pull subscription per topic to be used by one audit service. This would require a lot of topics and subscriptions, making the system more complex to manage.\nE. Create one Pub/Sub topic per authentication service. Create one push subscription per topic, with the endpoint pointing to one audit service. This would create a one-to-one relationship between authentication services and audit services, which is not scalable.","timestamp":"1721360100.0","poster":"thewalker","comment_id":"1250805","upvote_count":"1"}],"comment_id":"1250804","timestamp":"1721360100.0"},{"comment_id":"1075619","upvote_count":"1","content":"Selected Answer: A\nMost simple and efficient one is A","timestamp":"1700499420.0","poster":"Aeglas"},{"comment_id":"1073593","content":"Selected Answer: E\nOption E is a more scalable and efficient solution for handling a large volume of messages and scaling efficiently.","upvote_count":"1","poster":"braska","timestamp":"1700251320.0"},{"poster":"__rajan__","content":"Selected Answer: A\nI would go with A.","comment_id":"1011979","upvote_count":"1","timestamp":"1695191220.0"},{"poster":"Yochen","content":"In my opinion, Option C would be the most efficient way to handle the scenario. Here's why:\n\nSingle Topic: Having one Pub/Sub topic keeps things simpler and allows all authentication service instances to publish to the same topic.\n\nPush Subscription with Load Balancer: This allows incoming messages to be distributed among all available audit service instances. The load balancer would handle distributing the load, making it easier for the audit service to scale out as needed.\n\nOption C ensures both scalability and efficient handling of a large volume of messages.","comment_id":"998908","upvote_count":"1","timestamp":"1693873560.0"},{"content":"Selected Answer: A\ni go for A + custom pubsub metric on autoscale","comment_id":"892306","upvote_count":"1","poster":"closer89","timestamp":"1683561120.0"},{"comment_id":"767571","content":"Answer is E, in which there is one topic per authentication service and one push subscription per topic, with the endpoint pointing to one audit service, is a better option because it allows the audit services to scale horizontally to handle a large volume of messages, and it allows the messages to be processed in parallel. Each authentication service will send messages directly to its own topic, which will be handled by a specific audit service. This will ensure that the system can scale horizontally to handle a large volume of messages, and it will also allow the audit services to process the messages in parallel.","poster":"omermahgoub","upvote_count":"1","timestamp":"1673005380.0","comments":[{"timestamp":"1673005440.0","content":"A, in which there is only one topic and one pull subscription, would not allow the audit services to scale horizontally to handle a large volume of messages, as they would all be pulling messages from the same subscription. If the volume of messages increased, the audit services would not be able to process them all in a timely manner, as they would be competing for messages from the same subscription.\n\nB, in which there is only one topic and one pull subscription per audit service, would also not allow the audit services to scale horizontally, as they would all be pulling messages from the same topic","upvote_count":"1","poster":"omermahgoub","comment_id":"767572"},{"poster":"omermahgoub","timestamp":"1673005500.0","content":"C, in which there is only one topic and one push subscription with a load balancer endpoint, would not allow the audit services to scale horizontally to handle a large volume of messages. The messages would all be sent to the same endpoint, which would be handled by the load balancer. If the volume of messages increased, the load balancer would not be able to distribute the messages to the audit services in a timely manner, as it would have to process all of the messages itself before forwarding them to the audit services. This could lead to bottlenecks if the volume of messages increased.","upvote_count":"1","comment_id":"767573"}]},{"content":"Selected Answer: A\nA is the answer.","comment_id":"752532","upvote_count":"1","poster":"zellck","timestamp":"1671637860.0"},{"poster":"tomato123","comment_id":"649264","timestamp":"1660975260.0","upvote_count":"2","content":"Selected Answer: A\nA is correct I think"},{"content":"While this can be between C and D , I would go with Option D considering the large volume mentioned in question","poster":"Blueocean","upvote_count":"1","comment_id":"529129","timestamp":"1642768260.0"},{"content":"I vote C","upvote_count":"2","poster":"scaenruy","comment_id":"520132","timestamp":"1641725220.0"},{"content":"Agree with D","poster":"ParagSanyashiv","timestamp":"1641706920.0","comment_id":"519933","upvote_count":"2"}],"exam_id":7},{"id":"feMuIfbiIifsHH4TppTA","question_text":"You are developing a marquee stateless web application that will run on Google Cloud. The rate of the incoming user traffic is expected to be unpredictable, with no traffic on some days and large spikes on other days. You need the application to automatically scale up and down, and you need to minimize the cost associated with running the application. What should you do?","timestamp":"2022-01-10 04:37:00","question_id":334,"question_images":[],"answer_images":[],"choices":{"C":"Build the application in Python with CloudSQL as the database. Deploy the application to App Engine standard environment.","D":"Build the application in Python with Firestore as the database. Deploy the application to a Compute Engine managed instance group with autoscaling.","B":"Build the application in C# with Firestore as the database. Deploy the application to App Engine flexible environment.","A":"Build the application in Python with Firestore as the database. Deploy the application to Cloud Run."},"isMC":true,"url":"https://www.examtopics.com/discussions/google/view/69794-exam-professional-cloud-developer-topic-1-question-95/","discussion":[{"timestamp":"1658486520.0","comments":[{"comment_id":"875940","upvote_count":"1","content":"\"you need to minimize the cost associated with running the application\"\ncloud run is cheaper, with 0.10 time granularity","poster":"closer89","timestamp":"1697829660.0"}],"poster":"p4","content":"Why C? I chose option A because of the DB option.\n\nboth Cloud run (A) and App Engine Standard (C) can scale to zero, so we need to find out the correct DB Firestore vs CloudSQL \nsince we donâ€™t know any details if data structures require relational or noSQL, Iâ€™d go for Firestore because it is more flexible in scalability than CloudSQL, and also you only pay per storage usage + operations","comment_id":"529848","upvote_count":"11"},{"comment_id":"556488","poster":"GCPCloudArchitectUser","content":"Selected Answer: A\nI agree with A as it is the only one fits for scale up and down =","upvote_count":"6","timestamp":"1661476980.0"},{"poster":"dneves","upvote_count":"1","timestamp":"1734888720.0","content":"Selected Answer: A\nAnswer A. Python + Firestore + Cloud Run:\n\nTruly serverless (scales to zero)\nPay only for actual usage\nHandles spikes well\nFirestore scales automatically\nMinimal management overhead\nLowest cost when no traffic","comment_id":"1330495"},{"timestamp":"1729128900.0","poster":"alpha_canary","content":"Selected Answer: A\nA: Building the application in Python with Firestore as the database and deploying the application to Cloud Run is a good approach. Cloud Run is designed to scale up and down automatically, even down to zero, which can help minimize costs when there's no traffic. Firestore is a serverless, NoSQL document database that can scale automatically to meet your application's needs.\n\nWhy C is rejected?\nC: While App Engine standard environment can scale down to zero instances, CloudSQL is not serverless and you are billed for the time that the database instance is running, which could increase costs when compared to Firestore.","upvote_count":"1","comment_id":"1196925"},{"poster":"Aeglas","content":"Selected Answer: A\nAlso Firestore has a free tier quota","timestamp":"1716217140.0","comment_id":"1075621","upvote_count":"1"},{"timestamp":"1715969040.0","content":"Selected Answer: A\nOption A is a suitable choice for building a stateless web application with unpredictable traffic, aiming to automatically scale up and down while minimizing costs","upvote_count":"1","poster":"braska","comment_id":"1073598"},{"comment_id":"1011981","content":"Selected Answer: A\nA is best suited here.","upvote_count":"1","poster":"__rajan__","timestamp":"1710923280.0"},{"upvote_count":"1","comment_id":"797917","poster":"[Removed]","content":"Selected Answer: A\nBoth Cloud Run and App Engine Standard Environment allow scaling to zero (which minimize the cost), but Cloud SQL can't be minimized to zero while firestore is measured based on CPU usage.\nSo from the cost point of view, A is the answer","timestamp":"1691143560.0"},{"poster":"omermahgoub","comment_id":"767556","content":"Answer is A: To minimize the cost of running the application and to allow it to automatically scale up and down based on incoming traffic, you should build the application in Python with Firestore as the database, and deploy it to Cloud Run. \n\nB and C, which involve deploying the application to App Engine, may also allow the application to automatically scale, but they may not be as cost-effective as Cloud Run. Option D, which involves deploying the application to a Compute Engine managed instance group, would allow the application to automatically scale, but it would not be as cost-effective as Cloud Run, as you would have to pay for the resources that you use even when there is no traffic.","upvote_count":"2","timestamp":"1688635800.0"},{"content":"Selected Answer: A\nA is the answer.","comment_id":"752492","timestamp":"1687353540.0","poster":"zellck","upvote_count":"1"},{"comment_id":"649265","upvote_count":"2","poster":"tomato123","content":"Selected Answer: A\nA is correct","timestamp":"1676880120.0"},{"content":"Selected Answer: A\nA because of \"stateless web app\"","timestamp":"1676860500.0","comment_id":"649127","upvote_count":"1","poster":"kinoko1330"},{"content":"It's simple, we need a stateless web app (not relational DB as Cloud SQL), and sometimes it scales down to zero utilization (only GAE flex & Cloud Run can do this). I'll go with option A as well.","upvote_count":"1","comment_id":"575322","comments":[{"timestamp":"1715625060.0","comment_id":"1069724","poster":"Kadhem","content":"GAE flex don't scale to zero","upvote_count":"1"},{"comment_id":"575324","poster":"htakami","content":"And if you were wondering why not B, C# is not a supported language for GAE","upvote_count":"1","timestamp":"1664148240.0"}],"poster":"htakami","timestamp":"1664148180.0"},{"poster":"ESP_SAP","content":"Correct Answer is A;\nThey are talking about minimize cost, with Cloud SQL isn't cheaper than Firestore.","upvote_count":"1","timestamp":"1662081180.0","comment_id":"559155"},{"content":"Agree with Option C","upvote_count":"2","poster":"Blueocean","timestamp":"1658454480.0","comment_id":"529577"},{"upvote_count":"1","poster":"scaenruy","timestamp":"1657417020.0","content":"I vote C","comment_id":"520612"}],"answer_description":"","unix_timestamp":1641785820,"exam_id":7,"answer_ET":"A","answers_community":["A (100%)"],"answer":"A","topic":"1"},{"id":"5TWkGFXuHzwgCifcRpfG","topic":"1","answers_community":["D (89%)","11%"],"question_text":"You have written a Cloud Function that accesses other Google Cloud resources. You want to secure the environment using the principle of least privilege. What should you do?","discussion":[{"content":"Agree with D","poster":"ParagSanyashiv","comment_id":"519957","upvote_count":"7","timestamp":"1657339440.0"},{"timestamp":"1729129140.0","comment_id":"1196930","poster":"alpha_canary","content":"Selected Answer: D\nhttps://cloud.google.com/functions/docs/securing/function-identity#individual:~:text=In%20order%20to,you%20this%20permission","upvote_count":"1"},{"timestamp":"1719456240.0","comment_id":"1106570","content":"Selected Answer: D\nQuoted from https://cloud.google.com/functions/docs/securing/function-identity#individual \n\"In order to deploy a function with a user-managed service account, the deployer must have the iam.serviceAccounts.actAs permission on the service account being deployed\"","poster":"Xoxoo","upvote_count":"2"},{"comment_id":"1077153","poster":"wanrltw","upvote_count":"1","timestamp":"1716361200.0","content":"Selected Answer: D\nhttps://cloud.google.com/functions/docs/securing/function-identity#individual"},{"comment_id":"1012040","upvote_count":"1","timestamp":"1710930300.0","poster":"__rajan__","content":"Selected Answer: B\nThis approach allows you to create a service account with a custom IAM role that provides only the necessary permissions required by your Cloud Function. By granting the deployer permission to get the access token, you ensure that they can obtain the necessary credentials to deploy and manage the Cloud Function."},{"timestamp":"1687353420.0","upvote_count":"2","content":"Selected Answer: D\nD is the answer.\n\nhttps://cloud.google.com/functions/docs/securing/function-identity#per-function_identity","poster":"zellck","comment_id":"752489"},{"timestamp":"1676880120.0","content":"Selected Answer: D\nD is correct","upvote_count":"2","poster":"tomato123","comment_id":"649266"},{"content":"D should be the correct choice here.\nIn Google Cloud, the resource(which can be a Cloud Function, a VM, etc.) always acts as a service account while accessing other resources.","timestamp":"1675591080.0","upvote_count":"1","poster":"akshaychavan7","comment_id":"642818"},{"timestamp":"1669538220.0","content":"What 'deployer' means here? The function itself? or the user who set up the function?","poster":"[Removed]","comments":[{"content":"B. \nhttps://cloud.google.com/functions/docs/securing/authenticating","upvote_count":"1","comment_id":"608392","comments":[{"content":"Changed the mind to D. (the note above is when you *invoke* the function, not to access other GCP services). \nhttps://cloud.google.com/functions/docs/securing/function-identity\n\"While IAM-defined service accounts are the preferred method for managing access in Google Cloud, some services might require other modes, such as an API key, OAuth 2.0 client, or service account key.\" \nand \n\"Note: In order to deploy a function with a user-managed service account, the deployer must have the iam.serviceAccounts.actAs permission on the service account being deployed.\"","upvote_count":"4","comment_id":"608661","timestamp":"1669711740.0","poster":"[Removed]"}],"poster":"[Removed]","timestamp":"1669646280.0"}],"upvote_count":"1","comment_id":"607947"}],"exam_id":7,"answer_description":"","isMC":true,"answer_images":[],"answer_ET":"D","timestamp":"2022-01-09 07:04:00","question_id":335,"answer":"D","question_images":[],"url":"https://www.examtopics.com/discussions/google/view/69716-exam-professional-cloud-developer-topic-1-question-96/","unix_timestamp":1641708240,"choices":{"B":"Create a new service account that has a custom IAM role to access the resources. The deployer is given permission to get the access token.","A":"Create a new service account that has Editor authority to access the resources. The deployer is given permission to get the access token.","C":"Create a new service account that has Editor authority to access the resources. The deployer is given permission to act as the new service account.","D":"Create a new service account that has a custom IAM role to access the resources. The deployer is given permission to act as the new service account."}}],"exam":{"lastUpdated":"11 Apr 2025","id":7,"numberOfQuestions":338,"isBeta":false,"isMCOnly":false,"isImplemented":true,"provider":"Google","name":"Professional Cloud Developer"},"currentPage":67},"__N_SSP":true}