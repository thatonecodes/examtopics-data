{"pageProps":{"questions":[{"id":"gnRnDr6GmkvCWj4xfs13","answer_description":"","discussion":[{"upvote_count":"1","timestamp":"1735121700.0","comment_id":"1331500","content":"Selected Answer: A\nGoogle Cloud VMware Engine allows you to run your VMware workloads natively on Google Cloud without requiring changes to your applications or infrastructure. This is ideal for minimizing disruption and maintaining compatibility with your current Oracle application footprint.","poster":"Zakky_09"},{"comment_id":"1325998","timestamp":"1734060420.0","upvote_count":"1","poster":"sky09","content":"Selected Answer: A\nGoogle Cloud VMware Engine (GCVE) provides a fully compatible VMware environment in the cloud."},{"timestamp":"1731124740.0","poster":"hanayome","comment_id":"1208645","upvote_count":"2","content":"Selected Answer: A\nobviously A"},{"timestamp":"1710746700.0","content":"Selected Answer: A\nLift , shift. Correct andswer is A.","comment_id":"1010280","poster":"goodsport","upvote_count":"3"},{"comment_id":"827443","upvote_count":"3","timestamp":"1693681680.0","content":"Selected Answer: A\nClassic lift and lift. Everything keeps the same structure. Therefore minimizing impact to zero.","poster":"Nirca"},{"content":"A.\nThe key here is the current architecture and minimal disruption to it. The simplest way to keep the current architecture is a live migrate using VMware. That can only mean one thing, use Oracle running in GCVE. \nYou could do B. There's nothing stopping you creating a VM in GCE, copying the Oracle binaries to it and spinning up an Oracle database or several. However, the licensing costs would not be attractive (if even supported), plus the migration would likely be disruptive. C is wrong because Cloud SQL doesn't support Oracle. D is wrong because that represents an architecture change.","timestamp":"1691176200.0","poster":"dynamic_dba","comment_id":"798366","upvote_count":"4"},{"poster":"chelbsik","timestamp":"1687791540.0","content":"Selected Answer: A\nSince there is no Bare Metal for Oracle option and VMware mentioned -> Choose VMware","upvote_count":"4","comment_id":"757665"},{"timestamp":"1687151400.0","poster":"Popa","comment_id":"749576","upvote_count":"2","content":"Selected Answer: A\nHere is the explanation: https://cloud.google.com/blog/products/databases/migrate-databases-to-google-cloud-vmware-engine-gcve"},{"poster":"range9005","content":"Selected Answer: A\nA GCVE VMware environment runs natively on Google Cloud bare metal infrastructure in some Google Cloud locations, and the GCVE service includes all the features required to help consume the VMware platforms efficiently and securely\n.\nhttps://cloud.google.com/blog/products/databases/migrate-databases-to-google-cloud-vmware-engine-gcve","upvote_count":"1","timestamp":"1687136460.0","comment_id":"749401"},{"upvote_count":"1","poster":"fredcaram","timestamp":"1687114800.0","content":"Oracle databases can only be migrated to bare metal solutions","comments":[{"upvote_count":"1","poster":"GCP72","comment_id":"753858","content":"Yes .GCP recommended to use Bare Metal solution for Oracle but option is missing in answers","timestamp":"1687489260.0"}],"comment_id":"749187"}],"isMC":true,"question_id":56,"url":"https://www.examtopics.com/discussions/google/view/92023-exam-professional-cloud-database-engineer-topic-1-question-3/","question_images":[],"answers_community":["A (100%)"],"timestamp":"2022-12-18 22:00:00","unix_timestamp":1671397200,"answer_images":[],"question_text":"Your company wants to move to Google Cloud. Your current data center is closing in six months. You are running a large, highly transactional Oracle application footprint on VMWare. You need to design a solution with minimal disruption to the current architecture and provide ease of migration to Google Cloud. What should you do?","choices":{"B":"Migrate applications and Oracle databases to Compute Engine.","A":"Migrate applications and Oracle databases to Google Cloud VMware Engine (VMware Engine).","D":"Migrate applications and Oracle databases to Google Kubernetes Engine (GKE).","C":"Migrate applications to Cloud SQL."},"exam_id":5,"answer":"A","topic":"1","answer_ET":"A"},{"id":"xo7H369MdyREW9toTht7","timestamp":"2022-12-20 21:43:00","answer_images":[],"exam_id":5,"question_text":"Your company uses the Cloud SQL out-of-disk recommender to analyze the storage utilization trends of production databases over the last 30 days. Your database operations team uses these recommendations to proactively monitor storage utilization and implement corrective actions. You receive a recommendation that the instance is likely to run out of disk space. What should you do to address this storage alert?","answer":"C","isMC":true,"discussion":[{"upvote_count":"6","timestamp":"1718908980.0","poster":"Kloudgeek","comment_id":"751452","content":"Correct answer is C: https://cloud.google.com/sql/docs/mysql/using-ood-recommender#apply_recommendations"},{"comment_id":"836586","upvote_count":"6","poster":"dynamic_dba","timestamp":"1726087200.0","content":"C.\nA is wrong since modifying the schemas to 3NF would use more disk. D is nonsense. B sounds vague at best and probably not supported at the database level. C is the best answer. The link provided by Kloudgeek is spot on."},{"content":"Selected Answer: C\nout of disk means need for more space","comment_id":"861185","timestamp":"1728052800.0","upvote_count":"1","poster":"Pilot50"},{"upvote_count":"1","timestamp":"1719320640.0","content":"C: Manually or automatically increase the storage capacity.","poster":"pk349","comment_id":"755751"},{"comment_id":"754903","timestamp":"1719229140.0","upvote_count":"2","poster":"GCP72","content":"Selected Answer: C\nC is the correct answer"},{"upvote_count":"1","comment_id":"754491","poster":"lapeyus","timestamp":"1719165780.0","content":"Selected Answer: C\nhttps://cloud.google.com/sql/docs/mysql/instance-settings#storage-capacity-2ndgen"},{"poster":"range9005","content":"Selected Answer: C\nManually or automatically increase the storage capacity.","comment_id":"752508","timestamp":"1718976840.0","upvote_count":"2"}],"choices":{"B":"Compress the data using a different compression algorithm.","A":"Normalize the database to the third normal form.","C":"Manually or automatically increase the storage capacity.","D":"Create another schema to load older data."},"question_id":57,"answers_community":["C (100%)"],"answer_description":"","topic":"1","answer_ET":"C","unix_timestamp":1671568980,"question_images":[],"url":"https://www.examtopics.com/discussions/google/view/92223-exam-professional-cloud-database-engineer-topic-1-question/"},{"id":"A4LAqNPYvfZUrILd4Mr3","question_text":"You are managing a mission-critical Cloud SQL for PostgreSQL instance. Your application team is running important transactions on the database when another DBA starts an on-demand backup. You want to verify the status of the backup. What should you do?","answers_community":["B (85%)","Other"],"unix_timestamp":1671570660,"url":"https://www.examtopics.com/discussions/google/view/92229-exam-professional-cloud-database-engineer-topic-1-question/","choices":{"C":"Use Cloud Audit Logs to verify the status.","D":"Use the Google Cloud Console.","A":"Check the cloudsql.googleapis.com/postgres.log instance log.","B":"Perform the gcloud sql operations list command."},"timestamp":"2022-12-20 22:11:00","discussion":[{"content":"B.\nA is wrong. The cloudsql.googleapis.com/postgres.log log file could be used to find out who started the backup operation, not the status of the operation. C is wrong for a similar reason. D is partially right. In the console there’s an Operations option in the menu on the left. Click that and it shows “Creating backup” together a start time. That’s not a million miles different from the gcloud sql operations list command which shows similar output except there’s a STATUS: line showing the word RUNNING while the backup is in progress. Given the question specifically mentions “status”, B would be the better answer. Just.","comment_id":"837222","upvote_count":"7","timestamp":"1694529240.0","poster":"dynamic_dba"},{"upvote_count":"2","comment_id":"1190239","timestamp":"1728191760.0","poster":"honeymania23","content":"gcloud sql backup list --instance= instance-id will give the status of backup for that particular instance. So B is good."},{"timestamp":"1712101140.0","comment_id":"1023495","poster":"juliorevk","content":"Selected Answer: B\nB to get the status using gcloud. D is possible but as mentioned, it doesn't specifically mention where in the console so B is a better answer.","upvote_count":"2"},{"comment_id":"1017153","content":"Selected Answer: B\nIf you want the status of the backup, then gcloud is the only viable option, as the Audit Logs will just tell you who started it.","timestamp":"1711401120.0","upvote_count":"1","poster":"theseawillclaim"},{"upvote_count":"1","comment_id":"907429","content":"Selected Answer: D\nUsing the Google Cloud Console is the most straightforward and convenient method for verifying the status of an on-demand backup for your mission-critical Cloud SQL for PostgreSQL instance. It provides a graphical interface that displays the backup status and any relevant details, enabling you to quickly assess the situation and ensure the integrity of your important transactions.","timestamp":"1701015060.0","poster":"KennyHuang"},{"upvote_count":"1","comment_id":"861188","poster":"Pilot50","content":"Selected Answer: B\noption C is to find out who started the backup, for the status B is correct","timestamp":"1696430580.0"},{"timestamp":"1693987980.0","comment_id":"830714","content":"Selected Answer: B\nB should the right answer: via \ngcloud sql operations list --instance=<instance_name>\ngcloud alpha sql operations list --instance=<instance_name>","poster":"Nirca","upvote_count":"1"},{"comment_id":"779984","upvote_count":"4","content":"Selected Answer: B\nShould be B\nPerform the gcloud sql operations list command\n\nhttps://cloud.google.com/sql/docs/postgres/backup-recovery/backups#troubleshooting-backups\n\nUnder Troubleshooting:\nIssue: \"You can't see the current operation's status.\"\n\nThe Google Cloud console reports only success or failure when the operation is done. It isn't designed to show warnings or other updates.\nRun the gcloud sql operations list command to list all operations for the given Cloud SQL instance.\n\nA and C iis wrong because there are used for WHO issued the Backup, but not the current status of the backup\nD is wrong only shows success or failure in the Cloud Console but not the current status of the backup","poster":"Sekierer","timestamp":"1689676320.0"},{"poster":"chelbsik","comment_id":"757709","upvote_count":"1","timestamp":"1687794900.0","content":"Selected Answer: B\nVote for B"},{"upvote_count":"1","poster":"pk349","content":"B: Perform the gcloud sql operations list ***** command.","comment_id":"755749","timestamp":"1687698240.0"},{"poster":"GCP72","timestamp":"1687607100.0","content":"Selected Answer: C\nC is the correct answer.log gives more information","upvote_count":"1","comment_id":"754909"},{"upvote_count":"1","timestamp":"1687354500.0","comment_id":"752510","poster":"range9005","content":"Selected Answer: B\nPerform the gcloud sql operations list command."},{"poster":"Kloudgeek","upvote_count":"2","timestamp":"1687288260.0","content":"Correct answer is B. https://cloud.google.com/sql/docs/postgres/backup-recovery/backups#troubleshooting-backups","comment_id":"751481"}],"exam_id":5,"topic":"1","answer_ET":"B","isMC":true,"answer":"B","answer_images":[],"question_images":[],"answer_description":"","question_id":58},{"id":"ImycKz14WR5oBjDEqlpe","question_id":59,"answer_images":[],"answer":"A","answer_ET":"A","question_text":"You support a consumer inventory application that runs on a multi-region instance of Cloud Spanner. A customer opened a support ticket to complain about slow response times. You notice a Cloud Monitoring alert about high CPU utilization. You want to follow Google-recommended practices to address the CPU performance issue. What should you do first?","discussion":[{"poster":"887ad17","content":"Selected Answer: A\nnot good answers ;) a think A+B correct","timestamp":"1737664440.0","upvote_count":"1","comment_id":"1345665"},{"comment_id":"1190240","timestamp":"1728191880.0","content":"A seems to be the first go to choice, if that does not resolve we can move to other options, But first A.","upvote_count":"2","poster":"honeymania23"},{"comment_id":"1007551","timestamp":"1710424380.0","upvote_count":"3","content":"Selected Answer: A\nIn case of high CPU utilization like, mentioned in question, refer: https://cloud.google.com/spanner/docs/identify-latency-point#:~:text=Check%20the%20CPU%20utilization%20of%20the%20instance.%20If%20the%20CPU%20utilization%20of%20the%20instance%20is%20above%20the%20recommended%20level%2C%20you%20should%20manually%20add%20more%20nodes%2C%20or%20set%20up%20auto%20scaling.\n\"Check the CPU utilization of the instance. If the CPU utilization of the instance is above the recommended level, you should manually add more nodes, or set up auto scaling.\"\n\nIndexes and schema are reviewed post identifying query with slow performance. Refer : https://cloud.google.com/spanner/docs/troubleshooting-performance-regressions#review-schema","poster":"njda"},{"timestamp":"1709682900.0","content":"I surprised with the chosen answer. The correct answer is B. When addressing high CPU utilization in a Google Cloud Spanner instance, you should first consider B. Modify the database schema, and add additional indexes. High CPU utilization in a database often occurs due to inefficient queries or lack of appropriate indexes.","comment_id":"999953","poster":"learnazureportal","upvote_count":"3","comments":[{"timestamp":"1718541120.0","upvote_count":"1","content":"So, any words mentioned the schema is not right? or it lacks index?","poster":"ArtistS","comment_id":"1098240"}]},{"content":"Selected Answer: D\nBy modifying the database schema and adding additional indexes, you can optimize query performance and potentially reduce the CPU utilization in Cloud Spanner. This approach focuses on improving the efficiency of the database and aligning it with the specific requirements of the consumer inventory application. It is important to monitor the impact of these changes and make further optimizations as needed.","poster":"KennyHuang","upvote_count":"1","comment_id":"907431","timestamp":"1701015360.0"},{"upvote_count":"3","timestamp":"1694529900.0","content":"A.\nB is wrong since that would increase CPU utilization even further and the question does not mention anything being wrong with index design. D is wrong since that would reduce CPU capacity and thus increase the load on the remaining CPUs. Cloud Spanner does not autoscale. It’s up to you to allocate the number of nodes or processing units to keep CPU utilization under 65%. So add more processing units.","comment_id":"837232","poster":"dynamic_dba"},{"comment_id":"755748","upvote_count":"2","content":"Compute capacity defines amount of server and storage resources that are available to the databases in an instance. When you create an instance, you specify its compute capacity as a number of processing ***** units or as a number of nodes, with 1000 processing units being equal to 1 node. \nrange9005","timestamp":"1687698180.0","poster":"pk349"},{"poster":"pk349","upvote_count":"1","timestamp":"1687698120.0","content":"A: Increase the number of processing units.","comment_id":"755747"},{"upvote_count":"2","content":"Selected Answer: A\nA is correct answer\nB is not correct because modifying schema is not a correct option","timestamp":"1687649400.0","comment_id":"755360","poster":"GCP72"},{"comment_id":"752515","timestamp":"1687354860.0","upvote_count":"2","poster":"range9005","content":"Selected Answer: A\nIncrease the number of processing units."}],"unix_timestamp":1671637260,"answers_community":["A (89%)","11%"],"timestamp":"2022-12-21 16:41:00","isMC":true,"url":"https://www.examtopics.com/discussions/google/view/92363-exam-professional-cloud-database-engineer-topic-1-question/","exam_id":5,"topic":"1","answer_description":"","question_images":[],"choices":{"A":"Increase the number of processing units.","B":"Modify the database schema, and add additional indexes.","D":"Decrease the number of processing units.","C":"Shard data required by the application into multiple instances."}},{"id":"P3LbfpqFQ22P4s86hMHx","question_id":60,"isMC":true,"timestamp":"2022-12-20 22:14:00","answers_community":["A (100%)"],"question_images":[],"answer_images":[],"answer_description":"","choices":{"C":"Recommend hard disk drives (HDD).","D":"Recommend mixed storage types.","B":"Recommend splitting the Bigtable instance into two instances in order to load balance the concurrent reads.","A":"Recommend solid-state drives (SSD)."},"topic":"1","exam_id":5,"question_text":"Your company uses Bigtable for a user-facing application that displays a low-latency real-time dashboard. You need to recommend the optimal storage type for this read-intensive database. What should you do?","answer":"A","unix_timestamp":1671570840,"discussion":[{"upvote_count":"1","comment_id":"1023500","poster":"juliorevk","timestamp":"1727913420.0","content":"Selected Answer: A\nSSD because this is the more highly performant PD type"},{"comment_id":"1017155","upvote_count":"1","timestamp":"1727291580.0","content":"Selected Answer: A\nA.\nData is split correctly on nodes if the row-key is well designed.","poster":"theseawillclaim"},{"poster":"CloudKida","content":"Selected Answer: A\nif you plan to store extensive historical data for a large number of remote-sensing devices and then use the data to generate daily reports, the cost savings for HDD storage might justify the performance tradeoff. On the other hand, if you plan to use the data to display a real-time dashboard, it probably would not make sense to use HDD storage—reads would be much more frequent in this case, and reads that are not scans are much slower with HDD storage.","upvote_count":"1","timestamp":"1719459180.0","comment_id":"934993"},{"content":"A.\nWhen you create a Bigtable instance you have to choose either SSD or HDD. The SSD options says, “Lower latency and more rows read per second. Typically used for real-time serving use cases, such as ad serving and mobile app recommendations”. User facing plus low latency plus read intensive equals SSD.","comment_id":"837238","upvote_count":"2","poster":"dynamic_dba","timestamp":"1710262200.0"},{"content":"Selected Answer: A\nA is correct answer ,Question is about storage type (hardware)","upvote_count":"2","poster":"Nirca","timestamp":"1709720280.0","comment_id":"830717"},{"timestamp":"1703516520.0","comment_id":"755746","upvote_count":"2","poster":"pk349","content":"A: Recommend solid-state drives ***** (SSD)."},{"poster":"GCP72","timestamp":"1703472180.0","comment_id":"755387","upvote_count":"2","content":"Selected Answer: A\nA is correct answer ,Question is about storage type so B is not a correct answer"},{"timestamp":"1703362500.0","comment_id":"754498","upvote_count":"1","poster":"lapeyus","content":"Selected Answer: A\nSSD is significantly faster and has more predictable performance than HDD."},{"timestamp":"1703173320.0","content":"Selected Answer: A\nRecommend solid-state drives (SSD)","poster":"range9005","upvote_count":"2","comment_id":"752517"},{"timestamp":"1703107620.0","poster":"fredcaram","content":"Selected Answer: A\nB is a right answer but it is not a storage type","comment_id":"751504","upvote_count":"1"},{"upvote_count":"3","timestamp":"1703106840.0","comment_id":"751491","poster":"Kloudgeek","content":"Correct answer is A. https://cloud.google.com/bigtable/docs/choosing-ssd-hdd"}],"url":"https://www.examtopics.com/discussions/google/view/92231-exam-professional-cloud-database-engineer-topic-1-question/","answer_ET":"A"}],"exam":{"name":"Professional Cloud Database Engineer","isBeta":false,"provider":"Google","id":5,"isImplemented":true,"numberOfQuestions":132,"isMCOnly":true,"lastUpdated":"11 Apr 2025"},"currentPage":12},"__N_SSP":true}