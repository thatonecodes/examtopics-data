{"pageProps":{"questions":[{"id":"3TdLLspkP50corscD7hh","url":"https://www.examtopics.com/discussions/google/view/131300-exam-professional-machine-learning-engineer-topic-1-question/","unix_timestamp":1705407240,"question_text":"You work for a pet food company that manages an online forum. Customers upload photos of their pets on the forum to share with others. About 20 photos are uploaded daily. You want to automatically and in near real time detect whether each uploaded photo has an animal. You want to prioritize time and minimize cost of your application development and deployment. What should you do?","answer":"A","answer_ET":"A","question_id":156,"discussion":[{"timestamp":"1705570980.0","poster":"b1a8fae","comments":[{"content":"Agree. The main purpose for google certification is to Promote GCP services.","poster":"louisaok","comment_id":"1300675","upvote_count":"3","timestamp":"1729466460.0"},{"timestamp":"1705847880.0","comment_id":"1127879","upvote_count":"4","content":"I think the same, if the question mentions other services and gives you an alternative that Google has, obviously, the \"best option\" is Google, although I think the same, I think that a model downloaded from a HUB would possibly save us a few how many euros..","poster":"Dagogi96"}],"comment_id":"1125672","upvote_count":"10","content":"Selected Answer: A\nA. B would also work and I wonder if cost would be lower, but I think going with the google hosted service is most times the most likely choice to be correct."},{"timestamp":"1733181420.0","comment_id":"1321134","upvote_count":"1","content":"Selected Answer: D\nOption D is optimal as it uses image classification with Vertex AutoML, which is simple to implement, cost-effective, and scalable.","poster":"rajshiv"},{"poster":"d6e1ae4","upvote_count":"1","content":"Selected Answer: D\nThe labeling process is simpler than object detection, as it's just a binary classification. AutoML simplifies the model creation process, reducing development time. For the relatively low volume of images (20 per day), this solution is likely to be cost-effective in the long run.\n\nWhy not A? Cloud Vision is overkill for a binary classification and it is very expensive.","timestamp":"1724327160.0","comment_id":"1270655"},{"poster":"gscharly","timestamp":"1713627300.0","comment_id":"1199215","content":"Selected Answer: A\nagree with b1a8fae","upvote_count":"1"},{"upvote_count":"2","content":"Selected Answer: B\nI went Option B","poster":"CHARLIE2108","comment_id":"1143619","timestamp":"1707328680.0"},{"content":"Selected Answer: A\nAs minimising time and cost are of priority and considering the small subset of images I believe A is the best option","comment_id":"1124176","poster":"shadz10","upvote_count":"4","timestamp":"1705407240.0"}],"answer_description":"","exam_id":13,"question_images":[],"topic":"1","isMC":true,"answers_community":["A (79%)","11%","11%"],"timestamp":"2024-01-16 13:14:00","choices":{"D":"Manually label previously submitted images as having animals or not. Create an image dataset on Vertex AI. Train a classification model by using Vertex AutoML to distinguish the two classes. Deploy the model to a Vertex AI endpoint. Send new user-submitted images to your model endpoint to classify whether each photo has an animal.","B":"Download an object detection model from TensorFlow Hub. Deploy the model to a Vertex AI endpoint. Send new user-submitted images to the model endpoint to classify whether each photo has an animal.","C":"Manually label previously submitted images with bounding boxes around any animals. Build an AutoML object detection model by using Vertex AI. Deploy the model to a Vertex AI endpoint Send new user-submitted images to your model endpoint to detect whether each photo has an animal.","A":"Send user-submitted images to the Cloud Vision API. Use object localization to identify all objects in the image and compare the results against a list of animals."},"answer_images":[]},{"id":"bJ9PZoXYDetnRUp4jAu2","answer":"C","isMC":true,"answer_ET":"C","unix_timestamp":1624351260,"question_images":[],"timestamp":"2021-06-22 10:41:00","topic":"1","answers_community":["C (100%)"],"choices":{"A":"Build a classification model","B":"Build a knowledge-based filtering model","D":"Build a regression model using the features as predictors","C":"Build a collaborative-based filtering model"},"discussion":[{"content":"C. Collaborative filtering is about user similarity and product recommendations. Other models won't work","poster":"maartenalexander","upvote_count":"22","timestamp":"1624351260.0","comment_id":"387744"},{"content":"Selected Answer: C\nCollaborative filtering models, a core technique in recommender systems, predict user preferences by analyzing interactions between users and items, identifying similar users or items, and recommending items liked by similar users or the user in question","upvote_count":"1","comment_id":"1471377","timestamp":"1743778260.0","poster":"coupet"},{"timestamp":"1729634640.0","upvote_count":"2","poster":"DaleR","comment_id":"1301729","content":"C. Collaborative filtering is a foundational model for building a recommendation system as the input dataset is simple and the embeddings are learned for you. Matrix factorization is simply the model that applies to the collaborative filtering."},{"timestamp":"1717677780.0","poster":"PhilipKoku","upvote_count":"1","content":"Selected Answer: C\nC) Collaborative filtering model","comment_id":"1225502"},{"content":"Selected Answer: C\nChat gPT:\nCollaborative filtering models are specifically designed for recommendation systems. They work by analyzing the interactions and behaviors of users and items, then making predictions about what users will like based on similarities with other users. In this case, since you're looking at purchase behavior and user similarities, a collaborative filtering approach is well-suited to identify and recommend products that users with similar behaviors have liked or purchased.\n\nClassification models (Option A) and regression models (Option D) are generally used for different types of predictive modeling tasks, not specifically for recommendations. A knowledge-based filtering model (Option B), while useful in recommendation systems, relies more on explicit knowledge about users and items, rather than on user interaction patterns and similarities, which seems to be the focus in this scenario.","timestamp":"1700060280.0","upvote_count":"2","comment_id":"1071565","poster":"Sum_Sum"},{"content":"C. Collaborative filtering is apt amongst the answers","upvote_count":"1","poster":"10SR","comment_id":"986864","timestamp":"1692644220.0"},{"poster":"M25","comment_id":"892701","timestamp":"1683608460.0","upvote_count":"2","content":"Selected Answer: C\nWent with C"},{"upvote_count":"1","poster":"wish0035","content":"Selected Answer: C\nans: C","comment_id":"746541","timestamp":"1671140700.0"},{"content":"Selected Answer: C\nC\nhttps://cloud.google.com/blog/topics/developers-practitioners/looking-build-recommendation-system-google-cloud-leverage-following-guidelines-identify-right-solution-you-part-i","timestamp":"1670495640.0","comment_id":"738894","poster":"hiromi","upvote_count":"1"},{"comment_id":"725708","upvote_count":"1","timestamp":"1669283040.0","content":"Selected Answer: C\nThis is a textbook application of collaborative filtering, C is the correct answer","poster":"EFIGO"},{"poster":"GCP72","timestamp":"1660567860.0","upvote_count":"1","content":"Selected Answer: C\nCorrect answer is \"C\"","comment_id":"647200"},{"comment_id":"615498","upvote_count":"1","content":"Selected Answer: C\nhttps://developers.google.com/machine-learning/recommendation/collaborative/basics","poster":"Mohamed_Mossad","timestamp":"1655068560.0"},{"content":"Selected Answer: C\nDefinitely C","upvote_count":"2","timestamp":"1646591580.0","poster":"giaZ","comment_id":"562212"},{"poster":"caohieu04","content":"Selected Answer: C\nCommunity vote","comment_id":"557915","upvote_count":"2","timestamp":"1646031960.0"},{"comment_id":"534266","content":"should be C","timestamp":"1643335140.0","poster":"xiaoF","upvote_count":"2"},{"comment_id":"464664","poster":"mousseUwU","content":"C - https://cloud.google.com/architecture/recommendations-using-machine-learning-on-compute-engine#filtering_the_data","upvote_count":"4","timestamp":"1634648580.0"}],"question_id":157,"answer_description":"","question_text":"You are an ML engineer at a global shoe store. You manage the ML models for the company's website. You are asked to build a model that will recommend new products to the user based on their purchase behavior and similarity with other users. What should you do?","exam_id":13,"answer_images":[],"url":"https://www.examtopics.com/discussions/google/view/55818-exam-professional-machine-learning-engineer-topic-1-question/"},{"id":"BcAkji5GrFior1NMfJ8o","answer_images":[],"discussion":[{"upvote_count":"6","comment_id":"1151632","timestamp":"1723758480.0","poster":"guilhermebutzke","content":"My answer: D\n\nA: Not correct: Batch Prediction is designed for offline processing of large datasets, not for immediate real-time predictions needed in this scenario.\nB: Not correct: While Cloud Functions offer real-time processing, loading the model files each time might introduce latency, especially for larger models\nC: Not correct: Using a VM is less scalable and more complex to manage compared to other options.\nD: CORRECT: Vertex AI Model Registry ensures proper model management, versioning, and access control while Vertex AI endpoint provides a highly scalable and managed solution for real-time online inference, ensuring immediate predictions after game sessions."},{"timestamp":"1729216800.0","comment_id":"1197632","upvote_count":"5","content":"Selected Answer: D\nLow Latency: Vertex AI Endpoints are specifically designed for low-latency online inference. They offer automatic scaling and efficient resource allocation, ensuring quick responses to game session completion signals.\nReal-time Decisions: This deployment method allows your game backend to send data from finished game sessions to the Vertex AI endpoint in near real-time. The endpoint can then make classifications (cheater or not cheater) promptly.\nManaged Service: Vertex AI handles the infrastructure management and scaling of your model, freeing you from managing servers or virtual machines (VMs).","poster":"fitri001","comments":[{"upvote_count":"2","poster":"fitri001","timestamp":"1729216800.0","content":"A. Vertex Batch Prediction: Batch prediction is designed for offline processing of large datasets, not real-time inference on individual game sessions.\nB. Cloud Function with Model Files: While Cloud Functions can be triggered by events, reading the model files each time and running inference can introduce latency. This might not be ideal for immediate classifications.\nC. Model Files in a VM: Loading the model on a VM for each inference request incurs significant overhead and latency. This approach is not suitable for real-time processing.","comment_id":"1197634"}]},{"timestamp":"1720848600.0","comment_id":"1121378","poster":"pikachu007","comments":[{"poster":"sonicclasps","timestamp":"1722412320.0","content":"although the game is multiplayer, and you could submit requests for all the players in the game that just ended, as a batch. So I think A is also an option","upvote_count":"1","comment_id":"1136608"}],"content":"Selected Answer: D\nOption A: Batch prediction is too slow for your needs.\nOption B: Cloud Functions are ideal for short-lived tasks, not for continuously serving models. Loading the model on every request would be inefficient.\nOption C: VMs offer less scalability and management overhead compared to Vertex AI.","upvote_count":"3"}],"question_id":158,"question_text":"You work at a mobile gaming startup that creates online multiplayer games. Recently, your company observed an increase in players cheating in the games, leading to a loss of revenue and a poor user experience You built a binary classification model to determine whether a player cheated after a completed game session, and then send a message to other downstream systems to ban the player that cheated. Your model has performed well during testing, and you now need to deploy the model to production. You want your serving solution to provide immediate classifications after a completed game session to avoid further loss of revenue. What should you do?","exam_id":13,"choices":{"A":"Import the model into Vertex AI Model Registry. Use the Vertex Batch Prediction service to run batch inference jobs.","D":"Import the model into Vertex AI Model Registry. Create a Vertex AI endpoint that hosts the model, and make online inference requests.","C":"Save the model files in a VM. Load the model files each time there is a prediction request, and run an inference job on the VM","B":"Save the model files in a Cloud Storage bucket. Create a Cloud Function to read the model files and make online inference requests on the Cloud Function."},"url":"https://www.examtopics.com/discussions/google/view/131060-exam-professional-machine-learning-engineer-topic-1-question/","answer_ET":"D","timestamp":"2024-01-13 08:30:00","question_images":[],"isMC":true,"topic":"1","answers_community":["D (100%)"],"answer":"D","unix_timestamp":1705131000,"answer_description":""},{"id":"VqdhxleE6sIRZJXaMcby","choices":{"C":"Add a component to the Vertex AI pipeline that logs metrics to Vertex ML Metadata. Use Vertex AI Experiments to compare different executions of the pipeline. Use Vertex AI TensorBoard to visualize metrics.","A":"Add a component to the Vertex AI pipeline that logs metrics to a BigQuery table. Query the table to compare different executions of the pipeline. Connect BigQuery to Looker Studio to visualize metrics.","B":"Add a component to the Vertex AI pipeline that logs metrics to a BigQuery table. Load the table into a pandas DataFrame to compare different executions of the pipeline. Use Matplotlib to visualize metrics.","D":"Add a component to the Vertex AI pipeline that logs metrics to Vertex ML Metadata. Load the Vertex ML Metadata into a pandas DataFrame to compare different executions of the pipeline. Use Matplotlib to visualize metrics."},"unix_timestamp":1704732360,"answer":"C","question_images":[],"answer_ET":"C","question_id":159,"question_text":"You have created a Vertex AI pipeline that automates custom model training. You want to add a pipeline component that enables your team to most easily collaborate when running different executions and comparing metrics both visually and programmatically. What should you do?","topic":"1","answer_description":"","exam_id":13,"url":"https://www.examtopics.com/discussions/google/view/130600-exam-professional-machine-learning-engineer-topic-1-question/","discussion":[{"content":"Selected Answer: C\nwent with C. Experiments can be used to compare executions and metrics","timestamp":"1713627540.0","upvote_count":"5","poster":"gscharly","comment_id":"1199220"},{"upvote_count":"1","timestamp":"1733857740.0","content":"Selected Answer: C\nVertex ML Metadata and Vertex AI Experiments provide APIs and SDKs that allow you to access and analyze metrics programmatically. This enables you to automate comparisons, generate reports, or perform custom analysis on your pipeline executions.","poster":"Omi_04040","comment_id":"1324719"},{"content":"I can see why C is tempting, but Vertex Experiment's isn't actually required here, just a nice to have, whereas Workbench is actually required as they say \"visually AND programatically\". It's literally the only answer that allows programmatic comparison of the data in the metadata store.","upvote_count":"1","comment_id":"1283196","timestamp":"1726234620.0","poster":"baimus"},{"poster":"fitri001","comment_id":"1197462","comments":[{"content":"Isn't BQ too much for a dozen of metrics?","poster":"asmgi","timestamp":"1720987620.0","upvote_count":"1","comment_id":"1247956"},{"comment_id":"1199789","timestamp":"1713721020.0","content":"why log on BQ and not to MetadataAI?","poster":"pinimichele01","upvote_count":"1"}],"upvote_count":"4","timestamp":"1713385380.0","content":"Selected Answer: A\nWhy A?\nBigQuery: Stores pipeline metrics from different executions in a central location, allowing easy access for team members.\nBigQuery Queries: Enables programmatic comparison of metrics across runs using SQL queries.\nLooker Studio: Provides a collaborative visualization platform for team members to explore and compare metrics visually.\nwhy not C?\nVertex AI Experiments and TensorBoard: While Vertex AI Experiments can leverage ML Metadata for lineage tracking, it's not ideal for general metric comparison. TensorBoard is primarily for visualizing training data during the pipeline execution, not comparing results across runs."},{"upvote_count":"3","timestamp":"1705571580.0","comment_id":"1125686","content":"Selected Answer: C\nClearly C.","poster":"b1a8fae"},{"comment_id":"1116803","content":"Selected Answer: C\nC is the correct one here","upvote_count":"2","poster":"winston9","timestamp":"1704732360.0"}],"timestamp":"2024-01-08 17:46:00","answers_community":["C (73%)","A (27%)"],"answer_images":[],"isMC":true},{"id":"n2j4WChyQED9hZ2JTCY5","answer":"B","answer_description":"","answer_images":[],"discussion":[{"poster":"fitri001","content":"Selected Answer: B\nWhy B?\nCentralized Tracking: Vertex AI Experiments provides a central location to track and compare models trained in both pipelines and notebooks.\nReduced Overhead: Submitting pipelines as experiment runs leverages the existing pipeline infrastructure for logging and avoids creating additional pipeline steps for all models.\nNotebook Integration: Vertex AI SDK allows notebooks to log parameters and metrics directly to the experiment, simplifying data collection from notebooks.\nwhy not C?\nC. All Models in Pipelines: Moving all models to pipelines might not be feasible or desirable. Pipelines are best suited for automated, repeatable training, while notebooks offer flexibility for exploration.","comment_id":"1197472","timestamp":"1729197120.0","upvote_count":"3"},{"poster":"omermahgoub","comment_id":"1195967","content":"Selected Answer: B\nB. Create a Vertex AI experiment. Submit all the pipelines as experiment runs. For models trained on notebooks log parameters and metrics by using the Vertex AI SDK.","timestamp":"1728986940.0","upvote_count":"2"},{"poster":"guilhermebutzke","timestamp":"1723759140.0","comment_id":"1151641","upvote_count":"3","content":"Selected Answer: B\nMy Answer: B\n\nA: Not Correct: Not the best approach compared with Vertex AI experiment that does the same\nB: CORRECT: By submitting all pipelines as experiment runs, you can centralize the storage of parameters and metrics for models trained in Vertex AI Pipelines. This approach minimizes effort by providing a unified platform for storing and comparing model performance across different services.\nC: Not Correct: not feasible or ideal for models trained on Vertex AI Workbench notebook instances.\nD: Not Correct: If only basic parameter and metric storage is needed, and your team prioritizes simplicity over in-depth comparison, option D could be an alternative. For more complex scenarios requiring comprehensive analysis and comparison across diverse models, option B with Vertex AI Experiments"},{"content":"Selected Answer: B\nDivided between B and C. But logging parameters of models sounds easier than re-implementing a large amount of models as Vertex AI pipelines.","poster":"b1a8fae","upvote_count":"3","timestamp":"1721485440.0","comment_id":"1127385"},{"upvote_count":"1","comment_id":"1123209","content":"Selected Answer: B\nB is The correct answer here I believe - \nVertex AI experiments - provides a unified way to store and compare model runs.\npipeline runs - It provides a unified way to store and compare model runs.\nnotebook instances - models trained on Vertex AI Workbench notebook instances, logging parameters and metrics using the Vertex AI SDK provides a consistent way to record the necessary information.","poster":"shadz10","timestamp":"1721027520.0"},{"content":"Selected Answer: C\nOptions A and B: Logging metrics to BigQuery involves additional setup and integration efforts.\nOption D: Loading Vertex ML Metadata into a pandas DataFrame for visualization requires manual work and doesn't leverage built-in visualization tools.","upvote_count":"1","poster":"pikachu007","comments":[{"content":"On option B there are no Logging metrics to BigQuery suggested.\nHence why B is correct.","poster":"felipepin","timestamp":"1724409900.0","upvote_count":"2","comment_id":"1157120"}],"timestamp":"1720850760.0","comment_id":"1121401"}],"question_id":160,"exam_id":13,"choices":{"C":"Implement all models in Vertex AI Pipelines Create a Vertex AI experiment, and associate all pipeline runs with that experiment.","B":"Create a Vertex AI experiment. Submit all the pipelines as experiment runs. For models trained on notebooks log parameters and metrics by using the Vertex AI SDK.","D":"Store all model parameters and metrics as model metadata by using the Vertex AI Metadata API.","A":"Implement an additional step for all the models running in pipelines and notebooks to export parameters and metrics to BigQuery."},"topic":"1","isMC":true,"question_images":[],"timestamp":"2024-01-13 09:06:00","answers_community":["B (92%)","8%"],"unix_timestamp":1705133160,"answer_ET":"B","question_text":"Your team is training a large number of ML models that use different algorithms, parameters, and datasets. Some models are trained in Vertex AI Pipelines, and some are trained on Vertex AI Workbench notebook instances. Your team wants to compare the performance of the models across both services. You want to minimize the effort required to store the parameters and metrics. What should you do?","url":"https://www.examtopics.com/discussions/google/view/131063-exam-professional-machine-learning-engineer-topic-1-question/"}],"exam":{"isBeta":false,"isImplemented":true,"lastUpdated":"11 Apr 2025","numberOfQuestions":304,"id":13,"name":"Professional Machine Learning Engineer","isMCOnly":true,"provider":"Google"},"currentPage":32},"__N_SSP":true}