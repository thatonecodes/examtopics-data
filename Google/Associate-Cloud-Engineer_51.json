{"pageProps":{"questions":[{"id":"IEuwMbrZGZO3DgNDSARm","answer_description":"","question_id":251,"topic":"1","choices":{"A":"1. Give the BigQuery Data Editor role on the platform-logs dataset to the service accounts used by your instances. 2. Update your instances' metadata to add the following value: logs-destination: bq://platform-logs.","C":"1. In Cloud Logging, create a filter to view only Compute Engine logs. 2. Click Create Export. 3. Choose BigQuery as Sink Service, and the platform-logs dataset as Sink Destination.","D":"1. Create a Cloud Function that has the BigQuery User role on the platform-logs dataset. 2. Configure this Cloud Function to create a BigQuery Job that executes this query: INSERT INTO dataset.platform-logs (timestamp, log) SELECT timestamp, log FROM compute.logs WHERE timestamp > DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY) 3. Use Cloud Scheduler to trigger this Cloud Function once a day.","B":"1. In Cloud Logging, create a logs export with a Cloud Pub/Sub topic called logs as a sink. 2. Create a Cloud Function that is triggered by messages in the logs topic. 3. Configure that Cloud Function to drop logs that are not from Compute Engine and to insert Compute Engine logs in the platform-logs dataset."},"answer_images":[],"answer_ET":"C","timestamp":"2021-03-16 22:30:00","exam_id":1,"answer":"C","unix_timestamp":1615930200,"url":"https://www.examtopics.com/discussions/google/view/47413-exam-associate-cloud-engineer-topic-1-question-68-discussion/","question_text":"For analysis purposes, you need to send all the logs from all of your Compute Engine instances to a BigQuery dataset called platform-logs. You have already installed the Cloud Logging agent on all the instances. You want to minimize cost. What should you do?","isMC":true,"answers_community":["C (94%)","6%"],"question_images":[],"discussion":[{"poster":"sumanshu","content":"vote for ''C\"\n\nhttps://cloud.google.com/logging/docs/export/configure_export_v2","timestamp":"1631820600.0","upvote_count":"23","comment_id":"312750"},{"comment_id":"379876","upvote_count":"8","poster":"vmart","timestamp":"1639241580.0","content":"I vote for C"},{"timestamp":"1722330720.0","poster":"Nitesh2000","content":"Option C","upvote_count":"2","comment_id":"1135711"},{"content":"The correct answer is C","timestamp":"1714980600.0","upvote_count":"1","comment_id":"1063687","poster":"BAofBK"},{"upvote_count":"2","comment_id":"1021505","timestamp":"1711811400.0","poster":"axantroff","content":"C, it's simple enough"},{"upvote_count":"1","comment_id":"996576","timestamp":"1709362020.0","poster":"Captain1212","content":"Selected Answer: C\nC , it minimizes the cost"},{"content":"Answer: C. Option C allows you to create a log export from Cloud Logging to BigQuery with minimal setup and cost. By creating a filter to view only Compute Engine logs, you ensure that only the relevant logs are exported to BigQuery, reducing unnecessary data transfer and storage costs.","timestamp":"1705781340.0","poster":"jayjani66","upvote_count":"3","comment_id":"957829"},{"content":"Selected Answer: B\nB looks like the most cost effective option since filtering out only the logs you need will reduce storage and data transfer costs.","poster":"Kyle1776","upvote_count":"1","comments":[{"upvote_count":"1","timestamp":"1702149540.0","content":"Correction - C","comment_id":"919488","poster":"Kyle1776"}],"timestamp":"1701357180.0","comment_id":"910268"},{"content":"Selected Answer: C\nThe most cost-effective and recommended solution to send logs from Compute Engine instances to BigQuery is to use the Cloud Logging agent with a sink that streams the logs to BigQuery.\n\nAnswer C is the most appropriate solution. In Cloud Logging, create a filter to view only Compute Engine logs. Click Create Export. Choose BigQuery as Sink Service, and the platform-logs dataset as Sink Destination. This will allow all Compute Engine instance logs to be exported to BigQuery with minimal complexity and cost.","comment_id":"815974","poster":"Buruguduystunstugudunstuy","timestamp":"1692563160.0","upvote_count":"3"},{"timestamp":"1686664320.0","poster":"David_Esteban","content":"Selected Answer: C\nMi vote is for \"c\"","comment_id":"744237","upvote_count":"1"},{"timestamp":"1686069840.0","content":"Selected Answer: C\nvote for ''C\"","comment_id":"737131","poster":"cslince","upvote_count":"1"},{"poster":"Charumathi","comment_id":"686760","timestamp":"1680688800.0","upvote_count":"3","content":"C. is correct, Sinks control how Cloud Logging routes logs. Using sinks, you can route some or all of your logs to supported destinations."},{"timestamp":"1671819480.0","comment_id":"621110","upvote_count":"1","content":"I will go with C..","poster":"AzureDP900"},{"comment_id":"611352","content":"Go for C","upvote_count":"1","timestamp":"1670142720.0","poster":"haroldbenites"},{"timestamp":"1663322880.0","content":"Selected Answer: C\nOutdated question. It's now about Cloud Sink, but C is the closest option","upvote_count":"5","poster":"somenick","comment_id":"569047"},{"comment_id":"521957","content":"I think it's C as all the other ones seem to get logs from everywhere not just Compute Engine!","timestamp":"1657603440.0","upvote_count":"4","poster":"NoniGeorge"},{"poster":"jaykumarjkd99","upvote_count":"4","timestamp":"1653333120.0","content":"Selected Answer: C\nI vote for C","comment_id":"485419"},{"timestamp":"1653039840.0","comment_id":"482471","content":"C. 1. In Cloud Logging, create a filter to view only Compute Engine logs. 2. Click Create Export. 3. Choose BigQuery as Sink Service, and the platform-logs dataset as Sink Destination.","upvote_count":"2","poster":"vishnukumartr"},{"timestamp":"1646054760.0","upvote_count":"2","poster":"Nivesh93","content":"c is correct as it uses filter so it basically reduces the cost of operation .","comment_id":"436275"},{"timestamp":"1638418020.0","poster":"Finger41","content":"Its C.","comment_id":"372301","upvote_count":"4"},{"content":"C should be correct","timestamp":"1637421360.0","upvote_count":"3","comment_id":"362191","poster":"arsh1916"},{"upvote_count":"4","poster":"mcaromit","timestamp":"1636708320.0","comment_id":"355352","content":"C is correct as it would restrict the volume of data to be scanned by bq, thus reducing cost"},{"upvote_count":"5","content":"C is correct. 1. In Cloud Logging, create a filter to view only Compute Engine logs. 2. Click Create Export. 3. Choose BigQuery as Sink Service, and the platform-logs dataset as Sink Destination.","timestamp":"1632512100.0","poster":"[Removed]","comment_id":"319591"},{"timestamp":"1632416100.0","poster":"GCP_Student1","comment_id":"318388","content":"C. 1. In Cloud Logging, create a filter to view only Compute Engine logs. 2. Click Create Export. 3. Choose BigQuery as Sink Service, and the platform-logs dataset as Sink Destination.","upvote_count":"4"},{"upvote_count":"3","timestamp":"1632060780.0","poster":"Hi2ALL","content":"C is correct","comment_id":"315017"},{"timestamp":"1631878260.0","comment_id":"313294","poster":"drizzydroo","content":"C right? No need to establish pub/sub topic?","upvote_count":"2"}]},{"id":"ivseH6zTwA0NjlTvOhqe","url":"https://www.examtopics.com/discussions/google/view/22969-exam-associate-cloud-engineer-topic-1-question-69-discussion/","answer_ET":"A","question_id":252,"unix_timestamp":1591975080,"exam_id":1,"question_text":"You are using Deployment Manager to create a Google Kubernetes Engine cluster. Using the same Deployment Manager deployment, you also want to create a\nDaemonSet in the kube-system namespace of the cluster. You want a solution that uses the fewest possible services. What should you do?","choices":{"B":"Use the Deployment Manager Runtime Configurator to create a new Config resource that contains the DaemonSet definition.","D":"In the cluster's definition in Deployment Manager, add a metadata that has kube-system as key and the DaemonSet manifest as value.","C":"With Deployment Manager, create a Compute Engine instance with a startup script that uses kubectl to create the DaemonSet.","A":"Add the cluster's API as a new Type Provider in Deployment Manager, and use the new type to create the DaemonSet."},"timestamp":"2020-06-12 17:18:00","isMC":true,"answers_community":["A (86%)","14%"],"answer_images":[],"answer":"A","discussion":[{"timestamp":"1629744300.0","poster":"ESP_SAP","upvote_count":"77","comments":[{"upvote_count":"7","content":"very good find, sounds like you hit the nail in the head","poster":"magistrum","comment_id":"255678","timestamp":"1640876100.0"}],"content":"Correct Answer is (A):\n\nAdding an API as a type provider\nThis page describes how to add an API to Google Cloud Deployment Manager as a type provider. To learn more about types and type providers, read the Types overview documentation.\n\nA type provider exposes all of the resources of a third-party API to Deployment Manager as base types that you can use in your configurations. These types must be directly served by a RESTful API that supports Create, Read, Update, and Delete (CRUD).\n\nIf you want to use an API that is not automatically provided by Google with Deployment Manager, you must add the API as a type provider. \n\nhttps://cloud.google.com/deployment-manager/docs/configuration/type-providers/creating-type-provider","comment_id":"164625"},{"upvote_count":"10","comment_id":"485447","poster":"PR0704","content":"couldn't be more confusing","timestamp":"1669241400.0"},{"poster":"Captain1212","upvote_count":"3","content":"Selected Answer: A\nA is the correct , bcoz it help you contact directly to the gke cluster to create daemon","comment_id":"996581","timestamp":"1725252660.0"},{"poster":"sthapit","timestamp":"1723225140.0","comment_id":"976901","upvote_count":"1","content":"Should have been D"},{"poster":"sakdip66","comment_id":"868903","timestamp":"1712964360.0","content":"Selected Answer: A\noption A is the right answer because it lets you directly interact with the Kubernetes API to create the Daemonset using the same deployment Manager Deployment","upvote_count":"1"},{"content":"Selected Answer: A\nI would say both Answer A and Answer D are valid solutions, and it depends on your preference and requirements.\n\nAnswer A involves adding the cluster's API as a new Type Provider in Deployment Manager and using the new type to create the DaemonSet. This solution would allow you to create and manage the DaemonSet and the cluster in the same Deployment Manager deployment.\n\nAnswer D involves adding a metadata block to the Deployment Manager deployment of the cluster, which will create the DaemonSet in the kube-system namespace of the cluster. This solution would allow you to create the DaemonSet in a simple way and avoid the need to create a new Type of Provider.\n\nIn conclusion, I would choose Answer A to be considered the answer that uses the fewest possible services, as it only involves adding the cluster's API as a new Type Provider in Deployment Manager, which is a lightweight solution.","comment_id":"815989","poster":"Buruguduystunstugudunstuy","timestamp":"1708469820.0","upvote_count":"7"},{"content":"Selected Answer: D\nD. In the cluster's definition in Deployment Manager, add a metadata that has kube-system as key and the DaemonSet manifest as value.\n\nThis approach involves adding the DaemonSet manifest directly as a metadata entry in the cluster's definition in Deployment Manager. When the cluster is created, the DaemonSet is automatically created in the kube-system namespace. This approach is the simplest and requires the fewest number of services. Option A is also a viable solution but requires more work to set up a Type Provider. Option B is not suitable because it involves a separate service (Runtime Configurator). Option C is also not recommended because it involves creating a Compute Engine instance and using kubectl to create the DaemonSet, which is more complicated and less efficient than the other options.","poster":"Bobbybash","timestamp":"1707800520.0","upvote_count":"3","comment_id":"807076"},{"poster":"vkamlesh0205","upvote_count":"1","timestamp":"1703552640.0","content":"Selected Answer: A\nOption A is the right answer","comment_id":"756115"},{"comment_id":"626181","content":"Selected Answer: A\nAnswer is A.","timestamp":"1688307000.0","poster":"RanjithK","upvote_count":"1"},{"timestamp":"1687537200.0","comment_id":"621111","poster":"AzureDP900","content":"go with A as per ESP_SAP explanations..","upvote_count":"1"},{"poster":"haroldbenites","timestamp":"1685860800.0","content":"Go for A","upvote_count":"1","comment_id":"611353"},{"comment_id":"553080","poster":"luciorifa","timestamp":"1677003240.0","content":"Selected Answer: A\nA is the correct answe, the API need to be added as a type provider","upvote_count":"1"},{"timestamp":"1674751320.0","content":"Selected Answer: A\nA should be correct one","poster":"ArunTaneja","upvote_count":"1","comment_id":"533064"},{"timestamp":"1672075800.0","content":"Selected Answer: A\nhttps://medium.com/google-cloud/cloud-deployment-manager-kubernetes-2dd9b8124223","comment_id":"509724","poster":"thuvh","upvote_count":"2","comments":[{"content":"Good reference. Thanks for it. Recomended","comment_id":"1021511","upvote_count":"1","timestamp":"1727702580.0","poster":"axantroff"}]},{"comment_id":"493851","timestamp":"1670175000.0","content":"Selected Answer: A\nCorrect Answer is (A)","poster":"MCMS","upvote_count":"2"},{"timestamp":"1668944820.0","content":"A. Add the clusterג€™s API as a new Type Provider in Deployment Manager, and use the new type to create the DaemonSet.","upvote_count":"1","poster":"vishnukumartr","comment_id":"482474"},{"content":"dd the clusterג€™s API as a new Type Provider in Deployment Manager, and use the new type to create the DaemonSet.","timestamp":"1668869880.0","comment_id":"481819","poster":"shawnkkk","upvote_count":"1"},{"content":"A is correct","poster":"mcaromit","upvote_count":"1","comment_id":"355357","timestamp":"1652339940.0"},{"timestamp":"1648723740.0","poster":"Linus11","upvote_count":"1","content":"A is correct.","comment_id":"324987"},{"content":"A: in addition to ESP_SAP's comment, the following link explains exactly how to...\n\nhttps://github.com/GoogleCloudPlatform/deploymentmanager-samples/blob/master/examples/v2/gke/daemonsets/daemonset.jinja","comment_id":"321823","timestamp":"1648376880.0","upvote_count":"2","poster":"pca2b"},{"comment_id":"320191","timestamp":"1648211880.0","upvote_count":"3","content":"A is correct. Add the clusterג€™s API as a new Type Provider in Deployment Manager, and use the new type to create the DaemonSet.","poster":"[Removed]"},{"timestamp":"1647466860.0","upvote_count":"3","comment_id":"312756","content":"vote for 'D'","poster":"sumanshu"},{"timestamp":"1646843580.0","content":"A. Add the cluster's API as a new Type Provider in Deployment Manager, and use the new type to create the DaemonSet.","poster":"GCP_Student1","upvote_count":"3","comment_id":"306549"},{"poster":"JackGlemins","upvote_count":"1","content":"https://cloud.google.com/deployment-manager/docs/deployments/updating-deployments","timestamp":"1645989840.0","comment_id":"300432"},{"timestamp":"1645841280.0","content":"A. is the correct answer:\nAdd the cluster's API as a new Type Provider in Deployment Manager, and use the new type to create the DaemonSet","poster":"nliaustemac","comment_id":"299493","upvote_count":"2"},{"comment_id":"297086","timestamp":"1645582140.0","upvote_count":"2","content":"Answer is D\nadd this to your yml file: -\nkind: DeamonSet\nand you are done!","poster":"nitinz"},{"content":"Why not B?","comments":[{"poster":"Buruguduystunstugudunstuy","timestamp":"1708470000.0","content":"My friend, Answer \"B\" is not the recommended solution because it involves using the Deployment Manager Runtime Configurator to create a new Config resource that contains the DaemonSet definition, which would also add additional complexity. Hope that helps.","upvote_count":"1","comment_id":"815992"}],"poster":"JackGlemins","comment_id":"281529","upvote_count":"1","timestamp":"1643764800.0"},{"comment_id":"274485","upvote_count":"1","timestamp":"1642933320.0","poster":"victory108","content":"A - Add the cluster's API as a new Type Provider in Deployment Manager, and use the new type to create the DaemonSet."},{"timestamp":"1642250100.0","comment_id":"267902","content":"D is correct.","poster":"nherrerab","upvote_count":"1"},{"timestamp":"1638857640.0","poster":"Bhagirathi","upvote_count":"3","content":"it is like no one sure of answer...all of you confusing.\n\nI can chose A.","comment_id":"237015"},{"timestamp":"1637577900.0","content":"all of you hoose A, B C & D ...what is final take away?\nmore than finding what is correct - why A/B/C/D you choose ?","comment_id":"224897","upvote_count":"2","poster":"Bhagirathi"},{"comment_id":"221023","content":"• A. Add the cluster's API as a new Type Provider in Deployment Manager, and use the new type to create the DaemonSet.","timestamp":"1637150460.0","upvote_count":"1","poster":"swatititame"},{"poster":"Sanwal","comment_id":"219422","content":"A.\nYou can configure the GKE nodes (provisioned by Deployment manager) to report their status to the Runtime Configurator, and when they are UP, you can run a task to create a DaemonSet. While this is possible, it involves one additional service - to run a task e.g. using Cloud Functions, etc. Our requirement is to achieve using the fewest possible services and as you'll notice later, the correct answer uses fewer services.","upvote_count":"2","timestamp":"1636934280.0"},{"upvote_count":"4","comment_id":"215990","content":"It can be done both A and C, I think the answer is A cuz question says \"You want a solution that uses the fewest possible services.\", With C you need to enable GCE service when with A non-additional of that are already going to be in use - DM, and GKE. Thought I'll take more steps, but less GCP serices, that's the key.","poster":"Eshkrkrkr","timestamp":"1636467840.0"},{"upvote_count":"3","comment_id":"206796","poster":"nwk","content":"Vote for B\nhttps://github.com/GoogleCloudPlatform/deploymentmanager-samples/blob/master/examples/v2/gke/daemonsets/README.md","timestamp":"1635300900.0"},{"poster":"glam","content":"C. With Deployment Manager, create a Compute Engine instance with a startup script that uses kubectl to create the DaemonSet.","upvote_count":"1","timestamp":"1633840740.0","comment_id":"197095"},{"comments":[{"comment_id":"788784","timestamp":"1706277840.0","content":"I agree with C: Below link seems to make the same point:\nhttps://cloud.google.com/solutions/automatically-bootstrapping-gke-nodes-with-daemonsets\n\nA is necessary if you want to use 3-party provider. In this case you are using GKE which belongs to google and it already contains Kubernetes (kube-system) by default.","poster":"eBooKz","upvote_count":"1"},{"content":"Who says of force using kubectl? Questions asks to do all via DM in the first place.","poster":"Eshkrkrkr","timestamp":"1636470240.0","comment_id":"216016","upvote_count":"2"}],"upvote_count":"3","comment_id":"195796","timestamp":"1633675500.0","poster":"JJ_ME","content":"C.\nYou can create a DaemonSet using kubectl apply or kubectl create.\nOption C is the only option using kubectl\n\nhttps://cloud.google.com/kubernetes-engine/docs/concepts/daemonset#creating_daemonsets"},{"upvote_count":"1","timestamp":"1632729840.0","comment_id":"188212","poster":"AZahid","content":"Ans Is A"},{"comment_id":"180358","poster":"rezavage","timestamp":"1631797320.0","upvote_count":"1","content":"D is the answer:\nhttps://kubernetes.io/docs/concepts/workloads/controllers/daemonset/"},{"upvote_count":"1","comment_id":"162184","content":"A is correct for me","poster":"SSPC","timestamp":"1629458940.0"},{"timestamp":"1629105240.0","poster":"MohammedGhouse","upvote_count":"1","comment_id":"159116","content":"D is the answer"},{"comments":[{"content":"I'll take that back. Types cannot refer to daemonSets. A is not correct!","poster":"Verve","comment_id":"147486","timestamp":"1627657020.0","upvote_count":"1"}],"content":"For me its A\nhttps://cloud.google.com/deployment-manager/docs/configuration/supported-gcp-types","timestamp":"1627656780.0","poster":"Verve","comment_id":"147483","upvote_count":"1"},{"comment_id":"137351","content":"Answer is A.","timestamp":"1626540540.0","poster":"Soumya308","upvote_count":"3"},{"comments":[{"poster":"Meeda","comments":[{"comment_id":"312753","content":"https://cloud.google.com/kubernetes-engine/docs/concepts/daemonset\n\nkind: DaemonSet","timestamp":"1647466800.0","upvote_count":"1","poster":"sumanshu"}],"upvote_count":"3","comment_id":"148553","content":"Why D ? \n\nThere is no concept of key name as namespace and value as daemonset !\n\nhttps://www.bluematador.com/blog/an-introduction-to-kubernetes-daemonsets","timestamp":"1627820520.0"}],"content":"D for sure","timestamp":"1625902380.0","poster":"Effan","upvote_count":"1","comment_id":"131241"},{"poster":"DarioFama23","upvote_count":"2","timestamp":"1625578260.0","content":"for me is A","comment_id":"127845"},{"timestamp":"1623656340.0","upvote_count":"10","comment_id":"109943","poster":"kishoredeena","content":"Option A is the right answer"},{"poster":"[Removed]","timestamp":"1623511080.0","content":"B is correct answer","comment_id":"108782","upvote_count":"3"}],"answer_description":"","question_images":[],"topic":"1"},{"id":"Z24DszcusFbowGaaFHbZ","answer_description":"","answer":"D","timestamp":"2020-04-21 04:15:00","discussion":[{"poster":"samcat84","timestamp":"1590488340.0","content":"C is incomplete. Moving projects under an organisation doesn't change their linked billing project.\nhttps://cloud.google.com/resource-manager/docs/migrating-projects-billing\n----\nNote: The link between projects and billing accounts is preserved, irrespective of the hierarchy. When you move your existing projects into the organization they will continue to work and be billed as they used to before the migration, even if the corresponding billing account has not been migrated yet. \n----\nD is incomplete as well, after setting the billing account in the organisation you need to link the projects to the new billing account.","comment_id":"95938","upvote_count":"58","comments":[{"upvote_count":"3","content":"I agree that neither C or D is correct. I did the cert a month ago and this question was not on it. Although a similar question about how to change the payment method from your own card in your project to to the company's \"card\". So they might have removed this one.","timestamp":"1608022440.0","comments":[{"poster":"ehizren","content":"What's was the answer your chose for your particular exam question?","comments":[{"content":"We need to add a new payment method and need to set that as Primary, post that we need to remove the previous one\n\"If you want to remove a payment method, you should add a new payment method first.\"\nRefer : https://cloud.google.com/billing/docs/how-to/payment-methods","upvote_count":"2","poster":"GokulVelusaamy","timestamp":"1667714160.0","comment_id":"712167"}],"upvote_count":"7","comment_id":"279337","timestamp":"1611928020.0"}],"poster":"sarahf","comment_id":"244421"},{"timestamp":"1643056200.0","comment_id":"531561","poster":"Raz0r","upvote_count":"3","content":"The given answers make D the only possible solution. C can not be right, you all need to look it up here: https://cloud.google.com/resource-manager/docs/project-migration#change_billing_account"},{"comment_id":"639414","timestamp":"1659140100.0","upvote_count":"3","poster":"ryumada","content":"This link explains clearly that move a project won't affect billing.\nhttps://cloud.google.com/resource-manager/docs/project-migration#permissions-billing"}]},{"upvote_count":"17","poster":"poogcp","comment_id":"106619","timestamp":"1591779600.0","content":"C is correct Answer. there will be 1 billing account for the organization and all projects under that organization are linked to single billing account.","comments":[{"upvote_count":"7","timestamp":"1647587520.0","content":"https://cloud.google.com/resource-manager/docs/project-migration#change_billing_account\n\"Moving a project from one organization to another won't impact billing, and charges will continue against the old billing account. \"","comment_id":"570297","poster":"arathefu"},{"comment_id":"936222","timestamp":"1687932720.0","content":"The question is under the organization different projects are maintained the different cloud platforms.all the different project should single corporate bill account instead of the employee billing account. So try to update the corporate bill account details and mark it as primary for the all projects, post that employee account details need to removed. So suitable recomanded option is D","upvote_count":"1","poster":"Neha_Pallavi"}]},{"comment_id":"1310043","upvote_count":"1","comments":[{"comment_id":"1310049","timestamp":"1731329700.0","content":"Consolidate multiple Billing Accounts into your main Billing Accounts.\n\n1. First identify your main Billing Accounts and the projects you want to link to those billing accounts. \n2. Link or move existing projects onto your main Billing Accounts.\n\nReference: https://cloud.google.com/billing/docs/onboarding-checklist","upvote_count":"1","poster":"psyll0n"}],"poster":"psyll0n","content":"D is the correct answer!","timestamp":"1731329460.0"},{"upvote_count":"1","content":"Answer is correct (D)\n1.Create a New Billing Account: Go to the \"Billing\" section in the Google Cloud Platform Console. Follow the instructions to set up a new billing account. During this process, you will specify the payment method that the company prefers to use, such as a corporate credit card or bank account.\n\n2.Associate Projects with the New Billing Account: Once the billing account is created, you can then link all existing projects to this centralized billing account. This is done under the “Billing” section for each project, where you can change the billing account associated with the project.","timestamp":"1731070800.0","poster":"Makar","comment_id":"1308788"},{"poster":"Buruguduystunstugudunstuy","content":"Selected Answer: D\nOption A is incorrect because you cannot request a corporate billing account by emailing cloud-billing@google.com. This email address is for general billing inquiries and support.\n\nOption B is incorrect because you cannot create a ticket with Google Support to share your credit card details over the phone. To set up a payment method for a billing account, you must do it through the Google Cloud Platform Console.\n\nOption C is incorrect because moving projects to the root organization will not create a new billing account. You must first create a new billing account and then move the projects to the root organization to ensure that they are all billed to the same billing account.\n\nTherefore, the correct answer is Option D.\n\nhttps://cloud.google.com/billing/docs/how-to/manage-billing-account#create_a_new_billing_account","comment_id":"761405","upvote_count":"4","timestamp":"1727162760.0"},{"upvote_count":"4","content":"Selected Answer: D\nThe correct answer is D. You have to follow the complete steps to successfully:\n1. Create a new Billing Account\n2. Move the existing projects into the new billing account\n3. Cancel the earlier billing accounts of individual projects \n\nThis would meet all the requirements in the question - to centrally have all the projects under a single billing account.","timestamp":"1727162760.0","comment_id":"1014193","poster":"YourCloudGuru"},{"upvote_count":"1","content":"D is correct,\n\"get-contexts\" shows us our Kubernetes cluster contexts, that's right. But the question says that you want to review the cluster itself, so you need to use-context to get into the cluster. Answer A: Using `gcloud config configurations described` will only show you the details of the current configuration, not the Kubernetes Engine cluster of an inactive configuration. Answer B: Using `gcloud config configurations activate` and `gcloud config list` to review the output will only show you the list of configurations and activate one of them, but it won't provide you with the details of the Kubernetes Engine cluster of an inactive configuration. Answer C: Using `kubectl config get-contexts` will only list the available contexts, including their clusters, but it won't provide you with the details of the Kubernetes Engine cluster of an inactive configuration.","timestamp":"1725826440.0","poster":"Nido1919","comment_id":"1280607"},{"content":"Correct Answer is D","timestamp":"1725826380.0","comment_id":"1280606","upvote_count":"1","poster":"Nido1919"},{"poster":"Robot101","upvote_count":"1","content":"Selected Answer: C\nC is correct. Because it is the best practice recommended by google. And D, you cannot have multiple billing account in one project.","timestamp":"1712085060.0","comment_id":"1188263"},{"poster":"BAofBK","timestamp":"1699219200.0","content":"The correct answer is D.","comment_id":"1063299","upvote_count":"1"},{"comment_id":"1059454","timestamp":"1698826680.0","upvote_count":"1","content":"Selected Answer: C\nC is the Google best practice","poster":"gsmasad"},{"upvote_count":"2","timestamp":"1697014440.0","poster":"Evan7557","comment_id":"1040396","content":"D is right Ans"},{"poster":"Captain1212","comment_id":"996168","content":"Selected Answer: D\nD : as per question new account , d is the right answer","upvote_count":"1","timestamp":"1693581720.0"},{"poster":"Praxii","content":"Selected Answer: C\nI think this is multiple choice. C and D together make sense but otherwise they are both incomplete.","timestamp":"1682529900.0","upvote_count":"2","comment_id":"881881"},{"timestamp":"1672952400.0","comment_id":"767041","upvote_count":"2","poster":"aramisrocha","content":"Selected Answer: D\nD is correct, C is incorrect, because all accounts already is in root"},{"content":"D, as other options are not correct","poster":"leogor","comment_id":"701983","upvote_count":"2","timestamp":"1666510620.0"},{"timestamp":"1666252560.0","upvote_count":"2","content":"Selected Answer: D\nD is more complete than C","comment_id":"699669","poster":"hiromi"},{"comment_id":"690927","poster":"AwesomeGCP","timestamp":"1665393960.0","upvote_count":"2","content":"Selected Answer: D\nIt’s pretty straight-forward: you should establish a new billing account with a company-based payment method. Then set all the projects to use that new billing account."},{"comment_id":"681369","upvote_count":"3","poster":"Rajagopal","timestamp":"1664335860.0","content":"I think \"D\" is the right answer (https://cloud.google.com/resource-manager/docs/project-migration#change_billing_account)"},{"timestamp":"1664036040.0","content":"had this question today","poster":"Cornholio_LMC","comment_id":"677972","upvote_count":"2"},{"comment_id":"658193","timestamp":"1662190740.0","content":"Selected Answer: D\nD is the correct one, even tho could be written in a better way.","poster":"ale_brd_111","upvote_count":"1"},{"upvote_count":"2","timestamp":"1661855940.0","poster":"Qureshizaid64","content":"Selected Answer: C\nIf we move all projects under the root organization hierarchy, they still need to modify to use a billing account within the organization.\n\nRef: https://cloud.google.com/resource-manager/docs/migrating-projects-billing#top of page Note: The link between projects and billing accounts is preserved, irrespective of the hierarchy. When you move your existing projects into the organization, they will continue to work and be billed as they used to before the migration, even if the corresponding billing account has not been migrated yet.\n\nBut in this option, all projects are in the organization resource hierarchy so the organization can uniformly apply organization policies to all its projects which is a Google recommended practice. So this is the better of the two options.\nRef: https://cloud.google.com/billing/docs/concepts","comment_id":"653992"},{"timestamp":"1660311120.0","upvote_count":"1","comment_id":"645912","poster":"akg001","content":"Selected Answer: D\nD. In the Google Cloud Platform Console, create a new billing account and set up a payment method."},{"content":"D\nhttps://cloud.google.com/billing/docs/concepts","timestamp":"1659564000.0","upvote_count":"1","comment_id":"642107","poster":"habros"},{"timestamp":"1655931660.0","content":"In the GCP Console, navigate to the Resource Manage section and move all projects to the root Organization. C is right","upvote_count":"1","comment_id":"620637","poster":"AzureDP900"},{"comment_id":"620636","poster":"AzureDP900","comments":[{"content":"Tutorial Dojo's question mentions Organization in the question, here no mention of Org, assuming org does not exist. Just link billing account to each project.","timestamp":"1659097020.0","upvote_count":"1","poster":"Paulv82003","comment_id":"639199"}],"content":"C is right .. o In the GCP Console, navigate to the Resource Manage section and move all projects to the root Organization. Tutorial Dojo practice questions having the similar question.","upvote_count":"1","timestamp":"1655931540.0"},{"upvote_count":"1","timestamp":"1647667320.0","comment_id":"570859","poster":"dinesh198728","content":"Selected Answer: D\nCatch the word : new billing account"},{"comment_id":"567767","upvote_count":"4","content":"The answer is D.\n Carefully read this sentence \"Several employees at your company have been creating projects with Cloud Platform and paying for it with their personal credit cards\". all projects are already in the root org. no need to move especially. but the thing is they are paying individually. So need to solve this should create a new account and move it to all projects.","poster":"janukaz","timestamp":"1647274740.0"},{"poster":"tigerbaer","content":"Selected Answer: D\nhttps://cloud.google.com/resource-manager/docs/project-migration","comment_id":"545216","upvote_count":"1","timestamp":"1644572760.0"},{"upvote_count":"1","timestamp":"1644572640.0","comment_id":"545215","content":"D is correct: https://cloud.google.com/resource-manager/docs/project-migration","poster":"tigerbaer"},{"content":"Selected Answer: D\nIt just can be D! Because C is wrong, read it here from Google's documentation itself:","upvote_count":"3","poster":"Raz0r","timestamp":"1643056080.0","comment_id":"531559"},{"poster":"ahsangh","content":"Selected Answer: C\nC. In the Google Platform Console, go to the Resource Manage and move all projects to the root Organization.","upvote_count":"1","comment_id":"512546","timestamp":"1640801940.0"},{"comment_id":"508909","timestamp":"1640391480.0","poster":"9ankit00","content":"D is corrrect because moving project in a orgnazation node is time consuming","upvote_count":"1"},{"comment_id":"498936","poster":"wh1t4k3r","content":"C and D should be one whole answer\nI go with D because it is the only one that mentions `new billing account`","timestamp":"1639167420.0","upvote_count":"2"},{"comment_id":"496875","poster":"pnVino27","upvote_count":"1","timestamp":"1638972240.0","content":"Selected Answer: C\nAnswer: C"},{"content":"C. In the Google Platform Console, go to the Resource Manage and move all projects to the root Organizarion.","poster":"shawnkkk","timestamp":"1637305800.0","comment_id":"481440","upvote_count":"1"},{"content":"C. In the Google Platform Console, go to the Resource Manage and move all projects to the root Organizarion.","poster":"vishnukumartr","comment_id":"481357","timestamp":"1637299740.0","upvote_count":"1"},{"comment_id":"481059","upvote_count":"2","poster":"Jaira1256","timestamp":"1637271180.0","content":"Ans - D"},{"content":"C is correct","timestamp":"1629545040.0","upvote_count":"1","poster":"Shruti_Pal","comment_id":"428627"},{"comment_id":"422824","upvote_count":"3","poster":"bryzhatov","timestamp":"1628607600.0","content":"I assume that billing is new, but already created by Company. Then C is more correct than D. I think that the question is more oriented on centralizing projects under the existing billing account. In other words, if Google would like to direct us to create new billing, then the correct wording would be like \"Company wants to have new billing account and centralize all these projects under new single billing account\".\nSo, C is more correct than D if we need to choose only one answer."},{"poster":"hasib125","upvote_count":"2","comment_id":"404424","timestamp":"1626071460.0","content":"I will go with C.\n\nRead the question. The company wants to centralize all these projects under a single, new billing account. What should you do? Company will also reimburses employees billing.\n\nIn Google Cloud, you set up a Cloud Billing account and use it to define who pays for a given set of Google Cloud resources. You use Identity and Access Management (IAM) roles to control access to a Cloud Billing account. You can also move projects under one cloud billing account . https://cloud.google.com/billing/docs/how-to/modify-project. The Resource Manager (D) does not include billing merely resource management."},{"content":"The company wants to centralize all these projects under a single, new billing account.\ncentralising all projects to a single account might require moving to the organisation root.","comment_id":"388740","upvote_count":"1","timestamp":"1624445700.0","poster":"Larysmith"},{"content":"What is thw correct answer? C or D. Please advise.","timestamp":"1624075080.0","upvote_count":"3","comment_id":"385193","poster":"Sruthigp"},{"upvote_count":"3","comment_id":"362175","comments":[{"upvote_count":"2","comment_id":"362370","poster":"Mannu12","timestamp":"1621529760.0","content":"How are you 100%sure?"}],"content":"D, 100%","timestamp":"1621516140.0","poster":"arsh1916"},{"content":"D is correct, as that is a mandatory step. C is not mandate.","timestamp":"1621043100.0","upvote_count":"1","poster":"Agraved","comment_id":"357531"},{"timestamp":"1620877140.0","upvote_count":"3","content":"Technically, its a combo of C and D.","comment_id":"355961","poster":"Finger41"},{"upvote_count":"1","poster":"mcaromit","timestamp":"1620697020.0","content":"D is correct...https://cloud.google.com/resource-manager/docs/project-migration clearly clarifies changing Org won't impact billing","comment_id":"354224"},{"timestamp":"1618989120.0","comments":[{"comment_id":"362189","upvote_count":"1","poster":"Mannu12","timestamp":"1621516500.0","comments":[{"upvote_count":"1","timestamp":"1622370960.0","content":"You are correct, there will be none. D is an incomplete solution for it as the next step to D would be C(also not entirely), as we'd move the projects into the organization and change the billing accounts for them.","comment_id":"370082","poster":"wazza11"}],"content":"but what projects will be under the new account that should be build?"}],"comment_id":"340144","content":"Tricky one however the question does state that they want a NEW billing account for these projects and simply moving a project under the Org will likely just use the existing billing account already in situ. \n\nMy answer is D","poster":"meh009","upvote_count":"1"},{"timestamp":"1617580440.0","comments":[{"comments":[{"timestamp":"1687933260.0","content":"All the projects under the organization same root right.why shoud user move the projects once again. mapping single corporate billing account to all the projects","poster":"Neha_Pallavi","comment_id":"936229","upvote_count":"1"}],"comment_id":"337507","timestamp":"1618656840.0","poster":"tavva_prudhvi","content":"So, you create a billing account and set up a payment method, after that???\nYou have to ask all the users to map their projects to this billing account to get reimbursed, which neither C/D states but the closest one is C.","upvote_count":"5"}],"poster":"civilizador","comment_id":"328290","content":"D obviously is the answer because it literally says in the question: \" new billing account\" . I can't believe so many people do not read the question","upvote_count":"1"},{"poster":"sumanshu","timestamp":"1616107440.0","content":"Correct answer is C as Google Cloud Resource Manager can help group the existing accounts under an Organization for centralized billing.","upvote_count":"1","comment_id":"314433"},{"upvote_count":"1","content":"C is correct. In the Google Platform Console, go to the Resource Manage and move all projects to the root Organizarion.","comment_id":"305769","timestamp":"1615213920.0","poster":"EABDAJA"},{"comments":[{"comment_id":"311867","poster":"sumanshu","timestamp":"1615854600.0","content":"Only creating the new billing account is not sufficient.","upvote_count":"1"}],"poster":"GCP_Student1","timestamp":"1614899280.0","comment_id":"303672","upvote_count":"1","content":"D. In the Google Cloud Platform Console, create a new billing account and set up a payment method."},{"upvote_count":"1","timestamp":"1614866880.0","poster":"navsaru","content":"C is correct answer","comment_id":"303365"},{"poster":"JackGlemins","timestamp":"1614221820.0","upvote_count":"3","content":"C is wrong: https://cloud.google.com/resource-manager/docs/migrating-projects-billing\nYou can move the projects but the billing no chance:\nNote: The link between projects and billing accounts is preserved, irrespective of the hierarchy. When you move your existing projects into the organization they will continue to work and be billed as they used to before the migration, even if the corresponding billing account has not been migrated yet. Similarly, if you move a billing account into the organization, all projects linked to it will continue to work even if they are still outside of the organization. There should be no server downtime or impact as a result of migration.\n\nI think D is best answers","comment_id":"298699"},{"comment_id":"295962","comments":[{"poster":"ShakthiGCP","comment_id":"303833","upvote_count":"1","content":"Then Option C : doesnt tell that you need to create a new Billing account. The company asked its employees to create their own Projects which means the organization node for the company already exist. You create a new Billing account and ask all the users to map their projects to this billing account to get reimbursed . Problem solved.","timestamp":"1614910200.0"}],"timestamp":"1613929500.0","upvote_count":"1","content":"Option C. D does not mention how the new billing account will be mapped to each project","poster":"Sarin"},{"content":"Ans: D : This where you are creating a new Billing account to link all other projects into one.\n C - is not the right answer because moving the project under root doesnt solve the question for creating a new billing account and more over that company must have the organization structure created for its employees to create their own projects.","poster":"ShakthiGCP","comment_id":"292875","timestamp":"1613593560.0","upvote_count":"3"},{"upvote_count":"1","content":"D - In the Google Cloud Platform Console, create a new billing account and set up a payment method.","timestamp":"1612686180.0","poster":"victory108","comment_id":"285377"},{"upvote_count":"1","content":"Answer is D , you create the billing account and when you start doing this, it will ask you to add the projects , so it is included in the wizard and not separate action. C is under IAM resource manager and only policies applied but moving these projects do not affect their billings.","poster":"INASR","timestamp":"1611618240.0","comment_id":"276410"},{"poster":"nherrerab","timestamp":"1610659260.0","content":"Correct is C.","upvote_count":"1","comment_id":"267436"},{"timestamp":"1608885660.0","comment_id":"251950","upvote_count":"2","poster":"vara3dk","content":"All Google Cloud resources that belong to an Organization are grouped under the Organization node, allowing you to define settings, permissions, and policies for all projects, folders, resources, and Cloud Billing accounts it parents. Correct Answer is C"},{"content":"None of the provided answer is correct. Neither C nor D address the single billing. I think this is a beta question or the question was poorly worded.","comment_id":"246807","poster":"JKRowlings","timestamp":"1608234300.0","upvote_count":"1"},{"timestamp":"1607144340.0","upvote_count":"2","content":"Finally - which one you guys decided - C or D ?","poster":"Bhagirathi","comment_id":"235412"},{"poster":"robor97","content":"C: In Google Cloud, you set up a Cloud Billing account and use it to define who pays for a given set of Google Cloud resources. You use Identity and Access Management (IAM) roles to control access to a Cloud Billing account. You can also move projects under one cloud billing account . https://cloud.google.com/billing/docs/how-to/modify-project. The Resource Manager (D) does not include billing merely resource management","upvote_count":"3","timestamp":"1606768140.0","comment_id":"231351"},{"upvote_count":"1","timestamp":"1605788700.0","poster":"sheensh","content":"D is correct. We need to centralize the projects to have only the billing account in common but not the IAM policies etc which is applicable at the org level.","comment_id":"222757"},{"content":"D is my choice, as we can have multiple projects linked to single billing account. and i agree with @baudrual","timestamp":"1604782680.0","upvote_count":"1","comment_id":"214851","poster":"gh999l"},{"content":"C or D? That's easy - google is testing not our knowledge but attention skill. Question - to centralize THESE projects, when C states move ALL projects. Answer is D, new centralized billing account + link THESE project to it.","comment_id":"214847","timestamp":"1604782440.0","poster":"Eshkrkrkr","comments":[{"poster":"Eshkrkrkr","comment_id":"214848","timestamp":"1604782560.0","content":"Plus the beginig of the question says \"several employees...\" too much result after option C.","upvote_count":"2"}],"upvote_count":"1"},{"upvote_count":"1","comment_id":"209561","content":"C is correct .. Have one billing account attached to Org level","poster":"Surya1","timestamp":"1604089260.0"},{"comment_id":"209288","poster":"hems4all","timestamp":"1604064780.0","content":"A & B are wrong as billing consolidation is User responsibility and GCP does not support it.Option D is wrong as it would not centralize the billing under a single account.","upvote_count":"1"},{"content":"Ans D\nTo manage billing accounts and to add projects to them, you must be a billing administrator.\nTo change the billing account for an existing project, you must be an owner on the project and the billing administrator on the destination billing account.\nWhen you create a new project, you're prompted to choose which of your billing accounts you want to link to the project.\nIf you only have one billing account, that account is the one that will automatically link to your project.\nIf you don't have a billing account, you must create one and enable billing for your project before you can use many Google Cloud platform features. Avoid surprises on your bill by creating budgets to monitor all your Google Cloud platform charges in one place. After you've set a budget amount, you set budget alert rules that are used to trigger notifications. So you can stay informed of how you're spend is tracking against your budget.","comment_id":"207532","poster":"swatititame","upvote_count":"2","timestamp":"1603863480.0"},{"content":"D. In the Google Cloud Platform Console, create a new billing account and set up a payment method.","timestamp":"1603776960.0","upvote_count":"1","poster":"swatititame","comment_id":"206834"},{"timestamp":"1603685340.0","upvote_count":"2","comment_id":"206007","content":"Ans: D , C is not correct since moving project to organization doesnt move the billing account. D correct since it new centralize billing first step you have to create billing first.","poster":"adedj99"},{"upvote_count":"1","timestamp":"1603685100.0","comment_id":"206005","content":"To migrate your existing billing accounts into an organization, follow the steps below:\nGo to the Cloud Console Billing page:\nGo to the Billing page\nFrom the **Select an organization** menu, select an organization to see the Cloud Billing accounts associated with it, or select No organization to see billing accounts that aren't associated with an organization.\nUnder Billing account name, click the name of the Cloud Billing account that you want to migrate. The billing account overview page opens.\nIn the Billing navigation menu, click Account management.\nAt the top of the Account management page, click business Change Organization, then select the organization to which you want to migrate the Cloud Billing account.","poster":"adedj99"},{"content":"Well A & B are out, so we have C and D\n\nAbout C:\nProjects are already under root org... and as far as I know, you cannot move projects \"to the root org\", as you are already under the root org ... with possible layers of folders and so. Each project it's supposed to have its billing account, so, merely moving the projects does not necessarily changes the billing. D on the contrary explicitly talks about a new billing account. If we have a multi choice... maybe C&D could be right, as you can set new billing accounts and move the project under a new structure ....","poster":"Ozymandiax","timestamp":"1603622040.0","upvote_count":"3","comment_id":"205559"},{"poster":"nwk","content":"Vote D. C does not update billing. Moving Project does not impact billing, it just organize your project","timestamp":"1603440600.0","upvote_count":"2","comment_id":"204551"},{"timestamp":"1602061080.0","content":"C. In the Google Platform Console, go to the Resource Manage and move all projects to the root Organization.","upvote_count":"4","comment_id":"195029","poster":"glam"},{"content":"D. When a member creates project/billing A/c, an organization resource is created by default and they become the child of it.","comment_id":"191351","upvote_count":"4","poster":"Abishaik","timestamp":"1601610420.0"},{"upvote_count":"2","poster":"Ozymandiax","comments":[{"comment_id":"164509","content":"IN addition: https://cloud.google.com/billing/docs/how-to/modify-project","upvote_count":"1","poster":"Ozymandiax","timestamp":"1598197980.0"},{"upvote_count":"2","comments":[{"comment_id":"165719","content":"From my point of view that is it. The answer C says that you move projects to your org, but it does not says specifically ( and D states it), that you create a new Billing account....","timestamp":"1598334720.0","upvote_count":"1","poster":"Ozymandiax"}],"comment_id":"164799","poster":"SSPC","timestamp":"1598233860.0","content":"But I think that the first you need move the projects to your organization, and after you crea a new billing accoung. For me C is correct"}],"timestamp":"1598197920.0","comment_id":"164508","content":"I'd say D; C does not creates a new Billing account"},{"timestamp":"1598026680.0","upvote_count":"3","poster":"SSPC","comment_id":"163070","content":"C is correct"},{"upvote_count":"5","timestamp":"1596619140.0","comment_id":"151037","content":"Option D is correct, as in the question requirement called out \"want to centralize all these project under a single billing account\", hence i feel D is the correct option and not C. As mentioned for option C it would mean if there is any policy set at project level which is overridden from Org then it would get impacted.","poster":"mbiy"},{"content":"The deal by choosing D instead of C that is about the IAM policies. If you change the billign process nothing change expect the billing. If you move every project into the organization then the organization's policies are applied to the projects ....","upvote_count":"1","poster":"baudrual","timestamp":"1596088560.0","comment_id":"147136"},{"comment_id":"129028","poster":"enli1014","timestamp":"1594131600.0","upvote_count":"3","content":"does anyone already took the exam? did the questions here reflect in the exam?"},{"upvote_count":"1","content":"Ans is C\n\nYou can group all the projects under one organization\nIAM & Admin > Manage resources","poster":"professor","timestamp":"1593111060.0","comment_id":"119717"},{"content":"Correct: C","comment_id":"119182","poster":"cloudenthu01","timestamp":"1593069480.0","upvote_count":"1"},{"timestamp":"1591844640.0","comment_id":"107372","poster":"AnjuMaria","upvote_count":"3","content":"The company wants to centralize all these projects under a single, new billing account.. D won't do this. So I think C is correct answer."},{"content":"If this is multiple choice then both C and D is correct answer. You need both C and D to achieve this.","comment_id":"102345","upvote_count":"6","poster":"saurabh1805","timestamp":"1591272180.0"},{"content":"C\nhttps://cloud.google.com/resource-manager/docs/migrating-projects-billing\nOnce a Google Cloud Organization resource has been created for your domain, you can move your existing projects into the organization.","upvote_count":"2","comment_id":"88133","timestamp":"1589352480.0","poster":"Khaled_Rashwan"},{"upvote_count":"2","comment_id":"87172","poster":"zukko78","timestamp":"1589207400.0","content":"C is correct."},{"comment_id":"83371","comments":[{"content":"Wrong, moving to one Org doesn't affect billing linkage at all. Answer is D.","poster":"Eshkrkrkr","comments":[{"comment_id":"302594","poster":"Calistus","upvote_count":"1","content":"To consume GCP resources, billing must be setup. This assumes that the organisation has an active billing account. So moving all the resources into the organisation account will link them to the central billing. So C, seems to be the correct answer","timestamp":"1614772140.0"}],"comment_id":"216534","upvote_count":"3","timestamp":"1605005760.0"}],"content":"Correct Answer is C","poster":"YashBindlish","upvote_count":"6","timestamp":"1588562220.0"},{"content":"Correct answer is C as Google Cloud Resource Manager can help group the existing accounts under an Organization for centralized billing.Refer GCP documentation - Resource Manager Google Cloud Platform (GCP)","comments":[],"poster":"leba","timestamp":"1588266480.0","comment_id":"81785","upvote_count":"5"},{"timestamp":"1587435300.0","content":"D does not answer the question. C is close","poster":"Agents89","upvote_count":"3","comment_id":"77232"}],"answer_images":[],"choices":{"B":"Create a ticket with Google Support and wait for their call to share your credit card details over the phone.","A":"Contact cloud-billing@google.com with your bank account details and request a corporate billing account for your company.","D":"In the Google Cloud Platform Console, create a new billing account and set up a payment method.","C":"In the Google Platform Console, go to the Resource Manage and move all projects to the root Organizarion."},"answer_ET":"D","question_text":"Several employees at your company have been creating projects with Cloud Platform and paying for it with their personal credit cards, which the company reimburses. The company wants to centralize all these projects under a single, new billing account. What should you do?","unix_timestamp":1587435300,"topic":"1","question_id":253,"url":"https://www.examtopics.com/discussions/google/view/18825-exam-associate-cloud-engineer-topic-1-question-7-discussion/","answers_community":["D (73%)","C (27%)"],"question_images":[],"exam_id":1,"isMC":true},{"id":"a48snVmaLwT1wmwVvd3r","answer_ET":"B","answer_description":"","question_images":[],"exam_id":1,"url":"https://www.examtopics.com/discussions/google/view/24342-exam-associate-cloud-engineer-topic-1-question-70-discussion/","answer":"B","answer_images":[],"discussion":[{"content":"Correct answer should be (B):\n\nTo use a service account outside of Google Cloud, such as on other platforms or on-premises, you must first establish the identity of the service account. Public/private key pairs provide a secure way of accomplishing this goal.\n\nhttps://cloud.google.com/iam/docs/creating-managing-service-account-keys","comment_id":"159592","poster":"ESP_SAP","timestamp":"1629170520.0","upvote_count":"55"},{"content":"Selected Answer: B\nThe recommended approach for enabling authentication from an on-premises environment to Google Cloud Platform (GCP) services like AutoML is to use a service account and generate a JSON key file for the service account. This key file can then be used to authenticate and authorize API calls from your on-premises environment to GCP.\n\nTherefore, the correct answer is B. Use gcloud to create a key file for the service account that has appropriate permissions.","comment_id":"816024","upvote_count":"7","timestamp":"1708472280.0","poster":"Buruguduystunstugudunstuy"},{"poster":"85c887f","content":"Selected Answer: A\nCorrect answer should be A. \"Use service account credentials\", so here \"credentials\" indicate that we will use JSON key file in our on-premises application, and it is a correct way to authenticate from on-premises to APIs. The B option just says how to create this file, and it misses the next step for what to do next to achieve an authentication. In option A and B we will have the same JSON key file, but only option A contains full way to accomplish the task.","timestamp":"1742961540.0","upvote_count":"1","comment_id":"1410239"},{"content":"Selected Answer: B\nB\nAs per the documentation: https://cloud.google.com/iam/docs/keys-create-delete#creating","timestamp":"1732345680.0","upvote_count":"4","poster":"thewalker","comment_id":"1078161"},{"timestamp":"1730886600.0","poster":"BAofBK","upvote_count":"1","comment_id":"1063707","content":"The correct answer is B"},{"poster":"drinkwater","upvote_count":"1","content":"A. Use service account credentials in your on-premises application.\n\nExplanation:\n\n Service accounts are the recommended way to authenticate your application and authorize it to access GCP services.\n You can create and use service account credentials to authenticate your application running in your on-premises environment and access GCP services like AutoML.\n\nOption B (using gcloud to create a key file for the service account) is a valid approach to generate credentials for a service account, but using those credentials in your application is essential, which aligns with option A.\n\nOptions C and D are not directly related to enabling authentication for on-premises applications using service account credentials. Setting up direct interconnect (option C) is about networking, and granting permissions to a user account (option D) is not the standard approach for authenticating an application running on-premises to GCP services","comment_id":"1043706","timestamp":"1728938160.0"},{"poster":"Captain1212","comment_id":"996583","timestamp":"1725252780.0","upvote_count":"1","content":"Selected Answer: B\nB is the correct answer, as to access the out side the google cloud , you need the key"},{"content":"Selected Answer: A\nA. Use service account credentials in your on-premises application.\n\nTo enable authentication to GCP services from your on-premises environment, you can use service account credentials in your on-premises application. This involves creating a service account that has appropriate access to the required GCP services, downloading the service account key file, and using the key file to authenticate the API requests in your on-premises application. This is a secure way to authenticate to GCP services as it does not require direct access to your GCP project or credentials from your on-premises environment.","comments":[{"comment_id":"816018","upvote_count":"3","content":"Cloud Security/Auditor doesn't like Answer \"A\". Using service account credentials in your on-premises application could be a security risk if the credentials are compromised. If the key file is stolen or leaked, an attacker could use it to access your GCP resources, potentially causing data breaches, service disruptions, or financial losses.\n\nI would select Answer \"B\". Use gcloud to create a key file for the service account that has appropriate permissions and let Security Auditor stay away from my back. Never-ending \"You cannot do this, you cannot do that\" on Answer A.","timestamp":"1708471980.0","poster":"Buruguduystunstugudunstuy"}],"poster":"Bobbybash","timestamp":"1707801360.0","upvote_count":"2","comment_id":"807088"},{"timestamp":"1701888540.0","content":"Selected Answer: B\nB it is.","comment_id":"737138","poster":"cslince","upvote_count":"1"},{"timestamp":"1701121980.0","content":"Selected Answer: B\nB it is.","upvote_count":"1","poster":"mvk2022","comment_id":"728640"},{"comment_id":"712032","upvote_count":"1","content":"Selected Answer: B\nCorrect answer should be (B):","timestamp":"1699223220.0","poster":"Kopy"},{"timestamp":"1687537380.0","poster":"AzureDP900","comment_id":"621112","content":"B is right\nTo use a service account from outside of Google Cloud, such as on other platforms or on-premises, you must first establish the identity of the service account. Public/private key pairs provide a secure way of accomplishing this goal. When you create a service account key, the public portion is stored on Google Cloud, while the private portion is available only to you. For more information about public/private key pairs, see Service account keys.","upvote_count":"4"},{"upvote_count":"1","comment_id":"611378","timestamp":"1685873520.0","content":"Go for B","poster":"haroldbenites"},{"content":"Selected Answer: B\nEven thought A and B seem to be doing the same thing the best practice is to create a key so B is the right answer \n!","upvote_count":"1","poster":"NoniGeorge","comment_id":"521960","timestamp":"1673508900.0"},{"upvote_count":"3","poster":"vishnukumartr","timestamp":"1668944880.0","content":"B. Use gcloud to create a key file for the service account that has appropriate permissions.","comment_id":"482477"},{"content":"B. Use gcloud to create a key file for the service account that has appropriate permissions.","comment_id":"481823","upvote_count":"3","poster":"shawnkkk","timestamp":"1668869940.0"},{"comments":[{"timestamp":"1668942900.0","content":"A is not really telling you the steps to accomplish the task, it's only telling you the result of it (creating a SA with sufficient permissions and then use Console / gcloud to create a JSON token for it)","upvote_count":"1","comment_id":"482441","poster":"jabrrJ68w02ond1"}],"upvote_count":"3","poster":"Vivekvkt123","content":"Why not A? Aren't A and B getting the same key file?","comment_id":"451743","timestamp":"1664183340.0"},{"timestamp":"1656729960.0","content":"B is correct.\n\nCreating service account keys\nTo use a service account from outside of Google Cloud, such as on other platforms or on-premises, you must first establish the identity of the service account. Public/private key pairs provide a secure way of accomplishing this goal. When you create a service account key, the public portion is stored on Google Cloud, while the private portion is available only to you. For more information about public/private key pairs, see Service account keys.","upvote_count":"3","poster":"sunilw","comment_id":"396493"},{"timestamp":"1653052560.0","upvote_count":"1","comment_id":"362192","poster":"arsh1916","content":"B is correct"},{"content":"B is correct as a 1st step...the key file is to be referenced in the env variable GOOGLE_APPLICATION_CREDENTIALS which would then provide access to on-prem application using ADC library","poster":"mcaromit","timestamp":"1652340300.0","comment_id":"355361","upvote_count":"1"},{"timestamp":"1648158000.0","upvote_count":"2","poster":"[Removed]","content":"B is correct. Use gcloud to create a key file for the service account that has appropriate permissions.","comment_id":"319592"},{"timestamp":"1645869060.0","comment_id":"299667","poster":"nliaustemac","content":"B. is the correct answer:\n Use gcloud to create a key file for the service account that has appropriate permissions.","upvote_count":"1"},{"comment_id":"296973","timestamp":"1645566120.0","upvote_count":"2","content":"B. Use gcloud to create a key file for the service account that has appropriate permissions.","poster":"GCP_Student1"},{"poster":"lutoa","comment_id":"284947","content":"I think it is B. I have seen other variations on this question where the scenario specifies that the on-premise has no internet, in which case interconnect is required. \n\nThis question does NOT specify, and since it is using API connection (so HTTP) it must have internet so the JSON key should be fine in answer B.","upvote_count":"2","timestamp":"1644164520.0"},{"timestamp":"1643681580.0","content":"B. Use gcloud to create a key file for the service account that has appropriate permissions.","poster":"DucSiu","upvote_count":"1","comment_id":"280920"},{"poster":"DucSiu","content":"D. In the cluster's definition in Deployment Manager, add a metadata that has kube-system as key and the DaemonSet manifest as value.","timestamp":"1643681520.0","comment_id":"280919","upvote_count":"1"},{"timestamp":"1643018160.0","content":"B - Use gcloud to create a key file for the service account that has appropriate permissions.","poster":"victory108","comment_id":"275167","upvote_count":"1"},{"comment_id":"272636","upvote_count":"1","timestamp":"1642749180.0","content":"B = 100%","poster":"DucSiu"},{"comment_id":"237018","content":"B = 100%","timestamp":"1638857820.0","poster":"Bhagirathi","upvote_count":"1"},{"comment_id":"221026","content":"• B. Use gcloud to create a key file for the service account that has appropriate permissions.","poster":"swatititame","timestamp":"1637150700.0","upvote_count":"1"},{"comment_id":"206813","content":"B, should use key file","upvote_count":"1","timestamp":"1635302760.0","poster":"nwk"},{"poster":"glam","timestamp":"1633843260.0","content":"B. Use gcloud to create a key file for the service account that has appropriate permissions.","comment_id":"197104","upvote_count":"3"},{"comment_id":"158954","content":"The answer is B:\nAccessing private data on behalf of a service account outside Google Cloud environments Service account key\nYou need to create a service account, and download its private key as a JSON file. You need to pass the file to Google Cloud Client Libraries, so they can generate the service account credentials at runtime.","upvote_count":"1","timestamp":"1629080940.0","poster":"francisco_guerra"},{"comment_id":"154468","comments":[{"content":"After reading this again, yes B is a need but only AFTER the Interconnect is setup. I'm changing my answer to C.","upvote_count":"3","comment_id":"157026","timestamp":"1628835660.0","poster":"XRiddlerX","comments":[{"poster":"Ale1973","comment_id":"174106","content":"I think that B is the right answer for the same reason.\nMy mental map is: B resolve the requirement, and yes, C is a prerequisite for B, but only C doesn't solve the scenery.","upvote_count":"3","timestamp":"1630862580.0"}]}],"content":"The Answer is B.\nhttps://cloud.google.com/anthos/gke/docs/on-prem/how-to/service-accounts#create_service_accounts\nThis section shows how to create the service accounts that you need to install and use GKE on-prem. It also shows how to create JSON key files for your service accounts and how to grant the appropriate IAM roles to your service accounts.","timestamp":"1628596080.0","poster":"XRiddlerX","upvote_count":"3"},{"upvote_count":"3","timestamp":"1628530020.0","content":"I Opt for B as per: https://cloud.google.com/docs/authentication#strategies","poster":"filco72","comment_id":"153861"},{"comment_id":"125913","timestamp":"1625368320.0","poster":"gtlranjan","content":"B is true","upvote_count":"4"},{"poster":"DarioFama23","content":"i think C","timestamp":"1624972620.0","comment_id":"122790","upvote_count":"2","comments":[{"content":"Wow, just for this small thing make interconnect? B will do the job just fine.","poster":"nitinz","timestamp":"1645582260.0","comment_id":"297088","upvote_count":"1"},{"comment_id":"124985","timestamp":"1625226900.0","poster":"spudleymcdudley","content":"Nobody else does. It's B","upvote_count":"18"}]}],"isMC":true,"topic":"1","question_id":254,"timestamp":"2020-06-29 05:14:00","answers_community":["B (84%)","A (16%)"],"question_text":"You are building an application that will run in your data center. The application will use Google Cloud Platform (GCP) services like AutoML. You created a service account that has appropriate access to AutoML. You need to enable authentication to the APIs from your on-premises environment. What should you do?","choices":{"D":"Go to the IAM & admin console, grant a user account permissions similar to the service account permissions, and use this user account for authentication from your data center.","C":"Set up direct interconnect between your data center and Google Cloud Platform to enable authentication for your on-premises applications.","B":"Use gcloud to create a key file for the service account that has appropriate permissions.","A":"Use service account credentials in your on-premises application."},"unix_timestamp":1593400440},{"id":"5LZFLqTMokN4tH0JUOzc","answer_description":"","question_text":"You are using Container Registry to centrally store your company's container images in a separate project. In another project, you want to create a Google\nKubernetes Engine (GKE) cluster. You want to ensure that Kubernetes can download images from Container Registry. What should you do?","answers_community":["A (100%)"],"choices":{"A":"In the project where the images are stored, grant the Storage Object Viewer IAM role to the service account used by the Kubernetes nodes.","B":"When you create the GKE cluster, choose the Allow full access to all Cloud APIs option under 'Access scopes'.","D":"Configure the ACLs on each image in Cloud Storage to give read-only access to the default Compute Engine service account.","C":"Create a service account, and give it access to Cloud Storage. Create a P12 key for this service account and use it as an imagePullSecrets in Kubernetes."},"exam_id":1,"question_images":[],"answer_images":[],"discussion":[{"poster":"ESP_SAP","comment_id":"159601","timestamp":"1597635300.0","upvote_count":"64","content":"Correct Answer (A):\nIAM permissions\nIAM permissions determine who can access resources. All users, service accounts, and other identities that interact with Container Registry must have the appropriate Cloud Storage permissions.\n\nBy default, Google Cloud use default service accounts to interact with resources within the same project. For example, the Cloud Build service account can both push and pull images when Container Registry is in the same project.\n\nYou must configure or modify permissions yourself if:\n\nYou are using a service account in one project to access Container Registry in a different project\nYou are using a default service account with read-only access to storage, but you want to both pull and push images\nYou are using a custom service account to interact with Container Registry\n\nhttps://cloud.google.com/container-registry/docs/access-control","comments":[{"timestamp":"1600606140.0","comment_id":"182982","upvote_count":"11","content":"A is correct, practical implementation in video https://www.youtube.com/watch?v=R16z7Sjrkxs","poster":"[Removed]"}]},{"poster":"XRiddlerX","timestamp":"1597253940.0","comment_id":"156665","upvote_count":"21","content":"A is correct...\nContainer Registry uses Cloud Storage buckets as the underlying storage for container images. You control access to your images by granting appropriate Cloud Storage permissions to a user, group, service account, or other identity.\n\nIf the service account needs to access Container Registry in another project, you must grant the required permissions in the project with Container Registry.\n\nReference:\nhttps://cloud.google.com/container-registry/docs/access-control#permissions"},{"upvote_count":"1","content":"Selected Answer: A\nContainer Registry stores images in Cloud Storage buckets under gcr.io, us.gcr.io, etc.\nGKE nodes need permission to pull images from this registry.","poster":"gseva","comment_id":"1357029","timestamp":"1739650800.0"},{"content":"Selected Answer: A\nA is correct","poster":"Enamfrancis","comment_id":"1288108","timestamp":"1727094360.0","upvote_count":"1"},{"upvote_count":"1","comment_id":"1212159","content":"As per https://cloud.google.com/container-registry/docs/access-control.\n\nContainer Registry is deprecated and scheduled for shutdown. After May 15, 2024, Artifact Registry will host images for the gcr.io domain in Google Cloud projects without previous Container Registry usage. After March 18, 2025, Container Registry will be shut down.\n\nArtifact Registry is the recommended service for container image storage and management on Google Cloud.","timestamp":"1715814480.0","poster":"omunoz"},{"upvote_count":"2","poster":"Captain1212","content":"Selected Answer: A\nA is the correct answer , as granting this role allow to download the image","comment_id":"996588","timestamp":"1693630920.0"},{"content":"Selected Answer: A\nGrating Storage Object Viewer IAM Role to the service account used by Kubernetes nodes allow the nodes to download the images from Container registry.","poster":"sakdip66","comment_id":"868913","timestamp":"1681342980.0","upvote_count":"1"},{"upvote_count":"5","comment_id":"816036","content":"Selected Answer: A\nAnswer A. In the project where the images are stored, grant the Storage Object Viewer IAM role to the service account used by the Kubernetes nodes.\n\nTo ensure that Kubernetes can download container images from Container Registry, you need to grant the necessary permissions to the service account used by the Kubernetes nodes. In this case, you would need to grant the Storage Object Viewer IAM role to the service account used by the Kubernetes nodes in the project where the images are stored. This role allows the service account to read objects from Cloud Storage buckets, including the container images in Container Registry.","poster":"Buruguduystunstugudunstuy","timestamp":"1676937060.0"},{"content":"Selected Answer: A\nDefinitely A seems more practical and accurate.","poster":"jrisl1991","comment_id":"791990","upvote_count":"1","timestamp":"1675020540.0"},{"upvote_count":"1","timestamp":"1665821640.0","content":"CORRET ANS is A","poster":"GaneshSurwase","comment_id":"695274"},{"timestamp":"1662900480.0","comment_id":"666134","poster":"ravip12345","content":"Answer A is correct.\nStorage Object Viewer (roles/storage.objectViewer) -- Grant the role on the registry storage bucket.\nhttps://cloud.google.com/container-registry/docs/access-control","upvote_count":"1"},{"content":"Storage Object viewer is enough, A is right.","upvote_count":"1","poster":"AzureDP900","timestamp":"1656001500.0","comment_id":"621114"},{"content":"Go for A.\nthe option A is specific with the role that will be used. In GCP , the recommendations is using the specific permission. The others options not are specific and are not correct .","timestamp":"1654338240.0","comment_id":"611380","upvote_count":"1","poster":"haroldbenites"},{"upvote_count":"2","comment_id":"569741","poster":"somenick","content":"Selected Answer: A\nhttps://cloud.google.com/container-registry/docs/access-control","timestamp":"1647523200.0"},{"comment_id":"553088","poster":"luciorifa","content":"Selected Answer: A\nA is the correct answe because it follows google recommended practices to grant permissions to service accounts, also the object viewer is the appropiate role for the GKE to pull the image","timestamp":"1645467480.0","upvote_count":"2"},{"comment_id":"542726","upvote_count":"1","timestamp":"1644273060.0","content":"Selected Answer: A\nA is the most obvious","poster":"jdx000"},{"upvote_count":"2","comment_id":"533069","poster":"ArunTaneja","content":"A should be correct \nhttps://cloud.google.com/container-registry/docs/pushing-and-pulling#pulling_images_from_a_registry\nhttps://cloud.google.com/storage/docs/access-control/iam-roles#standard-roles","timestamp":"1643215620.0"},{"timestamp":"1641973320.0","upvote_count":"1","poster":"NoniGeorge","content":"It's A as you need Storage Object Viewer IAM role in order to have access to the images!","comment_id":"521961"},{"content":"ES A Y PÚNTO","timestamp":"1641651180.0","upvote_count":"1","comments":[{"poster":"Anirudha077","upvote_count":"1","timestamp":"1670841840.0","content":"What??","comment_id":"742673"},{"comment_id":"816033","content":"Selected Answer: R \"as in\" RONG. LOL!","upvote_count":"2","poster":"Buruguduystunstugudunstuy","timestamp":"1676936880.0"}],"poster":"DiegoCG","comment_id":"519573"},{"poster":"Pret","comment_id":"494341","content":"Option A:\nPulling images from a registry\nPulling an image requires the Storage Object Viewer for the registry storage bucket, or a role with the same permissions.\n\nTo pull from Container Registry, use the command:\ndocker pull HOSTNAME/PROJECT-ID/IMAGE:TAG\n\nhttps://cloud.google.com/container-registry/docs/pushing-and-pulling","timestamp":"1638709680.0","upvote_count":"1"},{"upvote_count":"2","comment_id":"491853","timestamp":"1638381600.0","content":"C is correct answer: imagePullSecrets is use for pulling images from the private registry.","poster":"PradeepPen"},{"timestamp":"1637409060.0","upvote_count":"1","content":"A. In the project where the images are stored, grant the Storage Object Viewer IAM role to the service account used by the Kubernetes nodes.","comment_id":"482481","poster":"vishnukumartr"},{"upvote_count":"1","content":"A. In the project where the images are stored, grant the Storage Object Viewer IAM role to the service account used by the Kubernetes nodes.","comment_id":"481825","timestamp":"1637334000.0","poster":"shawnkkk"},{"comments":[{"timestamp":"1634386200.0","upvote_count":"1","content":"sorry Ignore this comment.","comment_id":"463053","poster":"Zesn"}],"upvote_count":"2","poster":"Zesn","comment_id":"463037","content":"How A is correct?? \nStorage Object Viewer IAM role can only view or list the object. Here the ask is to pull the image. Must be C","timestamp":"1634385720.0"},{"comment_id":"453101","timestamp":"1632811440.0","poster":"erikamrqz","upvote_count":"1","content":"Answer is A: Pulling an image requires the Storage Object Viewer for the registry storage bucket, or a role with the same permissions.\n\nhttps://cloud.google.com/container-registry/docs/pushing-and-pulling"},{"comment_id":"363437","timestamp":"1621661640.0","poster":"viswanand","upvote_count":"1","content":"A looks more sensible option"},{"content":"A is correct","comment_id":"355872","poster":"mcaromit","upvote_count":"1","timestamp":"1620866760.0"},{"comment_id":"347341","poster":"ssgcp","upvote_count":"1","content":"C should be the answer. It is the correct procedure to pull images from gcr in another project.","timestamp":"1619919540.0"},{"comment_id":"319594","timestamp":"1616622060.0","content":"A is correct. In the project where the images are stored, grant the Storage Object Viewer IAM role to the service account used by the Kubernetes nodes.","upvote_count":"2","poster":"[Removed]"},{"comment_id":"312758","content":"vote for 'A'\n\nC - does not mention which access provided?","poster":"sumanshu","timestamp":"1615931280.0","upvote_count":"1"},{"upvote_count":"2","timestamp":"1615665480.0","content":"https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\nI guess its C","comment_id":"309955","poster":"jackycc"},{"timestamp":"1615308960.0","comment_id":"306559","poster":"GCP_Student1","upvote_count":"2","content":"A. In the project where the images are stored, grant the Storage Object Viewer IAM role to the service account used by the Kubernetes nodes."},{"content":"Storage Object Viewer to pull images only\nStorage Object Admin to push and pull images\n\nA is correct!","timestamp":"1614474720.0","upvote_count":"2","poster":"AGHPE","comment_id":"300532"},{"comment_id":"299669","timestamp":"1614333540.0","poster":"nliaustemac","upvote_count":"1","content":"A. is the correct answer:\n In the project where the images are stored, grant the Storage Object Viewer IAM role to the service account used by the Kubernetes nodes."},{"content":"A. In the project where the images are stored, grant the Storage Object Viewer IAM role to the service account used by the Kubernetes nodes.","upvote_count":"1","poster":"DucSiu","comment_id":"280929","timestamp":"1612146900.0"},{"content":"Answer is A, please read it here https://cloud.google.com/container-registry/docs/using-with-google-cloud-platform","comment_id":"274510","upvote_count":"2","poster":"guid1984","timestamp":"1611399600.0"},{"comment_id":"267575","poster":"nherrerab","upvote_count":"2","content":"A is correct.","timestamp":"1610679840.0"},{"timestamp":"1607322300.0","comment_id":"237024","upvote_count":"2","poster":"Bhagirathi","content":"A to choose<"},{"timestamp":"1606042440.0","content":"why this page carries some answer and you guys find a new one?\n\nwhat shall we understand finally ? for me it only confusions","comment_id":"224902","poster":"Bhagirathi","upvote_count":"4"},{"poster":"ayj","upvote_count":"2","comment_id":"221938","timestamp":"1605708480.0","content":"A\nIf the VM and Container Registry are in separate projects\nYou must grant the service account with IAM permissions to access the storage bucket used by Container Registry.\n\nhttps://cloud.google.com/container-registry/docs/access-control#integration"},{"poster":"swatititame","upvote_count":"2","timestamp":"1605616740.0","content":"• A. In the project where the images are stored, grant the Storage Object Viewer IAM role to the service account used by the Kubernetes nodes.","comment_id":"221047"},{"content":"Vote A\nhttps://cloud.google.com/container-registry/docs/access-control#grant-bucket","poster":"nwk","comment_id":"206815","timestamp":"1603774200.0","upvote_count":"1"},{"poster":"cpd","timestamp":"1602435180.0","comment_id":"197857","content":"PULL---> Object viewer\nPUSH --> Storage Admin","upvote_count":"3"},{"upvote_count":"3","content":"A. In the project where the images are stored, grant the Storage Object Viewer IAM role to the service account used by the Kubernetes nodes.","comment_id":"197118","poster":"glam","timestamp":"1602312300.0"},{"upvote_count":"2","poster":"GopinathM","timestamp":"1600772040.0","comment_id":"184341","content":"A is correct\n\nFrom the menu that appears, fill the Members field with the email addresses of users needing permission, separated by commas. This email address can be one of the following:\n\na Google account (for example, someone@example.com)\nA Google group (for example, my-developer-team@googlegroups.com)\nan IAM service account\nthe Compute Engine default service account of another project. This account is used by the Google Kubernetes Engine to pull container images clusters by default. It is in the form PROJECT-NUMBER-compute@developer.gserviceaccount.com, where PROJECT-NUMBER is the Google Cloud project number of the project that is running the Google Kubernetes Engine cluster.\nFrom the Select a role drop-down menu, select the Storage category, and then select the appropriate permission.\n\nStorage Object Viewer to pull images only\nStorage Object Admin to push and pull images\nClick Add."},{"upvote_count":"3","comment_id":"176126","timestamp":"1599602220.0","poster":"[Removed]","content":"I agree that A is correct. \n\nA - see other explanations\nB - Full access is way to permissive for the nice case of needing to pull registry images\nC - setting ACLs on each image is not suitable for the use case where the separate project needs access to all images in in the registry. Also, It does not indicate that the default compute engine service account is used, thus it may be a different one used by the GKE cluster."},{"timestamp":"1596122400.0","comment_id":"147502","upvote_count":"1","content":"this was very tricky to answer. It required a lot of research. \nThe correct answer is C\nhttps://blog.container-solutions.com/using-google-container-registry-with-kubernetes","poster":"Verve","comments":[{"upvote_count":"3","timestamp":"1596302640.0","poster":"someoneinthecloud","content":"C is wrong. ImagePullSecrets has nothing to do with pulling images from a container registry. A is the only possible answer","comment_id":"148674","comments":[{"upvote_count":"2","comment_id":"148677","timestamp":"1596302820.0","poster":"someoneinthecloud","content":"https://cloud.google.com/container-registry/docs/access-control"}]}]},{"poster":"Hjameel","content":"Storage Object Viewer to pull images only\nStorage Object Admin to push and pull images\nOption A is a wrong answer because you need to push not pull the image, C said the service account in the project of the container image and it has a viewer role, not in the project of K8. \nthe closed answer is C","comments":[{"timestamp":"1597340460.0","upvote_count":"4","poster":"Hjameel","comment_id":"157531","content":"I will take it back, A is the right answer because the service account will pull the image from the container image"}],"comment_id":"146688","timestamp":"1596042360.0","upvote_count":"2"},{"poster":"svram","content":"Its A. Read the docs\n\nhttps://cloud.google.com/container-registry/docs/access-control","comment_id":"129785","upvote_count":"8","timestamp":"1594214760.0"},{"upvote_count":"7","timestamp":"1593691440.0","poster":"spudleymcdudley","content":"Suspect 'A' is correct given this: \"If the cluster is in a different project or if the VMs in the cluster use a different service account, you must grant the service account the appropriate permissions to access the storage bucket used by Container Registry.\" & \"For the service account used by Compute Engine VMs, including VMs in Google Kubernetes Engine clusters, access is based on both Cloud IAM permissions and storage access scopes.\" - https://cloud.google.com/container-registry/docs/using-with-google-cloud-platform","comments":[{"content":"'C' doesn't make sense as Google moved all the access into IAM and access scopes. Process is verbose and pointless","comment_id":"124996","timestamp":"1593691620.0","poster":"spudleymcdudley","upvote_count":"2"},{"upvote_count":"2","poster":"spudleymcdudley","content":"'D' would only work inside one of the projects, the other isn't mantioned","timestamp":"1593691560.0","comment_id":"124995"}],"comment_id":"124994"},{"timestamp":"1592630220.0","poster":"Ciumela","comment_id":"114438","upvote_count":"4","content":"I think option A too"},{"timestamp":"1592120400.0","comment_id":"109945","content":"I think Option A is the right answer","upvote_count":"7","poster":"kishoredeena"},{"timestamp":"1592094000.0","upvote_count":"1","content":"C is the correct answer - https://medium.com/@michaelmorrissey/using-cross-project-gcr-images-in-gke-1ddc36de3d42","comment_id":"109790","poster":"Gurnoor"},{"upvote_count":"2","comments":[{"comment_id":"107060","poster":"dan80","timestamp":"1591812180.0","content":"i take it back , https://cloud.google.com/container-registry/docs/using-with-google-cloud-platform - C is correct","upvote_count":"1"}],"comment_id":"103168","content":"B is correct - https://cloud.google.com/ai-platform/pipelines/docs/configure-gke-cluster","poster":"dan80","timestamp":"1591363740.0"},{"comment_id":"103156","poster":"[Removed]","upvote_count":"1","timestamp":"1591362300.0","content":"I think it is C"}],"answer_ET":"A","unix_timestamp":1591362300,"question_id":255,"url":"https://www.examtopics.com/discussions/google/view/22192-exam-associate-cloud-engineer-topic-1-question-71-discussion/","answer":"A","topic":"1","isMC":true,"timestamp":"2020-06-05 15:05:00"}],"exam":{"id":1,"name":"Associate Cloud Engineer","numberOfQuestions":285,"isBeta":false,"lastUpdated":"11 Apr 2025","provider":"Google","isMCOnly":true,"isImplemented":true},"currentPage":51},"__N_SSP":true}