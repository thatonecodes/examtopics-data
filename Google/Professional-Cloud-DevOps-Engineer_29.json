{"pageProps":{"questions":[{"id":"NwsnJ3mAtxjQS4jQbGSt","isMC":true,"choices":{"D":"A GPU-accelerated video rendering platform that retrieves and stores videos in a storage bucket.","C":"A distributed, eventually consistent NoSQL database cluster with sufficient quorum.","A":"A scalable in-memory caching system.","B":"The organization's public-facing website."},"answer_images":[],"timestamp":"2021-06-13 22:11:00","topic":"1","answer_ET":"D","question_text":"You need to reduce the cost of virtual machines (VM) for your organization. After reviewing different options, you decide to leverage preemptible VM instances.\nWhich application is suitable for preemptible VMs?","answer":"D","unix_timestamp":1623615060,"answers_community":["D (38%)","A (38%)","C (23%)"],"exam_id":6,"discussion":[{"poster":"Charun","comment_id":"393472","comments":[{"comment_id":"864716","upvote_count":"3","poster":"NiveusSol","comments":[{"comment_id":"987475","timestamp":"1692711720.0","poster":"xarom","upvote_count":"3","content":"https://cloud.google.com/compute/docs/instances/preemptible#preemptible-with-gpu"}],"timestamp":"1680961140.0","content":"A\nA GPU-accelerated video rendering platform that retrieves and stores videos in a storage bucket: Video rendering requires a stable and powerful infrastructure with persistent storage, which is not provided by preemptible VMs. Additionally, GPUs are not available on all preemptible VM instances."}],"upvote_count":"17","timestamp":"1624938900.0","content":"D is correct"},{"comments":[{"timestamp":"1623646260.0","comment_id":"381546","poster":"akg001","upvote_count":"4","content":"Agree with you on Answer D"},{"comment_id":"864717","content":"D GPU-accelerated video rendering platform that retrieves and stores videos in a storage bucket: Video rendering requires a stable and powerful infrastructure with persistent storage, which is not provided by preemptible VMs. Additionally, GPUs are not available on all preemptible VM instances.","poster":"NiveusSol","timestamp":"1680961200.0","upvote_count":"2"}],"upvote_count":"6","content":"ans: D","timestamp":"1623615060.0","comment_id":"381314","poster":"devopsbatch"},{"timestamp":"1739185140.0","upvote_count":"2","content":"Selected Answer: C\nPreemptible VMs are short-lived and can be terminated by Google Cloud at any time if resources are needed elsewhere, so they are ideal for fault-tolerant applications that can handle interruptions without significant impact on functionality.\n\n Option C describes a distributed, eventually consistent NoSQL database.\n Eventually consistent systems can tolerate temporary unavailability of some nodes and reconcile the data once nodes are back online.\n Quorum-based systems (like many NoSQL databases) can continue to operate even if some VMs are preempted, as long as the required quorum of nodes is still available.\n Therefore, this setup is well-suited for preemptible VMs, as it can handle intermittent node loss.","poster":"dneves","comment_id":"1354427"},{"timestamp":"1723595280.0","poster":"6a8c7ad","upvote_count":"2","content":"Selected Answer: D\nHas to be D. Definitely not A","comment_id":"1265446"},{"content":"Selected Answer: D\ncannot be A, if the VM is removed by the preemption process, we lose data in memory","poster":"winston9","timestamp":"1717926300.0","upvote_count":"1","comment_id":"1227218"},{"poster":"jinaldesailive","upvote_count":"1","timestamp":"1709834400.0","content":"Selected Answer: A\nIt seems A & D both as suitable answer. But I'll go with A, as attaching GPU with preemptible VM will increase cost, and in this question the purpose of opting for preemptible VM is reducing cost.\nhttps://cloud.google.com/compute/docs/instances/preemptible#preemptible-with-gpu","comment_id":"1168247"},{"comment_id":"1167663","content":"Will go with D. \nLooking for cost effective. \nhttps://cloud.google.com/compute/docs/instances/preemptible#preemptible-with-gpu","timestamp":"1709787780.0","upvote_count":"1","poster":"FI22"},{"timestamp":"1703301720.0","content":"Selected Answer: A\nans: A\nPreemptible VMs are best suited for fault-tolerant, non-critical applications due to their temporary nature. Among the options listed, A, a scalable in-memory caching system, aligns well with preemptible instances as it can handle interruptions and doesn't require continuous uptime.","comment_id":"1103844","upvote_count":"2","poster":"MFay"},{"timestamp":"1701513360.0","comment_id":"1086062","poster":"jomonkp","upvote_count":"1","content":"Selected Answer: D\nOption D"},{"comment_id":"1055137","content":"Selected Answer: A\nI would go with A compared to other options","timestamp":"1698385560.0","poster":"Jason_Cloud_at","upvote_count":"2"},{"content":"Selected Answer: D\nAns is D\nVideo rendering service is like application type called Batch job. Therefore, we can use instance type preemptible for them. If they complete task, they could be destroy and generate new instance to work continuously next task.","comment_id":"902371","timestamp":"1684561500.0","upvote_count":"2","poster":"Watcharin_start"},{"poster":"izekc","timestamp":"1678422480.0","comment_id":"834635","upvote_count":"3","content":"Selected Answer: C\nC is more accurate"},{"upvote_count":"5","content":"Selected Answer: A\nWhy not A? \"A scalable in-memory caching system.\"\nIn general a caching system is not critical to the function of an application.\nIf the cache is down it will cause requests to have cache miss and query the DB instead. User requests will still get served albeit slower.\nIn addition the answer specifies that the caching system is \"scalable\" reducing further the impact of 1 VM getting preempted, ie traffic can be automatically redirected to other cache replicas.\nTo me all other answers seem to have a more severe impact on the user in case the VM is preempted.","timestamp":"1670893320.0","comment_id":"743465","poster":"eks4x"},{"upvote_count":"1","poster":"kisshs","content":"Selected Answer: C\nC is the right answer","comment_id":"735686","timestamp":"1670219280.0"},{"comment_id":"733278","upvote_count":"2","poster":"hanweiCN","timestamp":"1669942680.0","content":"i think is C, database cluster is storage, and distributed, eventually consistence is resistant for the preempted. and sufficient quorum can ensure the DB transitions."},{"timestamp":"1654875120.0","poster":"eliC","upvote_count":"2","comment_id":"614620","content":"Selected Answer: D\nD is correct"},{"timestamp":"1652382300.0","poster":"psyx21","content":"Selected Answer: D\nD is correct","upvote_count":"2","comment_id":"600781"},{"poster":"TNT87","timestamp":"1630654380.0","comment_id":"438384","content":"D\nhttps://cloud.google.com/compute/docs/instances/preemptible","upvote_count":"4"},{"upvote_count":"4","timestamp":"1624076760.0","comment_id":"385217","poster":"ralf_cc","content":"D - external persistent storage"}],"url":"https://www.examtopics.com/discussions/google/view/55256-exam-professional-cloud-devops-engineer-topic-1-question-49/","question_id":141,"question_images":[],"answer_description":""},{"id":"whYervlBd08zIUMPAM18","exam_id":6,"topic":"1","answer_ET":"D","isMC":true,"choices":{"B":"Install the most recent version of the Stackdriver agent.","A":"Look for the agent's test log entry in the Logs Viewer.","C":"Verify the VM service account access scope includes the monitoring.write scope.","D":"SSH to the VM and execute the following commands on your VM: ps ax | grep fluentd."},"question_id":142,"timestamp":"2021-06-02 16:30:00","discussion":[{"content":"Between C and D, I think D\n\nReason : When an instance is created, we can specify which service account the instance uses when calling Google Cloud APIs. The instance is automatically configured with access scope and one such access scope is monitoring.write (Link : https://cloud.google.com/compute/docs/access/service- read is to publish metric data and logging.write is to write compute engine logs.\n\nConsidering above, I believe D as the answer (check whether the agent is running)","poster":"raf2121","comment_id":"421450","upvote_count":"12","comments":[{"upvote_count":"3","timestamp":"1647172200.0","poster":"cetanx","content":"Agree. If you check here: https://cloud.google.com/logging/docs/agent/logging/troubleshooting#checklist\nYou will see that first recommended troubleshooting step is to check if the agent is running or not... So it should be D.\n\nAlso if you refer to Google Groups link provided as the answer, you will see that they first checked if the agent is running/installed.","comment_id":"443883"}],"timestamp":"1644294300.0"},{"upvote_count":"1","comment_id":"1193957","poster":"desertlotus1211","content":"Why nnot Answer A as a starting point?","timestamp":"1728669960.0"},{"upvote_count":"1","comment_id":"772012","timestamp":"1689042420.0","poster":"JonathanSJ","content":"Selected Answer: D\nAnswer is D."},{"comment_id":"754742","timestamp":"1687583340.0","upvote_count":"2","poster":"floppino","content":"Selected Answer: D\nAns: D"},{"poster":"DoodleDo","content":"D. Check if fluentd is running is the right answer. C is incorrect as monitoring.write scope is for monitoring agent and not logging agent.","comment_id":"727715","upvote_count":"2","timestamp":"1685115360.0"},{"timestamp":"1682338440.0","upvote_count":"1","poster":"zellck","content":"Selected Answer: D\nD is the answer.\n\nhttps://cloud.google.com/logging/docs/agent/logging/troubleshooting#checklist\nIf you are having trouble installing or using the Logging agent, here are some things to check:\n- Verify that the agent service is running on your VM instance","comment_id":"702997"},{"upvote_count":"1","poster":"GCP72","timestamp":"1674543780.0","comment_id":"635879","content":"Selected Answer: D\nAns: D"},{"comment_id":"617688","upvote_count":"1","timestamp":"1671284580.0","content":"Selected Answer: D\nAns: D","poster":"Devtestnew"},{"upvote_count":"1","content":"Selected Answer: D\nSubmitted D","comment_id":"599113","poster":"Ananda","timestamp":"1668015360.0"},{"timestamp":"1666236840.0","comment_id":"588428","upvote_count":"1","content":"answer is D","poster":"gomezzang"},{"upvote_count":"2","comment_id":"547567","timestamp":"1660538820.0","poster":"alexweberlopes","content":"The VM has cloud-platform scope on the VM means Full access if you using the default compute account. I would say answer D is right check is the fluentd daemon running."},{"upvote_count":"1","content":"Selected Answer: D\nhttps://cloud.google.com/logging/docs/agent/logging/troubleshooting#test-agent","comment_id":"532759","timestamp":"1658821740.0","poster":"pddddd"},{"timestamp":"1654422900.0","poster":"alaahakim","content":"Ans: D","upvote_count":"2","comment_id":"494289"},{"upvote_count":"2","timestamp":"1653390900.0","content":"C is not good, “monitoring.write\" is use for metric not log","poster":"Wwhite44","comment_id":"485969"},{"upvote_count":"1","content":"https://cloud.google.com/compute/docs/access/service-accounts#associating_a_service_account_to_an_instance\n\nWhen you create an instance using the gcloud command-line tool or the Google Cloud Console, you can specify which service account the instance uses when calling Google Cloud APIs. The instance is automatically configured with the following access scopes:\n\n\n* ...\n\nSo D is better than C.","timestamp":"1646068620.0","poster":"danchoif2","comment_id":"434694","comments":[{"poster":"Manumj","timestamp":"1648655280.0","comments":[{"upvote_count":"1","comment_id":"470717","content":"https://cloud.google.com/logging/docs/agent/logging/installation\n\nLogging agent is fluentd based (now fluentbit).\n\nThe Logging agent streams logs from your VM instances and from selected third-party software packages to Cloud Logging. It is a best practice to run the Logging agent on all your VM instances.\n\nThe VM images for Compute Engine and Amazon Elastic Compute Cloud (EC2) don't include the Logging agent, so you must complete these steps to install it on those instances. The agent runs under both Linux and Windows.\n\nIf your VMs are running in Google Kubernetes Engine or App Engine, the agent is already included in the VM image, so you can skip this page.","poster":"danchoif2","timestamp":"1651323000.0"}],"content":"i don't think so , reason is option-D is looking for fluent d which is specifically for customized logs , also by default the syslog will be captured with default monitoring agent and no need for fluent-d","comment_id":"455005","upvote_count":"1"}]},{"content":"C, first thing to check should be the access scope. There are 3 types of scopes, default, full access and access for each API. Even thought the default scope have the Stackdriver write access, it doesn't mean the instance has the default scope. It could be access for each API. Hence, first thing to check is the scope. After that, you can check the fluentd service in the system. C over D.","poster":"guruguru","comments":[{"upvote_count":"1","content":"Monitoring.write is for metric, so C is not correct. In that case logging.write was the right command. So D is the correct ANS ;)","timestamp":"1653390840.0","poster":"Wwhite44","comment_id":"485966"}],"comment_id":"389120","timestamp":"1640307720.0","upvote_count":"2"},{"upvote_count":"2","comments":[{"comment_id":"453049","upvote_count":"2","poster":"TNT87","content":"Sorry Ans is D","timestamp":"1648444860.0"}],"comment_id":"387760","content":"Ans C \nhttps://cloud.google.com/logging/docs/agent/logging/troubleshooting","timestamp":"1640170080.0","poster":"TNT87"},{"poster":"francisco_guerra","timestamp":"1639952880.0","comments":[{"upvote_count":"1","comment_id":"500444","poster":"burndayl","timestamp":"1655099520.0","content":"I think the answer is D. C couldn't be right because it suggest to verify the monitoring.write scope. But this kind of scope is for monitoring agent not for logging agent. If you see here:\nhttps://cloud.google.com/logging/docs/agent/logging/troubleshooting?hl=en\nthey say: If you do not have suitable access scopes in your Compute Engine instance, add the needed access scopes to your instance. The following table shows the scopes relevant to the Logging and Monitoring agents:\nAccess scope Agent permissions\nhttps://www.googleapis.com/auth/logging.write Adequate for the Logging agent\nhttps://www.googleapis.com/auth/monitoring.write Adequate for the Monitoring agent\nwhat do you think about it?"},{"timestamp":"1641475500.0","comment_id":"399920","upvote_count":"5","poster":"syslog","content":"I think it's D: https://cloud.google.com/logging/docs/agent/logging/troubleshooting#test-agent. Maybe the agent is installed but not running."}],"comment_id":"385773","content":"Ans is C\nWhy?:\nA: Does not make sense at all\nB: the version it's not possible?\nC: Its OK because both (scope and service account) need access to write to logging\nD: Really? the question clearly says: \"The image has the Stackdriver Logging agent installed.\"\n\nExplanation:\nGenerally, you can just set the cloud-platform access scope to allow access to most of the Cloud APIs, then grant the service account only relevant IAM roles. The combination of access scopes granted to the virtual machine instance and the IAM roles granted to the service account determines the amount of access the service account has for that instance. The service account can execute API methods only if they are allowed by both the access scope and its IAM roles.\n\nhttps://cloud.google.com/compute/docs/access/create-enable-service-accounts-for-instances\n\nPlease do not try to confuse people if you put your explanation add the link","upvote_count":"3"},{"content":"C because vm need writer access and i feel D as well because fluent need to be available to export ,aggregate and process logs into stack driver monitoring tool... suggestions needed here","timestamp":"1638462600.0","upvote_count":"3","comment_id":"372781","poster":"devopsbatch","comments":[{"timestamp":"1642518480.0","upvote_count":"2","content":"i think it's D, cause ans C is less precise. on question mention \"logging agent\" not \"monitoring agent\" and from here :https://cloud.google.com/logging/docs/agent/logging/troubleshooting#verifying_access_scopes\nit should be \"logging.write\" not \"monitoring.write\"","comment_id":"408960","poster":"Zuy01"},{"poster":"akg001","comment_id":"379751","timestamp":"1639228500.0","content":"Default: read-only access to Storage and Service Management, write access to Stackdriver Logging and Monitoring, read/write access to Service Control.\n\nSo answer should be D","upvote_count":"1"},{"content":"Cloud-platform scope covers all the GCP service scope so no need to add any other scope. hence answer should be D","poster":"rinkeshgala1","timestamp":"1638843900.0","upvote_count":"1","comment_id":"376395"}]}],"answer_description":"","url":"https://www.examtopics.com/discussions/google/view/54227-exam-professional-cloud-devops-engineer-topic-1-question-5/","answers_community":["D (100%)"],"answer_images":[],"answer":"D","unix_timestamp":1622644200,"question_images":[],"question_text":"You are running an application in a virtual machine (VM) using a custom Debian image. The image has the Stackdriver Logging agent installed. The VM has the cloud-platform scope. The application is logging information via syslog. You want to use Stackdriver Logging in the Google Cloud Platform Console to visualize the logs. You notice that syslog is not showing up in the \"All logs\" dropdown list of the Logs Viewer. What is the first thing you should do?"},{"id":"cb04t5CiAW3CgckEyykx","isMC":true,"timestamp":"2021-06-13 22:12:00","discussion":[{"comment_id":"390711","upvote_count":"27","timestamp":"1640464740.0","poster":"francisco_guerra","content":"this question is a little bit strange, but first we need to remove the invalid answers\n\nB: Incorrect An admission controller is a piece of code that intercepts requests to the Kubernetes API server prior to persistence of the object, but after the request is authenticated and authorized. (its for security but not \"enforce approvals\")\nC: Incorrect, we need to \"enforce approvals\" roles apply in the cluster and Ops always could push to production without approval.\nA: Incorrect, for me this answer sound well but this does not sound that an answer for a gcp exam and this do not enforce the use of the pipeline.\nD: Correct, they cannot push code to production without approval because their images are not signed."},{"upvote_count":"15","poster":"francisco_guerra","comment_id":"395931","timestamp":"1641046980.0","content":"I win the exam today so this questions help me a lot"},{"comment_id":"1086087","timestamp":"1717318860.0","upvote_count":"1","poster":"jomonkp","content":"Selected Answer: D\nOption D"},{"upvote_count":"1","comment_id":"736129","poster":"WhyIronMan","comments":[{"poster":"Greg123123","upvote_count":"2","comment_id":"762560","content":"but you missed the point here \"The security auditor is concerned that developers or operators could circumvent\". I see why you think pull request is the only way to circumvent the deployment process. But how about the operators? They have access to cluster and can simply redeploy it by some kubectl / cloud build command. So A is not correct.","comments":[{"poster":"WhyIronMan","comment_id":"769311","content":"That said, I send the question back to you, how about the developers?: \"is concerned that developers or operators could circumvent\" \nDeveloper will push code direct to master, with bug that is not caught by the tests and here we go: you do have a signed imaged, attested, with a BUG or something like that will be deployed\nso the question depends on the point of view, the combination of both are right\n\nand one more thing, D prevent to push to the registry, but the operator can get the kubernetes deployment yaml and point to other GCR...","upvote_count":"1","timestamp":"1688807100.0"}],"timestamp":"1688106780.0"}],"timestamp":"1685977380.0","content":"Selected Answer: A\nIf you are not familiarised, Pull Requests are one way to bring changes from one branch (e.g. develop) into protected branches (e.g. master, main).\n\n1. First you need to protect the production branch (e.g, master, main)\n2. If a developer attempts to push new code to a production (now protected) it will trow a Permission denied error like this:\nremote: Permission denied to update branch master.\nTo git.com:org/repository.git\n ! [remote rejected] master -> master (pre-receive hook declined)\nerror: failed to push some refs to 'git.com:org/repository.git'\n\n3. in order to push their code to production branch, the developers will need to open a Pull Request (If you are using GitLab, it is called Merge Request) and ask someone to Review and Approve your changes.\n4. The pipeline points to the protected branch; any new code pushed trigger the pipeline, and runs the tests and then deploy it.\n\nThis is how we do devops."},{"comment_id":"674715","timestamp":"1679372760.0","content":"Selected Answer: D\nD is correct answer, binary auth is best practice","poster":"ramzez4815","upvote_count":"3"},{"upvote_count":"2","content":"Correct me if I am wrong, but this question is ambiguous. You can push the code at 3 stages:\n1. You can merge a branch to master without Merge Request if the master is not protected\n2. You can push the image to container registry to a repository if you have role assigned (only pipeline should be privileged to do).\n3. An operator can change the code altering image/yaml using kubectl cli. \n\nThe ultimate question is which problem are we trying to solve?","poster":"lxs","comment_id":"613205","timestamp":"1670505360.0"},{"upvote_count":"3","content":"Selected Answer: D\nD - Binary authorisation","comment_id":"546339","timestamp":"1660373640.0","poster":"PhilipKoku"},{"content":"D\nhttps://cloud.google.com/binary-authorization\nBinary Authorization is a deploy-time security control that ensures only trusted container images are deployed on Google Kubernetes Engine (GKE) or Cloud Run. With Binary Authorization, you can require images to be signed by trusted authorities during the development process and then enforce signature validation when deploying. By enforcing validation, you can gain tighter control over your container environment by ensuring only verified images are integrated into the build-and-release process.","comment_id":"517831","timestamp":"1657051200.0","upvote_count":"2","poster":"DarkMatterOne"},{"comment_id":"451807","timestamp":"1648301640.0","upvote_count":"3","content":"Questions 51-55 is not available.. can someone please help me to get 51-55 questions?","poster":"maddy94"},{"content":"Agreed with D. The keywords here is \"developers or operators\". Option A the operators could push images to production without approval (operators could touch the cluster directly and the cluster cannot do any action against them). Rest same as francisco_guerra.","comment_id":"394260","upvote_count":"4","timestamp":"1640826900.0","poster":"zanhsieh"},{"upvote_count":"1","poster":"ralf_cc","timestamp":"1639895340.0","comment_id":"385220","content":"D - PR approval will ensure the automated testing etc., the question is asking how to ensure all code changes go through the pipeline, where automated tests are integrated"},{"upvote_count":"1","comment_id":"381552","poster":"akg001","content":"Answer C is the most close answer. Leverage best practice .\nanswer A is for pulling the code but in the question , the security auditor is concern about pushing the code .","timestamp":"1639465080.0","comments":[{"content":"If you are not familiarised, Pull Requests are one way to bring changes from one branch (e.g. develop) into protected branches (e.g. master, main).\n\nIn order to push their code to production branch, the developers will need to open a Pull Request (If you are using GitLab, it is called Merge Request) and ask someone to Review and Approve their changes.","comment_id":"736131","timestamp":"1685977500.0","upvote_count":"1","poster":"WhyIronMan"}]},{"poster":"devopsbatch","timestamp":"1639433520.0","comment_id":"381315","content":"A could be the ans","comments":[{"upvote_count":"1","comment_id":"1101841","content":"IMHO the statement is concert about runnigs unsafe workload on a cluster Kubernet, and not how to protect the code repository, in this other case, pull request approval and an Admission Controller would be fine. Then D is the ans","poster":"Feliphus","timestamp":"1718901840.0"},{"content":"I think you are right : A\nhttps://github.community/t/best-practices-for-protected-branches/10204","comment_id":"381560","timestamp":"1639465620.0","poster":"akg001","upvote_count":"2"}],"upvote_count":"2"}],"exam_id":6,"choices":{"A":"Configure the build system with protected branches that require pull request approval.","C":"Leverage Kubernetes Role-Based Access Control (RBAC) to restrict access to only approved users.","B":"Use an Admission Controller to verify that incoming requests originate from approved sources.","D":"Enable binary authorization inside the Kubernetes cluster and configure the build pipeline as an attestor."},"answers_community":["D (88%)","13%"],"url":"https://www.examtopics.com/discussions/google/view/55257-exam-professional-cloud-devops-engineer-topic-1-question-50/","answer_ET":"D","question_id":143,"answer_description":"","unix_timestamp":1623615120,"question_text":"Your organization recently adopted a container-based workflow for application development. Your team develops numerous applications that are deployed continuously through an automated build pipeline to a Kubernetes cluster in the production environment. The security auditor is concerned that developers or operators could circumvent automated testing and push code changes to production without approval. What should you do to enforce approvals?","question_images":[],"answer_images":[],"topic":"1","answer":"D"},{"id":"hlxr17ZKwd6rfD6EE1Fo","choices":{"C":"Set up additional service instances in other zones and load balance the traffic between all instances","D":"Set up additional service instances in other zones and use them as a failover in case the primary instance is unavailable","B":"Move the service to higher-specification compute instances with more memory","A":"Change the specified SLO to match the measured SLI"},"url":"https://www.examtopics.com/discussions/google/view/64620-exam-professional-cloud-devops-engineer-topic-1-question-51/","discussion":[{"upvote_count":"12","poster":"Alaaelanwr","timestamp":"1666630140.0","comment_id":"467057","content":"Ans: C"},{"upvote_count":"1","content":"Selected Answer: C\nOption C","poster":"jomonkp","comment_id":"1086096","timestamp":"1733137680.0"},{"poster":"jomonkp","comment_id":"1086089","upvote_count":"1","timestamp":"1733137440.0","content":"Option C"},{"timestamp":"1705274400.0","poster":"JonathanSJ","upvote_count":"2","comment_id":"776014","content":"Selected Answer: C\nC. Set up additional service instances in other zones and load balance the traffic between all instances\n\nThis option will provide redundancy and increase the availability of the service by distributing the traffic across multiple instances. Additionally, if one instance goes down, the load balancer will redirect the traffic to the other healthy instances, minimizing the impact on the service availability."},{"content":"Selected Answer: C\nC is the correct anwer, it is required to increase reliability","upvote_count":"3","poster":"ramzez4815","comment_id":"687386","timestamp":"1696559580.0"},{"comment_id":"599138","upvote_count":"2","poster":"Ananda","content":"Selected Answer: C\nSubmitted C","timestamp":"1683648120.0"},{"content":"Ans: C","upvote_count":"1","timestamp":"1674195600.0","comment_id":"528181","poster":"Sekierer"},{"content":"C, this option will offer resilience and distribute the load, also provides ability to configure health checks at VM level and Load Balancer can send only to Healthy Instances.","timestamp":"1669165980.0","upvote_count":"1","comment_id":"484675","poster":"muk5658"},{"comment_id":"476025","poster":"Manh","timestamp":"1668149100.0","content":"ANSWER: C","upvote_count":"2"}],"exam_id":6,"answer_images":[],"isMC":true,"answers_community":["C (100%)"],"question_images":[],"unix_timestamp":1635094140,"timestamp":"2021-10-24 18:49:00","answer_ET":"C","question_id":144,"answer":"C","topic":"1","question_text":"You support a stateless web-based API that is deployed on a single Compute Engine instance in the europe-west2-a zone. The Service Level Indicator (SLI) for service availability is below the specified Service Level Objective (SLO). A postmortem has revealed that requests to the API regularly time out. The time outs are due to the API having a high number of requests and running out memory. You want to improve service availability. What should you do?","answer_description":""},{"id":"OjlTW18xYOPFSaDXr1OJ","choices":{"B":"Enable VPC Flow Logs on the production VPC network frontend and backend subnets only with a sample volume scale of 1.0.","A":"Enable VPC Flow Logs on the production VPC network frontend and backend subnets only with a sample volume scale of 0.5.","C":"Enable VPC Flow Logs on the testing and production VPC network frontend and backend subnets with a volume scale of 0.5. Apply changes in testing before production.","D":"Enable VPC Flow Logs on the testing and production VPC network frontend and backend subnets with a volume scale of 1.0. Apply changes in testing before production."},"url":"https://www.examtopics.com/discussions/google/view/64619-exam-professional-cloud-devops-engineer-topic-1-question-52/","discussion":[{"poster":"NXD","comment_id":"470902","timestamp":"1651345140.0","content":"B\n\nhttps://cloud.google.com/vpc/docs/flow-logs#log-sampling","upvote_count":"16"},{"upvote_count":"9","comment_id":"776019","content":"Selected Answer: B\nB. Enable VPC Flow Logs on the production VPC network frontend and backend subnets only with a sample volume scale of 1.0.\n\nVPC flow logs are a feature that allows you to capture network traffic data in your VPC network. To ensure that all network traffic is captured for analysis, you should enable VPC flow logs on the production VPC network frontend and backend subnets with a sample volume scale of 1.0. This will capture all network traffic data, including the potentially malicious process, for further analysis.\nOption A. Enable VPC Flow Logs on the production VPC network frontend and backend subnets only with a sample volume scale of 0.5 is not adequate, as it captures only half of the network traffic, there is a chance that the logs of the malicious process are not captured.\nOption C and D, Enable VPC Flow Logs on the testing and production VPC network frontend and backend subnets with a volume scale of 0.5/1.0. Apply changes in testing before production, is not necessary, it's important to have the logs in production environment to detect and mitigate the problem.","timestamp":"1689369900.0","poster":"JonathanSJ"},{"comment_id":"1086095","upvote_count":"1","content":"Selected Answer: B\nOption B","poster":"jomonkp","timestamp":"1717319280.0"},{"upvote_count":"1","comment_id":"1070366","content":"Selected Answer: B\nB: enabling VPC Flow Logs on the production VPC network frontend and backend subnets only with a sample volume scale of 1.0. This means that all traffic will be logged, ensuring that all network traffic is captured for analysis.","timestamp":"1715682840.0","poster":"maxdanny"},{"upvote_count":"1","comment_id":"865912","timestamp":"1696899180.0","poster":"anshad666","content":"Selected Answer: D\nApp Engine grants the Error Reporting Writer role by default. The Error Reporting library for Python can be used without needing to explicitly provide credentials. Error Reporting is automatically enabled for App Engine flexible environment applications. No additional setup is required"},{"poster":"hello_aws","content":"Selected Answer: D\nin real project background, first we should keep the consistency of configuration between test env and prod env. second, we should apply changes in testing before production.","comment_id":"804243","comments":[{"content":"That is true, but the statement says the problem is only in the production frontend servers, maybe you are not going to find the malicious process in the testing frontend servers","timestamp":"1718902800.0","poster":"Feliphus","upvote_count":"1","comment_id":"1101863"}],"upvote_count":"1","timestamp":"1691659620.0"},{"comment_id":"736145","poster":"WhyIronMan","upvote_count":"3","timestamp":"1685978340.0","content":"Selected Answer: B\nquestion saying test envs can be eliminated"},{"comment_id":"674721","content":"Selected Answer: B\nCorrect answer is B","poster":"ramzez4815","timestamp":"1679373000.0","upvote_count":"2"},{"comment_id":"599140","poster":"Ananda","content":"Selected Answer: B\nSubmitted B","upvote_count":"2","timestamp":"1668016920.0"},{"timestamp":"1662702840.0","upvote_count":"1","poster":"ric79","comment_id":"563839","content":"B is better that A because you are filtering 1:20 instead of 1:10 and the malicious process generates very low traffic"},{"upvote_count":"1","poster":"Sekierer","comment_id":"528182","timestamp":"1658290860.0","content":"Selected Answer: B\nAns: B"},{"poster":"Suraj2611","comments":[{"timestamp":"1722080700.0","upvote_count":"1","content":"Most people rated D, sure that is better, but it will require re-deployment other than just changing the instance type. If a company doesn't have the capacity or resources to setup D, B is the quickly way to improve SLI. At the end of the day customer first, then you focus on how to do D or move things to serverless like Cloud Run","poster":"4246cd7","comment_id":"1133389"}],"upvote_count":"6","comment_id":"469163","timestamp":"1651139220.0","content":"The Answer for this is B"},{"content":"i think Answer: D","upvote_count":"2","comments":[{"content":"Question clearly says only in Production they suspect, so we can eliminate the C and D options.","timestamp":"1653261300.0","poster":"muk5658","upvote_count":"3","comment_id":"484677"},{"timestamp":"1651243200.0","upvote_count":"4","poster":"giammydell","comment_id":"469808","content":"if there isnt problem in test environment why log it"}],"comment_id":"467056","poster":"Alaaelanwr","timestamp":"1650818880.0"}],"exam_id":6,"answer_images":[],"isMC":true,"answers_community":["B (90%)","10%"],"unix_timestamp":1635094080,"answer_ET":"B","question_images":[],"timestamp":"2021-10-24 18:48:00","question_id":145,"topic":"1","answer":"B","question_text":"You are running a real-time gaming application on Compute Engine that has a production and testing environment. Each environment has their own Virtual Private\nCloud (VPC) network. The application frontend and backend servers are located on different subnets in the environment's VPC. You suspect there is a malicious process communicating intermittently in your production frontend servers. You want to ensure that network traffic is captured for analysis. What should you do?","answer_description":""}],"exam":{"isMCOnly":true,"lastUpdated":"11 Apr 2025","id":6,"isBeta":false,"provider":"Google","numberOfQuestions":196,"isImplemented":true,"name":"Professional Cloud DevOps Engineer"},"currentPage":29},"__N_SSP":true}