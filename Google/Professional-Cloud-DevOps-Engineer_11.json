{"pageProps":{"questions":[{"id":"PnhZfAHmZERed0d7zeYs","discussion":[{"comment_id":"1060215","upvote_count":"5","comments":[{"timestamp":"1703414700.0","content":"A-> You don't need a new service, you need a new version of the service. I think ans A is a wrong option\nB & D for me the correct","poster":"Feliphus","upvote_count":"1","comment_id":"1104550"}],"timestamp":"1698895800.0","poster":"activist","content":"A&E seem correct for using live production traffic. The question states \"You want to use live production traffic to test a new version of the application,\""},{"poster":"cachopo","upvote_count":"1","content":"Selected Answer: BE\nB. Deploy a new Cloud Run revision with a tag and use the --no-traffic option.\n- This allows manual testing by the QA team without exposing the new version to production traffic.\n- Tagging the revision makes it easy to access the new version directly for testing purposes.\n- The --no-traffic flag ensures no production traffic is automatically routed to the new revision.\n\nE. Deploy the new application version, and split traffic to the new version.\n- Splitting traffic lets you test the new version with a controlled percentage of live production requests.\n- This method follows best practices for gradual rollouts, limiting the risk of major failures.\n- If issues arise, you can easily revert traffic back to the previous version.","comments":[{"comment_id":"1361955","content":"Why not the other options?\n\nA. Deploy the application as a new Cloud Run service.\n- This creates a completely separate service instead of a new revision, which is unnecessary and complicates rollback and traffic management.\n\nC. Deploy a new Cloud Run revision without a tag and use the --no-traffic option.\n- Without a tag, there’s no easy way for the QA team to access the new revision.\n- This makes manual testing less convenient compared to using a tag.\n\nD. Deploy the new application version and use the --no-traffic option. Route production traffic to the revision’s URL.\n- Cloud Run only routes production traffic based on explicit traffic percentages or defaults, not directly via revision URLs.\n- This approach does not follow best practices for controlled rollouts.","timestamp":"1740577800.0","upvote_count":"1","poster":"cachopo"}],"comment_id":"1361952","timestamp":"1740577740.0"},{"poster":"kapara","comment_id":"1339096","content":"Selected Answer: BE\nI think this should be BE..\nBecause option D doesn’t provide a built-in mechanism for partial traffic splitting or rolling back easily. You’d end up routing all production traffic to the new revision’s URL without the safe test approach that traffic splitting offers. This increases the risk of disruptions if there are issues.","upvote_count":"1","timestamp":"1736586300.0"},{"upvote_count":"2","comment_id":"1265167","content":"Selected Answer: BE\nDefinitely E for prod traffic. And B for developer only end.","timestamp":"1723553580.0","poster":"6a8c7ad"},{"comment_id":"1151927","upvote_count":"1","content":"Selected Answer: BD\nB: https://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration#deploy-with-tags\n\nD: https://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration#console_1:~:text=In%20the%20form%3A-,Set%20it%20to%20the%20desired%20percentage%2C%20for%20example%2C%205.%20Note%20that%20the%20currently%20serving%20version%27s%20percentage%20is%20automatically%20reduced%20by%20that%20same%20amount.,-Click%20Save.","timestamp":"1708081500.0","poster":"alpha_canary"},{"content":"Selected Answer: BD\nLooks like just only (option B) is the most reasonable.\n\nBut after thinking harder on this question, maybe choosing (option B & D) its okey to involves deploying the new version of the application on Cloud Run by creating a new revision with a tag and using the --no-traffic option. This approach allows the isolation of the new revision from live production traffic initially. \n\nOnce the deployment is complete, extensive testing can be conducted without affecting users. Subsequently, when confident in the new version's stability, production traffic can be gradually directed to it using the Cloud Run services update-traffic command.\n\nThis combination ensures a controlled and risk-mitigated approach to deploying and testing new versions, with the ability to roll back if any issues arise during the testing phase.","comment_id":"1090781","poster":"xhilmi","timestamp":"1702012740.0","upvote_count":"3"},{"timestamp":"1701515100.0","upvote_count":"1","content":"Selected Answer: BD\nVote BD","comment_id":"1086092","poster":"nqthien041292"},{"comment_id":"1080989","content":"Selected Answer: BD\nI would go for BD\nOption E does not right as it talks about split the live traffic","upvote_count":"1","timestamp":"1701027000.0","poster":"bhunias"},{"upvote_count":"2","timestamp":"1700820300.0","content":"Selected Answer: BD\nI would go for BD","comment_id":"1079168","poster":"Andrei_Z"},{"timestamp":"1700049660.0","poster":"Angel_O","content":"Selected Answer: AE\nkeyword: You want to use live production traffic","comment_id":"1071401","upvote_count":"3"},{"content":"Selected Answer: B\nhttps://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration#tags\nB is correct which targets to utilise the cloud run tag feature without serving traffic first, the idea is once tested adequately, then migrate traffic to the tagged revision. But not sure what is another answer given it is multi-choice, none of them apart from B looks reasonable.","poster":"lelele2023","timestamp":"1698891180.0","comment_id":"1060193","upvote_count":"3"},{"poster":"ABZ10","upvote_count":"1","comment_id":"1055049","comments":[{"comments":[{"timestamp":"1698849720.0","comment_id":"1059810","content":"But idk, it says that he wants to serve live traffic to this new version..why --no-traffic?","poster":"[Removed]","comments":[],"upvote_count":"1"}],"timestamp":"1698371940.0","poster":"ABZ10","comment_id":"1055050","upvote_count":"1","content":"disregard this. I meant B\nhttps://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration"}],"content":"Selected Answer: C\nC should definitely be one of the options\nhttps://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration","timestamp":"1698371940.0"}],"exam_id":6,"question_text":"You have an application that runs on Cloud Run. You want to use live production traffic to test a new version of the application, while you let the quality assurance team perform manual testing. You want to limit the potential impact of any issues while testing the new version, and you must be able to roll back to a previous version of the application if needed. How should you deploy the new version? (Choose two.)","topic":"1","answer_ET":"BD","answer":"BD","answer_images":[],"answer_description":"","question_images":[],"unix_timestamp":1698371940,"timestamp":"2023-10-27 03:59:00","question_id":51,"url":"https://www.examtopics.com/discussions/google/view/124688-exam-professional-cloud-devops-engineer-topic-1-question-144/","isMC":true,"choices":{"D":"Deploy the new application version and use the --no-traffic option. Route production traffic to the revision’s URL.","E":"Deploy the new application version, and split traffic to the new version.","B":"Deploy a new Cloud Run revision with a tag and use the --no-traffic option.","C":"Deploy a new Cloud Run revision without a tag and use the --no-traffic option.","A":"Deploy the application as a new Cloud Run service."},"answers_community":["BD (42%)","BE (21%)","B (16%)","Other"]},{"id":"SwPlZg6TtooI44uIKkZ3","answer_description":"","timestamp":"2023-10-21 19:19:00","answer_images":[],"question_id":52,"unix_timestamp":1697908740,"answer_ET":"B","choices":{"A":"Notify the team about the lack of error budget and ensure that all their tests are successful so the launch will not further risk the error budget","B":"Notify the team that their error budget is used up. Negotiate with the team for a launch freeze or tolerate a slightly worse user experience.","D":"Look through other metrics related to the product and find SLOs with remaining error budget. Reallocate the error budgets and allow the feature launch.","C":"Escalate the situation and request additional error budget."},"answer":"B","question_images":[],"discussion":[{"poster":"alpha_canary","comments":[{"timestamp":"1723799340.0","comment_id":"1151930","upvote_count":"1","poster":"alpha_canary","content":"https://sre.google/workbook/error-budget-policy/#:~:text=If%20the%20service%20has,exceed%20the%20error%20budget."}],"upvote_count":"1","comment_id":"1151929","timestamp":"1723799280.0","content":"Selected Answer: B\nIf the service has exceeded its error budget for the preceding four-week window, we will halt all changes and releases other than P01 issues or security fixes until the service is back within its SLO.\nhttps://sre.google/workbook/error-budget-policy/#:~:text=If%20the%20service%20has,exceed%20the%20error%20budget.."},{"content":"Selected Answer: B\nChoosing (option B) aligns with Site Reliability Engineering (SRE) principles, emphasizing the importance of maintaining system reliability and availability.\n\nBy notifying the team that the error budget has been exhausted, the SRE team is proactively communicating the potential risks associated with launching the new feature during a period of heightened error rates.\n\nThe suggestion to negotiate for a launch freeze or tolerate a slightly degraded user experience demonstrates a commitment to preserving the system's reliability and ensuring that user impact is minimized.\n\nThis approach fosters a collaborative effort between the SRE team and the product team, allowing for informed decision-making that prioritizes reliability over feature deployment when necessary, adhering to the core tenets of SRE practices.","upvote_count":"1","poster":"xhilmi","comment_id":"1090783","timestamp":"1717817520.0"},{"poster":"nqthien041292","upvote_count":"1","timestamp":"1717319340.0","content":"Selected Answer: B\nVote B","comment_id":"1086097"},{"comment_id":"1062721","upvote_count":"2","timestamp":"1714891260.0","content":"Selected Answer: B\nThis is SRE-friendly approach.","poster":"mshafa"},{"timestamp":"1714609920.0","upvote_count":"3","poster":"lelele2023","content":"Selected Answer: B\nOnly B seems to make a bit sense although I don't like the idea to tolerate a worse user experience.","comment_id":"1060202"},{"upvote_count":"2","poster":"koo_kai","content":"Selected Answer: B\nNegotiate with the team for a launch freeze or tolerate a slightly worse user experience.","comment_id":"1056370","timestamp":"1714327440.0"},{"poster":"activist","content":"Answer C seems to be correct per Google docs:\nhttps://sre.google/workbook/error-budget-policy/","comments":[{"content":"If you look on link https://cloud.google.com/blog/products/management-tools/sre-error-budgets-and-maintenance-windowsfor silver bullets, there is an option to deploy when you have burnt the error budget. But it has to be scalated to ownerships. Then I think ans C is correct. You get extra error budget with the silver bullets. In B, you assume you can andthe Developer team negotiate a worse experience user, but it has to be negotiate to ownerships no between the developer team","poster":"Feliphus","timestamp":"1719219180.0","comment_id":"1104552","upvote_count":"1"},{"timestamp":"1714205400.0","upvote_count":"4","poster":"Jason_Cloud_at","comment_id":"1055229","content":"The link you have shared also tells about pausing the workload and nowhere says ask for error budget. I will go with B"}],"timestamp":"1713719940.0","comment_id":"1049695","upvote_count":"2"}],"url":"https://www.examtopics.com/discussions/google/view/124244-exam-professional-cloud-devops-engineer-topic-1-question-145/","isMC":true,"question_text":"You recently noticed that one of your services has exceeded the error budget for the current rolling window period. Your company's product team is about to launch a new feature. You want to follow Site Reliability Engineering (SRE) practices. What should you do?","answers_community":["B (100%)"],"topic":"1","exam_id":6},{"id":"aSpmNIwhl0WXSBsxdzvd","answer":"CD","answer_description":"","unix_timestamp":1697908980,"exam_id":6,"question_id":53,"answers_community":["CD (100%)"],"url":"https://www.examtopics.com/discussions/google/view/124245-exam-professional-cloud-devops-engineer-topic-1-question-146/","discussion":[{"upvote_count":"1","content":"Selected Answer: CD\nC. Encourage your senior leadership to acknowledge and participate in postmortems: This option is correct because when senior leadership acknowledges and participates in postmortems, it shows that they value the process and are committed to learning from mistakes. This can help in creating a culture where postmortems are well received and taken seriously by the organization.\n\nD. Ensure that writing effective postmortems is a rewarded and celebrated practice: This option is also correct because when effective postmortems are rewarded and celebrated, it creates a positive incentive for employees to invest time and effort in conducting thorough postmortems. It helps in reinforcing the importance of the process and encourages others to follow suit.","poster":"Dharini1","comment_id":"1206367","timestamp":"1730710200.0"},{"poster":"alpha_canary","content":"Selected Answer: CD\nhttps://sre.google/sre-book/postmortem-culture/#:~:text=Make%20sure%20that,value%20of%20postmortems!","comment_id":"1151939","timestamp":"1723800180.0","upvote_count":"2"},{"comment_id":"1090797","timestamp":"1717819260.0","upvote_count":"1","content":"Selected Answer: CD\nChoosing options C and D is a strategic approach to introducing and fostering a positive postmortem culture within an organization.\n\n- In option C, encouraging senior leadership to acknowledge and participate in postmortems sets a precedent for the importance of the process throughout the organization. It signals that the postmortem process is not solely about assigning blame but is a collaborative effort to learn and improve.\n\n- In option D, rewarding and celebrating the practice of writing effective postmortems further reinforces a positive culture around the process. Recognition for those who contribute to the postmortem process encourages transparency, learning, and continuous improvement, fostering an environment where individuals feel empowered to share insights and experiences without fear of punitive measures.","poster":"xhilmi"},{"upvote_count":"1","poster":"nqthien041292","content":"Selected Answer: CD\nVote CD","timestamp":"1717319520.0","comment_id":"1086100"},{"comments":[{"timestamp":"1715735880.0","content":"I think is CD \nhttps://sre.google/sre-book/postmortem-culture/","upvote_count":"1","comment_id":"1071036","poster":"TereRolon"}],"timestamp":"1714890660.0","poster":"mshafa","content":"Selected Answer: CD\nShould be C & D.","upvote_count":"2","comment_id":"1062718"},{"content":"C & D are the answer.\nhttps://cloud.google.com/blog/products/devops-sre/how-lowes-improved-incident-response-processes-with-sre","comment_id":"1056195","poster":"khoukha","timestamp":"1714307940.0","upvote_count":"3"},{"comment_id":"1049699","poster":"activist","upvote_count":"2","content":"Answers C, D seem correct.\nhttps://sre.google/sre-book/postmortem-culture/","timestamp":"1713720180.0"}],"isMC":true,"timestamp":"2023-10-21 19:23:00","question_images":[],"answer_ET":"CD","question_text":"You need to introduce postmortems into your organization. You want to ensure that the postmortem process is well received. What should you do? (Choose two.)","topic":"1","choices":{"D":"Ensure that writing effective postmortems is a rewarded and celebrated practice.","C":"Encourage your senior leadership to acknowledge and participate in postmortems.","E":"Provide your organization with a forum to critique previous postmortems.","A":"Encourage new employees to conduct postmortems to team through practice.","B":"Create a designated team that is responsible for conducting all postmortems."},"answer_images":[]},{"id":"a5m0owsPYP3GGHHIkFpg","question_id":54,"url":"https://www.examtopics.com/discussions/google/view/124246-exam-professional-cloud-devops-engineer-topic-1-question-147/","answer_description":"","answer_ET":"C","discussion":[{"content":"Selected Answer: C\nChoosing option C\n\nConfiguring Anthos Config Management with the GitHub repository, is the recommended approach for enforcing constraint templates across Google Kubernetes Engine (GKE) clusters.\n\nAnthos Config Management allows you to declaratively manage configurations using Kubernetes-style manifests, making it well-suited for policy enforcement in a Kubernetes environment. By configuring Anthos Config Management with the GitHub repository, any changes made to the policy parameters, stored in the repository, can be automatically applied to the GKE clusters.\n\nThis ensures consistency and compliance across clusters and streamlines the process of managing and enforcing policy changes in a Kubernetes environment. The integration with GitHub provides version control and auditability for the changes made to the policy parameters.","poster":"xhilmi","upvote_count":"1","timestamp":"1733638560.0","comment_id":"1090805"},{"poster":"nqthien041292","timestamp":"1733138340.0","comment_id":"1086110","upvote_count":"1","content":"Selected Answer: C\nVote C"},{"poster":"mshafa","comment_id":"1062717","timestamp":"1730795400.0","content":"Selected Answer: C\nAnthos for consistently enforce security and compliance policies across your fleet.","upvote_count":"1"},{"timestamp":"1730515140.0","poster":"lelele2023","upvote_count":"2","content":"Selected Answer: C\nC is the answe: using policy-controller to govern the policies.\nhttps://cloud.google.com/anthos-config-management/docs/concepts/policy-controller","comment_id":"1060203"},{"poster":"activist","content":"Answer C seems to be correct.\nhttps://medium.com/@kasiarun/introduction-to-anthos-config-management-1a43917c26ae","upvote_count":"2","timestamp":"1729531680.0","comment_id":"1049701"}],"answer_images":[],"topic":"1","exam_id":6,"unix_timestamp":1697909280,"isMC":true,"timestamp":"2023-10-21 19:28:00","question_text":"You need to enforce several constraint templates across your Google Kubernetes Engine (GKE) clusters. The constraints include policy parameters, such as restricting the Kubernetes API. You must ensure that the policy parameters are stored in a GitHub repository and automatically applied when changes occur. What should you do?","choices":{"D":"Configure Config Connector with the GitHub repository. When there is a change in the repository, use Config Connector to apply the change.","A":"Set up a GitHub action to trigger Cloud Build when there is a parameter change. In Cloud Build, run a gcloud CLI command to apply the change.","C":"Configure Anthos Config Management with the GitHub repository. When there is a change in the repository, use Anthos Config Management to apply the change.","B":"When there is a change in GitHub. use a web hook to send a request to Anthos Service Mesh, and apply the change."},"answers_community":["C (100%)"],"answer":"C","question_images":[]},{"id":"HtAx3XbDC2E6t8lv44FJ","answer_description":"","timestamp":"2023-10-22 21:12:00","answer_images":[],"question_id":55,"unix_timestamp":1698001920,"answer_ET":"A","choices":{"B":"1. Communicate your intent to the incident team.\n2. Add a new node to the pool, and wait for the new node to report as healthy.\n3. When traffic is being served on the new node, drain traffic from the unhealthy node, and remove the old node from service.","C":"1. Drain traffic from the unhealthy node and remove the node from service.\n2. Monitor traffic to ensure that the error is resolved and that the other nodes in the pool are handling the traffic appropriately.\n3. Scale the pool as necessary to handle the new load.\n4. Communicate your actions to the incident team.","A":"1. Communicate your intent to the incident team.\n2. Perform a load analysis to determine if the remaining nodes can handle the increase in traffic offloaded from the removed node, and scale appropriately.\n3. When any new nodes report healthy, drain traffic from the unhealthy node, and remove the unhealthy node from service.","D":"1. Drain traffic from the unhealthy node and remove the old node from service.\n2. Add a new node to the pool, wait for the new node to report as healthy, and then serve traffic to the new node.\n3. Monitor traffic to ensure that the pool is healthy and is handling traffic appropriately.\n4. Communicate your actions to the incident team."},"answer":"A","question_images":[],"discussion":[{"content":"Answer A seems to be correct.","timestamp":"1713813120.0","poster":"activist","upvote_count":"6","comment_id":"1050993"},{"upvote_count":"1","content":"C Ref: https://sre.google/sre-book/effective-troubleshooting/","comment_id":"1143818","timestamp":"1723057320.0","poster":"heftjustice"},{"comment_id":"1090815","timestamp":"1717820820.0","upvote_count":"1","poster":"xhilmi","content":"Selected Answer: A\nChoosing option A.\n\nFirst, communicating your intent to the incident team ensures transparency and collaboration. Performing a load analysis is crucial to determine if the remaining nodes can handle the increased traffic after offloading from the unhealthy node. Scaling appropriately is essential to maintain the overall capacity. Once new nodes report as healthy, draining traffic from the unhealthy node ensures a gradual transition without disrupting user experience. Removing the unhealthy node from service comes after ensuring that the other nodes can handle the load effectively.\n\nThis step-by-step approach, coupled with communication and load analysis, aligns with Google-recommended practices for incident response and minimizes the impact on users during the investigation and resolution process."},{"upvote_count":"2","poster":"nqthien041292","timestamp":"1717320120.0","content":"Selected Answer: A\nVote A","comment_id":"1086116"},{"comments":[{"poster":"pharao89","upvote_count":"3","comment_id":"1071891","content":"The second point in answer A is about scaling. A is correct. You can easily eliminate C and D because information to the incident team should be the first thing to do.\n\"2. Perform a load analysis to determine if the remaining nodes can handle the increase in traffic offloaded from the removed node, and scale appropriately.\"","timestamp":"1715800200.0"}],"upvote_count":"2","content":"Selected Answer: D\nOption A and option B do not add a new node to the pool to handle the increased load, which may leave the remaining nodes overburdened and unable to handle the traffic adequately.\n\nOption C starts with draining traffic from the unhealthy node, which is a good step, but it doesn't immediately add a new node to the pool to handle the load. It also lacks the step of explicitly communicating the actions to the incident team.","poster":"mshafa","timestamp":"1715456100.0","comment_id":"1068143"},{"poster":"lelele2023","comment_id":"1060205","timestamp":"1714610640.0","content":"Selected Answer: A\nThe service usually run 70% of the capacity, hence even one node is out of order you'd always want to see if the rest of the computing resource are enough to support the stress before arbitrarily adding any new nodes.","upvote_count":"4"}],"question_text":"You are the Operations Lead for an ongoing incident with one of your services. The service usually runs at around 70% capacity. You notice that one node is returning 5xx errors for all requests. There has also been a noticeable increase in support cases from customers. You need to remove the offending node from the load balancer pool so that you can isolate and investigate the node. You want to follow Google-recommended practices to manage the incident and reduce the impact on users. What should you do?","isMC":true,"url":"https://www.examtopics.com/discussions/google/view/124377-exam-professional-cloud-devops-engineer-topic-1-question-148/","answers_community":["A (78%)","D (22%)"],"topic":"1","exam_id":6}],"exam":{"isBeta":false,"isMCOnly":true,"name":"Professional Cloud DevOps Engineer","provider":"Google","lastUpdated":"11 Apr 2025","isImplemented":true,"numberOfQuestions":196,"id":6},"currentPage":11},"__N_SSP":true}