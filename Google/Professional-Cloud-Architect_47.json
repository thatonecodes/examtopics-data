{"pageProps":{"questions":[{"id":"jOcEimYl5YRurAX9GGvv","timestamp":"2021-12-28 08:14:00","answer":"A","answers_community":[],"answer_ET":"A","answer_description":"Reference:\nhttps://cloud.google.com/load-balancing/docs/https","isMC":false,"unix_timestamp":1640675640,"exam_id":4,"question_id":231,"discussion":[{"content":"Got this question in my exam, answered D","upvote_count":"45","comment_id":"527736","timestamp":"1642610040.0","poster":"technodev"},{"comment_id":"582306","content":"Is D:\nIn the GCP doc can see the same example\nhttps://cloud.google.com/armor/docs/configure-security-policies#gcloud_11\n\"gcloud compute security-policies rules create 1000 \\\n --security-policy my-policy \\\n --expression \"evaluatePreconfiguredExpr('sourceiplist-fastly')\" \\\n --action \"allow\"\n\"","comments":[{"timestamp":"1701447300.0","content":"I can not see the same example in that document and I saw \"evaluatePreconfiguredExpr\" is for preconfigure WAF rules https://cloud.google.com/armor/docs/rule-tuning","poster":"6b13108","upvote_count":"1","comment_id":"1085340"}],"poster":"elrizos","upvote_count":"32","timestamp":"1649319900.0"},{"timestamp":"1740424020.0","content":"Suggested Answer A is incorrect, answer is D. AWS firewalls can be used to restrict both internal and external traffic. GCP firewall rules are werid where VPC level firewall rules are for restricting internal traffic & cloud armor which gets attached to LB's is used to restrict external traffic. So due to GCP oddity: 'gcloud compute firewall' refers to internal VPC firewall config which isn't relevant, while 'gcloud compute security-policies' refers to Cloud Armor, which gets attached to LBs and is used to configure external firewall rules, which is relevant. Once you understand that D as the answer starts to make intuitive sense.","comments":[{"content":"Actually I'm unsure between A and D, my answer mainly explains why B & C can be eliminated.","timestamp":"1740424260.0","upvote_count":"1","poster":"neokyle","comment_id":"1361152"}],"comment_id":"1361149","poster":"neokyle","upvote_count":"2"},{"poster":"dfizban","timestamp":"1729098600.0","upvote_count":"1","comment_id":"1298828","content":"It's D"},{"upvote_count":"1","content":"The correct answer is D. The syntax for command must include --Security-policy, --expression or --src-in-ranges ( for option A IP range is wild card) hence correct answer is D.","timestamp":"1727244300.0","poster":"Begum","comment_id":"1288900"},{"content":"The most appropriate command for allowing traffic from all Fastly IP address ranges into the HRL Virtual Private Cloud (VPC) network through the External HTTP(S) load balancer would be:\n\nA. Create Cloud Armor Security Policy with the source IP ranges.\nExplanation:\nCloud Armor is the tool designed specifically for protecting HTTP(S) load balancers and controlling access based on IP address ranges. It allows you to create security policies to allow or deny traffic from specific IP ranges, which is what you need to do for Fastly IPs.\nThis approach is specifically designed for managing traffic to HTTP(S) load balancers, providing an additional layer of security that fits this scenario perfectly.","comment_id":"1288895","upvote_count":"2","poster":"JohnJamesB1212","timestamp":"1727243100.0","comments":[{"poster":"JohnJamesB1212","upvote_count":"2","content":"Why Not the Other Options?\nB. Create Cloud Armor Security Policy with the source IP list: Cloud Armor requires IP ranges, not a simple list of IPs.\n\nC. Create firewall rule to allow source IP list: Firewall rules operate at the VPC network level, and while they control network access, they are not specifically tied to HTTP(S) load balancers and would not efficiently apply to this context.\n\nD. Create firewall rule to allow source IP range: Firewall rules can allow traffic from IP ranges, but again, they are applied at the VPC level. For HTTP(S) load balancer traffic, Cloud Armor is the correct tool to manage IP range access control.","timestamp":"1727243100.0","comment_id":"1288896"}]},{"upvote_count":"3","timestamp":"1714327320.0","content":"(D), or \"Create Cloud Armor Security Policy with the source ip list\" (considering @hashi's comment) looks correct.\nhttps://codelabs.developers.google.com/codelabs/cloud-cloudarmor#0","comment_id":"1203672","poster":"researched_answer_boi"},{"poster":"dija123","upvote_count":"1","timestamp":"1713764280.0","content":"Totally agree with D","comment_id":"1199983"},{"content":"I got this question in March 2024. \nAs someone pointed out answers are reworked. \nInstead of asking for the command, the choices were given in wordings - something like the below. (Not the exact words)\nA. Create Cloud Armor Security Policy with the source ip ranges.\nB. Create Cloud Armor Security Policy with the source ip list\nC. Create firewall rule to allow source ip list\nD. Create firewall rule to allow source ip range\n\nBased on the answers for this question I went with \"Create Cloud Armor Security Policy with the source ip list\"","upvote_count":"15","comments":[{"poster":"exam4c3","upvote_count":"1","timestamp":"1737806340.0","content":"Fw rules are managed by VPC, not by cloud armor","comment_id":"1346429"},{"upvote_count":"1","poster":"Chandankm","comment_id":"1235801","comments":[{"upvote_count":"1","poster":"Chandankm","timestamp":"1719643920.0","comment_id":"1239083","content":"If the question really makes a distinction between ranges and lists as specified above, I'm quite disappointed with Google. It looks like they're more interested in throwing the examinee off-balance by confusing them with useless jargon rather than evaluating the actual skills."}],"content":"what's the difference between options A & B, i.e. source IP \"ranges\" and \"list\" ? what's the reason for choosing one over another ? I've been through the documentation and these terms are used intermittently.","timestamp":"1719142800.0"},{"timestamp":"1718034540.0","upvote_count":"2","poster":"ccpmad","comment_id":"1227964","content":"Thank you for the info, but for me, in your question, I would choose D. Firewall rule. Firewalls are designed to efficiently manage network traffic. Allowing IP ranges simplifies administration and enhances performance by handling access from multiple IP addresses effectively."}],"poster":"hashi","comment_id":"1177878","timestamp":"1710900660.0"},{"upvote_count":"1","content":"D is right","poster":"VidhyaBupesh","comment_id":"1155428","timestamp":"1708510440.0"},{"poster":"d0094d6","comment_id":"1138624","timestamp":"1706883780.0","upvote_count":"1","content":"should be D"},{"content":"D is the solution","poster":"Pime13","timestamp":"1706544780.0","comment_id":"1135098","upvote_count":"1"},{"comment_id":"1127212","upvote_count":"1","content":"D d d d","poster":"didek1986","timestamp":"1705748040.0"},{"comment_id":"1118132","content":"D is the ans","poster":"gun123","upvote_count":"1","timestamp":"1704858840.0"},{"timestamp":"1702342500.0","upvote_count":"1","poster":"MahAli","comment_id":"1093966","content":"I guess D"},{"upvote_count":"2","poster":"odacir","content":"D -> https://cloud.google.com/armor/docs/configure-security-policies#create-rules","timestamp":"1700395560.0","comment_id":"1074603"},{"comment_id":"1013832","poster":"didek1986","upvote_count":"2","timestamp":"1695371100.0","content":"D for sure"},{"comment_id":"926007","content":"A. Looks like it opens to all IPs\n\nB. Incorrect syntax \"ACTION must be one of: allow, deny, goto_next.\"\n\nC. Incorrect syntax \"ACTION must be one of: allow, deny, goto_next.\"\n\nD. Assuming the preconfigured expression is good then its right.","poster":"BiddlyBdoyng","upvote_count":"2","timestamp":"1687010280.0"},{"comment_id":"911048","poster":"LaxmanTiwari","timestamp":"1685525880.0","upvote_count":"1","content":"answer is D"},{"comment_id":"838299","timestamp":"1678741380.0","content":"D, def not A\n\nD is shown at https://cloud.google.com/armor/docs/configure-security-policies#use-console-gcloud","poster":"rr4444","upvote_count":"2"},{"content":"Why is no vote being allowed on this question?","upvote_count":"5","timestamp":"1678733820.0","comment_id":"838192","poster":"BeCalm"},{"comment_id":"833188","timestamp":"1678295040.0","poster":"romandrigo","content":"Answer is D","upvote_count":"1"},{"upvote_count":"8","content":"Answers is D \nI found the following useful\nhttps://cloud.google.com/armor/docs/integrating-cloud-armor#https-vpc-firewall-rules","comment_id":"759606","timestamp":"1672217820.0","poster":"csestony","comments":[{"poster":"csestony","upvote_count":"5","comment_id":"759608","timestamp":"1672217820.0","content":"\"Google Cloud Armor security policies and VPC firewall rules have different functions:\n\nGoogle Cloud Armor security policies provide edge security and act on client traffic to Google Front Ends (GFEs).\nVPC firewall rules allow or deny traffic to and from your backends. You must create ingress allow firewall rules, whose targets are the load-balanced backend VMs, and whose sources are IP ranges used by global external HTTP(S) load balancers or global external HTTP(S) load balancer (classic)s. These rules allow GFEs and the health check systems to communicate with your backend VMs.\""}]},{"upvote_count":"4","timestamp":"1672212660.0","comments":[{"comments":[{"upvote_count":"2","content":"HTTP(S) Load Balancer (HLB) is a load balancing service that distributes incoming traffic among the healthy instances of your application. It routes traffic based on the IP address and port of the incoming request, and it can handle both HTTP and HTTPS traffic. In this scenario, the HLB would be used to distribute traffic among the instances in the VPC network that are serving the content for the HRL races.\n\nCloud Armor is a network security service that provides protection against DDoS attacks and other threats. It allows you to create security policies that define rules for traffic coming to your resources, such as HLBs. In this scenario, Cloud Armor would be used to enforce the security policy \"hlr-policy\" and allow traffic from the Fastly IP address ranges through the HLB.","timestamp":"1672212720.0","poster":"omermahgoub","comment_id":"759500"}],"upvote_count":"3","poster":"omermahgoub","timestamp":"1672212720.0","comment_id":"759499","content":"The command gcloud compute security-policies rules update 1000 --security-policy=hlr-policy --expression=\"evaluatePreconfigurationExpr(`sourceiplist-fastly`)\" --action=allow updates a security policy rule with the name \"1000\" in the security policy \"hlr-policy\". The rule allows traffic that matches the specified expression and has the action \"allow\".\n\nIn this particular case, the expression used in the rule is \"evaluatePreconfigurationExpr(sourceiplist-fastly)\". The \"evaluatePreconfigurationExpr\" function is used to reference a preconfigured expression, in this case, the tag \"sourceiplist-fastly\". This means that the rule will allow traffic from any instances that have the \"sourceiplist-fastly\" tag."}],"comment_id":"759498","poster":"omermahgoub","content":"Option A, gcloud compute security-policies rules update 1000 --security-policy=from-fastly --src-ip-ranges=* --action=allow, would allow all source IP ranges and is not specific to the Fastly IP address ranges.\n\nOption B, gcloud compute firewall-rules update sourceiplist-fastly --priority=1000 --allow=tcp:443, allows traffic over TCP port 443 (HTTPS) but does not specify any target tags or source IP ranges.\n\nC. `gcloud compute firewall-rules update hlr-policy --priority=1000 --target-tags=sourceiplist-fastly --allow=tcp:443. This command updates a firewall rule with the name \"hlr-policy\" to allow traffic over TCP port 443 (HTTPS) from any instances with the tag \"sourceiplist-fastly\". The priority of the rule is set to 1000, which means that it will be evaluated before any other rules with lower priority."},{"poster":"surajkrishnamurthy","content":"D is the correct answer","upvote_count":"1","timestamp":"1671200160.0","comment_id":"747275"},{"upvote_count":"1","poster":"jaxclain","comment_id":"737402","content":"D for sure","timestamp":"1670385240.0"},{"timestamp":"1666282440.0","content":"D for sure","upvote_count":"1","poster":"Mahmoud_E","comment_id":"700110"},{"content":"The answer is D, for 2 reasons:\n1. They want to apply a firewall rule at HTTPS LB level. This can be done only with cloud armor. Cloud armor does not work with classic firewall; it works with security policies.\n2. D is the only answer that points to a list of IPs to whitelist, via preconfigured expression. The others will open to too broad IPs.","comment_id":"663856","timestamp":"1662658560.0","poster":"bossdellacert","upvote_count":"7"},{"content":"answer is D","upvote_count":"1","timestamp":"1662554880.0","comment_id":"662483","poster":"Nirca"},{"poster":"aut0pil0t","timestamp":"1662200340.0","comment_id":"658326","upvote_count":"3","content":"D. This is a Cloud Armour question, and interestingly \"sourceiplist-fastly\" is actually one of the GCP's preconfigured expressions.\n\n(project)$ gcloud compute security-policies list-preconfigured-expression-sets | grep fastly\nEXPRESSION_SET: sourceiplist-fastly\n\nhttps://cloud.google.com/armor/docs/configure-security-policies#list-preconfig-rules"},{"comment_id":"652614","content":"Agree D","timestamp":"1661614440.0","upvote_count":"1","poster":"Crick76"},{"upvote_count":"1","poster":"chinmay7682","comment_id":"649826","timestamp":"1661100480.0","content":"Answer is D"},{"timestamp":"1658397360.0","content":"D D D D","poster":"Nirca","comment_id":"634513","upvote_count":"3"},{"timestamp":"1656990240.0","upvote_count":"3","poster":"AzureDP900","content":"After reading discussions I am convinced with D.","comment_id":"627222"},{"poster":"Zonci","upvote_count":"3","timestamp":"1655816520.0","comment_id":"619817","content":"D is my answer"},{"poster":"Venket","upvote_count":"9","content":"The following command adds a rule that uses a preconfigured expression to allow access from all IP addresses on a named IP address list:\n\n\ngcloud compute security-policies rules create 1000 \\\n --security-policy my-policy \\\n --expression \"evaluatePreconfiguredExpr('sourceiplist-fastly')\" \\\n --action \"allow\"\n\nSo Answer is D","timestamp":"1651480140.0","comment_id":"595954"},{"poster":"marpayer","comment_id":"561968","upvote_count":"4","content":"One question about C, is it possible tag external IP addresses?","timestamp":"1646566500.0"},{"comment_id":"555373","content":"It's D:\nhttps://cloud.google.com/armor/docs/configure-security-policies#creating-policy-rules","upvote_count":"4","timestamp":"1645719720.0","poster":"mesodan"},{"content":"Why not A?","timestamp":"1643741880.0","upvote_count":"1","comment_id":"538150","poster":"Tan1234"},{"comment_id":"533077","upvote_count":"1","comments":[{"timestamp":"1660814700.0","upvote_count":"1","content":"because we all know fw rules apply to external LBs","comment_id":"648367","poster":"coco10k"}],"poster":"kkhurana","content":"both C and D are correct","timestamp":"1643215920.0"},{"poster":"[Removed]","upvote_count":"3","timestamp":"1642550700.0","comment_id":"527084","content":"Agree with D."},{"timestamp":"1641473280.0","comment_id":"518225","upvote_count":"2","content":"D is correct\nCreate Google Cloud Armor security policies to filter incoming traffic that is destined to external HTTP(S) load balancers\n\nhttps://cloud.google.com/armor/docs/configure-security-policies","poster":"timotei"},{"upvote_count":"2","poster":"victory108","content":"D is correct","comment_id":"514368","timestamp":"1641013260.0"},{"comments":[{"content":"Could it be because these firewall rules are for TCP and not HTTP(S)?","comments":[],"upvote_count":"1","comment_id":"520307","poster":"wisss","timestamp":"1641743700.0"},{"poster":"AMohanty","content":"In the firewall Rule Incoming IP Addresses isn't specified.\nTags can be used with only GCP Resources and NOT External Resources.","upvote_count":"1","comment_id":"643890","timestamp":"1659919620.0"}],"poster":"SanLi","content":"Why not firewall rules update? It is basic one to allow the traffic in the first place, right?","upvote_count":"3","timestamp":"1640843220.0","comment_id":"513012"},{"content":"Answer is D","upvote_count":"1","poster":"simbu1299","timestamp":"1640769600.0","comment_id":"512002"},{"content":"C is correct answer","timestamp":"1640716320.0","upvote_count":"2","poster":"reshuuuuu","comment_id":"511471"},{"comment_id":"511232","poster":"Pime13","content":"o me it's D -> https://cloud.google.com/armor/docs/configure-security-policies#update-rules","upvote_count":"2","timestamp":"1640704080.0"},{"upvote_count":"2","timestamp":"1640691120.0","poster":"daniva","content":"A would allow all source IP’s, IMHO the answer must be D","comment_id":"511036"},{"timestamp":"1640675640.0","poster":"StelSen","comment_id":"510873","upvote_count":"4","content":"Answer: D https://cloud.google.com/armor/docs/armor-named-ip"}],"url":"https://www.examtopics.com/discussions/google/view/68709-exam-professional-cloud-architect-topic-3-question-2/","answer_images":[],"question_images":["https://www.examtopics.com/assets/media/exam-media/04339/0006100001.png","https://www.examtopics.com/assets/media/exam-media/04339/0006100002.png","https://www.examtopics.com/assets/media/exam-media/04339/0006100003.png","https://www.examtopics.com/assets/media/exam-media/04339/0006100004.png"],"question_text":"For this question, refer to the Helicopter Racing League (HRL) case study. Recently HRL started a new regional racing league in Cape Town, South Africa. In an effort to give customers in Cape Town a better user experience, HRL has partnered with the Content Delivery Network provider, Fastly. HRL needs to allow traffic coming from all of the Fastly IP address ranges into their Virtual Private Cloud network (VPC network). You are a member of the HRL security team and you need to configure the update that will allow only the Fastly IP address ranges through the External HTTP(S) load balancer. Which command should you use?\nA.\n//IMG//\n\nB.\n//IMG//\n\nC.\n//IMG//\n\nD.\n//IMG//","topic":"3"},{"id":"qETD90FqZmrBTvhr3sMp","question_text":"For this question, refer to the Helicopter Racing League (HRL) case study. The HRL development team releases a new version of their predictive capability application every Tuesday evening at 3 a.m. UTC to a repository. The security team at HRL has developed an in-house penetration test Cloud Function called\nAirwolf. The security team wants to run Airwolf against the predictive capability application as soon as it is released every Tuesday. You need to set up Airwolf to run at the recurring weekly cadence. What should you do?","answer_ET":"C","timestamp":"2021-07-02 10:10:00","question_id":232,"choices":{"C":"Configure the deployment job to notify a Pub/Sub queue that triggers a Cloud Function.","A":"Set up Cloud Tasks and a Cloud Storage bucket that triggers a Cloud Function.","B":"Set up a Cloud Logging sink and a Cloud Storage bucket that triggers a Cloud Function.","D":"Set up Identity and Access Management (IAM) and Confidential Computing to trigger a Cloud Function."},"unix_timestamp":1625213400,"url":"https://www.examtopics.com/discussions/google/view/56890-exam-professional-cloud-architect-topic-3-question-3/","answer":"C","answer_images":[],"exam_id":4,"question_images":[],"answer_description":"","topic":"3","discussion":[{"content":"Answer C seems to be ok. Triggering Pub/Sub to invoke Cloud Functions seems to be relevant. Cloud Storage doesn't make any sense. It would have been straight forward if Cloud Scheduler is mentioned in Option C instead of Deployment Job. But if you make a bit of research on deployment jobs, it's pointing me to cron jobs which is making perfect sense.\nhttps://cloud.google.com/appengine/docs/flexible/nodejs/scheduling-jobs-with-cron-yaml\nhttps://cloud.google.com/scheduler/docs/tut-pub-sub","poster":"umashankar_a","comments":[{"upvote_count":"6","timestamp":"1671288660.0","poster":"elainexs","comment_id":"617715","content":"Cannot understand why push CICD event to pub/sub... which is only one event, why need pub/sub"},{"timestamp":"1650813120.0","upvote_count":"5","content":"But the question requires a scheduled execution, not one triggered by the deployment job. Shouldn’t A be the correct answer?","comment_id":"467015","poster":"stefanop","comments":[{"poster":"Nimbus2021","timestamp":"1654168380.0","upvote_count":"3","content":"I think no because question mentions \"as soon as it is released every Tuesday.\"","comment_id":"492523"},{"timestamp":"1730452800.0","poster":"Gino17m","upvote_count":"2","comment_id":"1204916","content":"Teh question requires recurring not scheduled execution"}]}],"timestamp":"1641439080.0","comment_id":"399577","upvote_count":"58"},{"comment_id":"401784","upvote_count":"18","comments":[{"content":"Please elaborate.","poster":"nandoD","upvote_count":"3","comment_id":"873798","timestamp":"1697643060.0"}],"poster":"MamthaSJ","timestamp":"1641645240.0","content":"Answer is A"},{"comment_id":"1194247","upvote_count":"1","content":"Selected Answer: C\nTotally agree with C","timestamp":"1728719460.0","poster":"dija123"},{"poster":"mouthwash","timestamp":"1717785060.0","upvote_count":"7","comment_id":"1090586","content":"Passed the GCP test today, answer is C\nThe key is to use google's native tools"},{"poster":"Jconnor","comment_id":"1086946","upvote_count":"1","content":"How is A even an option? What do you use cloud storage for? A good architecture is event driven, as it would be more resilient to failures, change in time, error and it is easier to debung, log and scale. That is what Pub/Sub is for.","timestamp":"1717425840.0"},{"timestamp":"1716865320.0","comment_id":"1082159","content":"Selected Answer: A\nA is simple and clean compared to the other options provided.","poster":"thewalker","upvote_count":"1","comments":[{"timestamp":"1718145060.0","content":"Where does a Cloud Storage bucket come into play here? Nothing in the question implies anything about storage. If they needed a place to store the results of the Airwolf job, then sure. But that isn't mentioned anywhere.","upvote_count":"2","poster":"MikeH20","comment_id":"1093958"}]},{"comment_id":"1050448","content":"Answer C seems to be right. There are 2 requirements here, \n1. Run every time it is released on Tuesday\n2. Set Airwolf to run weekly\nSince a new version of the predictive capability application is released every tuesday evening at 3.00 am, the deployment job would run every time its released which is every week recurring. So both the requirements above are satisfied","upvote_count":"2","poster":"Sarin","timestamp":"1713782220.0"},{"comment_id":"937288","poster":"sampon279","upvote_count":"3","content":"Selected Answer: C\nShould be C. Cannot be A, to schedule cloud task you need to know when the deployment is complete, deployments usually are unpredictable and do not meet scheduled time. With option C, CICD pipeline which deploys the code and publish a message to pub/sub to trigger cloud function - better solution to trigger via http endpoint if that is an option. pub/sub is till okay.","timestamp":"1703817840.0"},{"content":"Selected Answer: C\nTo run Airwolf against the predictive capability application as soon as it is released every Tuesday, you should configure the deployment job to notify a Pub/Sub queue that triggers a Cloud Function.","upvote_count":"2","timestamp":"1694761200.0","poster":"WinSxS","comment_id":"839713"},{"comment_id":"796691","content":"Selected Answer: A\nCloud task is supports scheduling","timestamp":"1691026440.0","poster":"zerg0","upvote_count":"1"},{"comment_id":"776985","poster":"tdotcat","timestamp":"1689441960.0","content":"Selected Answer: C\nc fits scenario","upvote_count":"1"},{"content":"Answer A seems correct since cloud tasks support scheduled delivery but pub/sub doesn't\nsee https://cloud.google.com/pubsub/docs/choosing-pubsub-or-cloud-tasks","upvote_count":"2","comments":[{"poster":"jlambdan","comment_id":"927575","content":"https://cloud.google.com/tasks/docs/comp-tasks-sched\nit seems to be scheduling of task ahead of time, not scheduling at fixed time interval.","upvote_count":"1","timestamp":"1703001480.0"}],"comment_id":"760697","poster":"main_street","timestamp":"1688014260.0"},{"comment_id":"759501","content":"To set up Airwolf to run at a recurring weekly cadence, the correct option would be C: Configure the deployment job to notify a Pub/Sub queue that triggers a Cloud Function.\n\nTo set up Airwolf to run at the desired weekly cadence, you can configure the deployment job to send a notification to a Pub/Sub queue when a new version of the predictive capability application is released. Then, you can set up a Cloud Function that is triggered by messages in the Pub/Sub queue and runs the Airwolf penetration test. This way, the Cloud Function will be triggered every time a new message is published to the queue, which will occur every Tuesday evening at 3 a.m. UTC when a new version of the application is released.","timestamp":"1687930380.0","poster":"omermahgoub","comments":[{"poster":"omermahgoub","content":"Option A, Set up Cloud Tasks and a Cloud Storage bucket that triggers a Cloud Function, would not be the correct solution because Cloud Tasks is a service for creating and managing asynchronous tasks that are executed later, but it does not support recurring schedules.\n\nOption B, Set up a Cloud Logging sink and a Cloud Storage bucket that triggers a Cloud Function, would not be the correct solution because Cloud Logging is a service for collecting, viewing, and analyzing logs, but it does not support triggering Cloud Functions on a recurring basis.\n\nOption D, Set up Identity and Access Management (IAM) and Confidential Computing to trigger a Cloud Function, would not be the correct solution because IAM is a service for managing access to Google Cloud resources and Confidential Computing is a service for running sensitive workloads in hardware-isolated environments, but neither of these services can be used to trigger Cloud Functions on a recurring basis.","timestamp":"1687930440.0","comments":[{"poster":"kat1969","timestamp":"1688431020.0","comments":[{"comment_id":"873803","content":"how I see it, the first post is the correct answer explanation, the second post is why the other 3 answers are wrong.","poster":"nandoD","upvote_count":"1","timestamp":"1697643360.0"}],"upvote_count":"1","comment_id":"765177","content":"This conflicts with your earlier statements? Is this statement intended as a correction?"}],"comment_id":"759502","upvote_count":"3"}],"upvote_count":"4"},{"upvote_count":"2","comments":[{"upvote_count":"2","comment_id":"825946","content":"That's what I taught too. \"Why do I need Cloud Storage?\"","poster":"amelm","timestamp":"1693570260.0"}],"timestamp":"1687800240.0","content":"answer A does not make sense why put a cloud task and check a storage (which is never updated) for cloud function? If the release has some late the task run for nothing.\nPub sub + cloud function is best practice","comment_id":"757779","poster":"thamaster"},{"upvote_count":"1","comment_id":"757623","content":"The correct answer is A: Set up Cloud Tasks and a Cloud Storage bucket that triggers a Cloud Function.\n\nTo set up Airwolf to run at a recurring weekly cadence, you should set up Cloud Tasks and a Cloud Storage bucket that triggers a Cloud Function.\n\nCloud Tasks is a fully managed service that allows you to schedule and execute background jobs in a scalable and reliable way. You can use Cloud Tasks to create a recurring task that runs at a specified interval (e.g., every week). When the task is triggered, it can send a message to a Cloud Storage bucket, which can then trigger a Cloud Function to run the Airwolf penetration test.\n\nOption B: Setting up a Cloud Logging sink and a Cloud Storage bucket would not allow you to schedule the task to run at a recurring weekly cadence.\n\nOption C: Configuring the deployment job to notify a Pub/Sub queue would not allow you to schedule the task to run at a recurring weekly cadence.\n\nOption D: Setting up Identity and Access Management (IAM) and Confidential Computing would not allow you to schedule the task to run at a recurring weekly cadence.","poster":"omermahgoub","timestamp":"1687787700.0"},{"timestamp":"1686919380.0","poster":"surajkrishnamurthy","comment_id":"747295","content":"Selected Answer: C\nC Is the Correct Answer","upvote_count":"1"},{"comment_id":"728345","poster":"Jackalski","content":"Selected Answer: A\nI vote on A\ncloud task can trigger CF ... with limit to 30 days - here it is weekly - so far so good\nhowever not sure why it would need any cloud storage .. potentially to store results of dony by CF\n\nanswer C - has no schedule option \n\nexample:\nhttps://cloud.google.com/tasks/docs/tutorial-gcf","upvote_count":"2","timestamp":"1685191800.0"},{"poster":"megumin","content":"Selected Answer: C\nC is ok","upvote_count":"1","comment_id":"716617","timestamp":"1683877560.0"},{"content":"Selected Answer: C\nC is ok\nNeeds to be triggered by the deployment and not on a schedule. Cloud storage doesn't seem relevant in the context of the question","timestamp":"1678555740.0","poster":"6721sora","upvote_count":"3","comments":[{"poster":"Kiroo","timestamp":"1699112580.0","upvote_count":"1","content":"Being honest, neither A or C seems entirely correct, to me the one that seems to be cheaper is C","comment_id":"889387"}],"comment_id":"666237"},{"timestamp":"1678278240.0","poster":"shekarcfc","content":"Selected Answer: C\nIMHO, the question is not clear. Is it a git or object repository. If its git repository than there need to be a logging or webhook that triggers the cloud function.. benefit of doubt goes to C.","upvote_count":"2","comment_id":"663485"},{"content":"Selected Answer: C\nC for sure","comment_id":"662488","upvote_count":"2","poster":"Nirca","timestamp":"1678200780.0"},{"poster":"kuboraam","upvote_count":"2","content":"Selected Answer: B\nA - NOK - is not reliable because Cloud Tasks could run before the repository is updated, there could be delays.\nB - OK. Tie the two events together independently. https://cloud.google.com/logging/docs/export/configure_export_v2#supported-destinations\nC - NOK - requires the dev team to make changes to support the security team. WHy would they do that? keep things independent.\nD - Nothing to do with this question.","comment_id":"662240","timestamp":"1678184940.0"},{"poster":"crg63","content":"Selected Answer: C\nC is good","upvote_count":"2","comment_id":"660429","timestamp":"1678047000.0","comments":[{"upvote_count":"1","timestamp":"1678189320.0","comment_id":"662308","content":"ok thanks, crg63 if you are about to take the exam , i see you took this question on 06 sep,","poster":"thenew_certguy"}]},{"poster":"MQQNB","content":"I would choose A\nbecause i'm not sure with deployment job in c","upvote_count":"2","comment_id":"651814","timestamp":"1677340320.0"},{"timestamp":"1676334540.0","poster":"chickennuggets","comment_id":"646453","content":"Selected Answer: C\nC - per: https://cloud.google.com/scheduler/docs/tut-pub-sub","upvote_count":"1"},{"upvote_count":"1","content":"I am inclined towards C before reading discussions and I am agreeing with all of you .. C is right","timestamp":"1672895220.0","poster":"AzureDP900","comment_id":"627223"},{"upvote_count":"1","content":"Selected Answer: C\nI'd go with C","timestamp":"1672301580.0","comment_id":"624451","poster":"RGTest"},{"timestamp":"1669110060.0","upvote_count":"4","content":"A.\nQuestion itself is misleading, \n1) every Tuesday evening at 3 a.m --- Note 3 a.m. is early morning not evening.\n2) It is not clear that deployment start or complete at 3 a.m.\n3) if we choose c., then what is significant of the time.\n\nbut exact time is given here i.e. 3 a.m. so I would prefer A - i.e. Scheduled task (i.e. low cost then C pub/sub)","comment_id":"605252","poster":"AmitAr"},{"comment_id":"591551","poster":"mad314","content":"Selected Answer: C\nHad this question on my exam.","upvote_count":"2","timestamp":"1666693080.0"},{"poster":"jpco","timestamp":"1661424900.0","comment_id":"555962","upvote_count":"1","content":"I think the correct answers is A because the question is \"You need to set up Airwolf to run at the recurring weekly cadence\" at the same date at the same hour. PUB/SUB is not the good idea"},{"timestamp":"1660207800.0","comment_id":"545248","upvote_count":"2","content":"Selected Answer: A\nQuestion mentions \"The HRL development team releases a new version of their predictive capability application every Tuesday evening at 3 a.m. UTC to a repository.\" Therefore the penetration test needs to be invoked by cloud function as soon as a new version is available in the storage. Here the penetration test is being done before the deployment.","poster":"SupraAzure","comments":[{"poster":"Mahmoud_E","timestamp":"1682008680.0","comment_id":"700125","content":"what would be the benefit of running the pen test prior to deploying the new version of code?","upvote_count":"1"}]},{"timestamp":"1658838180.0","content":"Selected Answer: C\nAnswer is C","comment_id":"532948","upvote_count":"1","poster":"charlie_spooki"},{"comments":[{"poster":"mum_lalitha0508","comment_id":"545128","timestamp":"1660195440.0","upvote_count":"5","content":"Hi i have been seeing your updates. How do you know that it is the correct answer? No where after exam we get the answer sheet to check. However in many dump questions your comment is confusing me."}],"timestamp":"1658241300.0","poster":"technodev","comment_id":"527737","upvote_count":"3","content":"Got this question in my exam, answered C"},{"content":"Selected Answer: C\nOption C Seems to be correct","poster":"GauravLahoti","timestamp":"1656947820.0","comment_id":"516858","upvote_count":"1"},{"comments":[{"upvote_count":"2","comment_id":"527706","comments":[{"comment_id":"555314","content":"yes they are","poster":"ahsangh","upvote_count":"1","timestamp":"1661346600.0"}],"content":"Agree and deliberate attempt to make it difficult. BTW are these questions really coming into real exam?","timestamp":"1658240340.0","poster":"Wonka"}],"timestamp":"1656566880.0","content":"This question is stupid.\nIn one place they say \"as soon as it is released every Tuesday\" and in another place they say \"run at the recurring weekly cadence\". Decide guys. Either a trigger or a schedule. The requirements are self-contradictory.","comment_id":"513107","poster":"spoxman","upvote_count":"2"},{"poster":"vmarquez92","timestamp":"1655912520.0","comment_id":"507273","content":"Selected Answer: C\nAnswer is C","upvote_count":"1"},{"poster":"vincy2202","timestamp":"1655778060.0","content":"Selected Answer: C\nC seems to be the correct answer","comment_id":"505815","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: C\nAnswer is C","poster":"escobar15","timestamp":"1655226480.0","comment_id":"501629"},{"poster":"[Removed]","upvote_count":"1","timestamp":"1654455300.0","comment_id":"494661","content":"Selected Answer: C\nC is correct.\nTriiger is \"as soon as build released on Tuesday\""},{"upvote_count":"1","poster":"pakilodi","comment_id":"493138","timestamp":"1654252140.0","content":"Selected Answer: C\nVote C"},{"poster":"mudot","comment_id":"488082","upvote_count":"1","content":"Selected Answer: C\n\"as soon as it is released every Tuesday\" \nyou cant use scheduling for that !","timestamp":"1653643920.0"},{"comment_id":"487788","timestamp":"1653611640.0","content":"Selected Answer: C\nvote C","upvote_count":"4","poster":"joe2211"},{"poster":"imranmani","content":"It is C : because the deployment job can send a message to a Pub/Subtopic, and a Cloud function can be triggered whenever there is a newmessage on the Pub/Sub topic","timestamp":"1649466060.0","upvote_count":"4","comment_id":"459441"},{"content":"Should be C. Cloud Tasks is better approach where we need to schedule the trigger or need more control over execution but as per question, we have to execute the test which should start only after build done.","timestamp":"1646851800.0","poster":"diaga2","upvote_count":"6","comment_id":"442087"},{"comment_id":"441077","content":"Pub Sub seems better to me here, the release is scheduled for 3am and the requirement is as sonn as released. With Cloud Tasks you would have to set an apropriate time delay to allow the release to complete which could vary. Also seems like a fudge using a bucket operation to trigger the function where Pub Sub can natively invoke.","poster":"Rzla","timestamp":"1646688480.0","upvote_count":"2"},{"comment_id":"417952","poster":"VishalB","content":"Answer A\n - Cloud Tasks is a fully managed service that allows you to manage the execution, dispatch, and delivery of a large number of distributed tasks. Using Cloud Tasks, you can perform work asynchronously outside of a user or service-to-service request","upvote_count":"5","timestamp":"1643652900.0"},{"upvote_count":"6","comment_id":"417395","timestamp":"1643554500.0","poster":"poseidon24","content":"This is tricky one.\nCloud Storage buckets can trigger a notification to Functions, but none the question nor the use case mention nothing about the \"repository\" used for new versions of applications is Cloud Storage, in any case if using along Scheduler, this can end up in duplicated execution of tests (imagine that the application release is delayed by couple of minutes, this will trigger the scheduler set at certain time, and when new release update is completed in Bucket will trigger the function again).\n\nHence I'll go with the Pub/Sub approach, the deployment process will send a signal and then the test can start, think like a pipeline."},{"content":"A looks correct after reading this blog https://medium.com/google-cloud/cloud-tasks-or-pub-sub-8dcca67e2f7a","comment_id":"417271","poster":"imgcp","timestamp":"1643539200.0","upvote_count":"1"},{"content":"hey guys new Qs posted as of July 12th, 2021, All 21 new Qs in Question #152","comment_id":"409217","timestamp":"1642555860.0","upvote_count":"2","poster":"kopper2019"},{"content":"hey guys new Qs posted as of July 12th, 2021, All 21 new Qs in Question #152","poster":"kopper2019","comment_id":"408948","timestamp":"1642516800.0","upvote_count":"1"},{"content":"A. Set up Cloud Tasks and a Cloud Storage bucket that triggers a Cloud Function.","comment_id":"408329","upvote_count":"1","poster":"victory108","timestamp":"1642414500.0"},{"content":"Answer is A as Cloud task is used to manage the execution, dispatch, and delivery of a large number of distributed tasks. Using Cloud Tasks, you can perform work asynchronously outside of a user or service-to-service request.","timestamp":"1641254880.0","comment_id":"397850","poster":"crazyaboutazure","upvote_count":"3"},{"timestamp":"1641118200.0","content":"I think you a) and c) might work.\nEven if I am unsure, what to do with the Cloud Storage Account in a) I think it might be the google prefered way considering that Cloud Tasks is a newer product and until now not asked for in any of the questions as far as I rememeber...","poster":"XDevX","upvote_count":"3","comment_id":"396701"}],"answers_community":["C (81%)","Other"],"isMC":true},{"id":"akgStH8HlHX22TGaqmG6","answer_images":[],"isMC":true,"topic":"3","discussion":[{"poster":"umashankar_a","timestamp":"1641440040.0","comment_id":"399592","content":"Answer A \nAI Explanations helps you understand your model's outputs for classification and regression tasks. Whenever you request a prediction on AI Platform, AI Explanations tells you how much each feature in the data contributed to the predicted result. You can then use this information to verify that the model is behaving as expected, recognize bias in your models, and get ideas for ways to improve your model and your training data.\nhttps://cloud.google.com/ai-platform/prediction/docs/ai-explanations/overview","upvote_count":"31"},{"content":"Got this question in my exam, answered A","comment_id":"527739","poster":"technodev","upvote_count":"11","timestamp":"1658241300.0"},{"poster":"gcloud007","content":"Selected Answer: A\nThe choices are wrong ... AI Explanations is Deprecated, its not called Vertex AI, see. .. https://cloud.google.com/ai-platform/prediction/docs/ai-explanations/overview","upvote_count":"4","comment_id":"1335223","timestamp":"1735747620.0"},{"comment_id":"1228033","poster":"JaimeMS","content":"Selected Answer: A\nAnswer A,\nBUT: \"This legacy version of AI Platform Prediction is deprecated and will no longer be available on Google Cloud after January 31, 2025. All models, associated metadata, and deployments will be deleted after January 31, 2025. Migrate your resources to Vertex AI to get new machine learning features that are unavailable in AI Platform.\"","upvote_count":"3","timestamp":"1733861340.0"},{"content":"Option A - Now its Vertex AI","timestamp":"1726686900.0","comment_id":"1176827","upvote_count":"5","poster":"yas_cloud"},{"upvote_count":"7","timestamp":"1713697140.0","poster":"CyanideX","comment_id":"1049415","content":"Selected Answer: A\nIt's now Vertex AI"},{"poster":"Kamngur","timestamp":"1710402480.0","comment_id":"1007248","content":"Selected Answer: A\nAnswer A is almost correct ;). Not it should be Vertex AI.","upvote_count":"3"},{"upvote_count":"5","timestamp":"1687788060.0","comments":[{"timestamp":"1687788060.0","comment_id":"757630","poster":"omermahgoub","upvote_count":"2","content":"Option C: Google Cloud's operations suite is a set of tools and services that helps you monitor, troubleshoot, and optimize your Google Cloud resources. It is not relevant to understanding and interpreting the predictions made by HRL's ML prediction models.\n\nOption D: Jupyter Notebooks is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations, and narrative text. It is not relevant to understanding and interpreting the predictions made by HRL's ML prediction models."}],"poster":"omermahgoub","comment_id":"757629","content":"The correct answer is A: Use Explainable AI.\n\nTo understand and interpret the predictions made by HRL's ML prediction models, you should use Explainable AI. Explainable AI, also known as XAI, is a suite of tools and techniques that helps you understand and interpret the predictions made by machine learning models. With Explainable AI, you can get insights into how the model made a particular prediction, which can help you understand the underlying factors that influenced the prediction. This can help HRL improve the accuracy of their predictions and make more informed decisions based on the output of their models.\n\nOption B: Vision AI is a suite of tools and services that helps you build and deploy computer vision applications. It is not relevant to understanding and interpreting the predictions made by HRL's ML prediction models."},{"upvote_count":"1","timestamp":"1683877680.0","poster":"megumin","content":"Selected Answer: A\nA is ok","comment_id":"716618"},{"upvote_count":"3","timestamp":"1678556100.0","poster":"6721sora","comment_id":"666241","content":"Selected Answer: A\nExplainable AI now included with Vertex AI\nhttps://cloud.google.com/explainable-ai"},{"comments":[{"poster":"AzureDP900","timestamp":"1672895700.0","content":"https://cloud.google.com/aiplatform/prediction/docs/ai-explanations/overview","upvote_count":"1","comment_id":"627225"}],"upvote_count":"2","timestamp":"1672895640.0","comment_id":"627224","poster":"AzureDP900","content":"Answer is A. \n\nhttps://cloud.google.com/explainable-ai"},{"upvote_count":"2","timestamp":"1666693200.0","comment_id":"591552","content":"Selected Answer: A\nHad this quection on my exam.","poster":"mad314"},{"content":"Selected Answer: A\nA is Correct","timestamp":"1656458880.0","comment_id":"511689","upvote_count":"1","poster":"esnecho"},{"poster":"vincy2202","comment_id":"505817","timestamp":"1655778180.0","content":"Selected Answer: A\nA is the correct answer","upvote_count":"1"},{"upvote_count":"4","comment_id":"487790","timestamp":"1653611640.0","poster":"joe2211","content":"Selected Answer: A\nvote A"},{"content":"hey guys new Qs posted as of July 12th, 2021, All 21 new Qs in Question #152","timestamp":"1642516800.0","upvote_count":"1","comment_id":"408942","poster":"kopper2019"},{"content":"A. Use Explainable AI.","timestamp":"1642416660.0","poster":"victory108","comment_id":"408351","upvote_count":"2"},{"content":"Answer is A","comment_id":"401788","upvote_count":"4","poster":"MamthaSJ","timestamp":"1641645300.0"},{"content":"A. Use Explainable AI.","timestamp":"1641567060.0","comment_id":"400883","upvote_count":"2","poster":"wilwong"},{"upvote_count":"2","content":"cloudstd 1 day, 9 hours ago\nanswer: A\n upvoted 1 times\n juccjucc 1 day, 12 hours ago\nis it A?","timestamp":"1641180180.0","comment_id":"397230","poster":"kopper2019"},{"poster":"XDevX","comment_id":"396704","upvote_count":"2","timestamp":"1641118800.0","content":"I think A is correct - A helps to better understand your models and to improve them.\nSee for example the comments of the customers, particularly vivint and robot:\nhttps://cloud.google.com/explainable-ai"},{"comment_id":"396396","timestamp":"1641083700.0","poster":"muhasinem","content":"A. Use Explainable AI.\nhttps://cloud.google.com/explainable-ai\nExplainable AI is a set of tools and frameworks to help you understand and interpret predictions made by your machine learning models. With it, you can debug and improve model performance, and help others understand your models' behavior. You can also generate feature attributions for model predictions in AutoML Tables and AI Platform, and visually investigate model behavior using the What-If Tool.","upvote_count":"1"},{"comment_id":"394672","comments":[{"poster":"ezioauditore123","comment_id":"426993","upvote_count":"14","content":"there's always some idiot like this in the comments","timestamp":"1645212240.0"}],"upvote_count":"4","content":"I think B is correct","timestamp":"1640873040.0","poster":"manhmaluc"}],"unix_timestamp":1625054640,"question_images":[],"question_id":233,"timestamp":"2021-06-30 14:04:00","answers_community":["A (100%)"],"answer_description":"","question_text":"For this question, refer to the Helicopter Racing League (HRL) case study. HRL wants better prediction accuracy from their ML prediction models. They want you to use Google's AI Platform so HRL can understand and interpret the predictions. What should you do?","exam_id":4,"choices":{"B":"Use Vision AI.","C":"Use Google Cloud's operations suite.","D":"Use Jupyter Notebooks.","A":"Use Explainable AI."},"url":"https://www.examtopics.com/discussions/google/view/56322-exam-professional-cloud-architect-topic-3-question-4/","answer":"A","answer_ET":"A"},{"id":"JKWswexHbJisb6l5CbhT","answer":"C","url":"https://www.examtopics.com/discussions/google/view/56326-exam-professional-cloud-architect-topic-3-question-5/","question_images":[],"question_text":"For this question, refer to the Helicopter Racing League (HRL) case study. HRL is looking for a cost-effective approach for storing their race data such as telemetry. They want to keep all historical records, train models using only the previous season's data, and plan for data growth in terms of volume and information collected. You need to propose a data solution. Considering HRL business requirements and the goals expressed by CEO S. Hawke, what should you do?","question_id":234,"topic":"3","isMC":true,"answers_community":["C (100%)"],"answer_ET":"C","answer_images":[],"exam_id":4,"answer_description":"","unix_timestamp":1625054940,"timestamp":"2021-06-30 14:09:00","choices":{"A":"Use Firestore for its scalable and flexible document-based database. Use collections to aggregate race data by season and event.","D":"Use Cloud SQL for its ability to automatically manage storage increases and compatibility with MySQL. Use separate database instances for each season.","B":"Use Cloud Spanner for its scalability and ability to version schemas with zero downtime. Split race data using season as a primary key.","C":"Use BigQuery for its scalability and ability to add columns to a schema. Partition race data based on season."},"discussion":[{"comment_id":"401794","content":"Answer is C","poster":"MamthaSJ","upvote_count":"17","timestamp":"1641645480.0","comments":[{"upvote_count":"3","comment_id":"527725","poster":"Wonka","comments":[{"content":"In exam actually :)","comment_id":"723420","poster":"ashrafh","upvote_count":"6","timestamp":"1684661160.0"}],"timestamp":"1658241000.0","content":"These questions are sounding too simple, are these really coming in exam or these are mocked up?"}]},{"content":"C. Use BigQuery for its scalability and ability to add columns to a schema. Partition race data based on season.","poster":"victory108","comment_id":"408350","timestamp":"1642416600.0","upvote_count":"6"},{"comment_id":"1204922","content":"Vote for C","poster":"Gino17m","timestamp":"1730453340.0","upvote_count":"1"},{"content":"How can it be C because BigQuery only support timestamp based partitions?","upvote_count":"1","poster":"Prakzz","comments":[{"upvote_count":"2","poster":"parthkulkarni998","timestamp":"1719226500.0","content":"Exactly. That means it will use timestamp of season for partition","comment_id":"1104595"}],"timestamp":"1712381280.0","comment_id":"1026262"},{"comment_id":"1007258","timestamp":"1710402960.0","content":"C looks good. Remember Telemetry would be stored and used for predictions later\nA. would be good if it would be stored only, as documents. \nB. Spanner is over kill. It is too expensive and we have no need to serve this data outside\nD. Cloud SQL is too simple solution and use multiple db's is only complicating architecture.","poster":"Kamngur","upvote_count":"5"},{"poster":"examch","content":"Selected Answer: C\nC is the correct Answer,\nWe can use BigQuery for making Predictions with live and trained data with Cloud ML Engine, and BigQuery can handle large amounts of data.\n\nRefer to the Link for more details on Game Predictions,\n\nhttps://cloud.google.com/blog/products/gcp/architecting-live-ncaa-predictions-from-archives-to-insights","timestamp":"1689808920.0","upvote_count":"5","comment_id":"781752"},{"timestamp":"1687788120.0","comment_id":"757631","poster":"omermahgoub","upvote_count":"3","content":"For HRL's data storage needs, it is recommended to use BigQuery due to its scalability and ability to handle large amounts of data. By partitioning the race data based on season, HRL can easily access and query specific seasons' data while also taking into consideration future data growth. BigQuery also allows for the flexibility to add new columns to the schema as needed, making it easier to adapt to changes in the data being collected. Additionally, BigQuery's pay-per-use pricing model allows HRL to only pay for the data storage and querying they use, making it a cost-effective solution."},{"comment_id":"747865","upvote_count":"1","content":"Selected Answer: C\nC is the correct answer","timestamp":"1686982380.0","poster":"surajkrishnamurthy"},{"timestamp":"1686972540.0","content":"Selected Answer: C\nC is the correct answer","poster":"surajkrishnamurthy","upvote_count":"1","comment_id":"747779"},{"timestamp":"1683877860.0","content":"Selected Answer: C\nC is ok","comment_id":"716622","poster":"megumin","upvote_count":"1"},{"content":"Selected Answer: C\nC it is","comment_id":"662500","upvote_count":"1","poster":"Nirca","timestamp":"1678201440.0"},{"content":"c C C c","poster":"Nirca","comment_id":"634514","timestamp":"1674302580.0","upvote_count":"1"},{"comment_id":"627226","timestamp":"1672895880.0","poster":"AzureDP900","upvote_count":"1","content":"C most obvious when data is growing day by day."},{"poster":"mad314","timestamp":"1666693260.0","upvote_count":"2","content":"Selected Answer: C\nHad this question on my exam.","comment_id":"591554"},{"comment_id":"574984","upvote_count":"3","poster":"SAMBIT","content":"Telemetry data in a relational table..what?? Why they gave firestore then","timestamp":"1664100120.0"},{"timestamp":"1658241300.0","content":"Got this question in my exam, answered C","poster":"technodev","comment_id":"527741","upvote_count":"3"},{"poster":"Pime13","content":"to me it's C -> https://cloud.google.com/architecture/mobile-gaming-analysis-telemetry","timestamp":"1656422100.0","comment_id":"511245","upvote_count":"4"},{"timestamp":"1655691600.0","content":"Selected Answer: C\nC seems to be the correct answer","comment_id":"505210","upvote_count":"1","poster":"vincy2202"},{"upvote_count":"1","content":"Selected Answer: C\nhttps://cloud.google.com/architecture/mobile-gaming-analysis-telemetry","poster":"SamGCP","timestamp":"1655405580.0","comment_id":"503191"},{"comment_id":"493767","poster":"vaibhav15","upvote_count":"1","content":"vote C","timestamp":"1654349460.0"},{"upvote_count":"4","poster":"joe2211","content":"Selected Answer: C\nvote C","timestamp":"1653611760.0","comment_id":"487792"},{"timestamp":"1642555800.0","content":"hey guys new Qs posted as of July 12th, 2021, All 21 new Qs in Question #152","comment_id":"409211","comments":[{"timestamp":"1649595180.0","comment_id":"460063","poster":"JasonL_GCP","content":"not seeing any new questions posted there?","upvote_count":"2","comments":[{"timestamp":"1687439280.0","content":"the guy just spammed questions everywhere under the comments not understanding that should be posted as a topic, also the question number changes so what was 152# a year ago, most likely is not anymore.","comment_id":"753416","poster":"ale_brd_111","upvote_count":"1"}]}],"poster":"kopper2019","upvote_count":"1"},{"poster":"kopper2019","content":"hey guys new Qs posted as of July 12th, 2021, All 21 new Qs in Question #152","upvote_count":"1","comment_id":"408944","timestamp":"1642516800.0"},{"timestamp":"1641622020.0","poster":"kopper2019","content":"looks like C","upvote_count":"3","comment_id":"401507"},{"comment_id":"400901","poster":"wilwong","content":"Answer C","upvote_count":"2","timestamp":"1641567720.0"},{"comment_id":"399580","content":"Answer C\nBigQuery is more appropriate as they are planning for analytics and none of the other option suit the need.","poster":"umashankar_a","timestamp":"1641439260.0","upvote_count":"2"},{"comment_id":"397232","poster":"kopper2019","content":"cloudstd 1 day, 9 hours ago\nanswer: C\n upvoted 1 times\n juccjucc 1 day, 12 hours ago\nis it C?\nall these questions are from the new exam? why they are here in the comments and not as questions in the list?","timestamp":"1641180240.0","upvote_count":"3"},{"poster":"manhmaluc","upvote_count":"4","comment_id":"394678","content":"maybe C for Big query","timestamp":"1640873340.0"}]},{"id":"Yua2mJypUfBkA7WxU6SF","url":"https://www.examtopics.com/discussions/google/view/56328-exam-professional-cloud-architect-topic-3-question-6/","unix_timestamp":1625055180,"discussion":[{"timestamp":"1641645780.0","upvote_count":"21","comment_id":"401798","content":"Answer is C","poster":"MamthaSJ","comments":[{"comment_id":"665223","upvote_count":"9","content":"I too got this question in 10-09-22 exam with similar option and result is pass","timestamp":"1678441860.0","poster":"khadar"}]},{"upvote_count":"19","poster":"mkhaired","comment_id":"395679","timestamp":"1641031320.0","content":"C is the Correct answer \nC. Use the gcloud recommender command to list the idle virtual machine instances.\nhttps://cloud.google.com/compute/docs/instances/viewing-and-applying-idle-vm-recommendations"},{"content":"Selected Answer: C\nC i scorrect","comment_id":"1204926","upvote_count":"2","timestamp":"1730453640.0","poster":"Gino17m"},{"poster":"tdotcat","timestamp":"1689442500.0","upvote_count":"3","comment_id":"776996","content":"answer C\ncheck here : \nhttps://cloud.google.com/compute/docs/instances/viewing-and-applying-idle-vm-recommendations#viewing_idle_vm_instance_recommendations"},{"content":"Selected Answer: C\nC is the correct answer","timestamp":"1686982440.0","poster":"surajkrishnamurthy","comment_id":"747866","upvote_count":"1"},{"timestamp":"1683878580.0","comment_id":"716630","upvote_count":"1","content":"Selected Answer: C\nC is ok","poster":"megumin"},{"upvote_count":"1","comment_id":"668111","timestamp":"1678723320.0","content":"Selected Answer: C\nC is the answer which is to use recommender.\nhttps://www.youtube.com/watch?v=VBsLG4jCHJk","poster":"zellck"},{"upvote_count":"1","content":"Selected Answer: C\nSome one who can explain me why A is an answer? is it deliberate?","comments":[{"timestamp":"1705132500.0","upvote_count":"1","content":"because the questions says \"quickly\"","comment_id":"950381","poster":"randy8984"},{"comment_id":"642352","content":"Don't pay too much attention to the \"correct answer\", the \"most voted\" is much more reliable.","poster":"Mikado211","timestamp":"1675517100.0","upvote_count":"8"}],"poster":"satamex","comment_id":"640744","timestamp":"1675273680.0"},{"upvote_count":"2","comment_id":"634032","poster":"deenee","content":"Selected Answer: C\nC looks decent as identification has to be done quickly. Manually checking each machines will take lot of time. Moreover--- even option A says \"CPUs\" and not GPUs \n\"Log into each Compute Engine instance and collect disk, CPU, memory, and network usage statistics for analysis.\"","timestamp":"1674224820.0"},{"content":"C is right","timestamp":"1672896060.0","poster":"AzureDP900","comment_id":"627227","upvote_count":"2"},{"content":"All the quesrions had come from this site , especially couple of case studies and answer is C","poster":"Tillssatya12","comment_id":"616199","upvote_count":"3","timestamp":"1671026460.0"},{"poster":"mad314","timestamp":"1666693320.0","upvote_count":"5","content":"Selected Answer: C\nHad this question on my exam.","comment_id":"591557"},{"content":"Got this question in my exam, answered C","upvote_count":"4","timestamp":"1658241300.0","comment_id":"527742","comments":[{"comment_id":"530435","upvote_count":"1","timestamp":"1658563860.0","content":"Did all the questions in the exam come from this site?","poster":"hightech"}],"poster":"technodev"},{"poster":"Pime13","upvote_count":"2","content":"Selected Answer: C\nto me should be C -> https://cloud.google.com/compute/docs/instances/viewing-and-applying-idle-vm-recommendations#before-you-begin","timestamp":"1656421980.0","comment_id":"511243"},{"poster":"vincy2202","comment_id":"505871","content":"Selected Answer: C\nC is the correct answer","timestamp":"1655787180.0","upvote_count":"2"},{"content":"Selected Answer: C\nhttps://cloud.google.com/compute/docs/instances/viewing-and-applying-idle-vm-recommendations","poster":"SamGCP","comment_id":"503194","timestamp":"1655405700.0","upvote_count":"2"},{"upvote_count":"2","comment_id":"502397","content":"Selected Answer: C\nhttps://cloud.google.com/compute/docs/instances/viewing-and-applying-idle-vm-recommendations","timestamp":"1655309640.0","poster":"SamGCP"},{"content":"C。 gcloud recommender recommendations list \\\n --project=PROJECT_ID \\\n --location=ZONE \\\n --recommender=google.compute.instance.IdleResourceRecommender \\\n --format=yaml","upvote_count":"2","poster":"ohmyhat2005","comment_id":"499698","timestamp":"1654980180.0"},{"upvote_count":"1","content":"Selected Answer: C\nC is right here","comment_id":"493143","poster":"pakilodi","timestamp":"1654252620.0"},{"upvote_count":"1","content":"Selected Answer: C\nC\nhttps://cloud.google.com/compute/docs/instances/viewing-and-applying-idle-vm-recommendations","poster":"vchrist","comment_id":"491086","timestamp":"1654036260.0"},{"timestamp":"1653661560.0","poster":"[Removed]","upvote_count":"3","comment_id":"488276","content":"Selected Answer: C\nSuggested A is wrong.\nC is right answer."},{"comment_id":"487793","poster":"joe2211","content":"Selected Answer: C\nvote C","upvote_count":"2","timestamp":"1653611760.0"},{"timestamp":"1652469600.0","poster":"XAliX","content":"Focus again on the question, it's video recording and streaming, and GPU module is not supported on IDLE VM report, the answer is A","comment_id":"477748","upvote_count":"2"},{"comment_id":"460099","timestamp":"1649600220.0","poster":"nocrush","content":"Regarding answer C, in https://cloud.google.com/compute/docs/instances/viewing-and-applying-idle-vm-recommendations, is reported:\n\nLimitations\nFor standalone VMs, idle recommendations are not available in following cases:\nInstances with local SSDs\nInstances with GPU/TPUs\nApp Engine flex resources\nDataflow resources\nGoogle Kubernetes Engine resources\n\nThe question and EHR Healthcare case study don't specify the technology, so the correct answer is A.","comments":[{"content":"I assume you mean \"Helicopter Racing League (HRL) case study. \" and if no technology is specified, why does C won't apply? If it's a MIG why wouldn't this help? Logging into every single VM given that it's know that \"Video encoding and transcoding is performed on VMs created for each job.\" seems not the best option. I would go with option C. - gcloud recommender command to list the idle virtual machine instances.","poster":"J19G","upvote_count":"1","comments":[{"comment_id":"465790","poster":"J19G","upvote_count":"1","timestamp":"1650560820.0","content":"I mean if we are dealing with standalone VMS or unmanaged Instance group."}],"timestamp":"1650560700.0","comment_id":"465788"},{"comment_id":"471550","content":"In question, technical requirement has \"Increase transcoding performance.\" , i think the zombie instances were included GPU","timestamp":"1651472340.0","upvote_count":"1","comments":[{"content":"There is no mention of standalone VMs or VMs with GPU, only in which case you can apply above limitations, makes sense?","poster":"Wonka","comment_id":"513970","timestamp":"1656572460.0","upvote_count":"1"}],"poster":"letonphat"}],"upvote_count":"3"},{"content":"Yes, it's C only","poster":"diaga2","timestamp":"1646857800.0","upvote_count":"1","comment_id":"442138"},{"poster":"PathToGCP","upvote_count":"2","comment_id":"441130","timestamp":"1646700240.0","content":"Compute Engine provides idle VM recommendations to help you identify virtual machine (VM) instances that have not been used. These recommendations are generated automatically based on system metrics gathered by the Cloud Monitoring service over the previous 14 days. You can use idle VM recommendations to find and stop idle VM instances to reduce waste of resources and reduce your compute bill"},{"content":"Limitations gcloud recommender command:\nFor standalone VMs, downtime recommendations are not available in the following cases:\n\nInstances with local SSDs\nInstances with GPU/TPUs\nFlexible App Engine Features\nDataflow Features\nGoogle Kubernetes Engine Features\n\nthe zombie machine has been allocated for video encoding and transcoding, does it not have a GPU? Why not A? \nhttps://cloud.google.com/compute/docs/instances/viewing-and-applying-idle-vm-recommendations","timestamp":"1642698000.0","upvote_count":"1","poster":"nathibispo","comments":[{"content":"https://cloud.google.com/compute/docs/instances/viewing-and-applying-idle-vm-recommendations#limitations\nFor standalone VMs, idle recommendations are not available for Instances with GPU/TPUs. In the question the VMs might be having GPU (Video Encoding & Decoding). So I think RECOMMENDER will not work for these VMs.","comment_id":"415398","timestamp":"1643289840.0","poster":"deep_ROOT","upvote_count":"1"}],"comment_id":"410361"},{"upvote_count":"1","content":"hey guys new Qs posted as of July 12th, 2021, All 21 new Qs in Question #152","comment_id":"409212","timestamp":"1642555800.0","poster":"kopper2019"},{"poster":"kopper2019","comment_id":"408945","upvote_count":"1","timestamp":"1642516800.0","content":"hey guys new Qs posted as of July 12th, 2021, All 21 new Qs in Question #152"},{"comment_id":"408348","content":"C. Use the gcloud recommender command to list the idle virtual machine instances.","poster":"victory108","upvote_count":"5","timestamp":"1642416480.0"},{"timestamp":"1641567900.0","comment_id":"400905","upvote_count":"2","content":"Answer C","poster":"wilwong"},{"content":"Answer C\nApply gcloud recommendations to instances. \nhttps://cloud.google.com/compute/docs/instances/apply-machine-type-recommendations-for-instances","poster":"umashankar_a","upvote_count":"3","comment_id":"399584","timestamp":"1641439560.0"},{"poster":"kopper2019","upvote_count":"2","timestamp":"1641180240.0","comment_id":"397233","content":"cloudstd 1 day, 9 hours ago\nanswer: C\n upvoted 1 times\n juccjucc 1 day, 12 hours ago\nis it C?"},{"comment_id":"395361","poster":"muhasinem","timestamp":"1641007440.0","upvote_count":"5","content":"Ans )C \nhttps://cloud.google.com/compute/docs/instances/viewing-and-applying-idle-vm-recommendations\n\ngcloud recommender recommendations list \\\n --project=PROJECT_ID \\\n --location=ZONE \\\n --recommender=google.compute.instance.IdleResourceRecommender \\\n --format=yaml"},{"content":"it is C\nhttps://cloud.google.com/compute/docs/instances/viewing-and-applying-idle-vm-recommendations","comment_id":"394682","poster":"manhmaluc","timestamp":"1640873580.0","upvote_count":"3"}],"answers_community":["C (100%)"],"answer":"C","exam_id":4,"question_text":"For this question, refer to the Helicopter Racing League (HRL) case study. A recent finance audit of cloud infrastructure noted an exceptionally high number of\nCompute Engine instances are allocated to do video encoding and transcoding. You suspect that these Virtual Machines are zombie machines that were not deleted after their workloads completed. You need to quickly get a list of which VM instances are idle. What should you do?","isMC":true,"question_images":[],"question_id":235,"choices":{"A":"Log into each Compute Engine instance and collect disk, CPU, memory, and network usage statistics for analysis.","B":"Use the gcloud compute instances list to list the virtual machine instances that have the idle: true label set.","C":"Use the gcloud recommender command to list the idle virtual machine instances.","D":"From the Google Console, identify which Compute Engine instances in the managed instance groups are no longer responding to health check probes."},"answer_ET":"C","answer_images":[],"topic":"3","timestamp":"2021-06-30 14:13:00","answer_description":""}],"exam":{"isImplemented":true,"numberOfQuestions":279,"id":4,"provider":"Google","isMCOnly":false,"isBeta":false,"name":"Professional Cloud Architect","lastUpdated":"11 Apr 2025"},"currentPage":47},"__N_SSP":true}