{"pageProps":{"questions":[{"id":"qnEcQHDei8nz97CjyGR4","exam_id":7,"question_images":["https://www.examtopics.com/assets/media/exam-media/04137/0001700001.jpg","https://www.examtopics.com/assets/media/exam-media/04137/0001700002.jpg"],"choices":{"B":"Request additional Compute Engine quota in the GCP Console.","A":"Request additional GKE quota in the GCP Console.","D":"Decouple services in the cluster, and rewrite new clusters to function with fewer cores.","C":"Open a support case to request additional GKE quota."},"answer_images":[],"answer_description":"","question_text":"You are creating a Google Kubernetes Engine (GKE) cluster and run this command:\n//IMG//\n\nThe command fails with the error:\n//IMG//\n\nYou want to resolve the issue. What should you do?","timestamp":"2020-11-08 20:04:00","question_id":201,"answers_community":["B (100%)"],"isMC":true,"answer":"B","discussion":[{"content":"Selected Answer: B\nThe issue with the command for creating the Google Kubernetes Engine (GKE) cluster is that it fails due to insufficient regional quota for CPUs. GKE clusters utilize Compute Engine resources, so when you encounter a quota issue like this, it is related to the Compute Engine quotas, not directly to GKE.\nTo resolve the issue, you should: B. Request additional Compute Engine quota in the GCP Console.\nCompute Engine quotas are set per region and include resources like CPUs, GPUs, and disk. When you create a GKE cluster, you're actually creating Compute Engine instances that will serve as nodes for the cluster. If your project doesn't have enough quota for the CPUs required to create the cluster, you need to request additional quota for CPUs in the relevant region.","upvote_count":"1","comment_id":"1168240","poster":"santoshchauhan","timestamp":"1725724140.0"},{"content":"Selected Answer: B\nGKE uses Compute Engine so we need to increase Compute Engine Quota.","poster":"__rajan__","timestamp":"1710831600.0","upvote_count":"1","comment_id":"1011067"},{"comment_id":"768299","poster":"omermahgoub","timestamp":"1688707740.0","content":"Option A is incorrect because the error message mentions Compute Engine quota, not GKE quota. Option C is incorrect because you can request additional quota through the GCP Console, rather than opening a support case. Option D is not a solution to the issue, as it does not address the shortage of Compute Engine quota.\n\nCorrect answer B: you should request additional Compute Engine quota in the GCP Console.","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: B\nNo such thing as a GKE quota","timestamp":"1682329680.0","comment_id":"702896","poster":"ExamTopiczz"},{"comment_id":"698359","poster":"hello_code","timestamp":"1681835940.0","content":"Selected Answer: B\nB is the most appropriate answer","upvote_count":"1"},{"content":"Selected Answer: B\nThe GKE node are Compute Engine instances, so if you need more CPUs you need to ask more quota of these.\n\nAsnwer is B for me.","poster":"brunoguzzo18","comment_id":"650576","upvote_count":"4","timestamp":"1677134400.0"},{"comment_id":"649189","content":"Selected Answer: B\nB is correct","upvote_count":"3","timestamp":"1676878620.0","poster":"tomato123"},{"content":"Selected Answer: B\nB - According to documentation https://cloud.google.com/kubernetes-engine/docs/how-to/node-upgrades-quota (last chapter)","comment_id":"607495","timestamp":"1669451820.0","poster":"ruben82","upvote_count":"3"},{"poster":"herocc","comment_id":"527160","timestamp":"1658189760.0","content":"B is best one","upvote_count":"2"},{"timestamp":"1657266660.0","poster":"ParagSanyashiv","content":"Selected Answer: B\nAs the error is refering CPU, the correct answer is B","comment_id":"519430","upvote_count":"1"},{"poster":"syu31svc","comment_id":"390916","content":"https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-architecture:\n\"A cluster typically has one or more nodes, which are the worker machines that run your containerized applications and other workloads. The individual machines are Compute Engine VM instances that GKE creates on your behalf when you create a cluster.\"\n\nError message mentions \"CPU\" so this would refer to Compute Engine VMs\n\nAnswer is B","upvote_count":"4","timestamp":"1640499780.0"},{"poster":"donchick","comment_id":"255408","timestamp":"1625027460.0","content":"B is correct - https://cloud.google.com/kubernetes-engine/quotas#limits_per_cluster","upvote_count":"1"},{"content":"Correct answer would be B, as its for number of node,","timestamp":"1620493440.0","poster":"saurabh1805","upvote_count":"3","comment_id":"215467"}],"topic":"1","url":"https://www.examtopics.com/discussions/google/view/36490-exam-professional-cloud-developer-topic-1-question-28/","unix_timestamp":1604862240,"answer_ET":"B"},{"id":"OlxrcGrGxCcN0mpyhj5X","question_id":202,"discussion":[{"content":"Selected Answer: C\nC is correct","timestamp":"1740688260.0","upvote_count":"1","poster":"09bd94b","comment_id":"1362718"},{"comment_id":"1296187","content":"Selected Answer: C\nTo extend storage space in GKE, you need to update the PersistentVolumeClaim (PVC) to request a larger volume size; this will trigger the creation of a new PersistentVolume (PV) with the desired capacity if your StorageClass is configured for dynamic provisioning","poster":"anshad666","timestamp":"1728665640.0","upvote_count":"1"}],"answer_ET":"C","unix_timestamp":1728665640,"question_text":"You recently deployed an application to GKE where Pods are writing files to a Compute Engine persistent disk. You have created a PersistentVolumeClaim (PVC) and a PersistentVolume (PV) object on Kubernetes for the disk, and you reference the PVC in the deployment manifest file.\n\nYou recently expanded the size of the persistent disk because the application has used up almost all of the disk space. You have logged on to one of the Pods, and you notice that the disk expansion is not visible in the container file system. What should you do?","answer_description":"","question_images":[],"choices":{"C":"Set the spec.resources.requests.storage value of the PVC object to match the size of the persistent disk. Apply the updated configuration by using kubectl.","D":"In the Pod, resize the disk partition to the maximum value by using the fdisk or parted utility.","B":"Recreate the application Pods by running the kubectl delete deployment DEPLOYMENT_NAME && kubectl apply deployment.yaml command, where the DEPLOYMENT_NAME parameter is the name of your deployment and deployment.yaml is its manifest file.","A":"Set the spec.capacity.storage value of the PV object to match the size of the persistent disk. Apply the updated configuration by using kubectl."},"isMC":true,"answer":"C","exam_id":7,"answer_images":[],"url":"https://www.examtopics.com/discussions/google/view/149091-exam-professional-cloud-developer-topic-1-question-280/","topic":"1","answers_community":["C (100%)"],"timestamp":"2024-10-11 18:54:00"},{"id":"WmHUPuuF29XyN7Zl3B1r","question_id":203,"discussion":[{"poster":"rsm_exam","content":"https://cloud.google.com/apigee/docs/api-platform/fundamentals/environments-overview#:~:text=You%20define%20hostnames%20on%20your,access%20proxies%20deployed%20within%20it.\nAnswer is D. You define hostnames on your environment groups (not on individual environments)","upvote_count":"1","timestamp":"1731777360.0","comment_id":"1313148"},{"upvote_count":"1","timestamp":"1728696180.0","content":"Selected Answer: D\nenvironment group can have multiple environments attached to it, but the environments will only respond to requests using the hostnames specified for that group.\nAttaching environments to environment groups ensures that only those environments use the corresponding hostnames.\nBy attaching orders-test to the test environment group and orders-prod to the production environment group, you are ensuring that each environment is restricted to its appropriate URL.","poster":"anshad666","comment_id":"1296296"}],"answer_ET":"D","answers_community":["D (100%)"],"timestamp":"2024-10-12 03:23:00","choices":{"D":"1. Attach orders-test to the test environment group, and attach orders-prod to the production environment group.\n2. Add each hostname to the appropriate environment group.","A":"1. Attach orders-test and orders-prod to the orders environment group.\n2. Add each hostname to the appropriate environment.","B":"1. Attach orders-test and orders-prod to the orders environment group.\n2. Add each hostname to the orders environment group.","C":"1. Attach orders-test to the test environment group, and attach orders-prod to the production environment group.\n2. Add each hostname to the appropriate environment."},"isMC":true,"question_text":"You work for an ecommerce company. You are designing a new Orders API that will be exposed through Apigee. In your Apigee organization, you created two new environments named orders-test and orders-prod. You plan to use unique URLs named test.lnk-42.com/api/v1/orders and Ink-42.com/api/v1/orders for each environment. You need to ensure that each environment only uses the assigned URL. What should you do?","question_images":[],"unix_timestamp":1728696180,"answer_images":[],"answer":"D","topic":"1","url":"https://www.examtopics.com/discussions/google/view/149100-exam-professional-cloud-developer-topic-1-question-281/","answer_description":"","exam_id":7},{"id":"TKPLlgtHc2DgeBaQACsy","isMC":true,"topic":"1","unix_timestamp":1728699540,"timestamp":"2024-10-12 04:19:00","answer":"B","exam_id":7,"answer_description":"","url":"https://www.examtopics.com/discussions/google/view/149103-exam-professional-cloud-developer-topic-1-question-282/","answer_images":[],"question_images":[],"discussion":[{"comment_id":"1296303","poster":"anshad666","timestamp":"1728699540.0","content":"Selected Answer: B\nEmulators are great for quickly testing and debugging cloud resources locally without incurring costs associated with deploying the resources on Google Cloud. For example, you can use the Bigtable and Pub/Sub emulators locally to simulate their behavior.","upvote_count":"5"},{"poster":"saratk1984","timestamp":"1742230800.0","comment_id":"1399712","upvote_count":"1","content":"Selected Answer: B\n1. Emulators allow you to simulate GCP services locally (like Bigtable and Pub/Sub) without incurring cloud costs.\n2. This enables rapid iteration, local debugging, and offline development, perfect for early MVP stages.\n3. Once validated, you can deploy to Cloud Run and integrate with actual cloud services."}],"choices":{"A":"Use Cloud Shell Editor and Cloud Shell to deploy the application, and test the functionality by using the Google Cloud console in the project.","C":"Use Cloud Build to create a pipeline, and add the unit testing stage and the manual approval stage. Deploy the code to your Google Cloud project.","B":"Use emulators to test the functionality of cloud resources locally, and deploy the code to your Google Cloud project.","D":"Use Cloud Code to develop, deploy, and test microservices resources. Use Cloud Logging to review the resource logs."},"answers_community":["B (100%)"],"answer_ET":"B","question_id":204,"question_text":"You are developing an application that uses microservices architecture that includes Cloud Run, Bigtable, and Pub/Sub. You want to conduct the testing and debugging process as quickly as possible to create a minimally viable product with minimal cost. What should you do?"},{"id":"bblCZsescy72Ud0O1Maf","exam_id":7,"timestamp":"2024-10-12 04:22:00","question_text":"You are a lead developer at an organization that recently integrated several Google Cloud services. These services are located within Virtual Private Cloud (VPC) environments that are secured with VPC Service Controls and Private Service Connect endpoints. Developers across your organization use different operating systems, development frameworks, and integrated development environments (IDEs). You need to recommend a developer environment that will ensure consistency in the developer process and improve the overall developer experience. You want this solution to:\n\n• Enforce consistent security controls.\n• Have access to Google Cloud resources and applications within the VPC.\n• Allow the installation of custom tools and utilities on the development environments.\n\nWhat solution should you recommend?","choices":{"A":"Use Cloud Workstations, and allow developers to create their own custom images.","C":"Use the Cloud Code extension with the IDEs that are used across the organization. Configure Cloud VPN to enable VPC access.","D":"Use the Cloud Code extension with the IDEs that are used across the organization. Use Identity-Aware Proxy to enable access to the services in the VPC.","B":"Use Cloud Workstations with preconfigured base images. For custom tools and utilities, use custom images that are rebuilt weekly."},"unix_timestamp":1728699720,"discussion":[{"content":"Selected Answer: B\n• Cloud Workstations: Google-managed, secure, container-based development environments that run within VPC.\n • Supports private access to resources secured by VPC Service Controls and Private Service Connect.\n • Provides consistency in the development environment, avoiding issues from local machine variances.\n • Enforces enterprise security policies by running within a controlled network.\n • Preconfigured base images ensure standardized environments for all developers.\n • Custom images rebuilt weekly support custom tools and provide controlled flexibility without compromising security.","comment_id":"1399713","timestamp":"1742230980.0","poster":"saratk1984","upvote_count":"1"},{"content":"Selected Answer: B\nCloud Workstations is a fully managed development environment designed for consistency, security, and access to cloud resources. It ensures that all developers have a uniform environment, meeting the requirement for consistent security controls.\nBy using preconfigured base images, you can ensure that all developers start with the same tools and settings. Allowing custom tools and utilities through custom images that are rebuilt regularly (e.g., weekly) ensures developers have the flexibility to use the tools they need without compromising security.\nAccess to Google Cloud resources within the VPC is supported with Cloud Workstations, and because it's managed on Google Cloud, it fits into VPC Service Controls and Private Service Connect security measures.","upvote_count":"1","comment_id":"1296305","poster":"anshad666","timestamp":"1728699720.0"}],"topic":"1","question_images":[],"url":"https://www.examtopics.com/discussions/google/view/149105-exam-professional-cloud-developer-topic-1-question-283/","answer_ET":"B","answer":"B","answer_images":[],"answer_description":"","answers_community":["B (100%)"],"isMC":true,"question_id":205}],"exam":{"isMCOnly":false,"name":"Professional Cloud Developer","id":7,"isImplemented":true,"isBeta":false,"numberOfQuestions":338,"provider":"Google","lastUpdated":"11 Apr 2025"},"currentPage":41},"__N_SSP":true}