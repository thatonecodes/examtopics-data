{"pageProps":{"questions":[{"id":"97azeGdCH1lPVdiFiLr6","topic":"1","answer":"A","question_text":"You work for a retail company that is using a regression model built with BigQuery ML to predict product sales. This model is being used to serve online predictions. Recently you developed a new version of the model that uses a different architecture (custom model). Initial analysis revealed that both models are performing as expected. You want to deploy the new version of the model to production and monitor the performance over the next two months. You need to minimize the impact to the existing and future model users. How should you deploy the model?","choices":{"C":"Import the new model to the same Vertex AI Model Registry as the existing model. Deploy each model to a separate Vertex AI endpoint.","A":"Import the new model to the same Vertex AI Model Registry as a different version of the existing model. Deploy the new model to the same Vertex AI endpoint as the existing model, and use traffic splitting to route 95% of production traffic to the BigQuery ML model and 5% of production traffic to the new model.","D":"Deploy the new model to a separate Vertex AI endpoint. Create a Cloud Run service that routes the prediction requests to the corresponding endpoints based on the input feature values.","B":"Import the new model to the same Vertex AI Model Registry as the existing model. Deploy the models to one Vertex AI endpoint. Route 95% of production traffic to the BigQuery ML model and 5% of production traffic to the new model."},"isMC":true,"answer_description":"","exam_id":13,"answers_community":["A (80%)","13%","7%"],"answer_ET":"A","question_id":151,"question_images":[],"url":"https://www.examtopics.com/discussions/google/view/131055-exam-professional-machine-learning-engineer-topic-1-question/","discussion":[{"upvote_count":"1","timestamp":"1722200820.0","comment_id":"1257086","content":"Selected Answer: B\nI’m considering two options, A and B. Both deploy to the same endpoint and divide traffic in a similar way. However, option B is more appropriate because it generates a new model rather than just creating a new version of the existing model.","poster":"bfdf9c8"},{"timestamp":"1713403260.0","poster":"fitri001","comment_id":"1197619","comments":[{"poster":"fitri001","comment_id":"1197620","timestamp":"1713403260.0","upvote_count":"1","content":"why not others option?\nB. Deploying Models to One Endpoint without Traffic Splitting: This approach doesn't allow for controlled rollout and could abruptly switch all traffic to the new model, potentially causing disruptions.\nC. Deploying Models to Separate Endpoints: This requires users to update their prediction pipelines to interact with the new endpoint, introducing unnecessary complexity and potential delays.\nD. Cloud Run Service with Feature-Based Routing: While Cloud Run can route traffic, feature-based routing might be more complex to implement for sales prediction and might not be necessary with traffic splitting."}],"upvote_count":"4","content":"Selected Answer: A\nMinimal Disruption: Deploying the new model to the same endpoint avoids changes for existing users. Traffic splitting ensures a gradual rollout, minimizing any potential impact on production.\nPerformance Monitoring: By routing a small percentage of traffic (5%) to the new model, you can monitor its performance in a controlled environment for the next two months. Metrics like prediction accuracy and latency can be compared with the BigQuery ML model.\nVersioning in Model Registry: Storing both models in the same Vertex AI Model Registry with clear versioning allows easy tracking and management."},{"content":"Selected Answer: A\nhttps://cloud.google.com/vertex-ai/docs/general/deployment#models-endpoint","upvote_count":"2","timestamp":"1712595840.0","comment_id":"1191701","poster":"pinimichele01"},{"poster":"Yan_X","content":"Selected Answer: A\nA, no need to separate endpoint.","timestamp":"1706496360.0","comment_id":"1134612","upvote_count":"4"},{"comment_id":"1126234","upvote_count":"2","timestamp":"1705614900.0","content":"Selected Answer: C\nas i understand we need to minimize the impact to the model users, so if we take a part of the traffic from the old model users, we will effect them. As for me we should deploy models to separated endpoints and duplicate the traffic","poster":"BlehMaks"},{"comment_id":"1121362","timestamp":"1705129620.0","content":"Selected Answer: A\nB. Doesn't Specify Traffic Splitting: Deploying models to a single endpoint without explicit traffic splitting might lead to unpredictable model selection behavior, hindering controlled evaluation.\nC. Separate Endpoints: While isolating models, it introduces complexity in managing multiple endpoints and routing logic, increasing operational overhead.\nD. Cloud Run Routing: Adds complexity by requiring a separate service to manage routing, potentially increasing latency and maintenance overhead compared to Vertex AI's built-in traffic splitting.","poster":"pikachu007","upvote_count":"2"}],"answer_images":[],"timestamp":"2024-01-13 08:07:00","unix_timestamp":1705129620},{"id":"iAkr9NJCJaHDyHlacKK6","topic":"1","answers_community":["D (84%)","C (16%)"],"answer_description":"","isMC":true,"timestamp":"2024-01-13 08:17:00","discussion":[{"comment_id":"1153632","upvote_count":"7","content":"Selected Answer: D\nMy Answer: D\n\nThis approach leverages Vertex Explainable AI to provide feature attributions, which helps in understanding the rationale behind the model's decisions. By aggregating these feature attributions over the entire dataset, you can gain insights into potential biases or areas of concern. Analyzing these results alongside standard model evaluation metrics allows for a comprehensive understanding of the model's performance and its interpretability.\n\nOption C is better to understand specific cases, but does not show overall contributions.","poster":"guilhermebutzke","timestamp":"1724018100.0"},{"timestamp":"1729437840.0","comment_id":"1199211","upvote_count":"1","content":"Selected Answer: D\nagree with guilhermebutzke","poster":"gscharly"},{"timestamp":"1729096620.0","poster":"pinimichele01","content":"Selected Answer: D\nDebugging models: Feature attributions can help detect issues in the data that standard model evaluation techniques would usually miss.","upvote_count":"1","comment_id":"1196696"},{"timestamp":"1721253540.0","poster":"shadz10","content":"Selected Answer: D\nIf you inspect specific instances, and also aggregate feature attributions across your training dataset, you can get deeper insight into how your model works. Consider the following advantages:\n\nDebugging models: Feature attributions can help detect issues in the data that standard model evaluation techniques would usually miss.\nhttps://cloud.google.com/vertex-ai/docs/explainable-ai/overview","upvote_count":"4","comment_id":"1125449"},{"content":"Selected Answer: C\nC. Example-based explanations make more sense in this case than feature based attributions (we want to understand with examples what kind of decisions the model takes; also explore the amount of bias in a visual, understandable way) https://cloud.google.com/vertex-ai/docs/explainable-ai/overview#example-based","timestamp":"1721220720.0","upvote_count":"3","poster":"b1a8fae","comment_id":"1125069"},{"timestamp":"1720847820.0","poster":"pikachu007","upvote_count":"3","content":"Selected Answer: D\nFeature-Level Insights: Feature attributions pinpoint which image regions contribute most to predictions, offering granular understanding of model reasoning.\nBias Detection: Aggregating feature attributions over the entire dataset can reveal systematic biases or patterns of model behavior, helping identify potential fairness issues.\nComplementary to Evaluation Metrics: Combining attributions with standard metrics (e.g., accuracy, precision, recall) provides a comprehensive view of model performance and fairness.","comment_id":"1121367"}],"question_images":[],"answer":"D","url":"https://www.examtopics.com/discussions/google/view/131056-exam-professional-machine-learning-engineer-topic-1-question/","answer_images":[],"answer_ET":"D","unix_timestamp":1705130220,"question_text":"You are using Vertex AI and TensorFlow to develop a custom image classification model. You need the model’s decisions and the rationale to be understandable to your company’s stakeholders. You also want to explore the results to identify any issues or potential biases. What should you do?","exam_id":13,"question_id":152,"choices":{"C":"1. Use Vertex Explainable AI to generate example-based explanations.\n2. Visualize the results of sample inputs from the entire dataset together with the standard model evaluation metrics.","A":"1. Use TensorFlow to generate and visualize features and statistics.\n2. Analyze the results together with the standard model evaluation metrics.","B":"1. Use TensorFlow Profiler to visualize the model execution.\n2. Analyze the relationship between incorrect predictions and execution bottlenecks.","D":"1. Use Vertex Explainable AI to generate feature attributions. Aggregate feature attributions over the entire dataset.\n2. Analyze the aggregation result together with the standard model evaluation metrics."}},{"id":"Tc0mCtsMqK8Y5UCZKKEF","question_images":[],"timestamp":"2024-01-13 08:20:00","answer_description":"","answer_images":[],"answer_ET":"B","isMC":true,"answers_community":["B (82%)","D (18%)"],"question_id":153,"url":"https://www.examtopics.com/discussions/google/view/131057-exam-professional-machine-learning-engineer-topic-1-question/","exam_id":13,"choices":{"D":"Create a logistic regression model in BigQuery ML. Use the ML.CONFUSION_MATRIX function to evaluate the model performance.","C":"Create a linear regression model in BigQuery ML. Use the ML.EVALUATE function to evaluate the model performance.","B":"Create a logistic regression model in BigQuery ML and register the model in Vertex AI Model Registry. Evaluate the model performance in Vertex AI .","A":"Create a linear regression model in BigQuery ML, and register the model in Vertex AI Model Registry. Evaluate the model performance in Vertex AI ."},"unix_timestamp":1705130400,"question_text":"You work for a large retailer, and you need to build a model to predict customer chum. The company has a dataset of historical customer data, including customer demographics purchase history, and website activity. You need to create the model in BigQuery ML and thoroughly evaluate its performance. What should you do?","topic":"1","discussion":[{"upvote_count":"3","content":"Selected Answer: B\nB is the definitive answer. By breaking down the question we know it is a classification problem, so A and C are wrong since they're linear regression.\n\nUsing confusion matrix to evaluate the model is not wrong (actually it's even the textbook answer to do it), but it is not enough if you want to thoroughly evaluate its performance. Hence the best way to do it is with Vertex AI.","comment_id":"1285178","poster":"Dirtie_Sinkie","timestamp":"1726573380.0"},{"comment_id":"1199212","content":"Selected Answer: B\nlogistic since it's classification, and Vertex AI because we need to \"thoroughly evaluate its performance\"","timestamp":"1713626700.0","upvote_count":"4","poster":"gscharly"},{"poster":"fitri001","comment_id":"1197624","timestamp":"1713404460.0","upvote_count":"1","content":"Selected Answer: B\nLogistic Regression: While linear regression (option C) can be used for continuous prediction tasks, customer churn is a binary classification problem (churned/not churned). Logistic regression is a better fit for this scenario.\nVertex AI Model Registry: Registering the model in Vertex AI Model Registry provides a centralized location for model management, versioning, and potentially future deployment to other Vertex AI services.\nVertex AI Evaluation: Vertex AI offers more comprehensive evaluation tools than BigQuery ML's ML.EVALUATE function (option C) or ML.CONFUSION_MATRIX function (option D). Vertex AI can provide metrics like accuracy, ROC-AUC, precision, and recall, which are crucial for churn prediction evaluation."},{"content":"Selected Answer: B\nMy Answer: B\n\npredict customer churn, which is a binary classification problem (whether a customer will churn or not). And, the phrase \"thoroughly evaluate its performance\" does suggest a more comprehensive approach, and in that sense, option B could be seen as a better answer than D.","comment_id":"1151303","upvote_count":"1","poster":"guilhermebutzke","timestamp":"1708032240.0"},{"poster":"BlehMaks","upvote_count":"1","timestamp":"1705616640.0","comment_id":"1126257","content":"Selected Answer: B\nB because Vertex AI provides us with more functions to evaluate model performance then just CONFUSION_MATRIX \n https://cloud.google.com/vertex-ai/docs/evaluation/introduction#classification_1"},{"timestamp":"1705503540.0","comment_id":"1125076","content":"Selected Answer: B\nB.\nLinear regression because customer churn is a number of customers (not just 1/0). The key here imo is \"thoroughly evaluate performance\", which Vertex AI seems to be better suited for than BQ (including the possibility of tracking experiment lineage, inspecting parameter selection of each run, etc)","upvote_count":"4","poster":"b1a8fae"},{"content":"Selected Answer: D\nCustomer churn prediction involves a binary classification task (whether a customer will churn or not). Logistic regression is specifically designed for this type of problem, making it the appropriate model.\n\nBigQuery ML allows building and training logistic regression models directly within BigQuery, leveraging its scalability and SQL-like syntax for model development.","poster":"pikachu007","timestamp":"1705130400.0","comment_id":"1121372","upvote_count":"3"}],"answer":"B"},{"id":"yQbLkPYDzcgmoqMDzFU7","question_images":[],"topic":"1","answer_ET":"D","url":"https://www.examtopics.com/discussions/google/view/131058-exam-professional-machine-learning-engineer-topic-1-question/","timestamp":"2024-01-13 08:23:00","discussion":[{"upvote_count":"16","comment_id":"1121373","timestamp":"1705130580.0","poster":"pikachu007","content":"Selected Answer: D\nNot A or B since automl doesnt provide you without flexibility to tune.\n\nNot C because object detection is not required since the images are cropped to a single traffic light"},{"upvote_count":"1","poster":"kornick","comment_id":"1339777","content":"Selected Answer: D\nNot C because object detection is not required since the images are cropped to a single traffic light","timestamp":"1736735640.0"},{"content":"Selected Answer: C\nC.\n\"identify\" a small signal is an object detection task, not a classification task.","poster":"shaoshao","timestamp":"1734622020.0","upvote_count":"1","comment_id":"1329020"},{"content":"Selected Answer: D\nAnswer is D, not C in my opinion. Object detection might be used in a real-world project since there are a lot of variables which may affect the picture like visibility, colour fading, having other things in the picture like streetlights, birds, etc. Way too overkill for our question here. I'm assuming the pictures are already nicely cropped out with none of this extra stuff in the pictures.","comment_id":"1285186","upvote_count":"1","timestamp":"1726573980.0","poster":"Dirtie_Sinkie"},{"timestamp":"1726233000.0","comment_id":"1283181","upvote_count":"2","content":"Selected Answer: C\nThere is literally no way to know if this is C or D, as \"labelled\" and \"identify street signs\" are too ambiguous to know if its detection or classification. The \"cropped to a single traffic light\" seems like maybe D, but that's hardly ML knowledge, it's a pub quiz guess.","poster":"baimus"},{"content":"Selected Answer: D\nagree with pikachu007","timestamp":"1713626880.0","comment_id":"1199214","upvote_count":"1","poster":"gscharly"},{"content":"Selected Answer: D\nNot C because object detection is not required since the images are cropped to a single traffic light","comment_id":"1191709","upvote_count":"1","poster":"pinimichele01","timestamp":"1712596560.0"},{"timestamp":"1708033140.0","content":"Selected Answer: C\nCorrect: C\n\nThe phrases \"identify traffic signs in images extracted from videos\" and \"images that were cropped to show one out of ten different traffic signs\" suggest that this is an image detection problem. The first phrase appears to have the same meaning as \"images with,\" and the second phrase suggests that only one type of traffic sign was used in the problem, indicating that it cannot be used in a multi-class problem. For all these reasons, I believe the best option is C.","comment_id":"1151309","poster":"guilhermebutzke","upvote_count":"3"}],"answer":"D","choices":{"C":"Develop the model training code for object detection, and train a model by using Vertex AI custom training.","B":"Train a model for image classification by using Vertex AI AutoML.","A":"Train a model for object detection by using Vertex AI AutoML.","D":"Develop the model training code for image classification, and train a model by using Vertex AI custom training."},"answers_community":["D (77%)","C (23%)"],"question_id":154,"unix_timestamp":1705130580,"answer_description":"","answer_images":[],"isMC":true,"exam_id":13,"question_text":"You are developing a model to identify traffic signs in images extracted from videos taken from the dashboard of a vehicle. You have a dataset of 100,000 images that were cropped to show one out of ten different traffic signs. The images have been labeled accordingly for model training, and are stored in a Cloud Storage bucket. You need to be able to tune the model during each training run. How should you train the model?"},{"id":"yClkyQyoG2UCZoJAifqk","timestamp":"2024-01-13 08:25:00","choices":{"B":"Increase the number of workers in your model server","D":"Increase the minReplicaCount in your DeployedModel configuration","C":"Schedule scaling of the nodes to match expected demand","A":"Attach a GPU to the prediction nodes"},"topic":"1","answers_community":["B (53%)","A (41%)","6%"],"answer":"B","discussion":[{"comments":[{"content":"sorry clicked wrong, answer is B","timestamp":"1706694540.0","poster":"sonicclasps","comment_id":"1136605","upvote_count":"3"}],"timestamp":"1706694480.0","upvote_count":"7","poster":"sonicclasps","content":"Selected Answer: A\n\"We generally recommend starting with one worker or thread per core. If you notice that CPU utilization is low, especially under high load, or your model is not scaling up because CPU utilization is low, then increase the number of workers.\"\nhttps://cloud.google.com/vertex-ai/docs/general/deployment","comment_id":"1136603"},{"poster":"f084277","comment_id":"1312395","upvote_count":"2","content":"Selected Answer: B\nB. One worker isn't enough to saturate the CPU and so no scaling is triggered.","timestamp":"1731642840.0"},{"comment_id":"1197626","timestamp":"1713404940.0","poster":"fitri001","content":"Selected Answer: B\nagree with sonicclasps -> B","upvote_count":"1"},{"content":"Selected Answer: B\nagree with sonicclasps -> B","comment_id":"1194969","timestamp":"1713013080.0","comments":[{"upvote_count":"1","content":"NOT D: This might help ensure at least one replica is always available, but it won't address the issue of not scaling up during high load.","poster":"pinimichele01","timestamp":"1713718440.0","comment_id":"1199769"}],"poster":"pinimichele01","upvote_count":"1"},{"timestamp":"1708946580.0","upvote_count":"2","poster":"Carlose2108","content":"Selected Answer: B\nI went B","comment_id":"1159630"},{"timestamp":"1708039080.0","poster":"guilhermebutzke","upvote_count":"1","content":"Selected Answer: C\nMy answer: C\n\nThe problem is in scale. The provided resources areok. So,\n\nA: Not correct, because CPU is enough.\n\nB: Not correct, because increasing the number of workers will accelerate the process in a single replica, and make the time of prediction faster for example, but not will happen in scale problem.\n\nC:Correct: This option involves adjusting the scaling of resources to match the expected demand, ensuring that the system can handle increased loads effectively\n\nD: This might help ensure at least one replica is always available, but it won't address the issue of not scaling up during high load.","comment_id":"1151615"},{"timestamp":"1705130700.0","upvote_count":"3","poster":"pikachu007","content":"Selected Answer: B\nLow CPU Utilization: Despite high load, low CPU utilization indicates underutilization of available resources, suggesting a bottleneck within the model server itself, not overall compute capacity.\nWorker Concurrency: Increasing the number of workers within the model server allows it to handle more concurrent requests, effectively utilizing available CPU resources and addressing the bottleneck.","comment_id":"1121375","comments":[{"content":"i don't get it. The autoscaling system should increase/decrease the number of workers itself. if we do it instead of the autoscaling system, why do we need it?","comment_id":"1126700","timestamp":"1705671540.0","upvote_count":"1","poster":"BlehMaks"},{"content":"Not scaling beyond one replica is symptom and not the source of the problem. The problem is low CPU utilization.","timestamp":"1720986960.0","poster":"asmgi","upvote_count":"1","comment_id":"1247953"}]}],"isMC":true,"question_text":"You have deployed a scikit-team model to a Vertex AI endpoint using a custom model server. You enabled autoscaling: however, the deployed model fails to scale beyond one replica, which led to dropped requests. You notice that CPU utilization remains low even during periods of high load. What should you do?","question_id":155,"answer_ET":"B","exam_id":13,"question_images":[],"url":"https://www.examtopics.com/discussions/google/view/131059-exam-professional-machine-learning-engineer-topic-1-question/","unix_timestamp":1705130700,"answer_description":"","answer_images":[]}],"exam":{"numberOfQuestions":304,"isImplemented":true,"isBeta":false,"lastUpdated":"11 Apr 2025","provider":"Google","name":"Professional Machine Learning Engineer","id":13,"isMCOnly":true},"currentPage":31},"__N_SSP":true}