{"pageProps":{"questions":[{"id":"7U0WPnNf8OAQ49pbmu7J","answer_ET":"B","exam_id":6,"discussion":[{"comment_id":"1395453","content":"Selected Answer: B\nThe appropriate latency SLO to publish would be 90th percentile - 160 ms and 95th percentile - 300 ms, as these values reflect the current performance measurements over a 28-day window. These values are based on the actual data, and since customers are already happy with the application's performance and availability, it's reasonable to set the SLOs in line with the current performance metrics.","timestamp":"1741907640.0","upvote_count":"1","poster":"cachopo"},{"timestamp":"1741120740.0","comment_id":"1365114","content":"Selected Answer: C\nSLO should never be the same as current performance. You should always leave some room for error budget.","poster":"Mileke","upvote_count":"1"},{"timestamp":"1740025020.0","upvote_count":"2","content":"Selected Answer: C\nWhen setting up SLO based on SLI, there should be some margin, but not too much. Therefore C","poster":"LONGBOW_RA","comment_id":"1359086"},{"upvote_count":"1","comment_id":"1356135","poster":"bartrek","timestamp":"1739454360.0","content":"Selected Answer: C\nC since B does not provide any error budget at all and D seem too relaxed"},{"content":"Selected Answer: B\nIn B SLO makes sense because it pushes engineering teams to maintain strong performance. Then, a more relaxed SLA could be introduced to reduce financial risk, and so that consumers don´t assume current performance as the SLA.","comment_id":"1349192","upvote_count":"2","timestamp":"1738264680.0","poster":"ricardovazz"}],"timestamp":"2025-01-30 20:18:00","answer":"C","question_id":76,"unix_timestamp":1738264680,"answer_images":[],"answers_community":["C (57%)","B (43%)"],"question_text":"You need to define SLOs for a high-traffic web application. Customers are currently happy with the application performance and availability. Based on current measurement, the 90th percentile of latency is 160 ms and the 95th percentile of latency is 300 ms over a 28-day window. What latency SLO should you publish?","url":"https://www.examtopics.com/discussions/google/view/155724-exam-professional-cloud-devops-engineer-topic-1-question-167/","isMC":true,"answer_description":"","topic":"1","question_images":[],"choices":{"D":"90th percentile - 300 ms\n95th percentile - 450 ms","B":"90th percentile - 160 ms\n95th percentile - 300 ms","A":"90th percentile - 150 ms\n95th percentile - 290 ms","C":"90th percentile - 190 ms\n95th percentile - 330 ms"}},{"id":"mjfkkGn2t0XjDbFOkDuA","unix_timestamp":1737691320,"topic":"1","answer_ET":"D","question_images":[],"choices":{"A":"Configure Cloud Build with a Terraform builder to execute the terraform plan and terraform apply commands.","B":"Install and configure Crossplane in GKE.","C":"Configure a GitHub Action with a Terraform builder to execute the terraform plan and terraform apply commands as part of the pull request process.","D":"Install and configure Config Connector in GKE."},"question_id":77,"answer_description":"","isMC":true,"exam_id":6,"discussion":[{"comment_id":"1400090","poster":"09bd94b","content":"Selected Answer: D\nD is the right choice","upvote_count":"1","timestamp":"1742295780.0"},{"upvote_count":"1","comment_id":"1395455","timestamp":"1741907820.0","content":"Selected Answer: D\nInstalling and configuring Config Connector in GKE is the best option. Config Connector allows you to manage Google Cloud resources using Kubernetes Custom Resource Definitions (CRDs). It integrates tightly with GKE, enabling developers to define, deploy, and manage Google Cloud resources as Kubernetes resources. This aligns with Google-recommended practices for managing infrastructure as code, and it is supported by the Google Cloud Support Portal, ensuring that your organization can get the necessary support for any issues.","poster":"cachopo","comments":[{"upvote_count":"1","poster":"cachopo","content":"A\nConfiguring Cloud Build with a Terraform builder is useful for managing infrastructure as code, but it doesn’t align with the goal of managing resources using Kubernetes CRDs. This approach would also not integrate as seamlessly with GKE as Config Connector does, and it doesn’t directly provide support for the CRD-based setup you’re looking for.","timestamp":"1741907880.0","comment_id":"1395456","comments":[{"upvote_count":"1","timestamp":"1741907880.0","content":"B\nCrossplane is an alternative to Config Connector and is used for managing cloud resources in a Kubernetes-native way. However, Config Connector is specifically designed and fully supported by Google Cloud for managing Google Cloud resources in GKE, making it a more appropriate choice in this case.","poster":"cachopo","comment_id":"1395457"}]}]}],"answers_community":["D (100%)"],"url":"https://www.examtopics.com/discussions/google/view/155336-exam-professional-cloud-devops-engineer-topic-1-question-168/","answer_images":[],"question_text":"Your company runs applications in Google Kubernetes Engine (GKE). Application developers frequently create cloud resources to support their applications. You need to give developers the ability to manage infrastructure as code while adhering to Google-recommended practices. You want to manage infrastructure as code through Kubernetes Custom Resource Definitions (CRDs) and ensure that your chosen setup can be supported by the Google Cloud Support Portal. What should you do?","timestamp":"2025-01-24 05:02:00","answer":"D"},{"id":"z819vNzbg0KhvODPRHw2","isMC":true,"choices":{"D":"Create a project-level logging sink with a siem Pub/Sub topic as the destination. Set an inclusion filter to include all logs. Repeat for each project.","C":"Create an organization-level aggregated sink with a siem Pub/Sub topic as the destination. Set an inclusion filter to include all logs.","A":"Create an organization-level aggregated sink with a siem log bucket as the destination. Set an inclusion filter to include all logs.","B":"Create a folder-level aggregated sink with a siem Pub/Sub topic as the destination. Set an inclusion filter to include all logs. Repeat for each folder."},"timestamp":"2025-01-15 17:05:00","answer":"C","answer_description":"","answer_ET":"C","exam_id":6,"url":"https://www.examtopics.com/discussions/google/view/154587-exam-professional-cloud-devops-engineer-topic-1-question-169/","discussion":[{"comment_id":"1395460","timestamp":"1741908000.0","content":"Selected Answer: C\nCreating an organization-level aggregated sink with a siem Pub/Sub topic as the destination and setting an inclusion filter to include all logs is the best approach. This will ensure that logs from all existing and future projects within the organization are automatically captured and sent to the SIEM system via Pub/Sub. By setting the sink at the organization level, you ensure that all logs, regardless of which team or project they belong to, are processed by the SIEM without requiring manual configuration for each new project or team.","poster":"cachopo","upvote_count":"1"},{"comment_id":"1359089","content":"Selected Answer: C\nSIEM ingests logs by using Pub/Sub","upvote_count":"1","timestamp":"1740025560.0","poster":"LONGBOW_RA"},{"upvote_count":"2","content":"Selected Answer: C\nsince we are using another app/system , so best to use queue solution in between it i.e pubsub \nso C","poster":"roaming_panda","timestamp":"1736957100.0","comment_id":"1341111"}],"topic":"1","question_images":[],"answer_images":[],"question_text":"Your company runs services on Google Cloud. Each team runs their applications in a dedicated project. New teams and projects are created regularly. Your security team requires that all logs are processed by a security information and event management (SIEM) system. The SIEM ingests logs by using Pub/Sub. You must ensure that all existing and future logs are scanned by the SIEM. What should you do?","answers_community":["C (100%)"],"question_id":78,"unix_timestamp":1736957100},{"id":"4axgb3uTyLtp8OuKeIk2","answer_ET":"A","topic":"1","choices":{"C":"Use the Stackdriver Monitoring API to create custom metrics, and then organize your containers using groups.","A":"Use Stackdriver Kubernetes Engine Monitoring.","D":"Use Stackdriver Logging to export application logs to BigQuery, aggregate logs per container, and then analyze CPU and memory consumption.","B":"Use Prometheus to collect and aggregate logs per container, and then analyze the results in Grafana."},"answer_images":[],"discussion":[{"poster":"danchoif2","content":"* https://cloud.google.com/anthos/clusters/docs/on-prem\nGKE on-prem is also called Anthos clusters on VMware\n\n* https://cloud.google.com/anthos/clusters/docs/on-prem/concepts/logging-and-monitoring\nYou have several logging and monitoring options for your Anthos clusters on VMware:\n+ Cloud Logging and Cloud Monitoring, enabled by in-cluster agents deployed with Anthos clusters on VMware.\n+ Prometheus and Grafana, disabled by default.\n+ Validated configurations with third-party solutions.\n\n=> it means, if not a special situation, the correct should be using the first option: Logging and Monitoring. In this case, we want metrics, so Monitoring (aka. Cloud Monitoring, Stackdriver Monitoring) should be used. We are talking about GKE, so we will use Kubernetest Engine Monitoring (https://cloud.google.com/kubernetes-engine-monitoring).\n\nObviously, A is correct.","upvote_count":"22","comment_id":"437697","comments":[{"comments":[{"poster":"Feliphus","upvote_count":"2","comment_id":"1104496","content":"I agree with @helg, if you check the link: https://cloud.google.com/kubernetes-engine/docs/concepts/observability. It says: \"Note: The provided GKE dashboards only display information for GKE clusters running on Google Cloud. They don't display information for GKE clusters running anywhere else, for example using on-premises or bare-metal servers.\"","comments":[{"content":"I found another link indicating B is the answer, https://cloud.google.com/anthos/clusters/docs/on-prem/1.3/concepts/logging-and-monitoring\nI copy a slice:\nYou have several logging and monitoring options for your GKE on-prem clusters:\n- Cloud Logging and Cloud Monitoring, enabled by in-cluster agents deployed with GKE on-prem.\n- Prometheus and Grafana, disabled by default.\n- Validated configurations with third-party solutions.","comment_id":"1106213","poster":"Feliphus","upvote_count":"2","timestamp":"1719412140.0"}],"timestamp":"1719209700.0"}],"comment_id":"523059","upvote_count":"6","content":"we are talking about GKE and GKE on Premise \nso you need a multi cloud monitoring option not a GKE logging option like A","poster":"helg","timestamp":"1657735500.0"}],"timestamp":"1646213220.0"},{"comment_id":"393265","comments":[{"poster":"raf2121","timestamp":"1644337320.0","comments":[{"upvote_count":"3","comment_id":"523057","content":"nor for A! \nSTackdriver Kub Engine only supports GKE not GKE on premise!","timestamp":"1657735440.0","poster":"helg"}],"upvote_count":"13","comment_id":"421669","content":"Point for discussion : \nGoogle highly recommends Google Logging and monitoring when running workloads only on GKE on-prem and GKE. For applications with component running on GKE on-prem and traditional on-premises infrastructure, other monitoring and logging solutions for an end-to-end view of application can be considered\n\nconsidering what is stated in the question \"GKE cluster deployed on-premises and Google Cloud Platform\", should \"A\" be the answer"}],"timestamp":"1640734500.0","upvote_count":"13","poster":"Charun","content":"B correct"},{"upvote_count":"2","content":"Selected Answer: B\nThe answer will change pre and post GKE 1.24 release.\nIf the question is asked before the release of GKE 1.24 the answer should be A.\nPost GKE 1.24 release metrics deprecated, B is the answer.","timestamp":"1725707040.0","poster":"jinaldesailive","comment_id":"1168006"},{"poster":"alpha_canary","content":"Selected Answer: A\nIf the on-prem was a non-GKE kubernetes solution, the the answer would be B. \nBut it's GKE on-prem, A is the best option here","comment_id":"1135015","timestamp":"1722253980.0","upvote_count":"2"},{"timestamp":"1717301820.0","comment_id":"1085745","content":"option A","upvote_count":"1","poster":"jomonkp"},{"upvote_count":"2","comment_id":"976210","poster":"SarumanMX","timestamp":"1707457320.0","content":"Selected Answer: B\nGKE workload monitoring has been deprecated, so should be Prometheus\nhttps://cloud.google.com/stackdriver/docs/solutions/gke/managing-metrics"},{"timestamp":"1705651740.0","upvote_count":"2","comment_id":"956296","poster":"Ajitshetty","content":"Selected Answer: B\nIt should be B check this link\nIt is clearly mentioned if you are application running on GKE or anthos cluster on Vmware you use stack driver counter part but if it is on On-prem then better find other solution\nWith respect to options we have here it is prometheus\n\nhttps://cloud.google.com/anthos/clusters/docs/on-prem/latest/concepts/logging-and-monitoring#:~:text=For%20applications%20with%20components%20running%20on%20Anthos%20clusters%20on%20VMware%20and%20traditional%20on%2Dpremises%20infrastructure%2C%20you%20might%20consider%20other%20solutions%20for%20an%20end%2Dto%2Dend%20view%20of%20those%20applications"},{"timestamp":"1697102400.0","content":"Selected Answer: A\nPrometheus is made for metrics not logs, in this way the correct answer is A, not be.","comment_id":"868096","poster":"felipeschossler","comments":[{"comment_id":"938252","poster":"sidharthwader","content":"Its telling to pick which uses most cpu and memory this has nothing to do with logs","comments":[{"upvote_count":"2","timestamp":"1705369260.0","content":"are these questions still relevant?","poster":"aswani","comment_id":"952774"}],"timestamp":"1703867100.0","upvote_count":"1"}],"upvote_count":"1"},{"upvote_count":"2","content":"B. Use Prometheus to collect and aggregate logs per container, and then analyze the results in Grafana.\n\nPrometheus is a popular open-source monitoring and alerting system that is well-suited for monitoring containers running in a Kubernetes cluster. It can scrape metrics from the Kubernetes API server and export them to a time series database, where they can be queried and visualized in Grafana. This approach allows you to monitor CPU and memory usage of individual containers, and set up alerts if usage exceeds certain thresholds.","poster":"taqihurr","comment_id":"785053","timestamp":"1690087860.0"},{"content":"Selected Answer: B\nI think the answer is B.\nA cant be because is not for on premises.","comment_id":"772057","poster":"JonathanSJ","upvote_count":"1","timestamp":"1689046440.0"},{"poster":"floppino","comment_id":"755468","content":"Selected Answer: A\nAns: A\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/","timestamp":"1687670340.0","comments":[{"upvote_count":"1","timestamp":"1690722780.0","poster":"jaykumarjkd99","comment_id":"792963","content":"any way to take dump of the discussions?"}],"upvote_count":"2"},{"comment_id":"727822","poster":"DoodleDo","timestamp":"1685129100.0","content":"Ans A - Anthos GKE On-Prem agent collects systems metric however it doesn't collect applications metric. Given that question asks for CPU and Memory GKE On-Prem agent should suffice of containers in on-prem. Source - https://cloud.google.com/anthos/clusters/docs/on-prem/1.3/concepts/logging-and-monitoring","upvote_count":"1"},{"upvote_count":"1","comment_id":"726300","poster":"hanweiCN","content":"for anthos clusters, need cloud monitoring & cloud logging agent, not GKE monitoring.","timestamp":"1684968540.0"},{"timestamp":"1684968180.0","poster":"hanweiCN","comment_id":"726295","upvote_count":"1","comments":[{"content":"\" Cloud Operations Suite for GKE \" is a tailored cloud monitoring & logging service for GKE. not cloud monitoring & logging service. A is correct.","poster":"hanweiCN","upvote_count":"1","comment_id":"745786","timestamp":"1686805860.0"}],"content":"The Cloud Operations Suite for GKE only displays information for GKE clusters running on Google Cloud. It does not display information for GKE clusters running elsewhere, such as using on-premises or bare metal servers \nhttps://cloud-google-com.translate.goog/stackdriver/docs/solutions/gke?hl=fr&_x_tr_sl=fr&_x_tr_tl=en&_x_tr_hl=en&_x_tr_pto=sc"},{"timestamp":"1684073400.0","poster":"enter_co","comment_id":"718087","content":"Selected Answer: B\nThe eCommerce app is a workload. \nSince v. 1.24 GKE workload metrics were deprecated and replaced with Prometheus https://cloud.google.com/stackdriver/docs/solutions/gke/workload-metrics#gcloud\nhttps://cloud.google.com/stackdriver/docs/solutions/gke/gmp-migration","upvote_count":"1"},{"content":"Selected Answer: A\nI work in the hybrid environment [anthos] and can confirm the required metric availability","poster":"mudot","timestamp":"1683278460.0","comment_id":"711714","upvote_count":"4"},{"timestamp":"1682505900.0","content":"A is correct\nCloud Operations for GKE is designed to monitor GKE clusters. It manages Monitoring and Logging services together and features a Cloud Operations for GKE dashboard that provides a customized interface for GKE clusters:\n\nYou can view a cluster's key metrics, such as CPU utilization, memory utilization, and the number of open incidents.\n\nYou can view clusters by their infrastructure, workloads, or services.\n\nYou can inspect namespaces, nodes, workloads, services, pods, and containers.\nFor pods and containers, you can view metrics as a function of time and view log entries.https://cloud.google.com/stackdriver/docs/solutions/gke","poster":"AzureDP900","upvote_count":"1","comment_id":"704578"},{"comment_id":"703056","poster":"zellck","upvote_count":"2","timestamp":"1682343300.0","content":"Selected Answer: A\nA is the answer.\n\nhttps://cloud.google.com/anthos/clusters/docs/on-prem/latest/concepts/logging-and-monitoring#logging_and_monitoring\nGoogle Cloud's operations suite (formerly Stackdriver) is the built-in observability solution for Google Cloud. It offers a fully managed logging solution, metrics collection, monitoring, dashboarding, and alerting. Cloud Monitoring monitors Anthos clusters on VMware clusters in a similar way as cloud-based GKE clusters."},{"comment_id":"637564","poster":"gcp_learner123","content":"\"Note: Cloud Operations for GKE only displays information for GKE clusters running on Google Cloud. It doesn't display information for GKE clusters running anywhere else, for example using on-premise or bare-metal servers.\"\n\n\nSo, A is wrong. Correct ans is B\n\n\nSource: https://cloud.google.com/stackdriver/docs/solutions/gke#about-skm","upvote_count":"1","timestamp":"1674764280.0"},{"comment_id":"635923","content":"Selected Answer: A\nA is correct","poster":"GCP72","upvote_count":"2","timestamp":"1674554460.0"},{"timestamp":"1672204080.0","poster":"[Removed]","comment_id":"623635","content":"Pass exam and Submit B\nThere has a little different about Option A in exam.\nIn exam, Option A was \"Use Cloud Operations for GKE\".\nBut based on description as below:\n\nNote: Cloud Operations for GKE only displays information for GKE clusters running on Google Cloud. It doesn't display information for GKE clusters running anywhere else, for example using on-premise or bare-metal servers.\n\nhttps://cloud.google.com/stackdriver/docs/solutions/gke#about-skm\n\nSo B is better in this question.","upvote_count":"2"},{"content":"Selected Answer: C\nagree with francisco_guerra, gcpengineer, & helg. Cloud operations for GKE only displays information for GKE Clusters running on Google cloud.","upvote_count":"2","timestamp":"1661108220.0","comment_id":"553256","poster":"zygomar"},{"poster":"Nalex9ja","content":"From this documentation, A should be the answer.\nIt is the recommend way. If application logs were to be collected, this solution won't work an Prometheus would have been the desired solution. I this case only system a system metric (CPU utilisation) is required. \nhttps://cloud.google.com/anthos/clusters/docs/on-prem/1.3/concepts/logging-and-monitoring#:~:text=GKE%20on%2Dprem%20includes%20multiple,proper%20solution%20for%20your%20environment.","upvote_count":"1","timestamp":"1658716500.0","comment_id":"531822"},{"content":"C for monitoring containers ..\nA - No because Stackdriver Kubernetes Engine Monitoring only supports GKE (on Google Cloud) - https://cloud.google.com/stackdriver/docs/solutions/gke \nB - nope for prometheus / Grafana (non managed and non GCP solutions) \nD- Nope for logging \nC - Yes - Cloud Monitoring can help https://cloud.google.com/anthos/clusters/docs/on-prem/1.3/concepts/logging-and-monitoring#configure_stackdriver_agents","poster":"helg","timestamp":"1657736040.0","upvote_count":"2","comment_id":"523077"},{"timestamp":"1657735200.0","comment_id":"523052","poster":"helg","upvote_count":"1","content":"No for A! \nNote: Cloud Operations for GKE only displays information for GKE clusters running on Google Cloud. It doesn't display information for GKE clusters running anywhere else, for example using on-premise or bare-metal servers."},{"poster":"simbu1299","content":"Selected Answer: A\nCorrect Answer is A","comment_id":"516672","upvote_count":"3","timestamp":"1656935520.0"},{"upvote_count":"2","timestamp":"1656367980.0","comment_id":"510683","content":"Selected Answer: A\nA is the answer...check GKE monitoring onthe doc","poster":"TNT87"},{"poster":"guid1984","upvote_count":"2","timestamp":"1655810040.0","comment_id":"506120","content":"The question is application is running on Google Kubernetes Engine (GKE) cluster deployed on-premises and also on the Google Cloud Platform, this means we need to add grouping for containers that are running on-prem GKE and also in GKE GCP. Option C is more relevant in this case as compared to A"},{"timestamp":"1654423860.0","content":"Ans : B","upvote_count":"1","comment_id":"494316","poster":"alaahakim"},{"poster":"TNT87","content":"C is he answer, B is not in GCP\nhttps://cloud.google.com/anthos/clusters/docs/on-prem/1.0/concepts/logging-and-monitoring","comment_id":"494150","upvote_count":"1","timestamp":"1654409520.0"},{"comment_id":"486973","content":"Selected Answer: A\nCloud Logging and Cloud Monitoring, enabled by in-cluster agents deployed with GKE on-prem.\n\nReference:https://cloud.google.com/anthos/clusters/docs/on-prem/1.5/concepts/logging-and-monitoring","upvote_count":"2","poster":"muk5658","timestamp":"1653512520.0"},{"content":"Selected Answer: A\nhttps://cloud.google.com/anthos/clusters/docs/on-prem/1.9/concepts/logging-and-monitoring#logging_and_monitoring","upvote_count":"2","comment_id":"479975","poster":"awrgdasfg","timestamp":"1652778840.0"},{"upvote_count":"2","poster":"Biden","timestamp":"1652374920.0","content":"Answer is A. Reason - this statement \"We highly recommend Logging and Monitoring when running workloads only on GKE on-prem, or workloads on GKE and GKE on-prem. For applications with components running on GKE on-prem and traditional on-premises infrastructure, you might consider other solutions for an end-to-end view of those applications.\"\nTHis question is about app running on GKE on-prem & GKE on Cloud - hence answer is A\nReference: https://cloud.google.com/anthos/clusters/docs/on-prem/1.5/concepts/logging-and-monitoring","comment_id":"477123"},{"comments":[{"content":"Read the article you posted - pod metrics are not exported.","comment_id":"532834","timestamp":"1658828040.0","upvote_count":"1","poster":"pddddd"}],"upvote_count":"1","timestamp":"1652140560.0","poster":"Manh","comment_id":"475164","content":"it's should be A\n\nOptions for GKE on-prem\nYou have several logging and monitoring options for your GKE on-prem clusters:\n\nCloud Logging and Cloud Monitoring, enabled by in-cluster agents deployed with GKE on-prem.\nPrometheus and Grafana, disabled by default.\nValidated configurations with third-party solutions.\nhttps://cloud.google.com/anthos/clusters/docs/on-prem/1.5/concepts/logging-and-monitoring#stackdriver_gkeop"},{"comment_id":"440882","upvote_count":"2","poster":"MF2C","content":"B- You have several logging and monitoring options for your GKE On-Prem clusters:\n\nCloud Logging and Cloud Monitoring, enabled by in-cluster agents deployed with GKE On-Prem.\nPrometheus and Grafana, enabled by default in new clusters.","timestamp":"1646660100.0"},{"timestamp":"1646291940.0","content":"B\nhttps://cloud.google.com/anthos/clusters/docs/on-prem/1.7/concepts/logging-and-monitoring","comment_id":"438280","poster":"TNT87","upvote_count":"2"},{"comment_id":"415523","content":"1. both prometheus & stackdriver need to be configured\n2. Prometheus doesn't collect & aggregate logs, it only plays metrics.\n3. stackdriver is a default component for GKE on-prem\nI would choose C.","timestamp":"1643300400.0","upvote_count":"3","poster":"grace_lau"},{"comment_id":"394760","poster":"WakandaF","content":"Monitoring(Stackdriver) allows you to view and address that type of behavior, but yes you need to have Anthos!\nNot sure if is A or B?","comments":[{"poster":"[Removed]","comment_id":"418266","content":"The application runs on a large Google Kubernetes Engine (GKE) cluster deployed on-premises and on Google Cloud Platform ==> so they use Anthos (GKE on PREM = Anthos).\nThe answer is A.","upvote_count":"4","timestamp":"1643728800.0"}],"timestamp":"1640877900.0","upvote_count":"2"},{"content":"A - because CPU and memory are standard metrics, you shouldn't need to create any custom metric for them. And as holahola mentioned, \"Cloud Monitoring monitors GKE on-prem clusters in a similar way as cloud-based GKE clusters.\" \nhttps://cloud.google.com/anthos/clusters/docs/on-prem/1.7/concepts/logging-and-monitoring","timestamp":"1640394060.0","poster":"guruguru","comments":[{"comment_id":"394124","timestamp":"1640807640.0","poster":"francisco_guerra","upvote_count":"2","content":"Like you say Cloud monitoring is not the same that Kubernetes engine monitoring"}],"upvote_count":"3","comment_id":"389967"},{"poster":"francisco_guerra","timestamp":"1640049600.0","upvote_count":"4","content":"Ans: C\n\nA: No, Cloud Operations for GKE (Stackdriver Kubernetes Engine Monitoring)only displays information for GKE clusters running on Google Cloud. It doesn't display information for GKE clusters running anywhere else, for example using on-premise or bare-metal servers.\n\nB: Google only recommed prometeus and Grafana if you have previous knowledge about it\nC: Correct its the Google's recommendation \nD: You want to monitoring\n\nhttps://cloud.google.com/stackdriver/docs/solutions/gke\n\nhttps://cloud.google.com/anthos/clusters/docs/on-prem/1.7/concepts/logging-and-monitoring","comment_id":"386614","comments":[{"comment_id":"423322","upvote_count":"1","timestamp":"1644591300.0","poster":"gcpengineer","content":"stackdiver monitoring displays GKE on prem."}]},{"content":"A - because \"Cloud Monitoring monitors GKE on-prem clusters in a similar way as cloud-based GKE clusters.\" It includes CPU and RAM utilization. https://cloud.google.com/anthos/clusters/docs/on-prem/1.5/concepts/logging-and-monitoring.\nPrometheus and grafana - disabled by default.","comment_id":"384787","poster":"holahola","upvote_count":"5","timestamp":"1639835880.0"},{"upvote_count":"6","timestamp":"1639745760.0","comment_id":"384119","poster":"ralf_cc","content":"C - workload is only on GKE, https://cloud.google.com/anthos/clusters/docs/on-prem/1.0/concepts/logging-and-monitoring"},{"content":"Answer -B\n\nhttps://cloud.google.com/anthos/clusters/docs/on-prem/1.5/concepts/logging-and-monitoring","timestamp":"1639314300.0","upvote_count":"1","poster":"akg001","comment_id":"380400"},{"comment_id":"372832","upvote_count":"2","content":"B because on gcp it provides stack driver by default but on premise we need to setup promotheus and graphana to monitor metrics like cpu memory etc","poster":"devopsbatch","timestamp":"1638466380.0"}],"timestamp":"2021-06-02 17:33:00","question_images":[],"exam_id":6,"answers_community":["A (69%)","B (25%)","6%"],"question_text":"You support an e-commerce application that runs on a large Google Kubernetes Engine (GKE) cluster deployed on-premises and on Google Cloud Platform. The application consists of microservices that run in containers. You want to identify containers that are using the most CPU and memory. What should you do?","unix_timestamp":1622647980,"isMC":true,"answer":"A","question_id":79,"url":"https://www.examtopics.com/discussions/google/view/54245-exam-professional-cloud-devops-engineer-topic-1-question-17/","answer_description":""},{"id":"luXIQc0u2PU52UTnIEEH","answers_community":["D (100%)"],"exam_id":6,"question_id":80,"topic":"1","answer_ET":"D","unix_timestamp":1742860140,"url":"https://www.examtopics.com/discussions/google/view/169788-exam-professional-cloud-devops-engineer-topic-1-question-170/","answer":"D","question_text":"Your company allows teams to self-manage Google Cloud projects, including project-level Identity and Access Management (IAM). You are concerned that the team responsible for the Shared VPC project might accidentally delete the project, so a lien has been placed on the project. You need to design a solution to restrict Shared VPC project deletion to those with the resourcemanager.projects.updateLiens permission at the organization level. What should you do?","answer_images":[],"answer_description":"","discussion":[{"content":"Selected Answer: D\nD. Enable the compute.restrictXpnProjectLienRemoval organization policy constraint.","poster":"kitaharazyl","upvote_count":"1","comment_id":"1409843","timestamp":"1742860140.0"}],"question_images":[],"choices":{"D":"Enable the compute.restrictXpnProjectLienRemoval organization policy constraint.","C":"Revoke the resourcemanager.projects.updateLiens permission from all users associated with the project.","B":"Enable VPC Service Controls for the container.googleapis.com API service.","A":"Instruct teams to only perform IAM permission management as code with Terraform."},"isMC":true,"timestamp":"2025-03-25 00:49:00"}],"exam":{"numberOfQuestions":196,"isMCOnly":true,"lastUpdated":"11 Apr 2025","id":6,"provider":"Google","isBeta":false,"isImplemented":true,"name":"Professional Cloud DevOps Engineer"},"currentPage":16},"__N_SSP":true}