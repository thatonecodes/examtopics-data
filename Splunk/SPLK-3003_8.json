{"pageProps":{"questions":[{"id":"RkJ1sWEw4FWui5jjJDqn","answer_images":[],"answers_community":["D (100%)"],"answer_ET":"B","unix_timestamp":1617492900,"choices":{"A":"Monitoring (via a process), collecting data (modular inputs) from remote systems/applications","D":"splunktcp, splunktcp-ssl, HTTP Event Collector (HEC)","C":"Actively listening on ports, monitoring (via a process), collecting data from remote systems/applications","B":"Modular inputs, HTTP Event Collector (HEC), inputs.conf monitor stanza"},"answer":"D","question_id":36,"topic":"1","question_text":"As a best practice which of the following should be used to ingest data on clustered indexers?","discussion":[{"comment_id":"518410","upvote_count":"6","content":"Answer should be D","poster":"Vatsal001","timestamp":"1657120320.0"},{"content":"Selected Answer: D\nmust be D. ref: https://docs.splunk.com/Documentation/Splunk/9.2.0/Indexer/Indexerclusterinputs . while it is possible to use inputs.conf (B) it is not best practice for several reasons (e.g \"To handle potential node failure\"). see the link for details","upvote_count":"1","comment_id":"1137503","poster":"hpbdcb","timestamp":"1722500820.0"},{"comment_id":"959203","timestamp":"1705909080.0","poster":"sutcocuk","content":"It's not recommended to use modular inputs on Clustered Indexers, because each indexer will ingest data and that means you have duplicate data. For HEC you use a load-balancer to prevent ingest duplicate data and better to also prevent single point of failure.","upvote_count":"1"},{"comment_id":"829727","content":"The recommended method to ingest data on clustered indexers in Splunk is to use option B, which includes Modular inputs, HTTP Event Collector (HEC), and inputs.conf monitor stanza.\n\nModular inputs are scripts or executables that can be run on remote systems to collect data and send it to Splunk. HEC is a data ingestion method that enables external systems to send data directly to Splunk via a REST API over HTTP or HTTPS. Inputs.conf monitor stanza is used to monitor local and network files for changes and ingest the data into Splunk.\n\nOptions A and C are not recommended because they involve collecting data actively by monitoring systems and listening on ports. This approach can be resource-intensive and may affect the performance of the clustered indexers.\n\nOption D includes Splunk TCP and TCP-SSL, which are not commonly used for data ingestion on clustered indexers. These protocols are typically used for data forwarding between Splunk instances or for inputs that require secure communication, such as Splunk Enterprise Security.","upvote_count":"1","timestamp":"1693893540.0","poster":"jcisco123"},{"timestamp":"1633304100.0","poster":"bigdo","comment_id":"327644","upvote_count":"1","content":"b http collector"}],"question_images":[],"answer_description":"","isMC":true,"exam_id":206,"timestamp":"2021-04-04 01:35:00","url":"https://www.examtopics.com/discussions/splunk/view/48992-exam-splk-3003-topic-1-question-41-discussion/"},{"id":"Bdij1J8jhiUMqJQfxl6B","question_images":[],"answer_images":[],"url":"https://www.examtopics.com/discussions/splunk/view/41493-exam-splk-3003-topic-1-question-42-discussion/","answers_community":["D (100%)"],"exam_id":206,"unix_timestamp":1609772100,"answer_ET":"D","choices":{"A":"The new search head connects to the captain and replays any recent configuration changes to bring it up to date.","C":"The new search head connects to the captain and pulls the most recently deployed bundle. It then connects to the deployer and replays any recent configuration changes to bring it up to date.","B":"The new search head connects to the deployer and replays any recent configuration changes to bring it up to date.","D":"The new search head connects to the deployer and pulls the most recently deployed bundle. It then connects to the captain and replays any recent configuration changes to bring it up to date."},"discussion":[{"comment_id":"259453","poster":"Giodada","upvote_count":"6","content":"D is correct\nhttps://docs.splunk.com/Documentation/Splunk/8.1.1/DistSearch/Addaclustermember","timestamp":"1625403300.0"},{"comment_id":"1214791","content":"Selected Answer: D\nCheck the Post-add activity in the documentation:\nhttps://docs.splunk.com/Documentation/Splunk/latest/DistSearch/Addaclustermember#Post-add_activity","upvote_count":"1","timestamp":"1732182360.0","poster":"bobixaka"},{"upvote_count":"3","comment_id":"662922","timestamp":"1678233240.0","poster":"frappe","content":"Selected Answer: D\nDeployed first, then captain"},{"upvote_count":"2","comment_id":"605775","poster":"Redtonyeah","timestamp":"1669177500.0","content":"D, page 431 SCI"},{"poster":"jbabbin","upvote_count":"1","timestamp":"1627604940.0","comment_id":"279700","content":"Agree D \nPost-add activity\nAfter the member joins or rejoins the cluster, it applies all replicated and deployed configuration updates:\n\n1. It contacts the deployer to get the configuration bundle.\n\n2. It contacts the captain and downloads the replicated configuration tarball."},{"poster":"simplekindaman","content":"Correct... the answer is D","timestamp":"1627601520.0","comment_id":"279680","upvote_count":"1"}],"question_id":37,"answer_description":"","isMC":true,"answer":"D","timestamp":"2021-01-04 15:55:00","topic":"1","question_text":"When adding a new search head to a search head cluster (SHC), which of the following scenarios occurs?"},{"id":"ac0Df0omRP25zfuI8LJb","isMC":true,"discussion":[{"content":"Selected Answer: C\ncrystal clear","comment_id":"1137509","timestamp":"1722501000.0","poster":"hpbdcb","upvote_count":"1"},{"poster":"Hamiltonian","comment_id":"1021324","upvote_count":"1","timestamp":"1711791240.0","content":"They are only specifying the connection to the LDAP server and nothing about role mappings. Thus: C"},{"poster":"wiz386","comment_id":"646989","content":"should be D","timestamp":"1676435580.0","upvote_count":"2"},{"comment_id":"608997","timestamp":"1669783440.0","poster":"Redtonyeah","upvote_count":"4","content":"C is OK"},{"upvote_count":"4","poster":"SasnycoN","timestamp":"1662549600.0","comment_id":"562638","content":"Answer is \"C\""},{"poster":"Danny52","comment_id":"407329","comments":[{"content":"Wrong, in the worts case should be D because you need to map the roles. But as I understood they are talking about authentication only so I would rather C in this case.","poster":"chuchoneitor","comment_id":"441336","upvote_count":"4","comments":[{"timestamp":"1662023460.0","upvote_count":"3","poster":"LearningDani","comment_id":"558694","content":"Role mapping is also done in authentication.conf. So no need to touch the authorize.conf -> C"}],"timestamp":"1646736720.0"},{"poster":"pbandj12","content":"D is the answer, B is super wrong","comment_id":"445192","timestamp":"1647353760.0","upvote_count":"1","comments":[{"comment_id":"445193","upvote_count":"1","timestamp":"1647353820.0","poster":"pbandj12","content":"Sorry I meant, C!!!!!"}]}],"upvote_count":"1","timestamp":"1642274760.0","content":"It is B"}],"answers_community":["C (100%)"],"topic":"1","timestamp":"2021-07-15 19:26:00","question_images":[],"answer_description":"Reference:\nhttps://docs.splunk.com/Documentation/Splunk/8.1.0/Security/ConfigureLDAPwithconfigurationfiles","exam_id":206,"question_text":"A customer wants to migrate from using Splunk local accounts to use Active Directory with LDAP for their Splunk user accounts instead. Which configuration files must be modified to connect to an Active Directory LDAP provider?","question_id":38,"answer_images":[],"choices":{"D":"authorize.conf, authentication.conf","B":"authentication.conf, ldap.conf","C":"authentication.conf","A":"authentication.conf, authorize.conf, ldap.conf"},"unix_timestamp":1626369960,"answer_ET":"C","answer":"C","url":"https://www.examtopics.com/discussions/splunk/view/57959-exam-splk-3003-topic-1-question-43-discussion/"},{"id":"vXDkUrJ4bsl2VieDez3x","question_text":"A customer has a number of inefficient regex replacement transforms being applied. When under heavy load the indexers are struggling to maintain the expected indexing rate. In a worst case scenario, which queue(s) would be expected to fill up?","answer_images":[],"discussion":[{"timestamp":"1609773240.0","content":"C is correct\nhttps://wiki.splunk.com/Community:HowIndexingWorks","upvote_count":"8","comment_id":"259471","poster":"Giodada"},{"content":"There is no such thing as a \"merging\" or \"input\" queue. There is the \"input\" pipeline that gets to the parsingQueue [utf8 processor, line breaker, header parsing], then to the aggregationQueue [date parsing and line merging], then typingQueue [regex replacement, punct:: addition], then to the indexQueue [tcp output, syslog output, http output, block signing, indexing, indexing metrics] and finally to disk.","upvote_count":"1","timestamp":"1725318540.0","poster":"memel0sky","comment_id":"1277056"},{"content":"I think it's A. A regex problem would cause the Typing queue to fill up first (answer C) BUT if this is a worst-case scenario then every queue before that (Parsing and Merging) would also get blocked. So it has to be more than just the Typing queue, and A is the only other one that fits.\nI'm assuming that when they say 'input', they mean that the forwarders would also not be able to send any more data to the Indexers so their queues would fill up as well","poster":"M9201715","timestamp":"1674592020.0","comment_id":"786925","upvote_count":"2"},{"poster":"cornripper","timestamp":"1671400020.0","content":"C, this is a tricky question. Indexing would not fill up because nothing would make it past the typing queue and input is not a queue. So therefore, the only logical answer is C.","upvote_count":"2","comment_id":"749212"},{"poster":"frappe","content":"Selected Answer: A\nIf indexers are slogging because of a blockage in the Typing pipeline, then worst-case scenario means Typing, Merging, Parsing, and Input queues would soon be filling up, while the Indexing queue would be practically empty.","upvote_count":"3","comment_id":"662924","timestamp":"1662587940.0"},{"comment_id":"464432","upvote_count":"1","content":"C is correct, refer https://wiki.splunk.com/Community:HowIndexingWorks\ntyping pipeline","timestamp":"1634612460.0","poster":"nutsu"},{"comment_id":"279681","upvote_count":"1","timestamp":"1611970500.0","content":"Agreed this is C","poster":"simplekindaman"},{"upvote_count":"2","content":"C is correct","timestamp":"1611646380.0","poster":"Nemo72","comment_id":"276691"}],"question_id":39,"choices":{"B":"Parsing","D":"Indexing, typing, merging, parsing, input","C":"Typing","A":"Typing, merging, parsing, input"},"question_images":[],"answer_description":"","topic":"1","isMC":true,"answers_community":["A (100%)"],"exam_id":206,"unix_timestamp":1609773240,"answer":"A","url":"https://www.examtopics.com/discussions/splunk/view/41498-exam-splk-3003-topic-1-question-44-discussion/","answer_ET":"A","timestamp":"2021-01-04 16:14:00"},{"id":"ktq8oTUnwyxcBa5HrHQT","answer":"C","timestamp":"2021-01-17 10:55:00","answer_images":[],"exam_id":206,"isMC":true,"question_id":40,"url":"https://www.examtopics.com/discussions/splunk/view/42603-exam-splk-3003-topic-1-question-45-discussion/","question_images":[],"choices":{"D":"Step 8","A":"Step 2","B":"Step 4","C":"Step 6"},"answers_community":["C (100%)"],"answer_description":"","topic":"1","answer_ET":"C","unix_timestamp":1610877300,"question_text":"A new single-site three indexer cluster is being stood up with replication_factor:2, search_factor:2. At which step would the Indexer Cluster be classed as \"˜Indexing Ready' and be able to ingest new data?\nStep 1: Install and configure Cluster Master (CM)/Master Node with base clustering stanza settings, restarting CM.\nStep 2: Configure a base app in etc/master-apps on the CM to enable a splunktcp input on port 9997 and deploy index creation configurations.\nStep 3: Install and configure Indexer 1 so that once restarted, it contacts the CM, download the latest config bundle.\nStep 4: Indexer 1 restarts and has successfully joined the cluster.\nStep 5: Install and configure Indexer 2 so that once restarted, it contacts the CM, downloads the latest config bundle\nStep 6: Indexer 2 restarts and has successfully joined the cluster.\nStep 7: Install and configure Indexer 3 so that once restarted, it contacts the CM, downloads the latest config bundle.\nStep 8: Indexer 3 restarts and has successfully joined the cluster.","discussion":[{"timestamp":"1725746520.0","poster":"frappe","comment_id":"662926","content":"Selected Answer: C\ningest blocked on peers connected to manager mode before RF/SF is met, thus two peers are necessary for “indexing ready” state.","upvote_count":"3"},{"upvote_count":"4","comment_id":"276692","content":"C is correct","timestamp":"1674718380.0","poster":"Nemo72","comments":[{"upvote_count":"1","comments":[{"comment_id":"354587","content":"My answer was wrong it is C:\nwhen the Master starts up for the 1st time it will block indexing on the peers until you have enabled and restarted the replication factor number of peers","timestamp":"1683799740.0","poster":"IDM","upvote_count":"2"}],"poster":"IDM","comment_id":"338758","content":"It can start ingesting raw data as soon as the 1st one is up, it won't meet the RF or SF factors until both are up and running","timestamp":"1681897740.0"}]},{"timestamp":"1673949300.0","upvote_count":"2","poster":"v12","content":"should be C, needs 2 peers","comment_id":"269436"}]}],"exam":{"name":"SPLK-3003","lastUpdated":"12 Apr 2025","numberOfQuestions":85,"id":206,"provider":"Splunk","isMCOnly":false,"isImplemented":true,"isBeta":false},"currentPage":8},"__N_SSP":true}