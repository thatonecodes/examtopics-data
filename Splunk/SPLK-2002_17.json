{"pageProps":{"questions":[{"id":"5ga9Gf2OLa44K10t7e5R","choices":{"B":"At least three search heads are needed.","A":"A deployer is required.","C":"Search heads must meet the high-performance reference server requirements.","D":"The deployer must have sufficient CPU and network resources to process service requests and push configurations."},"answer":"AB","topic":"2","answer_ET":"AB","question_images":[],"question_text":"Which of the following statements describe search head clustering? (Select all that apply.)","answer_images":[],"answers_community":["AB (75%)","BD (17%)","8%"],"url":"https://www.examtopics.com/discussions/splunk/view/31112-exam-splk-2002-topic-2-question-10-discussion/","answer_description":"","timestamp":"2020-09-11 23:47:00","discussion":[{"upvote_count":"9","poster":"RedYeti","timestamp":"1666702380.0","content":"Selected Answer: AB\nAnswers A,B,D\nPage 104 Architecting Splunk 8.0.1 Enterprise Deployments","comment_id":"591713"},{"timestamp":"1633709760.0","comment_id":"331345","upvote_count":"5","poster":"manu78","content":"A B and D are required."},{"timestamp":"1722430320.0","upvote_count":"1","comment_id":"1136889","poster":"bobixaka","content":"Selected Answer: AD\nA, B, D\nAnswer B Ref: https://docs.splunk.com/Documentation/Splunk/9.1.3/DistSearch/SHCarchitecture#:~:text=A%20cluster%20must%20consist%20of%20a%20minimum%20of%20three%20members.\n\nAnswer A and D Ref: \nArchitecting Splunk Enterprise Deployments - page 104"},{"poster":"Dak_G","comment_id":"1113928","upvote_count":"1","content":"KiranVM is correct. pg 104 Architecting Splunk slides. For C to be correct it would have to say minimums.","timestamp":"1720106640.0"},{"poster":"deepali_2710","comments":[{"comment_id":"986531","content":"this is the way","upvote_count":"1","poster":"qtygbapjpesdayazko","timestamp":"1708528680.0"}],"content":"A. A deployer is required. Most Voted\nB. At least three search heads are needed. Most Voted\nD. The deployer must have sufficient CPU and network resources to process service requests and push configurations.","timestamp":"1698449580.0","comment_id":"883106","upvote_count":"3"},{"poster":"KiranVM","timestamp":"1695340380.0","content":"A, B ,D\nonly telling the Deployer must have sufficient CPU and network resource, not asking for high performance one.","comment_id":"846569","upvote_count":"2"},{"comment_id":"746717","timestamp":"1686876000.0","content":"Selected Answer: BD\nAnswers is A,B,D. See for yourself, page 104, Architect Enterprise Deployments.pdf. Shows it clearly.","upvote_count":"2","poster":"denominator"},{"upvote_count":"1","content":"A& B\nI would love to see someone explain why d is an actual answer because i don't see anything regarding SHC & cpu/network resource to declare it a SHC\n\nhere \nhttps://docs.splunk.com/Documentation/Splunk/latest/Capacity/Referencehardware","poster":"samme","timestamp":"1684594380.0","comment_id":"722805"},{"timestamp":"1665343920.0","comment_id":"583457","upvote_count":"1","content":"A,B,D Architecting Splunk 8.0.1 Enterprise Deployments P.103","poster":"quaxy"},{"timestamp":"1658944380.0","upvote_count":"2","comment_id":"534085","poster":"Ehnicht73","comments":[{"upvote_count":"1","comment_id":"971652","timestamp":"1707025080.0","poster":"b5white","content":"I agree, but...\nSizing guidelines –Deployer\n–\nNo published minimums\n–\nMust have sufficient CPU and network resources to service requests and to push configurations"}],"content":"A and B. \n\nD is wrong, „the Processing requirements for a deployer Are fairly light“"},{"content":"A, B and C\ndeployer' requirement is Low resources.","comments":[{"comment_id":"398824","upvote_count":"4","timestamp":"1641362820.0","poster":"yarajin","content":"sorry, my mistake\nA, B, and D\nSHC does not always request the high-performance \"reference\".\nhttps://docs.splunk.com/Documentation/Splunk/latest/Capacity/Referencehardware"}],"timestamp":"1641224280.0","comment_id":"397599","upvote_count":"1","poster":"yarajin"},{"content":"A and B","timestamp":"1615506420.0","upvote_count":"4","poster":"sadhka","comment_id":"177884"}],"unix_timestamp":1599860820,"isMC":true,"question_id":81,"exam_id":203},{"id":"xYg1x2g2steFUzYlccpP","answers_community":["C (100%)"],"answer_images":[],"url":"https://www.examtopics.com/discussions/splunk/view/44315-exam-splk-2002-topic-2-question-11-discussion/","question_text":"Because Splunk indexing is read/write intensive, it is important to select the appropriate disk storage solution for each deployment. Which of the following statements is accurate about disk storage?","choices":{"A":"High performance SAN should never be used.","B":"Enable NFS for storing hot and warm buckets.","C":"The recommended RAID setup is RAID 10 (1 + 0).","D":"Virtualized environments are usually preferred over bare metal for Splunk indexers."},"discussion":[{"poster":"Proctor","content":"Selected Answer: C\nC\n\nSince this is focused on indexer performance, A can be ruled out because SAN is one of the faster storage technologies available. B can be ruled out because hot buckets need the fastest performance possible, and NFS is relatively slow (it usually runs over non-dedicated networks that are slower than those used by SAN). C is valid because it is a performance option - RAID 10 is faster than RAID5/6 while providing better redundancy. D can be ruled out because virtualized environments will always give lower raw performance than bare metal (despite having other advantages).","comment_id":"702872","timestamp":"1729761480.0","upvote_count":"1"},{"poster":"Redtonyeah","upvote_count":"3","timestamp":"1709587740.0","comment_id":"561051","content":"C, page 58 enterprise"},{"upvote_count":"3","timestamp":"1680970680.0","content":"C is the answer","comment_id":"331349","poster":"manu78"},{"timestamp":"1679896080.0","comment_id":"321673","content":"C is the answer","upvote_count":"3","poster":"ioana5"},{"content":"A B and D","timestamp":"1675910580.0","comment_id":"286558","comments":[{"timestamp":"1726451940.0","poster":"brettw","content":"High Performance SAN is better than an NFS as far as performance is concerned, so your answer of A and B are conflicting. The correct answer is C","comments":[{"comment_id":"670389","poster":"brettw","upvote_count":"1","content":"I forgot to mention that the tradeoff for the ease of using Virtualized environments is a slight performance hit that is introduced in the abstracting the hardware layer. So Bare Metal will always have high performance.","timestamp":"1726452120.0"}],"upvote_count":"1","comment_id":"670387"}],"poster":"scostic","upvote_count":"1"}],"answer_ET":"C","question_images":[],"exam_id":203,"isMC":true,"question_id":82,"answer_description":"Reference:\nhttps://www.splunk.com/pdfs/technical-briefs/splunk-deploying-vmware-tech-brief.pdf","unix_timestamp":1612838580,"topic":"2","answer":"C","timestamp":"2021-02-09 03:43:00"},{"id":"H25a9Ys2txHIQraT12h3","unix_timestamp":1599859440,"answers_community":["B (100%)"],"exam_id":203,"choices":{"B":"Total daily indexing volume, number of peer nodes, replication factor, and search factor.","C":"Total daily indexing volume, replication factor, search factor, and number of search heads.","A":"Total daily indexing volume, number of peer nodes, and number of accelerated searches.","D":"Replication factor, search factor, number of accelerated searches, and total disk size across cluster."},"answer":"B","answer_description":"","isMC":true,"timestamp":"2020-09-11 23:24:00","answer_images":[],"answer_ET":"B","topic":"2","url":"https://www.examtopics.com/discussions/splunk/view/31110-exam-splk-2002-topic-2-question-2-discussion/","question_images":[],"question_id":83,"question_text":"In an existing Splunk environment, the new index buckets that are created each day are about half the size of the incoming data. Within each bucket, about 30% of the space is used for rawdata and about 70% for index files.\nWhat additional information is needed to calculate the daily disk consumption, per indexer, if indexer clustering is implemented?","discussion":[{"timestamp":"1615505040.0","content":"My answer is B","poster":"sadhka","comment_id":"177878","upvote_count":"13"},{"upvote_count":"1","timestamp":"1722500760.0","poster":"bobixaka","comment_id":"1137501","content":"Selected Answer: B\nArchitecting Splunk PDF - page 96"},{"content":"Selected Answer: B\nindexing volume, no. of peer nodes, RF and SF.","upvote_count":"2","poster":"KiranVM","comment_id":"844825","timestamp":"1695202620.0"},{"comment_id":"591705","upvote_count":"1","content":"Selected Answer: B\nAnswer B","poster":"RedYeti","timestamp":"1666701540.0"},{"poster":"AnaBee","comment_id":"510545","timestamp":"1656347280.0","content":"Selected Answer: B\npg 27 | Cluster","upvote_count":"2"},{"comment_id":"436032","content":"It is B. Look at page 95-96 Architecting Splunk and it talks about considerations will include RF, SF and Daily index volume","upvote_count":"2","timestamp":"1646034120.0","poster":"not_another_user_007"},{"timestamp":"1638466620.0","content":"Actually I think D is right. I will explain. In B you have:\nnumber of peer nodes,\nbut you do not need that to calculate the disk usage as you don't care about number of peers only about the size of data and search factor + replication factor. Now it is said that you can see how much data comes in a day. Bucket = half the size so you can actually see the size of the bucket. So you do not need the size of the daily data. But if you need to calculate consumption of disk in % you would need answer from D being the size of the disk system.","poster":"SpTester","comments":[{"comment_id":"960020","upvote_count":"1","content":"You need to know the number of peers to know the average per peer. If you have an RF=3 among 5 peers, then the average is lower than it would be among 3 peers.","timestamp":"1705984680.0","poster":"b5white"}],"upvote_count":"1","comment_id":"372839"},{"content":"My answer is B as well.","upvote_count":"2","timestamp":"1633525020.0","comment_id":"329631","poster":"manu78"}]},{"id":"G8fy82clblfxoY5UhwpE","answer":"A","question_images":[],"question_id":84,"answer_ET":"A","topic":"2","answer_description":"","unix_timestamp":1646428320,"answers_community":["A (100%)"],"answer_images":[],"url":"https://www.examtopics.com/discussions/splunk/view/72324-exam-splk-2002-topic-2-question-3-discussion/","exam_id":203,"question_text":"What is the minimum reference server specification for a Splunk indexer?","isMC":true,"timestamp":"2022-03-04 22:12:00","discussion":[{"content":"Selected Answer: A\nA as per the following link for CPU/RAM. 800 IOPS is a minimum for any Splunk Enterprise installation regardless of role: https://docs.splunk.com/Documentation/Splunk/9.0.1/Capacity/Referencehardware#Minimum_indexer_specification","timestamp":"1729760400.0","comment_id":"702865","poster":"Proctor","upvote_count":"3"},{"upvote_count":"1","poster":"da_stingo","timestamp":"1725001560.0","content":"Selected Answer: A\nA is correct, see p.58 Architecting Splunk Deployments.pdf","comment_id":"653889"},{"comments":[{"upvote_count":"2","poster":"Redtonyeah","timestamp":"1709590800.0","comment_id":"561065","content":"sorry, A"}],"comment_id":"561042","content":"B is correct","upvote_count":"1","poster":"Redtonyeah","timestamp":"1709586720.0"}],"choices":{"A":"12 CPU cores, 12GB RAM, 800 IOPS","B":"16 CPU cores, 16GB RAM, 800 IOPS","C":"24 CPU cores, 16GB RAM, 1200 IOPS","D":"28 CPU cores, 32GB RAM, 1200 IOPS"}},{"id":"77sQfHMxwVObPiF7dR4b","question_images":[],"answers_community":["ABD (100%)"],"answer_description":"","unix_timestamp":1646428440,"topic":"2","question_text":"To optimize the distribution of primary buckets; when does primary rebalancing automatically occur? (Select all that apply.)","exam_id":203,"answer_images":[],"url":"https://www.examtopics.com/discussions/splunk/view/72325-exam-splk-2002-topic-2-question-4-discussion/","choices":{"C":"Captain joins or rejoins cluster.","B":"Master node rejoins the cluster.","A":"Rolling restart completes.","D":"A peer node joins or rejoins the cluster."},"answer_ET":"ABD","isMC":true,"answer":"ABD","discussion":[{"content":"Selected Answer: ABD\nhttps://docs.splunk.com/Documentation/Splunk/9.1.0/Indexer/Rebalancethecluster#How_primary_rebalancing_works","poster":"itsnicky","upvote_count":"2","comment_id":"997608","timestamp":"1725366660.0"},{"comment_id":"878995","upvote_count":"1","poster":"lzng3r","content":"Selected Answer: ABD\nClusterAdmin.pdf","timestamp":"1713930060.0"},{"upvote_count":"1","comment_id":"753312","content":"Selected Answer: ABD\nABD is correct","poster":"gorasz","timestamp":"1703250540.0"},{"comment_id":"561043","content":"A,B,D, page 110 cluster admin","timestamp":"1677964440.0","poster":"Redtonyeah","upvote_count":"4"}],"question_id":85,"timestamp":"2022-03-04 22:14:00"}],"exam":{"numberOfQuestions":90,"isBeta":false,"provider":"Splunk","name":"SPLK-2002","isMCOnly":true,"isImplemented":true,"id":203,"lastUpdated":"12 Apr 2025"},"currentPage":17},"__N_SSP":true}