{"pageProps":{"questions":[{"id":"aHkFNOSL4GVs9ERduIOJ","isMC":true,"answer_description":"","answer_ET":"D","timestamp":"2022-01-19 16:33:00","discussion":[{"upvote_count":"6","comment_id":"765276","timestamp":"1688441100.0","poster":"MattAnya","content":"was on exam 01/03/2023"},{"content":"Selected Answer: D\nD is correct because it has a keyword :\"submit\" to run","comment_id":"1226526","upvote_count":"1","poster":"evangelist","timestamp":"1733640240.0"},{"poster":"james2033","timestamp":"1713580800.0","comment_id":"1048318","content":"Selected Answer: D\nExperiment.submit(...) is used to start the experiment. \n\nThe config parameter of the submit method is used to specify the configuration for the run, which includes details about the script to be run and the compute target. \n\nIn this case, since you want to run the experiment on your local computer using the default environment, you would use a ScriptRunConfig object, which you have already created as script_config, to specify the script and source directory. \n\nThe script will be run in the default environment because you have not specified an environment in the ScriptRunConfig.\n\nrun = script_experiment.submit(config = script_config)\n\nThis line of code will start the experiment and run the script in your local environment. You can then use methods of the Run object, such as wait_for_completion, to monitor the progress of the run.","upvote_count":"1","comments":[{"poster":"james2033","comment_id":"1048319","timestamp":"1713580800.0","content":"Experiment and Run classes serve different purposes:\n\nExperiment: An Experiment in Azure Machine Learning is a container for a series of trials, or Runs. It’s a way to organize and group your machine learning work. You can have multiple runs under an experiment, each representing a different trial in your machine learning workflow. For example, you might create an experiment to test different algorithms on a dataset, with each run representing a trial with a specific algorithm.\n\nRun: A Run in Azure Machine Learning represents a single trial in an experiment. It’s an individual execution of a script or pipeline, and it can be used to monitor the progress of an experiment run, log metrics, store output files, and more. Each run has a unique identifier within its parent experiment.\n\nExperiment as a project or folder that contains related runs, and a Run as an individual trial or task within that project.","upvote_count":"2"}]},{"comment_id":"585558","content":"Selected Answer: D\nD is the answer","upvote_count":"1","timestamp":"1665726360.0","poster":"azurelearner666"},{"comment_id":"566048","timestamp":"1662970920.0","poster":"synapse","upvote_count":"1","content":"Selected Answer: D\nD is correct"},{"poster":"ranjsi01","timestamp":"1658237580.0","content":"D is correct","comment_id":"527667","upvote_count":"4"}],"question_id":181,"url":"https://www.examtopics.com/discussions/microsoft/view/70306-exam-dp-100-topic-3-question-100-discussion/","question_images":["https://www.examtopics.com/assets/media/exam-media/04274/0030400001.png"],"question_text":"You have the following code. The code prepares an experiment to run a script:\n//IMG//\n\nThe experiment must be run on local computer using the default environment.\nYou need to add code to start the experiment and run the script.\nWhich code segment should you use?","exam_id":64,"unix_timestamp":1642606380,"answer_images":[],"topic":"3","answers_community":["D (100%)"],"choices":{"A":"run = script_experiment.start_logging()","D":"run = script_experiment.submit(config=script_config)","C":"ws.get_run(run_id=experiment.id)","B":"run = Run(experiment=script_experiment)"},"answer":"D"},{"id":"0PVcnbp0IXWyNmC375N8","answers_community":["CD (57%)","C (29%)","14%"],"timestamp":"2022-01-19 16:36:00","question_images":[],"answer_images":[],"exam_id":64,"discussion":[{"comments":[{"comment_id":"1151819","poster":"Matt2000","upvote_count":"1","timestamp":"1723788960.0","content":"References: \nhttps://learn.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipeline(class)?view=azure-ml-py\n\nhttps://learn.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment(class)?view=azure-ml-py#azureml-core-experiment-submit"},{"timestamp":"1665727080.0","upvote_count":"2","comment_id":"585561","content":"Thanks for clarifying!","poster":"azurelearner666"}],"poster":"pancman","comment_id":"584330","upvote_count":"19","content":"The given answer of C & D is correct. Some people commented that they think it should be A & C. Don't let this confuse you as answer A is certainly wrong. You can't use [step1, step2] as a config to experiment submit, as given in the answer A. You need to create a pipeline object and provide it as the config.\nRefer to experiment class for proof: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment(class)?view=azure-ml-py#azureml-core-experiment-submit","timestamp":"1665508680.0"},{"upvote_count":"1","poster":"avinyc","content":"Selected Answer: CD\nOptions C and D","comment_id":"1336914","timestamp":"1736125020.0"},{"content":"Selected Answer: C\nC for me. \nFor A, you can't submit [step1, step2] parameters only; For D, you can't submit a string name only. Correct way is to submit Pipeline Obj or RunConfig Obj, not a list or string.","upvote_count":"1","comment_id":"1099773","poster":"haby","timestamp":"1718712720.0"},{"content":"Selected Answer: C\nOnly option C is correct\n\nOptions A and B are incorrect because they either submit the steps directly to the experiment without creating a Pipeline object (Option A), or try to create a Run object directly from the steps without creating a Pipeline or Experiment object (Option B). Both of these approaches will result in errors.\n\nOption D correctly creates a Pipeline object and then submits the pipeline with the experiment name. However, please note that the submit method of the Pipeline class does not take an experiment_name argument. Instead, it takes an Experiment object. So, the correct code should be:\n\npipeline = Pipeline(workspace=ws, steps=pipeline_steps)\nexperiment = Experiment(workspace=ws, name='pipeline-experiment')\nrun = pipeline.submit(experiment)","poster":"PI_Team","timestamp":"1717657320.0","upvote_count":"1","comment_id":"1089128"},{"timestamp":"1713581460.0","upvote_count":"1","content":"Selected Answer: CD\nConstructor azurelm.pipeline.core.pipeline.Pipeline() \n\nhttps://learn.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipeline.pipeline?view=azure-ml-py#constructor\n\nPipeline(workspace, steps, ...)","comment_id":"1048323","poster":"james2033"},{"comment_id":"848279","timestamp":"1695470580.0","content":"Selected Answer: CD\nCD is correct","upvote_count":"1","poster":"Tommo565"},{"comment_id":"819735","upvote_count":"1","poster":"AzureJobsTillRetire","content":"Selected Answer: AC\nThe correct command for pipeline run is as below\nexperiment.submit()\n\nOnly A and C has this command.\nD has command pipeline.submit(), which is incorrect","timestamp":"1692816480.0","comments":[{"content":"An Azure Machine Learning experiment represent the collection of trials used to validate a user's hypothesis. In Azure Machine Learning, an experiment is represented by the Experiment class and a trial is represented by the Run class.\n\nAn Azure Machine Learning pipeline is an independently executable workflow of a complete machine learning task.\n\nIn an experiment, we execute a pipeline, and this is why we use experiment.submit(pipeline)\n\nIt is not that in a pipeline, we execute an experiment, and that is why pipeline.submit(experiment) is wrong","upvote_count":"1","comment_id":"819744","timestamp":"1692817200.0","poster":"AzureJobsTillRetire"}]},{"comments":[{"comment_id":"819725","content":"I think so too. Also there is no definition of the experiment 'pipeline-experiment' in the code","timestamp":"1692816060.0","poster":"AzureJobsTillRetire","upvote_count":"1"}],"poster":"Arend78","timestamp":"1686911220.0","comment_id":"747170","upvote_count":"1","content":"I also think it's A & C: In the Azure documentations, I have only found examples of \nrun = experiment.submit(pipeline) \nand no examples of \nrun = pipeline.submit(experiment_name='pipeline-experiment')\n\nPlease reply if you don't agree"},{"timestamp":"1663566180.0","comment_id":"570887","upvote_count":"2","poster":"zehraoneexam","content":"correct answer."},{"comment_id":"569671","content":"I think A & C as well","poster":"Sjefen","timestamp":"1663406580.0","upvote_count":"1"},{"poster":"synapse","upvote_count":"1","comment_id":"566064","timestamp":"1662973380.0","content":"Selected Answer: CD\nC and are correct. As per below. A is not correct because the submit() expects a Pipeline object. not a list. \nhttps://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.experiment?view=azure-ml-py#azureml-core-experiment-experiment-submit"},{"upvote_count":"2","timestamp":"1659120480.0","content":"sorry i think it should be A and C","comment_id":"535709","poster":"ranjsi01"},{"poster":"ranjsi01","upvote_count":"1","timestamp":"1658237760.0","comment_id":"527670","content":"correct"}],"question_text":"You use the following code to define the steps for a pipeline: from azureml.core import Workspace, Experiment, Run from azureml.pipeline.core import Pipeline from azureml.pipeline.steps import PythonScriptStep ws = Workspace.from_config()\n. . .\nstep1 = PythonScriptStep(name=\"step1\", ...)\nstep2 = PythonScriptsStep(name=\"step2\", ...)\npipeline_steps = [step1, step2]\nYou need to add code to run the steps.\nWhich two code segments can you use to achieve this goal? Each correct answer presents a complete solution.\nNOTE: Each correct selection is worth one point.","answer_description":"","choices":{"A":"experiment = Experiment(workspace=ws, name='pipeline-experiment') run = experiment.submit(config=pipeline_steps)","D":"pipeline = Pipeline(workspace=ws, steps=pipeline_steps) run = pipeline.submit(experiment_name='pipeline-experiment')","B":"run = Run(pipeline_steps)","C":"pipeline = Pipeline(workspace=ws, steps=pipeline_steps) experiment = Experiment(workspace=ws, name='pipeline-experiment') run = experiment.submit(pipeline)"},"question_id":182,"isMC":true,"url":"https://www.examtopics.com/discussions/microsoft/view/70307-exam-dp-100-topic-3-question-101-discussion/","topic":"3","answer_ET":"CD","unix_timestamp":1642606560,"answer":"CD"},{"id":"o7RcTVvHHf2KAGk4Wbc6","discussion":[{"comment_id":"512043","content":"It should be NYN, shouldn't it?","comments":[{"timestamp":"1719592080.0","content":"I agree, it should be NYN\nBox 1: No -\nThis method does not create a new resource group or Azure Machine Learning workspace; it simply accesses an existing one.\nBox 2: Yes -\nThe get_mlflow_tracking_uri() method retrieves the tracking URI of the Azure Machine Learning workspace, and set_tracking_uri() directs MLflow to send its tracking data to this URI.\nBox 3: No -\nThe Python code provided does not include any code that specifically sets up tracking for the \"epoch loss\" metric. While MLflow is capable of tracking such a metric, it would require explicit calls to mlflow.log_metric() within the training loop, which are not present in the provided code segment.","poster":"Lion007","upvote_count":"2","comment_id":"1108038"},{"comment_id":"515851","content":"I agree","upvote_count":"3","timestamp":"1656852960.0","poster":"[Removed]"}],"upvote_count":"27","timestamp":"1656490140.0","poster":"TEO96B"},{"comment_id":"897497","upvote_count":"6","poster":"vish9","content":"https://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-mlflow-azure-databricks?view=azureml-api-2&tabs=cli%2Cmlflow\nThe above link states: Azure Databricks can be configured to track experiments using MLflow in two ways:\n\nTrack in both Azure Databricks workspace and Azure Machine Learning workspace (dual-tracking)\nTrack exclusively on Azure Machine Learning\nBy default, dual-tracking is configured for you when you linked your Azure Databricks workspace.\nHence It should be NNN","comments":[{"content":"I followed your link. The code specified in this question occurs in the section 'Tracking exclusively on Azure Machine Learning workspace'. I suppose that the second question should be 'Yes'.","poster":"Matt2000","comment_id":"1135038","timestamp":"1722256140.0","upvote_count":"1"}],"timestamp":"1699968420.0"},{"content":"Should be NNN.\n\nFor second box: NO\n\"You can configure Azure Databricks to track experiments using MLflow in two ways:\n\n - Track in both Azure Databricks workspace and Azure Machine Learning workspace (dual-tracking)\n - Track exclusively on Azure Machine Learning\n\nBy default, when you link your Azure Databricks workspace, dual-tracking is configured for you.\n\nLinking your Azure Databricks workspace to your Azure Machine Learning workspace enables you to track your experiment data in the Azure Machine Learning workspace and Azure Databricks workspace at the same time. This configuration is called Dual-tracking.\n\nhttps://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-mlflow-azure-databricks?view=azureml-api-2&tabs=cli%2Cmlflow#track-azure-databricks-runs-with-mlflow\n\nFor third box: NO\n\nThe code doesn't provide any segment to track metrics.","upvote_count":"1","comment_id":"1350160","poster":"Secure_Defense","timestamp":"1738470540.0"},{"content":"Should be NNN\nAfter you link your Azure Databricks workspace with your Azure Machine Learning workspace, MLflow Tracking is automatically set to be tracked in all of the following places:\nThe linked Azure Machine Learning workspace.\nYour original ADB workspace.","timestamp":"1694685300.0","comment_id":"838797","poster":"SunilB","upvote_count":"5"},{"content":"It should be N,N,N as i see that 1) we will not create ws 2) in latest Azure ML and Azure DB we can monitor the logs 3) there is no code for logging in mlflow","upvote_count":"6","comment_id":"769581","comments":[{"upvote_count":"1","timestamp":"1688823000.0","poster":"vishal_aiml164","comment_id":"769584","content":"FYR : https://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-mlflow-azure-databricks?tabs=cli%2Cmlflow"}],"timestamp":"1688822880.0","poster":"vishal_aiml164"},{"poster":"ning","timestamp":"1670520840.0","comment_id":"613358","upvote_count":"1","content":"I do not fully understand this question, in the statements, there are no statement for logging, in order mlflow to log, one the following needs to be called:\n\nmlflow.log_param(\"alpha\", alpha) \nmlflow.log_metric('mse', 1.23) \nmlflow.log_artifact(\"actuals_vs_predictions.png\") \nmlflow.log_model(lr, \"linear Model\")\n\nif no statement to log, how would anything to be traced or logged???"},{"comment_id":"559819","poster":"AjoseO","content":"On 03 March 2022\n\nThe 3rd question was different","upvote_count":"4","timestamp":"1662176100.0"}],"unix_timestamp":1640772540,"answers_community":[],"question_id":183,"url":"https://www.examtopics.com/discussions/microsoft/view/68896-exam-dp-100-topic-3-question-102-discussion/","answer_ET":"","timestamp":"2021-12-29 11:09:00","exam_id":64,"answer":"","answer_description":"","question_text":"HOTSPOT -\nYou create an Azure Databricks workspace and a linked Azure Machine Learning workspace.\nYou have the following Python code segment in the Azure Machine Learning workspace: import mlflow import mlflow.azureml import azureml.mlflow import azureml.core from azureml.core import Workspace subscription_id = 'subscription_id' resourse_group = 'resource_group_name' workspace_name = 'workspace_name' ws = Workspace.get(name=workspace_name, subscription_id=subscription_id, resource_group=resource_group) experimentName = \"/Users/{user_name}/{experiment_folder}/{experiment_name}\" mlflow.set_experiment(experimentName) uri = ws.get_mlflow_tracking_uri() mlflow.set_tracking_uri(uri)\nInstructions: For each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","answer_images":["https://img.examtopics.com/dp-100/image611.png"],"question_images":["https://www.examtopics.com/assets/media/exam-media/04274/0030700001.png"],"isMC":false,"topic":"3"},{"id":"qdGA4MAutZRRLrFjl8MK","isMC":true,"url":"https://www.examtopics.com/discussions/microsoft/view/69088-exam-dp-100-topic-3-question-103-discussion/","question_text":"You create and register a model in an Azure Machine Learning workspace.\nYou must use the Azure Machine Learning SDK to implement a batch inference pipeline that uses a ParallelRunStep to score input data using the model. You must specify a value for the ParallelRunConfig compute_target setting of the pipeline step.\nYou need to create the compute target.\nWhich class should you use?","answer_ET":"C","exam_id":64,"question_images":[],"topic":"3","question_id":184,"unix_timestamp":1640884620,"timestamp":"2021-12-30 18:17:00","answers_community":["C (100%)"],"discussion":[{"poster":"AjoseO","upvote_count":"6","comment_id":"559820","content":"On 03 March 2022","timestamp":"1677821760.0"},{"content":"The AmlCompute class is used in Azure Machine Learning for managing compute targets. It's designed for running machine learning workloads and supports various VM sizes for scaling resources according to the workload's needs.\n\nParallelRunStep, which you want to use for your batch inference pipeline, can efficiently use AmlCompute instances to parallelize and speed up the processing.","timestamp":"1721838780.0","comment_id":"961814","upvote_count":"1","poster":"phdykd"},{"content":"C. AmlCompute.\n\nExplanation:\nTo create a compute target for use with Azure Machine Learning, you can create an instance of the appropriate ComputeTarget class in the azureml.core.compute package. In this case, the compute target must support distributed processing, which is required for the ParallelRunStep. The AmlCompute class is the only class listed that provides this capability.\n\nBatchCompute is not a valid compute target class in the azureml.core.compute package. Instead, it is a service provided by Azure that enables you to run large-scale, high-performance batch jobs.\n\nAdlaCompute is a compute target class in the azureml.core.compute package, but it is not designed for distributed processing. Instead, it is used to manage Azure Data Lake Analytics clusters.\n\nAksCompute is a compute target class in the azureml.core.compute package that enables you to use an Azure Kubernetes Service (AKS) cluster for machine learning workloads. While AKS is capable of distributed processing, this compute target is not specifically designed for use with the ParallelRunStep.","poster":"Jin_22","comment_id":"839907","upvote_count":"1","timestamp":"1710509160.0"},{"comment_id":"566069","upvote_count":"2","timestamp":"1678619340.0","content":"Selected Answer: C\nAmlCompute is the correct answer.","poster":"synapse"},{"content":"Why not D?","comment_id":"513545","timestamp":"1672420620.0","comments":[{"timestamp":"1675458840.0","upvote_count":"3","poster":"ranjsi01","content":"batch inferencing is asynchronus and doesn't require scaling and low latency like production real time inferencing would so no need for any costly AKS. batch inferencing relies on parallel processing instead for achieving efficiency.","comment_id":"539993"},{"comment_id":"515855","comments":[{"poster":"RAHULsingla","timestamp":"1672852860.0","content":"Apparently webservices are not used with pipeline. Not sure why.","upvote_count":"1","comment_id":"516861"}],"timestamp":"1672758060.0","content":"The docs specifically mention AML: https://docs.microsoft.com/en-us/python/api/azureml-contrib-pipeline-steps/azureml.contrib.pipeline.steps.parallelrunconfig\n\nI assume D could be correct too, but the question is phrased as 'which SHOULD you use' and AML is prefereable - not sure why though","poster":"[Removed]","upvote_count":"2"}],"poster":"Xsytt419","upvote_count":"2"}],"answer_description":"Compute target to use for ParallelRunStep. This parameter may be specified as a compute target object or the string name of a compute target in the workspace.\nThe compute_target target is of AmlCompute or string.\nNote: An Azure Machine Learning Compute (AmlCompute) is a managed-compute infrastructure that allows you to easily create a single or multi-node compute.\nThe compute is created within your workspace region as a resource that can be shared with other users\nReference:\nhttps://docs.microsoft.com/en-us/python/api/azureml-contrib-pipeline-steps/azureml.contrib.pipeline.steps.parallelrunconfig https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.amlcompute(class)","answer":"C","choices":{"A":"BatchCompute","B":"AdlaCompute","C":"AmlCompute","D":"AksCompute"},"answer_images":[]},{"id":"AiHShjk7pWAECzpM5aVd","topic":"3","answers_community":[],"question_text":"DRAG DROP -\nYou previously deployed a model that was trained using a tabular dataset named training-dataset, which is based on a folder of CSV files.\nOver time, you have collected the features and predicted labels generated by the model in a folder containing a CSV file for each month. You have created two tabular datasets based on the folder containing the inference data: one named predictions-dataset with a schema that matches the training data exactly, including the predicted label; and another named features-dataset with a schema containing all of the feature columns and a timestamp column based on the filename, which includes the day, month, and year.\nYou need to create a data drift monitor to identify any changing trends in the feature data since the model was trained. To accomplish this, you must define the required datasets for the data drift monitor.\nWhich datasets should you use to configure the data drift monitor? To answer, drag the appropriate datasets to the correct data drift monitor options. Each source may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.\nNOTE: Each correct selection is worth one point.\nSelect and Place:\n//IMG//","answer_images":["https://img.examtopics.com/dp-100/image612.png"],"answer_description":"","question_images":["https://www.examtopics.com/assets/media/exam-media/04274/0030900001.png"],"exam_id":64,"question_id":185,"isMC":false,"unix_timestamp":1641047760,"answer":"","discussion":[{"timestamp":"1680857040.0","content":"The answer should be\nBox 1. Training dataset\nBox 2. Features dataset\n\nbecause in data drift monitor,\nBaseline dataset = \"usually the training dataset for a model\".\nTarget dataset = \"... MUST have a timestamp column specified\".","upvote_count":"18","poster":"David_Tadeu","comments":[{"comment_id":"747212","upvote_count":"2","poster":"Arend78","content":"Indeed, the drift monitor looks at changes (e.g. seasonal) in the inputs, and does not look at the predictions","timestamp":"1702732680.0"}],"comment_id":"582317"},{"comment_id":"1007906","timestamp":"1726344060.0","poster":"A_PL300","upvote_count":"1","content":"Question like this one on Sept-4, 2022 exam"},{"comment_id":"1003810","poster":"bobML","upvote_count":"1","timestamp":"1725955980.0","content":"To configure a data drift monitor, you typically use a baseline dataset and a target dataset for comparison. In this scenario, you want to monitor the changing trends in the feature data since the model was trained. Here's how you should configure the data drift monitor:\n\nBaseline Dataset: Training-dataset\n\nThe baseline dataset should be the dataset that represents the data at the time when the model was trained. In this case, it's the training-dataset since it is the original dataset used for training the model.\nTarget Dataset: Features-dataset\n\nThe target dataset should be the dataset that you want to monitor for data drift, which contains the features and timestamp information. In this case, it's the features-dataset because it contains the feature data that you want to compare with the baseline data.\nYou don't need to use the predictions-dataset for configuring the data drift monitor because it contains the predicted labels, which are not relevant for monitoring data drift in the features."},{"poster":"therealola","timestamp":"1687045680.0","upvote_count":"2","comment_id":"617991","content":"On exam 18-06-22"},{"timestamp":"1685702280.0","comment_id":"610552","poster":"striver","upvote_count":"4","content":"Correct answer is\nBox1: Training Dataset\nBox2: Features Dataset\n\nReference: https://docs.microsoft.com/en-us/azure/machine-learning/how-to-monitor-datasets?tabs=python#create-target-dataset"},{"comment_id":"589847","content":"on exam 04/22/2022","poster":"JTWang","upvote_count":"2","timestamp":"1682153520.0"},{"comment_id":"566073","upvote_count":"1","poster":"synapse","content":"1. baseline: Training dataset 2. Target: Features data set. Features dataset has a timestamp in it.","timestamp":"1678619880.0"},{"poster":"AjoseO","timestamp":"1677821760.0","content":"On 03 March 2022","upvote_count":"3","comment_id":"559821"},{"comments":[{"timestamp":"1677234180.0","content":"Sorry.\n2. Features dataset -> because this is the only dataset that has a timestamp column","upvote_count":"5","comment_id":"555189","poster":"AjoseO"}],"poster":"AjoseO","content":"1. Training dataset\n2. Predictions dataset -> because this is the only dataset that has a timestamp column","upvote_count":"2","comment_id":"555187","timestamp":"1677234120.0"},{"content":"target dataset should be features dataset. (mandatory timestamp column in target dataset\n)","comment_id":"528003","poster":"ranjsi01","upvote_count":"1","timestamp":"1674171300.0"},{"timestamp":"1673774820.0","comment_id":"524039","upvote_count":"2","poster":"Tsardoz","content":"I cant even find any reference to what a feature dataset is ... my vote goes to predictions dataset"},{"comment_id":"514544","timestamp":"1672583760.0","upvote_count":"4","comments":[{"poster":"Oliverto","upvote_count":"4","comment_id":"520837","timestamp":"1673353620.0","content":"Target dataset should be \"feature-dataset\". Because only the feature-dataset contains a timestamp which is mandatory \"target_dataset: Required. Dataset to run either adhoc or scheduled DataDrift jobs for. Must be a time series.\" (https://docs.microsoft.com/en-us/python/api/azureml-datadrift/azureml.datadrift.datadriftdetector(class)?view=azure-ml-py)"},{"timestamp":"1681235520.0","content":"J_AR you didn't read the question correctly. The dataset that contains the timestamp is features-dataset. Question states: \"another named features-dataset with a schema containing all of the feature columns and a timestamp column\"","upvote_count":"1","poster":"pancman","comment_id":"584348"}],"poster":"J_AR","content":"The target dataset should be \"predictions dataset' because this is the only dataset that has a timestamp column."}],"url":"https://www.examtopics.com/discussions/microsoft/view/69193-exam-dp-100-topic-3-question-104-discussion/","timestamp":"2022-01-01 15:36:00","answer_ET":""}],"exam":{"name":"DP-100","id":64,"isBeta":false,"provider":"Microsoft","numberOfQuestions":512,"isImplemented":true,"lastUpdated":"12 Apr 2025","isMCOnly":false},"currentPage":37},"__N_SSP":true}