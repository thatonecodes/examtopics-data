{"pageProps":{"questions":[{"id":"3nRcPzlEktu30KdP83vR","url":"https://www.examtopics.com/discussions/microsoft/view/81946-exam-pl-300-topic-14-question-1-discussion/","answer_description":"Box 1: App permissions -\nApp permissions.\nThis section describes the kinds of permissions you can grant to the specified users\n* Allow all users to connect to the app's underlying datasets using the Build permission\nThis option grants build permission on the app's underlying datasets.\n* Etc.\nNote: Contoso identifies the following security requirements for analyst access:\n✑ Analysts must be able to access all balance sheet and product catalog data.\n✑ Analysts must be able to access only the profit and loss data of their respective business unit.\n✑ Analysts must be able to create new reports from the dataset that contains the profit and loss data, but the reports built by the analysts must NOT be included in the quarterly reports for the board.\n✑ Analysts must NOT be able to share the quarterly reports with anyone.\n✑ Analysts must NOT be able to make new reports by using the balance sheet data.\nIncorrect:\nNot Member role: Would grant too much permissions.\nNot Viewer role: Need more granular permissions.\n\nBox 2: Reshare -\nApp permissions,\nThis section describes the kinds of permissions you can grant to the specified users\n* Allow users to share the app and the app's underlying datasets using the share permission\nThis option grants users reshare permission on the app's underlying datasets.\n* Etc.\nNote: Analysts must be able to create new reports from the dataset that contains the profit and loss data, but the reports built by the analysts must NOT be included in the quarterly reports for the board.\nReference:\nhttps://docs.microsoft.com/en-us/power-bi/collaborate-share/service-create-distribute-apps","topic":"14","question_images":["https://www.examtopics.com/assets/media/exam-media/04331/0028300001.png"],"answer_ET":"","answers_community":[],"question_id":56,"timestamp":"2022-09-13 08:50:00","unix_timestamp":1663051800,"question_text":"HOTSPOT -\nYou need to grant access to the business unit analysts.\nWhat should you configure? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","isMC":false,"answer":"","answer_images":["https://www.examtopics.com/assets/media/exam-media/04331/0028400001.jpg"],"discussion":[{"poster":"LucasCovey","upvote_count":"71","content":"I am part of an organization (with an organizational Workspace) and I just tested with another colleague - the only way to allow building via the underlying dataset was granting \"Viewer\" role in the Workspace, and then going into \"Manage permissions\" on the dataset in the Workspace and granting Build permission.\n\nI tried by adding the colleague JUST to the app (not Viewer role in Workspace) and it did not let them build from the dataset!\n\nHope this helps someone else who was unable to test.","timestamp":"1671818160.0","comments":[{"timestamp":"1702632180.0","upvote_count":"7","comment_id":"1097158","content":"LucasCovey: pro","poster":"StressFree"}],"comment_id":"754402"},{"comments":[{"upvote_count":"4","timestamp":"1668594240.0","comment_id":"719543","poster":"shakes103","content":"The Viewer role only grants \"read only\" access to the dataset. Therefore it cannot be correct for this question.","comments":[{"comment_id":"722144","timestamp":"1668879420.0","poster":"Peguero","content":"is correct \"access permission to an app\" for the first quesion?","upvote_count":"1"},{"content":"That is why we grant the Build right in the second part of the question. Viewer role + Build right on the dataset is perfectly valid and is the answer to this question.","comment_id":"726783","upvote_count":"12","timestamp":"1669381980.0","poster":"YokoSumiGaeshi"},{"poster":"Jew0598","content":"In Power BI, you can share a report with a user just for view only or give them access to view and build or to Edit. \n\nhttps://radacad.com/power-bi-user-access-levels-build-and-edit-are-different#:~:text=In%20Power%20BI%2C%20you%20can,and%20build%20or%20to%20Edit.","upvote_count":"2","timestamp":"1681362900.0","comment_id":"869101"}]}],"content":"- The Viewer roler to the workspace\n- Build","poster":"Namenick10","upvote_count":"53","timestamp":"1663651320.0","comment_id":"673825"},{"timestamp":"1727287800.0","content":"Given answer is only partially correct, the analysts must not be allowed to reshare.\n\n-Access to an app\n-Build","poster":"539d541","comment_id":"1289123","upvote_count":"5"},{"upvote_count":"1","timestamp":"1720142220.0","poster":"c63b646","comment_id":"1242380","content":"I believe it should be \n- Viewer (To keep the RLS applicable)\n- Build"},{"comment_id":"940702","timestamp":"1688290020.0","poster":"JJMC5544","content":"VIEWER to stay in RLS\nBUILD to let analysts create new report including with only RLS allowed content.","upvote_count":"7"},{"content":"Given answer is correct.","poster":"rmeng","upvote_count":"1","comment_id":"902499","timestamp":"1684576140.0"},{"comment_id":"872063","content":"The Viewer roler to the workspace and Build permission","poster":"Retro01","upvote_count":"2","timestamp":"1681671180.0"},{"poster":"BabaJee","upvote_count":"2","timestamp":"1672274580.0","content":"the current answer is correct as the app allows build permission to the underlying dataset.\nhttps://intercom.help/cognition360/en/articles/4731210-powerbi-adding-app-permissions","comment_id":"760462"},{"upvote_count":"13","poster":"Wadyba","timestamp":"1671819060.0","content":"One of the requirements is that Analysts must be able to access only the profit and loss data of their respective business unit. For this requirement to be achieved, you need to configure Row-level Security (RLS), and RLS only applies to the Viewer role. Thus:\n-Viewer\n-Build","comment_id":"754408"},{"comment_id":"746265","timestamp":"1671118980.0","content":"Correct answers a re:\nViewer\nBuild","poster":"iccent2","comments":[{"content":"I change my earlier submission:\n - Access permission to an app\n- Build\nIf the analyst can build, then that means they are not viewers .","poster":"iccent2","comments":[{"comment_id":"754214","timestamp":"1671800340.0","comments":[{"content":"Again, Access permission to an app, is it one of the permissions in powerbi.com?\nWe have Admin, Member, Contributor and Viewer. Or is it not so?","timestamp":"1672161720.0","poster":"iccent2","comment_id":"758837","upvote_count":"2"}],"content":"But again, we are told by Microsoft that:\n\n\"Contributors and Viewers can also share items in a workspace, if they have Reshare permissions\"\n\nSo, what can we make of that in relation to question 1? \nI would revert to Viewer.\n\nhttps://learn.microsoft.com/en-us/power-bi/collaborate-share/service-roles-new-workspaces","poster":"iccent2","upvote_count":"1"}],"timestamp":"1671800040.0","upvote_count":"2","comment_id":"754210"}],"upvote_count":"3"},{"poster":"Patrick666","content":"Access permission to an app\nBuild","timestamp":"1670807220.0","comment_id":"742268","upvote_count":"3"},{"poster":"disndat7","content":"\"Access permission to an app\" is correct, as this allows users to build contents with the datasets in the app (which is what the business analyst required to do). Refer to: https://learn.microsoft.com/en-us/power-bi/collaborate-share/service-create-distribute-apps#create-and-manage-audiences","upvote_count":"3","comment_id":"733447","timestamp":"1669956840.0"},{"content":"To be able to build new reports based on underlying dataset you need Build permission, not Reshare permission so the second option should be Build.","poster":"ThariCD","timestamp":"1663051800.0","comment_id":"667733","comments":[{"poster":"fdsdfgxcvbdsfhshfg","upvote_count":"5","timestamp":"1663530120.0","comment_id":"672710","content":"correct"},{"comment_id":"762510","poster":"charles879987","timestamp":"1672466460.0","upvote_count":"2","content":"No build permission option in app audience access. only reshare dataset or reshare dataset with build permission."}],"upvote_count":"19"}],"exam_id":116},{"id":"tfikM2o5XQrq4VAPo1Uk","discussion":[{"comment_id":"673823","timestamp":"1663651200.0","poster":"Namenick10","upvote_count":"73","content":"1. Using an App\n2. A mail-enabled security group in Azure Active Directory"},{"content":"- Using an app - as they require CUSTOM NAVIGATION\n- AAD","upvote_count":"14","comment_id":"672722","poster":"fdsdfgxcvbdsfhshfg","timestamp":"1663532040.0"},{"content":"-App\n-AD group","upvote_count":"2","poster":"539d541","timestamp":"1727288040.0","comment_id":"1289126"},{"comment_id":"1120989","poster":"Bolatayo","upvote_count":"2","content":"App\nAAD","timestamp":"1705082700.0"},{"timestamp":"1688294760.0","upvote_count":"4","content":"Question says \"How should you distribute...\", not \"How should analysts...\"\nIf you give them app how will they be able to produce report. \nThey are in RLS as a Viewer.","comment_id":"940770","poster":"JJMC5544"},{"comments":[{"comments":[{"upvote_count":"1","poster":"Sophieeeeee","comment_id":"1247621","timestamp":"1720933800.0","content":"And it is mentioned in the techinical requirements that \"The company wants to provide the board with a single package of reports that will contain custom navigation and links to supplementary information.\"...so Using an app for sure"}],"content":"Analysts must be able to create new reports from the dataset that contains the profit and loss data, but the reports built by the analysts must NOT be included in the quarterly reports for the board.---> that's why we are using an app not membership of the workspace","upvote_count":"6","poster":"Shalaleh","comment_id":"886093","timestamp":"1682936940.0"}],"poster":"Shalaleh","content":"Using an App\nSecurity group in AAD \nThe reports must be made available to the board from powerbi.com. An Azure Active Directory (Azure AD) group will be used to share information with the board.","timestamp":"1682936880.0","comment_id":"886092","upvote_count":"1"},{"upvote_count":"6","content":"Using as App\nA mail enabled security group","timestamp":"1668002100.0","comment_id":"714622","poster":"powerbibuddy"}],"question_text":"HOTSPOT -\nHow should you distribute the reports to the board? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","answer_description":"Box 1: Using a workspace membership\nNote 1: The company wants to provide the board with a single package of reports that will contain custom navigation and links to supplementary information.\nSharing is the easiest way to give people access to your reports and dashboards in the Power BI service. You can share with people inside or outside your organization.ֲ¨\nWhere you can share:\nYou can share reports and dashboards from My Workspace.\nYou can share from workspaces other than My Workspace, if you have the Admin or Member role in the workspace. If you have the Contributor or Viewer role, you can share if you have Reshare permissions.\nYou can share from the Power BI mobile apps.\nYou can't share directly from Power BI Desktop.\nBox 2: A mail-enabled security group in Azure Active Directory\n\nMail-Enabled Security Group -\nThis group also contains a list of email addresses of members and can also be used to control access to OneDrive and SharePoint.\nThe Mail-Enabled Security Group can be created in the Office 365 Admin Portal\nNote: The reports must be made available to the board from powerbi.com. An Azure Active Directory (Azure AD) group will be used to share information with the board.\nIncorrect:\n* Distribution Group\nThis group can also be called and Distribution List. The Distribution Group is a group which contains a list of email addresses of members, all of whom will be sent an email when an email is sent to the distribution groups email address.\nThe Distribution Group can be created in the Azure Active Directory\nReference:\nhttps://docs.microsoft.com/en-us/power-bi/collaborate-share/service-share-dashboards https://www.fourmoo.com/2020/04/01/power-bi-which-groups-can-be-used-to-set-permissions-in-power-bi/","answer_ET":"","question_images":["https://www.examtopics.com/assets/media/exam-media/04331/0028500001.png"],"unix_timestamp":1663532040,"answer":"","answers_community":[],"answer_images":["https://www.examtopics.com/assets/media/exam-media/04331/0028600001.jpg"],"timestamp":"2022-09-18 22:14:00","question_id":57,"isMC":false,"url":"https://www.examtopics.com/discussions/microsoft/view/82721-exam-pl-300-topic-14-question-2-discussion/","topic":"14","exam_id":116},{"id":"Gdal9PhBLXZpaMbSGTB2","topic":"14","question_id":58,"answer_description":"","question_text":"You need to ensure that the data is updated to meet the report requirements. The solution must minimize configuration effort.\nWhat should you do?","choices":{"C":"Configure a scheduled refresh without using an on-premises data gateway.","A":"From each report in powerbi.com, select Refresh visuals.","B":"From Power BI Desktop, download the PBIX file and refresh the data.","D":"Configure a scheduled refresh by using an on-premises data gateway."},"question_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/82722-exam-pl-300-topic-14-question-3-discussion/","isMC":true,"timestamp":"2022-09-18 22:19:00","answer":"C","exam_id":116,"unix_timestamp":1663532340,"discussion":[{"timestamp":"1663532340.0","comments":[{"comment_id":"692079","timestamp":"1665490500.0","content":"From your link:\n\"Scheduled refresh of reports isn’t supported with Dynamics 365 (on-premises) datasets that are published to the Power BI service. You can refresh reports using in Microsoft Power BI Desktop or Microsoft Office Excel and then upload the reports to the Power BI service.\"\nSo D is impossible. C is correct.","poster":"simba_10","upvote_count":"17"},{"poster":"MoneyStacking","timestamp":"1714654080.0","content":"At the 'Data type' table, it literally says Azure SQL database","comment_id":"1205538","upvote_count":"2"},{"comment_id":"1195060","content":"Migrating to the cloud with Business Central can help you reduce costs associated with maintaining on-premises systems, streamline operations by using more timely data, and enhance security. You’ll also have access to AI capabilities such as Copilot, enabling your teams to work smarter, adapt faster, and perform better.","timestamp":"1713027360.0","upvote_count":"1","poster":"JudT"},{"content":"The question mentions that \"The balance sheet is IMPORTED.\" My understanding is that it is on-premise and the correct answer is D.","timestamp":"1669351500.0","comment_id":"726386","poster":"MayaYao","upvote_count":"9"}],"poster":"fdsdfgxcvbdsfhshfg","content":"Selected Answer: C\nTrick question, depends whether the Microsoft Dynamics 365 is cloud or on prem.\nhttps://learn.microsoft.com/en-us/previous-versions/dynamicscrm-2016/administering-dynamics-365/dn708055(v=crm.8)#in-this-topic","upvote_count":"20","comment_id":"672728"},{"comments":[{"poster":"Hoeishetmogelijk","content":"Ah! And even more clearly: the table with data sources states clearly \"Azure SQL Database\"!","comment_id":"741988","timestamp":"1670784120.0","upvote_count":"4"}],"upvote_count":"5","timestamp":"1670433780.0","poster":"Hoeishetmogelijk","comment_id":"738163","content":"Selected Answer: C\nSomewhere in the requirements: \"An Azure Active Directory (Azure AD) group will be used to share information with the board.\"\nSo apparently the solutions is build on Azure. So answer: C"},{"comment_id":"1289130","poster":"539d541","timestamp":"1727288280.0","content":"Selected Answer: C\nAzure SQL is on the cloud. It follows that the rest of the solution would be for Dynamics als0","upvote_count":"1"},{"upvote_count":"1","content":"Azure SQL Server is considered as ON_PREM\n\nchecki it....","comment_id":"1239276","poster":"Smyrol","timestamp":"1719666840.0"},{"content":"Selected Answer: C\nIt is the only option that works","upvote_count":"1","comment_id":"971490","timestamp":"1691101140.0","poster":"MEG_Florida"},{"timestamp":"1687093320.0","upvote_count":"2","content":"Selected Answer: C\nC ONLY","comment_id":"926700","poster":"xkapelis"},{"poster":"charles879987","content":"C is the answer. The database is on Azure database, not on-premise","timestamp":"1672468560.0","comment_id":"762516","upvote_count":"4"},{"upvote_count":"2","poster":"AzureJobsTillRetire","content":"Selected Answer: C\nBoth C and D can achieve the results, but gateway requires more configuration effort, so the answer goes to C.\n\nDo not discount D just because it uses on-premise data gateway. Gateway can be used even if all data in a dataset is in Azure.\n\nHere below is directly copied from PowerBI service gateway connection configuration page for a dataset that comes out of an Azure SQL database. \"You don't need a gateway for this dataset, because all of its data sources are in the cloud, but you can use a gateway for enhanced control over how you connect\".","timestamp":"1671046020.0","comments":[{"timestamp":"1687962960.0","upvote_count":"1","content":"On-premises allows multiple users to connect to multiple on-premises data sources.\nThe report has to be related in a many-to-one relationship.","poster":"blrjohn","comment_id":"936778"}],"comment_id":"745395"}],"answer_images":[],"answer_ET":"C","answers_community":["C (100%)"]},{"id":"AvbXhGRHaECIKJt8949C","question_images":[],"answer":"B","discussion":[{"comments":[{"comment_id":"1058093","poster":"ZillowGosia","upvote_count":"20","content":"Finger crossed for every one. Good luck with exam <3. and thank yuo to every one who helped with anserws.","timestamp":"1698687060.0"},{"timestamp":"1672327860.0","poster":"VinayKadaya","comment_id":"761196","upvote_count":"54","content":"But, but, I am starting from reverse.","comments":[{"poster":"LearningBinomics","upvote_count":"8","comment_id":"1049180","content":"waaaajajajajajajajajajaja","timestamp":"1697844120.0"}]},{"content":"Take a rest girls, we earned it.","upvote_count":"103","comments":[{"upvote_count":"18","timestamp":"1674443820.0","poster":"yordiye","comment_id":"784929","content":"Take a rest girls & women :) We earned it ! Oh the answer is A","comments":[{"comments":[{"comments":[{"poster":"Caterpillar_Soni","upvote_count":"8","content":"No body comes here to comment after giving the EXAM, until unless you failed it.","timestamp":"1684520820.0","comment_id":"902174"}],"comment_id":"882279","timestamp":"1682576400.0","poster":"sa56","upvote_count":"3","content":"Yet to give Exam, will rest after that"}],"upvote_count":"2","poster":"Nemesizz","timestamp":"1676548500.0","comment_id":"810605","content":"Why A?"}]}],"timestamp":"1669352040.0","poster":"MayaYao","comment_id":"726390"},{"poster":"Aldeus","content":"i'm crying rn","upvote_count":"7","comment_id":"1091320","timestamp":"1702066860.0"}],"comment_id":"705556","poster":"milb","timestamp":"1666874880.0","upvote_count":"163","content":"Take a rest boys, we earned it."},{"comment_id":"703731","content":"Selected Answer: B\nIt's already stated correctly in the given answer.\n\"Analysts must be able to create new reports from the dataset that contains the profit and loss data\"\n\"Analysts must NOT be able to make new reports by using the balance sheet data\"\nDue to this different permissions you need 2 datasets. Import mode.","timestamp":"1666689720.0","poster":"fred92","upvote_count":"30","comments":[{"comment_id":"726389","poster":"MayaYao","content":"You can have multiple options. A single imported dataset can meet the requirements as well.\nP&L is Azure SQLDB - normally DirectQuery. If there is an option - one DirectQuery and one import will be more appropriate.","upvote_count":"5","timestamp":"1669351980.0"}]},{"timestamp":"1737624780.0","content":"Selected Answer: B\n2025 Batch good luck :-)","poster":"Odidepse","upvote_count":"6","comment_id":"1345273"},{"content":"Selected Answer: B\nTo all those taking the exam soon, just remember: No confusion, and no need to discuss further!","comment_id":"1322229","upvote_count":"4","timestamp":"1733374380.0","poster":"0a4bf3a"},{"timestamp":"1727771220.0","comment_id":"1291876","content":"Good luck musti.","poster":"imshop","upvote_count":"1"},{"timestamp":"1726427460.0","upvote_count":"1","poster":"Arth_1111","content":"Selected Answer: B\nBBBBBBBBBBBBBBBBBBbbbbb","comment_id":"1284249"},{"comments":[{"timestamp":"1721139660.0","comment_id":"1248988","upvote_count":"1","poster":"moniqbk","comments":[{"poster":"Rainbow_May","comment_id":"1302948","upvote_count":"2","timestamp":"1729876680.0","content":"he/she didn't reply to you meaning a success! people who failed might come this website again to learn the questions lol"}],"content":"let us know"}],"upvote_count":"2","timestamp":"1718670420.0","poster":"stacieinwonderland","content":"If I studied all the questions carefully and know all the answers by heart, will I pass the exam for sure?","comment_id":"1232170"},{"comment_id":"1229819","upvote_count":"1","timestamp":"1718283960.0","content":"Selected Answer: B\nPnL and BS data must be separated because of the different sharing settings.","poster":"HenryBiz"},{"upvote_count":"6","content":"Tomo is my exam....!","poster":"Invisible_Monk99","timestamp":"1716981600.0","comment_id":"1220852"},{"content":"The minimum number of Power BI datasets needed to support the reports is B. two imported datasets.\n\nReasoning: \n\n1. One dataset for balance sheet and product catalog data. This dataset can be accessed by all analysts.\n\n2. Another dataset for profit and loss data. This dataset needs to be filtered by business unit, so it should be separate to allow for row-level security. This will ensure that analysts can only access the data of their respective business unit.","timestamp":"1715828400.0","upvote_count":"4","poster":"e3ddceb","comment_id":"1212215"},{"comments":[{"comment_id":"1302949","timestamp":"1729876740.0","upvote_count":"1","content":"thank you for sharing!!","poster":"Rainbow_May"}],"timestamp":"1714660200.0","upvote_count":"16","poster":"MoneyStacking","comment_id":"1205653","content":"Guys and girls, we finally made it. \nI just passed with 917/1000. Save your time and learn and memorize all these questions because 85% of the 50 exam questions were exactly the same as here. \n\nCheers and goodluck!"},{"upvote_count":"13","timestamp":"1712620320.0","content":"Went through the questions in the last three weeks but only once, passed exam today 800+. Truly appreciate everyone who input in the comments section, I almost learned everything about this exam from each of you. Wish you all good luck!","poster":"Twinklingle","comment_id":"1191867"},{"timestamp":"1707228780.0","upvote_count":"2","poster":"JohnChung","comment_id":"1142199","content":"Selected Answer: B\nHints from the wordings in security requirements \"Analysts must be able to create new reports from the dataset that contains the profit and loss data\"\nUse of relative clause for dataset implies there are more than one datasets"},{"comment_id":"1113440","timestamp":"1704357600.0","content":"I have my exam tomorrow, gone through these questions 3 times, 4/5/6 times for the ones I got wrong. Will update how I go tomorrow.","upvote_count":"4","comments":[{"poster":"08b2ddd","content":"Hi, Just an update. I got 958/1000 but was hungover af and not feeling my best. Every single question bar 1 was from these 250 questions. Guys it was so easy, finished it in 30 minutes. The most important thing is to know these questions BY HEART! know every single answer (or at least a decent amount of them) and you will be fine. The questions are exactly the same. Obviously read the comments and don't go by what this website says it is.","upvote_count":"36","timestamp":"1704505980.0","comments":[{"content":"Thank you for this update! I'm taking my exam this week or the next one","upvote_count":"2","timestamp":"1707235680.0","poster":"madyjoe21","comments":[{"timestamp":"1708014900.0","comment_id":"1151121","upvote_count":"10","poster":"madyjoe21","content":"Hey guys! I just got 906/1000. There was about 10 questions that wasn't from here, 1 case study and 2 different sequence questions that use the same scenario, both from here. The language was a bit different as well, like sematic dataset/data model. Advise: know the answers here, I mean, learn them not only memorize it because you going to need it for the other questions that are not from here."}],"comment_id":"1142355"}],"comment_id":"1114883"}],"poster":"08b2ddd"},{"timestamp":"1703157480.0","comment_id":"1102391","upvote_count":"5","content":"I'm wishing all of you who are taking the exam eventually, that you all pass! I'm taking mine still this year, I just finished all the questions and now it's revision and practice time again and again. I'll get back after the exam to give some feedback on how was it and what should we expect. Thank you so much to all the community here for helping in all the questions :) Take care!","poster":"brunocbento"},{"comment_id":"1099983","timestamp":"1702927200.0","upvote_count":"7","content":"my brain is fried did all the questions in 3 days have exam tomorrow let's see.","poster":"sono_moma"},{"timestamp":"1702090800.0","upvote_count":"18","comment_id":"1091411","poster":"LeeTheRed","content":"I just came back from the exam. Just scrapped through with around 800 points (transcript not available yet, just a screen flashing at the end of the exam). I'd said most if not all of the questions were from this website (don't ask me which one because I forgot them right away after the exam except for one question which I remember because I was struggling with it and that was the one that you have to merge 5 or 6 different database tables together(Managers/RegionManager etc...), I spent a lot of times on this question so make sure you put extra attention on it! The rest were easy! There were 48 questions and one scenario question. Good luck to all and thank you to all that went through it and left your valuabe feedbacks on this site! Cheers!"},{"timestamp":"1701448500.0","content":"Hi All, I have passed an exam with score nearly 900 points. \nMost of the questions were from this site. Exam 01.12.2023\nGood luck all !!!","upvote_count":"18","comment_id":"1085352","poster":"Tomasz_Black"},{"timestamp":"1700497380.0","poster":"Suraj97","comment_id":"1075589","upvote_count":"6","content":"All the best, Kings! We got this..."},{"content":"B correct.\nIn this workspace includes two imported datasets:\n+ Dataset for Ending Balance with Dataset Permission as Read --> Cause analysts are not allow to make report. only read and view dat. Mode: Imported.\n+ Dataset for Profit & Loss with Dataset Permission: Build, cause analysts have to make report on this dataset. Mode :imported","timestamp":"1699790760.0","poster":"0a58a92","comment_id":"1068494","upvote_count":"4"},{"poster":"WRTopics","upvote_count":"1","content":"Selected Answer: A\nwe can have 1 dataset and 2 sources.","timestamp":"1697657100.0","comment_id":"1047173"},{"poster":"MEG_Florida","content":"Same, good luck to all.","comment_id":"971510","timestamp":"1691103420.0","upvote_count":"3"},{"content":"wishing us all best of luck","poster":"nmnm22","comment_id":"915149","timestamp":"1685949060.0","upvote_count":"8"},{"content":"Selected Answer: B\ntwo imported datasets","upvote_count":"5","poster":"rania","timestamp":"1685681700.0","comment_id":"912541"},{"content":"Selected Answer: B\nB. Two imported datasets\n\nTo meet the requirements, it is necessary to separate the balance sheet data from the profit and loss data. This will enable analysts to access all balance sheet and product catalog data (Dataset 1) and only the profit and loss data of their respective business unit (Dataset 2). By having separate datasets, analysts can create new reports from the profit and loss dataset without including them in the quarterly reports for the board.\n\nHaving two imported datasets allows for better data management, consistency, and flexibility in reporting. It also ensures that analysts cannot create new reports using the balance sheet data, as per the security requirements.\n\nTherefore, option B is the correct answer: two imported datasets.","poster":"Nemesizz","timestamp":"1685204880.0","comment_id":"908105","upvote_count":"6"},{"poster":"Alexdj7","upvote_count":"13","comment_id":"896685","timestamp":"1683983640.0","comments":[{"content":"So? did you pass?","poster":"SteveTheBeast","upvote_count":"3","comment_id":"997229","timestamp":"1693704420.0"}],"content":"I have scheduled exam for tomorrow, wish me GL :)"},{"timestamp":"1683348900.0","upvote_count":"5","poster":"Shalaleh","content":"Selected Answer: B\nAnalysts must be able to create new reports from the dataset that contains the profit and loss data.\nAnalysts must NOT be able to make new reports by using the balance sheet data.\nAccording to these two sentences we need to imported datasets.","comment_id":"890483"},{"comment_id":"886106","timestamp":"1682938140.0","upvote_count":"1","poster":"Shalaleh","content":"Selected Answer: A\nwe have two data sources, but we can have one single dataset."},{"content":"Correct answer","timestamp":"1682578320.0","comment_id":"882310","upvote_count":"1","poster":"sa56"},{"poster":"glenman0202","content":"Good works gentlemen, now back to the grind","timestamp":"1679168160.0","upvote_count":"5","comment_id":"843103"},{"poster":"charles879987","content":"Selected Answer: B\nAnswer is B. It's necessary to have two datasets. One for generating profit/loss, one for revenue-related data in quarterly reports","upvote_count":"4","comments":[{"timestamp":"1676749260.0","comment_id":"813450","content":"and ending balances.","upvote_count":"1","poster":"charles879987","comments":[{"poster":"charles879987","content":"Never mind. Answer is D because of the sentence: \"Analysts must NOT be able to make new reports by using the balance sheet data.\" So that rules of balance sheet data source. This is kind of assuming that analyst will be able to generate balance data based on Azure SQL database connection which uses direct query.","upvote_count":"1","comment_id":"813455","comments":[{"poster":"charles879987","content":"Never mind. Answer is D because of the sentence: \"Analysts must NOT be able to make new reports by using the balance sheet data.\" So that rules out balance sheet data source, assuming that analyst will be able to generate balance data, used in quarterly report, based on Azure SQL database connection which uses direct query.","timestamp":"1676749860.0","comment_id":"813457","upvote_count":"1"}],"timestamp":"1676749800.0"}]}],"timestamp":"1676749140.0","comment_id":"813449"},{"content":"Why A. Please explain","comment_id":"810602","timestamp":"1676548260.0","poster":"Nemesizz","upvote_count":"1"},{"content":"I need to revise again. Much revision needed!","comment_id":"806838","upvote_count":"4","timestamp":"1676236920.0","poster":"Nawabi"},{"content":"Selected Answer: A\nA should be correct here based on just 1 build requirement for analyist: allowed on P&L, not allowed on Balance sheet","timestamp":"1674499020.0","upvote_count":"1","poster":"LuukVriel","comment_id":"785717"},{"poster":"anasben","timestamp":"1673774220.0","upvote_count":"3","content":"Selected Answer: B\nWe can use One Imported Data Set an use OLS, but it's only applies to Viewers in a workspace. (Workspace members assigned Admin, Member, or Contributor have edit permission for the dataset and, therefore, OLS doesn’t apply to them. )\n\n=> In Our Case an Analyst have to Build a Report based in a signle Table (this table must Load in a independent Dataset )\n\n=> Solution then is the create to dataset in the same WS then publish an App. \n\n\nCorrect Answer is B :","comment_id":"776319"},{"comment_id":"765087","poster":"Marionjambon","content":"Selected Answer: B\nB as the permissions for Analysts are different for the Profit & Loss and the Balance sheet data","timestamp":"1672782300.0","upvote_count":"5"},{"poster":"AzureJobsTillRetire","timestamp":"1671046560.0","comment_id":"745400","content":"Selected Answer: B\nGiven answer is correct. Two datasets are required. One for profit and loss data, and one for balance sheet data. An app can be created on the profit and loss data set only for data analysts to build reports.","upvote_count":"4"},{"comment_id":"738180","poster":"Hoeishetmogelijk","comments":[{"poster":"Hoeishetmogelijk","upvote_count":"1","comments":[{"content":"Actually the requirement is: The reports must be updated with the latest data by 5 AM each day.\nImport is still the right choice.","poster":"Hoeishetmogelijk","timestamp":"1670784720.0","upvote_count":"2","comment_id":"742000"}],"comment_id":"738185","content":"I mean maximum load time must be 2 days of course!","timestamp":"1670435220.0"}],"upvote_count":"2","timestamp":"1670434740.0","content":"Selected Answer: A\nA. a single imported dataset.\nThere are 2 sources, but common logic must be applied (and the same time dimension). So the data will come together in one dataset.\nMinimum load time must be 2 days, so import is fine."},{"timestamp":"1670024520.0","comment_id":"734119","poster":"disndat7","upvote_count":"3","content":"Selected Answer: A\nA for sure. The rest doesn't make sense. Don't overthink it."},{"timestamp":"1665909840.0","content":"would go A","poster":"EMMALEEEEEEEEE","comment_id":"696105","upvote_count":"3"},{"timestamp":"1663651260.0","content":"Selected Answer: A\nA. a single imported dataset","comment_id":"673824","poster":"Namenick10","upvote_count":"17"},{"poster":"fdsdfgxcvbdsfhshfg","comments":[{"upvote_count":"3","poster":"Luffy561","content":"so you are going with A?","comment_id":"679320","timestamp":"1664154180.0"}],"timestamp":"1663532460.0","content":"Legit, all done 🤙🤙🤙","upvote_count":"8","comment_id":"672730"}],"unix_timestamp":1663532460,"url":"https://www.examtopics.com/discussions/microsoft/view/82723-exam-pl-300-topic-14-question-4-discussion/","answers_community":["B (75%)","A (25%)"],"question_text":"What is the minimum number of Power BI datasets needed to support the reports?","answer_ET":"B","timestamp":"2022-09-18 22:21:00","answer_description":"","answer_images":[],"isMC":true,"topic":"14","choices":{"D":"a single DirectQuery dataset","B":"two imported datasets","A":"a single imported dataset","C":"two DirectQuery datasets"},"question_id":59,"exam_id":116},{"id":"8EOA62miWDgNsM4lNtRH","answer":"D","discussion":[{"poster":"Muffinshow","comment_id":"657482","content":"Selected Answer: D\nWrong answer, A will affect the size of the model as would C.\nB doesn't give you enough information about the distribution (just the average)\nD is the right answer.","timestamp":"1662126240.0","upvote_count":"137","comments":[{"comment_id":"897061","upvote_count":"1","content":"for D to be correct we need to calculate length of the strings in col1 beforehand so it is not correct","timestamp":"1684012740.0","comments":[{"comment_id":"919074","upvote_count":"18","content":"If you enable to column profile from view menu, you can actually group the distribution by text length. It is not grouping the actual column, rather just grouping the distribution.","timestamp":"1686298380.0","poster":"sandipnair"}],"poster":"KARELA"},{"comment_id":"663740","poster":"GPerez73","content":"I agree","upvote_count":"2","timestamp":"1662650760.0"},{"comment_id":"723504","upvote_count":"2","timestamp":"1669035600.0","content":"I agree completely!","poster":"Hoeishetmogelijk"},{"comment_id":"714520","timestamp":"1667994240.0","comments":[{"upvote_count":"3","content":"D is not aggregating in power query, it's viewing the column profile","timestamp":"1710326220.0","poster":"Elektrolite","comment_id":"1172440"},{"upvote_count":"7","comments":[{"poster":"Mubarakbabs","comments":[{"comment_id":"884732","poster":"lizbette","upvote_count":"4","timestamp":"1682805900.0","content":"why doesn't B affect the size of the model but A does?"}],"content":"Yes, option B will not affect the size of the model, but it won't show us the frequency distribution, which is what we really need. Option D doesn't create any new column, it only changes how the column distribution is displayed, so it won't affect the size of the model","comment_id":"779801","timestamp":"1674033600.0","upvote_count":"12"}],"comment_id":"764346","poster":"GabryPL","timestamp":"1672736460.0","content":"Option B is also correct for me\nit's the only one that will not affect the size of the model"},{"timestamp":"1672071720.0","upvote_count":"5","poster":"Kai_don","comment_id":"757646","content":"Option A is saying useing calculated column which increases the size of the model. So D is correct."}],"poster":"Jonagan","content":"Why do you think that aggregating in the PowerQuery size will not influence the size of the datamodel? its getting smaller isnt it?\nMeasures are the only solutions that does not influence the datamodel. They require CPU but but does not store additional data or does not reduce the data in the model","upvote_count":"17"}]},{"comments":[{"upvote_count":"7","timestamp":"1676476080.0","comment_id":"809699","poster":"eloomis","content":"The problem is this method doesn't make the distribution analyzable in the report, which I think is what the question is getting at. It will show you the distribution but you need a dax measure to place in your report to visualize that. I would go with option B as it creates a measure which you can use in the report, and it doesn't contribute to the size of the model as with A."},{"content":"D is correct and it can be tested by following step mentioned by Lukelin08","poster":"HemantGorle","timestamp":"1673775900.0","comment_id":"776379","upvote_count":"2"},{"upvote_count":"1","comment_id":"1125940","poster":"cs3122","timestamp":"1705586760.0","content":"Thank you, just tested and it works. D has to be the answer, as it doesn't impact the model size"},{"poster":"miro26","comment_id":"958473","upvote_count":"2","timestamp":"1689943080.0","content":"Make sure your column type is not \"variant\" ;)"}],"poster":"lukelin08","content":"Selected Answer: D\nIts D, this can easily be tested by going to Power Query Editor > View > Column Profile > distribution graph, click the three little dots and select group by text length. This will allow you to view the distribution of text length within the column","comment_id":"687243","upvote_count":"81","timestamp":"1665005760.0"},{"timestamp":"1743561000.0","comment_id":"1419856","upvote_count":"1","content":"Selected Answer: D\nOpen the PQE enable the Column Distribution in View ribbon, click on the ellipses in the bottom Bar chart box Group By > Text length","poster":"e5accfd"},{"poster":"Minh2712","upvote_count":"1","content":"Selected Answer: D\nD is the correct answer","comment_id":"1402262","timestamp":"1742731200.0"},{"content":"Selected Answer: D\nIt's very simple and logical AB,C will increase the model size so D is the right answer.","comment_id":"1340611","poster":"MANANDAVEY","upvote_count":"1","timestamp":"1736907120.0"},{"content":"Selected Answer: D\nChanging the column profile distribution in Power Query Editor allows you to analyze the frequency distribution of string lengths without permanently modifying or adding new data. This operation is exploratory and does not affect the data loaded into the model or the size of the model.","comment_id":"1332011","upvote_count":"1","timestamp":"1735232340.0","poster":"Kleeneeex"},{"content":"Selected Answer: D\nTotally agree with lukelin98 who is also providing detiled steps to analyze frequency distribution of the string length.\nA and C solutions add columns to our model so are increasing its size.\nSolution B is returning one single value (the average lenght) and that's not something you can use to analyze any frequency","poster":"jaume","timestamp":"1731773880.0","comment_id":"1313117","upvote_count":"1"},{"content":"Selected Answer: D\noption D is correct","poster":"ae8a90c","comment_id":"1296216","timestamp":"1728672960.0","upvote_count":"1"},{"comment_id":"1291362","comments":[{"timestamp":"1727670600.0","upvote_count":"1","content":"As adding a Column can increase the model size, so this option does not work here.","poster":"ykb_proudly_Indian","comment_id":"1291390"}],"upvote_count":"1","timestamp":"1727665860.0","poster":"ykb_proudly_Indian","content":"C: Tried and tested\nTransform Data -> Add Column -> Extract -> Length"},{"content":"calculted columns will increase the size of the models so those are out and the other is finding the average leavind D as correct","timestamp":"1727510460.0","comment_id":"1290564","upvote_count":"1","poster":"itGoat"},{"timestamp":"1723643760.0","upvote_count":"2","comment_id":"1265809","content":"Selected Answer: D\nfor me is D. From Power Query Editor, change the distribution for the Column profile to group by length for col1","poster":"rcaliandro","comments":[{"content":"Tested it is D for sure. In power Query Editor, View check column profile. There is the possibility to group by value or text lenght. Choose text lenght and this will show the lenght of col1","comment_id":"1269231","poster":"rcaliandro","timestamp":"1724136780.0","upvote_count":"1"}]},{"upvote_count":"2","poster":"Datanoob101","comment_id":"1263972","content":"Selected Answer: D\nUpon a little research it turns out that calculated columns=larger data models.\nOption A & C: both introduce a new column. Will affect the size of the model.\nOption B: As muffin show and mubarakbabs stated above, it doesn't give us enough info (only avg)\n\nAns must be D.","timestamp":"1723366500.0"},{"poster":"Kiran37","comment_id":"1252374","upvote_count":"1","content":"correct answer","timestamp":"1721556720.0"},{"upvote_count":"1","timestamp":"1715167440.0","content":"Selected Answer: D\nD for me","poster":"yaya32","comment_id":"1208344"},{"content":"I also think D as it won't affect the data model size","comment_id":"1206801","upvote_count":"1","timestamp":"1714896660.0","poster":"RoxyRishi"},{"content":"D. It says to analyze, which means in the context of this question, look at to determine. It also states it must not affect the model size. A calculated dax column will affect size of the model. D is perfect, because with the column profile tool you able to see the exact information that are looking for.","poster":"9f73003","timestamp":"1713387840.0","upvote_count":"1","comment_id":"1197503"},{"comment_id":"1171672","upvote_count":"2","poster":"AZFabio","content":"Selected Answer: A\nA is right, but B looks correct to me as well","timestamp":"1710246660.0"},{"timestamp":"1710066900.0","comment_id":"1170246","content":"D works just fine and DOES NOT affects the model size.","upvote_count":"1","poster":"benni_ale"},{"upvote_count":"3","comment_id":"1159443","timestamp":"1708930140.0","poster":"Dani_eL","content":"Selected Answer: A\nI think sometimes it's better to stay grounded and read the question for what it is.\n\nrelying on facts only;\nyou create a REPORT\nyou load data\nyou need to be able to see frequency distribution of Len(col1) (supposedly on the report as you just were asked to create one, make sense?)\n\nIn the available answers you have 2 options from REPORT\nOne calculates sum, the other average.\nJust go for the sum which is answer A\n\nAs everyone knows DAX creates new info from data ALREADY in your model.\nIn Power query you need to close and apply to use your new info(=> affects model)"},{"content":"Option D , doesnot allow you to see the string length of each row, just shows Min and Max","comment_id":"1133426","upvote_count":"1","timestamp":"1706367780.0","poster":"svbz"},{"comment_id":"1132939","poster":"datacert2022","upvote_count":"1","timestamp":"1706308320.0","content":"Why is A the right answer when 91% of the community indicates it's D? That question is for Exam Topics the company, not the community."},{"comment_id":"1123120","timestamp":"1705301760.0","poster":"JohnChung","content":"I tried. D is the correct answer","upvote_count":"1"},{"comment_id":"1069874","poster":"Lalith_parsa","upvote_count":"1","content":"C. From Power Query Editor, add a column that calculates the length of col1\n\nAdding a column in Power Query Editor that calculates the length of col1 before the data is loaded into the model is a more efficient approach. This processing is done during the data load, and the calculated length can be used for analysis without increasing the size of the in-memory data model.","timestamp":"1699923420.0"},{"comment_id":"1069525","content":"chat GPT answer :\nC. From Power Query Editor, add a column that calculates the length of col1\n\nExplanation:\n\nIn Power Query Editor, you can add a custom column to calculate the length of the text in col1 without affecting the size of the Power BI model. This is a more efficient way to perform the operation on the data before it is loaded into the model.\n\nOption A suggests adding a DAX calculated column in the report, but this would affect the size of the model, which is not desired.\n\nOption B suggests using a DAX function to calculate the average length, which is not the same as analyzing the frequency distribution of string lengths.\n\nOption D refers to changing the distribution for the Column profile, which is a profiling feature and doesn't directly calculate the lengths for the purpose of frequency distribution. The correct approach for this scenario is to add a column in Power Query Editor.","timestamp":"1699894440.0","poster":"golia","upvote_count":"2"},{"poster":"oreshetnik","timestamp":"1698683640.0","upvote_count":"1","comment_id":"1058037","content":"I don't understand in solution they give answer not correct?("},{"upvote_count":"1","content":"Answer is D","poster":"RMUK","comment_id":"1045100","timestamp":"1697471040.0"},{"comment_id":"1044195","content":"Selected Answer: D\nD is the right answer. Since we just need to analyze and should not change the model size, viewing it on Power Query Editor Column profile is the only option","poster":"Kish1604","upvote_count":"4","timestamp":"1697378760.0"},{"timestamp":"1696661760.0","content":"Selected Answer: D\nTested in Power query. D is correct","poster":"sankeytm","comment_id":"1027141","upvote_count":"4"},{"upvote_count":"2","timestamp":"1693879680.0","poster":"Igetmyrole","comment_id":"998951","content":"D is the correct answer. \nBy changing the distribution to group by length in Power Query Editor, we can analyze the frequency distribution of string lengths in the \"col1\" column without adding additional calculated columns or measures that would increase the model's size. This allows us to perform this analysis at the data preparation stage, which is more efficient and does not impact the model's size in the report."},{"timestamp":"1689943500.0","comment_id":"958481","upvote_count":"1","content":"D\nhttps://learn.microsoft.com/en-us/power-query/data-profiling-tools#group-by-value\nBut \"The distribution cannot be computed for the currently selected column\" make sure your column type is not \"variant\".","poster":"miro26"},{"comment_id":"955380","content":"Selected Answer: D\nChatGPT:\nThe correct answer to your question is option D.\nHere's how to proceed:\n\n1. Load the data extract into Power Query Editor as you did before.\n\n2. Select the \"col1\" column in Power Query Editor.\n\n3. On the \"Home\" tab of the Power Query Editor pane, click \"Column Profile\" in the \"Column Tools\" group.\n\n4. In the \"Column Profile\" pane, click the radio button (gear icon) next to \"col1\".\n\n5. Select \"Distribution\" from the drop-down menu.\n\n6. In the \"Column Distribution\" dialog, select the \"Group By Length\" option to get the distribution of values based on the length of the string.\n\n7. Click \"OK\" to apply the change.\n\n8. Close and apply changes to load the changed data into Power BI Desktop.\n\nYou can now use clustered distribution column profiling to analyze the frequency of distribution of string lengths in \"col1\" without affecting the size of the data model.","timestamp":"1689682560.0","poster":"ManuelG00","upvote_count":"2"},{"upvote_count":"1","poster":"hDouk","comments":[{"comment_id":"964529","content":"Looks like we can't refer to Chat gpt, there's another comment saying D is the correct answer also using gpt","upvote_count":"2","poster":"Chita_3385","comments":[{"comment_id":"971108","poster":"EwoutBI","upvote_count":"1","timestamp":"1691066160.0","content":"Yeah, the answer from ChatGPT often depends on how you ask it."}],"timestamp":"1690449120.0"}],"timestamp":"1689682260.0","comment_id":"955370","content":"I think the answer is A.This is what i asked chat gpt, check the response which states DAX columns calculated on the fly, M columns in pquery are stored: what is the difference between custom column in power query and calculated column in report view?"},{"upvote_count":"1","comment_id":"927684","timestamp":"1687192320.0","content":"It's definitely D. No need for further discussion. With PowerQuery you could do that by going to View > Colum Profile > Group by > Length","comments":[{"comment_id":"968423","content":"How?? I can´t group by","upvote_count":"1","timestamp":"1690829460.0","poster":"AlejandroErazo"}],"poster":"RenzoNorero"},{"poster":"lordsharaf","content":"The correct answer is D. Tested solution.","upvote_count":"1","timestamp":"1685640300.0","comment_id":"912307"},{"poster":"Shalaleh","content":"Selected Answer: D\nI have checked it. We can group by value or length.","comment_id":"887066","timestamp":"1683008100.0","upvote_count":"2"},{"poster":"junaid2107","comment_id":"885637","content":"D is correct.","timestamp":"1682890620.0","upvote_count":"6"},{"poster":"alojt","content":"It seams ChatGPT has a better solution for us :D \nChatGPT says: \"you can follow the following steps:\n\nIn the Power BI Desktop, select the \"Modeling\" tab.\nClick on the \"New Measure\" option from the ribbon.\nIn the Formula Bar, enter the following formula:\nLength Distribution = COUNTROWS(VALUES(Table[col1]))\nClick on \"Enter\" to create the measure.\nNow, add a \"Histogram\" visualization to your report.\nFrom the Fields pane, select the \"Length Distribution\" measure and drag it onto the \"Values\" field well of the Histogram visualization.\nNext, drag the \"col1\" field into the \"Axis\" field well of the Histogram visualization.\nYou should now be able to see the distribution of string lengths of the col1 field in the Histogram visualization without affecting the size of the model.\"","comment_id":"870226","upvote_count":"2","timestamp":"1681480080.0"},{"poster":"RazaTheLegend","upvote_count":"1","timestamp":"1681279800.0","comment_id":"867957","content":"Selected Answer: D\nOption B will not affect the size of the model, but it won't show us the frequency distribution, which is what we really need. Option D doesn't create any new column, it only changes how the column distribution is displayed, so it won't affect the size of the model"},{"content":"Selected Answer: D\nD é a resposta certa.","comment_id":"864217","upvote_count":"1","timestamp":"1680900360.0","poster":"brunoquintela"},{"poster":"Aneran","upvote_count":"4","comment_id":"858671","content":"Selected Answer: C\nC. From Power Query Editor, add a column that calculates the length of col1.\n\nTo analyze the frequency distribution of the string lengths in a column in Power BI, you can add a column that calculates the length of the target column in the Power Query Editor. This can be achieved using the \"Add Column\" tab in the Power Query Editor and selecting \"Custom Column\". In the \"Custom Column\" dialog box, you can use the \"Text.Length\" function to calculate the length of the \"col1\" column. This will create a new column with the length of each \"col1\" value, which can be used for further analysis in the report without affecting the size of the model.","timestamp":"1680426000.0"},{"timestamp":"1679600940.0","upvote_count":"1","content":"D. En el Editor de Power Query, cambie la distribución del perfil de columna a agrupar por longitud para col1","comment_id":"848622","poster":"DUVANES"},{"timestamp":"1678864260.0","content":"Selected Answer: D\nD is the correct answer -- it is possible to analyze text lengths through \"Column Profile\". All other options affect the model size","poster":"Akin_Eren","upvote_count":"1","comment_id":"839607"},{"content":"Option C is Correct","comment_id":"837775","poster":"saharkma","timestamp":"1678697040.0","upvote_count":"1"},{"timestamp":"1678353360.0","poster":"Jae17","comment_id":"833757","upvote_count":"2","content":"Answer should be C \n\n Adding a column in Power Query Editor will increase the size of the query in the Power BI Desktop file. However, the requirement specified in the question was that the solution should not affect the size of the \"model\", which typically refers to the data model in Power BI.\n\nOption D suggests changing the distribution for the column profile to group by length for col1 from the Power Query Editor. However, the \"Column profile\" option is used to display the basic statistics of the data in a column, such as minimum, maximum, average, median, etc. It does not provide a frequency distribution of the string lengths in col1.\n\nTo get the frequency distribution of the string lengths in col1, we need to group the data by the length of col1 and count the frequency of each group, which can be achieved by adding a column that calculates the length of col1 in the Power Query Editor and then using the \"Group By\" feature in the same. Therefore, option D is not a valid solution to the problem described in the question."},{"upvote_count":"4","content":"Option C is correct on 04-March-2023","poster":"SanaCanada","timestamp":"1677916980.0","comment_id":"828738"},{"content":"Selected Answer: D\nYou need to analyze, you do not need to present this data in a chart, for example. In these words, I believe D is the correct answer.","comment_id":"825245","upvote_count":"1","poster":"oogrio","timestamp":"1677616200.0"},{"comment_id":"824556","timestamp":"1677573360.0","content":"Selected Answer: C\nI asked ChatGPT and this is what it said \n\"If the goal is to analyze the frequency distribution of string lengths in col1 without affecting the size of the model, the best option would be to use option C, which involves adding a custom column in Power Query Editor to calculate the length of col1.\n\nThis option creates a new column within Power Query, which does not increase the size of the model. It also allows you to perform the required analysis without adding a column to the underlying data model.\n\nOption A, which involves adding a calculated column to the data model using a DAX formula, would also achieve the same result, but it would add a column to the underlying data model, which could potentially impact the size of the model.\n\nOption D, which involves changing the distribution for the Column profile, is also a valid approach, but it provides a visual summary and does not allow for further analysis.\"","poster":"Heyzzzzzzzzzzzzzz","upvote_count":"4"},{"timestamp":"1676933340.0","upvote_count":"1","poster":"TauseefB","content":"The correct answer is C. From Power Query Editor, add a column that calculates the length of col1.\n\nAdding a new column to the table that calculates the length of col1 in Power Query Editor will allow you to analyze the frequency distribution of the string lengths without affecting the size of the model. This is because Power Query operates on the data before it is loaded into the model, so any changes made in Power Query Editor will not affect the size of the model.\n\nOption A, adding a DAX calculated column in the report, would add a new column to the model and could potentially affect the size of the model.\n\nOption B, adding a DAX function in the report to calculate the average length of col1, would not allow you to analyze the frequency distribution of string lengths.\n\nOption D, changing the distribution for the Column profile to group by length for col1 in Power Query Editor, would not add a new column to the table, but it would also not allow you to analyze the frequency distribution of string lengths","comment_id":"815984"},{"content":"Selected Answer: D\n1. Power Query Editor -> View -> Enable Column Profile\n2. Select three dots (top left corner) in the profile pane appear at the bottom of the Query Editor window.\n3. Group By -> Text length","comment_id":"803860","timestamp":"1675990980.0","upvote_count":"1","poster":"Gar9"},{"timestamp":"1674676260.0","upvote_count":"1","poster":"madyjoe21","content":"Selected Answer: D\nChecked! It is d. Just a visualization will not change the size of the ds.","comment_id":"788084"},{"upvote_count":"1","content":"Selected Answer: D\nIts D, this can easily be tested by going to Power Query Editor > View > Column Profile > distribution graph, click the three little dots and select group by text length. This will allow you to view the distribution of text length within the column.","comment_id":"776380","poster":"HemantGorle","timestamp":"1673775960.0"},{"timestamp":"1672984980.0","upvote_count":"1","comment_id":"767325","comments":[{"timestamp":"1672985340.0","content":"My Bad - calculated columns will store the result and increase the data model size .","upvote_count":"2","comment_id":"767330","poster":"dnpr"}],"content":"Generally, measures are more useful, but the trade-offs are the performance hit (report runtime vs. pre-processed), storage space, and the type of expressions you can use. For example calculated columns are often used when you want to filter on the result rather than just as a calculated result - Here \"A\" correct .","poster":"dnpr"},{"upvote_count":"4","timestamp":"1672936320.0","content":"Selected Answer: A\nCreating a new column in Power Query adds to the data model size because the column is calculated prior to being loaded into the data model. Where as creating a calculated column, that is not a part of the data model. I believe the answer is A.","poster":"oakey66","comment_id":"766834"},{"content":"Tested the scenario\nAnswer is D","timestamp":"1672906380.0","poster":"Analysis","upvote_count":"1","comment_id":"766362"},{"comments":[{"comment_id":"766271","content":"Did you do the test?","timestamp":"1672898040.0","poster":"PracticeAnalytics","upvote_count":"1"}],"timestamp":"1672750200.0","content":"I would say A is the answer. The top priority is not to affect the model size. \n\"A\" would not affect the model size but only increase memory use.\nBut \"D\" changes the model size.","upvote_count":"2","comment_id":"764639","poster":"uniquing"},{"timestamp":"1672230900.0","comment_id":"759813","upvote_count":"1","poster":"MBA_1990","content":"Right answer is D\nPower Query Editor > View > Column Profile > By clicking on the three little dots -> Group by text length"},{"poster":"AhmedMRagab","comment_id":"758988","content":"I believe D is the right one since the rest will increase the data size","timestamp":"1672171260.0","upvote_count":"1"},{"comment_id":"744254","timestamp":"1670947320.0","upvote_count":"2","comments":[{"upvote_count":"1","content":"Option A is saying useing calculated column which increases the size of the model. So D is correct.","poster":"Kai_don","timestamp":"1672071780.0","comment_id":"757647"}],"content":"Selected Answer: A\nusing DAX dont increase model size","poster":"AlexYang_"},{"comment_id":"738868","poster":"Mati_123","upvote_count":"2","timestamp":"1670493660.0","content":"Have a look into question again, it is mentioned that \"You need to analyze the frequency distribution of the string lengths in col1\", so with D option will we be able to analyze the frequency distribution of the string, if not then we should go for \"A\"."},{"poster":"lsperes2982","comment_id":"737349","content":"Selected Answer: A\nusing DAX you dont increase model size","upvote_count":"2","timestamp":"1670376720.0"},{"content":"Selected Answer: A\nYou need to analyze the data. so go with A, DAX calculations do not increase model size.\nThe problem with D is that you can only see the distribution, but no further analysis is possible.","timestamp":"1669646100.0","comment_id":"729231","poster":"Yaldaa","upvote_count":"1"},{"comment_id":"723523","upvote_count":"1","poster":"Hoeishetmogelijk","content":"Selected Answer: D\nAs Muffinshow already worded perfectly: A will affect the size of the model as would C.\nB doesn't give you enough information about the distribution (just the average)\nD is the right answer.\nSee for distribution on text length this page at the bottom: https://learn.microsoft.com/en-us/power-query/data-profiling-tools","timestamp":"1669036140.0"},{"comment_id":"719293","comments":[{"comment_id":"771274","upvote_count":"4","timestamp":"1673344860.0","content":"What confuses me is that if I tomorrow I am going to take the test which answer should I choose: the one that makes sense to me or the one stated here? Sometimes I feels these answers are not trusted even though I find same answers in other platforms!","poster":"RooneySmith"}],"poster":"andregrahamnz","content":"Selected Answer: D\nAnswer can ONLY be D. A and C both affect the size of the data model. B if you read it carefully is a measure to calculate the AVERAGE length, which will not provide the required 'analysis'. While it's a bit rich to refer to D as an 'analysis'; it's the only answer that provides a grouped breakdown of string length AND doesnt increase the size of the data model. The answer is D by process of elimination.","upvote_count":"4","timestamp":"1668567360.0"},{"poster":"Jonagan","timestamp":"1667994120.0","content":"Selected Answer: A\nD is definately wrong, because you will reduce the size of the datamodel.\nUsing measures is the only sway to not influence the size of the datamodel.\nIt requires a little bit more CPU to calculate, but it does not influence the size.\nHence, A is the correct answer.\nMuffinshow, why do you think answer A will affect the size of the model and D not?","comment_id":"714515","upvote_count":"2"},{"upvote_count":"4","content":"Selected Answer: D\nTested D , it works as expected.","timestamp":"1666783020.0","poster":"Churato","comment_id":"704612"},{"comment_id":"694710","timestamp":"1665747960.0","poster":"samad1234","upvote_count":"3","content":"Correct Answer : D"},{"upvote_count":"3","timestamp":"1665014460.0","poster":"PinkZebra","content":"Selected Answer: D\nd","comment_id":"687333"},{"timestamp":"1664565660.0","poster":"Ron22Ron","upvote_count":"1","content":"Selected Answer: D\nDue to analyze the frequency distribution of the string lengths and The solution must not affect the size of the model.","comment_id":"683820"},{"content":"B) is wrong, gives average not length\nA) gives the length as C), but calculated columns perform worse than Power Query\nC) gives the length but the column affects (a little) the size of the model\nD) allows an analysis only from Power Query, and does not increase the size of the model but the length cannot be used in the dashboard\nSo, C or D? Since the question says:\n - You need to analyze the frequency distribution\n - The solution must not affect the size of the model\nI would go for D).","upvote_count":"4","comment_id":"679569","poster":"zucchi","timestamp":"1664183760.0"},{"poster":"RichardOgoma","content":"Selected Answer: C\nI am confident that the length of the strings in col1 must be used for the report analysis. Creating a calculated column with DAX is not the best practice and not as efficient as using Power Query's M. I would go with C. \nD is tempting, but you need the data, not just to view the profile in Power Query.","timestamp":"1663939740.0","comment_id":"677190","upvote_count":"1","comments":[{"content":"Avoid assumptions and work with given information.\nAdding a column will increase the size of the model and that is what disqualified C from the answer leaving us with D","poster":"iccent2","timestamp":"1672314960.0","comment_id":"760960","upvote_count":"1"}]},{"poster":"saurinkhamar","upvote_count":"2","content":"Selected Answer: D\nD. is the right answer","timestamp":"1663834980.0","comment_id":"675886"},{"timestamp":"1663834920.0","poster":"saurinkhamar","comment_id":"675884","upvote_count":"2","content":"D. is the right answer"},{"comment_id":"672931","upvote_count":"3","content":"D is correct..\nFrom Power Query.. highlight the column.. from the tab view select Column Profile Option.. in the Value distribution section that appears below, from the 3dots.. you can change to group by text length distribution","timestamp":"1663563480.0","poster":"Manikom"},{"comments":[{"timestamp":"1663573260.0","comment_id":"673036","content":"My bad, reviewed the question and by 'analyze' they don't mean to create a report.\nCorrect: A","upvote_count":"4","poster":"fdsdfgxcvbdsfhshfg","comments":[{"comment_id":"673037","timestamp":"1663573260.0","content":"I mean D","upvote_count":"3","poster":"fdsdfgxcvbdsfhshfg"}]},{"content":"From Power Query.. highlight the column.. from the tab view select Column Profile Option.. in the Value distribution section that appears below, from the 3dots.. you can change to group by text lenght distribution... D is correct","poster":"Manikom","upvote_count":"1","timestamp":"1663563360.0","comment_id":"672930"}],"timestamp":"1663405980.0","comment_id":"671382","content":"Selected Answer: A\nD is not correct, column profile just shows you the information about the column in Power Query\nEven when it comes to grouping rows in Power Query, there are only a few basics operations and 'length' is not one of them\n\nA seem to be the only one making sense, it however consumes more RAM when loaded into the model","poster":"fdsdfgxcvbdsfhshfg","upvote_count":"1"},{"comment_id":"668015","poster":"hmax56","upvote_count":"2","content":"Selected Answer: D\nD is correct","timestamp":"1663073220.0"},{"content":"Selected Answer: D\nD is right","timestamp":"1662464820.0","upvote_count":"4","poster":"Guru1337","comment_id":"661181"},{"poster":"sheth","timestamp":"1662295200.0","comment_id":"659275","content":"A will affect the size because of calculated column","upvote_count":"4"}],"exam_id":116,"unix_timestamp":1662126240,"url":"https://www.examtopics.com/discussions/microsoft/view/79434-exam-pl-300-topic-2-question-1-discussion/","topic":"2","isMC":true,"answers_community":["D (91%)","6%"],"answer_images":[],"question_id":60,"question_text":"You are creating a report in Power BI Desktop.\nYou load a data extract that includes a free text field named coll.\nYou need to analyze the frequency distribution of the string lengths in col1. The solution must not affect the size of the model.\nWhat should you do?","question_images":[],"answer_description":"","choices":{"C":"From Power Query Editor, add a column that calculates the length of col1","D":"From Power Query Editor, change the distribution for the Column profile to group by length for col1","B":"In the report, add a DAX function that calculates the average length of col1","A":"In the report, add a DAX calculated column that calculates the length of col1"},"answer_ET":"D","timestamp":"2022-09-02 15:44:00"}],"exam":{"isImplemented":true,"numberOfQuestions":334,"lastUpdated":"12 Apr 2025","isMCOnly":false,"id":116,"isBeta":false,"provider":"Microsoft","name":"PL-300"},"currentPage":12},"__N_SSP":true}