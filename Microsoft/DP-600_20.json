{"pageProps":{"questions":[{"id":"0Y9vFlzMp3olGhwav53j","topic":"1","question_id":96,"isMC":true,"question_images":[],"choices":{"D":"PBIDS","C":"PBIT","B":"PBIX","A":"PBIP"},"exam_id":71,"answers_community":["A (86%)","14%"],"url":"https://www.examtopics.com/discussions/microsoft/view/133461-exam-dp-600-topic-1-question-22-discussion/","unix_timestamp":1707502620,"answer_description":"","answer_images":[],"answer":"A","discussion":[{"comment_id":"1177573","poster":"mtroyano","timestamp":"1710869700.0","upvote_count":"23","content":"Selected Answer: A\nThe correct option is PBIP - https://powerbiblogscdn.azureedge.net/wp-content/uploads/2024/02/tmdlPreviewFeature.png"},{"upvote_count":"20","content":"The correct file format for this purpose is:\n\nA. PBIP\n\nExplanation:\n\nPBIP (Power BI Project): This format is specifically designed for managing Power BI projects, including semantic models, in a way that supports bulk editing and version control. It allows you to use tools like Visual Studio Code to edit the model's metadata directly.\nOther formats:\n\nPBIX (Power BI Desktop File): This is the standard file format for Power BI Desktop reports, but it is not designed for direct bulk editing using TMDL.\nPBIT (Power BI Template File): This format is used for Power BI templates, which are useful for creating new reports based on a predefined structure, but it is not suitable for bulk editing using TMDL.\nPBIDS (Power BI Data Source File): This format is used for defining data sources for Power BI reports, not for semantic models.","timestamp":"1716761040.0","poster":"Shiven","comment_id":"1219165"},{"upvote_count":"1","timestamp":"1735154520.0","comment_id":"1331680","poster":"NRezgui","content":"Selected Answer: A\nThe correct option is PBIP"},{"timestamp":"1731650460.0","content":"Selected Answer: A\nPBIP is the answer","poster":"Rakesh16","comment_id":"1312437","upvote_count":"1"},{"comment_id":"1285032","timestamp":"1726545000.0","content":"To make bulk changes using the Tabular Model Definition Language (TMDL) extension is A. PBIP.\n\nExplanation:\n\n PBIP (Power BI Project) is a file format that supports the open-source TMDL format and is designed for integrating Power BI with external development environments like Visual Studio Code.\n PBIX is the common Power BI report file format but is not intended for bulk edits through TMDL.\n PBIT is a Power BI template file, used for creating new reports based on an existing structure but not for bulk editing in Visual Studio Code.\n PBIDS is for creating Power BI dataset connections and is unrelated to TMDL editing.","poster":"KipngenohVinnie","upvote_count":"2"},{"upvote_count":"2","comment_id":"1226999","poster":"woliveiras","content":"Selected Answer: A\nPIBP is the correct one","timestamp":"1717894980.0"},{"content":"Selected Answer: A\nPBIP for source code","comment_id":"1222263","poster":"dev2dev","timestamp":"1717175160.0","upvote_count":"1"},{"upvote_count":"1","timestamp":"1716148500.0","comment_id":"1213974","poster":"klkl03","content":"Selected Answer: A\nhttps://powerbi.microsoft.com/en-us/blog/tmdl-in-power-bi-desktop-developer-mode-preview/"},{"upvote_count":"2","comment_id":"1213642","poster":"David_Webb","timestamp":"1716102780.0","content":"Selected Answer: A\nhttps://learn.microsoft.com/en-us/power-bi/developer/projects/projects-overview"},{"content":"Selected Answer: A\nIMHO, \nI go with \"A\".\n\nHere: https://powerbi.microsoft.com/en-us/blog/tmdl-in-power-bi-desktop-developer-mode-preview/\n\"\"\"\nSaving as a PBIP using TMDL is currently in preview. Before giving it a try, you must first enable this feature in Preview features: go to File > Options and settings > Options > Preview features and check the box next to “Store semantic model using TMDL format”.\n\"\"\"","poster":"stilferx","upvote_count":"2","comment_id":"1208520","timestamp":"1715197020.0"},{"comment_id":"1208478","poster":"rlo123","upvote_count":"1","content":"C - PBIT\nHere's why:\n\nPBIT: The PBIT format is designed specifically for storing the semantic model definition in a way that is compatible with the Tabular Model Definition Language (TMDL) and readily editable in Visual Studio Code using the TMDL extension.\nLet's clarify the other options:\n\nPBIP, PBIX: These are standard Power BI Desktop file formats. They contain the semantic model but also include data, reports, visualizations, and other elements of a Power BI project.\nPBIDS: This file format is related to Power BI datasets hosted in the Power BI service, not for local editing with TMDL.","timestamp":"1715186460.0"},{"comment_id":"1208285","upvote_count":"1","poster":"BennyBenz","timestamp":"1715159640.0","content":"But it is the semantic model we are focusing on here? \nPBIX may be correct then? \nhttps://learn.microsoft.com/en-us/power-bi/create-reports/service-export-to-pbix#download-a-pbix-file-from-a-semantic-model"},{"timestamp":"1710937560.0","content":"Selected Answer: A\nA https://learn.microsoft.com/en-us/power-bi/developer/projects/projects-overview","poster":"a_51","comment_id":"1178246","upvote_count":"3"},{"content":"Selected Answer: A\nhttps://learn.microsoft.com/en-us/power-bi/developer/projects/projects-overview\n\nCheckout the title in the above link: Programmatic generation and editing artifact definitions","poster":"sraakesh95","timestamp":"1709058960.0","upvote_count":"2","comment_id":"1160900"},{"comment_id":"1160530","timestamp":"1709034900.0","upvote_count":"1","content":"Selected Answer: A\nAlso think it's A: https://learn.microsoft.com/en-us/power-bi/developer/projects/projects-overview","poster":"thuss"},{"timestamp":"1708428000.0","upvote_count":"3","content":"Selected Answer: A\nThe answer is A\nThe PBIP will create one file and two folders, PBIP.Dataset contains definition folder that is use to host the .tmdl files","comment_id":"1154655","poster":"Jeff_Zhu"},{"timestamp":"1708339200.0","content":"Selected Answer: C\nhttps://learn.microsoft.com/en-us/power-bi/create-reports/desktop-templates","poster":"lengzhai","upvote_count":"3","comment_id":"1153842"},{"upvote_count":"2","comment_id":"1152892","poster":"Momoanwar","timestamp":"1708209300.0","content":"Selected Answer: A\nits A.\nPbit iS only template.\nFor source control use pbip it also generate bim file for TMDL."},{"content":"Selected Answer: C\n\".pbit\" file is a Power BI Desktop template file. It includes both the data model and any reports or visuals you've created.","timestamp":"1707502740.0","poster":"IshtarSQL","comment_id":"1145687","upvote_count":"4"},{"timestamp":"1707502620.0","poster":"IshtarSQL","content":"My first thought would be BIM, but that is not an option. ?","comment_id":"1145685","upvote_count":"1"}],"question_text":"You are creating a semantic model in Microsoft Power BI Desktop.\nYou plan to make bulk changes to the model by using the Tabular Model Definition Language (TMDL) extension for Microsoft Visual Studio Code.\nYou need to save the semantic model to a file.\nWhich file format should you use?","answer_ET":"A","timestamp":"2024-02-09 19:17:00"},{"id":"lLc5Qw4hXv7iG0wPKiKj","timestamp":"2024-02-17 23:36:00","answer_description":"","answers_community":[],"question_id":97,"answer_ET":"","topic":"1","unix_timestamp":1708209360,"exam_id":71,"answer_images":["https://img.examtopics.com/dp-600/image28.png"],"isMC":false,"question_text":"HOTSPOT -\nYou have a Fabric tenant that contains a warehouse named Warehouse1. Warehouse1 contains three schemas named schemaA, schemaB, and schemaC.\nYou need to ensure that a user named User1 can truncate tables in schemaA only.\nHow should you complete the T-SQL statement? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\n//IMG//","discussion":[{"upvote_count":"31","content":"ALTER/SCHEMA \nThis statement allows to alter (which includes truncating) tables within the specified schema. It ensures that the permission is restricted to schemaA and does not grant access to other schemas or objects.","poster":"estrelle2008","comment_id":"1158836","timestamp":"1708868520.0"},{"comment_id":"1285037","poster":"KipngenohVinnie","timestamp":"1726547100.0","content":"GRANT ALTER ON SCHEMA::schemaA TO User1;","upvote_count":"6"},{"comment_id":"1312438","poster":"Rakesh16","content":"Alter, Schema_SchemaA","timestamp":"1731650460.0","upvote_count":"1"},{"timestamp":"1718188920.0","content":"ALTER/SCHEMA\nhttps://learn.microsoft.com/en-us/sql/t-sql/statements/truncate-table-transact-sql?view=sql-server-ver16#permissions\nhttps://learn.microsoft.com/th-th/sql/t-sql/statements/alter-schema-transact-sql?view=fabric&preserve-view=true","comment_id":"1228953","upvote_count":"1","poster":"py2356863"},{"comments":[{"content":"TRUNCATE is now supported on Fabric's Data Warehouse:\nhttps://community.fabric.microsoft.com/t5/Fabric-Ideas/Support-TRUNCATE-TABLE-in-Fabric-Warehouse/idi-p/4510865","timestamp":"1742340600.0","poster":"waltXc","comment_id":"1400328","upvote_count":"1"}],"comment_id":"1223562","poster":"Valcon_doo_NoviSad","content":"truncating tables is not even supported in warehouse so this question is pointless, good job microsoft...","timestamp":"1717415400.0","upvote_count":"5"},{"poster":"stilferx","timestamp":"1715197500.0","upvote_count":"1","content":"IMHO, \nALTER -> SCHEMA.\n\nAs well said below, \n1) ALTER is the thing to have for truncating:\nhttps://learn.microsoft.com/en-us/sql/t-sql/statements/truncate-table-transact-sql?view=sql-server-ver16&viewFallbackFrom=fabric\n2) SCHEMA:schema_name to define a particular schema for tables","comment_id":"1208523"},{"upvote_count":"4","comment_id":"1193854","content":"ALTER/SCHEMA\n\nhttps://learn.microsoft.com/en-us/sql/t-sql/statements/grant-schema-permissions-transact-sql?view=sql-server-ver16\n\nGRANT permission [ ,...n ] ON SCHEMA :: schema_name \n TO database_principal [ ,...n ] \n [ WITH GRANT OPTION ] \n [ AS granting_principal ]","poster":"VAzureD","timestamp":"1712843280.0"},{"comments":[{"poster":"Priyanka007","content":"It would have worked if the question said one table.. But it says \"user named User1 can truncate TABLE\"S\" in schemaA only\" so I would go with option C. SCHEMA.","timestamp":"1719102900.0","comment_id":"1235657","upvote_count":"1"},{"upvote_count":"2","comment_id":"1179108","content":"For schemas:\nhttps://learn.microsoft.com/en-us/sql/t-sql/statements/grant-schema-permissions-transact-sql?view=sql-server-ver16","timestamp":"1711016460.0","poster":"benja84"}],"content":"According to https://learn.microsoft.com/en-us/sql/t-sql/statements/grant-object-permissions-transact-sql?view=sql-server-ver16, answer seems to ALTER and OBJECT.","poster":"cresclux","comment_id":"1178680","upvote_count":"2","timestamp":"1710966660.0"},{"comment_id":"1163203","timestamp":"1709264460.0","content":"ALTER is DDL not DML so the right answer is EXECUTE SCHEMA.","upvote_count":"2","comments":[{"comment_id":"1222265","content":"TRUNCATE is DML","timestamp":"1717175340.0","upvote_count":"2","poster":"dev2dev","comments":[{"poster":"dev2dev","comment_id":"1222266","upvote_count":"1","timestamp":"1717175340.0","content":"Ignore my prevous comment.\nTRUNCATE is DDL so ALTER is what we need"}]},{"timestamp":"1709717940.0","upvote_count":"4","content":"ALTER is required for Truncate https://learn.microsoft.com/en-us/sql/t-sql/statements/truncate-table-transact-sql?view=sql-server-ver16&viewFallbackFrom=fabric","comment_id":"1167043","poster":"thomaski123"}],"poster":"AzureGeek79"},{"content":"Correct","upvote_count":"2","comment_id":"1152893","timestamp":"1708209360.0","poster":"Momoanwar"}],"answer":"","question_images":["https://img.examtopics.com/dp-600/image27.png"],"url":"https://www.examtopics.com/discussions/microsoft/view/134091-exam-dp-600-topic-1-question-23-discussion/"},{"id":"fiaewB2FbmgKAlqesGO8","answer_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/134093-exam-dp-600-topic-1-question-24-discussion/","question_text":"You plan to deploy Microsoft Power BI items by using Fabric deployment pipelines. You have a deployment pipeline that contains three stages named Development, Test, and Production. A workspace is assigned to each stage.\nYou need to provide Power BI developers with access to the pipeline. The solution must meet the following requirements:\nEnsure that the developers can deploy items to the workspaces for Development and Test.\nPrevent the developers from deploying items to the workspace for Production.\nFollow the principle of least privilege.\nWhich three levels of access should you assign to the developers? Each correct answer presents part of the solution.\nNOTE: Each correct answer is worth one point.","answer_description":"","exam_id":71,"isMC":true,"discussion":[{"upvote_count":"24","timestamp":"1709059680.0","content":"Selected Answer: BDE\nAs pointed out by XiltroX,\nB - Admin access is provided to the developers for the developers to manage the deployent process across the various stages (in this case Dev and Test). This is a basic necessary.\n\nD - To restrict the access on the Production workspace, provide an overriding Viewer access which lets the developers only view the Production environment and not make any changes.\n\nE - This is to provide the developers with the permissions to develop, edit and update the Dev and Test pipelines.","comment_id":"1160907","poster":"sraakesh95"},{"poster":"elma_qhor_19","timestamp":"1740603480.0","upvote_count":"1","comment_id":"1362294","content":"Selected Answer: BDE\nB - Admin access is provided to the developers for the developers to manage the deployent process across the various stages (in this case Dev and Test). This is a basic necessary.\n\nD - To restrict the access on the Production workspace, provide an overriding Viewer access which lets the developers only view the Production environment and not make any changes.\n\nE - This is to provide the developers with the permissions to develop, edit and update the Dev and Test pipelines."},{"upvote_count":"1","poster":"NRezgui","content":"Selected Answer: BDE\nB - Admin access is provided to the developers for the developers to manage the deployent process across the various stages (in this case Dev and Test). This is a basic necessary.\n\nD - To restrict the access on the Production workspace, provide an overriding Viewer access which lets the developers only view the Production environment and not make any changes.\n\nE - This is to provide the developers with the permissions to develop, edit and update the Dev and Test pipelines.","timestamp":"1735154880.0","comment_id":"1331683"},{"comment_id":"1312439","upvote_count":"1","content":"Selected Answer: BDE\nBAdmin access to the deployment pipeline\nDViewer access to the Production workspace\nEContributor access to the Development and Test workspaces","timestamp":"1731650520.0","poster":"Rakesh16"},{"timestamp":"1726554420.0","content":"To meet the requirements while following the principle of least privilege, you should assign the following levels of access to the developers:\n\n B. Admin access to the deployment pipeline - This is needed so developers can manage the deployment pipeline itself, including moving items between stages.\n\n E. Contributor access to the Development and Test workspaces - This allows developers to deploy and make changes to the items in the Development and Test workspaces.\n\n D. Viewer access to the Production workspace - This ensures developers can view the Production workspace but cannot make any changes or deploy items to it.","upvote_count":"1","poster":"KipngenohVinnie","comment_id":"1285057"},{"content":"Selected Answer: BDE\nB - There's only one role for pipelines so it's either having an Admin role or no access to a pipeline. You have to have an Admin role on a pipeline in order to do any deployments.\n\nD - Pipeline permissions and workspace permissions are kind of linked but the way it works is if a user has viewer permissions on a workspace and Admin on the Pipeline - They won't be able to do a deployment to that workspace, but they can still see things inside of it (as is the case as a viewer in any workspace).\n\nE - If you have the Contributer/Member/Admin role on a workspace AND Admin permissions on a pipeline, then you can deploy to that workspace.","poster":"user12345678","comment_id":"1273633","timestamp":"1724782260.0","comments":[{"comment_id":"1273634","upvote_count":"1","timestamp":"1724782320.0","poster":"user12345678","content":"One common misconception is people are thinking (and I initially thought) that D is selected to limit the user. This isn't the case. The workspace roles are separate and if you don't give any role to the Prod workspace, then the user won't be able to access it at all. By giving viewer, they can atleast see what's in the workspace."}],"upvote_count":"1"},{"content":"It does not say Developers need to manage deployments, just access items within the pipeline. So A, D, and E","upvote_count":"1","comment_id":"1272333","poster":"bad4b76","timestamp":"1724629440.0"},{"timestamp":"1721243280.0","comments":[{"content":"Agreed, but do they need build permissions?","timestamp":"1730467680.0","upvote_count":"1","comment_id":"1305825","poster":"semauni"}],"comment_id":"1249932","content":"A D E because: In Power BI, having Viewer access to a workspace does not automatically grant Build permission for a semantic model within that workspace. The Viewer role allows a user to view and interact with items in the workspace, but it does not include the ability to create new content or edit existing content.\n\nTo have Build permission, a user must be explicitly granted that permission, which allows them to build new content from the semantic model, access reports that use composite models on Power BI Pro workspaces, and pull data into Analyze in Excel, among other capabilities. This permission can be given by the workspace Admin or Member who has the authority to manage semantic model permissions","poster":"Ahmadpbi","upvote_count":"1"},{"timestamp":"1719186780.0","content":"Selected Answer: BDE\nB: It's admin or nothing for pipeline access.\nD: Viewer, so they cannot create it in production.\nE: You need Contributor on the workspaces you want to deploy and create.","upvote_count":"1","poster":"bmc15","comment_id":"1236061"},{"content":"Selected Answer: BDE\nRespostas BDE","poster":"SilvanoRamalho","upvote_count":"1","comment_id":"1234460","timestamp":"1718979360.0"},{"upvote_count":"1","content":"Was in exam. Scored 95%\nChose BDE \n\nAnswers swtichted Contributor for Member role","timestamp":"1718951100.0","comment_id":"1234221","poster":"Jons123son"},{"poster":"Gerald","upvote_count":"1","comment_id":"1234172","content":"I agree with BDE","timestamp":"1718940960.0"},{"timestamp":"1716830580.0","comment_id":"1219717","upvote_count":"2","content":"E. Contributor access to the Development and Test workspaces:\nThis allows developers to deploy and manage content in the Development and Test workspaces, meeting the requirement to allow deployments in these stages.\n\nD. Viewer access to the Production workspace: \nThis provides developers with read-only access to the Production workspace, ensuring they can view content but cannot deploy or make changes, which aligns with the requirement to prevent deployments to Production.\n\nB. Admin access to the deployment pipeline:\nThis allows developers to manage the deployment pipeline itself, including deploying items to the Development and Test stages but not to the Production stage. This ensures they can oversee the deployment process without overstepping into the Production environment.","poster":"282b85d"},{"poster":"David_Webb","comment_id":"1213645","timestamp":"1716103260.0","content":"Selected Answer: BDE\nAdmin access is needed in the development workspace for pipeline.","upvote_count":"2"},{"content":"To deploy from one stage to another in the pipeline, you must be a pipeline admin, and either a member or an admin of the workspaces assigned to the stages involved. For example, a pipeline admin that isn't assigned a workspace role, can view the pipeline and share it with others. However, this user can't view the content of the workspace in the pipeline, or in the service, and can't perform deployments.\nhttps://learn.microsoft.com/en-us/fabric/cicd/deployment-pipelines/understand-the-deployment-process#permissions/?azure-portal=true\n\nFrom task: Prevent the developers from deploying to the production.\n\nSo B is not correct, we can't give pipeline admin access?","poster":"72bd3bc","timestamp":"1715244780.0","comments":[{"upvote_count":"2","content":"we can and wee need viewer access to the Production, so that developers can't deploy at this stage. Without admin access they can't deploy from dev to test stages.","poster":"72bd3bc","timestamp":"1715778900.0","comment_id":"1211949"}],"comment_id":"1208773","upvote_count":"1"},{"content":"Selected Answer: BDE\nIMHO, \nB->D->E\n\nB. Admin access to the deployment pipeline - to be able to run\nD. Viewer access to the Production workspace - to not be able to run Prod\nE. Contributor access to the Development and Test workspaces - to be able to run Dev/Test","comments":[{"timestamp":"1715779020.0","comments":[{"timestamp":"1722070920.0","upvote_count":"1","comment_id":"1256224","poster":"Martin_Nbg","content":"So what does this mean referring to the auswärts? Do we have 3 correct answers at all? Obviously ist's Not Contributor to Test (Contributor to Dev would be enough because you only want to deploy FROM Dev but not TO Dev)."}],"comment_id":"1211951","content":"I see that contributors aren't able to deploy. Only members\n\nWorkspace contributor\n(and pipeline admin) \nConsume content\nCompare stages\nView semantic models\nUnassign a workspace from a stage\n\nWorkspace member\n(and pipeline admin) \nView workspace content\nCompare stages\nDeploy items (must be a member or admin of both source and target workspaces)\nUpdate semantic models\nUnassign a workspace from a stage\nConfigure semantic model rules (you must be the semantic model owner)\n\nhttps://learn.microsoft.com/en-us/fabric/cicd/deployment-pipelines/understand-the-deployment-process#permissions-table","poster":"72bd3bc","upvote_count":"3"},{"poster":"Mhmod48","content":"I like your answers","timestamp":"1715756160.0","comment_id":"1211801","upvote_count":"1"}],"timestamp":"1715198280.0","poster":"stilferx","upvote_count":"2","comment_id":"1208526"},{"comment_id":"1201489","upvote_count":"2","timestamp":"1713973620.0","poster":"PazaBIandData","content":"Selected Answer: BD\nMember or Admin rights on the workspace level are required to deploy datasets so E doesn't match the requirements.\nhttps://learn.microsoft.com/en-us/fabric/cicd/deployment-pipelines/understand-the-deployment-process#permissions-table"},{"poster":"Nefirs","content":"Selected Answer: BDE\nmy reasoning:\nA: nope since they should not be able to build things there\nB: not sure\nC: nope since this would prevent them from deploying stuff there\nD: yes because of least privilege\nE: yes so they can build/deploy stuff there\nF: nope. Too much permissions.\n--> so this leaves option B as the third answer.","comment_id":"1183394","comments":[{"upvote_count":"1","content":"yes, admin permission on the pipeline is required to manage the deployments between workspaces\n\nso BDE confirmed","poster":"STH","comment_id":"1184838","timestamp":"1711638780.0"}],"timestamp":"1711464240.0","upvote_count":"2"},{"content":"Selected Answer: BDE\nI think it is B,D,E, but the admin title throws you off as it can deploy items and is a key to what it asks. Build permission allows to create new content in the workspace, so not sure that is right, answer A.\nhttps://learn.microsoft.com/en-us/fabric/cicd/deployment-pipelines/understand-the-deployment-process?WT.mc_id=access_pane#permissions","upvote_count":"1","poster":"a_51","timestamp":"1710955920.0","comment_id":"1178554"},{"upvote_count":"3","timestamp":"1709035200.0","content":"Selected Answer: BDE\nI get a feeling the \"trick\" is making you think that B would allow publishing on Prod, but I think if you don't give them access to the workspace, they can indeed have admin rights on the build pipeline but not deploy on Prod? So BDE would be my guess. Also B is the only option granting access to the pipeline at all, and D and E are a must.","poster":"thuss","comment_id":"1160541"},{"comment_id":"1159925","poster":"XiltroX","content":"Selected Answer: BDE\nI think the answer should be BDE. If you have contributer access to the workspace, then you don't need to assign an additional viewer access (C) to the developers. One of the requirements is to grant access to the pipeline and the only option that fulfills that is (B). D and E fulfill the rest of the requirements in the question.","upvote_count":"4","timestamp":"1708964520.0"},{"poster":"estrelle2008","comment_id":"1158873","upvote_count":"4","timestamp":"1708872180.0","content":"Selected Answer: CDE\nI think build permission to the production semantic model, conflicts with requirement that any changes to the Production workspace should be prevented.\nIf question really requires 3 answers, I think both Viewer access (C) and Contributor access (E) can coexist effectively for the Development and Test workspaces."},{"content":"Selected Answer: ADE\nI think its correct if developper can read data on production.\nDont need b and c with E\nF is too high","poster":"Momoanwar","comment_id":"1152900","upvote_count":"2","timestamp":"1708210140.0"}],"question_id":98,"timestamp":"2024-02-17 23:49:00","answer_ET":"BDE","choices":{"B":"Admin access to the deployment pipeline","A":"Build permission to the production semantic models","E":"Contributor access to the Development and Test workspaces","D":"Viewer access to the Production workspace","C":"Viewer access to the Development and Test workspaces","F":"Contributor access to the Production workspace"},"topic":"1","answer":"BDE","question_images":[],"answers_community":["BDE (85%)","Other"],"unix_timestamp":1708210140},{"id":"TW1Xo9IqtPTvaENgBKhs","timestamp":"2024-02-12 18:26:00","answers_community":["AB (82%)","Other"],"url":"https://www.examtopics.com/discussions/microsoft/view/133635-exam-dp-600-topic-1-question-25-discussion/","answer":"AB","isMC":true,"question_images":[],"discussion":[{"poster":"sraakesh95","comment_id":"1160912","timestamp":"1709060340.0","content":"Selected Answer: AB\nAgree with lengzhai's reference of the 2 links:\nA - Custom aggregations enables PBI to not perform a Full Scan of the underlying datasets.\nB - The AutoAggregations feature automatically creates aggregations on large datasets and based on query optimization determines the total number of rows that requires processing based on the generated query plan.\n\nIncorrect to this question context:\nC - Although caching helps improve performance on large datasets, it doesn't support DirectQuery (Important note in https://learn.microsoft.com/en-us/power-bi/connect-data/power-bi-query-caching) ; Also, it is a feature available in PBI Service that is automatic and needs no intervention from the user.","upvote_count":"19"},{"content":"Selected Answer: AB\nD: onelake integration not for Direct Query\nC: only at loading for first page\n\nSo AV","comments":[{"content":"Agreed to AB.\nBoth UDA's and AA optimize direct query performance. One just requires more manual work and in depth knowledge data modelling and query optimization techniques (UDA), whereas the other makes simplifies this process through the use of ML algorithms (AA).","timestamp":"1708264380.0","comment_id":"1153301","upvote_count":"3","poster":"BrandonPerks"},{"upvote_count":"1","timestamp":"1708130400.0","comment_id":"1152301","content":"I mean AB*","poster":"Momoanwar"}],"poster":"Momoanwar","upvote_count":"11","timestamp":"1708130340.0","comment_id":"1152300"},{"poster":"NRezgui","upvote_count":"1","content":"Selected Answer: AB\nA. user-defined aggregations\nB. automatic aggregation","comment_id":"1331685","timestamp":"1735155060.0"},{"timestamp":"1734420780.0","content":"Selected Answer: AC\nUser-defined aggregations (A):\n\nUser-defined aggregations allow you to create pre-aggregated tables that summarize data at a higher level, reducing the volume of data that needs to be queried for specific visuals. This can significantly improve performance for common queries by avoiding the need to scan the entire dataset.\nQuery caching (C):\n\nQuery caching stores the results of previous queries for reuse. When users interact with visuals that require similar data, the cached results can be returned more quickly than querying the source again, thereby reducing execution time for those visuals.","upvote_count":"2","comment_id":"1327794","poster":"AshwiniVivek"},{"timestamp":"1731650580.0","comment_id":"1312440","content":"Selected Answer: AB\nA & B is the answer","upvote_count":"2","poster":"Rakesh16"},{"content":"Selected Answer: BD\nB&D are correct.\nDirect Lakes are great for performance in the OneLake integration \nhttps://learn.microsoft.com/en-us/fabric/get-started/direct-lake-overview","comment_id":"1245199","poster":"6d1de25","timestamp":"1720568880.0","comments":[{"content":"This was DirectQuery, not Direct Lake.","poster":"TimoRii","comment_id":"1299067","timestamp":"1729139700.0","upvote_count":"1"}],"upvote_count":"1"},{"content":"A&B\nWhile query caching can be beneficial in certain scenarios, user-defined aggregations and automatic aggregations are typically more effective for improving query performance in Power BI reports with large datasets and complex queries. These methods reduce the volume of data processed in real-time queries, directly addressing the performance bottlenecks associated with querying large datasets.","poster":"282b85d","timestamp":"1716830880.0","comment_id":"1219718","upvote_count":"1"},{"content":"CHATGPT saya AC","comment_id":"1212930","poster":"Murtaza_007","timestamp":"1715956380.0","upvote_count":"1","comments":[{"content":"no, it says AB. I go for AB","timestamp":"1741379040.0","comment_id":"1366373","upvote_count":"1","poster":"Jane5"}]},{"content":"Selected Answer: AB\nIMHO, A & B looks good","poster":"stilferx","timestamp":"1715198640.0","comment_id":"1208529","upvote_count":"1"},{"timestamp":"1708957980.0","comment_id":"1159838","content":"Selected Answer: AB\nAgree with A B\nhttps://learn.microsoft.com/en-us/power-bi/transform-model/aggregations-advanced\nhttps://learn.microsoft.com/en-us/power-bi/enterprise/aggregations-auto","upvote_count":"5","poster":"lengzhai"},{"timestamp":"1708874160.0","upvote_count":"2","content":"Selected Answer: AB\nAgreed AB. \nAlthough query caching (C) will reduce query execution time too, you risk outdated cached results when working with real-time or dynamic data.","poster":"estrelle2008","comment_id":"1158888"},{"poster":"Fermd","comments":[{"timestamp":"1711639440.0","comment_id":"1184842","content":"Question is about Fabric workspace... not Power BI Desktop !","poster":"STH","upvote_count":"2"}],"timestamp":"1707812220.0","content":"Selected Answer: AC\nA. User-defined aggregations (UDAs) allow you to pre-aggregate specific calculations directly in the semantic model. This reduces the amount of data that needs to be retrieved from the source each time a visual requires the calculation, significantly improving query execution time.\nC. Power BI Desktop enables query caching for DirectQuery models. This stores frequently used queries on the client machine, eliminating the need to re-send them to the source data for subsequent interactions.","upvote_count":"4","comment_id":"1148986"},{"timestamp":"1707758760.0","upvote_count":"2","poster":"Nicofr","content":"Selected Answer: BD\nhttps://learn.microsoft.com/en-us/power-bi/enterprise/aggregations-auto\nhttps://learn.microsoft.com/en-us/power-bi/enterprise/onelake-integration-overview","comment_id":"1148432"}],"exam_id":71,"topic":"1","choices":{"B":"automatic aggregation","C":"query caching","D":"OneLake integration","A":"user-defined aggregations"},"unix_timestamp":1707758760,"answer_ET":"AB","question_text":"You have a Fabric workspace that contains a DirectQuery semantic model. The model queries a data source that has 500 million rows.\nYou have a Microsoft Power Bi report named Report1 that uses the model. Report1 contains visuals on multiple pages.\nYou need to reduce the query execution time for the visuals on all the pages.\nWhat are two features that you can use? Each correct answer presents a complete solution,\nNOTE: Each correct answer is worth one point.","answer_images":[],"question_id":99,"answer_description":""},{"id":"70g5EFDJN2JEU6kuFPiI","unix_timestamp":1707812580,"timestamp":"2024-02-13 09:23:00","url":"https://www.examtopics.com/discussions/microsoft/view/133726-exam-dp-600-topic-1-question-26-discussion/","discussion":[{"comment_id":"1219721","upvote_count":"19","timestamp":"1716831300.0","content":"Selected Answer: D\nD. Query folding is NOT occurring.\nQuery folding refers to the ability of Power Query to push data transformation logic back to the data source, which can perform the transformations more efficiently. When query folding does not occur, all the data is pulled into Power BI and transformations are applied locally, which can be resource-intensive and lead to running out of resources, especially with large datasets like your 30 CSV files.\nE. The delta type of the column used to partition the data has changed: While this could cause issues with incremental refresh accuracy, it would not typically result in \"running out of resources\" during the refresh.","poster":"282b85d"},{"comment_id":"1183404","upvote_count":"15","content":"Selected Answer: E\ni don't really know.\nBut A and D regarding query folding seem for me not to be relevant since query folding does not make sense anyway on CSV/Flatfile connections. In my understanding, query folding sends a query back to the source. And what kind of query would that be to a CSV source?","poster":"Nefirs","comments":[{"poster":"Plb2","upvote_count":"4","content":"Don't think so too\nhttps://learn.microsoft.com/en-us/power-query/query-folding-examples#no-query-folding-example","comment_id":"1224260","timestamp":"1717525140.0"}],"timestamp":"1711464900.0"},{"upvote_count":"1","content":"Selected Answer: E\nAnswer is E : https://learn.microsoft.com/en-us/power-query/query-folding-examples#no-query-folding-example","poster":"kilowd","comment_id":"1399167","comments":[{"poster":"kilowd","content":"No, query folding does not occur when working with CSV files in OneLake from Power BI. Here’s why:\n 1. Query Folding Requires a Supported Source\n • Query folding happens when Power BI pushes transformations back to the data source (e.g., SQL Server, Snowflake).\n • CSV files do not support query folding because they are flat files, not a database with an engine to process queries.\n 2. OneLake Stores Data but Doesn’t Process Queries\n • OneLake is a storage layer in Microsoft Fabric, not a query engine.\n • When Power BI connects to a CSV in OneLake, it downloads the data and processes transformations in Power Query (M Engine)—not at the source.\n 3. Workaround for Performance\n • If you need query folding, consider loading the CSV into a Lakehouse or Warehouse in Fabric and querying it using DirectQuery or SQL-based sources.","timestamp":"1742833380.0","comment_id":"1409719","upvote_count":"1"}],"timestamp":"1742114460.0"},{"content":"Selected Answer: E\ndata type issue becoz PBI supports for lakehouse source","timestamp":"1741893480.0","comment_id":"1392925","upvote_count":"1","poster":"sajjuh"},{"timestamp":"1740478320.0","comment_id":"1361407","poster":"Devoteam2025","content":"Selected Answer: E\nThe correct answer is \"E.\" The answer is written incorrectl, \nthey meant to say \"data type\" instead of \"delta type,\" which is the reason for running out of resources.","upvote_count":"2"},{"poster":"VLADCS","upvote_count":"1","comment_id":"1338977","timestamp":"1736543700.0","content":"Selected Answer: D\nAnswer D.\nIf query folding is not supported, all transformations are performed in Power BI memory. This can cause excessive resource usage, especially for large data sources such as 30 CSV files. This is the most likely cause of the error.\nAnswer E is not correct. If the partitioning column type has changed, it will cause an update error, but not a resource overload. The error will be more related to data incompatibility."},{"timestamp":"1735155420.0","comment_id":"1331687","poster":"NRezgui","upvote_count":"2","content":"Selected Answer: E\nThe delta type of the column used to partition the data has changed.","comments":[{"timestamp":"1738015200.0","content":"I took my exam the last week, and the option \"E\", the text was: \"The data type of the column used....\"\nFor this, is \"E\" --> Correct","comment_id":"1347595","poster":"pirate84","upvote_count":"1"}]},{"timestamp":"1733498760.0","comment_id":"1322811","content":"Selected Answer: D\nD. Query folding is NOT occurring\nQuery folding happens when Power BI sends this list (your transformations) to the database, so it does the heavy lifting for you. If folding doesn’t happen, Power BI has to handle all the processing on its own, which is slower and less efficient.","poster":"rkandathil","upvote_count":"1"},{"poster":"Rakesh16","content":"Selected Answer: D\nQuery folding is NOT occurring.","comment_id":"1312441","upvote_count":"1","timestamp":"1731650580.0"},{"content":"D.\nWhile query folding typically does not apply to CSV files, OneLake does provide some structure that can prevent loading all data into PowerBI Memory.","timestamp":"1730193000.0","upvote_count":"1","poster":"jcu614","comment_id":"1304361"},{"timestamp":"1730031540.0","comment_id":"1303576","poster":"jass007_k","content":"Correct Option is D) If query folding is not occurring, it means that all 30 CSV files are likely being loaded into memory for processing, which can lead to resource exhaustion, especially if the files are large or numerous.\nA. Query folding is occurring: If query folding were happening, it would typically improve performance and reduce resource usage, not cause a failure.\nB. Only refresh complete days is selected: This option usually helps in managing the data being refreshed by only focusing on completed data, potentially alleviating resource issues rather than causing them.\nC. XMLA Endpoint is set to Read Only: If the XMLA Endpoint were set to read-only, it wouldn't directly cause a refresh failure due to resource issues. It would restrict write operations but not necessarily impact resource allocation during a refresh.\nE. The delta type of the column used to partition the data has changed: Changes in partitioning columns could cause refresh issues, but they wouldn’t inherently lead to resource exhaustion unless they also disrupt query folding.","upvote_count":"2"},{"timestamp":"1718951340.0","comment_id":"1234222","poster":"Jons123son","upvote_count":"8","content":"Was in exam. Scored 95%\nChose D.\n\nHonestly, I was guessing. No clue. However, query folding does occur for CSV files stored IN OneLake. OneLake does the work. This different from semantic models created with files stored on a normal machine and what had been common knowledge for a Power BI user."},{"timestamp":"1715360160.0","content":"Selected Answer: D\nAnswer D","upvote_count":"2","poster":"haran939","comment_id":"1209451"},{"comment_id":"1209157","timestamp":"1715305920.0","upvote_count":"5","poster":"PiyushT","content":"Selected Answer: D\nFor efficient data processing, Power BI aims to push as much of the filtering and calculations as possible to the source system (OneLake in this case). This is called query folding. When query folding fails, Power BI needs to pull all the raw data into the semantic model and perform operations there, increasing memory and processing strain.\n\nE This could lead to refresh errors but is less likely to cause the specific behavior of running out of resources."},{"poster":"stilferx","upvote_count":"3","timestamp":"1715199180.0","comment_id":"1208530","content":"Selected Answer: D\nIMHO, \n\nThe answer is D.\nLink: https://learn.microsoft.com/en-us/power-bi/connect-data/incremental-refresh-troubleshoot#cause-the-data-source-doesnt-support-query-folding\n\nCause: Data source queries aren't being folded\nWhile problems with query folding can usually be determined in Power BI Desktop before publishing to the service, it's possible that model refresh queries aren't being folded, leading to excessive refresh times and query mashup engine resource utilization. This situation happens because a query is created for every partition in the model. If the queries aren't being folded, and data isn't being filtered at the data source, the engine then attempts to filter the data."},{"upvote_count":"1","content":"Selected Answer: D\nD. Query folding is NOT occurring.\nAs described in Incremental refresh and real-time data for models - Requirements, incremental refresh is designed for data sources that support query folding. Make sure data source queries are being folded in Power BI Desktop before publishing to the service, where query folding issues can be significantly compounded.\nSo having said this, csv files is not a data source that support query folding.\n\nhttps://learn.microsoft.com/en-us/power-bi/connect-data/incremental-refresh-troubleshoot#cause-the-data-source-doesnt-support-query-folding","comment_id":"1207751","poster":"Fer079","timestamp":"1715063760.0"},{"timestamp":"1714844520.0","poster":"zerone72","upvote_count":"1","comment_id":"1206598","content":"If you connect power bi to the datasource through the SQL endpoint , you basically use as if it was a SQL server. Therefore, you might be able to use query folding. Am I correct ?"},{"poster":"d47320d","upvote_count":"5","content":"Correct Answer: \"E. The delta type of the column used to partition the data has changed.\"\n\nExplanation:\nQuery folding is not applicable with csv files, which rules out A,D answers.\nThe provided Microsoft link related to \"problem-loading-data-takes-too-long\", states two causes, one related to query folding (we've already ruled it out) and another one related to the data type, which in turn leads us to answer E.","comments":[{"timestamp":"1714231980.0","comment_id":"1203184","content":"But DELTA type? I have not found anything related to that concept...","upvote_count":"1","poster":"eeeliiisaaa"}],"timestamp":"1713957000.0","comment_id":"1201280"},{"timestamp":"1709061120.0","upvote_count":"2","content":"Selected Answer: D\nCombining the references by XiltroX and Momoanwar:\nhttps://learn.microsoft.com/en-us/power-bi/connect-data/incremental-refresh-troubleshoot#problem-loading-data-takes-too-long\nhttps://learn.microsoft.com/en-us/power-query/power-query-folding","poster":"sraakesh95","comments":[{"upvote_count":"1","poster":"neoverma","timestamp":"1712600520.0","comment_id":"1191757","content":"as per the documentation: \nhttps://learn.microsoft.com/en-us/power-query/query-folding-examples#no-query-folding-example\n\n\"Queries that rely solely on unstructured data sources or that don't have a compute engine, such as CSV or Excel files, don't have query folding capabilities. This means that Power Query evaluates all the required data transformations using the Power Query engine.\"\n\nso not sure what this has to do with query folding at all"}],"comment_id":"1160921"},{"timestamp":"1708965360.0","content":"Selected Answer: D\nD is the right choice. Here's why: \nhttps://learn.microsoft.com/en-us/power-query/power-query-folding","upvote_count":"1","poster":"XiltroX","comment_id":"1159932"},{"content":"Selected Answer: B\nWithout considering external tooling (C), without further context I can already identify B, D and E as possible causes. Question should be: What could NOT be a cause?\nI add answer B to this: Resource exhaustion due to partial-day refresh, when Only refresh complete days is selected while configuring incremental refresh.","timestamp":"1708876200.0","upvote_count":"2","comment_id":"1158928","poster":"estrelle2008"},{"poster":"Momoanwar","comment_id":"1152310","content":"Selected Answer: D\nhttps://learn.microsoft.com/en-us/power-bi/connect-data/incremental-refresh-troubleshoot#problem-loading-data-takes-too-long","timestamp":"1708131720.0","upvote_count":"4"},{"poster":"Nicofr","content":"Selected Answer: E\nhttps://learn.microsoft.com/en-us/power-bi/connect-data/incremental-refresh-troubleshoot#problem-loading-data-takes-too-long","timestamp":"1707853980.0","comment_id":"1149533","upvote_count":"2"},{"upvote_count":"2","content":"Selected Answer: C\nC. XMLA Endpoint is set to Read Only: If the XMLA endpoint for the Premium capacity is set to Read Only, any attempt to update or refresh the model through this endpoint, including incremental refresh, would fail. This configuration directly explains the resource exhaustion during a refresh operation as the read-only mode wouldn't allow the necessary updates to occur.","comment_id":"1148992","poster":"Fermd","timestamp":"1707812580.0"}],"answer_description":"","topic":"1","answer_ET":"D","question_id":100,"answer_images":[],"choices":{"B":"Only refresh complete days is selected.","A":"Query folding is occurring.","D":"Query folding is NOT occurring.","E":"The delta type of the column used to partition the data has changed.","C":"XMLA Endpoint is set to Read Only."},"exam_id":71,"question_images":[],"answers_community":["D (60%)","E (34%)","3%"],"question_text":"You have a Fabric tenant that contains 30 CSV files in OneLake. The files are updated daily.\nYou create a Microsoft Power BI semantic model named Model1 that uses the CSV files as a data source. You configure incremental refresh for Model1 and publish the model to a Premium capacity in the Fabric tenant.\nWhen you initiate a refresh of Model1, the refresh fails after running out of resources.\nWhat is a possible cause of the failure?","answer":"D","isMC":true}],"exam":{"isImplemented":true,"numberOfQuestions":179,"id":71,"provider":"Microsoft","lastUpdated":"12 Apr 2025","isMCOnly":false,"isBeta":false,"name":"DP-600"},"currentPage":20},"__N_SSP":true}