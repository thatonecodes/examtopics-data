{"pageProps":{"questions":[{"id":"sp6Wd69TyNv5YVmsXpDE","answer_ET":"","answers_community":[],"question_images":["https://img.examtopics.com/ai-102/image79.png"],"url":"https://www.examtopics.com/discussions/microsoft/view/122483-exam-ai-102-topic-3-question-58-discussion/","discussion":[{"content":"Pretty sure the second one is add_target_language","comment_id":"1025278","poster":"jangotango","upvote_count":"29","timestamp":"1696480740.0","comments":[{"poster":"nastolgia","timestamp":"1703505660.0","comment_id":"1105245","content":"you do speech-to-speech. so your output should be voice, but proposed answer is incomplete. You also need to specify the type of voice for the synthesizer","comments":[{"content":"Agree, the requirement should changed to translate from speech to text, look at the function name","poster":"upliftinghut","upvote_count":"2","timestamp":"1714414620.0","comment_id":"1204164"}],"upvote_count":"3"}]},{"upvote_count":"17","poster":"evangelist","timestamp":"1707006000.0","comment_id":"1139681","content":"The answer is WRONG! \nCorrect Answer is below:\ndef translate_speech_to_text():\n translation_config = speechsdk.translation.SpeechTranslationConfig(subscription=speech_key, region=service_region)\n translation_config.speech_recognition_language = \"en-US\"\n translation_config.add_target_language(\"de\")"},{"timestamp":"1740808860.0","content":"repeat qn\n\n1. speech_recognition_language\n2. add_target_language","upvote_count":"1","poster":"syupwsh","comment_id":"1363419"},{"content":"There is a distinction between speech-to-speech translation and speech-to-text-to-speech translation. Some questions refer natural language processing (NLP) and this simple mention changes the approach completely. Based on my experience, speech-to-speech translation requires both SpeechRecognitionLanguage and SpeechSynthesisLanguage. However, when performing speech-to-text-to-speech translation—where NLP is implicitly involved, since the speech is first converted to text before translation—you also need to specify the AddTargetLanguage. In this particular case, the answer would be: SpeechRecognitionLanguage and SpeechSynthesisLanguage because there is no mention to NLP.","poster":"Skyhawks","timestamp":"1728595320.0","upvote_count":"4","comment_id":"1295748"},{"content":"Repeated question","comment_id":"1264951","timestamp":"1723519800.0","upvote_count":"1","poster":"anto69"},{"poster":"krzkrzkra","content":"1. speech_recognition_language\n2. add_target_language","upvote_count":"2","timestamp":"1721067300.0","comment_id":"1248515"},{"content":"1. speech_recognition_language\n2. add_target_language","comment_id":"1234516","poster":"HaraTadahisa","timestamp":"1718981940.0","upvote_count":"5"},{"timestamp":"1716982380.0","upvote_count":"4","content":"speech_recognition_language\nadd_target_language","comment_id":"1220864","poster":"omankoman"},{"comment_id":"1215782","upvote_count":"2","content":"It MUST be translation_config.speech_recognition_language = \"en-US\" and translation_config.add_target_language(\"de\").\nWhat exactly have you studied? Memorization is not enough.","timestamp":"1716386040.0","poster":"takaimomoGcup"},{"content":"Similar with Question #40 (language is C#, not Python)\nI believe it's\n1.translation_config.speech_recognition_value = \"en-us\"\n2.translation_config.add_target_language(\"de\")\nthe second one is a method, not a property, thus the \"add\"","timestamp":"1706635380.0","comment_id":"1135984","poster":"Florin83","upvote_count":"2"},{"timestamp":"1701424800.0","content":"How is it even possible that ET provides us witth SO MANY wrong answers? I agree with rdemontis and jangotango, the second one is add_target_language","poster":"tdctdc","comment_id":"1085121","comments":[{"content":"rdemontis should be getting paid","comment_id":"1144441","upvote_count":"2","timestamp":"1707396360.0","poster":"idcanymore"}],"upvote_count":"3"},{"timestamp":"1699199640.0","content":"The second is wrong. it should be add_target_language\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/get-started-speech-translation?tabs=windows%2Cterminal&pivots=programming-language-python#translate-speech-from-a-microphone","upvote_count":"5","comment_id":"1063092","poster":"rdemontis"},{"content":"Proof - https://learn.microsoft.com/en-us/azure/ai-services/speech-service/get-started-speech-translation?tabs=windows%2Cterminal&pivots=programming-language-python","poster":"jangotango","upvote_count":"3","timestamp":"1696480920.0","comment_id":"1025279"}],"question_id":176,"unix_timestamp":1696480740,"timestamp":"2023-10-05 06:39:00","exam_id":40,"answer_description":"","question_text":"DRAG DROP -\n\nYou develop a Python app named App1 that performs speech-to-speech translation.\n\nYou need to configure App1 to translate English to German.\n\nHow should you complete the SpeechTranslationConfig object? To answer, drag the appropriate values to the correct targets. Each value may be used once, more than once or not at all. You may need to drag the split bar between panes or scroll to view content.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","topic":"3","answer":"","isMC":false,"answer_images":["https://img.examtopics.com/ai-102/image221.png"]},{"id":"XzR2ZH21uV0QLk0q1Skf","timestamp":"2023-10-05 11:49:00","question_id":177,"question_text":"HOTSPOT\n-\n\nYou are developing a streaming Speech to Text solution that will use the Speech SDK and MP3 encoding.\n\nYou need to develop a method to convert speech to text for streaming MP3 data.\n\nHow should you complete the code? To answer, select the appropriate options in the answer area.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","unix_timestamp":1696499340,"isMC":false,"question_images":["https://img.examtopics.com/ai-102/image81.png"],"answer":"","answer_images":["https://img.examtopics.com/ai-102/image82.png"],"answer_description":"","answer_ET":"","discussion":[{"upvote_count":"14","content":"first one has to configure the format as MP3, so \"AudioStreamFormat\" option is chosen. Second, since it is speech to text, the SpeechRecognition option is needed.\nThe answer is CORRECT","comment_id":"1139676","poster":"evangelist","timestamp":"1707005160.0"},{"upvote_count":"1","comment_id":"1358643","content":"1) AudioStreamFormat because it specifies the format of the audio stream, which in this case is MP3. The AudioStreamFormat class allows you to define the specific format of the audio data being streamed.\n\n2) SpeechRecognizer because it is used for converting speech to text. The SpeechRecognizer class is designed to recognize speech from audio streams and convert it into text.","poster":"syupwsh","timestamp":"1739956080.0"},{"timestamp":"1720979520.0","upvote_count":"4","comment_id":"1247891","poster":"krzkrzkra","content":"1. AudioStreamFormat\n2. SpeechRecognizer"},{"comment_id":"1235648","poster":"JacobZ","timestamp":"1719099840.0","upvote_count":"1","content":"Same as question 18 in topic 1"},{"content":"1. AudioStreamFormat\n2. SpeechRecognizer","timestamp":"1717677780.0","poster":"NagaoShingo","upvote_count":"2","comment_id":"1225499"},{"comment_id":"1220862","timestamp":"1716982080.0","upvote_count":"1","content":"AudioStreamFormat\nSpeechRecognizer","poster":"omankoman"},{"timestamp":"1716385920.0","poster":"takaimomoGcup","comment_id":"1215780","content":"audio_format = speechsdk.audio.AudioStreamFormat(compressed_stream_format=speechsdk.AudioStreamContainerFormat.MP3)\nrecognizer = speechsdk.SpeechRecognizer(speech_config, audio_config)","upvote_count":"2"},{"comment_id":"1117434","poster":"hkbnjos","comments":[{"content":"The answers are the same. Both chosen are AudioStreamFormat and SpeechRecognizer, but in question 18 there is an additional method for AudioStreamFormat (GetCompressedFormat).","upvote_count":"3","comment_id":"1170723","poster":"Mehe323","timestamp":"1710120060.0"}],"upvote_count":"1","content":"this question is same as Topic 1 Q18 but with different answer, which is correct?","timestamp":"1704799860.0"},{"content":"correct","upvote_count":"2","comment_id":"1063095","poster":"rdemontis","timestamp":"1699199820.0"},{"timestamp":"1696499340.0","content":"Answer correct\nhttps://github.com/Azure-Samples/cognitive-services-speech-sdk/blob/master/samples/python/console/speech_sample.py","poster":"SCyrus","comment_id":"1025510","upvote_count":"4"}],"topic":"3","url":"https://www.examtopics.com/discussions/microsoft/view/122496-exam-ai-102-topic-3-question-59-discussion/","answers_community":[],"exam_id":40},{"id":"EWdhhbwD8UFjMhpr0PFa","question_id":178,"answer_description":"","answers_community":[],"question_images":["https://www.examtopics.com/assets/media/exam-media/04271/0013400001.png"],"unix_timestamp":1629791460,"url":"https://www.examtopics.com/discussions/microsoft/view/60473-exam-ai-102-topic-3-question-6-discussion/","answer":"","isMC":false,"timestamp":"2021-08-24 09:51:00","topic":"3","question_text":"DRAG DROP -\nYou train a Custom Vision model used in a mobile app.\nYou receive 1,000 new images that do not have any associated data.\nYou need to use the images to retrain the model. The solution must minimize how long it takes to retrain the model.\nWhich three actions should you perform in the Custom Vision portal? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\nSelect and Place:\n//IMG//","answer_ET":"","answer_images":["https://img.examtopics.com/ai-102/image215.png"],"exam_id":40,"discussion":[{"comment_id":"430575","content":"The given answer is incorrect. The question emphasizes two things - 1) the model has already been trained 2) the solution should be expedient. The given answer will be very slow to manually tag 1,000 images. instead:\n\n1.) upload all the images\n2.) Get suggested tags\n3.) Review the suggestions and confirm the tags\n\nreference:\n\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/suggested-tags","poster":"SuperPetey","timestamp":"1629791460.0","upvote_count":"145","comments":[{"timestamp":"1631564220.0","poster":"Derin_tade","comment_id":"444179","content":"Thank you.","upvote_count":"3"},{"poster":"vominhtri854","content":"When you tag images for a Custom Vision model, the service uses the latest trained iteration of the model to predict the labels of untagged images\nwe need latest trained to predict the labels, but this isn NOT HAVE ANY ASSOCIATED DATA","comment_id":"464946","upvote_count":"3","timestamp":"1634710500.0"},{"timestamp":"1699108980.0","content":"Exactly. Here we need to use Smart Labeler instead.\nhttps://learn.microsoft.com/en-us/azure/ai-services/custom-vision-service/suggested-tags","upvote_count":"3","comment_id":"1062174","poster":"rdemontis"}]},{"content":"Answer is correct.\n\nWhen uploading all images from a same folder, you can tag all of them with the same value at the same time.\nThen you wont tag all 1000 images one by one, but only once by category (which is time saving as the question ask for).\n\nAlso, even if model is already trained, images are uploaded to workspace, and not to specific trained iteration.\nYou then cannot get tag suggestion when importing an image. There is none, that feature simply does not exist.\n\nTry by yourself :\nhttps://learn.microsoft.com/en-us/training/modules/classify-images/5-exercise-custom-vision","comments":[{"poster":"STH","content":"my bad the feature is real :\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/suggested-tags\n\nso right answer is\n- Upload all\n- Get suggested tags\n- Review and confirm tags","comment_id":"675847","upvote_count":"15","timestamp":"1663832160.0"}],"comment_id":"673909","poster":"STH","timestamp":"1663659840.0","upvote_count":"9"},{"poster":"gyaansastra","timestamp":"1740565680.0","content":"Based on best practices for the Custom Vision service, the correct sequence of three actions would be:\n\nUpload all the images.\nGet suggested tags.\nReview the suggestions and confirm the tags.\n\nThis sequence minimizes retraining time because:\n\nFirst, you need to get all 1,000 images into the Custom Vision portal\nThen, instead of manually tagging all images (which would be time-consuming), you use the auto-tagging/suggestion feature\nFinally, you review and confirm these suggested tags to ensure accuracy before retraining\n\nThis approach leverages Custom Vision's automated tagging capabilities to significantly reduce the manual effort required, while still maintaining quality through human review of the suggestions.","upvote_count":"1","comment_id":"1361866"},{"content":"1) Upload all the images is CORRECT. The first step is to upload all 1,000 images to the Custom Vision portal without sorting them into categories. This minimizes manual effort and prepares the images for automated processing.\n\n2) Get suggested tags is CORRECT. After the images are uploaded, the system can automatically generate tag suggestions based on existing data from the model. This saves time by reducing the need to manually assign tags.\n\n3) Review the suggestions and confirm the tags is CORRECT. Once the system provides tag suggestions, you need to review and confirm them to ensure accuracy. This step ensures the images are correctly labeled, which is essential for retraining the model effectively.","timestamp":"1739343780.0","poster":"syupwsh","comment_id":"1355499","upvote_count":"1"},{"comment_id":"1287918","upvote_count":"2","timestamp":"1727040360.0","poster":"Skyhawks","content":"1) Smart Labeler (Suggested Tags):\n\nThe Smart Labeler functionality uses the latest trained iteration of the model to predict labels for new images. Therefore, even if the images are new, as long as they share similarities with what the model has already seen, the suggested tags feature can save time and effort.\n\nOfficial Documentation: The Azure documentation clearly states that the Smart Labeler can automatically suggest tags for uploaded images, provided they are similar in context to previously trained data.\n\n2) Uploading All Images:\n\nBulk uploading images is the most time-efficient method. There is no need to manually categorize or upload by folder.\n\nThe official Azure documentation supports SuperPetey's reasoning"},{"poster":"krzkrzkra","timestamp":"1721066340.0","content":"1.) upload all the images\n2.) Get suggested tags\n3.) Review the suggestions and confirm the tags","comment_id":"1248498","upvote_count":"2"},{"content":"Can't be correct. You wanna tell me people should manually tag 1000 images?\nAnd how do you categorize them in folders when they have no association? Seems dumb\nIt has to be\n1. Upload all the Images\n2. Get suggested tags\n3. Review the suggested Tags and confirm","timestamp":"1720458060.0","upvote_count":"1","comment_id":"1244476","poster":"Toby86"},{"upvote_count":"1","content":"Group\nUpload category\nTag","poster":"nanaw770","timestamp":"1716559800.0","comment_id":"1217562"},{"poster":"9H3zmT6","upvote_count":"1","comment_id":"1204752","timestamp":"1714519200.0","comments":[{"poster":"nanaw770","content":"So questions registered in 2021 will still be on the exam in April 2024? Japan is a scary country.","comment_id":"1217564","timestamp":"1716559920.0","upvote_count":"1"}],"content":"This question was asked in the actual exam on April 30, 2024 (+9:00, Japan). I think SuperPetey's answer is CORRECT, because I passed the AI-102 exam with a score of 917/1000. Thank you very much."},{"poster":"varinder82","content":"Final Answer\n- Upload all\n- Get suggested tags\n- Review and confirm tags","timestamp":"1711613160.0","comment_id":"1184629","upvote_count":"2"},{"upvote_count":"4","poster":"evangelist","comment_id":"1152276","timestamp":"1708124340.0","content":"To minimize the time required for retraining the model, the correct three steps are:\n\nUpload all images: First, you need to bulk upload the 1000 new images to the Custom Vision service. This is the foundational step for preparing the data.\n\nGet suggested tags: Utilize Custom Vision's functionality to automatically suggest tags for the uploaded images. This can significantly reduce the workload of manual tagging.\n\nReview and confirm suggested tags: Finally, manually review and confirm the tags suggested by the system to ensure their accuracy. Then, use these tagged images to retrain the model.\n\nThis process leverages the automation tools provided by Custom Vision to streamline and expedite the data preparation process, particularly effective when dealing with a large number of untagged images."},{"timestamp":"1701257940.0","content":"Well, it's a bit confusing. In both cases (ET answers and SuperPetey suggestion) - we will have to walk through the pictures manually if there is no info about them. IF they are stored in class folders - the ET answer is less time consuming, if not - it's not possible to tell if separating them manually or manual check of suggested tags will take less time.","poster":"tdctdc","upvote_count":"1","comment_id":"1083383"},{"upvote_count":"2","comment_id":"1040135","timestamp":"1696993800.0","content":"The answer is correct - there is no magic here. You can’t suggest any new tags based on the model you currently have. Read the limitations of the smart labeler carefully: When to use Smart Labeler\nKeep the following limitations in mind:\nYou should only request suggested tags for images whose tags have already been trained on once. Don't get suggestions for a new tag that you're just beginning to train.","poster":"sl_mslconsulting","comments":[{"timestamp":"1705685160.0","poster":"josebernabeo","upvote_count":"3","content":"\"When you tag images for a Custom Vision model, the service uses the latest trained iteration of the model to predict the labels of new images\"\n\nsource: https://learn.microsoft.com/en-us/azure/ai-services/custom-vision-service/suggested-tags","comment_id":"1126847"}]},{"upvote_count":"3","content":"Answer given would be only option IF model had not already been trained with images, so...\nI agree with SuperPetey et al...\n\nUpload\nGet suggested tags\nReview and confirm tags","poster":"Eltooth","comment_id":"633039","timestamp":"1658150340.0"},{"timestamp":"1653639900.0","content":"I agree with SuperPetey. The answer should be\n\n1.) upload all the images\n2.) Get suggested tags\n3.) Review the suggestions and confirm the tags\n\nReason being that using the tools(suggested tags) would still applied to the new 1000 images item, even if those 1000 images doesn't associate with the original data pool. So, that means tagging even 1 less images using the suggested tags would still be faster than manually tagging them. \nhttps://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/suggested-tags","upvote_count":"4","poster":"Number00","comment_id":"607991"},{"upvote_count":"1","content":"1.) Upload all the images\n2.) Get suggested tags\n3.) Review the suggestions and confirm the tags\n\nIf an image does not have any associated TAG, we can add a new one while reviewing\n\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/getting-started-improving-your-classifier","timestamp":"1646135280.0","comment_id":"558708","poster":"reachmymind"},{"upvote_count":"2","poster":"Ravnit","comment_id":"488669","content":"Was on exam 27/11/2021","timestamp":"1638063000.0"},{"timestamp":"1632131220.0","comment_id":"448092","poster":"EXCEL1177","upvote_count":"3","comments":[{"timestamp":"1642599060.0","upvote_count":"4","comment_id":"527532","content":"I disagree, the images are unlabeled, but there is nothing in the text of the question mentioning that there are new tags. I agree with SuperPetey.","poster":"GilEdwards"},{"content":"\"You should only request suggested tags for images whose content has already been trained once. Don't get suggestions for a new tag that you're just beginning to train.\" And the question says RETRAINING of an existing model to which we are adding new images. So the response is actually wrong and @superpetey is correct","timestamp":"1633026180.0","poster":"angie31","upvote_count":"3","comment_id":"455084","comments":[{"timestamp":"1633026300.0","upvote_count":"5","content":"AHHHH but the key word is 'DO NOT HAVE ANY ASSOCIATED DATA'. So the content of images is brand new!!! Therefore we cant use suggester and the response is correct!","comment_id":"455086","comments":[{"content":"The point of machine learning is that a model eventually LEARNS how to do things independently. Even though there is no associated data, there is previous learning done and existing labels can be used. I am not sure why we would need ML if we still have to do things manually all the time?","timestamp":"1711517700.0","poster":"Mehe323","upvote_count":"2","comment_id":"1183891"},{"poster":"ThomasKong","comment_id":"522934","content":"I support your highlighted point to the right point. So the given answer should be correct.","upvote_count":"1","timestamp":"1642089720.0"}],"poster":"angie31"}]}],"content":"@superpetey, kindly read through the article in the link you shared, I just did and confirmed from it that the provided answer by the platform is correct."}]},{"id":"nKrYvpGAAJeo9BLTOcJo","answer_images":["https://img.examtopics.com/ai-102/image98.png"],"timestamp":"2024-02-29 19:57:00","question_text":"HOTSPOT\n-\n\nYou are building a chatbot.\n\nYou need to use the Content Moderator API to identify aggressive and sexually explicit language.\n\nWhich three settings should you configure? To answer, select the appropriate settings in the answer area.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","isMC":false,"question_images":["https://img.examtopics.com/ai-102/image97.png"],"answer_description":"","topic":"3","answers_community":[],"url":"https://www.examtopics.com/discussions/microsoft/view/134937-exam-ai-102-topic-3-question-60-discussion/","question_id":179,"answer":"","answer_ET":"","exam_id":40,"unix_timestamp":1709233020,"discussion":[{"comments":[{"comment_id":"1162939","comments":[{"content":"https://learn.microsoft.com/en-us/training/modules/classify-and-moderate-text-with-azure-content-moderator/4-exercise-use-the-api-console","comment_id":"1190705","timestamp":"1712453400.0","poster":"Training","upvote_count":"3"}],"content":"https://westus.dev.cognitive.microsoft.com/docs/services/57cf753a3f9b070c105bd2c1/operations/57cf753a3f9b070868a1f66f","timestamp":"1709233020.0","poster":"audlindr","upvote_count":"3"}],"content":"The answers should be \nResource Name\nclassify\nocp-Apim-Subscription-Key\n\nautocorrect has nothing to do with the question","comment_id":"1162938","upvote_count":"21","poster":"audlindr","timestamp":"1709233020.0"},{"comment_id":"1358644","content":"Resource Name is CORRECT. This specifies the name of the Content Moderator resource that you are using, ensuring that the API calls are directed to the correct resource.\n\nclassify is CORRECT. Setting this parameter to true enables the classification feature of the Content Moderator API, which is necessary to identify aggressive and sexually explicit language.\n\nOcp-Apim-Subscription-Key is CORRECT. This is the subscription key required to authenticate and authorize your API requests.","timestamp":"1739956320.0","poster":"syupwsh","upvote_count":"1"},{"comment_id":"1356216","upvote_count":"1","timestamp":"1739466480.0","poster":"sukantadey","content":"Resource Name\nclassify\nocp-Apim-Subscription-Key"},{"upvote_count":"4","content":"NagaoShingo 1 month, 1 week ago\n1. Resource name\n2. classify\n3. Ocp-Api-Suscription-Key","poster":"krzkrzkra","comment_id":"1247892","timestamp":"1720979580.0"},{"timestamp":"1718531880.0","poster":"PeteColag","comment_id":"1231293","content":"Resource Name: Provide the name of your Content Moderator resource.\nClassify: Set to true to enable classification of content.\nOcp-Apim-Subscription-Key: Provide your subscription key for authentication.\n\nAll other fields are not necessary to set.","upvote_count":"3"},{"poster":"NagaoShingo","content":"1. Resource name\n2. classify\n3. Ocp-Api-Suscription-Key","comment_id":"1225496","upvote_count":"3","timestamp":"1717677720.0"},{"upvote_count":"2","content":"Resource name\nclassify\nOcp-Api-Suscription-Key","poster":"takaimomoGcup","timestamp":"1716385140.0","comment_id":"1215770"}]},{"id":"p00Kw9dYaSXJJ7xvBQWK","isMC":true,"question_text":"You are developing an app that will use the Decision and Language APIs.\n\nYou need to provision resources for the app. The solution must ensure that each service is accessed by using a single endpoint and credential.\n\nWhich type of resource should you create?","timestamp":"2024-03-10 07:29:00","unix_timestamp":1710052140,"answer_ET":"C","topic":"3","answers_community":["C (100%)"],"answer_description":"","exam_id":40,"url":"https://www.examtopics.com/discussions/microsoft/view/135625-exam-ai-102-topic-3-question-61-discussion/","question_images":[],"answer_images":[],"discussion":[{"poster":"nanaw770","content":"Selected Answer: C\nC is right answer, but now this service name changed \"Azure AI\".","comment_id":"1220354","upvote_count":"5","timestamp":"1716906900.0"},{"poster":"syupwsh","upvote_count":"1","timestamp":"1740888480.0","comment_id":"1363764","content":"Selected Answer: C\nC for sure"},{"poster":"chrillelundmark","upvote_count":"3","comment_id":"1322625","content":"Selected Answer: C\nThis question is depricated. Azure Cognitive services is now Azure AI services. I can't find any info about the Decision API but Language API resides within the new AI Services.\n\nSo for the options:\nA) Part of Azure AI Services\nB) Part of Azure AI Services\nC) Renamed to Azure AI Services\nD) Part of Azure AI Services, but renamed to Content Safety","timestamp":"1733466780.0"},{"poster":"HaraTadahisa","content":"Selected Answer: C\nI say this answer is C.","comment_id":"1235187","timestamp":"1719037260.0","upvote_count":"2"},{"poster":"reigenchimpo","content":"Selected Answer: C\nC is answer.","timestamp":"1718201520.0","upvote_count":"1","comment_id":"1229214"},{"poster":"Murtuza","upvote_count":"1","timestamp":"1711887300.0","content":"Selected Answer: C\nThe correct answer is C. Azure Cognitive Services.\n\nWhen you create an Azure Cognitive Services resource, you get access to a suite of services and APIs, including the Decision and Language APIs, under a single endpoint and credential. This simplifies the management of these services and enhances security by reducing the number of credentials you need to manage. Other options like Language, Speech, and Content Moderator are individual services within Azure Cognitive Services. They do not provide a single endpoint and credential for accessing multiple services. Therefore, they do not meet the requirement specified in the question","comment_id":"1186766"},{"poster":"GHill1982","upvote_count":"3","content":"Selected Answer: C\nA Cognitive Services multi-service resource allows you to access multiple Azure AI services with a single key and endpoint.","comment_id":"1170078","timestamp":"1710052140.0"}],"question_id":180,"answer":"C","choices":{"C":"Azure Cognitive Services","B":"Speech","A":"Language","D":"Content Moderator"}}],"exam":{"name":"AI-102","numberOfQuestions":329,"id":40,"isBeta":false,"isImplemented":true,"provider":"Microsoft","lastUpdated":"12 Apr 2025","isMCOnly":false},"currentPage":36},"__N_SSP":true}