{"pageProps":{"questions":[{"id":"UhznI5JHkpaKImIkzRf6","topic":"4","discussion":[{"comment_id":"378756","content":"Correct.\n\nhttps://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-parallelization\nEmbarrassingly parallel jobs\nStep 3 and 4.","upvote_count":"44","poster":"Preben","timestamp":"1639122480.0","comments":[{"content":"The step 4 you’ve mentioned, @Preben, says: “The number of input partitions must equal the number of output partitions”. The documentation continues to talk about scenarios that are not embarrassingly parallel like @Maunik has mentioned below","upvote_count":"1","comments":[{"poster":"Liz42","comment_id":"461275","timestamp":"1649798460.0","content":"Disregard my above comment… meant to respond to another","upvote_count":"2"}],"timestamp":"1649798400.0","comment_id":"461274","poster":"Liz42"}]},{"content":"Correct cgatpgt :\nFor high scalability and quick processing in Azure Stream Analytics, it's important to align the output event hub partitions with the input source. Since the input event hub `retailhub` has 16 partitions, the output event hub `fraudhub` should also have 16 partitions to match. This ensures that the partitioning scheme is consistent and can handle the volume of transactions efficiently.\n\nThe partition key should be the `Transaction ID`, as this will ensure that all the events for a particular transaction will go to the same partition, maintaining the order of events which is crucial for transactional data and fraud detection scenarios.\n\nSo the correct answers are:\n\nNumber of partitions: 16\nPartition key: Transaction ID","upvote_count":"5","timestamp":"1719327480.0","poster":"Momoanwar","comment_id":"1105412"},{"poster":"kkk5566","timestamp":"1709270220.0","comment_id":"995623","content":"correct","upvote_count":"1"},{"content":"Number of partitions: Since the input event hub retailhub has 16 partitions, it makes sense to have the same number of partitions in the output event hub fraudhub to align the partitions. So the number of partitions should be 16.\n\nPartition key: Since the transaction ID was used as the partition key in the input event hub, using the same partition key in the output event hub ensures that the data for the same transaction ID is processed by the same partition in both event hubs. This makes the flow of data from one event hub to the other more efficient. So the partition key should be the Transaction ID.","poster":"_Lukas_","timestamp":"1707138180.0","comment_id":"972925","upvote_count":"2"},{"comment_id":"645979","poster":"Deeksha1234","upvote_count":"3","timestamp":"1676228700.0","content":"correct"},{"timestamp":"1672303800.0","poster":"nelineli","upvote_count":"3","comment_id":"624466","content":"\"A per-device or user unique identity makes a good partition key, but other attributes such as geography can also be used to group related events into a single partition.\""},{"poster":"sdokmak","content":"Event Hub -> Event Hub: x:x partitions\nEvent Hub -> Blob Storage: x:1 partitions or x:y partitions\nBlob Storage -> Event Hub: x:x partitions\nBlob Storage -> Blob Storage: x:1 partitions","upvote_count":"2","timestamp":"1669504800.0","comment_id":"607798"},{"content":"Example of scenarios that are not embarrassingly parallel\nMismatched partition count\nInput: Event hub with 8 partitions\nOutput: Event hub with 32 partitions\nhttps://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-parallelization\n\nShould be 8 partitions based on link above","comment_id":"443047","timestamp":"1647021900.0","comments":[{"timestamp":"1670584680.0","content":"Maunik it did mention there that it results to \"some level of parallelization\". So I don't think this is the best option to choose if you have equal number of partitions (i.e 16 here) in your options","poster":"Aditya0891","upvote_count":"1","comment_id":"613718"}],"poster":"Maunik","upvote_count":"2"},{"upvote_count":"1","comment_id":"415303","poster":"nichag","content":"Shouldn't the number of partitions only be 8, since the question only asks about the output?","timestamp":"1643280180.0"},{"upvote_count":"2","comments":[{"poster":"wwdba","timestamp":"1660765380.0","upvote_count":"2","content":"An embarrassingly parallel job is the most scalable scenario in Azure Stream Analytics. It connects one partition of the input to one instance of the query to one partition of the output.\nThe number of input partitions must equal the number of output partitions.","comment_id":"549771"},{"poster":"Davico93","content":"There are 2 eventhub, first has 16 partitions and the number of partitions asked is for the second eventhub, and both must be equals for better performance","timestamp":"1671944040.0","comment_id":"621935","upvote_count":"2"},{"upvote_count":"10","content":"Embarrassingly parallel jobs","comment_id":"378203","comments":[{"content":"It's not THAT embarrassing","comment_id":"388493","upvote_count":"10","poster":"captainbee","timestamp":"1640242020.0"}],"poster":"mbravo","timestamp":"1639054980.0"}],"comment_id":"370813","content":"Why 16? Don't understand...","timestamp":"1638267960.0","poster":"rumosgf"}],"exam_id":67,"answers_community":[],"answer_ET":"","url":"https://www.examtopics.com/discussions/microsoft/view/53900-exam-dp-203-topic-4-question-31-discussion/","answer":"","question_images":["https://www.examtopics.com/assets/media/exam-media/04259/0036700001.png"],"unix_timestamp":1622449560,"question_text":"HOTSPOT -\nYou have an Azure event hub named retailhub that has 16 partitions. Transactions are posted to retailhub. Each transaction includes the transaction ID, the individual line items, and the payment details. The transaction ID is used as the partition key.\nYou are designing an Azure Stream Analytics job to identify potentially fraudulent transactions at a retail store. The job will use retailhub as the input. The job will output the transaction ID, the individual line items, the payment details, a fraud score, and a fraud indicator.\nYou plan to send the output to an Azure event hub named fraudhub.\nYou need to ensure that the fraud detection solution is highly scalable and processes transactions as quickly as possible.\nHow should you structure the output of the Stream Analytics job? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","answer_description":"Box 1: 16 -\nFor Event Hubs you need to set the partition key explicitly.\nAn embarrassingly parallel job is the most scalable scenario in Azure Stream Analytics. It connects one partition of the input to one instance of the query to one partition of the output.\n\nBox 2: Transaction ID -\nReference:\nhttps://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-features#partitions","question_id":326,"timestamp":"2021-05-31 10:26:00","isMC":false,"answer_images":["https://www.examtopics.com/assets/media/exam-media/04259/0036800001.png"]},{"id":"DNgZatSnCQbMhfcXk4g2","topic":"4","exam_id":67,"discussion":[{"poster":"lara_mia1","upvote_count":"107","comments":[{"timestamp":"1624975440.0","content":"I agree with lara_mia1","upvote_count":"3","comment_id":"393840","poster":"Marcello83"},{"poster":"niceguy0371","upvote_count":"5","comments":[{"upvote_count":"4","comment_id":"607806","poster":"sdokmak","content":"nah mate, check out his link:\nIs used in JOIN, GROUP BY, DISTINCT, OVER, and HAVING clauses. When two large fact tables have frequent joins, query performance improves when you distribute both tables on one of the join columns. When a table is not used in joins, consider distributing the table on a column that is frequently in the GROUP BY clause.\nIs not used in WHERE clauses. This could narrow the query to not run on all the distributions.\nIs not a date column. WHERE clauses often filter by date. When this happens, all the processing could run on only a few distributions.","timestamp":"1653601380.0"}],"comment_id":"425905","content":"Disagree on nr. 1 because of the reason you give for nr. 2. (choose a distribution column that is not used in where clauses. A join is also a where clause","timestamp":"1629130860.0"},{"poster":"vblessings","comment_id":"416070","timestamp":"1627459500.0","upvote_count":"3","content":"i agree"}],"content":"1. Hash Distributed, ProductKey because >2GB and ProductKey is extensively used in joins\n2. Hash Distributed, RegionKey because \"The table size on disk is more than 2 GB.\" and you have to chose a distribution column which: \"Is not used in WHERE clauses. This could narrow the query to not run on all the distributions.\" \n\nsource: https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-distribute#choosing-a-distribution-column","timestamp":"1622715600.0","comment_id":"373474"},{"comment_id":"359614","timestamp":"1621260540.0","upvote_count":"29","poster":"Rob77","comments":[{"poster":"ploer","timestamp":"1643979720.0","content":"Correct: \"A round-robin distributed table distributes table rows evenly across all distributions. The assignment of rows to distributions is random. Unlike hash-distributed tables, rows with equal values are not guaranteed to be assigned to the same distribution.\" https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-distribute","comment_id":"540426","upvote_count":"1"}],"content":"Both hash as both are > 2GB. In the 2nd table RegionKey cannot be used with round_robin distribution as round_robin does not take a distribution key..."},{"timestamp":"1727074860.0","content":"My 2 cents. if you are choosing the productkey for the sales table and this table is used extensively in joins as stated, and since the regionkey is skewed, we should choose the productkey as a distribution column for the table invoice as well.","poster":"EvanG","upvote_count":"2","comment_id":"1288018"},{"upvote_count":"1","comment_id":"1249549","timestamp":"1721215560.0","content":"Based on the votes, the best agreement for the configuration is:\n\nSales Table: Hash Distributed, ProductKey (134 votes)\nInvoices Table: Hash Distributed, RegionKey (147 votes)","poster":"evangelist"},{"poster":"Dusica","timestamp":"1714129740.0","upvote_count":"1","content":"Hash - Product Key x2","comment_id":"1202551"},{"content":"1. Hash Distributed, ProductKey \n2. Hash Distributed, RegionKey","poster":"kkk5566","comment_id":"995635","upvote_count":"2","timestamp":"1693540140.0"},{"poster":"[Removed]","timestamp":"1692155760.0","content":"When two large fact tables have frequent joins - in this case one is large and another is a small dimension table. Hence highlighted answer is correct","upvote_count":"1","comments":[{"comment_id":"1202550","content":"both are fact tables","poster":"Dusica","upvote_count":"1","timestamp":"1714129440.0"}],"comment_id":"982143"},{"poster":"dom271219","comment_id":"666805","content":"\"Choose a distribution column with data that distributes evenly\"\nProductKey is more relevant in both cases","upvote_count":"4","timestamp":"1662976440.0"},{"timestamp":"1660325760.0","comment_id":"645988","poster":"Deeksha1234","content":"1. Hash Distributed, ProductKey because table size >2GB and ProductKey is extensively used in joins . another, region key could have been considered (after join key which is product key) since its being used in grouping but 75% records belongs to one region so - \nNO for region key.\n\n2. Hash Distributed, RegionKey because the table size on disk is more than 2 GB and Its being used in grouping (for this table more than 75% record doesn't fall in same region) and you have to chose a distribution column which is not used in WHERE clause.","upvote_count":"5"},{"upvote_count":"2","comment_id":"628676","content":"To minimize data movement, select a distribution column that:\n\nIs used in JOIN, GROUP BY, DISTINCT, OVER, and HAVING clauses. When two large fact tables have frequent joins, query performance improves when you distribute both tables on one of the join columns. When a table is not used in joins, consider distributing the table on a column that is frequently in the GROUP BY clause.\nIs not used in WHERE clauses. This could narrow the query to not run on all the distributions.\nIs not a date column. WHERE clauses often filter by date. When this happens, all the processing could run on only a few distributions.","timestamp":"1657266240.0","poster":"Nishikag"},{"poster":"Remedios79","comment_id":"625289","timestamp":"1656596100.0","upvote_count":"1","content":"the provided aswers are correct"},{"poster":"kiranSargar","content":"Generally facts table are hash distributed. so both the table should use hash distribution and distribution key would be product_key for both.","upvote_count":"1","comment_id":"568471","timestamp":"1647356340.0"},{"comments":[{"comment_id":"516941","timestamp":"1641324600.0","upvote_count":"4","poster":"Lucky_me","content":"If we choose RegionKey for Sales, we would have a processing skew."},{"poster":"Aditya0891","content":"DarioEtna where in the question is it mentioned that both tables will be used together in a join query? They have different set of columns in where and group by, so why are you so sure that they will be used together? Answers provided are correct here","upvote_count":"1","comment_id":"618348","timestamp":"1655571360.0"},{"content":"But we cannot use ProductKey in both because in Invoice table it is used in WHERE condition","poster":"DarioEtna","comment_id":"423155","timestamp":"1628666820.0","upvote_count":"4"}],"timestamp":"1628666640.0","content":"as for me i guess this is the right choice:\n1. Hash Distributed, RegionKey because \n2. Hash Distributed, RegionKey because \n\"When two large fact tables have frequent joins, query performance improves when you distribute both tables on one of the join columns\" [Microsoft Documentation]\nIf we use for one ProductKey and for one RegionKey maybe the data movements would increase...or not?","poster":"DarioEtna","comment_id":"423154","upvote_count":"3"},{"comment_id":"414601","timestamp":"1627297860.0","poster":"Amalbenrebai","content":"Regarding the invoces table, we can use the Round-robin distribution because there is no obvious joining key in the table","upvote_count":"2"},{"upvote_count":"9","poster":"zarga","content":"1. Hash on product key\n2. Hash on region key (used on group by and have 65 unique values)","timestamp":"1625830260.0","comment_id":"402661"},{"poster":"BrennaFrenna","comment_id":"379517","content":"The sales table makes sense with hashing distribution on ProductKey and since there is no obvious joining key for invoices, you should use round robin distribution on RegionKey. When it would be a smaller table you should use replicated.","timestamp":"1623395760.0","upvote_count":"3"},{"upvote_count":"1","content":"When it says 75% of records related to one of the 40 regions, if we partition the Sales by Region, isn't it improve the reading process drastically in compare to productKey?","comments":[{"upvote_count":"2","poster":"Preben","content":"That's 75 % of 61 % of the regions that will be done effectively. That's only efficient for 45 % of the queries. Not a whole lot.","timestamp":"1623304620.0","comment_id":"378767"},{"content":"No, if 75% relate to one region and we hash on region, that means that those will all be on one node and there will be skew. Correct answers are Hash, Product, Hash, Region.","comment_id":"408438","timestamp":"1626526260.0","upvote_count":"3","poster":"patricka95"}],"comment_id":"376500","poster":"tubis","timestamp":"1623041400.0"},{"content":"I AGREE WITH BOTH HASH WITH PRODUCT KEY","poster":"bc5468521","comment_id":"368526","timestamp":"1622181240.0","upvote_count":"10"}],"timestamp":"2021-05-17 16:09:00","answer_description":"Box 1: Hash-distributed -\n\nBox 2: ProductKey -\nProductKey is used extensively in joins.\nHash-distributed tables improve query performance on large fact tables.\n\nBox 3: Hash-distributed -\n\nBox 4: RegionKey -\nRound-robin tables are useful for improving loading speed.\nConsider using the round-robin distribution for your table in the following scenarios:\n✑ When getting started as a simple starting point since it is the default\n✑ If there is no obvious joining key\n✑ If there is not good candidate column for hash distributing the table\n✑ If the table does not share a common join key with other tables\n✑ If the join is less significant than other joins in the query\n✑ When the table is a temporary staging table\nNote: A distributed table appears as a single table, but the rows are actually stored across 60 distributions. The rows are distributed with a hash or round-robin algorithm.\nReference:\nhttps://docs.microsoft.com/en-us/azure/sql-data-warehouse/sql-data-warehouse-tables-distribute","question_id":327,"answers_community":[],"answer_images":["https://www.examtopics.com/assets/media/exam-media/04259/0037100001.png"],"unix_timestamp":1621260540,"answer":"","isMC":false,"url":"https://www.examtopics.com/discussions/microsoft/view/52955-exam-dp-203-topic-4-question-32-discussion/","question_images":["https://www.examtopics.com/assets/media/exam-media/04259/0036900001.png","https://www.examtopics.com/assets/media/exam-media/04259/0037000001.png"],"answer_ET":"","question_text":"HOTSPOT -\nYou have an on-premises data warehouse that includes the following fact tables. Both tables have the following columns: DateKey, ProductKey, RegionKey.\nThere are 120 unique product keys and 65 unique region keys.\n//IMG//\n\nQueries that use the data warehouse take a long time to complete.\nYou plan to migrate the solution to use Azure Synapse Analytics. You need to ensure that the Azure-based solution optimizes query performance and minimizes processing skew.\nWhat should you recommend? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point\nHot Area:\n//IMG//"},{"id":"36XtZExZnw7zdodVvbI3","question_id":328,"answers_community":["B (100%)"],"choices":{"C":"DISTINCT","D":"GROUP BY","A":"JOIN","B":"WHERE"},"answer_images":[],"isMC":true,"topic":"4","discussion":[{"content":"correct","comment_id":"412374","upvote_count":"9","poster":"elimey","timestamp":"1642932120.0"},{"timestamp":"1639475760.0","upvote_count":"7","poster":"SG1705","content":"Why ??","comments":[{"poster":"IgorLacik","timestamp":"1640102400.0","comment_id":"387174","upvote_count":"1","content":"Maybe this? https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-parallelization\n\nI think I read somewhere in the docs that you cannot apply complex queries on partition filtering, cannot find it though (not much help I guess, but hopefully better than nothing)"},{"timestamp":"1640090040.0","poster":"okechi","comment_id":"386982","content":"Why ?? Because When you add the \"WHERE\" clause to your T-SQL query it allows the query optimizer accesses only the relevant partitions to satisfy the filter criteria of the query - which is what partition elimination is all about.","comments":[{"timestamp":"1651224480.0","comment_id":"469679","upvote_count":"2","content":"In question 2, we just mentionned to not use the where condition columns to create partitions.. so the logic is unclear for me..","comments":[{"timestamp":"1651605240.0","poster":"noranathalie","upvote_count":"4","content":"please disregard my comment above. Partitioning is different from hash-column, so the criterias are different","comment_id":"472287"},{"timestamp":"1729394580.0","content":"I think you mean distributions instead of partitions. For example it is recommended to use the Date column for partitions but not for distributions.","upvote_count":"1","poster":"lcss27","comment_id":"1198923"}],"poster":"noranathalie"}],"upvote_count":"44"}],"comment_id":"381690"},{"comment_id":"1399888","timestamp":"1742253300.0","upvote_count":"1","content":"Selected Answer: B\nB. Where\nto \"eliminate\" some partitions is the best option","poster":"imatheushenrique"},{"timestamp":"1709272980.0","content":"Selected Answer: B\ncorrect","poster":"kkk5566","upvote_count":"1","comment_id":"995644"},{"upvote_count":"2","content":"Selected Answer: B\nTo maximize the benefits of partition elimination in Azure Synapse Analytics dedicated SQL pool, you should include the WHERE clause in your Transact-SQL queries.\n\nThe WHERE clause allows you to specify conditions that filter the rows returned by a query. When designing queries for partitioned tables, you can include predicates in the WHERE clause that align with the partitioning scheme. By doing so, the query optimizer can leverage partition elimination to exclude unnecessary partitions from the query execution plan.\n\nPartition elimination is the process of excluding partitions from query processing based on the predicates specified in the WHERE clause. By eliminating partitions that do not contain relevant data, the query performance can be significantly improved.","comment_id":"929954","poster":"vctrhugo","timestamp":"1703201340.0"},{"poster":"Deeksha1234","upvote_count":"1","comment_id":"645989","timestamp":"1676230740.0","content":"correct, agree with okechi"},{"comment_id":"629716","poster":"dsp17","upvote_count":"4","content":"100% Correct. Think of it this way, you have 36 partitions over Month column for a table. You are interested in a specific month. so in WHERE clause of your select statement, you will give specific month to \"eliminate\" other 35 partitions scan.","timestamp":"1673385660.0"},{"content":"A is surely true. But B also. If you have two tables small a and big B and you're joining them on condition a.some_column = b.some_column big table B would be filtered by the values found in a. An if B is partitioned on \"some_column\" we have the same effect as with the where clause.","upvote_count":"1","poster":"ploer","comment_id":"540429","timestamp":"1659611280.0"},{"timestamp":"1659195900.0","comment_id":"536357","upvote_count":"1","poster":"kilowd","content":"Selected Answer: B\nB is Correct \nData partition elimination refers to the database server's ability to determine, based on query predicates"},{"content":"what's the difference between distribution and partition? I don't find any doc online to describe it clearly. \n\n• Horizontal partitioning divides a table into multiple tables that contain the same number of columns.\n• A distributed table appears as a single table, but the rows are actually stored across 60 distributions.\n\nIf a table have both distribution and Horizontal partition, how are data stored in SQL? For example a customer table, hash-distributed by region and Horizontal Partitioned by year of the activation data.","comment_id":"510679","upvote_count":"2","poster":"Canary_2021","comments":[{"upvote_count":"1","comment_id":"582186","timestamp":"1665121980.0","content":"distribution is a generally used technique for Massive Distributed Computing. we explicitly decide which distribution pattern to be used in Azure DWH, while Hadoop/Hive automatically distributes the table when created.","poster":"sparkchu"},{"comment_id":"516977","upvote_count":"4","timestamp":"1656959400.0","poster":"Lucky_me","content":"https://stackoverflow.com/questions/51677471/what-is-a-difference-between-table-distribution-and-table-partition-in-sql/51677595"}],"timestamp":"1656367800.0"}],"unix_timestamp":1623657360,"question_images":[],"timestamp":"2021-06-14 09:56:00","exam_id":67,"url":"https://www.examtopics.com/discussions/microsoft/view/55298-exam-dp-203-topic-4-question-33-discussion/","answer":"B","answer_ET":"B","answer_description":"","question_text":"You have a partitioned table in an Azure Synapse Analytics dedicated SQL pool.\nYou need to design queries to maximize the benefits of partition elimination.\nWhat should you include in the Transact-SQL queries?"},{"id":"tZpBadwnPuMQKgtMhYXr","topic":"4","answers_community":["BD (100%)"],"url":"https://www.examtopics.com/discussions/microsoft/view/86591-exam-dp-203-topic-4-question-34-discussion/","unix_timestamp":1666965960,"timestamp":"2022-10-28 16:06:00","question_id":329,"question_text":"You have an Azure Stream Analytics query. The query returns a result set that contains 10,000 distinct values for a column named clusterID.\nYou monitor the Stream Analytics job and discover high latency.\nYou need to reduce the latency.\nWhich two actions should you perform? Each correct answer presents a complete solution.\nNOTE: Each correct selection is worth one point.","choices":{"A":"Add a pass-through query.","C":"Add a temporal analytic function.","E":"Convert the query to a reference query.","D":"Scale out the query by using PARTITION BY.","B":"Increase the number of streaming units."},"answer_ET":"BD","answer_images":[],"discussion":[{"poster":"vctrhugo","upvote_count":"8","comment_id":"929956","content":"Selected Answer: BD\nTo reduce latency in an Azure Stream Analytics job with a query returning a result set containing 10,000 distinct values for a column named clusterID, you should perform the following actions:\n\nB. Increase the number of streaming units:\nIncreasing the number of streaming units allocates more resources to your Stream Analytics job, allowing it to handle higher data volumes and processing loads. By increasing the streaming units, you can improve the job's throughput and reduce latency.\n\nD. Scale out the query by using PARTITION BY:\nUsing the PARTITION BY clause in your query allows you to distribute the workload across multiple partitions or parallel processes. By partitioning the data based on relevant criteria, such as clusterID in this case, you can distribute the processing load and reduce latency by enabling parallel processing.","timestamp":"1719005460.0"},{"timestamp":"1698567960.0","poster":"allagowf","content":"Selected Answer: BD\nkey word: contains 10,000 distinct values for a column named clusterID --> PARTITION.\nreduce the latency --> Increase SU + it refer to PARTITION too.","upvote_count":"8","comment_id":"707023"},{"poster":"kkk5566","upvote_count":"1","timestamp":"1725869280.0","content":"Selected Answer: BD\ncorrect","comment_id":"1003026"},{"comment_id":"1001343","content":"Selected Answer: BD\nB & D are correct","upvote_count":"1","poster":"hassexat","timestamp":"1725698640.0"},{"timestamp":"1698501960.0","poster":"rzeng","comment_id":"706520","upvote_count":"3","content":"correct"}],"isMC":true,"answer":"BD","question_images":[],"exam_id":67,"answer_description":""},{"id":"juINgiuETK7tU5lSaEhs","unix_timestamp":1662564120,"answers_community":["D (96%)","4%"],"isMC":true,"discussion":[{"comment_id":"777928","comments":[{"content":"I think Exam Topics is not about giving answers, but about hosting Q&As posted by contributors. All answers must be verified.","poster":"renan_ineu","timestamp":"1726309320.0","upvote_count":"1","comment_id":"1283584"}],"upvote_count":"10","content":"I don't understand why Exam Topics should be giving different answers for questions they have repeated...like this one!","timestamp":"1673886660.0","poster":"Ngol"},{"timestamp":"1662564120.0","comment_id":"662641","poster":"anks84","upvote_count":"7","content":"Selected Answer: D\nCorrect answer is D."},{"poster":"ahana1074","comment_id":"1284122","timestamp":"1726405320.0","content":"it D team please check cheat sheet -:https://learn.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/cheat-sheet","upvote_count":"1"},{"upvote_count":"1","timestamp":"1722018900.0","content":"Copilot\nSent by Copilot:\nTo identify the extent of the data skew in Table1 within your Azure Synapse Analytics dedicated SQL pool (Pool1), you should:\n\nD. Connect to Pool1 and query sys.dm_pdw_nodes_db_partition_stats.\n\nThis system view provides detailed information about the distribution of data across the nodes and partitions, which is essential for analyzing data skew.","poster":"iceberge","comment_id":"1255844"},{"timestamp":"1721129340.0","upvote_count":"1","poster":"evangelist","comment_id":"1248849","content":"To identify the extent of data skew in a table within an Azure Synapse Analytics dedicated SQL pool, you should connect to the specific pool (Pool1) and query the sys.dm_pdw_nodes_db_partition_stats dynamic management view. This view provides detailed information about data distribution across nodes, which is essential for identifying skew."},{"poster":"evangelist","comment_id":"1239013","timestamp":"1719633600.0","upvote_count":"1","content":"Selected Answer: D\nBuilt-in Pool Limitation: The built-in pool in Synapse Analytics is typically used for on-demand SQL queries and doesn't have access to the detailed statistics of the dedicated SQL pool's partitioned tables."},{"comment_id":"1238472","content":"Selected Answer: D\nsys.dm_pdw_nodes_db_partition_stats is a system view in Azure Synapse Analytics dedicated SQL pool that provides statistics about the distribution of data across distributions (similar to nodes or segments) within the pool.\nA is not an option because there's no specific concept of a \"built-in pool\" in Azure Synapse Analytics dedicated SQL pool context. You connect directly to the SQL pool instance (like Pool1) to execute commands.","upvote_count":"1","timestamp":"1719547440.0","poster":"learnwell"},{"comment_id":"1187940","content":"Selected Answer: A\nCorrect, you can only launch DMV and DBCC from built-in, not from pool1","upvote_count":"1","poster":"MBRSDG","timestamp":"1712047500.0"},{"upvote_count":"1","poster":"ArdiShah","comment_id":"1161066","timestamp":"1709079480.0","comments":[{"content":"D is correct","timestamp":"1709079540.0","upvote_count":"1","comment_id":"1161068","poster":"ArdiShah"}],"content":"In this series of question, we had the same question and correct answer was D."},{"comment_id":"1154574","poster":"j888","content":"A built-in pool usually means a dedicated SQL pool, I think A will be my choice.","comments":[{"timestamp":"1708419360.0","poster":"j888","upvote_count":"2","comment_id":"1154577","content":"On second thought the word 'pool1' is more definitive than the simple term 'built-in'. So D is correct"}],"timestamp":"1708418820.0","upvote_count":"1"},{"upvote_count":"1","comment_id":"1118743","poster":"dakku987","timestamp":"1704899820.0","content":"Selected Answer: D\nD. Connect to Pool1 and query sys.dm_pdw_nodes_db_partition_stats. \nbcz its connect to pool1"},{"timestamp":"1703025720.0","poster":"ShrikantW","upvote_count":"1","comment_id":"1101046","content":"D is the correct answer!"},{"poster":"kkk5566","upvote_count":"1","content":"Selected Answer: D\nrepetd","comment_id":"995649","timestamp":"1693541100.0"},{"timestamp":"1682756760.0","content":"Its D!\nOfficial Learning path:Returns page and row-count information for every partition in the current database.\nnodes_db_partition_stats\n\nhttps://learn.microsoft.com/en-us/training/modules/analyze-optimize-data-warehouse-storage-azure-synapse-analytics/2-understand-skewed-data-space-usage","upvote_count":"1","poster":"bp_a_user","comment_id":"884161"},{"upvote_count":"4","poster":"[Removed]","content":"We had the same question before. The correct answer is D","comment_id":"841397","timestamp":"1679006400.0"},{"comment_id":"826267","content":"Option A is confusing as we have different answer for same question.","timestamp":"1677704400.0","upvote_count":"1","poster":"Vikram1710"},{"upvote_count":"5","content":"Selected Answer: D\nAnswer is not so clear!, because I can't see any refernece on built-in pool. What is built-in pool?\n\nAnyway looking at the doc here: \nhttps://learn.microsoft.com/en-us/sql/relational-databases/system-dynamic-management-views/sys-dm-db-partition-stats-transact-sql?view=sql-server-ver16\nthat claims: \"This syntax is not supported by serverless SQL pool in Azure Synapse Analytics.\"\n\nSo if built-in pool is serverless SQL pool the correct answer should be D (Connect to Pool1 and query sys.dm_pdw_nodes_db_partition_stats).","timestamp":"1673952180.0","comment_id":"778795","poster":"vrodriguesp"},{"comments":[{"upvote_count":"1","content":"If it is the mistake in wording the question and instead of dedicated is serverless, then the answer is A.","timestamp":"1670263860.0","poster":"OldSchool","comment_id":"736183"}],"content":"Selected Answer: D\nIt can't be A and B because those two are connecting to Built-In pool (serverless) and the Q is about dedicated pool.","comment_id":"719774","upvote_count":"2","timestamp":"1668611700.0","poster":"OldSchool"},{"poster":"dimbrici","timestamp":"1668436980.0","upvote_count":"3","comment_id":"718035","content":"Selected Answer: D\nQuestione already seen"},{"timestamp":"1667470920.0","comment_id":"710415","content":"Question repeated","poster":"AdarshKumarKhare","upvote_count":"2"},{"timestamp":"1663689600.0","poster":"SD4592","upvote_count":"4","comment_id":"674328","content":"Selected Answer: D\nAbsolutely D"},{"comment_id":"668314","poster":"debarun","timestamp":"1663093620.0","content":"Correct answer is D.","upvote_count":"3"},{"upvote_count":"2","timestamp":"1662615420.0","content":"Agree with anks84. Correct answer should be D, built-in pool comes from a Synapse Serverless pool and here it says Dedicated","poster":"federc","comment_id":"663160"},{"content":"Selected Answer: D\nThe same question as #8 Topic #4, but different answer. Should be D.","comment_id":"663145","timestamp":"1662614640.0","upvote_count":"2","poster":"pangas2567"}],"timestamp":"2022-09-07 17:22:00","exam_id":67,"question_text":"You have an Azure Synapse Analytics dedicated SQL pool named Pool1 and a database named DB1. DB1 contains a fact table named Table1.\nYou need to identify the extent of the data skew in Table1.\nWhat should you do in Synapse Studio?","topic":"4","question_id":330,"question_images":[],"answer_ET":"D","url":"https://www.examtopics.com/discussions/microsoft/view/80948-exam-dp-203-topic-4-question-35-discussion/","answer":"D","choices":{"C":"Connect to Pool1 and query sys.dm_pdw_node_status.","D":"Connect to Pool1 and query sys.dm_pdw_nodes_db_partition_stats.","B":"Connect to the built-in pool and run DBCC CHECKALLOC.","A":"Connect to the built-in pool and query sys.dm_pdw_nodes_db_partition_stats."},"answer_images":[],"answer_description":""}],"exam":{"id":67,"isMCOnly":false,"isImplemented":true,"isBeta":false,"provider":"Microsoft","numberOfQuestions":384,"lastUpdated":"12 Apr 2025","name":"DP-203"},"currentPage":66},"__N_SSP":true}