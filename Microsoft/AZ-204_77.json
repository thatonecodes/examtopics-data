{"pageProps":{"questions":[{"id":"PqsT1r3EK4xlLpSXRneZ","topic":"5","url":"https://www.examtopics.com/discussions/microsoft/view/155242-exam-az-204-topic-5-question-64-discussion/","exam_id":48,"answer_description":"","timestamp":"2025-01-22 18:32:00","answers_community":[],"answer_ET":"","answer_images":["https://img.examtopics.com/az-204/image579.png"],"question_id":381,"unix_timestamp":1737567120,"question_text":"HOTSPOT\n-\n\nYou have an Azure Function app named App1 written in C# and an Application Insights workspace named Workspace1. App is implemented with Application Insights enabled and is configured to send its telemetry to Workspace1.\n\nYou observe that App1 telemetry collection regularly exceeds monthly quotas of Workspace1.\n\nYou need to ensure that the telemetry volume remains within the monthly quotas of Workspace1.\n\nWhat should you do? To answer, select the appropriate options in the answer area.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","question_images":["https://img.examtopics.com/az-204/image578.png"],"answer":"","discussion":[{"poster":"florianwicher","upvote_count":"5","timestamp":"1739043240.0","content":"Answer is correct:\n\"If adaptive or fixed rate sampling methods are enabled for a telemetry type, ingestion sampling is disabled for that telemetry.\"\nand\n\"Ingestion sampling happens at the Application Insights service endpoint. (...) It doesn't reduce telemetry traffic sent from your app, but helps you keep within your monthly quota.\"\n\nhttps://learn.microsoft.com/en-us/azure/azure-monitor/app/sampling-classic-api","comment_id":"1353600"},{"poster":"tafa_had","upvote_count":"1","timestamp":"1739019420.0","content":"Not correct.\nUse fixed-rate sampling at the App1 level to limit telemetry at the source.\nEnable ingestion sampling at Workspace1 to filter excess data before storing it.","comment_id":"1353402"},{"timestamp":"1737567120.0","poster":"Zezere","comment_id":"1344889","upvote_count":"1","content":"Answer seems not to be correct. To stay in the quotas, you can define a fixed-rate sampling. As ingestion sampling only works when the 2 other types of typing are deactivated, you can deactivate it on the application Insights side."}],"isMC":false},{"id":"OVuWGgAyx1d1TZdhAyaj","choices":{"B":"Create an alert rule.","C":"Enable the test.","D":"Enable the alert.","A":"Create an action group."},"answer":"B","answers_community":["B (71%)","A (29%)"],"question_id":382,"discussion":[{"timestamp":"1739476140.0","upvote_count":"4","poster":"dac15e0","content":"Selected Answer: B\nFrom this link: https://learn.microsoft.com/en-us/azure/azure-monitor/app/availability?tabs=standard\n\"Automatically enabled availability alerts trigger one email when the endpoint becomes unavailable, and another email when it's available again.\"","comment_id":"1356257"},{"poster":"florianwicher","comment_id":"1353601","content":"Selected Answer: A\nJust creating an alert is necessary but not sufficient. The email is sent from an action group associated with the alert rule.","timestamp":"1739043480.0","upvote_count":"2"},{"comment_id":"1353418","upvote_count":"1","poster":"tafa_had","content":"Selected Answer: B\nA is incorrect: Action groups define notification settings but require an alert rule to trigger them. Alone, they won't generate alerts. \nB is correct: This ensures that failed availability tests trigger email notifications to the subscription owners.\nC is incorrect: The test must be enabled, but enabling it does not automatically send alerts for failures.\nD is incorrect: Alerts are not enabled by default, but you must first create an alert rule before enabling alerts.","timestamp":"1739020800.0"}],"topic":"5","url":"https://www.examtopics.com/discussions/microsoft/view/156166-exam-az-204-topic-5-question-65-discussion/","answer_ET":"B","question_images":[],"isMC":true,"question_text":"You have an Azure subscription that contains an Application Insights resource named AI1 and an Azure App Service web app named App1.\n\nYou create a Standard availability test in AI1. You set its URL to point to App1.\n\nYou need to ensure that any failed tests generate email notifications to the owners of the subscription.\n\nWhat should you do?","timestamp":"2025-02-08 14:20:00","answer_images":[],"exam_id":48,"unix_timestamp":1739020800,"answer_description":""},{"id":"Qelkp3yBJzpH3SxuSDf8","topic":"5","answer_ET":"A","answer_images":[],"discussion":[{"content":"I think the correct answer is A because it is the one tuhat takes advantage of the swagger definition of the API?","timestamp":"1612713780.0","comment_id":"285613","poster":"Vano6k","upvote_count":"86","comments":[{"timestamp":"1632889380.0","comment_id":"453795","content":"There is an example of importing an API from an Open Api Link using Import-AzApiManagementApi cmdlet:\nhttps://docs.microsoft.com/en-us/powershell/module/az.apimanagement/import-azapimanagementapi#example-4--import-an-api-from-a-open-api-link\n\nAnd as mentioned here:\nhttps://docs.microsoft.com/en-us/powershell/module/azurerm.apimanagement/import-azurermapimanagementapi\nthe Import-AzureRmApiManagementApi cmdlet is obsoleted by Import-AzApiManagementApi cmdlet.\n\nSo I would select answer A.","poster":"MiraA","upvote_count":"8"},{"timestamp":"1612793520.0","poster":"pac1311","upvote_count":"1","content":"Think so too, the accepted answer has to be wrong.","comment_id":"286244"},{"upvote_count":"3","timestamp":"1613937300.0","comments":[{"timestamp":"1614765960.0","comments":[{"content":"They are not the same.","poster":"trance13","timestamp":"1616938680.0","comment_id":"322666","comments":[{"comment_id":"435091","timestamp":"1630300260.0","upvote_count":"14","poster":"dhishkiyaau","content":"OpenAPI = The specification itself, formerly known as Swagger specification. Swagger = Tools used in the implementation of OpenAPI."}],"upvote_count":"2"}],"poster":"fadikh","upvote_count":"14","comment_id":"302551","content":"Swagger and OpenAPI specs are the same"}],"poster":"Eduarv2015","content":"It does not says that the API has swagger, D is correct.","comment_id":"296083"},{"upvote_count":"4","content":"Totally agree. \nfind the 2 line code here. \nhttps://docs.microsoft.com/en-us/powershell/module/azurerm.apimanagement/import-azurermapimanagementapi?view=azurermps-6.13.0","timestamp":"1623070560.0","comment_id":"376791","poster":"zero0"}]},{"poster":"10x","content":"D should be the answer - it is about accessing API - not creating it (eg based on swagger)","timestamp":"1613625540.0","comments":[{"comment_id":"332698","content":"but you should have one first, that's why you need to create it before able to use","upvote_count":"1","poster":"XYZ2","timestamp":"1618073940.0","comments":[{"poster":"borfavor","comment_id":"343327","comments":[{"comment_id":"519013","upvote_count":"6","poster":"asdasdasg2","content":"It exists in reality, but not on API management. API management API != backend API","timestamp":"1641565500.0"}],"content":"\"The news API back end is implemented as a RESTful service and uses an OpenAPI specification.\" This clearly tells us the API already exists","upvote_count":"4","timestamp":"1619446200.0"}]}],"upvote_count":"15","comment_id":"293116"},{"content":"Selected Answer: A\nImport-AzureRmApiManagementApi -Context $ApiMgmtContext -SpecificationFormat \"Swagger\" -SpecificationPath $SwaggerPath -Path $Path","timestamp":"1731844020.0","upvote_count":"1","poster":"Vichu_1607","comment_id":"1313495"},{"comment_id":"1007425","content":"A\nWhen importing certain APIs, API Management configures the API backend automatically. For example, API Management configures the backend web service when importing:\n\nAn OpenAPI specification.\nA SOAP API.\nAzure resources, such as an HTTP-triggered Azure Function App or Logic App.","timestamp":"1694683800.0","poster":"katrang","upvote_count":"1"},{"timestamp":"1676922900.0","poster":"uffuchsi","upvote_count":"2","content":"Selected Answer: A\nSince we already have an API back end, we need to import to Azure API Management.\n\nhttps://docs.microsoft.com/en-us/azure/api-management/scripts/powershell-import-api-and-add-to-product?toc=/powershell/module/toc.json","comment_id":"815765"},{"upvote_count":"1","comment_id":"811894","timestamp":"1676639760.0","poster":"Sriniv","content":"Answer is B reason\n\nTo configure an Azure API Management instance for a RESTful service that uses an OpenAPI specification, you can use the New-AzApiManagementBackend cmdlet to define the backend service and the Set-AzApiManagementApi cmdlet to add an API to the API Management instance. Here's an example Azure PowerShell command:\n\nNew-AzApiManagementBackend -ResourceGroupName \"myResourceGroup\" -Name \"myBackend\" -Url \"https://news-api.example.com\" -Protocol \"https\" -Title \"News API\"\n\n\n\nSet-AzApiManagementApi -Context \"myApiManagementInstance\" -SpecificationFormat \"OpenApi\" -SpecificationUrl \"https://news-api.example.com/openapi.json\" -Path \"/news\" -DisplayName \"News API\" -BackendUrl \"https://news-api.example.com\" -BackendProtocol \"https\" -BackendId \"myBackend\""},{"comment_id":"811891","content":"I think answer is b\nNew-AzApiManagementBackend -ResourceGroupName \"myResourceGroup\" -Name \"myBackend\" -Url \"https://news-api.example.com\" -Protocol \"https\" -Title \"News API\"\nSet-AzApiManagementApi -Context \"myApiManagementInstance\" -SpecificationFormat \"OpenApi\" -SpecificationUrl \"https://news-api.example.com/openapi.json\" -Path \"/news\" -DisplayName \"News API\" -BackendUrl \"https://news-api.example.com\" -BackendProtocol \"https\" -BackendId \"myBackend\"\n\nThis command creates a new backend service named \"myBackend\" that points to the URL of the news API, and then creates a new API in the specified Azure API Management instance that references the OpenAPI specification for the news API. The API is mapped to the \"/news\" path and is associated with the backend service. The BackendId parameter specifies the ID of the backend service that was created earlier.","timestamp":"1676639580.0","upvote_count":"1","poster":"Sriniv"},{"upvote_count":"2","timestamp":"1670065140.0","content":"Selected Answer: A\nA. Import-AzureRmApiManagementApi -Context $ApiMgmtContext -SpecificationFormat \"Swagger\" -SpecificationPath $SwaggerPath -Path $Path","comments":[{"content":"not sure A or C ..\nNew-AzApiManagement -Name \"myapim\" -ResourceGroupName \"myResourceGroup\" `\n -Location \"West US\" -Organization \"Contoso\" -AdminEmail \"admin@contoso.com\"\nReference: https://learn.microsoft.com/en-us/azure/api-management/powershell-create-service-instance","upvote_count":"1","comment_id":"755453","poster":"POOOJAAAAAAAAAA","timestamp":"1671951900.0"}],"poster":"OPT_001122","comment_id":"734362"},{"poster":"elequiel","content":"Selected Answer: A\nLetter A because you need to create using OpenAPI","upvote_count":"1","comment_id":"716987","timestamp":"1668296400.0"},{"comment_id":"710575","poster":"OPT_001122","content":"Selected Answer: A\ncorrect answer is A","timestamp":"1667487480.0","upvote_count":"1"},{"content":"*-AzureRmApiManagement* can be *-AzApiManagement in future exams\nAzureRM will be replaced by AZ Powershell.","poster":"coffecold","comment_id":"694610","timestamp":"1665737460.0","upvote_count":"2"},{"timestamp":"1665062220.0","poster":"gmishra88","comment_id":"687849","comments":[{"content":"More people will have to retake the exam, more money for Microsoft!","timestamp":"1693055880.0","upvote_count":"2","comment_id":"990779","poster":"macobuzi"}],"content":"Seems like Microsoft has no review mechanism. Look at how the vote is so divided. Microsoft should make this an open book exam. They can be assured people still will not get good scores. Isn't that their intention?","upvote_count":"2"},{"timestamp":"1659798000.0","content":"Selected Answer: D\nD is correct","poster":"Satish_Babu","upvote_count":"1","comment_id":"643434"},{"poster":"HumbleYolo","upvote_count":"5","content":"Selected Answer: C\nwhizlab has c","timestamp":"1657111980.0","comment_id":"627904"},{"upvote_count":"2","comment_id":"588254","content":"Selected Answer: C\nIt is a creation, and docs https://docs.microsoft.com/en-us/powershell/module/azurerm.apimanagement/new-azurermapimanagement?view=azurermps-6.13.0 says there are obligatory params\n\n-ResourceGroupName <String>\n -Name <String>\n -Location <String>\n -Organization <String>\n -AdminEmail <String>\n\nIt must be C.","timestamp":"1650381300.0","poster":"vavra"},{"upvote_count":"1","timestamp":"1646853360.0","comment_id":"564257","content":"Selected Answer: A\nA seems more promising","poster":"SivajiTheBoss"},{"upvote_count":"9","poster":"ReniRechner","content":"Selected Answer: A\nA: Import also creates. Importing also creates an already configured instance (opposed to C)\nB: We don't need another backend, we need a frontend for an exisiting backend\nC: creates a new APIM, but you would still need to manually configure it.\nD: is meant to proxy a public API (https://petri.com/how-to-use-the-azure-api-management-to-proxy-a-public-api)\n\n=> A looks most promising","comment_id":"560665","timestamp":"1646385720.0"},{"upvote_count":"1","timestamp":"1644868800.0","poster":"fearoffree","content":"It seems the trick here is to have the knowledge of API Proxy that could be used for verifying the API availability without a need the need to call the backend APIs. But the question is very vague!","comment_id":"547331"},{"content":"Got this one 02/2022. Went with most voted","timestamp":"1644231600.0","comment_id":"542305","upvote_count":"6","poster":"oescm"},{"content":"Got this one 01/2022. Went with IMPORT","upvote_count":"5","comment_id":"527610","timestamp":"1642603500.0","poster":"lugospod"},{"timestamp":"1641319020.0","upvote_count":"3","comment_id":"516875","poster":"Lucario95","content":"Selected Answer: A\nAccording to this Link -> Import APIM from Swagger Definition\n\nAnd yes, OpenID and Swagger should be synonims from some year"},{"poster":"hsdave","upvote_count":"4","comment_id":"469601","content":"Answer is C according to https://docs.microsoft.com/en-us/azure/api-management/powershell-create-service-instance","timestamp":"1635487260.0"},{"upvote_count":"6","comments":[{"content":"If create new only without import, still cannot access it?","timestamp":"1645659960.0","upvote_count":"1","poster":"huislaw","comment_id":"554952"}],"comment_id":"465888","poster":"nonoss","content":"Correct answer is C. New-AzureRmApiManagement -ResourceGroupName $ResourceGroup -Name $Name ג€\"Location $Location -Organization $Org -AdminEmail $AdminEmail\n\nWhizlabs:\n- A is import not create\n- B is to create a new backend for the api\n-D is used just to create a new backend proxy\n\nhttps://docs.microsoft.com/en-us/powershell/module/az.apimanagement/New-AzApiManagement?view=azps-6.5.0&viewFallbackFrom=azps-4.3.0","timestamp":"1634855280.0"},{"content":"I think the answer is A. \nsee https://docs.microsoft.com/en-us/powershell/module/azurerm.apimanagement/import-azurermapimanagementapi?view=azurermps-6.13.0\nAzureRM module does not have OpenApi as spec. Swagger is used.\nand this page https://docs.microsoft.com/en-us/azure/api-management/backends says, When importing certain APIs, API Management configures the API backend automatically.","timestamp":"1632367440.0","poster":"lxzhu2013","upvote_count":"4","comment_id":"449856"},{"poster":"ning","comment_id":"424539","timestamp":"1628890920.0","content":"This is very confusing ...\n\nIf the backend API is in azure as web app, then I guess I will go A\n\nIf the backend is open public API, you need a proxy for that in order to use inside azure, then possibly D","upvote_count":"1"},{"poster":"AzureLearning","content":"Answer is : A\nSince we already have a API back end, we need to import to Azure API Management.\n\nhttps://docs.microsoft.com/en-us/azure/api-management/scripts/powershell-import-api-and-add-to-product?toc=/powershell/module/toc.json","upvote_count":"5","comment_id":"410646","timestamp":"1626843900.0"},{"poster":"kondapaturi","comment_id":"392167","timestamp":"1624806360.0","content":"Answer is A- To use an existing API (which uses an Open API specification) behind the Azure API Management service , you can use the Import-AzApiManagementApi command.","upvote_count":"5"},{"content":"I would go for C. \n\"The news API back end is implemented as a RESTful service and uses an OpenAPI specification.\". This implies that the API is already imported from a Swagger file.\n\n\"You need to ensure that you can access the news API by using an Azure API Management service instance.\". This implies we need the APIM to use the API which doesn't technically mean the APIM is created yet.","upvote_count":"1","timestamp":"1622547480.0","poster":"TakumaK","comment_id":"371854"},{"upvote_count":"3","content":"The correct answer is C.","comment_id":"364082","timestamp":"1621741440.0","poster":"BabyTechMaggie"},{"comment_id":"360415","poster":"glam","timestamp":"1621337100.0","upvote_count":"5","content":"A. Import-AzureRmApiManagementApi -Context $ApiMgmtContext -SpecificationFormat \"Swagger\" -SpecificationPath $SwaggerPath -Path $Path"},{"comment_id":"359806","content":"I think it is A b/c of https://docs.microsoft.com/en-us/powershell/module/azurerm.apimanagement/import-azurermapimanagementapi?view=azurermps-6.13.0","timestamp":"1621279320.0","upvote_count":"2","poster":"nnto"},{"comment_id":"359065","content":"To old question its recommended to use az module instead of azure","upvote_count":"1","poster":"kimalto452","timestamp":"1621203540.0"},{"comment_id":"358153","timestamp":"1621108080.0","upvote_count":"2","poster":"Frakandel","content":"I thinks it's A, because the question states \"you should be able to use it\", i.e. calling operations on it... A is the only one that actually takes care of defining operations using the swagger definitions."},{"upvote_count":"5","timestamp":"1620826740.0","content":"Correct answer is A. \nThey ask to import an API in APIM. OpenApi is formerly known as Swagger. RM syntax will be deprecated by feb 2024. The correct function is Import-AzApiManagementApi.\nhttps://docs.microsoft.com/en-us/powershell/module/az.apimanagement/import-azapimanagementapi","comment_id":"355541","poster":"SnakePlissken"},{"timestamp":"1618932720.0","content":"Read carefully:\nYou need to ensure that you can access the news API by using an Azure API Management service instance\n\nSo here we can assume that the APIM instance is already there I would say. \nThen it's obvous that you should import the api via the swagger definition.","poster":"sien","upvote_count":"3","comment_id":"339685"},{"content":"C only creates API management instance, it doesnt do anything about backend service, so imho C can not be the answer.","timestamp":"1618883520.0","upvote_count":"2","comment_id":"339266","poster":"jvyas"},{"upvote_count":"3","timestamp":"1618607220.0","poster":"Omallick2","comment_id":"337227","content":"A is the right answer"},{"upvote_count":"1","content":"As AzureRM PowerShell modules will be retired on 29 February 2024, can't see the point of study them, should we really do?","comments":[{"timestamp":"1628206740.0","comments":[{"poster":"ast10","upvote_count":"1","comment_id":"424060","content":"what is the correct answer","timestamp":"1628827380.0"}],"content":"I got this question yesterday.","comment_id":"420514","upvote_count":"1","poster":"mild00"},{"comment_id":"371819","poster":"TakumaK","timestamp":"1622546520.0","upvote_count":"2","content":"It means it is not retired at the moment, so still need to study them."}],"comment_id":"318912","timestamp":"1616572800.0","poster":"vb3d"},{"timestamp":"1616489460.0","poster":"rdemontis","content":"The problem here seems to be the question statement. In my humble opinion it has no sense to declare to support Open API Specification (alias Swagger) and then do not exploit it. If you have this possibility it would be stupid not do it. And the only way to do this is to import the API with Open API Specification in your Azure API Management assuming that you have already an instance of it. Otherwise the first thing to do would be to create a new APIM instance. But if this is really the solution the question would be really useless, I would even say meaningless.","upvote_count":"1","comment_id":"317903"},{"content":"C looks to be correct. A new API Management Instance uses New-AzApiManagement\nhttps://docs.microsoft.com/en-us/azure/api-management/powershell-create-service-instance#create-an-api-management-service","timestamp":"1615554720.0","comment_id":"308858","comments":[{"upvote_count":"1","comment_id":"384227","poster":"Idkhow","content":"dont mind me asking but, what does it have to do with the resource group? the part:\n -ResourceGroupName $ResourceGroup -Name $Name ג€\"Location $Location -Organization $Org -AdminEmail $AdminEmail","timestamp":"1623937260.0"},{"poster":"clarionprogrammer","comment_id":"336732","timestamp":"1618545120.0","content":"Agreed. 'C' makes the most sense.\nhttps://docs.microsoft.com/en-us/powershell/module/azurerm.apimanagement/new-azurermapimanagement?view=azurermps-6.13.0","upvote_count":"2"}],"poster":"hobob","upvote_count":"5"},{"content":"I would select C.","poster":"matejka","comment_id":"291236","timestamp":"1613416800.0","upvote_count":"4"}],"question_images":[],"timestamp":"2021-02-07 17:03:00","isMC":true,"question_id":383,"exam_id":48,"unix_timestamp":1612713780,"answer":"A","choices":{"B":"New-AzureRmApiManagementBackend -Context $ApiMgmtContext -Url $Url -Protocol http","D":"New-AzureRmApiManagementBackendProxy -Url $ApiUrl","C":"New-AzureRmApiManagement -ResourceGroupName $ResourceGroup -Name $Name ג€\"Location $Location -Organization $Org -AdminEmail $AdminEmail","A":"Import-AzureRmApiManagementApi -Context $ApiMgmtContext -SpecificationFormat \"Swagger\" -SpecificationPath $SwaggerPath -Path $Path"},"answers_community":["A (71%)","C (25%)","4%"],"answer_description":"","url":"https://www.examtopics.com/discussions/microsoft/view/44188-exam-az-204-topic-5-question-7-discussion/","question_text":"You develop a gateway solution for a public facing news API. The news API back end is implemented as a RESTful service and uses an OpenAPI specification.\nYou need to ensure that you can access the news API by using an Azure API Management service instance.\nWhich Azure PowerShell command should you run?"},{"id":"uSoTLLofUzTXfaxb9vq6","answer_images":[],"answers_community":["AD (100%)"],"answer_description":"","isMC":true,"question_text":"You are creating a hazard notification system that has a single signaling server which triggers audio and visual alarms to start and stop.\nYou implement Azure Service Bus to publish alarms. Each alarm controller uses Azure Service Bus to receive alarm signals as part of a transaction. Alarm events must be recorded for audit purposes. Each transaction record must include information about the alarm type that was activated.\nYou need to implement a reply trail auditing solution.\nWhich two actions should you perform? Each correct answer presents part of the solution.\nNOTE: Each correct selection is worth one point.","question_images":[],"choices":{"E":"Assign the value of the hazard message SequenceNumber property to the DeliveryCount property.","A":"Assign the value of the hazard message SessionID property to the ReplyToSessionId property.","B":"Assign the value of the hazard message MessageId property to the DevileryCount property.","D":"Assign the value of the hazard message MessageId property to the CorrelationId property.","F":"Assign the value of the hazard message MessageId property to the SequenceNumber property.","C":"Assign the value of the hazard message SessionID property to the SequenceNumber property."},"topic":"5","question_id":384,"answer":"AD","unix_timestamp":1612899660,"url":"https://www.examtopics.com/discussions/microsoft/view/44385-exam-az-204-topic-5-question-8-discussion/","discussion":[{"content":"Answer is correct. \nReplyToSessionId (reply-to-group-id) This value augments the ReplyTo information and specifies which SessionId should be set for the reply when sent to the reply entity.\nCorrelationId (correlation-id) Enables an application to specify a context for the message for the purposes of correlation; for example, reflecting the MessageId of a message that is being replied to.","poster":"Kitkit","comment_id":"287091","upvote_count":"43","timestamp":"1612899660.0"},{"comment_id":"427862","content":"I have no clue what this is about, but I get the feeling we are supposed to arrive at the correct answer by elimination.","timestamp":"1629433680.0","upvote_count":"34","comments":[{"poster":"coffecold","comment_id":"694635","upvote_count":"7","content":"You're right : DeliveryCount, SequenceNumber are read only, two remaining.","timestamp":"1665739800.0"}],"poster":"rustycables"},{"content":"Selected Answer: AD\nA. Assign the value of the hazard message SessionID property to the ReplyToSessionId property.\n\nD. Assign the value of the hazard message MessageId property to the CorrelationId property.","upvote_count":"1","timestamp":"1731844200.0","poster":"Vichu_1607","comment_id":"1313497"},{"comment_id":"815769","poster":"uffuchsi","upvote_count":"1","content":"I believe A + D is correct","timestamp":"1676923020.0"},{"comment_id":"811915","content":"Assign the value of the hazard message MessageId property to the CorrelationId property: When an alarm event is published to the Service Bus, set the MessageId property to a unique value that identifies the message. Then, when the alarm controller receives the message, set the CorrelationId property to the value of the MessageId property. This enables the controller to associate the message with the corresponding transaction record for auditing purposes.","poster":"Sriniv","upvote_count":"4","timestamp":"1676640540.0"},{"poster":"Sriniv","upvote_count":"1","comment_id":"811911","timestamp":"1676640480.0","content":"Therefore, the two actions that you should perform are A and D:\n\nA. Assign the value of the hazard message SessionID property to the ReplyToSessionId property.\nD. Assign the value of the hazard message MessageId property to the CorrelationId property."},{"content":"Selected Answer: AD\nAnswer is correct.","upvote_count":"2","timestamp":"1674661620.0","comment_id":"787834","poster":"alexein74"},{"timestamp":"1667487540.0","comment_id":"710576","upvote_count":"3","content":"Selected Answer: AD\nAnswer is correct.","poster":"OPT_001122"},{"content":"AD\nhttps://docs.microsoft.com/en-us/training/modules/discover-azure-message-queue/5-messages-payloads-serialization","upvote_count":"1","poster":"Praks13","timestamp":"1662580200.0","comment_id":"662842"},{"upvote_count":"2","poster":"meoukg","content":"https://www.examtopics.com/discussions/microsoft/view/44385-exam-az-204-topic-4-question-11-discussion/\nGot it on 03/2022, I chose as below:\nA. Assign the value of the hazard message SessionID property to the ReplyToSessionId property.\nD. Assign the value of the hazard message MessageId property to the CorrelationId property.","timestamp":"1647145140.0","comment_id":"566545"},{"timestamp":"1643572920.0","comment_id":"536450","poster":"ScubaDiver123456","upvote_count":"3","content":"Selected Answer: AD\nI arrived at A+D using the explanations given here\n\nhttps://docs.microsoft.com/en-us/learn/modules/discover-azure-message-queue/5-messages-payloads-serialization"},{"content":"Selected Answer: AD\nAnswer seems correct : AD","comment_id":"522163","upvote_count":"2","poster":"ehurfheiz","timestamp":"1641992580.0"},{"content":"correct.","upvote_count":"3","comment_id":"360424","timestamp":"1621337880.0","poster":"glam"},{"poster":"SnakePlissken","content":"Answer is correct. Nice example to show the purpose of CorrelationId and ReplyToSessionId.","timestamp":"1621148520.0","comment_id":"358372","upvote_count":"4"},{"timestamp":"1617714000.0","poster":"kwaazaar","comment_id":"329635","content":"what reply entity? this question makes no sense.\na simple picture of the setup would greatly clarify things","upvote_count":"6"},{"upvote_count":"3","comment_id":"319470","content":"Also, all the other answers are really kind of obviously wrong...","timestamp":"1616611800.0","poster":"MrZoom"}],"exam_id":48,"timestamp":"2021-02-09 20:41:00","answer_ET":"AD"},{"id":"fe9YsdkVQd2rEcWjUKS2","timestamp":"2021-03-15 13:49:00","answer_images":[],"discussion":[{"comment_id":"311416","poster":"VK7Az204","upvote_count":"75","content":"A is the correct answer","timestamp":"1615812540.0"},{"content":"The error shown is a SQL Server error not an Azure functions error.\nhttps://forums.asp.net/t/2004198.aspx?Timeout+expired+The+timeout+period+elapsed+prior+to+obtaining+a+connection+from+the+pool+This+may+have+occurred+because+all+pooled+connections+were+in+use+and+max+pool+size+was+reached+\nThe actual issue appears to be that you have too many simultaneous functions running, the solution is to limit the batch size (# functions that can run in parallel)\nhttps://social.msdn.microsoft.com/Forums/azure/en-US/a2955297-1c14-45f2-b799-6346b340519a/how-does-batchsize-works-in-hostjson?forum=AzureFunctions","upvote_count":"30","comment_id":"316232","comments":[{"timestamp":"1616492460.0","comments":[{"comment_id":"694653","upvote_count":"1","timestamp":"1665741900.0","comments":[{"upvote_count":"2","content":"B.t.w usage in host.json :\n{\n \"queues\": {\n \"batchSize\": 1,\n \"newBatchThreshold\": 7\n }\n}\nIt has nothing to do with the aggrator batchsize","timestamp":"1665742140.0","poster":"coffecold","comment_id":"694658"}],"poster":"coffecold","content":"This article explains well and easy : https://medium.com/@hammadarif/throttling-the-scalability-of-azure-functions-v2-ddb8625eeedc\nIt gives also the answer why upgrading to premium won't help."}],"upvote_count":"8","poster":"rdemontis","comment_id":"317948","content":"Correct! We have to consider we are speaking about Azure Function with Azure Storage Queue Trigger. This is a case where execution could happens in parallel based on the queue batchSize property\n(see https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-queue).\n\nI think this is the batchSize property referred in the question (and not that in the functions aggregator. That's another thing). \n\nBesides, we have to consider the origin of the error message: Azure Sql Database!! So upgrading the plan the problem could only get worse thing."}],"poster":"djffcnhhyiyaigyvuy","timestamp":"1616320860.0"},{"timestamp":"1731844320.0","poster":"Vichu_1607","comment_id":"1313499","upvote_count":"2","content":"Selected Answer: A\nA. In the host.json file, decrease the value of the batchSize option"},{"comment_id":"1054304","upvote_count":"1","content":"The answer should be A. \nThe error message shows that there is not enough connections, which means that the concurrency is too high. Too many instances are running parallel. So we have to reduce the concurrency of the app.\n\nhttps://github.com/Azure/azure-functions-host/wiki/host.json\nIf you search for \"batchSize\" on the above official microsoft github wiki page for host.json, you will find the explanation for the batchSize: \n// The number of queue messages to retrieve and process in\n // parallel (per job function). The default is 16 and the maximum is 32.\n \"batchSize\": 16,","timestamp":"1698298920.0","poster":"NPE_"},{"content":"Selected Answer: C\nExplanation:\nWith the Premium plan the max outbound connections per instance is unbounded compared to the 600 active (1200 total) in a Consumption plan.\nNote: The number of available connections is limited partly because a function app runs in a sandbox environment. One of the restrictions that the sandbox imposes on your code is a limit on the number of outbound connections, which is currently 600 active (1,200 total) connections per instance. When you reach this limit, the functions runtime writes the following message to the logs: Host thresholds exceeded: Connections.","upvote_count":"1","timestamp":"1694806740.0","comment_id":"1008667","poster":"Lola2023"},{"content":"got this question on 29/06/2023","comment_id":"966775","poster":"BaoNguyen2411","comments":[{"poster":"macobuzi","comment_id":"990786","timestamp":"1693056240.0","upvote_count":"2","content":"What option did you choose?"}],"upvote_count":"3","timestamp":"1690680660.0"},{"timestamp":"1679567280.0","upvote_count":"2","content":"Answer A, the error is at SQL Instance no a function error, and the questions does not say the plan you have... so you cannot asume that you are using consumtion plan.","comment_id":"848059","poster":"JOSEEVILLASMIL"},{"upvote_count":"1","timestamp":"1676641320.0","poster":"Sriniv","content":"None of the options provided are correct I think","comment_id":"811928"},{"timestamp":"1676641260.0","upvote_count":"1","comment_id":"811927","poster":"Sriniv","content":"the most appropriate solution in this case is to optimize the function code and increase the Max Pool Size property of the connection string used by the function."},{"comment_id":"787836","timestamp":"1674661740.0","upvote_count":"1","poster":"alexein74","content":"Selected Answer: A\nA is the correct answer"},{"upvote_count":"3","poster":"OPT_001122","content":"Selected Answer: A\nA is the correct answer","timestamp":"1667487900.0","comment_id":"710581"},{"timestamp":"1665065940.0","comment_id":"687882","comments":[{"comment_id":"687886","poster":"gmishra88","content":"This is the way to limit scale out, but guess that is not there in the options \nhttps://learn.microsoft.com/en-us/azure/azure-functions/event-driven-scaling#limit-scale-out","timestamp":"1665066180.0","upvote_count":"1"},{"poster":"gmishra88","comment_id":"687890","content":"And yes, there is another batchSize that could be for the storage queue. But then we have to imagine that could be the unwritten scenario.","timestamp":"1665066960.0","upvote_count":"1"}],"poster":"gmishra88","upvote_count":"3","content":"This is a question for a machine. I have to remember all options in host.json. How many of these random questions can be asked by Microsoft. \nhttps://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messages-payloads\nhttps://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messages-payloads\nhttps://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messages-payloads\nhttps://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messages-payloads\nhttps://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messages-payloads\nhttps://learn.microsoft.com/en-us/azure/azure-functions/functions-host-json#aggregator\nAccording to the above link batchSize is about application insights. Another marvel from Microsoft to make it without application insights anywhere and cherry on top to ask that mistake in an exam. Especially when batching will make people think it has something to do with batching the calls. Microsoft wins again\nhttps://learn.microsoft.com/en-us/azure/azure-functions/functions-host-json#aggregator"},{"content":"it can not be C when Pool connection is running out, it's able the DB connections pool is out, changing the function plan only allow more callers to access the DB but it does not increase the connections pool size, so it will still be out of connections in DB.","poster":"Knightie","upvote_count":"1","comment_id":"671970","timestamp":"1663473780.0"},{"poster":"Knightie","upvote_count":"2","timestamp":"1661230740.0","comment_id":"650585","content":"Selected Answer: A\nIt's the DB connection Pool..... you scale up the app also no use.. the connectors from DB Pool not release fast enough for the next app to operate."},{"timestamp":"1657026720.0","upvote_count":"2","comment_id":"627479","content":"Selected Answer: A\nA is the correct answer","poster":"Dani_ac7"},{"upvote_count":"4","comment_id":"566546","content":"Got it on 03/2022, I chose A. In the host.json file, decrease the value of the batchSize option","timestamp":"1647145200.0","poster":"meoukg"},{"comment_id":"560678","upvote_count":"1","content":"Selected Answer: C\nA: seems not correct for me.\nsee: https://docs.microsoft.com/en-us/azure/azure-functions/functions-host-json#aggregator\nit just seems to affect metrics. Besides an increase would help => more elements per function => less functions => less connections\n\nB: might help (if scaling can be limited), but for itself is not a solution\n\nC: does not help since source of problem (to many incoming connections to SQL Server) unchanged. There is no problem with number of outgoing connections in function\n\nD: searching for \"queueScaling\" only resulted in AZ-204 question results ;-)\n\nSo what should I choose?\n\nWhile doing research for point B I git to this site\nhttps://medium.com/microsoftazure/azure-functions-limiting-throughput-and-scalability-of-a-serverless-app-5b1c381491e3\n\nI found the hint that a premium plan can limit instances, which is verified here:\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-premium-plan?tabs=portal#maximum-function-app-instances\n\nSo I would go with C but for the option to limit scaling and not for the explanation in the result.","poster":"ReniRechner","timestamp":"1646387940.0","comments":[{"content":"I agree with your reason for not A.. batching is supposed to reduce number of IO requests and thus connections to SQL DB\n\nThe Medium post you referenced is outdated. You can actually limit the scaling on both Consumption and Premium plans: https://docs.microsoft.com/en-us/azure/azure-functions/event-driven-scaling#limit-scale-out \n\nI don't think there is a right answer here... pick A and prAy, buddies","upvote_count":"2","timestamp":"1647331560.0","poster":"iamstudying","comment_id":"568214"}]},{"timestamp":"1645639260.0","poster":"massnonn","upvote_count":"2","content":"Selected Answer: A\nhere: https://stackoverflow.com/questions/56489553/host-json-meaning-of-batchsize","comment_id":"554744"},{"timestamp":"1645605540.0","poster":"ytingyeu","upvote_count":"4","content":"If the root cause is Function running out of connections, the message should be \"Host thresholds exceeded: Connections\" \nhttps://docs.microsoft.com/en-us/azure/azure-functions/manage-connections?tabs=csharp#connection-limit","comment_id":"554319"},{"content":"C is the correct answer according to another test that I did","comment_id":"531347","poster":"pandaz","timestamp":"1643033280.0","upvote_count":"2"},{"content":"Selected Answer: A\nThe problem is that number of connections to SQL Server reached the limit. \nA different trigger is irrelevant. Changing to the Premium plan does not solve the problem with SQL Server connection pool limits. There is no the queueScaling option.\n\nBatchSize allows to group messages that reduce the number of required connections. This is the only relevant solution.","poster":"leonidn","upvote_count":"7","timestamp":"1642225740.0","comment_id":"523946"},{"content":"Selected Answer: A\nA seems to be the correct answer","upvote_count":"1","comment_id":"522167","poster":"ehurfheiz","timestamp":"1641992700.0"},{"poster":"GhostJoe","comment_id":"510340","content":"Selected Answer: A\nA is the correct answer","upvote_count":"1","timestamp":"1640612460.0"},{"comment_id":"392173","content":"A is correct - It could be that the batchSize is high, causing more messages to be processed at once. Here the function would run in parallel and each function would create a new connection to the SQL database. You can reduce the batchSize property in the host.json file.","upvote_count":"7","timestamp":"1624807260.0","poster":"kondapaturi"},{"content":"as per the https://docs.microsoft.com/en-us/azure/azure-functions/functions-host-json\nbatchSize in host.json is for setting the Maximum number of requests to aggregate for calculating metrics for Application Insights so not sure if it really helps in reducing the maximum no of connections to the db. If this is true then the obvious answer would be to go to premium plan to have more processing power so the each function instance execution will complete fast and db connections will be closed much faster and those connections will be available for new or other function execution instances and can prevent the timeout error.","timestamp":"1624679040.0","poster":"Kvm1","comment_id":"390897","comments":[{"timestamp":"1627053600.0","comment_id":"412632","content":"Authors probably meant the other batchSize which sits in queue settings and tells how many messages can be processed in paralel - then answer A will be correct https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-queue#host-json","poster":"Arrrqqq","upvote_count":"4"}],"upvote_count":"1"},{"poster":"kishe","comment_id":"370411","content":"A should be the correct answer according to https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-queue-trigger?tabs=csharp#concurrency","upvote_count":"2","timestamp":"1622402400.0"},{"timestamp":"1621338540.0","upvote_count":"5","poster":"glam","content":"A is the correct","comment_id":"360435"},{"content":"Answer A, decreasing batchSize is correct. \nSwitching to Premium seems a very bad idea. When the connections are unbounded, you will exceed the maximum sessions on the Azure SQL Database for sure when you don't scale that up too. The max concurrent sessions ranges between 300 (Basic) and 30.000 (Standard S9 or Premium).\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/resource-limits-dtu-single-databases","upvote_count":"13","poster":"SnakePlissken","comment_id":"358397","timestamp":"1621150860.0","comments":[{"timestamp":"1622184540.0","content":"Got this question at the exam and scored 100% on Azure Storage, so I'm sure this is correct.","comments":[{"poster":"jvyas","upvote_count":"3","content":"Cant get more sure than this. Thank you.","comment_id":"437508","timestamp":"1630535340.0"},{"comment_id":"376806","timestamp":"1623071280.0","comments":[{"poster":"windflower555","upvote_count":"2","content":"He answered A above","comment_id":"419989","timestamp":"1628118960.0"}],"content":"This measn what? A or C ?","poster":"zero0","upvote_count":"1"},{"content":"which answer was correct","comment_id":"466414","poster":"babaryanryhim","timestamp":"1634959860.0","upvote_count":"1"}],"upvote_count":"12","comment_id":"368545","poster":"SnakePlissken"}]},{"comment_id":"356952","poster":"roshansir","timestamp":"1620973740.0","upvote_count":"1","content":"A is the correct answer"},{"comment_id":"352550","upvote_count":"2","timestamp":"1620490380.0","comments":[{"timestamp":"1640753880.0","comment_id":"511797","upvote_count":"1","content":"your link is about Azure Data factory ,where the question talking about Azure functions and Azure Sql , Don't confuse people's","poster":"MohmmadFayez"}],"poster":"jshah","content":"Given answer C is correct answer because reducing batchsize will help only in case of largeRequestSize. here we are talking about number of connection pool\nError message: Request size is too large\nSymptoms: When you copy data into Azure Cosmos DB with a default write batch size, you receive the following error: Request size is too large.\n\nCause: Azure Cosmos DB limits the size of a single request to 2 MB. The formula is request size = single document size * write batch size. If your document size is large, the default behavior will result in a request size that's too large. You can tune the write batch size.\n\nResolution: In the copy activity sink, reduce the write batch size value (the default value is 10000)\nhttps://docs.microsoft.com/en-us/azure/data-factory/connector-troubleshoot-guide"},{"poster":"jokergester","upvote_count":"2","comment_id":"327160","content":"A - since you have no control on how many connections allowed by the database\nC - only if the current plan specified is Consumption and if the requirement is the amount of compute power of the current function - which are not specified here","timestamp":"1617425760.0"},{"poster":"Zsolt72","upvote_count":"2","timestamp":"1616349660.0","content":"C should not be good, there is nothing wrong with the function itself, the DB connection pool is limited so the function should be aligned with the DB connection pool. In theis case reduce the number of the parallel functions.\nI agree with \"A\".","comment_id":"316572"},{"timestamp":"1616324820.0","content":"A is the correct answer:\nHere the issue could be that the Azure Function is executing in parallel and taking up all the connections in the connection pool. You can either increase the connection pool property on the database side or change the host.json file and edit the batchSize property which tells how many parallel executions should be allowed for the functions defined in the function app.\nThe Microsoft documentation mentions the following on the property.\nSince this is the ideal logical step to take, all other options are incorrect\n\nFor more information on the function bindings for storage queues, please refer to the following URL\n\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-queue-output","poster":"RavindraDevkhile","comment_id":"316274","upvote_count":"1"},{"poster":"malay1232489","comments":[{"comment_id":"379825","timestamp":"1623417900.0","content":"How do we know, App function's current Plan: it could already be in Premium Plan","upvote_count":"1","poster":"jay158","comments":[{"timestamp":"1643110200.0","upvote_count":"1","comment_id":"532071","content":"But if we have got that error message, so the service plan is Consumption, because Premium plan have no that limits.","poster":"smianna"}]}],"timestamp":"1616292300.0","upvote_count":"5","comment_id":"316008","content":"The given answer would be correct. \n\nWhy?\n\nBecause A is configuring the aggregator. The runtime aggregates data about function executions over a period of time. \n\nhttps://docs.microsoft.com/en-us/azure/azure-functions/configure-monitoring?tabs=v2#configure-the-aggregator\n\nIf i convert to a premium plan.\n\n✔ Your function apps run continuously, or nearly continuously.\n✔ You have a high number of small executions and a high execution bill, but low GB seconds in the Consumption plan.\n✔ You need more CPU or memory options than what is provided by the Consumption plan.\n✔ Your code needs to run longer than the maximum execution time allowed on the Consumption plan.\n✔ You require features that aren't available on the Consumption plan, such as virtual network connectivity.\n\nFunction timeout: Maximum\n\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-scale\n\nAnswer for me is C\n\nCorrect answer"},{"upvote_count":"3","comment_id":"313566","comments":[{"timestamp":"1618124760.0","poster":"atomicicebreaker","content":"Because error is coming from SQL Database, as the concurrent connections to the database are exhausted. This means that you are running more functions than you have connections to the database in the pool. You should reduce concurrent connections, not increase them.","comment_id":"333066","upvote_count":"1"},{"timestamp":"1618114920.0","upvote_count":"4","poster":"ahaz","comment_id":"332964","content":"Considering this part of the exception \"This may have occurred because all pooled connections were in use and max pool size was reached\", the problem is that too many instances of the function are running concurrently, which causes the database connection pool to exceed its limit. The needed solution for resolving this issue is to decrease the number of concurrent running functions, and changing tier to premium doesn't help that. Actually it does the opposite. We should decrease the number of concurrent processes, and that could be achieved by decreasing the batch size."}],"poster":"tevivi8222","timestamp":"1616011740.0","content":"Any reference to why \"A\" is the correct answer, apart from writing \"udemy\"?"},{"content":"As per Udemy, correct answer is A","upvote_count":"3","poster":"Basu525","timestamp":"1615873140.0","comment_id":"312016"}],"topic":"5","exam_id":48,"question_id":385,"answer":"A","answers_community":["A (91%)","9%"],"isMC":true,"unix_timestamp":1615812540,"answer_ET":"A","question_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/47176-exam-az-204-topic-5-question-9-discussion/","choices":{"A":"In the host.json file, decrease the value of the batchSize option","D":"In the function.json file, change the value of the type option to queueScaling","B":"Convert the trigger to Azure Event Hub","C":"Convert the Azure Function to the Premium plan"},"answer_description":"","question_text":"You are developing an Azure function that connects to an Azure SQL Database instance. The function is triggered by an Azure Storage queue.\nYou receive reports of numerous System.InvalidOperationExceptions with the following message:\n`Timeout expired. The timeout period elapsed prior to obtaining a connection from the pool. This may have occurred because all pooled connections were in use and max pool size was reached.`\nYou need to prevent the exception.\nWhat should you do?"}],"exam":{"numberOfQuestions":452,"id":48,"provider":"Microsoft","isImplemented":true,"isBeta":false,"name":"AZ-204","isMCOnly":false,"lastUpdated":"12 Apr 2025"},"currentPage":77},"__N_SSP":true}