{"pageProps":{"questions":[{"id":"r3o6OKA0qGQhJoQctxJ8","timestamp":"2020-03-09 11:45:00","exam_id":66,"topic":"3","url":"https://www.examtopics.com/discussions/microsoft/view/15924-exam-dp-201-topic-3-question-18-discussion/","answer":"ACE","unix_timestamp":1583750700,"answer_images":[],"discussion":[{"timestamp":"1583884860.0","upvote_count":"77","comments":[{"poster":"rmk4ever","content":"Vulnerability Assessment is a scanning service built into Azure SQL Database. The service employs a knowledge base of rules that flag security vulnerabilities. It highlights deviations from best practices, such as misconfigurations, excessive permissions, and unprotected sensitive data.\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/sql-vulnerability-assessment","upvote_count":"2","timestamp":"1600082520.0","comment_id":"179238"},{"poster":"cadio30","timestamp":"1623305640.0","upvote_count":"1","comment_id":"378784","content":"This solution is the appropriate for the requirements."}],"content":"ACE\nD - is for finding the vulnerability. Question is not for finding the vulnerability but identify the sensitive data and monitor the access.","poster":"RJ12345678","comment_id":"62017"},{"timestamp":"1584423900.0","content":"correct answer - ACE , I believe","poster":"Nehuuu","comments":[{"comment_id":"149766","timestamp":"1596459540.0","upvote_count":"8","content":"Yes, ACE is correct Answer.. Vulnerability assessment in not fits the purpose","poster":"krisspark"}],"upvote_count":"44","comment_id":"65033"},{"poster":"AngelRio","comment_id":"372197","content":"ACD\nReference Whizlabs Course.","timestamp":"1622579460.0","upvote_count":"3"},{"poster":"syu31svc","timestamp":"1607411580.0","comment_id":"237984","content":"I would go for ACE\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/data-discovery-and-classification-overview\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/threat-detection-overview","upvote_count":"2"},{"content":"https://docs.microsoft.com/en-us/learn/modules/secure-your-azure-sql-database/5-monitor-your-database\nData discovery & classification (currently in preview)","comment_id":"211014","poster":"Shiva1122","upvote_count":"3","timestamp":"1604302500.0","comments":[{"timestamp":"1606197060.0","comment_id":"226384","upvote_count":"1","poster":"WilsonShen","content":"IDENTIFY , Not Encrypt !"}]},{"timestamp":"1603729080.0","upvote_count":"1","poster":"jasu","content":"ACE is correct answer","comment_id":"206397"},{"upvote_count":"4","poster":"groy","timestamp":"1601462940.0","comment_id":"190283","content":"**Correct Answer**\nA. Enable Data Discovery and Classification \nC. Enable Auditing\nE. Use Advanced Threat Protection."},{"timestamp":"1593116760.0","content":"ACE\n\nA) reporting the sensitive data in your databases + monitoring (auditing) and alerting on anomalous access to sensitive data.\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/data-discovery-and-classification-overview\n\nC) Clicking View dashboard at the top of the Audit records page will open a dashboard displaying audit logs info, where you can drill down into Security Insights, Access to Sensitive Data and more.\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/auditing-overview\n\nE) detects anomalous activities indicating unusual and potentially harmful attempts to access or exploit databases.\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/threat-detection-overview","upvote_count":"7","comment_id":"119820","poster":"AhmedReda"},{"poster":"SebK","upvote_count":"1","comment_id":"119692","timestamp":"1593108420.0","content":"ACE: https://docs.microsoft.com/en-us/learn/modules/secure-your-azure-sql-database/5-monitor-your-database"},{"comments":[{"upvote_count":"1","content":"You can configure to perform periodic scan automatically","timestamp":"1613627400.0","comments":[{"timestamp":"1613628180.0","poster":"spiitr","upvote_count":"1","comment_id":"293146","content":"However, I will also go for ACE because VA is better fit for other use-cases in context of proactive checks of unprotected sensitive data if masking is not configured etc. rather than tracking user activities like anomalous access pattern which is ATP"}],"poster":"spiitr","comment_id":"293139"}],"timestamp":"1592749560.0","poster":"Abhilvs","upvote_count":"1","comment_id":"115639","content":"vulnerability assessment can't be the right choice here, Vulnerability assessment is manual check and it doesn't integrate with monitor. ACE is the best choice here."},{"upvote_count":"4","poster":"jovsta","comment_id":"107015","timestamp":"1591809180.0","content":"I think it's ACE. \nA) for identify sensitive data, C) Threat Detection requires Auditing (see link), and E) - ATP should meet the monitor access to the sensitive data.\n(C) - https://docs.microsoft.com/en-us/azure/azure-sql/database/threat-detection-overview#overview.\n\nThe issue is when you read about \"Vulnerability Assessment\", it seems to encapsulate A & E. The key is 'Run' Vulnerability Assessment, instead of 'Enable' or 'Use' <X>. The run VA seems to be a once of to get reports, where as the requirement is constant and live."},{"content":"A, D, E\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/data-discovery-and-classification-overview","comment_id":"104761","upvote_count":"2","timestamp":"1591553820.0","poster":"remz"},{"content":"Vulnerability Assessment is a scanning service built into Azure SQL Database. The service employs a knowledge base of rules that flag security vulnerabilities. It highlights deviations from best practices, such as misconfigurations, excessive permissions, and unprotected sensitive data.\nhttps://docs.microsoft.com/en-us/azure/sql-database/sql-vulnerability-assessment","timestamp":"1587701460.0","comments":[{"comment_id":"84074","content":"The scan report also provides a map of sensitive data discovered in your database. It includes recommendations to classify that data by using data discovery and classification.\n\n- It makes sense. Thank you.","timestamp":"1588676940.0","upvote_count":"2","poster":"MamadouNiang"},{"comment_id":"96327","timestamp":"1590516600.0","content":"So ACDE is probably best answer. Does Auditing really need to be enabled?","upvote_count":"1","poster":"runningman"}],"upvote_count":"3","poster":"talktorahuljoshi","comment_id":"78957"},{"timestamp":"1583829840.0","upvote_count":"8","poster":"NJin","content":"\"You need to identify sensitive data that is stored in the database and monitor access to the data\" this should be A, Discovery and Classification.\nADE","comment_id":"61547"},{"comment_id":"61042","content":"but Data Discovery & Classification introduces a new tool built into SQL Server Management Studio (SSMS) for discovering, classifying, labeling & reporting the sensitive data in your databases.","timestamp":"1583750700.0","upvote_count":"6","poster":"epgd"}],"question_id":146,"question_text":"You plan to use Azure SQL Database to support a line of business app.\nYou need to identify sensitive data that is stored in the database and monitor access to the data.\nWhich three actions should you recommend? Each correct answer presents part of the solution.\nNOTE: Each correct selection is worth one point.","answers_community":[],"answer_ET":"ACE","choices":{"A":"Configure Data Discovery and Classification.","B":"Implement Transparent Data Encryption (TDE).","D":"Run Vulnerability Assessment.","E":"Use Advanced Threat Protection.","C":"Enable Auditing."},"answer_description":"A: Data Discovery & Classification is built into Azure SQL Database, Azure SQL Managed Instance, and Azure Synapse Analytics. It provides advanced capabilities for discovering, classifying, labeling, and reporting the sensitive data in your databases.\nC: An important aspect of the information-protection paradigm is the ability to monitor access to sensitive data. Azure SQL Auditing has been enhanced to include a new field in the audit log called data_sensitivity_information. This field logs the sensitivity classifications (labels) of the data that was returned by a query.\nE: Data Discovery & Classification is part of the Advanced Data Security offering, which is a unified package for advanced Azure SQL security capabilities. You can access and manage Data Discovery & Classification via the central SQL Advanced Data Security section of the Azure portal.\nReference:\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/data-discovery-and-classification-overview","isMC":true,"question_images":[]},{"id":"Zhi7FFintBddMnGOQAJd","answers_community":[],"choices":{"B":"No","A":"Yes"},"answer":"B","url":"https://www.examtopics.com/discussions/microsoft/view/19384-exam-dp-201-topic-3-question-19-discussion/","discussion":[{"timestamp":"1588263900.0","content":"There is no such thing as \"Select\" trigger.","upvote_count":"11","comment_id":"81774","poster":"Leonido","comments":[{"poster":"karma_wins","content":"Correct. https://www.sqlshack.com/triggers-in-sql-server/","upvote_count":"1","comment_id":"347423","timestamp":"1619934360.0"}]},{"poster":"Arsa","content":"Answer is correct","upvote_count":"2","timestamp":"1598014440.0","comment_id":"162964"}],"question_id":147,"question_images":[],"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou have an Azure SQL database that has columns. The columns contain sensitive Personally Identifiable Information (PII) data.\nYou need to design a solution that tracks and stores all the queries executed against the PII data. You must be able to review the data in Azure Monitor, and the data must be available for at least 45 days.\nSolution: You create a SELECT trigger on the table in SQL Database that writes the query to a new table in the database, and then executes a stored procedure that looks up the column classifications and joins to the query text.\nDoes this meet the goal?","exam_id":66,"timestamp":"2020-04-30 18:25:00","answer_description":"Instead add classifications to the columns that contain sensitive data and turn on Auditing.\nNote: Auditing has been enhanced to log sensitivity classifications or labels of the actual data that were returned by the query. This would enable you to gain insights on who is accessing sensitive data.\nReference:\nhttps://azure.microsoft.com/en-us/blog/announcing-public-preview-of-data-discovery-classification-for-microsoft-azure-sql-data-warehouse/","answer_ET":"B","answer_images":[],"isMC":true,"topic":"3","unix_timestamp":1588263900},{"id":"BTKDqEcUKgPo9y3UEMl6","timestamp":"2021-03-23 20:57:00","isMC":true,"answer_ET":"B","question_id":148,"unix_timestamp":1616529420,"question_text":"You are designing an enterprise data warehouse in Azure Synapse Analytics that will contain a table named Customers. Customers will contain credit card information.\nYou need to recommend a solution to provide salespeople with the ability to view all the entries in Customers. The solution must prevent all the salespeople from viewing or inferring the credit card information.\nWhat should you include in the recommendation?","topic":"3","answer_description":"SQL Database dynamic data masking limits sensitive data exposure by masking it to non-privileged users.\nThe Credit card masking method exposes the last four digits of the designated fields and adds a constant string as a prefix in the form of a credit card.\n\nExample: XXXX-XXXX-XXXX-1234 -\nReference:\nhttps://docs.microsoft.com/en-us/azure/sql-database/sql-database-dynamic-data-masking-get-started","answers_community":[],"answer":"B","url":"https://www.examtopics.com/discussions/microsoft/view/48032-exam-dp-201-topic-3-question-2-discussion/","choices":{"A":"row-level security","B":"data masking","C":"column-level security","D":"Always Encrypted"},"question_images":[],"answer_images":[],"discussion":[{"comment_id":"321639","content":"The correct answer is \"Column-level security\".","timestamp":"1616826300.0","upvote_count":"34","poster":"sdas1","comments":[{"upvote_count":"7","timestamp":"1623738180.0","content":"\"You need to recommend a solution to provide salespeople with the ability to view all the entries in Customers\". Column level security does not meet this requirement so I think Data Masking (B) is the right answer.","poster":"hichemck","comment_id":"382380"},{"poster":"Sasidhar39","comment_id":"344496","content":"Yes Column level security is the right answer\nhttps://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/column-level-security","upvote_count":"3","timestamp":"1619597760.0"},{"comment_id":"366904","poster":"cadio30","content":"This is the appropriate answer than data masking as the user can still query the said column even if it is mask","upvote_count":"2","timestamp":"1622013180.0"}]},{"content":"I think the answer should be D, since you can infer data that is masked using brute-force techniques. The question states that the solution must prevent the salespeople from viewing or INFERRING the credit card information.\n\n\"It is appropriate for preventing accidental sensitive data exposure, but will not protect against malicious intent to infer the underlying data.\"\nhttps://docs.microsoft.com/nl-nl/sql/relational-databases/security/dynamic-data-masking?view=sql-server-ver15","comment_id":"318429","timestamp":"1616529420.0","comments":[{"timestamp":"1618044960.0","comments":[{"comment_id":"333621","poster":"DongDuong","timestamp":"1618189620.0","content":"Disregard my previous post. Always encrypted is not supported by Synapse Analytics so it's Column level security","upvote_count":"3"}],"content":"I agree, should be Always encrypted","comment_id":"332404","poster":"DongDuong","upvote_count":"1"},{"timestamp":"1618138740.0","content":"Synapse does not support always encrypted only SQL server and Azure SQL DB: https://docs.microsoft.com/en-us/sql/relational-databases/security/encryption/always-encrypted-database-engine?view=sql-server-ver15.\nCorrect answer is Column-level","poster":"rahul_t","upvote_count":"4","comment_id":"333225"}],"poster":"AntonS","upvote_count":"8"},{"comment_id":"575897","timestamp":"1648344720.0","poster":"DingDongSingSong","upvote_count":"1","content":"Answer is data masking. Please re-read column level security here : https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/column-level-security\n\nColumn level security is when you need to restrict user access to certain columns. Not where you need to give them access to all data BUT want to stop them from viewing/inferring certain information as is the case in this question (credit card info must not be visible or be inferred i.e. data masking)"},{"timestamp":"1624969440.0","comment_id":"393765","poster":"YuvrajSingh","upvote_count":"1","content":"Answer C\nColumn-level security simplifies the design and coding of security in your application, allowing you to restrict column access to protect sensitive data. For example, ensuring that specific users can access only certain columns of a table pertinent to their department."},{"upvote_count":"2","content":"C. column-level security","timestamp":"1619712720.0","poster":"davita8","comment_id":"345528"},{"content":"Data masking in this case can not be inferred as it simply hides the characters with XXX-es. There is no hashing logic or something involved. Therefore you can't infer the original value. Therefore the given answer is correct","comments":[{"comments":[{"content":"I agree.","comment_id":"357058","poster":"Hrabia","upvote_count":"1","timestamp":"1620984900.0"}],"poster":"fe","upvote_count":"7","comment_id":"355422","content":"Additionally, the requirment states that \"... provide salespeople with the ability to view all the entries in Customers.\" With CLS the salespeople would not be able to see all columns in the Customers table. Therefore, data masking is the correct answer.","timestamp":"1620813060.0"}],"comment_id":"342979","timestamp":"1619410260.0","upvote_count":"6","poster":"joegei"},{"poster":"JohnCrawford","comments":[{"timestamp":"1619161740.0","comment_id":"341438","content":"Creating a mask on a column does not prevent updates to that column.","upvote_count":"1","poster":"v_gul"}],"content":"Given answer is wrong. Data Masking allows information to be inferred. \nRow level security acts as a filter at the row level so not preventing information within a column from being viewed.\n\nThat leaves Always Encrypted and Column Level Encryption. Even column level encryption data can be inferred through the use of divide by zero errors, but, as noted by rahul_t, we cannot use Always Encrypted on Synapse at this time so by process of elimination correct answer is Column Level Encryption.","timestamp":"1618314960.0","comment_id":"334640","upvote_count":"1"}],"exam_id":66},{"id":"uqJgu58NdGo1vQ87gU9S","timestamp":"2020-03-09 16:25:00","answer_ET":"A","topic":"3","answer":"A","url":"https://www.examtopics.com/discussions/microsoft/view/15961-exam-dp-201-topic-3-question-20-discussion/","answer_images":[],"question_images":[],"answer_description":"Auditing has been enhanced to log sensitivity classifications or labels of the actual data that were returned by the query. This would enable you to gain insights on who is accessing sensitive data.\nNote: You now have multiple options for configuring where audit logs will be written. You can write logs to an Azure storage account, to a Log Analytics workspace for consumption by Azure Monitor logs, or to event hub for consumption using event hub. You can configure any combination of these options, and audit logs will be written to each.\nReference:\nhttps://azure.microsoft.com/en-us/blog/announcing-public-preview-of-data-discovery-classification-for-microsoft-azure-sql-data-warehouse/","discussion":[{"comments":[{"content":"In the Azure Log Analytics, which is part of the Azure Monitor Tool, you can add these logs added manually. Just go to the advanced options and configure the connection","comment_id":"321679","poster":"jms309","upvote_count":"1","timestamp":"1616833620.0"}],"content":"Sending logs to blob meets 45 days storage requirement. But how about, \"You must be able to review the data in Azure Monitor\"? I think it should be NO.","timestamp":"1616592900.0","upvote_count":"7","comment_id":"319147","poster":"al9887655"},{"content":"90 days in log analytics. So Log Aalaytics works(bure previous answer was no to this question which is silly). Now about blob storage we can easily connect to Azure Monitor/log analytics and then it will be available in Monitor(to meet the question). But then where is that extra step of connecting to log analytics? Also if you plan to connect to log analytics, why use storage account? The only extra benefit of doing this (Storage + log analytics) is that auditing information(the user) is only mentioned in the storage logs and is masked in log analytics. But such a scenario is not asked in this question. So the answer to this question is a big NO. Log Anlaytics is the correct answer. Dont even think about replying to this text","comments":[{"comments":[{"comment_id":"392546","timestamp":"1624850220.0","content":"now if log analytics really masks the PII then how will it work when storage account is connected to Log Analytics for monitor? So the stackoverflow answer is wrong and my answer aboe is correct or the answer to this question is \"NO\"still","upvote_count":"1","poster":"tes"}],"content":"https://stackoverflow.com/questions/66302107/unable-to-get-the-user-id-identity-details-from-log-analytics-workspace-captured\nWell, I might be wrong: \"Log analytics does not capture any PII\" but then the storage to log analytics connection is missing in the question","timestamp":"1624849800.0","poster":"tes","comment_id":"392542","upvote_count":"1"}],"poster":"tes","timestamp":"1624849500.0","comment_id":"392540","upvote_count":"1"},{"timestamp":"1607438760.0","poster":"syu31svc","content":"https://docs.microsoft.com/en-us/azure/azure-sql/database/auditing-overview\nAnswer is yes","upvote_count":"2","comment_id":"238369","comments":[{"comment_id":"317208","upvote_count":"2","timestamp":"1616421360.0","content":"Bro same article the answer IS NO, you can see auditing information is monitor if they are stored in blob storage","poster":"H_S"}]},{"upvote_count":"1","timestamp":"1594243020.0","comments":[{"content":"Over there log analytics is used instead of blob.","comment_id":"142700","poster":"VijayTeja","timestamp":"1595592240.0","upvote_count":"8"},{"content":"Nothing on page 20","upvote_count":"1","timestamp":"1623766860.0","comment_id":"382710","poster":"ZodiaC"}],"comment_id":"130163","content":"on the page 20 in this dump the same question is answed no and here yes ! just wondering if you urself are not sure of ur answer","poster":"kompressor"},{"timestamp":"1583767500.0","content":"But if you need to use Azure Monitor you should audit to Log Analytics destination.\nhttps://docs.microsoft.com/en-us/azure/sql-database/sql-database-auditing","comment_id":"61152","comments":[{"content":"Here the storage is needed for 45 days, Log analytics can store default logs till 31 days. Blob would be a convenient storage medium if longer retention is needed from default.","poster":"Nehuuu","comments":[{"poster":"Tombarc","comments":[{"comments":[{"timestamp":"1590652260.0","upvote_count":"2","comments":[{"timestamp":"1600445880.0","poster":"AJMorgan591","upvote_count":"2","comment_id":"181792","content":"I can't find any articles that suggest Azure Monitor can works with log data held in Blob Storage. Can you please confirm why you think this is so?"},{"timestamp":"1621880460.0","content":"@AJMorgan591 \n\"Azure Monitor logs can be exported to an Azure Storage Account\"\nhttps://docs.microsoft.com/en-us/azure/azure-monitor/logs/azure-data-explorer-query-storage#send-data-to-azure-storage","comment_id":"365812","poster":"111222333","upvote_count":"1"}],"content":"Yes, it is a valid solution. It can work with log stored in a Blob or Log Analytics.","poster":"Mathster","comment_id":"97352"}],"timestamp":"1588264020.0","upvote_count":"1","content":"But the solution will work","comment_id":"81775","poster":"Leonido"}],"timestamp":"1587797220.0","comment_id":"79393","upvote_count":"7","content":"With free tier is up to 31 days, but you can store it up 730 days for an increased charge, also if you're using Sentinel it's stored for 90 days for free. \nhttps://www.shudnow.io/2019/10/14/increasing-azure-log-analytics-retention-per-data-type/\nhttps://blogs.msdn.microsoft.com/canberrapfe/2017/01/25/change-oms-log-analytics-retention-period-in-the-azure-portal/\n\nI believe the answer is Log Analytics, with storage account you wouldn't be able to set up alerts and monitor it from the Azure Monitor service."}],"upvote_count":"17","timestamp":"1584421980.0","comment_id":"65026"}],"upvote_count":"3","poster":"epgd"}],"choices":{"A":"Yes","B":"No"},"answers_community":[],"question_id":149,"unix_timestamp":1583767500,"exam_id":66,"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou have an Azure SQL database that has columns. The columns contain sensitive Personally Identifiable Information (PII) data.\nYou need to design a solution that tracks and stores all the queries executed against the PII data. You must be able to review the data in Azure Monitor, and the data must be available for at least 45 days.\nSolution: You add classifications to the columns that contain sensitive data. You turn on Auditing and set the audit log destination to use Azure Blob storage.\nDoes this meet the goal?","isMC":true},{"id":"5QkZg66RkhYKWXqKu4ld","timestamp":"2021-04-10 14:25:00","url":"https://www.examtopics.com/discussions/microsoft/view/49797-exam-dp-201-topic-3-question-21-discussion/","answer_description":"C: Virtual Network (VNet) service endpoint provides secure and direct connectivity to Azure services over an optimized route over the Azure backbone network.\nEndpoints allow you to secure your critical Azure service resources to only your virtual networks. Service Endpoints enables private IP addresses in the VNet to reach the endpoint of an Azure service without needing a public IP address on the VNet.\nA: You must have Allow trusted Microsoft services to access this storage account turned on under the Azure Storage account Firewalls and Virtual networks settings menu.\nIncorrect Answers:\nD: Virtual Network (VNet) service endpoint policies allow you to filter egress virtual network traffic to Azure Storage accounts over service endpoint, and allow data exfiltration to only specific Azure Storage accounts. Endpoint policies provide granular access control for virtual network traffic to Azure Storage when connecting over service endpoint.\nReference:\nhttps://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-service-endpoints-overview","question_id":150,"discussion":[{"content":"Answer: CD","timestamp":"1620323460.0","comments":[{"content":"This is the appropriate configuration for the requirement","timestamp":"1622536140.0","poster":"cadio30","comment_id":"371696","upvote_count":"2"}],"poster":"Invalid","upvote_count":"23","comment_id":"351321"},{"content":"Should be A and D: https://docs.microsoft.com/en-us/azure/storage/common/storage-network-security?tabs=azure-portal#grant-access-from-a-virtual-network","upvote_count":"3","comments":[{"timestamp":"1618147740.0","content":"I meant C and D","comments":[{"upvote_count":"6","timestamp":"1618333740.0","poster":"JohnCrawford","content":"I agree with rahul_t.\n\nA. Select Allow trusted Microsoft services to access this storage account.\n\nNo - this setting is too broad and does not restrict access to the VM which is NOT a Microsoft service in this usage\n\nB. Select Allow read access to storage logging from any network.\n\nAgain, too permissive. We want to limit access not allow it from anywhere.\n\nC. Enable a virtual network service endpoint. - First step\nD. Set the Allow access from setting to Selected networks. - Second step","comment_id":"334825"}],"upvote_count":"4","comment_id":"333314","poster":"rahul_t"}],"timestamp":"1618147680.0","poster":"rahul_t","comment_id":"333312"},{"upvote_count":"1","timestamp":"1618057500.0","comment_id":"332524","content":"Hmm, why not D instead of A?","poster":"DongDuong"}],"answer_images":[],"answer_ET":"AC","topic":"3","answer":"AC","choices":{"D":"Set the Allow access from setting to Selected networks.","C":"Enable a virtual network service endpoint.","B":"Select Allow read access to storage logging from any network.","A":"Select Allow trusted Microsoft services to access this storage account."},"question_images":[],"question_text":"You have an Azure subscription that contains an Azure virtual machine and an Azure Storage account. The virtual machine will access the storage account.\nYou are planning the security design for the storage account.\nYou need to ensure that only the virtual machine can access the storage account.\nWhich two actions should you include in the design? Each correct answer presents part of the solution.\nNOTE: Each correct selection is worth one point.","isMC":true,"exam_id":66,"unix_timestamp":1618057500,"answers_community":[]}],"exam":{"provider":"Microsoft","name":"DP-201","lastUpdated":"12 Apr 2025","id":66,"numberOfQuestions":206,"isImplemented":true,"isBeta":false,"isMCOnly":false},"currentPage":30},"__N_SSP":true}