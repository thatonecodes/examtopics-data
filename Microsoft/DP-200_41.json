{"pageProps":{"questions":[{"id":"44W5lSmnyWEp5S0Ox5B5","answer_description":"There are a number of other resource constraints that can cause the streaming pipeline to slow down. The watermark delay metric can rise due to:\n✑ Not enough processing resources in Stream Analytics to handle the volume of input events.\n✑ Not enough throughput within the input event brokers, so they are throttled.\n✑ Output sinks are not provisioned with enough capacity, so they are throttled. The possible solutions vary widely based on the flavor of output service being used.\nIncorrect Answers:\nA: Deserialization issues are caused when the input stream of your Stream Analytics job contains malformed messages.\nReference:\nhttps://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-time-handling","question_images":[],"exam_id":65,"topic":"4","question_text":"Your company uses Azure Stream Analytics to monitor devices.\nThe company plans to double the number of devices that are monitored.\nYou need to monitor a Stream Analytics job to ensure that there are enough processing resources to handle the additional load.\nWhich metric should you monitor?","discussion":[{"timestamp":"1606395060.0","comment_id":"228326","poster":"syu31svc","content":"Answer is correct","upvote_count":"7"},{"content":"correct","upvote_count":"1","comment_id":"560541","poster":"PRACKY","timestamp":"1646370540.0"}],"url":"https://www.examtopics.com/discussions/microsoft/view/37838-exam-dp-200-topic-4-question-46-discussion/","question_id":201,"choices":{"A":"Input Deserialization Errors","B":"Early Input Events","D":"Watermark delay","C":"Late Input Events"},"answer_images":[],"answers_community":[],"unix_timestamp":1606395060,"answer_ET":"D","answer":"D","isMC":true,"timestamp":"2020-11-26 13:51:00"},{"id":"Q3dO4ASmGBEGfh5lberG","topic":"4","url":"https://www.examtopics.com/discussions/microsoft/view/26010-exam-dp-200-topic-4-question-47-discussion/","answer":"C","answer_description":"DWU used, defined as DWU limit * DWU percentage, represents only a high-level representation of usage across the SQL pool and is not meant to be a comprehensive indicator of utilization. To determine whether to scale up or down, consider all factors which can be impacted by DWU such as concurrency, memory, tempdb, and adaptive cache capacity. We recommend running your workload at different DWU settings to determine what works best to meet your business objectives.\nReference:\nhttps://docs.microsoft.com/bs-latn-ba/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-concept-resource-utilization-query-activity","choices":{"C":"DWU percentage","B":"DWU used","A":"CPU percentage","D":"Data IO percentage"},"timestamp":"2020-07-18 02:22:00","question_text":"You have an enterprise data warehouse in Azure Synapse Analytics.\nYou need to monitor the data warehouse to identify whether you must scale up to a higher service level to accommodate the current workloads.\nWhich is the best metric to monitor?\nMore than one answer choice may achieve the goal. Select the BEST answer.","isMC":true,"question_id":202,"exam_id":65,"unix_timestamp":1595031720,"answers_community":["C (100%)"],"question_images":[],"discussion":[{"comments":[{"poster":"Tommy65","comment_id":"158220","content":"Agree, that would keep consistency in the way of operating regardless the size of Synapse","upvote_count":"1","timestamp":"1597424040.0"}],"comment_id":"137529","poster":"cmihai","content":"It is better to monitor DWU %, as it would be a consistent way to monitor independent of the absolute DWU used value (which can increase or decrease over time)","upvote_count":"24","timestamp":"1595031720.0"},{"upvote_count":"5","poster":"M0e","content":"DWU percentage is the correct answer.","comment_id":"190954","timestamp":"1601555340.0"},{"content":"Selected Answer: C\nDWU percentage = Maximum between CPU percentage and Data IO percentage\nDWU used = DWU limit * DWU percentage\nC is the answer","timestamp":"1644570840.0","upvote_count":"2","poster":"brieucboonen1","comment_id":"545199"},{"timestamp":"1619593800.0","content":"From the reference link in the answer:\n\"To determine whether to scale up or down, consider all factors which can be impacted by DWU such as concurrency, memory, tempdb, and adaptive cache capacity.\"","upvote_count":"1","comment_id":"344463","poster":"Maddaa"},{"timestamp":"1612710660.0","poster":"gobeyot404","content":"From microsoft docs: Things to consider when viewing metrics and setting alerts:\n***DWU used*** represents only a high-level representation of usage across the SQL pool and ***is not meant*** to be a comprehensive indicator of utilization.","comment_id":"285590","upvote_count":"5"},{"comments":[{"upvote_count":"2","content":"Really? From the reference link I quote: 'DWU used represents only a high-level representation of usage across the SQL pool and is not meant to be a comprehensive indicator of utilization","timestamp":"1619981760.0","comment_id":"347973","poster":"NamishBansal"}],"content":"Based on referenced link the anwser \"DWU used\" seems correct.","timestamp":"1611755940.0","upvote_count":"1","poster":"ssantos","comment_id":"277835"},{"content":"Answer is B. DWU used, defined as DWU limit * DWU percentage, represents only a high-level representation of usage across the SQL pool and is not meant to be a comprehensive indicator of utilization. As mentioned, it is not a comprehensive indicator, but is the best in the list. DWU percentage indicates only a maximum value between CPU and Data I/O.","upvote_count":"4","poster":"ACSC","timestamp":"1608661500.0","comment_id":"250340"},{"content":"DWU percentage = Maximum between CPU percentage and Data IO percentage\nDWU used = DWU limit * DWU percentage\nC is the answer","timestamp":"1606395240.0","poster":"syu31svc","upvote_count":"3","comment_id":"228336"}],"answer_images":[],"answer_ET":"B"},{"id":"kJKBVkNcXIE7VgL7gDtQ","answer_ET":"","question_text":"DRAG DROP -\nYour company analyzes images from security cameras and sends alerts to security teams that respond to unusual activity. The solution uses Azure Databricks.\nYou need to send Apache Spark level events, Spark Structured Streaming metrics, and application metrics to Azure Monitor.\nWhich three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions in the answer area and arrange them in the correct order.\nSelect and Place:\n//IMG//","unix_timestamp":1622297460,"discussion":[{"upvote_count":"2","content":"Provided answer is correct","poster":"weenypenguin","timestamp":"1622576940.0","comment_id":"372180"},{"poster":"MC_06","upvote_count":"2","timestamp":"1622563620.0","content":"the given answer is CORRECT.\n1. config databrick cluster to use the monitoring libirary (Prerequisites)\n2. build spark-listeners-loganalytics-1.0-SNAPSHOT.jar JAR file \n3. create dropwizard counters in application code\n\nref https://docs.microsoft.com/en-us/azure/architecture/databricks-monitoring/application-logs","comment_id":"372025"},{"comment_id":"369535","content":"Sequence provided as the answer is wrong. \nCorrect answer is - \n1. Configure your Azure Databricks cluster to use the monitoring library\n2. Create dropwizard counters in application code\n3. Build the spark-listeners-loganalytics-1.0-SNAPSHOT.jar JAR\n\nRef - https://docs.microsoft.com/en-us/azure/architecture/databricks-monitoring/application-logs","timestamp":"1622297460.0","upvote_count":"2","comments":[{"content":"your link provided right answer but your answer is wrong","timestamp":"1622404560.0","comments":[{"upvote_count":"1","comment_id":"370966","content":"What is it then?","comments":[{"content":"The given answer by ExamTopics is correct!","comment_id":"446089","timestamp":"1631809800.0","upvote_count":"1","poster":"Podavenna"}],"poster":"ZodiaC","timestamp":"1622461140.0"}],"comment_id":"370432","upvote_count":"1","poster":"corentin"}],"poster":"davem0193"}],"answers_community":[],"question_id":203,"question_images":["https://www.examtopics.com/assets/media/exam-media/03872/0045000001.png"],"isMC":false,"answer":"","answer_description":"You can send application logs and metrics from Azure Databricks to a Log Analytics workspace.\nSpark uses a configurable metrics system based on the Dropwizard Metrics Library.\nPrerequisites: Configure your Azure Databricks cluster to use the monitoring library.\nNote: The monitoring library streams Apache Spark level events and Spark Structured Streaming metrics from your jobs to Azure Monitor.\nTo send application metrics from Azure Databricks application code to Azure Monitor, follow these steps:\nStep 1. Build the spark-listeners-loganalytics-1.0-SNAPSHOT.jar JAR file\nStep 2: Create Dropwizard gauges or counters in your application code.\nReference:\nhttps://docs.microsoft.com/bs-latn-ba/azure/architecture/databricks-monitoring/application-logs","url":"https://www.examtopics.com/discussions/microsoft/view/53773-exam-dp-200-topic-4-question-48-discussion/","topic":"4","exam_id":65,"answer_images":["https://www.examtopics.com/assets/media/exam-media/03872/0045000002.png"],"timestamp":"2021-05-29 16:11:00"},{"id":"rrd3jAanPjhK6Cc5MJew","question_text":"You manage a solution that uses Azure HDInsight clusters.\nYou need to implement a solution to monitor cluster performance and status.\nWhich technology should you use?","url":"https://www.examtopics.com/discussions/microsoft/view/11152-exam-dp-200-topic-4-question-49-discussion/","topic":"4","answers_community":[],"discussion":[{"poster":"cnuusd","comment_id":"33975","content":"The question is asking about ' Implement a Solution' - I think the answer is 'Ambari REST API' \nAmbari Web UI is a Tool but not a Technology to implement the solution.","upvote_count":"28","timestamp":"1577791800.0"},{"comment_id":"102992","timestamp":"1591343520.0","content":"Ambari web UI is the answer. https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-key-scenarios-to-monitor","poster":"serger","upvote_count":"13","comments":[{"poster":"indradatabricks","content":"Why not Ambari REST API and Azure Log Analytics?","timestamp":"1594406880.0","upvote_count":"1","comment_id":"131679"},{"comment_id":"134603","timestamp":"1594706880.0","poster":"raphylee","upvote_count":"2","comments":[{"content":"https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-manage-ambari","upvote_count":"2","poster":"raphylee","comment_id":"134606","timestamp":"1594707000.0"}],"content":"I looked up the link shared, this is correct."}]},{"content":"It should be Ambari web UI .\nhttps://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-key-scenarios-to-monitor","upvote_count":"1","timestamp":"1615628820.0","comment_id":"309597","poster":"ZenRajnish"},{"upvote_count":"2","poster":"dumpsm42","content":"hi to all,\ni agree with \"rjdask\", the text says \"...IMPLEMENT...\" so it means develop, so i will choose also Ambari REST API\nRegards","comment_id":"238222","timestamp":"1607430840.0","comments":[{"comment_id":"238228","upvote_count":"1","content":"https://docs.cloudera.com/HDPDocuments/Ambari-2.7.5.0/managing-and-monitoring-ambari/content/amb_understanding_ambari_architecture.html","poster":"dumpsm42","timestamp":"1607431020.0","comments":[{"timestamp":"1607431140.0","content":"this exam dp-200 variation bellow justifies NOW the use of ambari web UI, in this case yes, this is the right answer.\nA company has a Microsoft Azure HDInsight solution that uses different cluster types to process and analyze data. Operations are continuous.\nReports indicate slowdowns during a specific time window.\nYou need to determine a monitoring solution to track down the issue in the least amount of time.\nWhat should you use?\n\nA. Azure Log Analytics log search query\nB. Ambari REST API\nC. Azure Monitor Metrics\nD. HDInsight .NET SDK\nE. Azure Log Analytics alert rule query","poster":"dumpsm42","comments":[{"comment_id":"453987","upvote_count":"1","content":"It say \"determine a monitoring solution \" not to implement solution!","timestamp":"1632907020.0","poster":"satyamkishoresingh"}],"comment_id":"238230","upvote_count":"4"}]}]},{"timestamp":"1606310040.0","upvote_count":"3","content":"100% is E","comment_id":"227597","poster":"syu31svc"},{"poster":"Egocentric","comment_id":"223030","upvote_count":"2","content":"https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-key-scenarios-to-monitor hence E is the answer","timestamp":"1605813000.0"},{"timestamp":"1605021300.0","comment_id":"216712","poster":"lingjun","content":"Apache Ambari simplifies Hadoop management by providing an easy-to-use web UI. You can use Ambari to manage and monitor Hadoop clusters. Developers can integrate these capabilities into their applications by using the Ambari REST APIs.","upvote_count":"1"},{"comment_id":"150490","upvote_count":"3","poster":"rjdask","timestamp":"1596551220.0","content":"It say implement a solution, not use a solution. I would think REST API."},{"timestamp":"1588120740.0","comments":[{"timestamp":"1594759860.0","comment_id":"135239","upvote_count":"1","content":"Correct answer is Ambari REST API","poster":"Sennkumar"}],"poster":"Sudipta3009","upvote_count":"3","comment_id":"81087","content":"I think Azure Log Analytics would be the answer.\nALA monitors the Performance and Availability of the clusters. \nWhereas Ambari is used to Monitor the Health and Utilization for any given HDIsight Cluster.\nCan anyone plz confirm the correct answer."},{"comment_id":"77806","upvote_count":"4","content":"https://azure.microsoft.com/en-us/blog/monitoring-on-hdinsight-part-1-an-overview/\n\nThe recommended way to monitor workload information and logs on Azure HDInsight is using Azure Monitor logs.","timestamp":"1587542700.0","comments":[{"content":"One of the key benefits of Azure Monitor logs is that you can push metrics and logs from multiple HDInsight clusters to the same Log Analytics workspace, allowing you to monitor multiple clusters in one place.","comment_id":"77808","timestamp":"1587542820.0","poster":"Huepig","upvote_count":"2"}],"poster":"Huepig"},{"upvote_count":"1","content":"CDE all look correct to me","timestamp":"1586621700.0","comment_id":"73374","poster":"Yuri1101"},{"content":"Why the correct answer is Azure Log Analytics?¿","timestamp":"1580381160.0","poster":"epgd","upvote_count":"1","comment_id":"44625"}],"question_images":[],"answer_images":[],"answer_ET":"E","question_id":204,"answer":"E","isMC":true,"choices":{"A":"Azure HDInsight .NET SDK","C":"Ambari REST API","E":"Ambari Web UI","D":"Azure Log Analytics","B":"Azure HDInsight REST API"},"answer_description":"Ambari is the recommended tool for monitoring utilization across the whole cluster. The Ambari dashboard shows easily glanceable widgets that display metrics such as CPU, network, YARN memory, and HDFS disk usage. The specific metrics shown depend on cluster type. The ג€Hostsג€ tab shows metrics for individual nodes so you can ensure the load on your cluster is evenly distributed.\nThe Apache Ambari project is aimed at making Hadoop management simpler by developing software for provisioning, managing, and monitoring Apache Hadoop clusters. Ambari provides an intuitive, easy-to-use Hadoop management web UI backed by its RESTful APIs.\nReferences:\nhttps://azure.microsoft.com/en-us/blog/monitoring-on-hdinsight-part-1-an-overview/ https://ambari.apache.org/","exam_id":65,"timestamp":"2019-12-31 12:30:00","unix_timestamp":1577791800},{"id":"AHMTMrUtAOnXuWa4nRIc","question_id":205,"topic":"4","answer_images":[],"unix_timestamp":1631809980,"answer":"B","answer_ET":"B","answer_description":"Data Factory stores pipeline-run data for only 45 days. Use Azure Monitor if you want to keep that data for a longer time. With Monitor, you can route diagnostic logs for analysis to multiple different targets.\nReference:\nhttps://docs.microsoft.com/en-us/azure/data-factory/monitor-using-azure-monitor","choices":{"A":"the Activity log blade for the Data Factory resource","C":"the Monitor & Manage app in Data Factory","B":"Azure Monitor","D":"the Resource health blade for the Data Factory resource"},"timestamp":"2021-09-16 18:33:00","isMC":true,"exam_id":65,"question_text":"You have an Azure data factory.\nYou need to examine the pipeline failures from the last 60 days.\nWhat should you use?","answers_community":[],"question_images":[],"discussion":[{"poster":"Podavenna","comment_id":"446091","timestamp":"1631809980.0","upvote_count":"2","content":"Correct Answer!"}],"url":"https://www.examtopics.com/discussions/microsoft/view/62225-exam-dp-200-topic-4-question-50-discussion/"}],"exam":{"provider":"Microsoft","isBeta":false,"isMCOnly":false,"id":65,"lastUpdated":"12 Apr 2025","isImplemented":true,"numberOfQuestions":228,"name":"DP-200"},"currentPage":41},"__N_SSP":true}