{"pageProps":{"questions":[{"id":"YDdcLn22jwK8944JScbq","exam_id":68,"unix_timestamp":1629656160,"topic":"1","discussion":[{"content":"Selected Answer: A\ncorrect answer is A: you need to mask the email.","upvote_count":"15","comment_id":"487167","timestamp":"1669450140.0","comments":[{"timestamp":"1706599140.0","poster":"KingChuang","content":"https://learn.microsoft.com/en-us/azure/azure-sql/database/dynamic-data-masking-overview?view=azuresql","upvote_count":"3","comment_id":"792511"}],"poster":"jddc"},{"comment_id":"445059","upvote_count":"7","comments":[{"poster":"jerkyflexoff","timestamp":"1667560620.0","comment_id":"472504","upvote_count":"7","content":"Yep A\nYou set up a dynamic data masking policy in the Azure portal by selecting the Dynamic Data Masking blade under Security in your SQL Database configuration pane. This feature cannot be set using portal for SQL Managed Instance. For more information, see Dynamic Data Masking.\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/dynamic-data-masking-overview"}],"timestamp":"1663225680.0","poster":"Aggie0702","content":"The correct answer is A"},{"upvote_count":"1","comment_id":"1559661","timestamp":"1744305720.0","content":"Selected Answer: A\nanswer A","poster":"sincerebb"},{"poster":"jerrychan","timestamp":"1726411380.0","comment_id":"1008531","upvote_count":"2","content":"reference: https://www.examtopics.com/discussions/microsoft/view/36123-exam-dp-200-topic-3-question-4-discussion/\nThe answer should be C. The key word is \"a SQL pool in Azure Synapse\". Dynamic data masking does not apply to it. (So we can't achieve this from the Azure portal.)"},{"upvote_count":"4","timestamp":"1724962560.0","content":"This is a DP-203 question. Azure Synapse Analytics is not part of the DP-300 curriculum.","poster":"ofzrgrz","comment_id":"993488"},{"upvote_count":"1","content":"Selected Answer: A\nThe correct option is A. From the Azure portal, set a mask on the Email column.\n\nBy setting a mask on the Email column, you can control the way sensitive data is displayed to non-administrative users. The mask allows you to show a modified version of the data while keeping the original data secure. In this case, you can configure the mask to display the email addresses in the format of aXXX@XXXX.com as required.\n\nOption B, setting a sensitivity classification of Confidential for the Email column, is not the most appropriate choice for this scenario. While sensitivity classifications can be used to label data and apply policies, they do not directly handle the masking of data for display purposes.\n\nOptions C and D, setting an email mask from Microsoft SQL Server Management Studio or granting SELECT permission to users for all columns except Email, are not correct because they both involve implementing security measures at the database level, but they do not specifically address the data masking requirement for displaying the email addresses in the desired format.","timestamp":"1722695040.0","poster":"Socket","comment_id":"971187"},{"timestamp":"1714061340.0","content":"according to this article you can do it in portal. so my take is A\nhttps://www.sqlshack.com/dynamic-data-masking-in-azure-synapse-analytics/","poster":"amazonalex","upvote_count":"2","comment_id":"880613"},{"content":"Selected Answer: A\nDynamic Masking","comment_id":"773259","timestamp":"1705047300.0","upvote_count":"2","poster":"louisaok"},{"poster":"Fer079","upvote_count":"2","content":"A and B can both work, however, I would select C since A doesn't describe the type of mask. It needs to be email mask on the email column.\nIf you apply dynamic data from Azure portal, and you donÂ´t specify the type of mask, it will detect the type of the column to apply the mask, so in this case, it applies the default mask for a column type as varchar therefore it is not applying an email mask type","comment_id":"773229","timestamp":"1705045200.0"},{"content":"Dynamic Data Masking in the Azure portal is support for SQL DB and Synapse Analytics, just not for Managed Instance.\n\nhttps://www.sqlshack.com/dynamic-data-masking-in-azure-synapse-analytics/","timestamp":"1704716340.0","poster":"OneplusOne","upvote_count":"1","comment_id":"769375"},{"upvote_count":"2","poster":"mmat","comment_id":"769281","content":"Selected Answer: A\nC is not supported for Azure Synapse.","timestamp":"1704709560.0"},{"content":"You set up a dynamic data masking policy in the Azure portal by selecting the Dynamic Data Masking blade under Security in your SQL Database configuration pane. This feature cannot be set using portal for SQL Managed Instance.","poster":"wyindualizer","upvote_count":"1","timestamp":"1699782540.0","comment_id":"716619"},{"comment_id":"634953","timestamp":"1689993120.0","poster":"New_Azure_User","content":"A - set a mask","upvote_count":"2"},{"content":"Selected Answer: A\nThe question is on masking the data.","upvote_count":"1","timestamp":"1688870100.0","comment_id":"628967","poster":"Itsalwaymethecap"},{"poster":"Itsalwaymethecap","timestamp":"1688818860.0","upvote_count":"1","comment_id":"628768","content":"Correct answer is A. The question is on masking not classifying."},{"timestamp":"1687941720.0","comment_id":"623849","content":"This question is play on words as they want to know HOW you will PREVENT NONADMINISTRATIVE USERS from SEEING the ENAIL COLOMB and not how to hide the email colomb data itself.","poster":"GigaCaster","upvote_count":"2"},{"timestamp":"1684566660.0","content":"Selected Answer: C\nMore specific than A","poster":"JVDA_","comment_id":"604269","upvote_count":"3"},{"comment_id":"556038","upvote_count":"1","timestamp":"1677336420.0","content":"Selected Answer: A\nverified in AZ","poster":"peterp999"},{"upvote_count":"1","comment_id":"553995","timestamp":"1677097860.0","content":"Selected Answer: A\nMask not classify","poster":"AlCubeHead"},{"poster":"calvintcy","content":"A is the right answer.","comment_id":"550584","timestamp":"1676768640.0","upvote_count":"1"},{"content":"Selected Answer: A\ncorrect answer is A: you need to mask the email.","timestamp":"1674017580.0","poster":"VinayakBudapanahalli","comment_id":"526306","upvote_count":"1"},{"timestamp":"1663167840.0","poster":"Dawn7","comment_id":"444638","content":"Which is the correct one?","upvote_count":"1"},{"content":"https://docs.microsoft.com/En-us/azure/azure-sql/database/dynamic-data-masking-overview\nThe answer should be correct","timestamp":"1663136220.0","poster":"Masako","upvote_count":"2","comment_id":"444370"},{"upvote_count":"1","comment_id":"444018","poster":"Dawn7","content":"Which is the correct answer?","timestamp":"1663075680.0"},{"poster":"RussleC","content":"Correct answer is C ???\nhttps://www.examtopics.com/discussions/microsoft/view/36123-exam-dp-200-topic-3-question-4-discussion/","upvote_count":"3","comment_id":"443671","timestamp":"1663029420.0","comments":[{"comment_id":"445267","content":"This reference shows A as correct.","comments":[{"poster":"Dawn7","timestamp":"1664556600.0","comment_id":"455040","upvote_count":"1","content":"But discussion seems to be C, yes."}],"upvote_count":"1","poster":"Dawn7","timestamp":"1663252500.0"}]},{"poster":"kamilsky","content":"Correct answer is A. Even the description says about masking.","comment_id":"429448","upvote_count":"3","timestamp":"1661192160.0"}],"answer":"A","answer_description":"","timestamp":"2021-08-22 20:16:00","question_images":[],"answer_images":[],"question_text":"You have a SQL pool in Azure Synapse that contains a table named dbo.Customers. The table contains a column name Email.\nYou need to prevent nonadministrative users from seeing the full email addresses in the Email column. The users must see values in a format of aXXX@XXXX.com instead.\nWhat should you do?","question_id":16,"url":"https://www.examtopics.com/discussions/microsoft/view/60273-exam-dp-300-topic-1-question-23-discussion/","choices":{"A":"From the Azure portal, set a mask on the Email column.","D":"From Microsoft SQL Server Management Studio, grant the SELECT permission to the users for all the columns in the dbo.Customers table except Email.","C":"From Microsoft SQL Server Management Studio, set an email mask on the Email column.","B":"From the Azure portal, set a sensitivity classification of Confidential for the Email column."},"answer_ET":"A","isMC":true,"answers_community":["A (89%)","11%"]},{"id":"h5ioHHNQ1dfYtlsQk6B0","isMC":true,"topic":"1","unix_timestamp":1637270340,"question_text":"You have an Azure Databricks workspace named workspace1 in the Standard pricing tier. Workspace1 contains an all-purpose cluster named cluster1.\nYou need to reduce the time it takes for cluster1 to start and scale up. The solution must minimize costs.\nWhat should you do first?","question_images":[],"answer":"C","exam_id":68,"choices":{"B":"Configure a global init script for workspace1.","C":"Create a pool in workspace1.","D":"Create a cluster policy in workspace1.","A":"Upgrade workspace1 to the Premium pricing tier."},"answers_community":[],"answer_ET":"C","discussion":[{"poster":"Ciupaz","content":"Exam DP-203: Data Engineering on Microsoft Azure","timestamp":"1728830040.0","comment_id":"693985","upvote_count":"7"},{"content":"looks correct","comments":[{"comment_id":"483753","content":"its correct.","upvote_count":"1","poster":"o2091","timestamp":"1700612760.0"}],"upvote_count":"4","timestamp":"1700342340.0","poster":"o2091","comment_id":"481050"}],"url":"https://www.examtopics.com/discussions/microsoft/view/66307-exam-dp-300-topic-1-question-24-discussion/","answer_images":[],"question_id":17,"answer_description":"You can use Databricks Pools to Speed up your Data Pipelines and Scale Clusters Quickly.\nDatabricks Pools, a managed cache of virtual machine instances that enables clusters to start and scale 4 times faster.\nReference:\nhttps://databricks.com/blog/2019/11/11/databricks-pools-speed-up-data-pipelines.html","timestamp":"2021-11-18 22:19:00"},{"id":"itwDoaa4ASooLY7j1Q4z","question_id":18,"exam_id":68,"timestamp":"2021-11-18 01:08:00","question_images":[],"answers_community":["A (75%)","B (25%)"],"answer_description":"","answer_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/66264-exam-dp-300-topic-1-question-25-discussion/","answer":"A","choices":{"A":"Yes","B":"No"},"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou have an Azure Synapse Analytics dedicated SQL pool that contains a table named Table1.\nYou have files that are ingested and loaded into an Azure Data Lake Storage Gen2 container named container1.\nYou plan to insert data from the files into Table1 and transform the data. Each row of data in the files will produce one row in the serving layer of Table1.\nYou need to ensure that when the source data files are loaded to container1, the DateTime is stored as an additional column in Table1.\nSolution: In an Azure Synapse Analytics pipeline, you use a Get Metadata activity that retrieves the DateTime of the files.\nDoes this meet the goal?","unix_timestamp":1637194080,"isMC":true,"answer_ET":"A","topic":"1","discussion":[{"upvote_count":"12","poster":"tesen_tolga","timestamp":"1644308400.0","content":"This is a DP-203 question.","comment_id":"542925","comments":[{"timestamp":"1719786060.0","content":"Its DP 203. Though answer will be NO. I got this question and passed with very very high score.","upvote_count":"1","comment_id":"1239885","poster":"Sr18"}]},{"comment_id":"554815","upvote_count":"6","timestamp":"1645644480.0","content":"Selected Answer: A\nYes, Get Metadata can be used to retrieve the DateTime of the files and allow you to use this data. The question is to add it to Table1, not to an external table.","poster":"CaptainJameson"},{"upvote_count":"1","comment_id":"1410825","poster":"AntonioTest","timestamp":"1743068460.0","content":"Selected Answer: B\nAgree with B, seems incomplete"},{"content":"No - , retrieving the DateTime alone doesn't meet the goal unless the DateTime is also incorporated into the process that inserts the data into the table","comment_id":"1288641","timestamp":"1727186820.0","poster":"bingomutant","upvote_count":"1"},{"upvote_count":"1","timestamp":"1717540080.0","comment_id":"1224403","poster":"scottytohotty","content":"Selected Answer: B\nAgree with B, seems incomplete"},{"poster":"U_C","content":"Using a Get Metadata activity in an Azure Synapse Analytics pipeline to retrieve the DateTime of the files will not directly ensure that the DateTime is stored as an additional column in Table1. The Get Metadata activity only retrieves metadata information about the files, such as their names, size, and date created or modified.\n\nTo achieve the goal of storing the DateTime as an additional column in Table1, you would need to use other pipeline activities, such as a Data Flow or a Copy activity, to extract data from the files, transform it as necessary, and load it into Table1. During this process, you could use derived columns or mappings to add the DateTime column and populate it with the appropriate values.\n\nTherefore, B is the correct answer.","timestamp":"1681089480.0","upvote_count":"1","comment_id":"865924"},{"upvote_count":"1","comment_id":"693988","timestamp":"1665671760.0","poster":"Ciupaz","content":"Exam DP-203: Data Engineering on Microsoft Azure"},{"content":"Get Metadata activity retrieves the DateTime of the files but it does not create a column in Table1, so answer is B","comment_id":"620986","poster":"Backy","upvote_count":"4","timestamp":"1655988480.0"},{"upvote_count":"1","poster":"RehanRajput","timestamp":"1653836280.0","content":"Not sure if the answer is Yes. However, the explanation makes absolutely no sense. \n\nWe want to load data into our SQL Pools, why would we load the data in our SQL serverless pools? :-/ \n\nUsing metadata activity might be PART of a solution but in itself does not give a complete indication of what the solution should be.","comment_id":"608813"},{"poster":"o2091","upvote_count":"3","timestamp":"1637194080.0","content":"Answer looks correct","comment_id":"480336"}]},{"id":"3mz4XSfc3vGmlYkwOrqR","question_id":19,"timestamp":"2021-11-18 01:08:00","topic":"1","answer_description":"","exam_id":68,"isMC":true,"discussion":[{"timestamp":"1700266080.0","upvote_count":"5","poster":"o2091","content":"Answer looks correct","comment_id":"480337"},{"timestamp":"1728830280.0","content":"Exam DP-203: Data Engineering on Microsoft Azure","upvote_count":"3","poster":"Ciupaz","comment_id":"693995"},{"poster":"charliebasssssss","comment_id":"666630","upvote_count":"1","content":"Answer is A\n\n\"An external table points to data located in Hadoop, Azure Storage blob, or Azure Data Lake Storage. External tables are used to read data from files or write data to files in Azure Storage. With Synapse SQL, you can use external tables to read external data using dedicated SQL pool or serverless SQL pool.\"\nhttps://docs.microsoft.com/en-us/azure/synapse-analytics/sql/develop-tables-external-tables?tabs=hadoop","timestamp":"1726120920.0"},{"poster":"Backy","content":"Answer B\n\n\n\"The column definitions, including the data types and number of columns, must match the data in the external files. If there's a mismatch, the file rows will be rejected when querying the actual data\"\n\nhttps://docs.microsoft.com/en-us/sql/t-sql/statements/create-external-table-transact-sql?view=azure-sqldw-latest&preserve-view=true&tabs=dedicated","comment_id":"620993","timestamp":"1719147660.0","upvote_count":"1"},{"content":"this is not for DP-300 exam","timestamp":"1714695360.0","poster":"freemun05","upvote_count":"2","comment_id":"596260"},{"timestamp":"1708716480.0","poster":"CaptainJameson","content":"Selected Answer: B\nNo, Get Metadata can be used to retrieve the DateTime of the files and allow you to use this data. The question is to add it to Table1, not to an external table.","comment_id":"554816","upvote_count":"3"},{"content":"This is a DP-203 question.","timestamp":"1707380400.0","poster":"tesen_tolga","comment_id":"542926","upvote_count":"3"}],"answers_community":["B (100%)"],"answer_images":[],"choices":{"B":"No","A":"Yes"},"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou have an Azure Synapse Analytics dedicated SQL pool that contains a table named Table1.\nYou have files that are ingested and loaded into an Azure Data Lake Storage Gen2 container named container1.\nYou plan to insert data from the files into Table1 and transform the data. Each row of data in the files will produce one row in the serving layer of Table1.\nYou need to ensure that when the source data files are loaded to container1, the DateTime is stored as an additional column in Table1.\nSolution: You use an Azure Synapse Analytics serverless SQL pool to create an external table that has an additional DateTime column.\nDoes this meet the goal?","question_images":[],"unix_timestamp":1637194080,"answer":"B","answer_ET":"B","url":"https://www.examtopics.com/discussions/microsoft/view/66265-exam-dp-300-topic-1-question-26-discussion/"},{"id":"2sZSbXhKrsJEUPZFxmUw","answers_community":[],"answer_images":[],"answer_description":"Instead, in an Azure Synapse Analytics pipeline, you use a Get Metadata activity that retrieves the DateTime of the files.\nNote: You can use the Get Metadata activity to retrieve the metadata of any data in Azure Data Factory or a Synapse pipeline. You can use the output from the\nGet Metadata activity in conditional expressions to perform validation, or consume the metadata in subsequent activities.\nReference:\nhttps://docs.microsoft.com/en-us/azure/data-factory/control-flow-get-metadata-activity","discussion":[{"content":"Azure Synapse Analytics is NOT part of DP-300","timestamp":"1696492920.0","comments":[{"timestamp":"1711903140.0","poster":"cusman","comment_id":"579060","upvote_count":"3","content":"Exactly. Too many questions here are for DP-203"}],"poster":"SamBalbij","comment_id":"457581","upvote_count":"13"},{"poster":"Ciupaz","comment_id":"693997","upvote_count":"2","content":"Exam DP-203: Data Engineering on Microsoft Azure","timestamp":"1728830340.0"},{"content":"Answer B\n\nCannot be done in serverless or dedicated, for the same reason\n\n\n\"The column definitions, including the data types and number of columns, must match the data in the external files. If there's a mismatch, the file rows will be rejected when querying the actual data\"\n\nhttps://docs.microsoft.com/en-us/sql/t-sql/statements/create-external-table-transact-sql?view=azure-sqldw-latest&preserve-view=true&tabs=dedicated","poster":"Backy","timestamp":"1719148140.0","upvote_count":"1","comment_id":"620999"},{"poster":"o2091","comment_id":"483777","timestamp":"1700616300.0","upvote_count":"3","content":"The answer looks right"}],"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou have an Azure Synapse Analytics dedicated SQL pool that contains a table named Table1.\nYou have files that are ingested and loaded into an Azure Data Lake Storage Gen2 container named container1.\nYou plan to insert data from the files into Table1 and transform the data. Each row of data in the files will produce one row in the serving layer of Table1.\nYou need to ensure that when the source data files are loaded to container1, the DateTime is stored as an additional column in Table1.\nSolution: You use a dedicated SQL pool to create an external table that has an additional DateTime column.\nDoes this meet the goal?","timestamp":"2021-10-05 10:02:00","question_id":20,"exam_id":68,"choices":{"A":"Yes","B":"No"},"unix_timestamp":1633420920,"question_images":[],"topic":"1","isMC":true,"answer_ET":"B","url":"https://www.examtopics.com/discussions/microsoft/view/63619-exam-dp-300-topic-1-question-27-discussion/","answer":"B"}],"exam":{"name":"DP-300","isImplemented":true,"provider":"Microsoft","numberOfQuestions":360,"lastUpdated":"12 Apr 2025","id":68,"isMCOnly":false,"isBeta":false},"currentPage":4},"__N_SSP":true}