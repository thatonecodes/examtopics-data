{"pageProps":{"questions":[{"id":"f5a7frvmn2TRCGBPQlGE","url":"https://www.examtopics.com/discussions/microsoft/view/95362-exam-dp-203-topic-2-question-92-discussion/","question_text":"You are creating an Apache Spark job in Azure Databricks that will ingest JSON-formatted data.\n\nYou need to convert a nested JSON string into a DataFrame that will contain multiple rows.\n\nWhich Spark SQL function should you use?","answer_ET":"A","question_images":[],"answer_description":"","answer":"A","choices":{"C":"coalesce","B":"filter","D":"extract","A":"explode"},"answer_images":[],"timestamp":"2023-01-15 04:04:00","question_id":251,"unix_timestamp":1673751840,"answers_community":["A (100%)"],"topic":"2","isMC":true,"exam_id":67,"discussion":[{"poster":"Rajcse03","timestamp":"1689452340.0","content":"Selected Answer: A\nhttps://learn.microsoft.com/en-us/azure/databricks/kb/scala/flatten-nested-columns-dynamically","upvote_count":"6","comment_id":"777111","comments":[{"poster":"Gikan","comment_id":"1136778","timestamp":"1722425220.0","upvote_count":"1","content":"This example is for scala. SQL example like this: \nhttps://learn.microsoft.com/en-us/u-sql/statements-and-expressions/select/from/cross-apply/explode"}]},{"upvote_count":"2","poster":"warre","content":"Selected Answer: A\nThe explode function in Spark SQL is used to transform an array or a map column into multiple rows, essentially \"exploding\" the nested structure","comment_id":"1116696","timestamp":"1720443360.0"},{"upvote_count":"1","poster":"hassexat","timestamp":"1709640120.0","content":"Selected Answer: A\nA is correct answer!","comment_id":"999345"},{"upvote_count":"1","poster":"kkk5566","content":"Selected Answer: A\nA is correct","comment_id":"993792","timestamp":"1709198160.0"},{"upvote_count":"3","content":"Selected Answer: A\ncorrect","poster":"[Removed]","comment_id":"776131","timestamp":"1689383040.0"}]},{"id":"nqYG1gqBUeoQnsxvpVM1","answer_ET":"","url":"https://www.examtopics.com/discussions/microsoft/view/95363-exam-dp-203-topic-2-question-93-discussion/","discussion":[{"content":"df_sales.filter(col(\"Region\") == \"HQ\")\n .groupBy(col('SalesPerson'))\n .agg(sum('Amount').alias('TotalAmount'))\n .orderBy(desc('TotalAmount'))\n .limit(3)","timestamp":"1694328180.0","comment_id":"834775","upvote_count":"17","poster":"esaade"},{"timestamp":"1709198400.0","comment_id":"993794","poster":"kkk5566","upvote_count":"5","content":".groupBy(col('SalesPerson')) and .orderBy(desc('TotalAmount'))"},{"content":"The syntax for orderBy function should be orderBy(col('TotalAmount').desc())","comment_id":"1401665","timestamp":"1742585100.0","poster":"sachin_mt","upvote_count":"1"},{"content":"The answer is correct!","comment_id":"1145609","timestamp":"1723211100.0","upvote_count":"1","poster":"Alongi"},{"comment_id":"789347","upvote_count":"5","poster":"aurorafang","content":"for the sequence, group by usually put before the order by operations","timestamp":"1690429500.0"},{"content":"correct","comment_id":"776132","poster":"[Removed]","timestamp":"1689383340.0","upvote_count":"3"}],"question_images":["https://img.examtopics.com/dp-203/image266.png"],"answer_images":["https://img.examtopics.com/dp-203/image267.png"],"topic":"2","answers_community":[],"timestamp":"2023-01-15 04:09:00","question_text":"DRAG DROP\n-\n\nYou have an Azure subscription that contains an Azure Databricks workspace. The workspace contains a notebook named Notebook1.\n\nIn Notebook1, you create an Apache Spark DataFrame named df_sales that contains the following columns:\n\n• Customer\n• SalesPerson\n• Region\n• Amount\n\nYou need to identify the three top performing salespersons by amount for a region named HQ.\n\nHow should you complete the query? To answer, drag the appropriate values to the correct targets. Each value may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","unix_timestamp":1673752140,"answer_description":"","question_id":252,"exam_id":67,"answer":"","isMC":false},{"id":"FGL2BM0PzIacDzhLgZXI","question_id":253,"url":"https://www.examtopics.com/discussions/microsoft/view/104991-exam-dp-203-topic-2-question-94-discussion/","answers_community":["D (100%)"],"question_text":"You need to schedule an Azure Data Factory pipeline to execute when a new file arrives in an Azure Data Lake Storage Gen2 container.\n\nWhich type of trigger should you use?","answer_images":[],"discussion":[{"poster":"FRANCIS_A_M","timestamp":"1680536760.0","content":"Selected Answer: D\nCorrect, D","comment_id":"860089","upvote_count":"9"},{"comment_id":"1271878","content":"Selected Answer: D\nCorrect","upvote_count":"1","poster":"VaneA","timestamp":"1724535660.0"},{"content":"Correct. So easy that even Exam Topics got it right!","upvote_count":"1","timestamp":"1713075600.0","poster":"lcss27","comment_id":"1195311"},{"upvote_count":"1","content":"Selected Answer: D\nIt's ok","poster":"Alongi","comment_id":"1145611","timestamp":"1707493560.0"},{"poster":"kkk5566","content":"Selected Answer: D\ncorrect","comment_id":"993795","timestamp":"1693380060.0","upvote_count":"2"},{"content":"Correct, D","upvote_count":"2","poster":"haythemsi","timestamp":"1683643080.0","comment_id":"893179"},{"timestamp":"1680561540.0","content":"ans is correct","comment_id":"860405","upvote_count":"1","poster":"AHUI"}],"answer_ET":"D","timestamp":"2023-04-03 17:46:00","answer":"D","question_images":[],"topic":"2","answer_description":"","exam_id":67,"unix_timestamp":1680536760,"isMC":true,"choices":{"C":"schedule","A":"on-demand","D":"storage event","B":"tumbling window"}},{"id":"HNPvqCu9bWbRKLWcsER8","unix_timestamp":1680537060,"url":"https://www.examtopics.com/discussions/microsoft/view/104992-exam-dp-203-topic-2-question-95-discussion/","answer_description":"","isMC":false,"timestamp":"2023-04-03 17:51:00","question_id":254,"question_text":"DRAG DROP\n-\n\nYou have a project in Azure DevOps that contains a repository named Repo1. Repo1 contains a branch named main.\n\nYou create a new Azure Synapse workspace named Workspace1.\n\nYou need to create data processing pipelines in Workspace1. The solution must meet the following requirements:\n\n• Pipeline artifacts must be stored in Repo1\n• Source control must be provided for pipeline artifacts.\n• All development must be performed in a feature branch.\n\nWhich four actions should you perform in sequence in Synapse Studio? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\n\n//IMG//","answers_community":[],"topic":"2","answer":"","answer_images":["https://img.examtopics.com/dp-203/image277.png"],"exam_id":67,"discussion":[{"upvote_count":"31","comments":[{"comment_id":"1165461","content":"In the context of Azure Synapse Studio, it's recommended not to use the 'main' branch as a collaboration branch. Here's why:\n\n- Deployment Branch: The 'main' branch serves as the source of truth for your production-ready pipelines. Changes made directly in 'main' could potentially introduce instability or untested features into the production environment.\n-Code Stability: Isolating development work in separate collaboration branches protects your 'main' branch from unintended changes or broken code during development.\n-Review Process: Collaboration branches allow for code reviews, testing, and approval processes before merging changes into the 'main' branch, ensuring higher code quality.","timestamp":"1709542740.0","poster":"Fusejonny1","upvote_count":"2"},{"upvote_count":"1","content":"Isn't the main branch by default the collaboration branch?","timestamp":"1694463960.0","comments":[{"upvote_count":"1","poster":"[Removed]","content":"Your Azure Repos collaboration branch that is used for publishing. By default, it's main. \nhttps://learn.microsoft.com/en-us/azure/data-factory/source-control","timestamp":"1709882400.0","comment_id":"1168615"}],"poster":"j4g092t","comment_id":"1005151"},{"upvote_count":"3","poster":"macinpune9","comment_id":"1091937","content":"This is wrong, given answer by exam topics is right","timestamp":"1702142520.0"}],"content":"Configure a code repo and select Repo1\nSet the main branch as the collaboration branch\nCreate a new brach\nCreate pipeline artifacts and save them in the new branch","comment_id":"902756","timestamp":"1684615140.0","poster":"SinSS"},{"timestamp":"1684232880.0","comment_id":"899065","content":"Shouldn't you merge the new branch into the main branch?","poster":"mhi","comments":[{"content":"totally agree with this, I was looking for that option in the possible Actions and couldn't find any.","comment_id":"1310539","timestamp":"1731409020.0","poster":"Pian12345","upvote_count":"1"},{"upvote_count":"5","timestamp":"1686691140.0","content":"Agree, you create a feature branch from the collaboration branch, work on it, and after you finished you merge back to the collaboration branch (by default is main). Source: https://learn.microsoft.com/en-us/azure/synapse-analytics/cicd/source-control#version-control","comment_id":"922551","poster":"peches"}],"upvote_count":"16"},{"comment_id":"1248223","upvote_count":"1","timestamp":"1721036280.0","poster":"evangelist","content":"Configure a code repository and select Repo1.\nSet the main branch as the collaboration branch.\nCreate a new branch.\nCreate pipeline artifacts and save them in the new branch."},{"comments":[{"poster":"Sleuth","content":"Ignore you might have to configure repo in local before doing any operation","upvote_count":"1","comment_id":"1227712","timestamp":"1718003700.0"}],"timestamp":"1717773180.0","poster":"Sleuth","content":"Read question first line again don't know why you all missed it, the top line says code repository Repo1 exists and has main branch therefore:\n\n\n1. Set the main branch as collaboration branch.\n2. Create a new branch.\n3. Create a pull request to merge the contents of main branch to new branch. (You do this step to make new branch up-to-date to main branch)\n4. Create pipeline artifacts in the new branch","comment_id":"1226224","upvote_count":"2"},{"timestamp":"1710689460.0","comment_id":"1175918","content":"I think we could exclude two options, one is wrong and the other doesn´t make sense:\n- You do not create a PR to merge the contents of the \"main\" branch to \"feature\" branch, it´s from the \"feature\" into the \"main\" branch.\n- We don´t create the artifacts for the first time directly on the main branch and then fork to a new branch, you create directly on the new feature branch.\n\nThis leaves four available options:\n- Configure a code repository and select Repo1\n- Set the main branch as the collaboration branch (remember that repo was already created inside DevOps, a generic git project)\n- Create a new branch\n- Create pipelines artifacts and save in the new branch","upvote_count":"5","poster":"Mausar"},{"comment_id":"1118484","content":"From DOWN \nYOU CAN PUT THEM IN SEQUENCE DONT NEED TO REMEMBER THE STEPS","comments":[{"timestamp":"1709385120.0","content":"In the real exam the order may be randomised, speaking from personal experience with other fundamental exams. Memorise the answers instead","poster":"Delphin_8150","upvote_count":"1","comment_id":"1164121"}],"poster":"dakku987","upvote_count":"4","timestamp":"1704884820.0"},{"comment_id":"993802","upvote_count":"1","timestamp":"1693381380.0","content":"correct","poster":"kkk5566","comments":[{"comments":[{"timestamp":"1694227740.0","poster":"kkk5566","content":"forgot it ,the given answer is right.","comment_id":"1002853","upvote_count":"5"}],"timestamp":"1693381560.0","content":"Configure a code repo and select Repo1\nSet the main branch as the collaboration branch\nCreate a new brach\n and PR","comment_id":"993804","poster":"kkk5566","upvote_count":"2"}]},{"poster":"AlviraTony","upvote_count":"3","comment_id":"991483","timestamp":"1693144140.0","content":"Given solution is correct"},{"comment_id":"976602","content":"\"Configure a code repository and select Repo2\" is not required as you already have a repo Repo1 with main as branch.","upvote_count":"1","timestamp":"1691581800.0","poster":"Matt2000"},{"upvote_count":"6","content":"Correct","poster":"FRANCIS_A_M","comment_id":"860094","timestamp":"1680537060.0"}],"answer_ET":"","question_images":["https://img.examtopics.com/dp-203/image276.png"]},{"id":"6tIGQkLe4rnD6yhgQlxY","question_id":255,"topic":"2","answer":"BC","question_text":"You have an Azure subscription that contains an Azure SQL database named DB1 and a storage account named storage1. The storage1 account contains a file named File1.txt. File1.txt contains the names of selected tables in DB1.\n\nYou need to use an Azure Synapse pipeline to copy data from the selected tables in DB1 to the files in storage1. The solution must meet the following requirements:\n\n• The Copy activity in the pipeline must be parameterized to use the data in File1.txt to identify the source and destination of the copy.\n• Copy activities must occur in parallel as often as possible.\n\nWhich two pipeline activities should you include in the pipeline? Each correct answer presents part of the solution.\n\nNOTE: Each correct selection is worth one point.","discussion":[{"timestamp":"1696348560.0","poster":"FRANCIS_A_M","upvote_count":"13","comments":[{"poster":"ExamDestroyer69","comment_id":"1101052","upvote_count":"1","content":"This is correct, Get Metadata doesn't directly retrieve the content of the file itself. If you want to obtain the content of a .txt file like File1.txt, specifically the table names contained within it, you'd typically use Lookup.\nCorrect Anwser: BC","timestamp":"1718829960.0"}],"comment_id":"860102","content":"Selected Answer: BC\nIt's BC. Use the LookUp Activity to read the .txt file. ForEach to Loop though making sure Sequential is off (which off by default) for parallelization"},{"timestamp":"1697448300.0","content":"Selected Answer: BC\nLookup activity reads and returns the content of a configuration file or table. It also returns the result of executing a query or stored procedure. The output can be a singleton value or an array of attributes, which can be consumed in a subsequent copy, transformation, or control flow activities like ForEach activity.\n\nhttps://learn.microsoft.com/en-us/azure/data-factory/control-flow-lookup-activity","poster":"aemilka","comment_id":"871626","upvote_count":"6"},{"content":"Selected Answer: BC\ncorrect","poster":"kkk5566","timestamp":"1709200620.0","upvote_count":"2","comment_id":"993812"},{"poster":"examtopicsofyannick","content":"Selected Answer: BC\nBC - Lookup and ForEach.\nLookup - reads .txt file\nForEach - iteration through contents read in Lookup activity for COPY activity","timestamp":"1707484020.0","upvote_count":"2","comment_id":"976537"},{"comment_id":"931533","upvote_count":"2","content":"Selected Answer: BC\nCorrect answers.","timestamp":"1703338920.0","poster":"auwia"},{"upvote_count":"2","poster":"vctrhugo","content":"Selected Answer: BC\nB. Lookup: The Lookup activity can be used to read the contents of File1.txt from the storage account. It will retrieve the names of selected tables in DB1 as parameter values for the Copy activity.\n\nC. ForEach: The ForEach activity can be used to iterate over the retrieved table names from File1.txt. Inside the loop, you can configure the Copy activity with the source and destination information based on the current table name.","timestamp":"1702780260.0","comment_id":"925672"},{"content":"Selected Answer: BC\nAnswer is B and C.","poster":"shakes103","timestamp":"1696847340.0","comment_id":"865419","upvote_count":"4"},{"upvote_count":"4","comment_id":"862330","content":"' Get Metadata' cannot read the content of the file. Its Lookup and ForEach.\nRefer to link : https://learn.microsoft.com/en-us/azure/data-factory/control-flow-get-metadata-activity and https://learn.microsoft.com/en-us/azure/data-factory/control-flow-lookup-activity","poster":"Sibaprasad","timestamp":"1696525800.0"}],"url":"https://www.examtopics.com/discussions/microsoft/view/104993-exam-dp-203-topic-2-question-96-discussion/","exam_id":67,"answer_ET":"BC","answer_description":"","unix_timestamp":1680537360,"answers_community":["BC (100%)"],"timestamp":"2023-04-03 17:56:00","choices":{"B":"Lookup","A":"Get Metadata","C":"ForEach","D":"If Condition"},"isMC":true,"answer_images":[],"question_images":[]}],"exam":{"provider":"Microsoft","isBeta":false,"id":67,"lastUpdated":"12 Apr 2025","isMCOnly":false,"numberOfQuestions":384,"name":"DP-203","isImplemented":true},"currentPage":51},"__N_SSP":true}