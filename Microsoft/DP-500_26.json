{"pageProps":{"questions":[{"id":"uGpen7yOTY86NGCy1Gbb","isMC":true,"discussion":[{"comment_id":"989485","upvote_count":"1","timestamp":"1692910020.0","content":"Selected Answer: B\nan Apache Spark pool","poster":"gerryboy"},{"content":"Selected Answer: B\nMachine learning models can be trained with help from various algorithms and libraries. Spark MLlib offers scalable machine learning algorithms that can help solving most classical machine learning problems","timestamp":"1692578040.0","upvote_count":"1","poster":"orionduo","comment_id":"986136"},{"poster":"DarioReymago","content":"Selected Answer: B\nb is correct","timestamp":"1679968740.0","upvote_count":"1","comment_id":"852658"},{"upvote_count":"2","content":"Correct","comments":[{"poster":"ivanb94","timestamp":"1672997700.0","upvote_count":"2","content":"I would agree based on this https://learn.microsoft.com/en-us/azure/synapse-analytics/machine-learning/what-is-machine-learning","comment_id":"767464"}],"timestamp":"1671978180.0","comment_id":"755706","poster":"Chk88"}],"topic":"1","url":"https://www.examtopics.com/discussions/microsoft/view/92771-exam-dp-500-topic-1-question-47-discussion/","question_images":[],"answer":"B","timestamp":"2022-12-25 15:23:00","answer_description":"","answer_images":[],"answer_ET":"B","question_id":126,"question_text":"You have a group of data scientists who must create machine learning models and run periodic experiments on a large dataset.\nYou need to recommend an Azure Synapse Analytics pool for the data scientists. The solution must minimize costs.\nWhich type of pool should you recommend?","unix_timestamp":1671978180,"choices":{"D":"a serverless SQL pool","A":"a Data Explorer pool","B":"an Apache Spark pool","C":"a dedicated SQL pool"},"answers_community":["B (100%)"],"exam_id":70},{"id":"17eGK3ZRXtT33u0cbFdg","answer_description":"","timestamp":"2022-12-13 16:04:00","discussion":[{"comment_id":"788520","upvote_count":"19","timestamp":"1674721080.0","content":"1. No: the endpoint for HNS is dfs not blob. https://learn.microsoft.com/en-us/azure/storage/blobs/upgrade-to-data-lake-storage-gen2-how-to?tabs=azure-portal#migrate-data-workloads-and-applications\n2. No\n3. Yes","poster":"eekman"},{"content":"I think the answers are correct.\nCheck this: https://learn.microsoft.com/en-us/powerquery-m/azurestorage-datalake","poster":"nbagchi","comment_id":"744171","timestamp":"1670943840.0","comments":[{"timestamp":"1671978180.0","poster":"Chk88","upvote_count":"3","comment_id":"755708","content":"it is correct"}],"upvote_count":"10"},{"timestamp":"1702807140.0","poster":"salvalcaraz","upvote_count":"1","comment_id":"1098777","content":"1. Yes: I use ADLS Gen 2 blobs at work at it doest allow hierarchical namespaces.\n2. No\n3. Yes"},{"timestamp":"1693202640.0","comment_id":"991838","poster":"fireofsea","content":"I think answer is\nNo\nYes\nNo","upvote_count":"1","comments":[{"comments":[{"comment_id":"991840","comments":[{"upvote_count":"1","comment_id":"991845","poster":"fireofsea","comments":[{"content":"Sorry, Update\nNo\nNo\nYes","timestamp":"1693203840.0","comment_id":"991852","poster":"fireofsea","upvote_count":"1"}],"timestamp":"1693203300.0","content":"if there is no funtion name in the script?"}],"content":"Update\nNo\nYes\nYes","poster":"fireofsea","upvote_count":"1","timestamp":"1693202820.0"}],"upvote_count":"1","timestamp":"1693202760.0","poster":"fireofsea","content":"For in Editor uses \"Table.AddColumn\" and \"TransformFiles\" to load file data","comment_id":"991839"}]},{"timestamp":"1692421920.0","upvote_count":"3","poster":"SamuComqi","content":"I took the exam a few days ago (14/8/2023) and I passed the exam with a score of 915.\nMy answer was:\n- No\n- No\n- Yes","comment_id":"984970"},{"content":"I think the first one is \"No\" because HierarchicalNavigation is not an option for \"AzureStorage.Blobs\", see here: https://learn.microsoft.com/en-us/powerquery-m/azurestorage-datalake\nHierarchicalNavigation is an option for AzureStorage.Datalake: https://learn.microsoft.com/en-us/powerquery-m/azurestorage-datalake","poster":"AlanMont","comment_id":"918579","timestamp":"1686249660.0","upvote_count":"6"}],"unix_timestamp":1670943840,"answer":"","isMC":false,"answers_community":[],"answer_ET":"","topic":"1","question_text":"HOTSPOT -\nYou have an Azure Data Lake Storage Gen 2 container that stores more than 300,000 files representing hourly telemetry data. The data is organized in folders by the year, month, and day according to when the telemetry was captured.\nYou have the following query in Power Query Editor.\n//IMG//\n\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\n//IMG//","question_id":127,"question_images":["https://img.examtopics.com/dp-500/image54.png","https://img.examtopics.com/dp-500/image55.png"],"answer_images":["https://img.examtopics.com/dp-500/image56.png"],"url":"https://www.examtopics.com/discussions/microsoft/view/91444-exam-dp-500-topic-1-question-48-discussion/","exam_id":70},{"id":"X3KR15YPPAf96q12OT9q","url":"https://www.examtopics.com/discussions/microsoft/view/91445-exam-dp-500-topic-1-question-49-discussion/","answer_description":"","timestamp":"2022-12-13 16:05:00","question_images":["https://img.examtopics.com/dp-500/image57.png","https://img.examtopics.com/dp-500/image58.png"],"question_text":"HOTSPOT -\nYou manage a dataset that contains the two data sources as shown in the following table.\n//IMG//\n\nWhen you attempt to refresh the dataset in powerbi.com, you receive the following error message: “[Unable to combine data] Add Columns is accessing data sources that have privacy levels which cannot be used together. Please rebuild this data combination.”\nYou discover that the dataset contains queries that fold data from the SharePoint folder to the Azure SQL database.\nYou need to resolve the error. The solution must provide the highest privacy possible.\nWhich privacy level should you select for each data source? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\n//IMG//","exam_id":70,"answer_ET":"","isMC":false,"answer_images":["https://img.examtopics.com/dp-500/image59.png"],"discussion":[{"upvote_count":"12","comment_id":"760700","poster":"Maazi","timestamp":"1672296900.0","comments":[{"comment_id":"760703","content":"*Organisational = Organizational","timestamp":"1672296960.0","poster":"Maazi","upvote_count":"2"}],"content":"The answers ie Private and Organisational are correct. \nRef: https://learn.microsoft.com/en-us/power-bi/enterprise/desktop-privacy-levels"},{"comment_id":"915263","upvote_count":"1","content":"Agreed - Private and Organizational.","poster":"Eltooth","timestamp":"1685956560.0"},{"timestamp":"1675065480.0","upvote_count":"1","comment_id":"792534","poster":"stfglv","content":"Sensitive data --> must be private. The other dataset could theoretically be public but why would it be when a higher privacy level is organizational and it seems appropriate for organizational data. The name says it all."},{"upvote_count":"2","timestamp":"1671978300.0","content":"Answer correct, data type","comment_id":"755710","poster":"Chk88"},{"upvote_count":"4","content":"I would have selected the same","poster":"nbagchi","timestamp":"1670943900.0","comment_id":"744173"}],"topic":"1","question_id":128,"answers_community":[],"unix_timestamp":1670943900,"answer":""},{"id":"LpEX6OnLFapeY0YD4U4Q","answers_community":["D (100%)"],"answer_images":[],"choices":{"B":"an XMLA endpoint","D":"the on-premises data gateway","A":"Azure Purview","C":"Site-to-Site VPN"},"exam_id":70,"answer_ET":"D","timestamp":"2022-12-12 20:14:00","question_id":129,"question_text":"This is a case study. Case studies are not timed separately. You can use as much exam time as you would like to complete each case. However, there may be additional case studies and sections on this exam. You must manage your time to ensure that you are able to complete all questions included on this exam in the time provided.\nTo answer the questions included in a case study, you will need to reference information that is provided in the case study. Case studies might contain exhibits and other resources that provide more information about the scenario that is described in the case study. Each question is independent of the other questions in this case study.\nAt the end of this case study, a review screen will appear. This screen allows you to review your answers and to make changes before you move to the next section of the exam. After you begin a new section, you cannot return to this section.\n\nTo start the case study -\nTo display the first question in this case study, click the Next button. Use the buttons in the left pane to explore the content of the case study before you answer the questions. Clicking these buttons displays information such as business requirements, existing environment, and problem statements. If the case study has an All Information tab, note that the information displayed is identical to the information displayed on the subsequent tabs. When you are ready to answer a question, click the Question button to return to the question.\n\nOverview -\nContoso, Ltd. is a company that sells enriched financial data to a variety of external customers.\nContoso has a main office in Los Angeles and two branch offices in New York and Seattle.\n\nExisting Environment -\n\nData Infrastructure -\nContoso has a 50-TB data warehouse that uses an instance of SQL Server on Azure Virtual Machines.\nThe data warehouse populates an Azure Synapse Analytics workspace that is accessed by the external customers. Currently, the customers can access all the data.\nContoso has one Power BI workspace named FinData that contains a single dataset. The dataset contains financial data from around the world. The workspace is used by 10 internal users and one external customer. The dataset has the following two data sources: the data warehouse and the Synapse Analytics serverless SQL pool.\nUsers frequently query the Synapse Analytics workspace by using Transact-SQL.\n\nUser Problems -\nContoso identifies the following user issues:\nSome users indicate that the visuals in Power BI reports are slow to render when making filter selections.\nUsers indicate that queries against the serverless SQL pool fail occasionally because the size of tempdb has been exceeded.\nUsers indicate that the data in Power BI reports is stale. You discover that the refresh process of the Power BI model occasionally times out.\n\nPlanned Changes -\nContoso plans to implement the following changes:\nInto the existing Power BI dataset, integrate an external data source in JSON that is accessible by using the REST API.\nBuild a new dataset in the FinData workspace by using data from the Synapse Analytics dedicated SQL pool.\nProvide all the customers with their own Power BI workspace to create their own reports. Each workspace will use the new dataset in the FinData workspace.\nImplement subscription levels for the customers. Each subscription level will provide access to specific rows of financial data.\nDeploy prebuilt datasets to Power BI to simplify the query experience of the customers.\nProvide internal users with the ability to incorporate machine learning models loaded to the dedicated SQL pool.\nYou need to recommend a solution to add new fields to the financial data Power BI dataset with data from the Microsoft SQL Server data warehouse.\nWhat should you include in the recommendation?","isMC":true,"discussion":[{"comment_id":"763596","timestamp":"1672648680.0","upvote_count":"9","poster":"cherious","content":"Selected Answer: D\nSince the data is located in Microsoft SQL Server DWH, we need on-premises data gateway."},{"content":"D is correct.\nIt seems that you need the gateway, as stated in this article:\nhttps://community.powerbi.com/t5/Power-Query/SQL-Server-hosted-on-Azure-VM-Do-I-need-a-Gateway/td-p/489761","comment_id":"746924","upvote_count":"9","poster":"Az301301X","timestamp":"1671176640.0"},{"comment_id":"964037","content":"Selected Answer: D\nOn-prem gateway. A SQL Server database on Azure Virtual Machine is considered on-premises and needs a gateway, check it out here : https://radacad.com/the-power-bi-gateway-all-you-need-to-know","timestamp":"1690392600.0","upvote_count":"1","poster":"hoss29"},{"comment_id":"923785","upvote_count":"1","poster":"Eltooth","timestamp":"1686810960.0","content":"Selected Answer: D\nD is correct answer."},{"comment_id":"892094","timestamp":"1683546180.0","upvote_count":"2","content":"The source talks about a gateway, not an on-prem gateway. Azure VMs run in the cloud, what you would need is a gateway but not an on-prem gateway.\n\nYou use an On-prem gateway to transfer data between servers that are not in the cloud and servers that are. In this case, both are in the cloud.\n\nhttps://learn.microsoft.com/en-us/power-bi/connect-data/service-gateway-onprem?WT.mc_id=DP-MVP-5003635","poster":"LuukvdD"},{"poster":"DarioReymago","comment_id":"870414","timestamp":"1681498740.0","upvote_count":"1","content":"D assuming that DWH or sql pool is on-premise and not cloud"},{"poster":"cookiemonster42","comment_id":"799211","timestamp":"1675634640.0","upvote_count":"1","content":"D is correct because dedicated SQL pool is also called data-warehouse so, on-premise gateway will be used to build power BI dataset."},{"comment_id":"743239","comments":[{"timestamp":"1674475320.0","poster":"stfglv","comments":[{"comment_id":"785316","content":"Another confirmation (albeit from a completely different angle) can be found here as well: https://community.powerbi.com/t5/Service/How-to-Install-on-premise-gateway-on-azure-virtual-machine/m-p/2419686","timestamp":"1674475380.0","upvote_count":"1","poster":"stfglv"}],"comment_id":"785314","upvote_count":"1","content":"I would normally agree if we look at things black vs white i.e. on-prem vs. cloud, here Azure, but as the link from Az301301X states, nothing is black and white and we do need a gateway."},{"content":"Apologies for constantly adding comments, but this just crossed my mind as well: XMLA endpoint is connected to a Premium capacity and the question scenario does not mention Premium at all.","timestamp":"1675074780.0","poster":"stfglv","upvote_count":"1","comment_id":"792647"}],"timestamp":"1670872440.0","upvote_count":"6","content":"I believe the correct answer is the XMLA endpoint.\nQuestion mentions - 'Contoso has a 50-TB data warehouse that uses an instance of SQL Server on Azure Virtual Machines (imp)'. Since it's on Azure, we won't need an on-prem gateway. We can use a PowerShell cmdlet script to update the dataset.","poster":"nbagchi"}],"answer_description":"","unix_timestamp":1670872440,"topic":"1","url":"https://www.examtopics.com/discussions/microsoft/view/91269-exam-dp-500-topic-1-question-5-discussion/","question_images":[],"answer":"D"},{"id":"UI0Gcqoc9z08ACqKm7xE","exam_id":70,"topic":"1","answer_description":"","question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this question, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou have a Power BI dataset named Dataset1.\nIn Dataset1, you currently have 50 measures that use the same time intelligence logic.\nYou need to reduce the number of measures, while maintaining the current functionality.\nSolution: From Power BI Desktop, you group the measures in a display folder.\nDoes this meet the goal?","url":"https://www.examtopics.com/discussions/microsoft/view/91446-exam-dp-500-topic-1-question-50-discussion/","answer_ET":"B","answer_images":[],"discussion":[{"content":"Selected Answer: B\nmay be calculation groups would help reduce the number of measures","upvote_count":"2","poster":"hoss29","timestamp":"1692319500.0","comment_id":"984093"},{"comment_id":"915264","poster":"Eltooth","upvote_count":"1","timestamp":"1685956680.0","content":"Selected Answer: B\nB is correct answer."},{"timestamp":"1679996640.0","upvote_count":"2","content":"Selected Answer: B\nb is correct","comment_id":"853067","poster":"DarioReymago"},{"comment_id":"767498","upvote_count":"3","content":"putting them in the same folder is just a cosmetic change that does not impact any underlying problems","timestamp":"1672999800.0","poster":"ivanb94"},{"comments":[{"content":"DAX grouping does not exist, you can GROUPBY as a DAX function.","upvote_count":"1","timestamp":"1682506680.0","comment_id":"881490","poster":"sgodd_0298"}],"poster":"Chk88","timestamp":"1671978360.0","upvote_count":"1","comment_id":"755711","content":"correct, use dax grouping instead"},{"comment_id":"744174","poster":"nbagchi","timestamp":"1670943960.0","upvote_count":"1","content":"Selected Answer: B\nCorrect"}],"answers_community":["B (100%)"],"unix_timestamp":1670943960,"choices":{"A":"Yes","B":"No"},"isMC":true,"question_images":[],"timestamp":"2022-12-13 16:06:00","answer":"B","question_id":130}],"exam":{"numberOfQuestions":183,"name":"DP-500","provider":"Microsoft","isBeta":false,"isMCOnly":false,"lastUpdated":"12 Apr 2025","id":70,"isImplemented":true},"currentPage":26},"__N_SSP":true}