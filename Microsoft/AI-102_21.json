{"pageProps":{"questions":[{"id":"MTFOjEdBHLPDUkzh5tLy","discussion":[{"poster":"zellck","content":"Selected Answer: A\nA is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/search/search-howto-large-index#run-indexers-in-parallel\nIf you partition your data, you can create multiple indexer-data-source combinations that pull from each data source and write to the same search index. Because each indexer is distinct, you can run them at the same time, populating a search index more quickly than if you ran them sequentially.","comments":[{"comment_id":"1062011","timestamp":"1714812180.0","content":"thanks for explanation","poster":"rdemontis","upvote_count":"1"}],"comment_id":"936544","upvote_count":"11","timestamp":"1703769480.0"},{"content":"Selected Answer: A\nParallel indexing allows you to process multiple documents simultaneously, thereby minimizing the time it takes to build the index. This approach is suitable for handling large volumes of documents and images efficiently. \n\nA is correct","upvote_count":"1","timestamp":"1739164680.0","poster":"syupwsh","comment_id":"1354253"},{"timestamp":"1732899120.0","content":"Selected Answer: A\nA is correct.","comment_id":"1221060","upvote_count":"2","poster":"fuck_india"},{"poster":"taiwan_is_not_china","timestamp":"1732810560.0","comment_id":"1220330","content":"Selected Answer: A\nThe answer to this question is A.","upvote_count":"2"},{"timestamp":"1732118040.0","upvote_count":"1","content":"Selected Answer: A\nA is right answer.","comment_id":"1214370","poster":"takaimomoGcup"},{"comment_id":"925179","poster":"nitz14","content":"Selected Answer: A\nTo minimize the time it takes to build the index for the documents and images in the Azure Storage account, the best approach would be to use parallel indexing.\nTherefore, the correct option is:\nA. From the Azure portal, configure parallel indexing.\n\nConfiguring parallel indexing allows you to process multiple documents or images simultaneously","timestamp":"1702738500.0","upvote_count":"2"},{"upvote_count":"1","poster":"ulloo","comment_id":"892223","content":"https://learn.microsoft.com/en-us/azure/search/search-howto-large-index","timestamp":"1699458780.0"},{"poster":"Mike19D","content":"seems logical","comment_id":"887518","timestamp":"1698942540.0","upvote_count":"1"}],"choices":{"A":"From the Azure portal, configure parallel indexing.","B":"From the Azure portal, configure scheduled indexing.","C":"Configure field mappings by using the REST API.","D":"Create a text-based indexer by using the REST API."},"question_text":"You have an Azure subscription that contains an AI enrichment pipeline in Azure Cognitive Search and an Azure Storage account that has 10 GB of scanned documents and images.\n\nYou need to index the documents and images in the storage account. The solution must minimize how long it takes to build the index.\n\nWhat should you do?","url":"https://www.examtopics.com/discussions/microsoft/view/108276-exam-ai-102-topic-2-question-25-discussion/","answer_images":[],"answers_community":["A (100%)"],"unix_timestamp":1683037740,"exam_id":40,"question_id":101,"answer_description":"","answer_ET":"A","isMC":true,"timestamp":"2023-05-02 16:29:00","question_images":[],"topic":"2","answer":"A"},{"id":"O5tV1iOovO9O8hOpD6Ds","exam_id":40,"question_id":102,"url":"https://www.examtopics.com/discussions/microsoft/view/110625-exam-ai-102-topic-2-question-26-discussion/","answer_description":"","answer_images":["https://img.examtopics.com/ai-102/image27.png"],"answers_community":[],"isMC":false,"discussion":[{"content":"1. Sign in to Azure Video Analyzer for Media website\n2. From Content model customization, select Brands\n3. Add specific company names to include list\n\nhttps://learn.microsoft.com/en-us/azure/azure-video-indexer/customize-brands-model-with-website","comments":[{"content":"Gotten this in Jul 2023 exam.","timestamp":"1688774580.0","comment_id":"946060","poster":"zellck","upvote_count":"9"}],"comment_id":"939640","timestamp":"1688191860.0","poster":"zellck","upvote_count":"30"},{"comment_id":"1363387","timestamp":"1740805200.0","upvote_count":"1","content":"1) Sign in to the Azure Video Indexer web portal is CORRECT because Azure Video Indexer is the primary service used for analyzing video content, including speech-to-text, brand detection, and entity recognition. Before configuring any settings, you must access the Video Indexer portal.\n\n2) From Content model customization, select Brands is CORRECT because brand detection in Video Indexer allows customization to recognize specific company names. This feature helps detect brand mentions in spoken words, text, and visual content.\n\n3) Add the specific company names to the include list is CORRECT because to ensure that specific company names are recognized and included in the analysis, they must be explicitly added to the include list under the Brands customization settings.","poster":"syupwsh"},{"poster":"krzkrzkra","upvote_count":"1","content":"1. Sign in to Azure Video Analyzer for Media website\n2. From Content model customization, select Brands\n3. Add specific company names to include list","timestamp":"1721121000.0","comment_id":"1248790"},{"content":"1. Sign in website ,analyzer\n2. From Brands\n3. Add include list","poster":"hatanaoki","timestamp":"1716905220.0","comment_id":"1220318","upvote_count":"3"},{"comment_id":"1214363","upvote_count":"2","timestamp":"1716212820.0","poster":"takaimomoGcup","content":"Sign in website, From Brands, Add include list.\nI memorized this line."},{"content":"login to azure video analyzer==>select brands tab to customize the analyzer==>add specific company names to the \"include\" list","upvote_count":"3","timestamp":"1708123380.0","poster":"evangelist","comment_id":"1152264"},{"content":"Now it's call \"Azure AI Video Indexer website \"","upvote_count":"1","comment_id":"1126626","poster":"josebernabeo","timestamp":"1705662600.0"},{"upvote_count":"2","timestamp":"1699094820.0","content":"correct answer","comment_id":"1062014","poster":"rdemontis"},{"timestamp":"1685519520.0","poster":"mmaguero","content":"ChatGPT agree: \nAnswer Area:\n\n Sign in to the Azure Video Analyzer for Media website.\n From Content model customization, select Brands.\n Add the specific company names to the include list.","upvote_count":"3","comment_id":"910975"}],"question_text":"DRAG DROP\n-\n\nYou need to analyze video content to identify any mentions of specific company names.\n\nWhich three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\n\n//IMG//","unix_timestamp":1685519520,"timestamp":"2023-05-31 09:52:00","topic":"2","answer":"","question_images":["https://img.examtopics.com/ai-102/image26.png"],"answer_ET":""},{"id":"y0WlKqr46BcLKj28zoJI","answer_description":"","topic":"2","unix_timestamp":1683343740,"question_id":103,"choices":{"C":"JSON","B":"form URL encoded","A":"raw image binary"},"exam_id":40,"answer_ET":"A","isMC":true,"answer_images":[],"answers_community":["A (100%)"],"discussion":[{"upvote_count":"7","content":"Selected Answer: A\nTo send images to the Form Recognizer API endpoint without storing them in the cloud, you should send the images in the following format:\n\nA. raw image binary\n\nSending the images as raw image binary data allows you to transmit the image directly to the Form Recognizer API without the need to store them in the cloud or convert them into other formats. This format ensures compliance with your requirements. (ChatGPT)","timestamp":"1714813140.0","poster":"rdemontis","comment_id":"1062023"},{"timestamp":"1714356240.0","content":"Appeared on Oct/29/2023","comment_id":"1056561","upvote_count":"5","poster":"trashbox"},{"poster":"syupwsh","upvote_count":"1","content":"Selected Answer: A\nhttps://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/faq?view=doc-intel-4.0.0#does-document-intelligence-store-my-data-\n\nAnswer is A","comment_id":"1354254","timestamp":"1739164860.0"},{"poster":"taiwan_is_not_china","comment_id":"1220328","content":"Selected Answer: A\nThe answer to this question is A.","upvote_count":"1","timestamp":"1732810500.0"},{"comment_id":"1218285","poster":"nanaw770","content":"Selected Answer: A\nA is right.","upvote_count":"1","timestamp":"1732542840.0"},{"poster":"takaimomoGcup","upvote_count":"1","comment_id":"1214368","content":"Selected Answer: A\nA is right answer.","timestamp":"1732117980.0"},{"upvote_count":"2","timestamp":"1719676020.0","poster":"ankitdhir","content":"Selected Answer: A\nits correct","comment_id":"1108960"},{"content":"Selected Answer: A\nA. raw image binary\nhttps://westus.dev.cognitive.microsoft.com/docs/services/form-recognizer-api-v2-1/operations/AnalyzeReceiptAsync\nRequest body: Document containing the receipt image(s) to be analyzed. The POST body should be the raw image binary, or the image URL in JSON.\n\nhttps://ittichaicham.com/2020/03/call-azure-form-recognizer-api-on-sharepoint-document-image-url-in-power-automate/\nPower Automate (formerly Microsoft Flow) can call Azure Form Recognizer via the connector. Since Power Automate is a cloud solution, the natural choice is to use the image URL. This should work fine if the URL is accessible to the public or requires no authentication. Unfortunately, the company’s SharePoint URL, most of the time, is not.\nTo solve this, we can add another flow step to move the SharePoint file to where it is accessible, or, better, instead of using file URL, we can pass binary content in the Form Recognizer API.","comment_id":"995288","upvote_count":"3","poster":"M25","timestamp":"1709231760.0"},{"comments":[],"poster":"zellck","comment_id":"936540","content":"Selected Answer: A\nA is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/applied-ai-services/form-recognizer/faq?view=form-recog-3.0.0#does-form-recognizer-store-my-data-\nFor all features, Form Recognizer temporarily stores data and results in Azure storage in the same region as the request. Your data is then deleted within 24 hours from the time an analyze request was submitted.","timestamp":"1703769180.0","upvote_count":"3"},{"upvote_count":"1","timestamp":"1701770940.0","comment_id":"915207","content":"Should be A. When you send images to the endpoint, the images don't get stored anywhere.","poster":"ziggy1117"},{"content":"chat gpt \"To send images directly to Forms Recognizer and extract relevant information without storing the image files in the cloud, you should use the raw image binary format.\"","poster":"hens","comment_id":"898069","upvote_count":"3","timestamp":"1700035560.0"},{"content":"Looks like URL (not sure about the \"encoded\" part though!)\nhttps://learn.microsoft.com/en-us/azure/applied-ai-services/form-recognizer/v3-migration-guide?view=form-recog-3.0.0#analyze-request-body","upvote_count":"1","comment_id":"890448","timestamp":"1699248540.0","poster":"Rob77"}],"url":"https://www.examtopics.com/discussions/microsoft/view/108600-exam-ai-102-topic-2-question-27-discussion/","timestamp":"2023-05-06 05:29:00","question_text":"You have a mobile app that manages printed forms.\n\nYou need the app to send images of the forms directly to Forms Recognizer to extract relevant information. For compliance reasons, the image files must not be stored in the cloud.\n\nIn which format should you send the images to the Form Recognizer API endpoint?","answer":"A","question_images":[]},{"id":"pMq9Omo40uIVcjvGdbrN","exam_id":40,"answer_description":"","question_id":104,"answer_images":[],"isMC":true,"question_images":[],"discussion":[{"comments":[{"upvote_count":"2","content":"agree with you","comment_id":"1062026","poster":"rdemontis","timestamp":"1699095720.0"}],"upvote_count":"19","content":"Selected Answer: C\nI think the answer should be C, because of the minimized developement effort. Since the prebuilt model of C also fits the other two requirements, so there is no need to train a custom model.\n\nsource: https://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/how-to/call-analyze-image?tabs=rest","timestamp":"1682331600.0","comment_id":"879223","poster":"MaliSanFuu"},{"comment_id":"1132968","content":"Selected Answer: C\nHere's why:\n\nMultilingual Tag Generation: Azure's Computer Vision Image Analysis service can analyze images and provide a list of tags describing the content of the images. It also has the capability to return these tags in various languages, including English, French, and Spanish, which aligns with your requirement.\n\nMinimizing Development Effort: This service offers a pre-built model, which means there is no need for you to collect data and train your own model. This significantly reduces the development effort and time. You simply need to call the API with your images, and it will return the tags.","timestamp":"1706317380.0","poster":"evangelist","upvote_count":"8"},{"upvote_count":"1","comment_id":"1354256","poster":"syupwsh","timestamp":"1739164980.0","content":"Selected Answer: C\nComputer Vision Image Analysis provides a comprehensive set of features for analyzing images, including generating tags. It supports multiple languages, including English, French, and Spanish, which meets the requirement of generating tags in a user's preferred language. Additionally, it minimizes development effort by offering a ready-to-use endpoint for image analysis and tagging.\n\nC is correct"},{"comment_id":"1235336","poster":"reiwanotora","content":"Selected Answer: C\nC is the answer.","upvote_count":"1","timestamp":"1719053460.0"},{"upvote_count":"1","poster":"HaraTadahisa","timestamp":"1719036780.0","comment_id":"1235169","content":"Why C?"},{"comment_id":"1221061","content":"Selected Answer: C\nC is correct.","poster":"fuck_india","timestamp":"1716994320.0","upvote_count":"1"},{"content":"Selected Answer: C\nC is right.","upvote_count":"1","poster":"nanaw770","timestamp":"1716638220.0","comment_id":"1218287"},{"timestamp":"1716213480.0","comment_id":"1214372","upvote_count":"1","poster":"takaimomoGcup","content":"Selected Answer: C\nC. Computer Vision Image Analysis"},{"content":"generate tags as per image is an Image Analysis operation rather than an image classification operation","timestamp":"1708123500.0","upvote_count":"3","comment_id":"1152266","poster":"evangelist"},{"upvote_count":"2","timestamp":"1703872140.0","content":"Selected Answer: C\nVerified with google bard","comment_id":"1108962","comments":[{"poster":"anto69","upvote_count":"1","timestamp":"1707026280.0","comment_id":"1139829","content":"C, verified with Copilot too"}],"poster":"ankitdhir"},{"comments":[{"upvote_count":"1","content":"Yes it is. URL below. \nhttps://learn.microsoft.com/en-us/azure/ai-services/computer-vision/language-support#image-analysis","timestamp":"1733354460.0","poster":"3fbc31b","comment_id":"1322139"},{"comment_id":"1167717","poster":"Mehe323","content":"French is supported, I just tested it in Azure. See also this link (the table 'Analyze image':\nhttps://learn.microsoft.com/en-us/azure/ai-services/computer-vision/language-support#image-analysis","timestamp":"1709791800.0","upvote_count":"1"},{"content":"True.\n\nURL parameter Value Description\nlanguage en English\nlanguage es Spanish\nlanguage ja Japanese\nlanguage pt Portuguese\nlanguage zh Simplified Chinese\n\nSource: https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/call-analyze-image?tabs=rest","poster":"josebernabeo","upvote_count":"1","timestamp":"1705663080.0","comment_id":"1126627"}],"timestamp":"1703496660.0","poster":"TRUESON","content":"Selected Answer: B \nFrench is not supported by computer vision","upvote_count":"2","comment_id":"1105133"},{"poster":"zellck","comment_id":"936528","content":"Selected Answer: C\nC is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-tagging-images\nImage Analysis can return content tags for thousands of recognizable objects, living beings, scenery, and actions that appear in images. Tags are not organized as a taxonomy and do not have inheritance hierarchies. A collection of content tags forms the foundation for an image description displayed as human readable language formatted in complete sentences. When tags are ambiguous or not common knowledge, the API response provides hints to clarify the meaning of the tag in context of a known setting.","timestamp":"1687950300.0","comments":[{"comments":[{"timestamp":"1699794000.0","content":"thanks for explanation","upvote_count":"1","comment_id":"1068528","poster":"rdemontis"}],"upvote_count":"4","poster":"zellck","comment_id":"936532","timestamp":"1687950420.0","content":"https://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/language-support#image-analysis\nSome features of the Analyze - Image API can return results in other languages, specified with the language query parameter. Other actions return results in English regardless of what language is specified, and others throw an exception for unsupported languages. Actions are specified with the visualFeatures and details query parameters; see the Overview for a list of all the actions you can do with image analysis. Languages for tagging are only available in API version 3.2 or later."}],"upvote_count":"3"},{"comment_id":"935873","upvote_count":"4","timestamp":"1687904640.0","poster":"Pixelmate","content":"Asked in 28/06/2023 exam"},{"poster":"ziggy1117","upvote_count":"1","content":"C: https://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-tagging-images","comment_id":"918740","timestamp":"1686266340.0"},{"timestamp":"1684130880.0","upvote_count":"1","comment_id":"898073","poster":"hens","content":"chat gpt \"To generate a list of tags for uploaded images in multiple languages, you should use the Computer Vision Image Analysis service endpoint in Azure.\n\nComputer Vision provides a pre-built model that can generate image tags based on a given image. It also supports multiple languages, including English, French, and Spanish, which meets the requirements of the app. Additionally, the service provides a REST API, which can be easily integrated into your app without requiring significant development effort.\""}],"choices":{"C":"Computer Vision Image Analysis","A":"Content Moderator Image Moderation","B":"Custom Vision image classification","D":"Custom Translator"},"timestamp":"2023-04-24 12:20:00","topic":"2","answer":"C","answer_ET":"C","question_text":"You plan to build an app that will generate a list of tags for uploaded images. The app must meet the following requirements:\n\n• Generate tags in a user's preferred language.\n• Support English, French, and Spanish.\n• Minimize development effort.\n\nYou need to build a function that will generate the tags for the app.\n\nWhich Azure service endpoint should you use?","answers_community":["C (100%)"],"unix_timestamp":1682331600,"url":"https://www.examtopics.com/discussions/microsoft/view/107293-exam-ai-102-topic-2-question-28-discussion/"},{"id":"AoosNJk84baOnwbHJttB","url":"https://www.examtopics.com/discussions/microsoft/view/108601-exam-ai-102-topic-2-question-29-discussion/","answer":"","answer_ET":"","discussion":[{"poster":"zellck","content":"YYN is the answer.\n\nhttps://learn.microsoft.com/en-us/rest/api/computervision/3.1/detect-objects/detect-objects?tabs=HTTP#boundingrect\nA bounding box for an area inside an image.\n- x\nX-coordinate of the top left point of the area, in pixels.\n- y\nY-coordinate of the top left point of the area, in pixels.\n- h\nHeight measured from the top-left point of the area, in pixels.\n- w\nWidth measured from the top-left point of the area, in pixels.","timestamp":"1688191500.0","upvote_count":"12","comment_id":"939637"},{"upvote_count":"1","content":"Yes is CORRECT because the code will display the name of each detected brand with a confidence equal to or higher than 75 percent. The if condition checks if brand.Confidence is greater than or equal to 0.75, and if so, it prints the brand name along with its coordinates.\nYes is CORRECT. The properties brand.Rectangle.X and brand.Rectangle.Y represent the X and Y coordinates of the top-left point of the area, respectively.\nNo is CORRECT because the code does not directly display the coordinates for the bottom-right corner of the rectangle. It displays the coordinates for the top-left corner (brand.Rectangle.X, brand.Rectangle.Y) and the width (brand.Rectangle.W) and height (brand.Rectangle.H). The bottom-right corner coordinates are not explicitly calculated or displayed.","comment_id":"1355488","poster":"syupwsh","timestamp":"1739341140.0"},{"timestamp":"1721064420.0","upvote_count":"1","content":"YYN is the answer.","comment_id":"1248477","poster":"krzkrzkra"},{"timestamp":"1716905700.0","comment_id":"1220327","upvote_count":"1","poster":"taiwan_is_not_china","content":"The answer is YYN."},{"upvote_count":"1","timestamp":"1716213120.0","poster":"takaimomoGcup","content":"Yes Yes No","comment_id":"1214367"},{"comment_id":"1132969","content":"answer is correct: Y Y N\nresponse only display the top left corner and width and height from this origin","upvote_count":"2","timestamp":"1706317500.0","poster":"evangelist"},{"content":"YYN: correct answer and duplicated question","timestamp":"1699095900.0","poster":"rdemontis","comment_id":"1062031","upvote_count":"3"},{"comments":[{"upvote_count":"3","timestamp":"1695279720.0","comment_id":"1012872","poster":"AnonymousJhb","content":"YYN. not the bottom right"}],"content":"YYY - the last one is Y because all coordinates together give you top left and bottom right.","comment_id":"1006049","timestamp":"1694554560.0","upvote_count":"1","poster":"jangotango"},{"poster":"[Removed]","content":"Answer is correct","comment_id":"1005346","timestamp":"1694492160.0","upvote_count":"1"},{"poster":"zellck","upvote_count":"4","comment_id":"939666","timestamp":"1688193780.0","content":"Same as Question 14.\nhttps://www.examtopics.com/discussions/microsoft/view/55050-exam-ai-102-topic-2-question-14-discussion"},{"upvote_count":"1","content":"Correct YYN. The last one is width and height.","timestamp":"1683345060.0","comment_id":"890453","poster":"Rob77"}],"timestamp":"2023-05-06 05:51:00","answer_images":["https://img.examtopics.com/ai-102/image30.png"],"topic":"2","question_id":105,"isMC":false,"answer_description":"","exam_id":40,"unix_timestamp":1683345060,"question_text":"HOTSPOT\n-\n\nYou develop a test method to verify the results retrieved from a call to the Computer Vision API. The call is used to analyze the existence of company logos in images. The call returns a collection of brands named brands.\n\nYou have the following code segment.\n\n//IMG//\n\n\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","question_images":["https://img.examtopics.com/ai-102/image28.png","https://img.examtopics.com/ai-102/image29.png"],"answers_community":[]}],"exam":{"lastUpdated":"12 Apr 2025","isBeta":false,"provider":"Microsoft","numberOfQuestions":329,"isImplemented":true,"name":"AI-102","id":40,"isMCOnly":false},"currentPage":21},"__N_SSP":true}