{"pageProps":{"questions":[{"id":"3sPjn4eFqCPYQAfFrM0L","isMC":false,"answer_ET":"","topic":"1","answer_description":"Box 1: Dual -\nCustomer should use the dual storage mode.\nDual: Tables with this setting can act as either cached or not cached, depending on the context of the query that's submitted to the Power BI dataset. In some cases, you fulfill queries from cached data. In other cases, you fulfill queries by executing an on-demand query to the data source.\nNote: You set the Storage mode property to one of these three values: Import, DirectQuery, and Dual.\n\nBox 2: Dual -\nYou can set the dimension tables (Customer, Geography, and Date) to Dual to reduce the number of limited relationships in the dataset, and improve performance.\n\nBox 3: DirectQuery -\nSales should use the DirectQuery storage mode.\nDirectQuery: Tables with this setting aren't cached. Queries that you submit to the Power BI datasetג€\"for example, DAX queriesג€\"and that return data from\nDirectQuery tables can be fulfilled only by executing on-demand queries to the data source. Queries that you submit to the data source use the query language for that data source, for example, SQL.\n\nBox 4: Import -\nImport: Imported tables with this setting are cached. Queries submitted to the Power BI dataset that return data from Import tables can be fulfilled only from cached data.\nReference:\nhttps://docs.microsoft.com/en-us/power-bi/transform-model/desktop-storage-mode","answer_images":["https://www.examtopics.com/assets/media/exam-media/04331/0000800001.png"],"answer":"","discussion":[{"upvote_count":"213","comment_id":"663134","timestamp":"1726840020.0","poster":"_Jay_","content":"Technically Yes, Correct \n\nDual (Composite) Mode:\nThe dual storage mode is between Import and DirectQuery. it is a hybrid approach, Like importing data, the dual storage mode caches the data in the table. However, it leaves it up to Power BI to determine the best way to query the table depending on the query context.\n\n1) Sales Must be Refreshed in Near real time so \"Direct Query\"\n2) Sales Aggregate is once per week so \"Import\" (performance also required)\n3) Both Date and Customer has relationship with both Sales and SalesAggregate tables so \"Dual\"\nbecause to support performance for DirectQuery(Sales) and Import(SalesAggregate)","comments":[{"content":"thanks for sharing your comment so I would ask if in case the Sales and the Sales Aggregate fact tables are both in near real-time will be a Direct Query not dual? thanks in advance","poster":"mustafaalhnuty","comments":[{"comment_id":"983387","upvote_count":"2","content":"I mean for Both Date and Customer dimension tables","timestamp":"1692261120.0","poster":"mustafaalhnuty"}],"timestamp":"1692261000.0","upvote_count":"2","comment_id":"983385"},{"upvote_count":"30","comments":[{"comment_id":"1126433","poster":"__Sai_Mounika__","upvote_count":"1","content":"the link provided is on spot","timestamp":"1705640160.0"}],"poster":"Nawabi","content":"Correct. IF someone still unable to understand I would highly recommend going through this link. Excellent explanation","comment_id":"803840","timestamp":"1675989660.0"}]},{"content":"My interpretation of the answer:\n\nthere are 2 fact tables connected to 2 dim tables. Sales fact table needs DirectQuery.. Sales Aggregate table needs to weekly refreshes hence Import mode. But both dimension tables have to serve these fact tables and hence they will be in DUAL MODE. Am I correct?","timestamp":"1710728820.0","poster":"Raj1690","upvote_count":"5","comment_id":"1176207"},{"upvote_count":"1","comment_id":"1410713","poster":"Indako","timestamp":"1743043080.0","content":"Import - Customer is cached\nImport - Date is cached\nDirect Query - Sales is not cached\nDual - Sales Aggregation either cached or not cached"},{"poster":"Nityaanantha_Raman","content":"Technically Yes, Correct\n\nDual (Composite) Mode:\nThe dual storage mode is between Import and DirectQuery. it is a hybrid approach, Like importing data, the dual storage mode caches the data in the table. However, it leaves it up to Power BI to determine the best way to query the table depending on the query context.\n\n1) Sales Must be Refreshed in Near real time so \"Direct Query\"\n2) Sales Aggregate is once per week so \"Import\" (performance also required)\n3) Both Date and Customer has relationship with both Sales and SalesAggregate tables so \"Dual\"\nbecause to support performance for DirectQuery(Sales) and Import(SalesAggregate)\n\nhttps://docs.google.com/document/d/1oNH9i2ssNi9gISG3JGuxUoUhmAA4xCaGahEKv2dRN6Y/edit?usp=sharing","upvote_count":"1","comment_id":"1401837","timestamp":"1742631480.0"},{"timestamp":"1727447820.0","comment_id":"1290095","content":"If the tables are from the same database in this model. Then there is only one frequency of refresh possible. It cannot be weekly , since it says \"Customer must be refreshed daily.\" \nAlso Import mode generally minimizes the load time of visuals compared to Dual mode. This is because Import mode caches all the data in-memory, allowing for very fast query performance and quick rendering of visuals\n\nCustomer: Import - refresh daily requirement\nDate: Dual - just because Sales is direct query and might be more efficient to have as Dual.\nSales: Direct Query - Real Time by requirements\nSales Aggregate: Imported, is weekly, but there is no saving in refresh, since the refresh is daily because the Customers table.","poster":"examtopicsms99","upvote_count":"1"},{"poster":"Gbucci72","timestamp":"1723791300.0","upvote_count":"4","content":"I dont agree, sales are to be done near real time so direct query is right. Sales aggregates once a week, then dual is ok as we want performance too. Customer is dual too. while Date, updated once every 3 yrs can be import.","comment_id":"1266876"},{"content":"In PBI there are 3 connection modes:\n1 - Import Mode, all the data is loaded into the model once and you need to manually refresh data before get latest updates\n2 - Direct query mode (or similar live for Azure Analysis Service or SSAS), in which PBI sends queries to the sources each time a visualization is refreshed or interacted with\n3 - Dual, it is an hybrid mode\n\nSaying that, we need for sure a direct query for the sales (since it is near real time) then the sales aggregate should be put to Import since there is an once per week update. Finally, as Microsoft suggest, the dimension tables should be set to dual (date and customers in this case)","upvote_count":"3","timestamp":"1723120260.0","poster":"rcaliandro","comment_id":"1262478"},{"timestamp":"1720433640.0","upvote_count":"1","content":"Dual Mode","poster":"Nishi_06","comment_id":"1244282"},{"timestamp":"1710071340.0","content":"The answer is correct","upvote_count":"1","comment_id":"1170291","poster":"docoumn"},{"comment_id":"1167374","timestamp":"1709746980.0","content":"Why does Sales Aggregate use Import as per the solution? Where as Date uses Dual.\nIn both the cases there is no real time refresh required, why are we going with Import mode for sales aggregate??\n\nBTW, I understand logic behind selecting Dual for Date as it is dimension table and we intend to reduce number of limited relationships.","poster":"GowthamMupparapu","upvote_count":"1"},{"timestamp":"1709746320.0","poster":"LOCOBI","upvote_count":"2","comment_id":"1167368","content":"Sales need to be real time so a DirectQueary storage mode.\nSales aggregate as is a weekly load you can use Import Mode and save on performance.\n\nAs you have one of each, the other table connected to this source should be Dual. If they where not connected they would be Import mode."},{"content":"Dual, dual, direct query, import","timestamp":"1699447080.0","poster":"Mal42","comment_id":"1065624","upvote_count":"2"},{"comment_id":"1063563","upvote_count":"2","timestamp":"1699253820.0","content":"Give answer is correct. The tables that are connected to both Direct Query and Import should be set as Dual.","poster":"TrustMyAnswers"},{"content":"Customer(dual), date(dual), sales(direct query) , salesaggregate(import)","poster":"allapu","upvote_count":"1","comment_id":"1054844","timestamp":"1698344880.0"},{"timestamp":"1693843620.0","poster":"Igetmyrole","content":"1. Customer table: Import mode should be used because it needs to be refreshed daily, and importing the data will provide better performance for visuals.\n2. Date table: Import mode should be used because even though it is refreshed once every three years, importing it will not significantly affect performance, and it ensures that visual loads quickly.\n 3. For Sales table: Dual mode should be used for this table because it needs to be refreshed in near real-time.\n4. SalesAggregate Tabe: Import mode should be used because it needs to be refreshed once per week, and importing the data will insure better visual performance.","comment_id":"998674","upvote_count":"2"},{"poster":"Igetmyrole","comment_id":"998672","upvote_count":"1","content":"3. Date table: Import mode should be used because even though it is refreshed once every three years, importing it will not significantly affect performance, and it ensures that visual loads quickly.","timestamp":"1693843500.0"},{"content":"Dual\nDual\nDQ\nImport","comment_id":"886117","upvote_count":"1","poster":"Shalaleh","timestamp":"1682938620.0"},{"timestamp":"1682789640.0","comment_id":"884567","content":"This link is helpful in describing when to use which import mode. The requirement of the data (real-time refresh vs. performance) and the relationships in the exhibit are what this question comes down to.\nhttps://learn.microsoft.com/en-us/training/modules/choose-power-bi-model-framework/1-introduction","upvote_count":"2","poster":"lizbette"},{"upvote_count":"3","poster":"DUVANES","comment_id":"848318","timestamp":"1679582400.0","content":"Dual\nDual\nDirectQuery\nImport"},{"timestamp":"1679571960.0","content":"I found the perfect explanation why the answer is correct:","comment_id":"848142","upvote_count":"3","poster":"Maria86"},{"content":"Hi everybodyI Does anyone could explain me why 1 and 2 must be Dual? Could be Import or no way?","upvote_count":"1","timestamp":"1679503620.0","poster":"Plinio","comment_id":"847294"},{"upvote_count":"1","timestamp":"1678966440.0","poster":"Jew0598","content":"The customer table should be stored in Direct Query mode as the table has a solid line on the top. The solid line means Direct query, and a dashed bar at the top of the table means Dual.\nSo I think the answer is Direct Query, Dual, Dual, Import.","comment_id":"840896"},{"poster":"hungry85","content":"the answer approach is correct","upvote_count":"1","timestamp":"1674314100.0","comment_id":"783459"},{"comment_id":"759858","upvote_count":"1","timestamp":"1672232940.0","content":"Is this correct?: THe tables should be set to DUAL since it will interact with a DQ table (sales) for query optimization reasons","poster":"UserNo1"},{"comment_id":"715891","poster":"Raza12","timestamp":"1668157620.0","content":"i think the given answer is Right. please check the link and confirm back for the rest of the people.","upvote_count":"1"},{"comment_id":"709705","poster":"Namenick10","upvote_count":"3","timestamp":"1667378820.0","content":"Customer: Dual\nDate: Dual\nSales: DirectQuery\nSalesAggregate: Import"},{"content":"Direct Query\nDual \nDual \nImport","timestamp":"1666712100.0","comment_id":"703990","upvote_count":"2","poster":"Churato"},{"content":"@Elena3061 I guess you should dual instead of DirectQuery because of their relationship with both import mode table and directQuery mode table. Take a look at _Jay_'s post and at the \"Limited Relationship\" paragraph in this article https://learn.microsoft.com/en-us/power-bi/transform-model/desktop-relationships-understand","timestamp":"1663417980.0","comment_id":"671509","poster":"zerone72","upvote_count":"3"},{"comment_id":"663150","timestamp":"1662614880.0","upvote_count":"2","content":"Can someone explain for me why should we use Dual instead of DirectQuiry for Date and Customer tables? Thank you","poster":"Elena3061"},{"comment_id":"658978","timestamp":"1662269940.0","content":"is the answer correct?","poster":"gabrysr1997","upvote_count":"4"}],"question_id":1,"timestamp":"2022-09-04 07:39:00","question_text":"HOTSPOT -\nYou plan to create the Power BI model shown in the exhibit. (Click the Exhibit tab.)\n//IMG//\n\nThe data has the following refresh requirements:\n✑ Customer must be refreshed daily.\n✑ Date must be refreshed once every three years.\n✑ Sales must be refreshed in near real time.\n✑ SalesAggregate must be refreshed once per week.\nYou need to select the storage modes for the tables. The solution must meet the following requirements:\n✑ Minimize the load times of visuals.\n✑ Ensure that the data is loaded to the model based on the refresh requirements.\nWhich storage mode should you select for each table? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","url":"https://www.examtopics.com/discussions/microsoft/view/79961-exam-pl-300-topic-1-question-1-discussion/","exam_id":116,"answers_community":[],"unix_timestamp":1662269940,"question_images":["https://www.examtopics.com/assets/media/exam-media/04331/0000600001.jpg","https://www.examtopics.com/assets/media/exam-media/04331/0000700001.png"]},{"id":"F1dQZHKotNPCICeZFATO","answers_community":["C (84%)","Other"],"exam_id":116,"question_text":"You have a CSV file that contains user complaints. The file contains a column named Logged. Logged contains the date and time each complaint occurred. The data in Logged is in the following format: 2018-12-31 at 08:59.\nYou need to be able to analyze the complaints by the logged date and use a built-in date hierarchy.\nWhat should you do?","question_images":[],"discussion":[{"poster":"_Jay_","content":"Selected Answer: C\nAnswer C is best approach\nSplit the Logged column by using \"at\" as the delimiter.","upvote_count":"98","timestamp":"1662624120.0","comment_id":"663343","comments":[{"comment_id":"1343845","content":"correct answer","poster":"SylUK","upvote_count":"1","timestamp":"1737404100.0"},{"upvote_count":"3","timestamp":"1672199100.0","content":"Agreed with you Jay","poster":"GuerreiroJunior","comment_id":"759331"},{"poster":"Jay_98_11","upvote_count":"2","timestamp":"1669143840.0","comment_id":"724585","content":"agreed"},{"poster":"red_02","content":"If you choose to split it will create 2 columns but extract will give 1 column.","upvote_count":"9","timestamp":"1681692840.0","comment_id":"872264"},{"poster":"Pals1512","timestamp":"1706355600.0","comment_id":"1133296","upvote_count":"2","content":"wont that give an extra space at the end?"}]},{"upvote_count":"41","content":"C,\n\nYou should split the Logged column by using \"at\" as the delimiter. This will allow you to separate the date and time into separate columns, which will enable you to analyze the complaints by date and use a built-in date hierarchy. Alternatively, you could also use a transformation to extract the date and time from the Logged column and set the data type of the new columns to Date and Time, respectively. Option A is incorrect because it only extracts the last 11 characters of the Logged column, which would not include the date. Option B is incorrect because the data in the Logged column is in a non-standard date format and cannot be directly converted to the Date data type. Option D is incorrect because it only extracts the first 11 characters of the Logged column, which would not include the time.","comments":[{"timestamp":"1676094060.0","comments":[{"timestamp":"1678786080.0","upvote_count":"11","poster":"cabbagepie","content":"You actually can do that if you click on the \"Select or enter delimiter\" in the \"Split Column by Delimiter\" window that pops up after you click on \"Split Column\" in the \"Transform\" tab on top of your Power BI window. After you select the --Custom-- option from the drop down menu in the \"Select or enter delimiter\" drop down list, you can write \"at\" in the text box that appears below the drop down list.","comment_id":"838687"},{"content":"Correct answer","upvote_count":"1","comment_id":"949710","poster":"dodoinparis","timestamp":"1689161400.0"}],"comment_id":"805016","content":"delimiter uses only one character, so \"at\" is not valid","poster":"AFarag","upvote_count":"3"}],"timestamp":"1672229940.0","poster":"Meebler","comment_id":"759795"},{"poster":"Kbo05","timestamp":"1741972680.0","comment_id":"1395662","upvote_count":"1","content":"Selected Answer: C\nSplit the logged column with the delimiter space"},{"content":"Selected Answer: D\nD. Apply a transformation to extract the first 11 characters of the Logged column.\n\nExtracting the first 11 characters will give you 2018-12-31, which is the date part. You can then set the data type of this new column to Date. This is the most straightforward and efficient approach.","upvote_count":"2","poster":"teenthabo","comment_id":"1346226","timestamp":"1737751140.0"},{"content":"Selected Answer: D\nExplanation:\nThe Logged column format is \"2018-12-31 at 08:59\".\nTo analyze by date and use a built-in date hierarchy, you need to extract just the date part.\nThe first 11 characters (\"2018-12-31\") represent the date.\nOnce extracted, you can convert this new column into a Date data type for proper analysis and use of the date hierarchy.\nThis ensures that the data is in a suitable format for date-based analysis.","timestamp":"1737516060.0","upvote_count":"2","comment_id":"1344596","poster":"Shrav95"},{"comment_id":"1340073","upvote_count":"1","timestamp":"1736807040.0","content":"Selected Answer: C\nAnswer is correct. Tried and tested.","poster":"MANANDAVEY"},{"upvote_count":"1","timestamp":"1735719420.0","comment_id":"1335143","poster":"Bilalwaris786","content":"Selected Answer: B\nCorrect answer is \"Change the data type of the Logged column to Date.\"\n\nas question is saying \"You need to be able to analyze the complaints by the logged date and use a built-in date hierarchy.\"\nif you select split option, column will be still in text format, so we have to change Logged column to a date format."},{"content":"Selected Answer: B\nI have seen the same question in the Microsoft pl-300 preparation course on coursera and here is the answer to that question:\n\nYou have a CSV file that contains user complaints. The table contains a column called Logged, which has data and the time of each complaint. The data is logged in the following format: 2022-12-21 at 08:35. You want to analyze the complaints by the logged date and utilize Power BI’s built-in date hierarchy. What should you do?\n\n- Split the logged column using ‘at’ as a delimiter.\n- You can use the same column as the date hierarchy.\n- Apply transformation to extract the column's first characters that only contain the date.\n- Change the data type of the logged column to Date. ✔","timestamp":"1734966480.0","comment_id":"1330851","upvote_count":"3","poster":"BIFakeGuru"},{"content":"Selected Answer: D\nI have seen the same question in the Microsoft pl-300 preparation course on coursera and here is the answer to that question:\n\nYou have a CSV file that contains user complaints. The table contains a column called Logged, which has data and the time of each complaint. The data is logged in the following format: 2022-12-21 at 08:35. You want to analyze the complaints by the logged date and utilize Power BI’s built-in date hierarchy. What should you do?\n\n1- Split the logged column using ‘at’ as a delimiter.\n2- You can use the same column as the date hierarchy.\n3- Apply transformation to extract the column's first characters that only contain the date.\n4- Change the data type of the logged column to Date. ✔","timestamp":"1734966420.0","poster":"BIFakeGuru","comment_id":"1330850","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: D\nMy bad, A is talking about the last 11 characters, so my choice is D.","poster":"AlexBear","timestamp":"1734830160.0","comment_id":"1330226"},{"timestamp":"1734829980.0","upvote_count":"1","content":"Selected Answer: A\nAnd yeah you should change the data type after D so the correct answer should be A","comment_id":"1330222","poster":"AlexBear"},{"comment_id":"1330221","poster":"AlexBear","timestamp":"1734829920.0","upvote_count":"1","content":"Selected Answer: D\nI've tried in PBI desktop, and D works well."},{"timestamp":"1734053580.0","upvote_count":"1","comment_id":"1325947","content":"Selected Answer: C\nTried it in power query.\nsplitting the column by delimiter at indeed will result in a space character after the date\nas in 2018-12-31[space]\nhowever the space does not prevent power query from automatically converting the data type to date.\n\nIf we chose to extract the first 11 characters, power query will still treat them as text. It does not become a date data type.","poster":"YuanQingTan"},{"upvote_count":"2","poster":"GraceKHE","comment_id":"1310500","content":"Selected Answer: A\nTested. Yes, delimiter can customized by delimiting \"at\" but the column format is still Text. answer A automatically change the column format to Date hierarchy.","timestamp":"1731402780.0"},{"poster":"Madhu155","upvote_count":"1","timestamp":"1728281220.0","content":"Option D","comment_id":"1294047"},{"upvote_count":"1","poster":"Bob_38","comment_id":"1290330","timestamp":"1727466780.0","content":"CCCCCCCCCCCCCCCCC! No Brainer!"},{"poster":"Dani_eL","comment_id":"1157081","content":"Selected Answer: D\nanswer is D, apply a TRANSFORMATION; \nusing a demo. create a csv with complaint id, complaint date(use the date format described in the example)\nCreate new report -> transform data : opens Power Query editor\nNew Sources -> csv\n\nHere comes the tricky part: when you import a csv, you can apply TRANSFORMATION on the fly;\nthere is a button at the bottom left part of the window : Extract table using examples\n\nclick that button, here comes the TRANSFORMATION\nYou are presented with a form allowing you to pick up the fields and the data you want by example.\nName your headers according to the csv headers and in the first data row, type the kind of data you want.\n\nFor the logged column, you will type the date only.\nAfter import you will see that Query editor imported and converted your field in Date format.\n\nFinally, go to report view and expand your imported csv in the Data pane.\nYou will see that Power BI created a date hierarchy","timestamp":"1726896600.0","upvote_count":"1"},{"poster":"Giuditta","comment_id":"1172051","timestamp":"1726896600.0","upvote_count":"2","content":"there are two major issues with both C and D\nC have the wrong delimeter. \"at\" needs you to have a trim operation after the split. \" at \" (with a space before and after) will do the trick for us\nD we cannot be sure that different dates with month or days with just one units will be written as i.e. 2024-12-03 or 2024-12-3 making the fixed value of 11 character a bit confusing. mostly in dates like 2024-1-1 at 00:00:0000 where the first 11 characters are 2024-1-1 a\ni think that C will be better. in both cases the resulted columns need to have other transformation to be interpreted as date and not string"},{"timestamp":"1726470540.0","comment_id":"1284528","poster":"kattamuri12","upvote_count":"1","content":"Selected Answer: C\ncorrect is C"},{"timestamp":"1726224540.0","poster":"RG10","comment_id":"1283120","content":"While Option C (splitting by \"at\") could work, Option D is the better answer because it provides a more direct and efficient method to extract the date. It avoids the extra step of splitting and discarding the time part, which is unnecessary when you only need the date for analysis.","upvote_count":"2"},{"content":"Selected Answer: C\nSplitting the column with the custom delimiter - at works well as the datatype is automatically recognized as Date","upvote_count":"3","poster":"nammm112","timestamp":"1725588720.0","comment_id":"1279289"},{"comment_id":"1274013","timestamp":"1724843760.0","upvote_count":"2","content":"Selected Answer: D\nthere is no need for the time, only for the date","poster":"patrup"},{"poster":"MMunib","upvote_count":"1","comment_id":"1272412","timestamp":"1724647920.0","content":"According to me c is correcct because D option will capture space in the 11th character and there should not be space in date."},{"poster":"Mustafa__","timestamp":"1723959360.0","comment_id":"1267940","upvote_count":"1","content":"Answer: D. Apply a transformation to extract the first 11 characters of the Logged column.\n\nReason:\n\nThe date part of the Logged column is contained in the first 11 characters (\"2018-12-31\"). To analyze the complaints by date and use the built-in date hierarchy in Power BI, you need to isolate the date from the time. By extracting the first 11 characters, you capture just the date part, which can then be converted to a Date data type. This allows Power BI to recognize it as a date and automatically generate a date hierarchy for analysis.\n\nOption A (extracting the last 11 characters) would give you only the time, not the date.\nOption B would not work directly because the column has both date and time, and the format includes additional text (\"at\").\nOption C (splitting the column) is more complex and unnecessary when extracting the first 11 characters achieves the goal efficiently."},{"timestamp":"1723638300.0","comment_id":"1265729","upvote_count":"1","content":"Selected Answer: C\nIf you get the first 11 characters then there should be a space and you need a trim operation before transform as date. The best option is to use \" at\" as delimiter (also in this case notice the space). So,\nC. Split the Logged column by using at as the delimiter is correct","poster":"rcaliandro"},{"timestamp":"1723550520.0","upvote_count":"2","content":"Selected Answer: D\nC and D both correct answers to extract the date, but after reading the question several times, in no case they mentioned the need of the time to proceed the analysis. So as an optimized solution i go with tranformation of the current column because i don't want an unused column (time) to be loaded in my model.","poster":"Rayen_BF","comment_id":"1265136"},{"comment_id":"1251935","poster":"Milan1999","upvote_count":"1","timestamp":"1721501760.0","content":"Technically, this is the wrong answer. If you select answer C, you will split the data by \"at\", but you must also convert the date into a date format to use the hierarchy. As mentioned in option A, using 11 characters to split the data might not work in case there is extra space in some of the rows. So, the right answer should be to extract the date using \"at\" as a custom delimiter to split the columns, then convert the split column to the date data type, and then use this column for visualization.","comments":[{"content":"More recent versions of PBI should auto detect the split columns as date and time types.","timestamp":"1733774640.0","upvote_count":"1","comment_id":"1324214","poster":"bdub1976"}]},{"comment_id":"1237463","content":"Selected Answer: C\nyou should split the logged column.","timestamp":"1719406260.0","upvote_count":"1","poster":"Migs123"},{"poster":"FadiAntar","content":"o analyze the complaints by the logged date and utilize Power BI’s built-in date hierarchy, you should apply a transformation to extract the first 11 characters of the Logged column. This will give you the date portion, which can then be used effectively for your analysis","upvote_count":"1","comment_id":"1236416","timestamp":"1719241620.0"},{"content":"c: as it converts its type to date as well.","comment_id":"1233880","poster":"alirazaidi","timestamp":"1718907840.0","upvote_count":"1"},{"upvote_count":"1","comment_id":"1232846","poster":"TheEngineer22","content":"Selected Answer: C\nRemoves the 'at', which in this case is not needed and unnecessarily increases the size of our model","timestamp":"1718796180.0"},{"timestamp":"1718365140.0","content":"Selected Answer: C\nTested. Only Option C will give a date format column instantly after the split. Extract 11 left character will still leave the column in TEXT format, need one extra step to convert it to date field.","comment_id":"1230460","poster":"HenryBiz","upvote_count":"2"},{"upvote_count":"1","content":"Hello all, I am voting C and not D because I am counting only 10 characters from teh left to extract 2018-12-31 and not 11, so extracting 11 will include a space at the end wont it? Though I tried it in PQE and after the split column applied step, it was changed to date....so I am not sure about the space. Though I understand that using split with \"at\" delimiter creates and extra column, but the case does not ask us to optimise the model . we must always go with what the question says not general PBI practices.","timestamp":"1717025940.0","poster":"F4FEY","comment_id":"1221328"},{"timestamp":"1716615780.0","poster":"e31df62","content":"Selected Answer: C\nC is correct","comment_id":"1218025","upvote_count":"2"},{"upvote_count":"3","comment_id":"1217252","poster":"SIH007","timestamp":"1716532920.0","content":"I think _Jay_ is right, C would be the best approach, you can split a column by a delimiter having more than 1 character. If you choose D, you still would have to transform the column to date before you can run the required analysis."},{"timestamp":"1715047140.0","content":"why does everyone choose C? the questions says \"Logged contains the date and time\" but you need to analyze by date, so we don't need an additional time column. D is enough","comment_id":"1207677","poster":"hypersam","upvote_count":"1"},{"timestamp":"1714929180.0","content":"Option D seems weird but it is logically correct. To avoid creating unnecessary 'time' column, you don't need to use split function. I would have been worried about data type, because a column structured as presented in the question would have wrong data type. But the provided answer stated that CSV has no data type. Strange, but I will go with it.","upvote_count":"1","poster":"Mrkay24","comment_id":"1206977"},{"timestamp":"1714874280.0","upvote_count":"1","poster":"Sheree_Data","comment_id":"1206749","content":"Microsoft Fabric states it is D!"},{"comment_id":"1205940","timestamp":"1714714140.0","upvote_count":"1","poster":"Pedre","content":"The correct answer is D. Although answers C and D may be correct, answer D is more optimal. When you \"Split\" columns, it adds a new column, in this case with the time. This causes us to add more data to the data model that we are not going to use."},{"content":"Selected Answer: C\nwe can split 2018-12-31 at 08:59. using Space (\" \") as delimiter and then will remove column where \"at\" is present.","timestamp":"1714195320.0","poster":"Deva_1","comment_id":"1202966","upvote_count":"1"},{"timestamp":"1713433080.0","content":"The correct answer is definitely C. \nIn the power query editor, you can customized split it by 'at'. Once you do it, it would result in giving you two column, one of them containing the date with the date datatype, and the other containing time with the time datatype. Once you apply and close it, in the power bi report, you can see that you have a date hierarchy.","comment_id":"1197827","poster":"shahrzadkhb","upvote_count":"1"},{"comment_id":"1197368","upvote_count":"2","content":"Wouldn't it be the first 10 characters you would want to extract? I believe D works, but you would need the additional step of changing the data type to Date, since you will be using a hierarchy.","poster":"9f73003","timestamp":"1713375420.0"},{"comment_id":"1185990","comments":[{"poster":"ab97776","timestamp":"1711861260.0","content":"I'm a newcomer to all things PowerBI. I attempted to create sample data and chose to implement option B and I encountered an error. It's possible there was an oversight on my part. Option D proved successful for me. Although I haven't experimented with option C, I anticipate it could potentially work based on its methodology.\n\nHowever, my reservation with option C lies in its inclusion of time data, which seems unnecessary for the analysis at hand. The initial question does not clarify the importance of retaining time information, leading me to believe that extraneous data, which does not directly support our analysis, could be omitted for efficiency. I keep getting hinted at that unnecessary data complicates analysis without adding value. Furthermore, as mentioned by a previous commenter, option D is not only suitable but also faster than C, which enhances its appeal for data processing tasks.","comment_id":"1186590","upvote_count":"2"}],"content":"B should be the answer, \"analyze the complaints by the logged date\".","timestamp":"1711789620.0","poster":"ykb_proudly_Indian","upvote_count":"2"},{"timestamp":"1711789500.0","content":"B should be the answer","upvote_count":"1","poster":"ykb_proudly_Indian","comment_id":"1185989"},{"comment_id":"1184815","upvote_count":"3","timestamp":"1711636560.0","comments":[{"timestamp":"1712041320.0","poster":"Uhoh","comment_id":"1187898","upvote_count":"1","content":"Agree, both work. But since you don't need time and need to remove the \"at\" and \"time\" columns it'll be more work."}],"poster":"Przemo__","content":"I checked both C and D work. \nDelimiter should be custom and \" at \" with spaces before and after. \nAs D is faster and you do not need time column, this is probably the correct answer."},{"timestamp":"1711096620.0","upvote_count":"3","poster":"Tharun_Idul","comment_id":"1179960","content":"Answer D is Correct.\nSince he is asking to extract only the date from that column, using \"at\" as a delimiter to split would separate the date and time into two different columns. This could result in unnecessary memory usage for the report."},{"upvote_count":"2","poster":"ggsss","timestamp":"1710948240.0","comment_id":"1178440","content":"Selected Answer: C\nc is the correct answer"},{"poster":"TrainingCA06","timestamp":"1710466980.0","content":"BE CAREFULL, QUESTION 10 AND 27ARE EXACTLY THE SAME, here the answer is D, but in 27 is C. incredible","upvote_count":"2","comment_id":"1173941"},{"poster":"moe33","comments":[{"content":"Yeah, you are correct that Coursera did include this question, and they said EXACTLY what you said, change data type to \"date\". That simply DOES NOT WORK. The answer should be \"C\", I even tested it and it does work. Use, \" at \", as a custom delimiter. The issue, which is correct for the test?","timestamp":"1713375120.0","upvote_count":"1","comment_id":"1197366","poster":"9f73003"}],"content":"This Question appeared in the Mock Exam provided in Coursera Power BI course and has B. Change the data type of the Logged column to Date as the correct answer. Even though I think it should be \"C\"","comment_id":"1167884","upvote_count":"2","timestamp":"1709806320.0"},{"timestamp":"1709105940.0","content":"C is the correct option \nbecause when i did it practically splitting on the basis of \"at\" would make it 2 columns the date column would automatically have date datatype and other time column will have time datatype and that to automatically \nThis would preserve our data and will not lead to dataloss as well hence C is the correct option in my opinion","poster":"ajinkya42069","upvote_count":"2","comment_id":"1161370"},{"comment_id":"1151988","poster":"Danialmellfoye","timestamp":"1708086780.0","upvote_count":"3","content":"Selected Answer: C\nI tried in my power bi editor and when I extract first 11 or 10 characters the datatype still in string format, but when I split with \"at\" the data type automatically changed to date and time\nSo C is my choice"},{"comment_id":"1142197","poster":"CandySays","content":"Selected Answer: C\n1) Split using \"at\"\n2) Trim and convert to date\n3) Delete the other column containing the time value","timestamp":"1707228480.0","upvote_count":"2"},{"upvote_count":"1","timestamp":"1705502580.0","poster":"cs3122","comment_id":"1125059","content":"C is the best option. But I wonder what Microsoft scores it as?"},{"poster":"INDEAVR","comments":[{"poster":"Danialmellfoye","upvote_count":"2","timestamp":"1708085940.0","comment_id":"1151981","content":"The actual length of the date is 10. so 11 from left also includes the space after date"}],"upvote_count":"2","timestamp":"1705480920.0","comment_id":"1124797","content":"If you choose C - 'as' delimiter you will get empty space after the 11 character or date. With D you get the exact amount of characters with no space after the date."},{"upvote_count":"4","poster":"momo1165","comment_id":"1112192","content":"both C and D work. the difference:\nC: once you split the string it will automatically change to date data type but you will also have the time column\nD however will require you to change the data type but will not have the time column.\nthe issue here is to know what is wanted by MS","timestamp":"1704224100.0"},{"timestamp":"1702411620.0","upvote_count":"2","comment_id":"1094920","poster":"Saluk_DE","content":"Selected Answer: C\nC: custom delimiter \"at\" and date field is automatically recognized, which is not so with answer D."},{"content":"which one is correct answer option C or D","timestamp":"1702361460.0","comment_id":"1094173","upvote_count":"1","poster":"8b24250"},{"content":"Selected Answer: C\nThe requirement is:\nYou need to be able to analyze the complaints by the logged date and use a built-in date hierarchy.\nA is incorrect because the result is \"31 at 08:59\".\nB is incorrect because the result is \"Error: We couldn't parse the input provided as a Date value.\"\nC provides a complete solution by splitting the column, the Split 1 result is automatically assigned with a Date Type.\nD is incorrect because the step provided is incomplete. You need to add \"Convert the data type to Date\" just like what was mentioned in answer A.","poster":"CookieMingkee","upvote_count":"7","timestamp":"1700943120.0","comment_id":"1080307"},{"poster":"gulutulu","upvote_count":"2","timestamp":"1699609800.0","content":"WE CAN GO WITH C OR D BOTH ARE RIGHT","comment_id":"1067135"},{"comment_id":"1065431","timestamp":"1699432560.0","poster":"Ryan_042","upvote_count":"2","content":"Selected Answer: D\nThe answer is D.\n- Well according to my trial, option D does not cause any error. I added a column by using Text.Middle([Logged], 0, 11), and when I change the column type to Date, no error occurs. \n - Answer C will operate almost the same as D (it missing the Changed type step) because it splits the Logged column into Logged.1 and Logged.2. \n+ Logged.1 contains the value \"2018-12-31 \", do you see the trailing space at the end of the text? it is the same as extracting the first 11 characters from Logged.\n+ Option C also removes the original Logged column, which might not be a good idea in analyses"},{"comment_id":"1063655","upvote_count":"1","timestamp":"1699260720.0","content":"Selected Answer: C\nSplit the Logged column by using \"at\" as the delimiter.","poster":"TrustMyAnswers"},{"content":"Selected Answer: C\nC","poster":"slu239","comment_id":"1059288","timestamp":"1698800400.0","upvote_count":"1"},{"upvote_count":"1","content":"ChatGPT says answer D is correct","poster":"oreshetnik","comments":[{"content":"Oh no.. Why ChatGpt told me B?????","comment_id":"1102308","upvote_count":"2","poster":"bbshu0801","timestamp":"1703150100.0"}],"timestamp":"1698343260.0","comment_id":"1054817"},{"content":"Selected Answer: C\nPower Query allows 'at' as Delimiter, so the answer is C.","upvote_count":"1","poster":"sagar_1993","timestamp":"1698110280.0","comment_id":"1052395"},{"content":"May be the test wants us to make a decision between having two columns (C) and having a column with an extra space (D). C is not good solution compare two D. Because with C we increase cardinality (more unique values in data) but with D we gonna have just 11th character which will be same for whole column.","timestamp":"1697900400.0","comment_id":"1049584","poster":"Zarina_H","upvote_count":"1"},{"comment_id":"1043822","timestamp":"1697335140.0","content":"Selected Answer: C\nJust tried all the options in Query Editor. \nSplit the Logged column by using at as the delimiter - is the best approach since it will automatically change the first split column to Date type\nApply a transformation to extract the first 11 characters of the Logged column - This is wrong - Firstly, it should take only first 10 characters. Secondly, the column type is still unchanged.","upvote_count":"1","poster":"Kish1604"},{"upvote_count":"3","comment_id":"1041230","timestamp":"1697067300.0","poster":"IrynaVilner","content":"Answer D. According to the question we really don't need time as a separate column, so we can only extract first 11 characters for date, and then using updated date column build hierarchy."},{"comment_id":"1023999","upvote_count":"2","timestamp":"1696341600.0","content":"How is this question related to Power BI?","poster":"Dnw_hhnn_111"},{"upvote_count":"1","timestamp":"1696037640.0","comment_id":"1021195","content":"Answer C is the best because if you split using the space will create 3 columns 1) date 2) at 3) hour","poster":"wally91"},{"comment_id":"1017410","upvote_count":"1","poster":"MagM","content":"My choice is D. csv file has no columns, need to transform the 'logged' into column and extract first 11 characters (includes the white space before '2') which tells the year and day.","timestamp":"1695707040.0","comments":[{"comment_id":"1049577","poster":"Zarina_H","timestamp":"1697899920.0","content":"where from we can know that there is a white space before two?","upvote_count":"1"}]},{"comment_id":"1014832","content":"Selected Answer: C\nbest solution","timestamp":"1695466320.0","poster":"poli361","upvote_count":"1"},{"poster":"Posi","timestamp":"1693927380.0","comment_id":"999637","upvote_count":"3","content":"Selected Answer: C\nI tested it and C is the correct answer"},{"comment_id":"998753","timestamp":"1693850940.0","content":"The correct answer is B.\nTo analyze the complaints by the logged date and use a build-in date hierarchy in Power BI, we should \"Change the data type of the logged column to date\". Because the logged column contains the date and time in the \"2018-12-31 at 08:59\" format. To use it as a date for analysis and to create a build-in date hierarchy, we need to change its data type to date.","poster":"Igetmyrole","upvote_count":"2"},{"comments":[{"content":"You know that with A, you will end with \"2018-12-\" and \"31 at 08:59\".","poster":"Kundelp","upvote_count":"4","comment_id":"992915","timestamp":"1693297320.0"}],"content":"A. Apply a transformation to extract the last 11 characters of the Logged column and set the data type of the new column to Date.\nOption B is not the correct choice because directly changing the data type of the Logged column to Date won't work without proper formatting due to the \"at\" text in the middle of the string.\nOption C is not necessary because there's no need to split the Logged column since you can extract the necessary date information without splitting.\nOption D is also incorrect because you need the date information, not the time, and extracting the first 11 characters would result in the \"2018-12-31\" part of the string, which is the date information you need. However, it's better to extract the last 11 characters to avoid any potential issues with the \"at\" text in the middle of the string.\nSo, the correct choice is A.","upvote_count":"2","poster":"Mujadidi","timestamp":"1693231320.0","comment_id":"992263"},{"content":"c is correct answer","poster":"datawithabhi","upvote_count":"1","timestamp":"1692021240.0","comment_id":"980845"},{"comment_id":"980581","poster":"SinaRamzi","upvote_count":"1","timestamp":"1691999040.0","content":"If we put \"at\" as a delimeter, we will have 2 columns as the date. one for day and the other for hour....what is the use of it?"},{"comment_id":"974219","timestamp":"1691353920.0","poster":"ApacheKafka","upvote_count":"3","content":"Selected Answer: C\nTested. It is 100% C ✔✔✔✔✔✔✔✔✔"},{"content":"Overall, option C provides a clear separation of the date and time components, allowing for easier date-based analysis. Additionally, Power Query's ability to automatically detect date formats and assign the correct data type to the new column simplifies the process. If needed, you can manually adjust the data type in Power Query after the split.","poster":"ApacheKafka","upvote_count":"1","comment_id":"974216","timestamp":"1691353620.0"},{"timestamp":"1690056780.0","upvote_count":"12","comment_id":"959808","content":"Selected Answer: C\nI tested this and the best answer is C. Ideally, C would also include changing the data type to date, but this is the best option.\nA returns \"12-31 at 08\" and then when you change to date there is an error.\nB causes an error.\nC gives \"12/31/2018\" with no additional whitespace.\nD gives \"2018-12-31 \" which has an extra space.","poster":"TheTman"},{"upvote_count":"3","timestamp":"1688485260.0","poster":"ET_phone_home_son","comment_id":"942941","content":"Selected Answer: D\nQuestion says you need to analyze by DATE - transform to extract date value suffices, though TRIM is needed to remove terminal whitespace character from extracted date string"},{"content":"Extracting is the best way as the question says analyse by Date only, not Date and time. Therefore, no need to split the column using delimiter and no need to keep the time.","poster":"Kushal_P","timestamp":"1687821240.0","upvote_count":"5","comment_id":"934856"},{"timestamp":"1687337940.0","comment_id":"929240","poster":"arnoh","content":"Selected Answer: C\nSplitting by using at as the delimiter gives the only desired result. The formatting for single digit months, days isn't mentioned. But if it uses the shorter notation i.e.; 2018-7-18, you would extract the incorrect amount of characters","upvote_count":"2"},{"upvote_count":"1","timestamp":"1687183920.0","comment_id":"927588","content":"Splitting the column is not the best approach since you will need to format the text as \"Date\" afterwards. If you use extract, there is no need to format. The data will already be formatted as Date","poster":"JonDave"},{"timestamp":"1686865740.0","comment_id":"924604","poster":"JonDave","content":"how about split using a space as the delimiter. delete the unnecessary columns created by the split. make sure data format is \"date\"","upvote_count":"1"},{"timestamp":"1685953140.0","poster":"vat4444","content":"Literally tested this out. Answer C, Splitting by using \"at\" works perfectly.\nTry this in the editor if you have doubts,\n\n= Table.SplitColumn(#\"Changed Type1\", \"Date\", Splitter.SplitTextByDelimiter(\"at\", QuoteStyle.Csv), {\"Date.1\", \"Date.2\"})","upvote_count":"3","comment_id":"915211"},{"upvote_count":"1","content":"You cant use at as the delimiter because at is multiple characters","poster":"Tiger9","comment_id":"900238","timestamp":"1684332600.0"},{"comment_id":"886205","poster":"Shalaleh","timestamp":"1682943180.0","content":"Selected Answer: C\nby Spilt we do not lose any information","upvote_count":"1"},{"comment_id":"875273","timestamp":"1681965240.0","upvote_count":"2","poster":"UlyUkr","content":"If you extract the 11 characters you get the date and a space. So you actually need to extract 10 characters. \nIf you use the at delimiter then you end up with 2 columns, date and time. Time was not required in the task. Only the date. But because 11 characters is not correct I vote for the delimiter option, answer C."},{"comment_id":"870749","timestamp":"1681545420.0","content":"Selected Answer: D\nYou are correct. Thank you for pointing that out. In Power BI, the delimiter used for splitting a column must be a single character. Therefore, Option C is not a valid solution.\nOption D is correct","comments":[{"content":"Sorry ,i tried 'at' is working .I believe option c is not correct because it not clearly mentioned to use before or after delimitator . So ,direct option it works with D.","upvote_count":"2","timestamp":"1681606500.0","poster":"newGodking","comment_id":"871394","comments":[{"upvote_count":"2","content":"It's not D. D leaves a whitespace while option C doesn't.","poster":"TheTman","comment_id":"959810","timestamp":"1690056900.0"}]}],"upvote_count":"2","poster":"newGodking"},{"timestamp":"1681527540.0","comment_id":"870586","upvote_count":"1","poster":"rddghfhghjlok","content":"I tried it and Power BI automatically separates the column in 3 columns , Date, Text and Time.\nSo none of the options are correct."},{"upvote_count":"2","comments":[{"upvote_count":"1","comment_id":"866573","timestamp":"1681154340.0","content":"The Date Column has only 10 characters. If you take the first eleven, you get something different than a date","poster":"shmmini"}],"content":"Selected Answer: D\nAnswer D is best approach as this will give us only date column which we needed unlike couple of columns which we get from split by delimeter option.\nAlso extracting first n characters is faster than splitting by delimeter","timestamp":"1681103460.0","poster":"PradeepReddyKancharla","comment_id":"866006"},{"poster":"ilk777","content":"D\n\nResult from C is the same but D has better performance because counting characters is faster than finding delimiter.","upvote_count":"1","timestamp":"1680522660.0","comment_id":"859866"},{"comment_id":"856716","poster":"SanaCanada","comments":[{"comment_id":"919938","timestamp":"1686390180.0","content":"The date part is at the front not at the back so can't be \"the LAST 11 characters\".","poster":"LeeTheRed","upvote_count":"2"}],"timestamp":"1680247800.0","content":"Selected Answer: A\nThe correct answer is A\n\nA. Apply a transformation to extract the last 11 characters of the Logged column and set the data type of the new column to Date.\n\nExplanation: To analyze the complaints by the logged date and use a built-in date hierarchy, we need to transform the Logged column to a date data type. The data in the Logged column is in the format \"2018-12-31 at 08:59\", which is not in a date data type. Therefore, we need to apply a transformation to extract only the date part, which is the last 11 characters of the Logged column. Then we can set the data type of the new column to Date, which will allow us to use the built-in date hierarchy in Power BI. Option A is the correct choice for this scenario.\n\nNo confusion, and no need to discuss further","upvote_count":"4"},{"upvote_count":"1","timestamp":"1680103680.0","comment_id":"854586","content":"I just tried this out. I created a one column csv file and imported it into PBI Desktop. It imports it as three columns. Date as column 1, at as column 2 and time as column 3. \n2023-01-01 at 04:34\n2023-01-02 at 05:00\n2023-02-02 at 2:00\nAnd they are in the correct format, Date, Text and Time lol... was this a trick question?","poster":"voodimac"},{"upvote_count":"4","content":"ChatGPT says totally different:\n\nThe correct answer is B. Change the data type of the Logged column to Date.\n\nBy changing the data type of the Logged column to Date, Power BI will automatically recognize it as a date/time column and will allow you to use the built-in date hierarchy.\n\nOption A is not correct because extracting only the last 11 characters of the Logged column will not provide enough information for Power BI to recognize it as a date/time column.\n\nOption C is also not correct because splitting the Logged column by using \"at\" as the delimiter will result in two separate columns: one containing the date and the other containing the time. This will not allow Power BI to recognize the column as a date/time column and will not provide the built-in date hierarchy.\n\nOption D is also not correct because extracting only the first 11 characters of the Logged column will not provide enough information for Power BI to recognize it as a date/time column.","comments":[{"poster":"LouStar2","timestamp":"1685696340.0","comment_id":"912663","content":"Well if ChatGPT says it then it must be true","upvote_count":"1"},{"comment_id":"852925","timestamp":"1679987580.0","poster":"letiwang","upvote_count":"1","content":"Just tried option B in Power BI desktop and it actually works easily."}],"poster":"pepix74","comment_id":"852057","timestamp":"1679917320.0"},{"comment_id":"848338","poster":"DUVANES","timestamp":"1679583180.0","upvote_count":"1","content":"Selected Answer: C\nC. Divida la columna Registro utilizando at como delimitador."},{"timestamp":"1679044080.0","comment_id":"841827","poster":"quxxy","upvote_count":"1","content":"Correct answer is \"D\" because we need to think about performance and size of dataset... Separating with delimiter \"at\" or whatever provides growth of dataset by addition column..."},{"content":"If we use ”Extract” function tje time value will be lost. If we use split the time will be addet as a new column.","upvote_count":"1","timestamp":"1678911840.0","comment_id":"840298","poster":"PetJoh422"},{"content":"If we extract 11 characters, wouldn’t we have a ” ” space at the end of the date? We cant build a relationship on that… why not use ” at ” as delimiter?","timestamp":"1678911660.0","upvote_count":"3","poster":"PetJoh422","comment_id":"840294"},{"timestamp":"1678701360.0","content":"Both C and D are correct.\nYou can use one or more characters as a delimiter (I tried), so \"at\" is valid as a delimiter. C is correct\n\n Getting the first 11 characters as the date is a correct approach as well.","poster":"Pinha","comment_id":"837819","upvote_count":"3"},{"timestamp":"1678508940.0","poster":"PowerBiDAXSQL","comment_id":"835657","upvote_count":"2","content":"Selected Answer: C\nShould Be C. Datacamp taught me this, I tested and it works using this Method."},{"timestamp":"1678508880.0","comment_id":"835656","poster":"PowerBiDAXSQL","upvote_count":"2","content":"I really don't like how I can use many different methods to get the same result, but the exam only accepts one. If it works it works. Should be C. Thats what Datacamp Taught me."},{"content":"Extrahiere das Datum, also die ersten 11 Zeichen.\nCSV-Dateien haben keine Datentypen.\nHinweis: Eine CSV-Datei ist eine Datei mit kommagetrennten Werten, die es ermöglicht, Daten in einem tabellarischen Format zu speichern. CSVs sehen aus wie eine Tabellenkalkulation für Gartensorten, aber mit einer . csv-Erweiterung. CSV-Dateien können mit den meisten Tabellenkalkulationsprogrammen wie Microsoft Excel oder Google Spreadsheets verwendet werden. Antwort D ist somit Korrekt","timestamp":"1678283700.0","comment_id":"833019","poster":"Mutti","upvote_count":"1"},{"upvote_count":"1","timestamp":"1677833520.0","content":"Answer A\nTo use the built in date hierachy we need a date type field so we need to extract the text that can be converted to date then change type to date","comment_id":"827797","poster":"Neilsy"},{"timestamp":"1677635340.0","comment_id":"825466","poster":"srikanth923","upvote_count":"1","content":"The answer is C. To separate a column into two new columns based on a specific character or symbol, we can use the \"at\" function as the delimiter in Power BI.\n\nOnce the column is split, Power BI will automatically detect the data type for the new columns. In this case, the two new columns will likely be \"date\" and \"time\". If Power BI detects the data type incorrectly, we can manually change it.\n\nNote: you must use a custom delimiter and set it to \"at\" because delimiter will only accept a single character as input"},{"timestamp":"1676309160.0","comment_id":"807645","upvote_count":"1","content":"Answer C works. Tested in Power BI. We can select a custom delimiter \"at\", it will split columns accordingly","poster":"Bidhi"},{"comments":[{"upvote_count":"2","content":"a is last 11 ch its not correct","timestamp":"1678870800.0","comment_id":"839714","poster":"1sourabhpatel1"}],"upvote_count":"1","comment_id":"806242","content":"I've just tested A and it works. If I don't apply the date format it just a text","timestamp":"1676199780.0","poster":"pisanoagus"},{"timestamp":"1676094120.0","poster":"AFarag","upvote_count":"2","content":"Selected Answer: D\ndelimiter uses only one character, so \"at\" is not valid\nso left function to get the first 11 characters as date \"\"","comment_id":"805017","comments":[{"upvote_count":"3","content":"no , you can use at as a delimiter using custom delimiter","poster":"1sourabhpatel1","comment_id":"839711","timestamp":"1678870740.0"}]},{"content":"Did LAB>100% correct Answer is C. \nIn PBI desktop>make a table(just one column) >>click enter data>Logged column name>enter 2018-12-31 at 08:59>click edit>PQ editor> split column> delimiter> custom> at>OK>>see two column Logged1 with date and data type is date(automatic)\nAnd Logged2 with time data type is time PBI generated. SO\nC is 100%correct> Split the Logged column by using at as the delimiter.","comment_id":"804298","poster":"skaha","upvote_count":"5","timestamp":"1676032800.0"},{"upvote_count":"2","content":"Selected Answer: C\nC - use at as delimiter so it will split column to date and time parts","comment_id":"774631","poster":"ewelaela","timestamp":"1673624940.0"},{"content":"C it didn't mention before or after delimiter, D is correct","comments":[{"timestamp":"1678786140.0","upvote_count":"1","content":"you mean \"left-most\" or \"right-most\"?","poster":"cabbagepie","comment_id":"838689"}],"upvote_count":"3","poster":"hassan2383","comment_id":"771294","timestamp":"1673346480.0"},{"upvote_count":"1","timestamp":"1672781580.0","content":"Selected Answer: C\nCorrect answer is C","comment_id":"765079","poster":"kiwi69"},{"content":"Os arquivos csv (Comma-separated values) separam valores com virgula e não tem tipo de dados.\nEntão a resposta C faz muito sentido.\nC. Divida a coluna Logged usando at como delimitador.","poster":"PsgFe","comment_id":"752751","upvote_count":"1","timestamp":"1671656400.0"},{"comment_id":"748967","poster":"LucianaFS","upvote_count":"3","timestamp":"1671371520.0","content":"Selected Answer: C\nThe answer is C, I've tested. Split column with at as delimiter recgonize automatically in a date and a hour column."},{"poster":"prad_raj1","content":"Answer D is wrong. It should be A or C","upvote_count":"2","comment_id":"744648","timestamp":"1670984940.0"},{"comment_id":"743876","content":"Selected Answer: C\nAfter testing this in PowerBI - only splitting with a delimiter automatically changes the column type transforms automatically into a date column. By extracting the first 11 (or 10, if you don't want the \" \" at the end), the column type does not automatically change.","upvote_count":"3","timestamp":"1670926560.0","poster":"ThomasDB"},{"poster":"KarthikKumarK","comment_id":"737471","upvote_count":"1","timestamp":"1670392200.0","content":"Selected Answer: C\nIf we take 10 characters from left, Then D also correct.\n\nThanks\nKarthik"},{"upvote_count":"5","poster":"golden_retriever","content":"I'm new to this site. Why does the answer has not yet corrected? It should be C","timestamp":"1670292060.0","comment_id":"736467"},{"comment_id":"736290","timestamp":"1670273220.0","poster":"rajkoma","upvote_count":"1","content":"Both C and D, still makes the split value as Text.In that case,A should be the answer."},{"upvote_count":"2","poster":"Pauwels","timestamp":"1669563660.0","comment_id":"728388","content":"It is C because if it was D then the best Answer should have been A. Cause we must change the time to Date. So it is C."},{"poster":"Lewiasskick","comment_id":"727089","upvote_count":"2","timestamp":"1669411560.0","content":"A, is correct, the essential step is to change the type to date."},{"poster":"Analysis","timestamp":"1669353840.0","content":"I have tested the scenario, Created the column name as logged complains and put the sample data as 2018-12-31 at 08:59 and save the file with CSV.\nImported the file with get data it opens a window and shows the table with three column headers. Second column consist of Delimiter. Put space as delimiter you will get the date as 12/31/2018 and when you transform the data in power query it shows data type as Date.\nTherefore, answer is C.","comment_id":"726402","upvote_count":"3"},{"content":"Selected Answer: C\nI think that the catch is that extracting the first 11 characters gives you the date plus a space character (the actual date is 10 characters). So you get \"2018-12-31 \". And that leaves answer C as the best answer.","upvote_count":"4","poster":"Hoeishetmogelijk","comment_id":"721307","timestamp":"1668779400.0"},{"timestamp":"1668727680.0","poster":"Pauwels","content":"Selected Answer: C","comment_id":"720956","upvote_count":"1"},{"comment_id":"720751","timestamp":"1668709800.0","upvote_count":"2","poster":"Hoeishetmogelijk","content":"Also the split option automatically transforms the first column to date format, where extracting the first 11 or 10 characters doesn't."},{"upvote_count":"2","content":"I think that the catch is that extracting the first 11 characters gives you the date plus a space character (the actual date is 10 characters). So you get \"2018-12-31 \". And that leaves answer C as the best answer.","poster":"Hoeishetmogelijk","comment_id":"720732","timestamp":"1668709080.0"},{"upvote_count":"1","content":"I would split at the \"at\" delimiter instead of taking first 11 characters because what if the day or the month is a single digit. To be safe the delimiter option seems best.","poster":"scotchtapebunny","timestamp":"1668621180.0","comment_id":"719881"},{"content":"Selected Answer: C\nC - OK","poster":"Gabrielmacedo","upvote_count":"1","timestamp":"1667954940.0","comment_id":"714175"},{"comment_id":"714144","timestamp":"1667946300.0","upvote_count":"1","content":"An automatically generated date hierarchy in power BI includes year, quarter, month,week,day. In the world of programming, date is different to time. This is why D is the answer.","poster":"Pocu"},{"timestamp":"1666824900.0","poster":"rnjr7","upvote_count":"1","content":"Tested\nC works","comment_id":"705054"},{"comment_id":"703955","content":"Selected Answer: C\ntested here, split works fine","upvote_count":"2","timestamp":"1666708980.0","poster":"Churato"},{"comment_id":"703151","poster":"NotMeAnyWay","timestamp":"1666623900.0","content":"Selected Answer: C\nThe answer is C:\n\nSimply create a custom table in Power Query, enter the date shown in the question into a column called Date, and then Split it by a delimiter. No need for spaces on either side of \"at\" Power BI takes care of the rest:\n\n= Table.SplitColumn(#\"Changed Type\", \"Date\", Splitter.SplitTextByDelimiter(\"at\", QuoteStyle.Csv), {\"Date.1\", \"Date.2\"})\n\nIt will even automatically change the type to Date:\n\n= Table.TransformColumnTypes(#\"Split Column by Delimiter\",{{\"Date.1\", type date}, {\"Date.2\", type time}})","upvote_count":"3"},{"upvote_count":"1","content":"C is correct, if D is to extract 10 characters, then D will be correct.","comment_id":"693474","poster":"Ryanmumu","timestamp":"1665621420.0"},{"timestamp":"1665280260.0","poster":"qiqiqibiu","upvote_count":"1","content":"Selected Answer: D\nI tried C in my excel, it turns out D is true. Clearly most of us thought C(split)&D(transform) are both reasonable. \nBut here's the thing------delimeter can only use one letter/delimeter, while Answer C \"Split the Logged column by using [at] as the delimiter\", which is not possible to use \"at\" to split. But it's ok to split by using \"a\".","comment_id":"689847","comments":[{"upvote_count":"2","content":"It's ok to split by using \"at\".\nSplit by using \"at\", you will get a date column\nUsing option D, you will get a text column then need another step to convert from text to date.","comment_id":"692310","timestamp":"1665510540.0","poster":"PinkZebra"},{"timestamp":"1665554100.0","comment_id":"692704","upvote_count":"1","content":"In excel, yes. Splitting by at doesnt work. But the question is, are we using Excel or Power query in this scenario? Not mentioned here.","poster":"Dovoto"}]},{"comment_id":"687225","upvote_count":"3","comments":[{"timestamp":"1665250920.0","poster":"NevilleV","comment_id":"689554","content":"D wont work","upvote_count":"1"},{"content":"can't agree any more. they even don't have a correct&clear answer sheet....","poster":"qiqiqibiu","upvote_count":"2","timestamp":"1665278640.0","comment_id":"689815"}],"timestamp":"1665003840.0","poster":"lukelin08","content":"Selected Answer: C\nC and D are valid. They both will automatically update the date column to a 'date' data type. However 'C' is the more complete and proper solution as it would also leave the time column as a 'time' data type automatically and would result in a more proper data model. Stupid Microsoft and their ambiguous questions. Im sick of tired of questions with two possible answers, thats not testing knowledge, its just trying to catch people out. Questions should have answers with only one clear possibility!"},{"content":"Selected Answer: C\nC should be the right answer","timestamp":"1664862780.0","upvote_count":"2","comment_id":"685946","poster":"Ry7anZZ"},{"poster":"Manikom","timestamp":"1663740600.0","upvote_count":"4","comment_id":"674837","content":"Selected Answer: C\nA is wrong since you extract last 11\nB is wrong cause it retrieves an error when changing type without transformation\nC and D achieve same results but with one difference: if you split through a delimiter the resulting columns have data type automatically updated (date type and time type)\nIf you extract first 11 characters from a text type column you will still have a text type column as a result.\nI would go with C as you also need to build hierarchy"},{"content":"C seems to be correct answer. For, date we need First 10, but option is First 11.","comment_id":"674771","poster":"saurinkhamar","upvote_count":"2","timestamp":"1663734000.0"},{"poster":"blito123","upvote_count":"3","content":"D is correct, Hour is not necessary in the question.","timestamp":"1663686060.0","comment_id":"674289"},{"timestamp":"1663422720.0","comment_id":"671575","upvote_count":"1","poster":"zerone72","content":"I believe that both C and D are correct as you don't need to keep the hour for your analysis. You just need to analyse the complaints by logged date. However, in both C and D, you'd need to convert the new column to date in order to build a date hierarchy (the \"Auto-DateTime\" setting allows automatically creating a date-hierarchy on a date column)"},{"upvote_count":"1","content":"Selected Answer: C\nc is correct","comment_id":"669575","poster":"alosh","timestamp":"1663225560.0"},{"content":"Answer C is the right answer","timestamp":"1663162440.0","upvote_count":"1","poster":"elma_qhor_19","comment_id":"669056"},{"poster":"ThariCD","upvote_count":"1","timestamp":"1663135560.0","comment_id":"668651","content":"Selected Answer: C\nShould split the column by delimiter \"at\" into a Date and Time and then set the column type to Date"},{"poster":"_Jay_","comment_id":"663342","upvote_count":"1","content":"Answer C is best approach\nSplit the Logged column by using at as the delimiter.","timestamp":"1662624060.0"},{"timestamp":"1662460200.0","content":"Selected Answer: A\nIn Power BI you can add a new column with only the first 11 characters and then you do have the option to set the type to Date on that column, maybe the question is just unclear but it does seem to be possible to set the type on a .csv in the Power Query Editor...","poster":"ThariCD","upvote_count":"1","comment_id":"661091","comments":[{"comments":[{"upvote_count":"1","comment_id":"668650","content":"You're right, I think it should be C indeed, splitting the column by at as the delimiter.","poster":"ThariCD","timestamp":"1663135500.0"}],"content":"A is talking about the last 11 characters. That wouldn’t extract the date into a new column.","poster":"June15","upvote_count":"2","timestamp":"1662715440.0","comment_id":"664390"}]},{"comment_id":"661022","upvote_count":"4","content":"C is the best approach \nSplit with \"at\" Using Custom delimiter","poster":"emmanuelkech","timestamp":"1662454440.0"}],"answer":"C","question_id":2,"unix_timestamp":1662454440,"url":"https://www.examtopics.com/discussions/microsoft/view/80557-exam-pl-300-topic-1-question-10-discussion/","isMC":true,"answer_description":"","timestamp":"2022-09-06 10:54:00","topic":"1","answer_ET":"C","answer_images":[],"choices":{"D":"Apply a transformation to extract the first 11 characters of the Logged column.","A":"Apply a transformation to extract the last 11 characters of the Logged column and set the data type of the new column to Date.","B":"Change the data type of the Logged column to Date.","C":"Split the Logged column by using at as the delimiter."}},{"id":"hlJGhhqvoX6g8Wckrhrf","answer_description":"","answers_community":["DE (78%)","11%","9%"],"timestamp":"2022-09-06 13:14:00","isMC":true,"url":"https://www.examtopics.com/discussions/microsoft/view/80588-exam-pl-300-topic-1-question-11-discussion/","question_images":[],"discussion":[{"content":"Selected Answer: DE\nWe can import an excel file from multiple connectors (excel workbook, folder, web, sharepoint) but if we must refresh the data from the service with no gateways then We must use web and sharepoint connectors","comment_id":"682808","upvote_count":"89","poster":"Fer079","comments":[{"timestamp":"1742930880.0","upvote_count":"1","comment_id":"1410144","poster":"Kikong75","content":"and why not Excel Workbook?: I think that this connector allows you to connect directly to an Excel file stored in OneDrive for Business. While some may argue that it could create a \"local copy,\" this connector actually connects to the file in the cloud and allows you to refresh the dataset (with scheduled refreshes) in PowerBI.com without the need for a gateway."},{"upvote_count":"1","comment_id":"1339855","poster":"gstep","timestamp":"1736762520.0","content":"A, D and E are valid answers, which two are tem more accurate?"},{"timestamp":"1713376740.0","comment_id":"1197378","upvote_count":"2","poster":"9f73003","content":"It would depend if there is authentication involved with the SharePoint folder or the Web address, what if they are using basic auth? Anyway, either of the answers, a,b,c,d all offer difficulty for me to answer as the correct one. So, I guess it is which is the most correct?"},{"comment_id":"886209","content":"but OneDrive is cloud and we do not need a gateway.","upvote_count":"4","timestamp":"1682943420.0","poster":"Shalaleh"},{"poster":"NevilleV","comment_id":"694629","timestamp":"1665739620.0","upvote_count":"2","content":"Try it. D and E won't work. Its looking for a URL","comments":[{"content":"I tried both and they work perfectly, and of course, you need the path (in this case the URL of the excel file on One Drive) of the file, so I don´t see the problem you say...","upvote_count":"18","poster":"Fer079","comment_id":"696959","timestamp":"1665985980.0"},{"comments":[{"poster":"GuerreiroJunior","timestamp":"1672200240.0","comment_id":"759342","upvote_count":"5","content":"Agreed KobeData"}],"content":"Works just fine, this is how you do it :)","upvote_count":"15","poster":"KobeData","comment_id":"709944","timestamp":"1667409000.0"}]}],"timestamp":"1664466000.0"},{"content":"Selected Answer: DE\nA, B, C: wrong! Would work technically, but the connection will be only to the local copy of the file, no refresh from the online version stored on OneDrive\nD: correct, but more complicated than option E\nE: correct, this is the best option to import from OneDrive","timestamp":"1664871720.0","upvote_count":"37","poster":"fred92","comment_id":"686026"},{"poster":"Kbo05","timestamp":"1741972800.0","comment_id":"1395663","content":"Selected Answer: AB\nExcel/Workbook, Text/CSV","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: DE\nFor people who are using chat GPT, if you ask another question: which connectors allow refresh from powerbi.com, it will show you that if the file is on OneDrive, we should connect it via SharePoint, not a direct support. It answered A because it is a possibility and GPT does not always consider all the logic.","comment_id":"1352972","poster":"NgocPham","timestamp":"1738931400.0"},{"poster":"Ajani161","content":"Selected Answer: AE\nIt doesn’t say Sharepoint folder. It explicitly says OneDrive.","upvote_count":"2","comment_id":"1350541","timestamp":"1738512720.0"},{"poster":"b2775a4","timestamp":"1738288200.0","comment_id":"1349350","upvote_count":"3","content":"Selected Answer: AD\nCorrect Answers:\nA. Excel Workbook: This is a direct and commonly used connector for importing Excel files into Power BI. It supports OneDrive integration and allows scheduled refreshes on powerbi.com.\nD. SharePoint Folder: If the file is stored in a OneDrive folder, which is backed by SharePoint in the backend, the \"SharePoint Folder\" connector can be used to access it. This method is also refreshable.\nExplanation of Other Options:\nB. Text/CSV: Not applicable for Excel files unless the file is exported as a .csv. Even then, it won't support refresh like the Excel connector.\nC. Folder: Used for combining files in a folder but not specifically for accessing a single Excel file in OneDrive.\nE. Web: Can be used if the file is accessible via a web URL (e.g., a public link), but this is not optimal or commonly used for OneDrive-stored files."},{"content":"Selected Answer: AD\nSince the Excel file is stored in a OneDrive folder, you need a connector that allows cloud-based access and scheduled refresh in Power BI Service.\n\n✅ A. Excel Workbook (Correct)\nThis is the most direct and recommended way to connect to an Excel file stored in OneDrive.\nIt allows scheduled refresh in Power BI Service.\n✅ D. SharePoint Folder (Correct)\nOneDrive for Business is built on SharePoint, so the SharePoint Folder connector can also be used.\nThis is useful if you need to access multiple files in a OneDrive folder at once.\nIt supports scheduled refresh in Power BI Service.","comment_id":"1349085","upvote_count":"2","poster":"Fatima300","timestamp":"1738245060.0"},{"content":"Selected Answer: AE\nI tested this and answer is confirmed A and E. Question is what connectors, Excel workbook is a clear choice as stated on the question \"Microsoft Excel file in a Microsoft OneDrive folder\" when you select the 'excel workbook' connector, it grabs the file from one Drive. And E is the other clear answer (Web) connector, on the excel file , go to file>Info>copy path. Use the path and paste it on the URL section and I was able to retrieve and do a refresh. Nothing on the question that states excel is stored on a sharepoint folder so it is A and E for me.","timestamp":"1736287560.0","poster":"Odidepse","comment_id":"1337721","upvote_count":"1"},{"timestamp":"1734892260.0","upvote_count":"2","comment_id":"1330518","content":"Selected Answer: AD\nTried Option A and it works. When you have OneDrive syncing on your machine then this option is simple and Straight forward.\n\nD: Onedrive for business is built on SharePoint Online, hence you can access Ondrive files from SharePoint folder connector","poster":"mdnaseershah"},{"poster":"jaume","comment_id":"1312591","timestamp":"1731668460.0","upvote_count":"1","content":"I would vote for A and D options.\nExcel connector looks like requiring local gateway and web option in Semantic Model (former Dataset) I just tried is offering \"Web API\" and \"Web Page\" available options which doesn't look correct to me"},{"poster":"SanaCanada","upvote_count":"4","timestamp":"1727943180.0","comments":[{"timestamp":"1707230820.0","comments":[{"comment_id":"1347436","poster":"masto71","timestamp":"1737988020.0","upvote_count":"1","content":"The video is two years old, and it seems that Microsoft has resolved the issue since then. I tested it, and it worked in my case."}],"content":"https://www.youtube.com/watch?v=CYSMZxaXNLk","poster":"CandySays","comment_id":"1142268","upvote_count":"4"}],"comment_id":"856753","content":"Selected Answer: AD\nCorrect Answer A and D\n\nA. Excel Workbook\nD. SharePoint folder\n\nYou can use the \"Excel Workbook\" connector to connect to the Excel file stored in OneDrive and import it into a Power BI dataset. This connector allows you to select the OneDrive folder where the file is located and specify the file name.\n\nYou can also use the \"SharePoint folder\" connector to connect to the OneDrive folder and import the Excel file into a Power BI dataset. This connector allows you to specify the URL of the OneDrive folder and navigate to the Excel file within the folder.\n\nUsing either of these connectors ensures that the dataset can be refreshed in Power BI, as the connection to the OneDrive folder will remain active even if the Excel file is updated or moved within the folder.\n\nNo confusion, and no need to discuss further"},{"content":"I believe A & C are the right answers. I have my excel file in Onedrive and I connect to the dataset through this means and refresh my dashboards. We can import excel files directly from Onedrive which is cloud. gateway connection isnt needed.","comment_id":"1287278","poster":"T_bone","timestamp":"1726912440.0","upvote_count":"1"},{"comment_id":"1279290","timestamp":"1725588780.0","poster":"nammm112","content":"Selected Answer: DE\nschedule refresh without a gateway","upvote_count":"1"},{"timestamp":"1724157900.0","comments":[{"upvote_count":"1","comment_id":"1285691","timestamp":"1726658820.0","poster":"asdren88","content":"that is how I understood it as well. As mentioned we have an Excel file in one drive. \nSo we would first connect with the SharePoint folder, and then get the Excel from that folder."}],"content":"Answer: A. Excel Workbook and D. SharePoint folder\n\nReason:\n\nExcel Workbook (A): Directly connects to an Excel file stored in OneDrive. Power BI supports this connection type, and the dataset can be refreshed in Power BI service.\n\nSharePoint folder (D): Connects to files stored in SharePoint, which includes OneDrive for Business. This allows Power BI to access and refresh the Excel file as long as it's in a SharePoint or OneDrive for Business folder.\n\nText/CSV (B): Used for CSV files, not Excel files.\nFolder (C): Used for multiple files in a folder, not specifically for a single Excel file.\nWeb (E): Used for web URLs, not for files stored in OneDrive.","comment_id":"1269465","poster":"Mustafa__","upvote_count":"1"},{"content":"Selected Answer: DE\nYou need to ensure that the dataset can be refreshed in powerbi.com","upvote_count":"1","timestamp":"1723638540.0","poster":"rcaliandro","comment_id":"1265736"},{"poster":"niceguysfinishlast","content":"a and c are correct. it requires physical copies to be imported into the power bi dataset and not some data gateway as in the case of web and sharepoint.","comment_id":"1251829","upvote_count":"1","timestamp":"1721490900.0"},{"poster":"KipngenohVinnie","content":"The correct Answer that i am very sure of is E, i always connect my google sheet file to power BI using web option and it always get refreshed on schedule refresh","comment_id":"1232294","upvote_count":"1","timestamp":"1718694300.0"},{"content":"Selected Answer: DE\nTested.","comment_id":"1230659","poster":"HenryBiz","upvote_count":"1","timestamp":"1718399520.0"},{"timestamp":"1713770460.0","upvote_count":"1","content":"Selected Answer: DE\nSince the File is in excel format and residing in cloud (OneDrive), we can connect to it easily either by SharePoint or Web Connecters.","comment_id":"1200022","poster":"CaptainSappy11"},{"comment_id":"1190429","content":"Chatgpt says the answer is sharepointfolder and web and I agree","comments":[{"poster":"9f73003","timestamp":"1713375780.0","upvote_count":"4","content":"ChatGPT is wrong A TON!!! Be very careful with that thing.","comment_id":"1197371"}],"poster":"emmanueladisa1","upvote_count":"1","timestamp":"1712412360.0"},{"upvote_count":"5","content":"Selected Answer: AC\n\"The file must be imported to a Power BI dataset.\" that may be the key of this question, as the 4 options can connect to the online file, if want this file can be imported to a Power BI dataset, Sharepoint folder and Web will have some limitations, but Excel Workbook and Folder can definitely be imported to this Power BI dataset. \n\nExcel Workbook and Folder related documents: \nConnect to a folder from Power Query Online: \nhttps://learn.microsoft.com/en-us/power-query/connectors/folder#connect-to-a-folder-from-power-query-online \nConnect to an Excel workbook from Power Query Online: \nhttps://learn.microsoft.com/en-us/power-query/connectors/excel#connect-to-an-excel-workbook-from-power-query-online","timestamp":"1712148420.0","poster":"Muying_Zhao","comment_id":"1188666"},{"timestamp":"1708687560.0","comment_id":"1157079","content":"Selected Answer: AC\nA & C connectors present you the common dialog window allowing you to pickup the file from your ONE DRIVE FOLDER(available from windows explorer).\nNo credentials needed, no extra authentication","upvote_count":"5","poster":"Dani_eL"},{"comments":[{"poster":"Uhoh","comment_id":"1187899","upvote_count":"1","content":"thnx was looking for this :)","timestamp":"1712041560.0"}],"content":"option D&E - The SharePoint folder connector also work for files hosted on OneDrive for Business.","upvote_count":"4","timestamp":"1705365240.0","comment_id":"1123786","poster":"shs31"},{"comment_id":"1104659","poster":"SumaiyaKS","upvote_count":"4","timestamp":"1703428740.0","content":"The correct answer is E - Web\nhttps://learn.microsoft.com/en-us/power-bi/connect-data/desktop-use-onedrive-business-links","comments":[{"content":"2 answers brah","poster":"HoanNguyenVNmese","timestamp":"1705235880.0","comment_id":"1122525","upvote_count":"2"}]},{"poster":"asnygen","comments":[{"poster":"bbshu0801","timestamp":"1703185800.0","comments":[{"content":"ChatGPT is wrong a ton and DANGEROUS! Seriously. People need to do their homework and recognize ChatGPT for the entertainment piece that it is, and that is all it is.","poster":"9f73003","comment_id":"1197373","upvote_count":"1","timestamp":"1713375900.0"}],"content":"Chatgpt is not always right.","upvote_count":"5","comment_id":"1102885"},{"upvote_count":"5","poster":"cs3122","content":"GPT probably found its answer from this site, unfortunately","timestamp":"1705502820.0","comment_id":"1125064"}],"content":"Chatgpt: Excelworkbook and Web","timestamp":"1702931820.0","upvote_count":"1","comment_id":"1100028"},{"comments":[{"content":"The requirement is \"You need to ensure that the dataset can be refreshed in powerbi.com\". No assumption on what you need to configure so that the dataset is updated. If you're connected through the Web or SharePoint Location, the ability to refresh from Power BI is already available with no additional connection configuration.","poster":"CookieMingkee","comment_id":"1072798","timestamp":"1700168160.0","upvote_count":"5"}],"timestamp":"1699434060.0","upvote_count":"5","content":"Selected Answer: AC\n- The biggest difference between AC and DE is about authentication. With AC you already have the OneDrive folder synced to your computer, so once the dataset is published into the Power BI service, no further configuration needs to be made (assume that gateway was installed on your computer).\n- On top of that all 4 option is possible, but AC requires the least operation. Since the question does not mention anything about authentication, AC should be the most suitable","comment_id":"1065475","poster":"Ryan_042"},{"timestamp":"1699305720.0","poster":"venupurna","upvote_count":"28","content":"This was in the exam today.\nI passed the exam with 911 score.\nMy answer : SharePoint Folder and Web","comment_id":"1064259"},{"content":"D and E, because the data needs to be refreshed from PBI Service.","comment_id":"1063804","upvote_count":"1","poster":"TrustMyAnswers","timestamp":"1699271580.0"},{"comment_id":"1043824","timestamp":"1697335620.0","upvote_count":"3","poster":"Kish1604","content":"Selected Answer: DE\nConnecting via SharePoint folder or Web does not require Gateway service"},{"upvote_count":"1","timestamp":"1697068320.0","poster":"IrynaVilner","comment_id":"1041237","content":"My answer is A,C"},{"comment_id":"1026594","content":"Selected Answer: DE\nReferred to -\nhttps://learn.microsoft.com/en-us/power-bi/connect-data/desktop-use-onedrive-business-links","upvote_count":"3","poster":"sankeytm","timestamp":"1696594860.0"},{"poster":"Pratham8285","upvote_count":"5","content":"Selected Answer: DE\nIt's definitely DE as explained from Microsoft instructor","timestamp":"1696267260.0","comment_id":"1023326"},{"poster":"Igetmyrole","timestamp":"1693851420.0","upvote_count":"2","content":"A & D are the two connectors we use to connect to the file.\nThat is because:\nA. Excel Workbook: Power BI supports direct connections to Excel files in OneDrive, allowing you to import data and refresh it in Power BI Service. \nD. SharePoint folder: OneDrive for Business is often integrated with SharePoint, and you can use the SharePoint folder connector to access files stored in a SharePoint document library, which can include OneDrive files.","comment_id":"998757"},{"timestamp":"1690899060.0","upvote_count":"2","content":"Selected Answer: DE\nIn the Excel connector you can see the docmentation says \"If the Excel workbook is online, use the Web connector to connect to the workbook.\"","comment_id":"969132","poster":"MEG_Florida"},{"poster":"Bnxyl","timestamp":"1689744600.0","comment_id":"956245","upvote_count":"1","content":"The answer is D and E.\nThis is what stands out in the question\n\n \"You need to ensure that the dataset can be refreshed in powerbi.com.\"\n\nYou can sync your one drive with SharePoint folder and then for one drive, no gateway is needed so you can just use web for connecting"},{"content":"ChatGPT4:\nAccording to the document, to connect to the Excel file in a Microsoft OneDrive folder for importing to a Power BI dataset, you can use the following two connectors:\n\nExcel Workbook (Option A): Power BI allows you to get data from many types of files, including Excel workbooks. You can select the Excel option when using the Get data feature in Power BI Desktop.\n\nSharePoint - Team Sites (Option D): Saving your Power BI Desktop files to SharePoint Team Sites is similar to saving to OneDrive for Business. The main difference is how you connect to the file from Power BI. You can specify a URL or connect to the root folder.","comment_id":"952425","timestamp":"1689428280.0","upvote_count":"1","comments":[{"comment_id":"960437","content":"ChatGPT doesn't know the question, which is about Excel Workbook but on OneDrive, not on your computer.\nThe answer is Web & Sharepoint (can by synced with OneDrive).","poster":"Maniula","upvote_count":"3","timestamp":"1690116000.0"}],"poster":"globalexamtopics"},{"upvote_count":"1","comment_id":"951690","timestamp":"1689353640.0","poster":"AlanTech","content":"From reading materials:\nAccording to the document, to connect to a Microsoft Excel file in a Microsoft OneDrive folder and ensure that the dataset can be refreshed in powerbi.com, you can use the following two connectors:\n\nExcel Workbook (Option A): Power BI allows you to get data from many types of files, including Excel workbooks. You can select the Excel option when using the Get Data feature in Power BI Desktop.\n\nSharePoint - Team Sites (Option D): Saving your Power BI Desktop files to SharePoint Team Sites is similar to saving to OneDrive for Business. The main difference is how you connect to the file from Power BI. You can specify a URL or connect to the root folder."},{"comment_id":"942952","upvote_count":"1","poster":"ET_phone_home_son","content":"Selected Answer: DE\nThe answer depends on the requirement to be able to refresh the dataset in Power BI Service - of the choices here, only the Web and SharePoint Folder connectors permit scheduled refresh in PBI Service.","timestamp":"1688485920.0"},{"comment_id":"941200","upvote_count":"1","content":"Selected Answer: DE\nSurely, when you use SharePoint Folder, you need to use root folder, not subfolders. \nWeb is directly connection to excel file","poster":"JJMC5544","timestamp":"1688327700.0"},{"upvote_count":"1","poster":"Amosrab","comment_id":"937554","content":"D and E","timestamp":"1688015880.0"},{"upvote_count":"1","comment_id":"924942","timestamp":"1686899640.0","content":"Selected Answer: DE\nTo connect PowerBi to a one drive folder you need a digital link","poster":"CrisRondaloGonzalez"},{"poster":"inejo","timestamp":"1686184080.0","upvote_count":"2","comment_id":"917687","content":"Hola de nuevo, es A y E, de acuerdo con este vídeo https://youtu.be/RSh3ZaPUX24"},{"timestamp":"1685687040.0","content":"Selected Answer: DE\nThe question asks us \"Dataset can be refreshed in PBI\" so when the report published to any other owner's Workspaces it can be refeshed\n- Options A - B - C use the local address of your single file/folder although it stay in Onedrive but this is your synced local file/folder\n- Options D - E of course using web address (https://)","comment_id":"912579","upvote_count":"2","poster":"NLeeXTung"},{"comment_id":"907654","poster":"mhv22","timestamp":"1685146140.0","content":"CHATGPT answer :\n\nTo ensure that the dataset can be refreshed in powerbi.com from a Microsoft Excel file in a Microsoft OneDrive folder, you can use the following connectors:\n\nA. Excel Workbook: This connector allows you to connect directly to Excel files and import data from them into Power BI.\n\nD. SharePoint folder: Since the file is located in a Microsoft OneDrive folder, which is often associated with SharePoint, you can use the SharePoint folder connector to connect to the OneDrive folder and import the Excel file.\n\nTherefore, the correct connectors to use in this scenario are A. Excel Workbook and D. SharePoint folder.","upvote_count":"3"},{"upvote_count":"1","content":"Ans: (A)Excel Workbook and (D) SharePoint folder.\n option C (Folder) and option E (Web) are not the appropriate connectors for connecting to an Excel file in a Microsoft OneDrive folder.","comment_id":"906571","timestamp":"1685009520.0","poster":"PREM77"},{"poster":"Jagu_sheth","upvote_count":"1","timestamp":"1684813380.0","content":"Selected Answer: AD\nExcel Workbook and Sharepoint are the best methods to connect data in this scenario","comment_id":"904526"},{"timestamp":"1683666480.0","upvote_count":"1","content":"The Web connector in Power BI allows you to connect to various web-based data sources, such as web pages, web APIs, and OData feeds. While it is not specifically designed to connect to OneDrive, you may be able to use the Web connector to access OneDrive data if you have a way to authenticate and access the API for your OneDrive account. However, using one of the other connectors specifically designed for OneDrive (such as Excel Workbook or SharePoint Folder) would likely be a more straightforward and efficient way to connect to your Excel file in OneDrive.","comment_id":"893434","poster":"SanaCanada"},{"poster":"snrg564","upvote_count":"2","timestamp":"1683409980.0","comment_id":"891040","comments":[{"comment_id":"943271","timestamp":"1688527020.0","comments":[{"upvote_count":"1","comment_id":"973090","poster":"madyjoe21","timestamp":"1691245200.0","content":"why not?"}],"poster":"safz","content":"web is not recommended for connecting Excel files stored in OneDrive .","upvote_count":"1"},{"upvote_count":"1","timestamp":"1691245260.0","comment_id":"973091","poster":"madyjoe21","content":"that is my understanding too"}],"content":"The correct connectors to connect to a Microsoft Excel file in a Microsoft OneDrive folder and ensure dataset refresh in Power BI are:\n\nA. Excel Workbook\nE. Web\n\nExplanation:\nA. Excel Workbook: This connector allows you to connect directly to an Excel file (.xlsx) stored in OneDrive and import data into Power BI. It provides a seamless integration between Excel and Power BI.\n\nE. Web: This connector enables you to connect to a file hosted on the web, including files stored in OneDrive. By providing the URL of the Excel file in OneDrive, you can import its data into Power BI and set up automatic refreshes.\n\nBoth these connectors, Excel Workbook and Web, provide the necessary functionality to connect to a file in OneDrive and import it into Power BI while ensuring dataset refresh in Power BI service."},{"content":"Selected Answer: AD\nExcel workbook is in OneDrive and OneDrive is cloud and we do not need a gateway.","comment_id":"886211","poster":"Shalaleh","upvote_count":"1","timestamp":"1682943600.0"},{"content":"Selected Answer: AD\nIf the Excel file is stored in OneDrive, then the best connectors to use for refreshing the file in Power BI service are:\n\nExcel Workbook connector - This connector allows you to import data from an Excel workbook stored in OneDrive and create a dataset in Power BI. Once the dataset is created, you can publish it to Power BI service and set up scheduled refresh to ensure the data is up-to-date.\n\nSharePoint Folder connector - This connector allows you to access files stored in SharePoint and OneDrive for Business, including Excel workbooks. You can use this connector to import data from an Excel workbook stored in OneDrive, create a dataset in Power BI, and set up scheduled refresh.\n\nIf the Excel file is stored locally on your computer or on a network drive, then the best connector to use for refreshing the file in Power BI service is:","poster":"SanaCanada","timestamp":"1682532540.0","upvote_count":"2","comment_id":"881913"},{"poster":"SanaCanada","timestamp":"1682532180.0","content":"Selected Answer: AD\nFurther clarification\n\nThe Web connector in Power BI is not the best option for connecting to an Excel file. There are other connectors specifically designed for connecting to Excel files, such as the Excel Workbook connector and the SharePoint Folder connector.\n\nThe Web connector is best suited for connecting to web-based data sources that expose data through a URL or web address, such as web pages, web APIs, and OData feeds.\n\nTo connect to an Excel file stored in OneDrive or SharePoint, you should use the Excel Workbook or SharePoint Folder connector, respectively. These connectors are specifically designed to connect to Excel files and allow you to import data from the Excel file and create a dataset in Power BI.\n\nOnce the dataset is created, you can then publish the dataset to the Power BI service and set up scheduled refresh to ensure the data is up-to-date.","upvote_count":"6","comment_id":"881908"},{"upvote_count":"1","poster":"wellingtonluis","comment_id":"877111","timestamp":"1682148300.0","content":"Guys, How do you connect excel file in one drive via SharePoint ?"},{"comment_id":"858368","timestamp":"1680392760.0","content":"AC are correct, tried, one drive is a folder after all.","upvote_count":"1","poster":"luojihencha"},{"poster":"pepix74","comment_id":"852062","upvote_count":"2","timestamp":"1679917620.0","content":"From chatGPT:\n\nOneDrive is a web-based storage service. However, in the context of this question, option E (Web) is not a suitable connector to use for importing the Excel file to a Power BI dataset because the Web connector is designed for connecting to web-based APIs and web services, and not for importing files from cloud-based storage solutions like OneDrive.\n\nTo import an Excel file from OneDrive to Power BI, it is recommended to use the Excel Workbook connector or the SharePoint folder connector, depending on how the file is stored.\n\nTherefore, in this specific scenario, option E (Web) is not the correct answer."},{"upvote_count":"1","content":"Selected Answer: DE\nEl archivo de .xlsx se encuentra en una carpeta de OneDrive, por lo que conectarse a ella puede ser atreves de una carpeta SP o Web","poster":"DUVANES","timestamp":"1679583540.0","comment_id":"848344"},{"content":"Selected Answer: AC\nA and C seems correct -- if you connect to your excel file on one drive through Excel connection, the updates on one drive document are reflected on Power BI https://learn.microsoft.com/en-us/power-bi/connect-data/refresh-excel-file-onedrive","upvote_count":"2","poster":"Akin_Eren","timestamp":"1678776000.0","comment_id":"838605"},{"content":"These tricky questions are so annoying.","timestamp":"1678509420.0","poster":"PowerBiDAXSQL","upvote_count":"5","comment_id":"835659"},{"upvote_count":"2","timestamp":"1678485000.0","content":"Selected Answer: DE\nKey Phrase :: Each correct answer presents a complete solution.","comment_id":"835471","poster":"mecham"},{"poster":"Mutti","timestamp":"1678283820.0","comment_id":"833024","upvote_count":"1","content":"Wie so nicht A und C das ist doch viel sinnfoller!"},{"comment_id":"774651","content":"Selected Answer: DE\nOtherwise we would only connect locally and it would't be possible to refresh it in power bi service.","timestamp":"1673626260.0","upvote_count":"1","poster":"ewelaela"},{"upvote_count":"1","timestamp":"1672669140.0","content":"A and C","comment_id":"763778","poster":"JainiFleischer"},{"content":"a make a test with my personal onedrive space from office 365 logged on my windows 11, then i can catch the excel using excel connectors and folder connector, its work but only personal onedrive, maybe on ONEDRIVE FOR BUSSINESS the answer is other.","timestamp":"1672173000.0","poster":"Nikeferrr","comment_id":"759042","upvote_count":"2"},{"comment_id":"748979","poster":"LucianaFS","content":"This is a very tricky question. The options A and E are correct IF MIcrosoft OneDrive had syncronized with a folder at personal computer... Otherwise the answer is D and E.","upvote_count":"3","timestamp":"1671372660.0"},{"upvote_count":"1","content":"Selected Answer: E\nI Agree. E is a better solution.","comment_id":"744374","poster":"marcionlinerj","timestamp":"1670957340.0"},{"upvote_count":"6","poster":"KarthikKumarK","content":"Selected Answer: DE\nIf data should be refreshed, Then refresh will work when the connectors are web or SharePoint folder. It means, data should be available all time (online). If we use local path, It required a gateways.\n\nThanks\nKarthik","comment_id":"737475","timestamp":"1670392500.0"},{"poster":"golden_retriever","upvote_count":"2","content":"The question is tricky. It stated \"OneDrive Folder\", not \"OneDrive for Business Folder\", which turns to Sharepoint and has path. Mere OneDrive has no path at all.","comment_id":"736472","timestamp":"1670292540.0"},{"upvote_count":"6","timestamp":"1669717980.0","poster":"Hoeishetmogelijk","comment_id":"730239","content":"Selected Answer: DE\nD & E"},{"content":"Selected Answer: DE\nI have Try them,\n\nA, B, C Totally impossible.\n\nE work\nD i got some errors surelly i miss something","timestamp":"1669564560.0","comment_id":"728399","poster":"Pauwels","upvote_count":"3"},{"timestamp":"1669143780.0","content":"Selected Answer: DE\nD & E seem to be the consensus","comment_id":"724584","poster":"lukelin08","upvote_count":"2"},{"poster":"Glubbs","timestamp":"1667753400.0","comment_id":"712480","upvote_count":"1","content":"Selected Answer: DE\nTo keep the dataset on powerbi.com updated, should be online. (I believe also must be considered the right OneDrive version - https://www.microsoft.com/en-ca/microsoft-365/onedrive/onedrive-for-business)"},{"timestamp":"1667379780.0","upvote_count":"2","comment_id":"709717","poster":"Namenick10","content":"Selected Answer: DE\nD & E correct"},{"upvote_count":"4","comment_id":"703957","poster":"Churato","content":"Selected Answer: DE\nD and E. that's the way that I actually do on my job","timestamp":"1666709160.0"},{"upvote_count":"3","content":"It's DE i think referred from\nhttps://learn.microsoft.com/en-us/power-bi/connect-data/refresh-excel-file-onedrive","timestamp":"1665844560.0","comment_id":"695474","poster":"Djibsonx7"},{"comment_id":"687281","timestamp":"1665008880.0","upvote_count":"4","content":"Selected Answer: DE\nTwo options:\n- Copy and edit Path of the Excel file then use \"Web\" Connector: Option E\n- Copy and edit Path of the OneDrive folder then use \"Sharepoint Folder\" connector: Option D\nSource: https://www.youtube.com/watch?v=GGHbbg6yi-A","poster":"PinkZebra"},{"poster":"adrale26","comment_id":"680076","upvote_count":"1","timestamp":"1664218440.0","content":"I think the option is Web insted of Excel woorkbook https://learn.microsoft.com/en-us/power-bi/connect-data/desktop-use-onedrive-business-links"},{"timestamp":"1664169540.0","poster":"zagiel","content":"You have to ensure that data wil be update. So should will be correct answer Sharepoint folder and web? Because you have to import Excel workbook and folder, but Web and Sharepoint folder update automatically.","upvote_count":"2","comment_id":"679423"},{"upvote_count":"1","poster":"nucleus21","timestamp":"1663945080.0","comment_id":"677262","content":"A.Excel workbook with web path to the file \nD.Sharepoint Folder with web path to OneDrive (sharepoint) root domain >navigation to file\nsince it needs to be refreshed online option C will fail as it calls the folder from local path"},{"upvote_count":"2","comment_id":"676065","timestamp":"1663847520.0","poster":"Snow_28","content":"A. Excel workbook\nC. Folder"},{"timestamp":"1663585200.0","upvote_count":"6","comments":[{"upvote_count":"1","poster":"NevilleV","content":"I dont think so. Where do you find a URL for One Drive","comment_id":"694633","timestamp":"1665739740.0"}],"content":"Isn't Web an option as well?\nhttps://learn.microsoft.com/en-us/power-bi/connect-data/desktop-use-onedrive-business-links","poster":"bjornopjemic","comment_id":"673204"},{"content":"Selected Answer: AC\nA. Excel Workbook\nC. Folder","upvote_count":"4","comment_id":"665990","poster":"OGESSIUSER","timestamp":"1662889560.0"},{"poster":"GPerez73","upvote_count":"2","comment_id":"662720","timestamp":"1662569400.0","content":"It is correct for me"},{"comments":[{"poster":"GPerez73","comment_id":"662744","upvote_count":"3","timestamp":"1662571560.0","content":"It says Excel file, so B does not meet the requeriment"},{"poster":"NevilleV","timestamp":"1665739860.0","comment_id":"694638","upvote_count":"1","content":"Not! The question states Excel file not Text/csv"}],"timestamp":"1662462840.0","upvote_count":"1","poster":"Guru1337","comment_id":"661141","content":"So I agree with the answer, but I believe you could also use the Text/Csv connector. So B should in theory also be a valid answer."}],"answer":"DE","question_id":3,"unix_timestamp":1662462840,"choices":{"B":"Text/CSV","C":"Folder","E":"Web","A":"Excel Workbook","D":"SharePoint folder"},"question_text":"You have a Microsoft Excel file in a Microsoft OneDrive folder.\nThe file must be imported to a Power BI dataset.\nYou need to ensure that the dataset can be refreshed in powerbi.com.\nWhich two connectors can you use to connect to the file? Each correct answer presents a complete solution.\nNOTE: Each correct selection is worth one point.","topic":"1","exam_id":116,"answer_ET":"DE","answer_images":[]},{"id":"9897ddRLqRAm06UvmCdr","question_id":4,"answer_ET":"","question_text":"HOTSPOT -\nYou are profiling data by using Power Query Editor.\nYou have a table named Reports that contains a column named State. The distribution and quality data metrics for the data in State is shown in the following exhibit.\n//IMG//\n\nUse the drop-down menus to select the answer choice that completes each statement based on the information presented in the graphic.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","exam_id":116,"answers_community":[],"timestamp":"2022-09-13 01:48:00","discussion":[{"timestamp":"1663656720.0","comments":[{"content":"69 and 4","timestamp":"1723111440.0","comment_id":"1262438","upvote_count":"7","poster":"loganzz"},{"comment_id":"954737","poster":"yaguitoEC","timestamp":"1689639600.0","upvote_count":"5","content":"Yes, best answer"}],"upvote_count":"144","poster":"olajor","comment_id":"673873","content":"69 is always the right choice! ;)"},{"upvote_count":"28","content":"Answer is correct","comment_id":"667536","poster":"learnazureportal","timestamp":"1663026480.0"},{"timestamp":"1739568780.0","content":"Different should include Distinct and Unique records","upvote_count":"1","poster":"pavanmanideep","comment_id":"1356608"},{"content":"Actually, I tested and \"unique\" also counts a unique blank cell if you have it","timestamp":"1726658700.0","comment_id":"1285690","upvote_count":"2","poster":"ddd29291998"},{"comment_id":"1265742","timestamp":"1723638720.0","upvote_count":"3","content":"69 and 4 is the correct option:\nThere are 69 different values in State including nulls\nThere are 4 non-null values that occur only once in State","poster":"rcaliandro"},{"timestamp":"1723638660.0","content":"69 and 4 is the correct option:","upvote_count":"1","comment_id":"1265740","poster":"rcaliandro"},{"comment_id":"1200024","timestamp":"1713770580.0","poster":"CaptainSappy11","upvote_count":"2","content":"Answer is correct."},{"upvote_count":"18","timestamp":"1712061120.0","poster":"sm222","content":"For everyone confused, the rule to remember is that Unique values are a subset of distinct values. So, every unique value is a distinct value but distinct values are not always unique.","comment_id":"1188035"},{"content":"Answer is correct","poster":"shulaijia","timestamp":"1709532300.0","comment_id":"1165340","upvote_count":"1"},{"upvote_count":"6","timestamp":"1699271640.0","content":"Given answers are correct. 69 distinct, 4 unique.","poster":"TrustMyAnswers","comment_id":"1063805"},{"poster":"thomas_90","comment_id":"1018321","content":"69 and 4","timestamp":"1695777180.0","upvote_count":"4"},{"content":"69 , 4 : )","upvote_count":"2","timestamp":"1694592360.0","poster":"SaiCharan534","comment_id":"1006350"},{"poster":"Igetmyrole","content":"69 and 4 are correct.\nThe column has 69 distinct values, which includes all unique values (4) plus the empty values(nulls).\nThere are 4 unique values in the column, those are non-null values that occur only once in the \"State\" column.","upvote_count":"9","timestamp":"1693852140.0","comment_id":"998769"},{"upvote_count":"3","poster":"n_uttam28","comment_id":"980905","content":"69 and 4","timestamp":"1692027120.0"},{"upvote_count":"1","timestamp":"1691248920.0","poster":"madyjoe21","comments":[{"comment_id":"979190","timestamp":"1691824020.0","upvote_count":"11","poster":"Bamlaku","comments":[{"timestamp":"1695219960.0","poster":"Xtophine","comment_id":"1012407","upvote_count":"1","content":"Nice explanation!!!"},{"comment_id":"1128933","upvote_count":"1","content":"Perfect explanation, but correct me if I am wrong this data set would then have 65 null values?","poster":"powerbot9000","timestamp":"1705948140.0"}],"content":"This Column Distribution feature allows you to get a sense for the overall distribution of values within a column in your data previews, including the count of distinct values (total number of different values found in a given column) and unique values (total number of values that only appear once in a given column). In other words, distinct values represent the total number of different values found in a given column, while unique values represent the total number of values that only appear once in a given column.\nCheers!"},{"poster":"mustafaalhnuty","content":"every unique value is considered as distinct so sum with distinct my friend :)","upvote_count":"1","timestamp":"1692267780.0","comment_id":"983478"}],"comment_id":"973133","content":"Why the 4 unique values are not considered district values as well? I didn't get it! Does anyone could help me please? Ty. Answer: 73 and 4"},{"poster":"ET_phone_home_son","timestamp":"1688500380.0","content":"69 DIstinct (DIfferent) values (including null) / 4 UNIque (1 (UNI) appearance each) values","comment_id":"943126","upvote_count":"1"},{"timestamp":"1687954200.0","comment_id":"936625","poster":"Vandey","upvote_count":"3","content":"Can anyone share the downloaded pdf for the exam. Because I am writing the exam tomorrow"},{"timestamp":"1686184380.0","comment_id":"917691","content":"69 y 4 esta bn","upvote_count":"2","poster":"inejo"},{"timestamp":"1685697060.0","comment_id":"912670","upvote_count":"6","content":"This was on the exam.\nI thought I understood it but now certain I got the first answer wrong.\nIt helps me to notice that unique values are counted within the distinct values.\nSo yeah, 69 and 4","poster":"LouStar2"},{"comment_id":"886345","poster":"Shalaleh","timestamp":"1682949660.0","content":"69 different values\n4 unique","upvote_count":"3"},{"upvote_count":"3","comment_id":"848460","poster":"glenman0202","content":"Correct. There are 69 different values in the column, 4 of which only occur once.","timestamp":"1679590320.0"},{"comment_id":"848362","timestamp":"1679584680.0","content":"1. Hay 69 valores diferentes en State, incluidos los valores nulos.\n2. Hay 4 valores no nulos que aparecen solo una vez en State.","upvote_count":"1","poster":"DUVANES"},{"upvote_count":"2","content":"69&4 is correct","comment_id":"790218","poster":"JuliaYan","timestamp":"1674875400.0"},{"poster":"yordiye","comment_id":"783854","upvote_count":"2","timestamp":"1674350880.0","content":"73 \n4 ABOSOLUTLY CORRECT ..HERE IS THE EVIDENCE distinct in this table tells you the total count of how many values are present, while unique tells you how many of those values only appear once.","comments":[{"poster":"Jew0598","content":"Hey, the column distribution clearly mentions that there are 69 distinct values out of which 4 values occurs only once. So clearly, its 69 & 4.","upvote_count":"1","timestamp":"1676534340.0","comment_id":"810406"}]},{"comment_id":"776185","timestamp":"1673761260.0","content":"There are literally two numbers mentioned in the question oxo.","poster":"Ashishsingh07","upvote_count":"1"},{"comment_id":"761178","poster":"opek","content":"69 nice\n4","timestamp":"1672326840.0","upvote_count":"2"},{"content":"null value is counted in distinct and unique values","comments":[{"poster":"MawadaRaafat","comment_id":"757816","timestamp":"1672086180.0","upvote_count":"2","content":"it will not be counted in case of unique because it occurred 4% I think it happened more than one time"}],"comment_id":"744289","timestamp":"1670950500.0","upvote_count":"1","poster":"synru"},{"comment_id":"724594","content":"69 & 4. Answer is correct","upvote_count":"6","poster":"lukelin08","timestamp":"1669144380.0"},{"comment_id":"719287","poster":"andregrahamnz","content":"69/4, 100%","upvote_count":"2","timestamp":"1668566160.0"},{"comments":[{"comment_id":"704595","timestamp":"1666782120.0","poster":"Churato","upvote_count":"1","content":"Please, disregard the \"PS\""}],"poster":"Churato","upvote_count":"4","comment_id":"703985","content":"Unique represents values that appears just 1 time (Only once) at this column...\n If Null is greater than 1, it counts JUST as a \"Distinct\" and will NOT change the \"Unique Value\".\nPS: In case of just 1 Null row, it WILL increase the Unique (just +1, no matters how many times it will occured, JUST +1)!!!\n\n..So, 69 different values (including Nulls) are on this Column AND it's not possible to define How many rows it has (so far, so good! this is not required here)\n\nAND, as... Null is GREATER than 1 (just checking the percentage), we conclued that : There are 4 Unique non-nulls values that occured only once in State.\nthe answer is:\n69 for the first and 4 to the last one.","timestamp":"1666711440.0"},{"content":"The given answer is correct.\nThere are 69 different values in State including nulls.\nThere are 4 non-null values that occur only once in State.","poster":"Nurgul","comment_id":"685261","upvote_count":"6","timestamp":"1664778060.0"},{"content":"answer is correct","poster":"div4lyfe","upvote_count":"4","comment_id":"669915","timestamp":"1663245480.0"}],"question_images":["https://www.examtopics.com/assets/media/exam-media/04331/0002500001.jpg","https://www.examtopics.com/assets/media/exam-media/04331/0002600001.jpg"],"url":"https://www.examtopics.com/discussions/microsoft/view/81899-exam-pl-300-topic-1-question-12-discussion/","topic":"1","unix_timestamp":1663026480,"answer":"","isMC":false,"answer_description":"Box 1: 69 -\n69 distinct/different values.\nNote: Column Distribution allows you to get a sense for the overall distribution of values within a column in your data previews, including the count of distinct values (total number of different values found in a given column) and unique values (total number of values that only appear once in a given column).\n\nBox 2: 4 -\nReference:\nhttps://systemmanagement.ro/2018/10/16/power-bi-data-profiling-distinct-vs-unique/","answer_images":["https://www.examtopics.com/assets/media/exam-media/04331/0002700001.jpg"]},{"id":"3AeLPBoPcWzuyvSDdExK","unix_timestamp":1662573060,"exam_id":116,"answers_community":[],"timestamp":"2022-09-07 19:51:00","answer":"","url":"https://www.examtopics.com/discussions/microsoft/view/80990-exam-pl-300-topic-1-question-13-discussion/","question_id":5,"topic":"1","question_text":"HOTSPOT -\nYou have two CSV files named Products and Categories.\nThe Products file contains the following columns:\n✑ ProductID\n✑ ProductName\n✑ SupplierID\n✑ CategoryID\nThe Categories file contains the following columns:\n✑ CategoryID\n✑ CategoryName\n✑ CategoryDescription\nFrom Power BI Desktop, you import the files into Power Query Editor.\nYou need to create a Power BI dataset that will contain a single table named Product. The Product will table includes the following columns:\n✑ ProductID\n✑ ProductName\n✑ SupplierID\n✑ CategoryID\n✑ CategoryName\n✑ CategoryDescription\nHow should you combine the queries, and what should you do on the Categories query? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","answer_images":["https://www.examtopics.com/assets/media/exam-media/04331/0002900002.jpg"],"answer_ET":"","isMC":false,"question_images":["https://www.examtopics.com/assets/media/exam-media/04331/0002900001.jpg"],"answer_description":"Box 1: Merge -\nThere are two primary ways of combining queries: merging and appending.\n* When you have one or more columns that you'd like to add to another query, you merge the queries.\n* When you have additional rows of data that you'd like to add to an existing query, you append the query.\n\nBox 2: Disable the query load -\n\nManaging loading of queries -\nIn many situations, it makes sense to break down your data transformations in multiple queries. One popular example is merging where you merge two queries into one to essentially do a join. In this type of situations, some queries are not relevant to load into Desktop as they are intermediate steps, while they are still required for your data transformations to work correctly. For these queries, you can make sure they are not loaded in Desktop by un-checking 'Enable load' in the context menu of the query in Desktop or in the Properties screen:\nReference:\nhttps://docs.microsoft.com/en-us/power-bi/connect-data/desktop-shape-and-combine-data https://docs.microsoft.com/en-us/power-bi/connect-data/refresh-include-in-report-refresh","discussion":[{"poster":"GPerez73","timestamp":"1662573060.0","upvote_count":"65","content":"Ok for me","comments":[{"timestamp":"1692268080.0","poster":"mustafaalhnuty","upvote_count":"2","content":"Ok for me too 👍🏻","comment_id":"983484"}],"comment_id":"662768"},{"timestamp":"1664779680.0","upvote_count":"24","comment_id":"685276","poster":"Nurgul","content":"The given answer is correct.\nCombine the queries by performing a: Merge.\nOn the Categories query: Disable the query load."},{"timestamp":"1727467380.0","content":"Correct","upvote_count":"1","comment_id":"1290333","poster":"Bob_38"},{"poster":"rcaliandro","upvote_count":"1","timestamp":"1723639020.0","comment_id":"1265745","content":"Of course we need to merge the two queries (join them) and we have also to disable the query load. THe asnwer is OK for me"},{"timestamp":"1695777360.0","upvote_count":"1","content":"answer is correct","poster":"thomas_90","comment_id":"1018325"},{"timestamp":"1693852920.0","poster":"Igetmyrole","comment_id":"998779","content":"Merge & Exclude the query from report refresh are correct answers. \nUse the merge to combine the \"Products\" and \"Categories\" queries based on the \"CategoryID\" column.\nOnce we have combined the queries, we don't need the standalone \"Categories\" query because we have merged its data into the \"Product\" table. We \"Exclude the query from report refresh\" to ensure it doesn't unnecessarily reload when refreshing the report.","upvote_count":"5"},{"upvote_count":"1","timestamp":"1688500500.0","comment_id":"943129","poster":"ET_phone_home_son","content":"Merge / Disable query load"},{"comment_id":"917693","timestamp":"1686184620.0","content":"La respuesta es correcta Combinar, pq se requiere complementar la primera tabla y Deshabilitar la carga de la consulta, para mejor rendimiento.","poster":"inejo","upvote_count":"1"},{"comment_id":"848376","timestamp":"1679585280.0","poster":"DUVANES","upvote_count":"1","content":"1. Combine las consultas realizando: Merge - Combinar\n2. En la consulta Categorías: Deshabilite la carga de consultas."},{"content":"This is correct\n- Merge\n- Disable the query load","timestamp":"1672941900.0","poster":"svg10gh","upvote_count":"5","comment_id":"766906"},{"upvote_count":"3","comment_id":"759351","timestamp":"1672201560.0","poster":"GuerreiroJunior","content":"I totaly agree with the answer, Merge and disable the category query"},{"timestamp":"1671679740.0","upvote_count":"4","content":"correct \n- Merge\n- Disable the query load","poster":"PsgFe","comment_id":"752943"},{"timestamp":"1671246540.0","comment_id":"747739","content":"correct answer","poster":"SSN_18","upvote_count":"1"},{"upvote_count":"1","comment_id":"747189","timestamp":"1671195120.0","content":"Correct","poster":"GSKop"},{"poster":"AlexYang_","upvote_count":"1","comment_id":"746757","content":"-Merge\n-Disable load","timestamp":"1671161520.0"},{"upvote_count":"3","timestamp":"1669198740.0","content":"I understand the merge and the disable query concept but why don't you delete the categories table after merge","comments":[{"comments":[{"content":"Thanks 🙏, very clear now","upvote_count":"1","poster":"Addictedx_19","comment_id":"884982","comments":[{"comment_id":"942223","poster":"ZSun","upvote_count":"3","timestamp":"1688421180.0","content":"You should not thank him, because this answer didn't answer any question.\nThis is a good explanation of \"disable query update\", but not explanation of \"delete the query\"\nin fact, the answer is simple. If i delete query, i got nothing to upload to Power BI, think about this."}],"timestamp":"1682841720.0"}],"upvote_count":"6","poster":"Hoeishetmogelijk","timestamp":"1669719960.0","content":"Usually the import is not a one time excercise and you will want to be able to refresh the datamodel with updated sources. Then you will need the Categories QUERY again.\nThis first option is about deleting the Categories QUERY, not the Categories TABLE.","comment_id":"730284"}],"poster":"reyn007","comment_id":"725049"},{"comment_id":"724599","poster":"lukelin08","upvote_count":"3","content":"Answer is correct for me","timestamp":"1669144680.0"},{"content":"Answer is correct, disabling the query load for Categories will exclude it from appearing as a table.","upvote_count":"3","poster":"psychosystema","comment_id":"719683","timestamp":"1668605400.0"},{"content":"ok, make sense","comment_id":"710345","upvote_count":"2","poster":"JohnHail","timestamp":"1667461980.0"},{"comment_id":"709436","poster":"ClassMistress","content":"Correct answer","upvote_count":"2","timestamp":"1667336760.0"},{"poster":"Zainah22","timestamp":"1666601940.0","upvote_count":"2","comment_id":"702864","content":"Right Ans"},{"content":"Correct answer","upvote_count":"1","comment_id":"692713","timestamp":"1665554220.0","poster":"Dovoto"},{"poster":"adizzz54","timestamp":"1664543460.0","upvote_count":"2","comment_id":"683575","content":"Right Ans"},{"timestamp":"1663848180.0","content":"OK for me","poster":"val38","upvote_count":"3","comment_id":"676083"},{"comment_id":"664389","content":"Ok for me too","timestamp":"1662715200.0","upvote_count":"4","poster":"VeroF"}]}],"exam":{"isBeta":false,"lastUpdated":"12 Apr 2025","name":"PL-300","provider":"Microsoft","isMCOnly":false,"id":116,"numberOfQuestions":334,"isImplemented":true},"currentPage":1},"__N_SSP":true}