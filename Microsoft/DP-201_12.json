{"pageProps":{"questions":[{"id":"5KfqgN6iZg1FbxUxnmoT","question_text":"DRAG DROP -\nYou need to design the encryption strategy for the tagging data and customer data.\nWhat should you recommend? To answer, drag the appropriate setting to the correct drop targets. Each source may be used once, more than once, or not at all.\nYou may need to drag the split bar between panes or scroll to view content.\nNOTE: Each correct selection is worth one point.\nSelect and Place:\n//IMG//","unix_timestamp":1584382200,"answer_images":["https://www.examtopics.com/assets/media/exam-media/03774/0024700002.jpg"],"answer_description":"All cloud data must be encrypted at rest and in transit.\nBox 1: Transparent data encryption\nEncryption of the database file is performed at the page level. The pages in an encrypted database are encrypted before they are written to disk and decrypted when read into memory.\n\nBox 2: Encryption at rest -\nEncryption at Rest is the encoding (encryption) of data when it is persisted.\nReference:\nhttps://docs.microsoft.com/en-us/sql/relational-databases/security/encryption/transparent-data-encryption?view=sql-server-2017 https://docs.microsoft.com/en-us/azure/security/azure-security-encryption-atrest\nDesign for data security and compliance","discussion":[{"upvote_count":"86","content":"Tagging data - Cosmos DB - encryption at resr\nCustomer data - SQL DWH - TDE / SSL (SSL enabled by default)","comments":[{"upvote_count":"2","comment_id":"106578","poster":"obj95","content":"I agree with the data storage choices but not with the encryption methods because in the Security requirements:\nAll cloud data must be encrypted at rest and in transit.\n-> Tagging data requires TDE and (*processed*) Customer data requires Encryption at rest: So the answer is correct!\nWe only need Encryption at rest because the solution component=processed customer data and not all customer data,otherwhise I'd choose TDE","timestamp":"1591775700.0"},{"upvote_count":"1","comment_id":"236508","timestamp":"1607262780.0","poster":"JCWF","comments":[{"timestamp":"1621740240.0","upvote_count":"3","comment_id":"364075","poster":"toandm","content":"cosmos db does not have TDE, so encryption at rest"}],"content":"Cane explain why tagging data - Cosmos DB requires encryption at rest?"},{"comments":[{"upvote_count":"1","poster":"vrmei","comment_id":"388577","timestamp":"1624433040.0","content":"as per requirement, \"The tags must be stored in a document database\""}],"upvote_count":"2","comment_id":"388573","poster":"vrmei","content":"CosmosDB (Here, document db) - Does not support TDE","timestamp":"1624432920.0"},{"upvote_count":"3","poster":"AngelRio","timestamp":"1621753980.0","content":"I am agree with you totally, thanks!!","comment_id":"364228"}],"poster":"Nehuuu","comment_id":"64782","timestamp":"1584382200.0"},{"content":"I was impressed by Dp-200 model questions and quality but the answers for DP-201 questions by examtopics is not even average.. most of the answers are creating confusion when checked the discussions and sometimes the discussions are really useful like below.. one with real subject only can crack these questions..","comment_id":"149008","timestamp":"1596359640.0","upvote_count":"36","comments":[{"poster":"Gch","comment_id":"167873","timestamp":"1598567220.0","upvote_count":"1","content":"I totally agree with krisspark"}],"poster":"krisspark"},{"poster":"Steviyke","timestamp":"1624203780.0","content":"I believe this questions and answers are too old and almost irrelevant. The current Microsoft Docs says \" With the release of encryption at rest for Cosmos DB, all your databases, media attachments, and backups are encrypted. Your data is now encrypted in transit (over the network) and at rest (nonvolatile storage), giving you end-to-end encryption.\" Meaning you don't need to do anything to encrypt data at rest and in transit for Cosmos DB.","comment_id":"386372","upvote_count":"1"},{"content":"Answer is right. Combo DB gas TDE enabled by default. On synapse, we have to explicitly enable encryption at rest. It is not enable by default.","upvote_count":"1","poster":"Mandar77","comment_id":"380774","timestamp":"1623548760.0"},{"timestamp":"1613029500.0","upvote_count":"1","comment_id":"288109","content":"in essence TDE is Encryption at rest. SQL has this option by default (https://docs.microsoft.com/en-us/azure/azure-sql/database/transparent-data-encryption-tde-overview?tabs=azure-portal).\n In cosmos Al data is by default encrypted at rest ( but I do not think this is referred to as TDE: https://docs.microsoft.com/en-us/azure/cosmos-db/database-encryption-at-rest)\nSo The answers should be Reversed: Cosmos : Encrypt at rest; Sql: TDE","poster":"sturcu"},{"poster":"D_Duke","upvote_count":"3","comment_id":"251865","timestamp":"1608863580.0","content":"There seems to be some issues with the answers. Firstly, all user data stored in Azure Cosmos DB is encrypted at rest and in transport by default as per the link https://docs.microsoft.com/en-us/azure/cosmos-db/database-encryption-at-rest, so I believe we really don't need to do anything, and if we have to select an answer, it should be Encryption at rest. Secondly, for Azure SQL DB or managed instance, TDE is enabled by default to encrypt data at rest, so we need TLS to encrypt data in transit, but TLS is not in the selection list."},{"timestamp":"1607600460.0","upvote_count":"2","comment_id":"240063","content":"Reverse/flip the options and it is correct","poster":"syu31svc"},{"comment_id":"213341","content":"TDE is enabled by Default for CosmosDB and SQL DB. So both should be TDE. When you can get TDE by default why use Encryption at Rest?","poster":"sandGrain","timestamp":"1604572380.0","upvote_count":"4"},{"upvote_count":"5","content":"Nehuu is right:\nEncryption at rest for Taggin data (Cosmos DB)\nTDE for customer information (SQL)","comment_id":"126019","poster":"MLCL","timestamp":"1593852000.0"},{"poster":"Abhilvs","timestamp":"1592909880.0","upvote_count":"3","content":"yes, it should be otherwise here. It's mentioned that tagging data should reside in document DB i.e. Cosmos DB, in that case, that is Encryption at rest. Customer data in parallel processing architecture i.e synapse, which is TDE","comment_id":"117356"},{"comment_id":"101583","poster":"adamho","content":"I also agreed with Nehuuu","timestamp":"1591186380.0","upvote_count":"7"},{"timestamp":"1586164680.0","upvote_count":"16","comment_id":"71720","content":"Agree with Nehuuu","poster":"samok"}],"exam_id":66,"answer_ET":"","topic":"14","isMC":false,"answers_community":[],"question_id":56,"timestamp":"2020-03-16 19:10:00","url":"https://www.examtopics.com/discussions/microsoft/view/16757-exam-dp-201-topic-14-question-1-discussion/","question_images":["https://www.examtopics.com/assets/media/exam-media/03774/0024700001.jpg"],"answer":""},{"id":"VqBFvhrbsS5FXS1qQP0i","answer_ET":"A","timestamp":"2020-06-05 21:25:00","answer_images":[],"topic":"15","choices":{"A":"Deploy identical Azure Stream Analytics jobs to paired regions in Azure.","B":"Deploy a High Concurrency Databricks cluster.","C":"Deploy an Azure Stream Analytics job and use an Azure Automation runbook to check the status of the job and to start the job if it stops.","D":"Set Data Lake Storage to use geo-redundant storage (GRS)."},"answer":"A","answer_description":"Guarantee Stream Analytics job reliability during service updates\nPart of being a fully managed service is the capability to introduce new service functionality and improvements at a rapid pace. As a result, Stream Analytics can have a service update deploy on a weekly (or more frequent) basis. No matter how much testing is done there is still a risk that an existing, running job may break due to the introduction of a bug. If you are running mission critical jobs, these risks need to be avoided. You can reduce this risk by following Azure's paired region model.\nScenario: The application development team will create an Azure event hub to receive real-time sales data, including store number, date, time, product ID, customer loyalty number, price, and discount amount, from the point of sale (POS) system and output the data to data storage in Azure\nReference:\nhttps://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-job-reliability\nDesign for high availability and disaster recovery","exam_id":66,"answers_community":[],"unix_timestamp":1591385100,"url":"https://www.examtopics.com/discussions/microsoft/view/22238-exam-dp-201-topic-15-question-1-discussion/","question_images":[],"question_text":"What should you do to improve high availability of the real-time data processing solution?","discussion":[{"timestamp":"1618131000.0","comments":[{"content":"so dont need D!\nanswer is CORRECT","upvote_count":"3","poster":"memo43","timestamp":"1622036460.0","comment_id":"367175"}],"upvote_count":"10","poster":"maynard13x8","content":"Answer given is correct. Duplicate asa jobs to paired regions is common to continue processing real time data in case one region is out.","comment_id":"333149"},{"content":"Answer should be D. Data is output to data storage. High availability for data Storage: GRS. Scenario: The application development team will create an Azure event hub to receive real-time sales data, including store number, date, time, product ID, customer loyalty number, price, and discount amount, from the point of sale (POS) system and output the data to data storage in Azure.","upvote_count":"8","timestamp":"1610879640.0","comments":[{"timestamp":"1622314440.0","content":"Redundancy is more for disaster recovery than high availability though","upvote_count":"1","poster":"Dymize","comment_id":"369681"}],"poster":"ACSC","comment_id":"269456"},{"comment_id":"288110","upvote_count":"2","timestamp":"1613029680.0","content":"\" real-time data processing solution \" sounds like Streaming to me. Hence Steam Analytics","poster":"sturcu"},{"timestamp":"1591385100.0","poster":"thukza","content":"'The tags must be stored in a document database, and be queried by SQL\" - CosmosDB","upvote_count":"2","comment_id":"103365"}],"question_id":57,"isMC":true},{"id":"lwAxgF1CPCsSd9KWIneq","topic":"16","answer_ET":"C","choices":{"A":"Azure File Storage","C":"Azure Blob Storage","E":"Azure Synapse Analytics","B":"Azure Cosmos DB","D":"Azure SQL Database"},"question_images":[],"question_text":"You need to recommend a solution for storing the image tagging data.\nWhat should you recommend?","isMC":true,"answer_description":"Image data must be stored in a single data store at minimum cost.\nNote: Azure Blob storage is Microsoft's object storage solution for the cloud. Blob storage is optimized for storing massive amounts of unstructured data.\nUnstructured data is data that does not adhere to a particular data model or definition, such as text or binary data.\nBlob storage is designed for:\n✑ Serving images or documents directly to a browser.\n✑ Storing files for distributed access.\n✑ Streaming video and audio.\n✑ Writing to log files.\n✑ Storing data for backup and restore, disaster recovery, and archiving.\n✑ Storing data for analysis by an on-premises or Azure-hosted service.\nReference:\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction","answer":"C","discussion":[{"content":"scenario: The tags must be stored in a document database, and be queried by SQL.\nanswer: Cosmos DB","upvote_count":"29","poster":"AlexD332","timestamp":"1615649100.0","comments":[{"comment_id":"334562","poster":"maciejt","comments":[{"poster":"azurrematt123","content":"because the requirement is to store tagging data in a document database.","comment_id":"384321","upvote_count":"1","timestamp":"1623946440.0"},{"timestamp":"1619255880.0","poster":"anamaster","content":"\"Tagging data must be replicated to regions that are geographically close to company office locations.\" -> you need global distribution","comment_id":"341926","upvote_count":"7"}],"timestamp":"1618308780.0","upvote_count":"2","content":"Why Cosmos is better here than Azure SQL or Synapse?"}],"comment_id":"309797"},{"timestamp":"1615720440.0","comment_id":"310475","upvote_count":"9","content":"Images data in Blob Storage,\nImage tagging data is in Cosmos DB (Document Database, queried by SQL)","poster":"kz_data","comments":[{"upvote_count":"1","comments":[],"comment_id":"311065","content":"More than 2 TB of image data is added each day\nimages in Data Lake","poster":"AlexD332","timestamp":"1615771020.0"}]},{"timestamp":"1621485540.0","poster":"alain2","content":"tags \"must be stored in a document database\" -> CosmosDb (SQL API)","upvote_count":"2","comment_id":"361826"},{"poster":"davita8","upvote_count":"1","comment_id":"345662","timestamp":"1619727600.0","content":"B. Azure Cosmos DB"}],"url":"https://www.examtopics.com/discussions/microsoft/view/46896-exam-dp-201-topic-16-question-1-discussion/","timestamp":"2021-03-13 16:25:00","exam_id":66,"answer_images":[],"answers_community":[],"unix_timestamp":1615649100,"question_id":58},{"id":"R65LoUlms4j679zpRHPn","topic":"16","answer_ET":"A","choices":{"E":"Azure Batch","B":"Azure Data Lake Storage","D":"Azure Cognitive Services","C":"Azure Synapse Analytics","A":"Azure Databricks"},"question_images":[],"question_text":"You need to design the solution for analyzing customer data.\nWhat should you recommend?","isMC":true,"answer_description":"Customer data must be analyzed using managed Spark clusters.\nYou create spark clusters through Azure Databricks.\nReference:\nhttps://docs.microsoft.com/en-us/azure/azure-databricks/quickstart-create-databricks-workspace-portal","answer":"A","timestamp":"2021-03-13 16:26:00","discussion":[{"comment_id":"309799","content":"A is correct","timestamp":"1615649160.0","upvote_count":"9","poster":"AlexD332"},{"comment_id":"391735","timestamp":"1624767540.0","upvote_count":"1","poster":"hoangton","content":"D is correct. Because \"Images should automatically have object and color tags generated\""}],"url":"https://www.examtopics.com/discussions/microsoft/view/46897-exam-dp-201-topic-16-question-2-discussion/","exam_id":66,"answer_images":[],"answers_community":[],"unix_timestamp":1615649160,"question_id":59},{"id":"xoGjlYastjjfgJmnW82B","answer_ET":"C","answers_community":[],"isMC":true,"question_text":"You need to recommend a solution for storing customer data.\nWhat should you recommend?","unix_timestamp":1615649580,"question_images":[],"answer_description":"From the scenario:\nCustomer data must be analyzed using managed Spark clusters.\nAll cloud data must be encrypted at rest and in transit. The solution must support: parallel processing of customer data.\nReference:\nhttps://www.microsoft.com/developerblog/2019/01/18/running-parallel-apache-spark-notebook-workloads-on-azure-databricks/","timestamp":"2021-03-13 16:33:00","discussion":[{"poster":"kz_data","content":"Solution for Storing: either SQL Database or Azure Synapse\nSince the requirement is saying that we parallel processing of customer data, I would suggest Azure Synapse as it has MPP Feature","comment_id":"310480","timestamp":"1615720680.0","upvote_count":"22"},{"upvote_count":"6","timestamp":"1621754340.0","poster":"AngelRio","content":"The Case Study says \"The New York office hosts SQL Server databases that stores massive amounts of customer data\". So, Azure SQL Database!!","comment_id":"364234"},{"timestamp":"1621883640.0","poster":"Maddaa","upvote_count":"2","comment_id":"365843","content":"MPP -> Synapse"},{"comment_id":"341948","content":"its synapse -- we need to be able to do parallel processing of massive amount of data & we are looking for a storage here, not analytics","upvote_count":"5","poster":"anamaster","timestamp":"1619258100.0"},{"content":"That's not clear in requirements but DataBricks for analytics not for storing\nDW - more suitable","comment_id":"309806","upvote_count":"6","poster":"AlexD332","timestamp":"1615649580.0"}],"topic":"16","answer":"C","url":"https://www.examtopics.com/discussions/microsoft/view/46900-exam-dp-201-topic-16-question-3-discussion/","answer_images":[],"choices":{"C":"Azure Databricks","A":"Azure Synapse Analytics","D":"Azure SQL Database","B":"Azure Stream Analytics"},"exam_id":66,"question_id":60}],"exam":{"lastUpdated":"12 Apr 2025","id":66,"isBeta":false,"isImplemented":true,"isMCOnly":false,"numberOfQuestions":206,"provider":"Microsoft","name":"DP-201"},"currentPage":12},"__N_SSP":true}