{"pageProps":{"questions":[{"id":"gBc4YEkaMPJBQ0qxhsoP","answer_description":"Serverless is a compute tier for single Azure SQL Databases that automatically scales compute based on workload demand and bills for the amount of compute used per second. The serverless compute tier also automatically pauses databases during inactive periods when only storage is billed and automatically resumes databases when activity returns.\nIncorrect Answers:\nA: Azure HDInsight is a managed Apache Hadoop service that lets you run Apache Spark, Apache Hive, Apache Kafka, Apache HBase, and more in the cloud.\nB, C: Azure SQL Database Hyperscale and Azure SQL Database Business Critical are based on SQL Server database engine architecture that is adjusted for the cloud environment in order to ensure 99.99% availability even in the cases of infrastructure failures.\nReference:\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/serverless-tier-overview https://docs.microsoft.com/en-us/azure/hdinsight/ https://docs.microsoft.com/en-us/azure/azure-sql/database/service-tier-hyperscale","topic":"1","question_images":[],"choices":{"A":"an Azure HDInsight cluster","B":"Azure SQL Database Hyperscale","C":"Azure SQL Database Business Critical","D":"Azure SQL Database serverless"},"url":"https://www.examtopics.com/discussions/microsoft/view/39239-exam-dp-201-topic-1-question-37-discussion/","unix_timestamp":1607440080,"answer_ET":"D","discussion":[{"timestamp":"1607440080.0","upvote_count":"5","comments":[{"timestamp":"1608594060.0","poster":"Kampai787","content":"SI, es SI","comment_id":"249737","upvote_count":"1"}],"content":"A, B and C are wrong for sure","poster":"syu31svc","comment_id":"238407"},{"poster":"IAMKPR","comment_id":"363521","content":"Keyword \"Minimize administrative effort\" ---> Serverless","timestamp":"1621672320.0","upvote_count":"3"}],"question_text":"You plan to deploy a reporting database to Azure. The database will contain 30 GB of data. The amount of data will increase by 300 MB each year.\nRarely will the database be accessed during the second and third weeks of each month. During the first and fourth week of each month, new data will be loaded each night.\nYou need to recommend a solution for the planned database. The solution must meet the following requirements:\n✑ Minimize costs.\n✑ Minimize administrative effort.\nWhat should you recommend?","answers_community":[],"timestamp":"2020-12-08 16:08:00","answer_images":[],"exam_id":66,"isMC":true,"question_id":31,"answer":"D"},{"id":"CeB8wpn9lPnWUeUzlSGt","isMC":true,"question_images":[],"timestamp":"2021-04-30 06:10:00","exam_id":66,"answer":"A","topic":"1","choices":{"A":"Enable soft delete.","B":"Add a resource lock.","D":"Use read-access geo-redundant storage (RA-GRS).","C":"Enable diagnostics logging."},"url":"https://www.examtopics.com/discussions/microsoft/view/51187-exam-dp-201-topic-1-question-38-discussion/","answers_community":[],"question_id":32,"answer_description":"Soft delete protects blob data from being accidentally or erroneously modified or deleted. When soft delete is enabled for a storage account, blobs, blob versions\n(preview), and snapshots in that storage account may be recovered after they are deleted, within a retention period that you specify.\nReference:\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/soft-delete-overview","unix_timestamp":1619755800,"discussion":[{"upvote_count":"9","comment_id":"345870","poster":"jsonify","timestamp":"1619755800.0","content":"A is the correct answer because when you enable blob soft delete for a storage account, you specify a retention period for deleted objects of between 1 and 365 days. The retention period indicates how long the data remains available after it is deleted or overwritten."},{"upvote_count":"1","poster":"Sudhansu21","timestamp":"1621861140.0","content":"A. soft delete is the correct answer. It will allow you to recover quickly.","comment_id":"365609"},{"content":"Enable soft delete","upvote_count":"2","comment_id":"346852","poster":"sjain91","timestamp":"1619866080.0"}],"answer_ET":"A","answer_images":[],"question_text":"You are designing a solution for the ad hoc analysis of data in Azure Databricks notebooks. The data will be stored in Azure Blob storage.\nYou need to ensure that Blob storage will support the recovery of the data if the data is overwritten accidentally.\nWhat should you recommend?"},{"id":"Rh19iwtzM1ZGRQaBjPxz","question_id":33,"answer_description":"To land the data in Azure storage, you can move it to Azure Blob storage or Azure Data Lake Store Gen2. In either location, the data should be stored in text files.\nPolyBase and the COPY statement can load from either location.\nIncorrect Answers:\nB: Azure Synapse Analytics, uses distributed query processing architecture that takes advantage of the scalability and flexibility of compute and storage resources. Use Azure Synapse Analytics transform and move the data.\nReference:\nhttps://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/design-elt-data-loading","unix_timestamp":1624670460,"exam_id":66,"answer":"A","topic":"1","answer_images":[],"answer_ET":"A","answers_community":[],"question_text":"You are planning a solution that combines log data from multiple systems. The log data will be downloaded from an API and stored in a data store.\nYou plan to keep a copy of the raw data as well as some transformed versions of the data. You expect that there will be at least 2 TB of log files. The data will be used by data scientists and applications.\nYou need to recommend a solution to store the data in Azure. The solution must minimize costs.\nWhat storage solution should you recommend?","discussion":[{"poster":"ArunMonika","content":"Given answer is correct","upvote_count":"1","timestamp":"1640865660.0","comment_id":"513326"},{"timestamp":"1624670460.0","poster":"Ysandee","upvote_count":"3","content":"Agree with the answer provided.","comment_id":"390838"}],"url":"https://www.examtopics.com/discussions/microsoft/view/56082-exam-dp-201-topic-1-question-39-discussion/","choices":{"D":"Azure Cosmos DB","C":"Azure SQL Database","B":"Azure Synapse Analytics","A":"Azure Data Lake Storage Gen2"},"question_images":[],"isMC":true,"timestamp":"2021-06-26 03:21:00"},{"id":"gCu9csfnqxlRyacIXz2Y","discussion":[{"poster":"kate208","comment_id":"110390","content":"Sharding, not charding haha","timestamp":"1592172660.0","upvote_count":"32"},{"comment_id":"153438","poster":"Treadmill","timestamp":"1596958860.0","upvote_count":"27","content":"Customer scenarios for elastic query are characterized by the following topologies:\n\n • Vertical partitioning - Cross-database queries (Topology 1): The data is partitioned vertically between a number of databases in a data tier. Typically, different sets of tables reside on different databases. That means that the schema is different on different databases. For instance, all tables for inventory are on one database while all accounting-related tables are on a second database. Common use cases with this topology require one to query across or to compile reports across tables in several databases.\n\nHorizontal Partitioning - Sharding (Topology 2): Data is partitioned horizontally to distribute rows across a scaled out data tier. With this approach, the schema is identical on all participating databases. This approach is also called “sharding”. Sharding can be performed and managed using (1) the elastic database tools libraries or (2) self-sharding. An elastic query is used to query or compile reports across many shards. Shards are typically databases within an elastic pool. You can think of elastic query as an efficient way for querying all databases of elastic pool at once, as long as databases share the common schema."},{"content":"'Avoid creating \"hot\" partitions that can affect performance and availability. For example, using the first letter of a customer's name causes an unbalanced distribution, because some letters are more common. Instead, use a hash of a customer identifier to distribute data more evenly across partitions.' - From MS documentation for Horizontal Partitioning.","poster":"ShauryaRana","timestamp":"1625113260.0","upvote_count":"1","comment_id":"395491"},{"timestamp":"1613542260.0","upvote_count":"1","comment_id":"292318","content":"Here we're storing Customers data in a table and now we want to partition cust region so we need to use sharding as per the right concept as they are performed as long as DBs share common schema as per defn.","poster":"Deepu1987"},{"comment_id":"275690","content":"Answer : No\nApplicable solution : Horizontal partitioning\nReference : https://docs.microsoft.com/en-us/azure/architecture/best-practices/data-partitioning","timestamp":"1611550620.0","poster":"Shanmahi","upvote_count":"1"},{"timestamp":"1610729640.0","comment_id":"268072","upvote_count":"1","poster":"redalarm2000","content":"Ok i am confused as to the difference between question 4 and question 5 on this site. Question 4 says to use horizontal partitioning but Question 5 says it recommends to use horizontal partition and the wording is the same but they say that answer should be No still why?"},{"poster":"mojedapr","comments":[{"timestamp":"1601253900.0","comment_id":"188745","content":"it is because it is to partition customers IDs, so it means it is just 1 database.","poster":"clownfishman","upvote_count":"3"},{"content":"Vertical partitioning is to reduce the I/O and performance costs associated with fetching items that are frequently accessed. Vertical partitioning splits table and in the result we have more partitions with different schema instead of 1 big table. This is not what is expected in this scenario.\n\nHorizontal partitioning using sharding is expected. Horizontal sharding will split table row-wise, so we have multiple partitions with the same schema, but based on region in that case.\n\nFor instance split table containing all customers world-wise into multiple partitions based on the regions (customer from Europe, customers from USA etc)","timestamp":"1608361980.0","upvote_count":"1","comment_id":"247790","poster":"chaoxes"}],"upvote_count":"1","timestamp":"1600884060.0","content":"Still don't know why horizontal and not vertical !","comment_id":"185564"}],"answer_ET":"B","choices":{"A":"Yes","B":"No"},"topic":"1","timestamp":"2020-06-15 00:11:00","answer":"B","unix_timestamp":1592172660,"exam_id":66,"answer_description":"Vertical partitioning is used for cross-database queries. Instead we should use Horizontal Partitioning, which also is called charding.\nReference:\nhttps://docs.microsoft.com/en-us/azure/sql-database/sql-database-elastic-query-overview","answer_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/23160-exam-dp-201-topic-1-question-4-discussion/","question_images":[],"question_id":34,"answers_community":[],"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou are designing an Azure SQL Database that will use elastic pools. You plan to store data about customers in a table. Each record uses a value for\nCustomerID.\nYou need to recommend a strategy to partition data based on values in CustomerID.\nProposed Solution: Separate data into customer regions by using vertical partitioning.\nDoes the solution meet the goal?","isMC":true},{"id":"PwRzlKbJt7r1b2ATMo46","question_id":35,"answer_description":"Do you need serving storage that can serve as a hot path for your data? If yes, narrow your options to those that are optimized for a speed serving layer. This would be Cosmos DB among the options given in this question.\nNote: Analytical data stores that support querying of both hot-path and cold-path data are collectively referred to as the serving layer, or data serving storage.\nThere are several options for data serving storage in Azure, depending on your needs:\n✑ Azure Synapse Analytics\n✑ Azure Cosmos DB\n✑ Azure Data Explorer\n\nAzure SQL Database -\n\n✑ SQL Server in Azure VM\n✑ HBase/Phoenix on HDInsight\n✑ Hive LLAP on HDInsight\n✑ Azure Analysis Services\nIncorrect Answers:\nA, C: Azure Data Lake Storage & Azure Blob storage are not data serving storage in Azure.\nReference:\nhttps://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/analytical-data-stores","unix_timestamp":1615804140,"exam_id":66,"answer":"B","topic":"1","answer_images":["https://www.examtopics.com/assets/media/exam-media/03774/0009200008.png"],"answer_ET":"B","question_text":"You are designing a serving layer for data. The design must meet the following requirements:\n✑ Authenticate users by using Azure Active Directory (Azure AD).\n✑ Serve as a hot path for data.\n✑ Support query scale out.\n✑ Support SQL queries.\nWhat should you include in the design?","answers_community":[],"discussion":[{"timestamp":"1617869880.0","content":"scaleout+hotspot = cosmosdb\nhotspot = azuresqldb\nscaleout = azure synapse","upvote_count":"19","poster":"suman13","comment_id":"330997"},{"content":"Cosmos db is correct one because ( speed servicing not possible in azure Synapse)https://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/analytical-data-stores","timestamp":"1620658860.0","upvote_count":"1","comment_id":"353830","poster":"tamil1006","comments":[{"poster":"tamil1006","upvote_count":"1","content":"Do you need serving storage that can serve as a hot path for your data? If yes, narrow your options to those that are optimized for a speed serving layer --> in this way speed serving layer supports by cosmos db and not by synapse","timestamp":"1620659160.0","comment_id":"353832"}]},{"content":"I think that Azure Synapse Analytics could also be an answer for this question.","poster":"Geo_Barros","timestamp":"1615804140.0","upvote_count":"2","comments":[{"comments":[{"content":"Agree on this","timestamp":"1621832760.0","poster":"cadio30","upvote_count":"1","comment_id":"365203"}],"timestamp":"1616320440.0","poster":"szpinat","upvote_count":"11","content":"Synapse is note optimized for speed serving layer.","comment_id":"316227"}],"comment_id":"311316"}],"url":"https://www.examtopics.com/discussions/microsoft/view/47163-exam-dp-201-topic-1-question-40-discussion/","choices":{"D":"Azure Synapse Analytics","B":"Azure Cosmos DB","C":"Azure Blob storage","A":"Azure Data Lake Storage"},"question_images":[],"isMC":true,"timestamp":"2021-03-15 11:29:00"}],"exam":{"isImplemented":true,"name":"DP-201","isMCOnly":false,"isBeta":false,"numberOfQuestions":206,"lastUpdated":"12 Apr 2025","id":66,"provider":"Microsoft"},"currentPage":7},"__N_SSP":true}