{"pageProps":{"questions":[{"id":"ytWboFljJk8bcALuR7FT","isMC":false,"url":"https://www.examtopics.com/discussions/microsoft/view/48225-exam-az-204-topic-14-question-1-discussion/","timestamp":"2021-03-26 08:36:00","answer_description":"Box 1: var key = await Resolver.ResolveKeyAsyn(keyBundle,KeyIdentifier.CancellationToken.None);\nBox 2: var x = new BlobEncryptionPolicy(key,resolver);\nExample:\n// We begin with cloudKey1, and a resolver capable of resolving and caching Key Vault secrets.\nBlobEncryptionPolicy encryptionPolicy = new BlobEncryptionPolicy(cloudKey1, cachingResolver); client.DefaultRequestOptions.EncryptionPolicy = encryptionPolicy;\nBox 3: cloudblobClient. DefaultRequestOptions.EncryptionPolicy = x;\nReference:\nhttps://github.com/Azure/azure-storage-net/blob/master/Samples/GettingStarted/EncryptionSamples/KeyRotation/Program.cs","question_id":56,"exam_id":48,"answer_images":["https://www.examtopics.com/assets/media/exam-media/04273/0032800001.jpg"],"answers_community":[],"answer_ET":"","unix_timestamp":1616744160,"answer":"","topic":"14","discussion":[{"comment_id":"320896","poster":"wumingshi","timestamp":"1632634560.0","upvote_count":"32","content":"The answer is correct"},{"timestamp":"1680943320.0","upvote_count":"17","comment_id":"689139","comments":[{"upvote_count":"1","content":"The requirement says \"Receipt data must always be encrypted at rest.\" That might make a person think do not use client side encryption. But then proceeds to make the person guess from the answer choices that it is client side encryption. Why does this organization think this is a good way to ask questions?","comment_id":"689142","poster":"gmishra88","comments":[{"content":"\"Consider using service-side encryption features instead of client-side encryption. For more information about service-side encryption features, see Azure Storage encryption for data at rest.\"","timestamp":"1680943620.0","comment_id":"689143","upvote_count":"2","poster":"gmishra88"}],"timestamp":"1680943560.0"},{"poster":"macobuzi","upvote_count":"6","content":"To be honest, if you are an experienced programmer you can guess the right answer to this question by pure logic, no .Net code or even Azure knowledge is needed.","comments":[{"comment_id":"1048536","poster":"AndySmith","upvote_count":"2","timestamp":"1713600540.0","content":"Exactly! Did it from 1st try, but originally was very confused with plenty of optins, LOL.\nSo, 2nd and 3rd steps are easy to connect. And in 2nd step you should use \"key\" from Step1, but it only occurs in options 3 and 4. Since, 4 is about deletion policy, which doesn't make sense - then go with 3 which is Encryption Policy.\nAnd Encryption Policy is 1:1 mapping to last step 3 :)"},{"timestamp":"1719554220.0","comment_id":"1107545","poster":"bp_a_user","content":"but guessing should not be the goal","upvote_count":"2"}],"comment_id":"997506","timestamp":"1709466840.0"}],"content":"Also Microsoft says : you need not know .Net for this certification and proceed to ask questions deep in the dark corners of .Net libraries","poster":"gmishra88"},{"timestamp":"1669039440.0","poster":"SaintBahamut","content":"Answer is correct, checked that in code,\nIf we take second box as correct then only 4rd option from 1st box fits","upvote_count":"2","comment_id":"604882"},{"poster":"Yazhu","upvote_count":"2","comment_id":"504810","timestamp":"1655632260.0","content":"Given Answer is correct.\nRefer the below URL.\nhttps://csharp.hotexamples.com/examples/Microsoft.WindowsAzure.Storage.Blob/BlobEncryptionPolicy/-/php-blobencryptionpolicy-class-examples.html"},{"timestamp":"1637575500.0","content":"BlobEncryptionPolicy accept \"Ikey\" on constructor \n\n => https://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.storage.blob.blobencryptionpolicy.-ctor?view=azure-dotnet-legacy#Microsoft_Azure_Storage_Blob_BlobEncryptionPolicy__ctor_Microsoft_Azure_KeyVault_Core_IKey_Microsoft_Azure_KeyVault_Core_IKeyResolver_\n\n\n(keyBundle.Key return a Microsoft.Azure.KeyVault.WebKey.JsonWebKey).\n\nThe answer is correct !","comment_id":"363504","upvote_count":"9","poster":"UnknowMan"},{"content":"BlobEncryptionPolicy accept \"Ikey\" on constructor \n\n => https://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.storage.blob.blobencryptionpolicy.-ctor?view=azure-dotnet-legacy#Microsoft_Azure_Storage_Blob_BlobEncryptionPolicy__ctor_Microsoft_Azure_KeyVault_Core_IKey_Microsoft_Azure_KeyVault_Core_IKeyResolver_\n\n\n(keyBundle.Key return a Microsoft.Azure.KeyVault.WebKey.JsonWebKey).\n\nThe answer is correct !","upvote_count":"1","timestamp":"1637575260.0","poster":"UnknowMan","comment_id":"363500"},{"content":"1. var key = keyBundle.Key;\n2. var x = new BlobEncryptionPolicy(key, resolver);\n3. cloudBlobClient.DefaultRequestOptions.EncryptionPolicy = x;\n\nBut I'm afraid I've wasted my time. As you can see in the links, it's all legacy code.\n\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.keyvault.keyvaultclientextensions.getkeyasync?view=azure-dotnet-legacy&viewFallbackFrom=azure-dotnet\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.storage.blob.blobencryptionpolicy.-ctor?view=azure-dotnet-legacy#Microsoft_Azure_Storage_Blob_BlobEncryptionPolicy__ctor_Microsoft_Azure_KeyVault_Core_IKey_Microsoft_Azure_KeyVault_Core_IKeyResolver_\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.storage.blob.blobrequestoptions.encryptionpolicy?view=azure-dotnet-legacy#Microsoft_Azure_Storage_Blob_BlobRequestOptions_EncryptionPolicy","poster":"SnakePlissken","comment_id":"356299","comments":[{"content":"yes legacy code.. \n\nfor version 12 use KeyClient, ClientSideEncryptionOptions ...\n\nsee \nhttps://stackoverflow.com/questions/64644174/encryption-with-azure-bob-storage-v12-sdk-for-net","poster":"coffecold","upvote_count":"1","comment_id":"700743","timestamp":"1682073240.0"},{"comments":[{"timestamp":"1645877400.0","content":"No, it's a property. Read documenation. https://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.keyvault.models.keybundle.key?view=azure-dotnet-legacy#Microsoft_Azure_KeyVault_Models_KeyBundle_Key","comment_id":"432156","upvote_count":"3","poster":"vokep77043"}],"upvote_count":"1","content":"This is NOT correct, keyBundle.Key() is correct, it is a method, not a property, so no correct","timestamp":"1645622880.0","comment_id":"429916","poster":"ning"}],"upvote_count":"6","timestamp":"1636808580.0"},{"comment_id":"351622","poster":"jvyas","content":"According to Udemy instructor Alan Rodriguez answer for first box is \nvar key = keyBundle.key","upvote_count":"6","timestamp":"1636264860.0"},{"upvote_count":"4","timestamp":"1633264860.0","content":"https://docs.microsoft.com/en-us/azure/storage/blobs/storage-encrypt-decrypt-blobs-key-vault?tabs=dotnet11#encrypt-blob-and-upload","comment_id":"327351","poster":"jokergester"}],"question_images":["https://www.examtopics.com/assets/media/exam-media/04273/0032700001.jpg"],"question_text":"HOTSPOT -\nYou need to add code at line PC26 of Processing.cs to ensure that security policies are met.\nHow should you complete the code that you will add at line PC26? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//"},{"id":"aFyTtYMQgBEBAwQNZ4EC","url":"https://www.examtopics.com/discussions/microsoft/view/46895-exam-az-204-topic-14-question-2-discussion/","isMC":true,"answer_images":[],"answer_description":"","unix_timestamp":1615648800,"exam_id":48,"question_text":"You need to ensure the security policies are met.\nWhat code do you add at line CS07 of ConfigureSSE.ps1?","answer":"D","topic":"14","answer_ET":"D","answers_community":["D (100%)"],"question_id":57,"choices":{"D":"ג€\"PermissionsToKeys wrapkey, unwrapkey, get","C":"ג€\"PermissionsToCertificates wrapkey, unwrapkey, get","B":"ג€\"PermissionsToCertificates create, encrypt, decrypt","A":"ג€\"PermissionsToKeys create, encrypt, decrypt"},"question_images":[],"discussion":[{"comments":[{"content":"Yes! it's D \nPermissionsToKeys wrapkey, unwrapkey, get\nhttps://docs.microsoft.com/en-us/powershell/module/az.storage/set-azstorageaccount?view=azps-5.8.0#example-5--set-encryption-keysource-to-keyvault\ncode example at line 7","timestamp":"1640102280.0","upvote_count":"11","comment_id":"387173","poster":"azurelearner666"}],"timestamp":"1632372120.0","content":"My opinion is that the answer is D.\n\nThe policy should belong to a key. In the case study the code retrieve the key so the GET access policy is mandatory. The wrap/unwrap is used for symmetric encryption and in this case study the task is to encrypt the blobs.","upvote_count":"56","comment_id":"317825","poster":"Zsolt72"},{"poster":"mlantonis","upvote_count":"12","content":"Correct Answer: D\n\nPS C:\\>Set-AzKeyVaultAccessPolicy -VaultName \"MyKeyVault\" -ObjectId $account.Identity.PrincipalId -PermissionsToKeys wrapkey,unwrapkey,get\n\nReference:\n\nhttps://docs.microsoft.com/en-us/powershell/module/az.storage/set-azstorageaccount?view=azps-5.8.0#example-5--set-encryption-keysource-to-keyvault","timestamp":"1638376800.0","comment_id":"371961"},{"upvote_count":"1","comment_id":"1172327","poster":"james2033","content":"Selected Answer: D\nPermissionsToKeys wrapkey, unwrapkey, get","timestamp":"1726204380.0"},{"upvote_count":"6","comment_id":"879473","timestamp":"1698159660.0","content":"What is ג€\" ?","poster":"alejary"},{"content":"are these questions enough to pass the exam?","timestamp":"1697916060.0","poster":"adilkhan","comment_id":"876786","comments":[{"timestamp":"1713509940.0","content":"Some questions here appeared to the actual exam. But the problem is the answer here are not accurate. Same in some highly voted answers. I failed on my first attempt (646/1000) even though I have contributor access.","poster":"dddddd111","upvote_count":"5","comment_id":"1047637"}],"upvote_count":"3"},{"upvote_count":"3","timestamp":"1692576540.0","poster":"uffuchsi","comment_id":"816111","content":"Selected Answer: D\n100% D - All certificates and secrets used to secure data must be stored in Azure Key Vault.\n\nYou need to retrieve the keys so get permission is required. The wrapkey and unwrapkey will be used for symmetric encryption to encrypt the blobs.\n\nBelow link contains an example of same scenario.\n\nhttps://docs.microsoft.com/en-us/powershell/module/az.storage/set-azstorageaccount?view=azps-8.0.0#example-5-set-encryption-keysource-to-keyvault\n\nhttps://docs.microsoft.com/en-us/azure/key-vault/keys/about-keys-details#key-access-control"},{"content":"Got this in 16/02/2023","upvote_count":"1","timestamp":"1692163860.0","comments":[{"upvote_count":"1","poster":"mabdo","content":"same case study?","timestamp":"1692228120.0","comment_id":"811280"}],"poster":"AlexeyG","comment_id":"810362"},{"timestamp":"1684335000.0","poster":"OPT_001122","comment_id":"720663","content":"Selected Answer: D\nPermissionsToKeys wrapkey, unwrapkey, get","upvote_count":"1"},{"timestamp":"1680944040.0","poster":"gmishra88","content":"This page shows the example: https://learn.microsoft.com/en-us/powershell/module/azurerm.storage/set-azurermstorageaccount?view=azurermps-6.13.0#example-5-set-encryption-keysource-to-keyvault","upvote_count":"1","comment_id":"689148"},{"content":"Selected Answer: D\nhttps://docs.microsoft.com/en-us/powershell/module/az.storage/set-azstorageaccount?view=azps-8.0.0&viewFallbackFrom=azps-5.8.0#example-5--set-encryption-keysource-to-keyvault:~:text=PS%20C%3A%5C%3E%20Set%2DAzKeyVaultAccessPolicy%20%2DVaultName%20%24keyvaultName%20%2DResourceGroupName%20%24resourceGroupName%20%2DObjectId%20%24userId.PrincipalId%20%2DPermissionsToKeys%20get%2Cwrapkey%2Cunwrapkey%20%2DBypassObjectIdValidation","poster":"aruni_mishra","comment_id":"626112","timestamp":"1672663860.0","upvote_count":"1"},{"upvote_count":"1","comment_id":"590813","poster":"pandrer","content":"B and C wrong parameters","timestamp":"1666562040.0"},{"timestamp":"1662636480.0","content":"Selected Answer: D\nhttps://docs.microsoft.com/en-us/azure/key-vault/keys/about-keys-details#key-access-control","poster":"Bogdan75","comment_id":"563281","upvote_count":"1"},{"content":"Selected Answer: D\nPermissionsToKeys wrapkey, unwrapkey, get","upvote_count":"4","comment_id":"535215","timestamp":"1659066240.0","poster":"leonidn"},{"comment_id":"530190","upvote_count":"1","timestamp":"1658532780.0","poster":"edengoforit","content":"The Set-AzureRmKeyValutAccessPolicy parameter -PermissionsToKeys specifies an array of key operation permissions to grant to a user or service principal.\nAccording to the reference, the answer is D\n\nhttps://docs.microsoft.com/es-es/powershell/module/azurerm.storage/set-azurermstorageaccount?view=azurermps-6.13.0"},{"upvote_count":"3","comments":[{"poster":"ReniRechner","content":"This site also clearly states that PermissionsToCertificates only has these options:\nall, get, list, delete, create, import, update, managecontacts, getissuers, listissuers, setissuers, deleteissuers, manageissuers, recover, purge, backup, restore\n\n\nSo B and C are not even valid","upvote_count":"1","comment_id":"559269","timestamp":"1662100200.0"}],"timestamp":"1647823800.0","comment_id":"448509","poster":"RajMasilamani","content":"Answer is D.\nWrap,Unwrap,encrypt,decrypt available only for -PermissionsToKeys\nhttps://docs.microsoft.com/en-us/powershell/module/az.keyvault/set-azkeyvaultaccesspolicy?view=azps-6.4.0#parameters"},{"content":"D is correct from https://docs.microsoft.com/es-es/powershell/module/azurerm.storage/set-azurermstorageaccount?view=azurermps-6.13.0","timestamp":"1645618560.0","poster":"ning","upvote_count":"2","comment_id":"429868"},{"content":"Refer\nhttps://docs.microsoft.com/en-us/powershell/module/az.storage/set-azstorageaccount?view=azps-5.8.0#example-5--set-encryption-keysource-to-keyvault\nExample 5: Set Encryption KeySource to Keyvault\n\nAnswer should be D: wrapkey,unwrapkey,get\n\nPS C:\\>Set-AzKeyVaultAccessPolicy -VaultName \"MyKeyVault\" -ObjectId $account.Identity.PrincipalId -PermissionsToKeys wrapkey,unwrapkey,get","timestamp":"1637248920.0","comment_id":"360545","poster":"anandhprakash","upvote_count":"3"},{"timestamp":"1635505260.0","upvote_count":"5","content":"D is correct: \n\nhttps://docs.microsoft.com/en-us/powershell/module/az.storage/set-azstorageaccount?view=azps-5.8.0#example-5--set-encryption-keysource-to-keyvault","poster":"[Removed]","comment_id":"345272"},{"upvote_count":"3","content":"D is correct","poster":"Omallick2","timestamp":"1634477580.0","comment_id":"337614"},{"content":"It's B. See here https://www.examtopics.com/discussions/microsoft/view/7981-exam-az-203-topic-8-question-4-discussion/","comment_id":"334005","upvote_count":"2","poster":"wtkwsk","timestamp":"1634047380.0","comments":[{"timestamp":"1647527100.0","content":"In the question you are refering to is B the correct answer. B there is equivalent to D in this question. \nBut B in this question can not be correct because the given options do not even exist on the parameter. https://docs.microsoft.com/en-us/powershell/module/azurerm.keyvault/set-azurermkeyvaultaccesspolicy?view=azurermps-6.13.0#parameters","poster":"hstml","comment_id":"446605","upvote_count":"1"}]},{"upvote_count":"3","comment_id":"316338","poster":"Shion2009","timestamp":"1632221940.0","content":"See the other discussion here:\nhttps://www.examtopics.com/discussions/microsoft/view/7981-exam-az-203-topic-8-question-4-discussion/"},{"comments":[{"upvote_count":"3","comment_id":"334389","poster":"clarionprogrammer","comments":[{"upvote_count":"2","content":"nm.... It must be D. 'Get' is required.","timestamp":"1634392800.0","comment_id":"337049","poster":"clarionprogrammer"}],"content":"A is correct.","timestamp":"1634096580.0"}],"poster":"inputoutput","comment_id":"310608","upvote_count":"6","content":"PermissionsToCertificates doesn't accept 'encrypt' and 'decrypt' values. 'Wrapkey' and 'unwrapkey' options seems to be not required here. I think the correct answer is A.","timestamp":"1631624760.0"},{"timestamp":"1631539200.0","content":"B have wrong parameters\nI think it should be D","upvote_count":"7","poster":"Kuna_Lambo","comments":[{"poster":"sien","upvote_count":"1","timestamp":"1634637000.0","content":"the answer is indeed D. In the other link the answer is B which is the same as D in this question","comment_id":"338759"}],"comment_id":"309796"}],"timestamp":"2021-03-13 16:20:00"},{"id":"nG5rxWBCxd2IPycucY9R","question_images":[],"isMC":true,"choices":{"A":"Create a new composite index for the store location data queries in Azure Cosmos DB. Modify the queries to support parameterized SQL and update the Azure Function app to call the new queries.","B":"Provision an Azure Cosmos DB dedicated gateway. Update the Azure Function app connection string to use the new dedicated gateway endpoint.","D":"Provision an Azure Cosmos DB dedicated gateway. Update blob storage to use the new dedicated gateway endpoint.","C":"Configure Azure Cosmos DB consistency to session consistency. Cache session tokens in a new Azure Redis cache instance after every write. Update reads to use the session token stored in Azure Redis.","E":"Configure Azure Cosmos DB consistency to strong consistency. Increase the RUs for the container supporting store location data."},"answer_ET":"AB","answer_description":"","exam_id":48,"answers_community":["AB (58%)","AC (33%)","8%"],"discussion":[{"content":"Got this question on 30-Sep-2022 exam.\nCorrect answer is A and B. Passed with 870 score.","poster":"AbdulMannan","comments":[{"timestamp":"1692637980.0","upvote_count":"4","comment_id":"986769","poster":"ReyPirata","content":"Correct answer is A and B. \nThis was on the exam (08/20/2023). Scored 925"},{"upvote_count":"2","poster":"surprise0011","content":"I think is correct. If your wondering about B: https://learn.microsoft.com/en-us/azure/cosmos-db/dedicated-gateway\n\nAnd some info from ChatGpt: \nA dedicated gateway provides a dedicated endpoint for client applications to communicate with Azure Cosmos DB. By using a dedicated gateway, client applications such as the Azure Function app can reduce network latency and improve overall performance when communicating with Azure Cosmos DB.\n\nWhen a dedicated gateway is provisioned, it creates a Virtual Network (VNet) peering between the gateway and the Azure Cosmos DB account. This ensures that all traffic between the client application and Azure Cosmos DB remains within the same network, reducing the network latency.","comment_id":"869236","timestamp":"1681375560.0"}],"timestamp":"1664537220.0","upvote_count":"20","comment_id":"683493"},{"comment_id":"660456","timestamp":"1662403200.0","upvote_count":"9","comments":[{"content":"\"Cache session tokens in a new Azure Redis cache instance after every write\" in C. Does not sound right to me either.","timestamp":"1663878060.0","poster":"cecho123","comment_id":"676548","upvote_count":"2"}],"poster":"finnishr","content":"C makes no sense... so A and B"},{"comment_id":"1242261","upvote_count":"3","poster":"Jobalos009","content":"Selected Answer: AB\nCorrect answer is A and B.\n\"When you provision a dedicated gateway, an integrated cache is automatically configured within the dedicated gateway.\"\nSo no need to use redis.\nRef: https://learn.microsoft.com/en-us/azure/cosmos-db/dedicated-gateway#overview","timestamp":"1720122180.0"},{"content":"A) Creating a composite index tailored to the queries used by the application can significantly improve query performance and reduce RU consumption. Modifying the queries to support parameterized SQL can also help optimize query execution.\nB) A dedicated gateway in Azure Cosmos DB provides a consistent low-latency connection and can offload some of the query processing workloads from the client. This can help reduce read latency, especially for complex queries and under scaling conditions.","poster":"FeriAZ","timestamp":"1708258440.0","upvote_count":"2","comment_id":"1153248"},{"poster":"EliteAllen","content":"Selected Answer: AB\nA & B\nA. Create a new composite index for the store location data queries in Azure Cosmos DB. Modify the queries to support parameterized SQL and update the Azure Function app to call the new queries:\nBy creating a composite index tailored to the specific queries used, you can potentially reduce the query cost and improve performance. Parameterized queries can further improve efficiency.\n\nB. Provision an Azure Cosmos DB dedicated gateway. Update the Azure Function app connection string to use the new dedicated gateway endpoint:\nA dedicated gateway in Azure Cosmos DB provides improved performance for query execution and can reduce latency. Connecting the Azure Function app to this dedicated gateway can leverage these performance improvements.","comment_id":"968647","timestamp":"1690852680.0","upvote_count":"2"},{"content":"AB is correct","upvote_count":"1","poster":"phucngueyn","timestamp":"1685578260.0","comment_id":"911621"},{"poster":"winterthor4","upvote_count":"1","content":"Got this vanarsdelltd case study on 26-Mar-2023 exam. Go with A and C. Score 890.","comment_id":"850470","timestamp":"1679779500.0"},{"content":"A and C. ChatGPT","poster":"adilkhan","comment_id":"838401","upvote_count":"1","timestamp":"1678749120.0"},{"content":"Selected Answer: AC\nA and C","poster":"comoon","comment_id":"796867","upvote_count":"1","timestamp":"1675411860.0"},{"upvote_count":"3","content":"Selected Answer: AC\nA and C\nB & D are off due to Azure Cosmos DB dedicated gateway not supporting SQL queries. See limitations on:\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/dedicated-gateway#dedicated-gateway-in-multi-region-accounts\nE. Makes no sense as increasing consistency to Strong only makes the reads slower\n\nThus A & C which makes sense: Composite Index in Cosmos DB and Redis Cache for reads","poster":"rotimislaw","comments":[{"timestamp":"1676812380.0","poster":"NK203","content":"https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/query/getting-started\nIn Azure Cosmos DB for NoSQL accounts, there are two ways to read data：Point reads& SQL queries\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/dedicated-gateway#dedicated-gateway-in-multi-region-accounts\nDedicated gateways are only supported on API for NoSQL accounts\nSo dedicated gateway is support NoSQL account.How do you found that Azure Cosmos DB dedicated gateway not supporting SQL queries?","upvote_count":"3","comment_id":"814102"}],"timestamp":"1672834740.0","comment_id":"765602"},{"upvote_count":"2","content":"Selected Answer: AB\ncomposite index improves the sql performace","timestamp":"1672078020.0","comment_id":"757724","poster":"toysky731"},{"timestamp":"1668704580.0","content":"Selected Answer: BC\nAs per the description B and C look correct","comment_id":"720679","poster":"OPT_001122","upvote_count":"1"},{"timestamp":"1664540280.0","comment_id":"683547","content":"Redis is clearly a correct option if using Session consistency. From the following document it is clear that the session-id can be used in a cookie for multiple client-instances to share the same session. That is a clear case for redis-cache. So, if Session consistency is correct then redis cache is also correct. https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/data-cache-with-redis-cache","upvote_count":"2","poster":"gmishra88","comments":[{"poster":"gmishra88","timestamp":"1665220200.0","comment_id":"689157","content":"\"Parameterized SQL provides robust handling and escaping of user input, and prevents accidental exposure of data through SQL injection\" \nSo, it does not give performance improvements. Maybe a trick to confuse the traditional sql guys (at least the Java ones, who use that for performance). A trick to punish the Java guys (non-microsoft, I guess. Don't be evil, Microsoft). \nDedicated gateway is a fine option with integrated cache. But otherwise increases latency with an extra hop if using a gateway (either standard or dedicated). \nSo, another Microsoft gem to create total confusion. An ill conceived question that is half baked","upvote_count":"1","comments":[{"timestamp":"1680891240.0","comment_id":"864145","content":"Of course parametrization gives performance when it uses cached query plans.","upvote_count":"1","poster":"warchoon"},{"poster":"gmishra88","comment_id":"689159","comments":[{"poster":"gmishra88","upvote_count":"2","content":"I will bet on B (dedicated gateway) and E (Strong consistency with increased RUs). Strong consistency because that will make the writes do synchronous and so reads can be with lesser consistency level. \nThis is very innovative answer, but then I can only hope. It cannot be session consistency. It cannot be parameterized sql (unless the Microsoft guys does not understand that it does not increase performance)","timestamp":"1665220680.0","comment_id":"689160"}],"upvote_count":"1","content":"\"Connecting to Azure Cosmos DB with the dedicated gateway provides lower and more predictable latency than connecting to Azure Cosmos DB with the standard gateway.\" But worse than a direct connection unless the cache is used. Probably that is the guessing game we have to do with a lot of assumption thinking that the location data can be cached.","timestamp":"1665220560.0"}]}]},{"comment_id":"683538","upvote_count":"3","content":"B and C are correct. \nNot using Strong consistency (or bounded staleness is good for read latency), I\nRedis cache can be used to store session information. But that is about web sessions. But I guess this also can be stored in Redis.","timestamp":"1664539740.0","poster":"gmishra88","comments":[{"poster":"gmishra88","timestamp":"1665220320.0","comment_id":"689158","upvote_count":"1","content":"Strong consistency as default will make sure the writes are synchronized. But this is about the read latency. While reading any consistency less than Bounded staleness will be better for read latency (read on read quoroms)."}]},{"upvote_count":"4","comment_id":"656508","poster":"le129","timestamp":"1662053880.0","comments":[{"timestamp":"1675551900.0","upvote_count":"1","comment_id":"798459","poster":"adilkhan","content":"A = https://learn.microsoft.com/en-us/azure/cosmos-db/index-policy is correct"}],"content":"why not A composite index"}],"timestamp":"2022-09-01 19:38:00","answer_images":[],"answer":"AB","topic":"15","question_id":58,"question_text":"You need to reduce read latency for the retail store solution.\nWhat are two possible ways to achieve the goal? Each correct answer presents a complete solution.\nNOTE: Each correct selection is worth one point.","unix_timestamp":1662053880,"url":"https://www.examtopics.com/discussions/microsoft/view/79115-exam-az-204-topic-15-question-1-discussion/"},{"id":"RkPeB36e5BcdEev6Luse","isMC":true,"url":"https://www.examtopics.com/discussions/microsoft/view/75074-exam-az-204-topic-15-question-2-discussion/","timestamp":"2022-05-02 15:23:00","answer_description":"","choices":{"C":"Enable blob versioning for the storage account. Use an Azure Function to process a list of the blob versions per day.","D":"Process an Azure Storage blob inventory report by using an Azure Function. Create rule filters on the blob inventory report.","E":"Subscribe to blob storage events by using an Azure Function and Azure Event Grid. Filter the events by store location.","A":"Update the retail store location data upload process to include blob index tags. Create an Azure Function to process the blob index tags and filter by store location.","B":"Process the change feed logs of the Azure Blob storage account by using an Azure Function. Specify a time range for the change feed data."},"question_id":59,"exam_id":48,"answer_images":[],"answer_ET":"BE","answers_community":["BE (100%)"],"unix_timestamp":1651497780,"answer":"BE","discussion":[{"timestamp":"1670664360.0","content":"Selected Answer: BE\nB and E","comment_id":"740805","poster":"OPT_001122","upvote_count":"10","comments":[{"upvote_count":"1","poster":"1CY1","content":"With answer E. Ordinarily this would be an obvious choice in real time but the question has the requirement of 'Audit store sale transaction information nightly'. To me this meant that it would not be 'real time' but rather say a schedule at night. \nWhile this is not clear I'll still go with B and E.","comment_id":"1237877","timestamp":"1719464280.0"},{"comment_id":"986772","timestamp":"1692637980.0","upvote_count":"3","content":"Correct B and E. \nThis was on the exam (08/20/2023). Scored 925","poster":"ReyPirata"}]},{"timestamp":"1679351040.0","content":"B. Process the change feed logs of the Azure Blob storage account by using an Azure Function. Specify a time range for the change feed data.\nThe change feed provides a way to log changes to blobs in a storage account. By using an Azure Function to process the change feed logs, it is possible to track and audit sales transaction information. The time range for the change feed data can be specified to capture the transactions within a specific time period.\n\nE. Subscribe to blob storage events by using an Azure Function and Azure Event Grid. Filter the events by store location.\nAzure Event Grid allows subscribing to events raised by Azure services or third-party services. By using an Azure Function and Event Grid, it is possible to filter the events for a specific store location and track sales transactions. This approach can help to monitor sales transactions in real-time and provide an audit trail for reconciliation.","comment_id":"845296","upvote_count":"5","poster":"motekim"},{"timestamp":"1694365320.0","upvote_count":"1","comment_id":"1004174","content":"Selected Answer: BE\nMust be B and E","poster":"nardk"},{"timestamp":"1688628600.0","comment_id":"944405","poster":"juanckar","upvote_count":"2","content":"This was on the exam (July 2023). Went with highly voted. Scored 917"},{"content":"Also note that it is possible to react to change in storage blob the following way:\n* Blob storage trigger (Functions), They call this sometimes Blob storage trigger standard. This uses polling and latency is high\n* Blob storage trigger event based (function). Uses event grid but not the same as event-grid-trigger\n* Event grid trigger (function or others) Also called Storage Events: Not same as above. This uses an event grid subscription directly (for functions) and others as storage events that can be subscribed to\n* Change feed : Avro and event grid format (see articles for details, I never used). Latency higher than events. Transactional log, ordered\n* Azure storage blob inventory : Records of all read, write, list, and delete operations with successful and failed requests across all operations. Analytics logs are best-effort and no ordering is guaranteed. Not transactional log","upvote_count":"3","comment_id":"689170","poster":"gmishra88","timestamp":"1665221940.0"},{"comments":[{"poster":"gmishra88","content":"Unfortunately that cannot be explained because it is not clear what is being audited. Microsoft keeps that vague so that you can guess what the person who wrote this question is thinking. But if the audit is about content other two choices are fine.","comment_id":"683558","timestamp":"1664541600.0","upvote_count":"2"},{"timestamp":"1664541780.0","poster":"gmishra88","comment_id":"683561","upvote_count":"4","content":"Sorry, I did not read the question fully or forgot. It says clearly it needs to audit the transactions. The option to use Azure storage blob inventory does not give the transactions, but the properties for the blob containers. So, it is clearly not the option to audit the transactions. Hope it is clear"}],"poster":"Mousavi","upvote_count":"1","content":"why not D? can someone explain that?","comment_id":"680916","timestamp":"1664292900.0"},{"comment_id":"596058","content":"in Korean\nhttps://docs.microsoft.com/ko-kr/azure/storage/blobs/storage-blob-change-feed?tabs=azure-portal","poster":"sghaha","upvote_count":"4","comments":[{"content":"Sceen shots in English :D","comment_id":"665634","upvote_count":"3","poster":"Younes364","timestamp":"1662837360.0"},{"content":"in English\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-change-feed?tabs=azure-portal","upvote_count":"5","comment_id":"708785","timestamp":"1667265720.0","poster":"Billabongs"},{"content":"In Spanish\nhttps://learn.microsoft.com/es-es/azure/storage/blobs/storage-blob-change-feed?tabs=azure-portal\n\nGreetz, Señor developer :P","timestamp":"1694448000.0","comment_id":"1004963","poster":"mkahmann","upvote_count":"2"}],"timestamp":"1651497780.0"}],"topic":"15","question_images":[],"question_text":"You need to audit the retail store sales transactions.\nWhat are two possible ways to achieve the goal? Each correct answer presents a complete solution.\nNOTE: Each correct selection is worth one point."},{"id":"8F9ITzbISZ5gF7wuJUw6","question_text":"You need to monitor ContentUploadService according to the requirements.\nWhich command should you use?","unix_timestamp":1615799760,"url":"https://www.examtopics.com/discussions/microsoft/view/47154-exam-az-204-topic-16-question-1-discussion/","exam_id":48,"answer_description":"","question_images":[],"discussion":[{"upvote_count":"51","content":"C is the correct answer. We are dealing with containers here not VM so \"CPU usage\" is a valid condition. Had it been VM then it should have been \"Percentage CPU usage\". 800 is also correct since for containers its measured in millicores.\nRef : https://docs.microsoft.com/en-us/azure/azure-monitor/platform/metrics-supported#microsoftcontainerinstancecontainergroups","poster":"anirbanzeus","comment_id":"379512","timestamp":"1623395220.0","comments":[{"poster":"1CY1","content":"To be an average would we not need a time frame? \nNo time frame was mentioned.","upvote_count":"1","timestamp":"1719465480.0","comment_id":"1237883"},{"poster":"Illumielle","content":"Where does it say contentuploadservice uses containers? The main problem with B is that 800 is not a percentage.","comments":[{"poster":"Illumielle","comment_id":"457963","content":"It's in the code. There is still the problem with 800 not being a percentage","upvote_count":"1","timestamp":"1633476120.0"},{"comment_id":"460401","timestamp":"1633931580.0","content":"See ContentUploadService, line CS02.","upvote_count":"3","poster":"MiraA"}],"upvote_count":"2","comment_id":"457957","timestamp":"1633475820.0"},{"upvote_count":"2","content":"Correct. 800 percent does not make sense. CPU usage of 800 seems to be correct. C is the answer.","timestamp":"1653715140.0","poster":"RaviNikkam","comment_id":"608269"},{"comment_id":"472632","upvote_count":"5","timestamp":"1636037400.0","content":"It is \"avg\" and not \"usage\". Reason: it is generalized as multicores could be there.\n=>Answer C","comments":[{"upvote_count":"4","timestamp":"1636037400.0","content":"...B...","comment_id":"472634","poster":"beonsoft"}],"poster":"beonsoft"}]},{"comment_id":"311276","timestamp":"1615799760.0","content":"Shouldn't it be > 80 (instead of 800)?","upvote_count":"24","poster":"robjanssen","comments":[{"timestamp":"1615970460.0","content":"agree with you","poster":"Pozz4ever","comment_id":"313041","upvote_count":"2"},{"comment_id":"419890","poster":"SaNagh","upvote_count":"11","timestamp":"1628105400.0","content":"The CPU usage measurement is in milicores. 80% of a core would be 800 milicores."},{"upvote_count":"25","comment_id":"382974","poster":"insanewriters","content":"The CPU Usage measurement is in milicores (1/1000 of a core). So, 80% of a core would be 800 milicores.","timestamp":"1623801720.0"}]},{"content":"Selected Answer: C\nIn 2025 the questions are half answered, many parts are missing so it is difficult to answer","timestamp":"1740049320.0","poster":"037b907","comment_id":"1359202","upvote_count":"1"},{"poster":"uffuchsi","timestamp":"1676945880.0","content":"B - Scenario: An alert must be raised if the ContentUploadService uses more than 80 percent of available CPU-cores\n\nAzure Monitor provides the following metrics for Azure Container Instances. These metrics are available for a container group and individual containers. By default, the metrics are aggregated as averages.\n\nCPU Usage - measured in millicores. One millicore is 1/1000th of a CPU core, so 500 millicores represents usage of 0.5 CPU core.\n\nMemory Usage - in bytes.\n\nNetwork Bytes Received Per Second and Network Bytes Transmitted Per Second.\n\nhttps://docs.microsoft.com/en-us/azure/container-instances/container-instances-monitor","comments":[{"timestamp":"1681100220.0","comment_id":"865974","poster":"warchoon","upvote_count":"2","content":"Usage measured in millicores, percentage does not\nhttps://learn.microsoft.com/en-us/cli/azure/monitor/metrics/alert?view=azure-cli-latest#:~:text=%2D%2Dcondition%20%22-,avg%20Percentage%20CPU%20%3E%2090,-%22%20%2D%2Dwindow%2Dsize"}],"upvote_count":"2","comment_id":"816116"},{"timestamp":"1668705480.0","content":"Selected Answer: C\nC is the correct answer.","upvote_count":"2","comment_id":"720684","poster":"OPT_001122"},{"poster":"TheExamMaster2020","content":"Did my exam on 15th November 2022. This test case was on it, but not this specific question.","timestamp":"1668520800.0","upvote_count":"2","comment_id":"718816"},{"upvote_count":"1","timestamp":"1661834940.0","comment_id":"653820","content":"All wrong. \n1. It needs to be avg CPU, it doen't make sense for sudden spike of any individual computation, but if Average is over, it needs the alert.\n2. I don't see the syntax \"CPU Usage\" and the words do not match the percentage.\n3. Percentage > 80, not 8 nor 800, see from the official example.\n\naz monitor metrics alert create -n alert1 -g {ResourceGroup} --scopes {VirtualMachineID1} {VirtualMachineID2} {VirtualMachineID3} \\\n --condition \"avg Percentage CPU > 90\" --description \"High CPU\" --region westus","poster":"Knightie"},{"upvote_count":"4","content":"Selected Answer: C\nC is correct answer.","poster":"Eltooth","comment_id":"622071","timestamp":"1656149520.0"},{"comment_id":"618999","poster":"xRiot007","timestamp":"1655704140.0","upvote_count":"3","content":"We want an alert for an exceeded limit. \nA,B are invalid from the start, we do not care about averages. \nD has a wrong number in the evaluation expression \nC is the correct answer - that \"800\" is units per thousand. 800/1000 is 80%"},{"upvote_count":"2","content":"ContentUploadService is in ACI.\nwhen reading Microsft document found that CPU Usage is used for ACI and Avg percentage is used for VM\n\nAlso we don't want average just 80% of available CPU\nSO ANSWER IS C","comment_id":"617389","poster":"Sandeep12093","timestamp":"1655409720.0"},{"poster":"Elsheimy","content":"According to \nhttps://docs.azure.cn/zh-cn/cli/monitor/metrics/alert?view=azure-cli-latest\nThe answer is B. However, B states 800, I don't know if it's a typo","timestamp":"1653048960.0","upvote_count":"1","comment_id":"604397"},{"timestamp":"1650751200.0","upvote_count":"1","content":"Selected Answer: B\nsimilar alerts on https://docs.microsoft.com/en-us/cli/azure/monitor/metrics/alert?view=azure-cli-latest#az-monitor-metrics-alert-create","comment_id":"590815","poster":"pandrer"},{"comment_id":"559272","content":"Selected Answer: C\nUnit avg CPU: per hundred (%)\nUnit CPU: per thousand\nA:8%\nB:800%\nC:80%\nD:0.8%","timestamp":"1646210100.0","upvote_count":"9","poster":"ReniRechner"},{"content":"Selected Answer: C\nIt is a ACI not a VM so \"CPU usage\" is correct","timestamp":"1646140980.0","upvote_count":"4","comment_id":"558752","poster":"Netspud"},{"comment_id":"548357","poster":"heisenberg33","upvote_count":"4","content":"Selected Answer: C\nI believe its C based on this Ref: https://docs.microsoft.com/en-us/azure/container-instances/container-instances-monitor","timestamp":"1644995100.0"},{"content":"It's not A or B because we don't care about average usage, we want an alert when the usage goes above 80%. Therefore it mus be C, because as others have stated, CPU usage measurement is in millicores, so 800 would be 80%.\n\nCorrect answer: C","timestamp":"1641469020.0","upvote_count":"3","comment_id":"518190","poster":"asdasdasg2"},{"comment_id":"482414","timestamp":"1637405220.0","poster":"gfiorini","upvote_count":"2","content":"\"The ContentAnalysisService is deployed with Azure Container Instances\"\n\"The solution will use eight CPU cores.\"\nCPU usage is measured in millicore (https://docs.microsoft.com/en-us/azure/container-instances/container-instances-monitor)\nso correct answer should be 'C' (80% = 800millicore)"},{"poster":"mlantonis","comments":[{"timestamp":"1622955060.0","comment_id":"375634","poster":"Renwa","upvote_count":"3","content":"As per Udemy, C is the correct answer - https://docs.microsoft.com/en-us/azure/container-instances/container-instances-monitor"},{"timestamp":"1646140920.0","content":"Because it is an ACI \"CPU Usage\" is valid. If it were a VM then it would not be. In fact \"avg Percentage CPU\" is not valid for an ACI. Check the various links in the comments, all the ones I checked point to this.","upvote_count":"1","poster":"Netspud","comment_id":"558751"}],"timestamp":"1622558520.0","content":"Monitoring:\nAn alert must be raised if the ContentUploadService uses more than 80 percent of available CPU cores.\nThe metric \"CPU Usage\" does not exist, avg Percentage CPU is valid.\n\nNote: It should be “avg Percentage CPU > 80”\n\nReference:\n\nhttps://docs.microsoft.com/en-us/cli/azure/monitor/metrics/alert?view=azure-cli-latest#az_monitor_metrics_alert_create","upvote_count":"9","comment_id":"371966"},{"poster":"SnakePlissken","upvote_count":"6","comments":[{"comment_id":"444385","upvote_count":"5","content":"CPU Usage is available for Container Groups and individual Containers\nhttps://docs.microsoft.com/en-us/azure/container-instances/container-instances-monitor\nC should be the correct answer","timestamp":"1631603040.0","poster":"Alex42"}],"timestamp":"1620909240.0","comment_id":"356375","content":"The correct answer should be \"avg Percentage CPU > 80\" \nThe metric \"CPU Usage\" does NOT exist, so people, stop suggesting that answer!"},{"timestamp":"1619435880.0","comments":[{"timestamp":"1699375140.0","upvote_count":"1","content":"None of presented - most probably A or B (typo):\naz monitor metrics alert create -n alert1 -g {ResourceGroup} --scopes {VirtualMachineID1} {VirtualMachineID2} {VirtualMachineID3} --condition \"avg Percentage CPU > 90\" --description \"High CPU\" --region westus\n\nSource: https://learn.microsoft.com/en-us/cli/azure/monitor/metrics/alert?view=azure-cli-latest","poster":"LSandro","comment_id":"1065000"}],"comment_id":"343205","content":"Answer - B\nLooks correct based on the below link, the only thing is there should be 80 instead of 800\nhttps://docs.microsoft.com/en-us/cli/azure/monitor/metrics/alert?view=azure-cli-latest#az_monitor_metrics_alert_create","poster":"KaranKalra","upvote_count":"1"},{"upvote_count":"4","poster":"faizalzain","content":"the answer is C","timestamp":"1618892580.0","comment_id":"339313"},{"content":"can be the C as well if it is measured in millicore 800mCore is 80% with a single core","upvote_count":"1","comment_id":"325736","poster":"Zsolt72","timestamp":"1617275400.0"},{"upvote_count":"4","timestamp":"1617255780.0","poster":"Alluru","comments":[{"content":"According to the provided documentation, there is no thing such as \"CPU Usage > 800\" \nhttps://docs.microsoft.com/en-us/cli/azure/monitor/metrics/alert?view=azure-cli-latest\n\nWhere do you have that answer from?","timestamp":"1617446100.0","comments":[{"comment_id":"383576","poster":"ariel_dev","content":"https://docs.microsoft.com/en-us/azure/azure-monitor/platform/metrics-supported#microsoftcontainerinstancecontainergroups","upvote_count":"2","timestamp":"1623862500.0"}],"poster":"AndresMza","upvote_count":"4","comment_id":"327289"}],"comment_id":"325539","content":"CPU Usage > 800. Answer is C."}],"answers_community":["C (96%)","4%"],"choices":{"D":"az monitor metrics alert create ג€\"n alert ג€\"g ג€¦ - -scopes ג€¦ - -condition \"CPU Usage > 8\"","C":"az monitor metrics alert create ג€\"n alert ג€\"g ג€¦ - -scopes ג€¦ - -condition \"CPU Usage > 800\"","A":"az monitor metrics alert create ג€\"n alert ג€\"g ג€¦ - -scopes ג€¦ - -condition \"avg Percentage CPU > 8\"","B":"az monitor metrics alert create ג€\"n alert ג€\"g ג€¦ - -scopes ג€¦ - -condition \"avg Percentage CPU > 800\""},"answer_ET":"C","isMC":true,"timestamp":"2021-03-15 10:16:00","answer":"C","question_id":60,"topic":"16","answer_images":[]}],"exam":{"isBeta":false,"numberOfQuestions":452,"provider":"Microsoft","lastUpdated":"12 Apr 2025","name":"AZ-204","isMCOnly":false,"id":48,"isImplemented":true},"currentPage":12},"__N_SSP":true}