{"pageProps":{"questions":[{"id":"TdlgAPd1rymJ2Dt1rWo4","timestamp":"2021-06-30 19:21:00","answer_images":["https://www.examtopics.com/assets/media/exam-media/04273/0037000002.jpg"],"discussion":[{"comments":[{"comments":[{"comment_id":"787292","content":"Given answers are correct","upvote_count":"1","poster":"Esward","timestamp":"1706159820.0"}],"poster":"Esward","timestamp":"1706159760.0","comment_id":"787290","upvote_count":"1","content":"Agreed"},{"content":"agree with you!","timestamp":"1656890640.0","poster":"TakumaK","comment_id":"397874","upvote_count":"4"}],"content":"correct: https://docs.microsoft.com/en-us/azure/key-vault/keys/byok-specification#user-steps","comment_id":"394999","upvote_count":"52","poster":"aradice","timestamp":"1656609660.0"},{"timestamp":"1674330240.0","content":"Got this on the exam. :)\ntop kek","comments":[{"comment_id":"562857","timestamp":"1678220640.0","upvote_count":"8","poster":"mandynotmandy","content":"this is still showing up in feb 2022 exams, the kek definitely made this question unforgettable for me\ntop kek"}],"comment_id":"529334","upvote_count":"23","poster":"MasterQuestMaster"},{"content":"Given Answer is correct","poster":"kotireddy4120","timestamp":"1732369380.0","upvote_count":"1","comment_id":"1078453"},{"content":"is it enough to pass the exam to read up to 22 pages","comment_id":"906721","upvote_count":"7","timestamp":"1716646860.0","poster":"mewan"},{"content":"On my exam 2023-02-25","timestamp":"1709154660.0","upvote_count":"2","poster":"Videira","comment_id":"825295"},{"timestamp":"1708271400.0","content":"based kek question","comment_id":"813233","poster":"NombreFalso","upvote_count":"2"},{"upvote_count":"1","comment_id":"793696","poster":"Jeff8888","timestamp":"1706679720.0","content":"Agreed"},{"timestamp":"1678395900.0","content":"Got it in exam 03/22","poster":"petitbilly","comment_id":"564355","upvote_count":"4"},{"content":"Got this one 02/2022. Went with most voted","timestamp":"1675767540.0","comment_id":"542303","upvote_count":"6","poster":"oescm"},{"timestamp":"1674139380.0","comments":[{"timestamp":"1674642060.0","comment_id":"532035","content":"Ho many questions from you test you find on this site? Just interesting)","poster":"danila16030","upvote_count":"1"}],"content":"Got this one 01/2022. Went with originally proposed solution","upvote_count":"6","comment_id":"527607","poster":"lugospod"},{"content":"Generate KEK.\nRetrieve the public key of the KEK.\nUsing HSM vendor provided BYOK tool - Import the KEK into the target HSM and exports the Target Key protected by the KEK.\nImport the protected Target Key to Azure Key Vault.","upvote_count":"2","poster":"mcbc","timestamp":"1660480260.0","comment_id":"424787"}],"answer":"","topic":"4","answer_description":"To perform a key transfer, a user performs following steps:\n✑ Generate KEK.\n✑ Retrieve the public key of the KEK.\n✑ Using HSM vendor provided BYOK tool - Import the KEK into the target HSM and exports the Target Key protected by the KEK.\n✑ Import the protected Target Key to Azure Key Vault.\nStep 1: Generate a Key Exchange Key (KEK).\nStep 2: Retrieve the Key Exchange Key (KEK) public key.\nStep 3: Generate a key transfer blob file by using the HSM vendor-provided tool.\nGenerate key transfer blob using HSM vendor provided BYOK tool\nStep 4: Run the az keyvault key import command\nUpload key transfer blob to import HSM-key.\nCustomer will transfer the Key Transfer Blob (\".byok\" file) to an online workstation and then run a az keyvault key import command to import this blob as a new\nHSM-backed key into Key Vault.\nTo import an RSA key use this command:\naz keyvault key import\nReference:\nhttps://docs.microsoft.com/en-us/azure/key-vault/keys/byok-specification","question_id":261,"url":"https://www.examtopics.com/discussions/microsoft/view/56458-exam-az-204-topic-4-question-30-discussion/","isMC":false,"unix_timestamp":1625073660,"question_images":["https://www.examtopics.com/assets/media/exam-media/04273/0037000001.jpg"],"question_text":"DRAG DROP -\nYou are developing an Azure-hosted application that must use an on-premises hardware security module (HSM) key.\nThe key must be transferred to your existing Azure Key Vault by using the Bring Your Own Key (BYOK) process.\nYou need to securely transfer the key to Azure Key Vault.\nWhich four actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\nSelect and Place:\n//IMG//","answers_community":[],"exam_id":48,"answer_ET":""},{"id":"exqw95h1mYKp0UHlST0l","question_images":[],"unix_timestamp":1625073660,"question_text":"You develop and deploy an Azure Logic app that calls an Azure Function app. The Azure Function app includes an OpenAPI (Swagger) definition and uses an\nAzure Blob storage account. All resources are secured by using Azure Active Directory (Azure AD).\nThe Azure Logic app must securely access the Azure Blob storage account. Azure AD resources must remain if the Azure Logic app is deleted.\nYou need to secure the Azure Logic app.\nWhat should you do?","exam_id":48,"answer":"A","url":"https://www.examtopics.com/discussions/microsoft/view/56457-exam-az-204-topic-4-question-31-discussion/","answer_description":"","choices":{"A":"Create a user-assigned managed identity and assign role-based access controls.","C":"Create an Azure Key Vault and issue a client certificate.","E":"Create an Azure AD custom role and assign role-based access controls.","B":"Create an Azure AD custom role and assign the role to the Azure Blob storage account.","D":"Create a system-assigned managed identity and issue a client certificate."},"topic":"4","timestamp":"2021-06-30 19:21:00","answer_images":[],"answer_ET":"A","isMC":true,"answers_community":["A (100%)"],"discussion":[{"timestamp":"1625073660.0","upvote_count":"47","comments":[{"comment_id":"849992","content":"correct, in 2023Mar24, score: 904/1000.","upvote_count":"7","poster":"TonyMel","timestamp":"1679738700.0"}],"comment_id":"394998","poster":"aradice","content":"correct \"Azure AD resources must remain if the Azure Logic app is deleted.\""},{"content":"User-assigned keys are individual components. Even if the logic apps are deleted, the keys remain. But in case of system-assigned keys, those are auto generated and are deleted when the Azure resources themselves are deleted.","comment_id":"460096","upvote_count":"23","poster":"debanjan10","timestamp":"1633874580.0"},{"timestamp":"1730096280.0","upvote_count":"2","poster":"Vichu_1607","comment_id":"1303835","content":"Selected Answer: A\nA. Create a user-assigned managed identity and assign role-based access controls.\n\nTo securely access the Azure Blob storage account from the Azure Logic app while ensuring that Azure AD resources remain if the Azure Logic app is deleted, you should use a user-assigned managed identity. This approach allows you to manage the identity independently of the Logic app's lifecycle."},{"upvote_count":"1","comment_id":"1130863","content":"Selected Answer: A\nAzure AD resources must remain if the Azure Logic app is deleted -> User Managed Identity","poster":"Ciupaz","timestamp":"1706113800.0"},{"timestamp":"1705654620.0","comment_id":"1126546","poster":"FeriAZ","content":"A. Create a user-assigned managed identity and assign role-based access controls.\nThis approach ensures that the Azure Logic App can securely access the Azure Blob Storage with the appropriate permissions, and the managed identity remains operational and intact, independent of the Logic App's lifecycle.","upvote_count":"1"},{"comment_id":"1104425","upvote_count":"1","poster":"bgbgvfvf","timestamp":"1703386680.0","content":"correct answer"},{"content":"got this question today, answer A - 7/30/2023, score 895/1000","upvote_count":"5","timestamp":"1690724160.0","poster":"applepie","comment_id":"967168"},{"poster":"databasejamdown","content":"Selected Answer: A\nUser assigned will persist after resource is removed","upvote_count":"5","timestamp":"1684191240.0","comment_id":"898762"},{"comment_id":"867903","timestamp":"1681274760.0","content":"Why are other options wrong?","poster":"RaghavMGupta","upvote_count":"1"},{"comment_id":"820193","content":"Was on exam feb21","timestamp":"1677222420.0","upvote_count":"1","poster":"Sulzirsha"},{"poster":"rotimislaw","comments":[{"content":"Becouse a custom role only cover Authorization part , option A cover authorization and authentication to protect the login app","timestamp":"1722168600.0","comment_id":"1256769","poster":"Christian_garcia_martin","upvote_count":"1"}],"comment_id":"761997","content":"Why not E. Create Azure AD custom role?","upvote_count":"1","timestamp":"1672408260.0"},{"timestamp":"1669812540.0","comment_id":"731475","upvote_count":"4","poster":"r3verse","content":"\"You need to secure the Azure Logic app.\", lol, but we aren't securing the logic app, we are providing a mechanism for the logic app to securely access other resources. (a key not a lock). The logic app itself can still be accessed anonymously."},{"content":"correct \"Azure AD resources must remain if the Azure Logic app is deleted.\"","comment_id":"730521","timestamp":"1669732800.0","upvote_count":"1","poster":"EmnaDa"},{"comment_id":"687885","poster":"sam5678","upvote_count":"1","content":"correct","timestamp":"1665066060.0"},{"content":"Selected Answer: A\nA, buddies. Agree with @dejanban10","comment_id":"568097","timestamp":"1647315900.0","upvote_count":"2","poster":"iamstudying"},{"comment_id":"566538","poster":"meoukg","timestamp":"1647144480.0","content":"Got it on 03/2022, I chose A. Create a user-assigned managed identity and assign role-based access controls.","upvote_count":"3"},{"poster":"mattvasc","content":"Selected Answer: A\nIn here https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/overview\n\nWe can found:\n\"Common use cases: Workloads where resources are recycled frequently, but permissions should stay consistent.\"","comment_id":"558268","upvote_count":"1","timestamp":"1646076000.0"},{"upvote_count":"8","timestamp":"1632267360.0","poster":"AJ309","comment_id":"449211","comments":[{"content":"Yes, but this is more a Azure AD question","comment_id":"541638","poster":"mariodarken","timestamp":"1644143400.0","upvote_count":"2"}],"content":"logic app is out of course right?"}],"question_id":262},{"id":"SY12HZpD8e6dI3LNHZ8x","question_text":"HOTSPOT -\nYou are developing an application that uses a premium block blob storage account. You are optimizing costs by automating Azure Blob Storage access tiers.\nYou apply the following policy rules to the storage account. You must determine the implications of applying the rules to the data. (Line numbers are included for reference only.)\n//IMG//\n\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","answers_community":[],"timestamp":"2021-06-30 12:48:00","topic":"4","question_images":["https://www.examtopics.com/assets/media/exam-media/04273/0037300001.png","https://www.examtopics.com/assets/media/exam-media/04273/0037400001.png"],"answer_images":["https://img.examtopics.com/az-204/image602.png"],"answer":"","discussion":[{"comments":[{"comment_id":"822197","upvote_count":"1","timestamp":"1677403560.0","content":"I think you missed the difference between Blobs and Block blobs.\n1. Yes\n2. No - configuration is for Block Blobs and not for blob\n3. No - configuration is for Block Blobs and not for blob\n4. Yes - because of delete property","poster":"[Removed]","comments":[{"poster":"warchoon","comment_id":"825822","upvote_count":"2","content":"So 1 must be No too because of \"Blobs\" for 120 days","timestamp":"1677674340.0"},{"upvote_count":"3","content":"The scenario is about premium block blobs, so blobs can only be block blobs here","comments":[{"comment_id":"1299499","timestamp":"1729212960.0","comments":[{"content":"So for me its \nYes: 60 Days( BlockBlobs with container1/salesorder or container2/salesorder)\nNO : 120 Days (Mentions Blobs in general. where append blobs will not move as rule is for blockBlob)\nNO: 30 Days (Mentions Blobs in general . where append blobs will not move as rule is for blockBlob)\nNO: Auto move to hot (Mentions Blobs in general . where append blobs will not move as rule is for blockBlob)\nNO: 730 (rule is daysAfterModified not all blockBlobs)\n\nReference:\nlearn.microsoft.com/en-us/azure/storage/common/storage-account-overview\n\"Premium block blobs3 Blob Storage (including Data Lake Storage1) \nPremium storage account type for block blobs and append blobs. Recommended for scenarios with high transaction rates or that use smaller objects or require consistently low storage latency. Learn more about example workloads.\"","comments":[{"content":"Justification/correction for above: Premium Block Blob account can have append blobs as well, all the statements except first and last says blob and not blockBlob, where all the filters are related to blockBlob. Since the first and last statement mentions blockBlob explicitly that mean it needs to be considered. \nYES 4: auto move to hot as only block blobs are going to cool so that means all the blobs in cool will go to hot","timestamp":"1729216500.0","poster":"examprepau","comment_id":"1299508","upvote_count":"1"}],"timestamp":"1729216380.0","comment_id":"1299507","upvote_count":"1","poster":"examprepau"}],"upvote_count":"1","content":"Disagree: Append Blobs can also go in Premium Block Blobs","poster":"examprepau"}],"timestamp":"1677941820.0","poster":"TOM101","comment_id":"829054"}]},{"content":"Agree with you!","poster":"Esward","timestamp":"1674624540.0","comment_id":"787297","upvote_count":"1"},{"comment_id":"451020","comments":[{"comment_id":"458189","timestamp":"1633517340.0","upvote_count":"1","poster":"Vady98","content":"Agree\nI think"}],"poster":"windflower555","upvote_count":"12","content":"4 No, correct answer is: should be block blobs will be deleted 730 days after last modified\n(missed deleted part in my previous comment)","timestamp":"1632505080.0"},{"timestamp":"1668173100.0","comment_id":"716072","comments":[{"content":"Lifecycle","comment_id":"740209","timestamp":"1670597580.0","upvote_count":"2","poster":"MagoNero"},{"comment_id":"736503","poster":"Bear_Polar","content":"\"tierToCool\": {\n \"daysAfterLastAccessTimeGreaterThan\": 30\n}","timestamp":"1670297340.0","upvote_count":"4"}],"content":"Wondering why B is \"Yes\". There is no mentioning of moving the Blob from Hot to Cold Tier in 30 days...","poster":"somename20221106","upvote_count":"1"},{"poster":"Chris2349","timestamp":"1686816840.0","upvote_count":"2","content":"Went with this answer as well. Received this question on 15th of June 2023. Scored 887","comment_id":"923866"},{"content":"In my exam there were no 4th question, so don't break your head too much about it :)","poster":"CarlosTheBoldest","comment_id":"1093529","timestamp":"1702302720.0","upvote_count":"3"},{"comment_id":"451018","upvote_count":"15","content":"Agree, 4 should be no. Instead of \"All block blobs older than 730 days will be deleted\", it should be: \"all block blobs 730 days after last modified\".\nAll info can be found at:\n\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview?tabs=azure-portal#move-aging-data-to-a-cooler-tier","timestamp":"1632504900.0","poster":"windflower555"}],"upvote_count":"93","comment_id":"422205","timestamp":"1628521680.0","poster":"finnishr","content":"Correct answer: \n1. Yes\n2. Yes\n3. Yes\n4. No"},{"upvote_count":"39","timestamp":"1625255220.0","comment_id":"397136","content":"Answer is correct\n1. Yes\n2. Yes\n3. Yes\n4. Yes","poster":"jay158","comments":[{"poster":"vtomy","comment_id":"397469","timestamp":"1625305680.0","upvote_count":"4","content":"Answer is correct"},{"content":"4 is Yes. Per the Microsoft docs \"Some data is expected to expire days or months after creation. You can configure a lifecycle management policy to expire data by deletion based on data age. The following example shows a policy that deletes all block blobs older than 365 days.\" \n\n \"actions\": {\n \"baseBlob\": {\n \"delete\": { \"daysAfterModificationGreaterThan\": 365 }\n }\n }\n\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview?tabs=azure-portal#move-aging-data-to-a-cooler-tier","comments":[{"content":"It actually says \"The following example shows a policy that deletes all block blobs that haven't been MODIFIED in the last 365 days.\" Not \"older than\".","timestamp":"1721918880.0","comments":[{"comment_id":"1255046","poster":"KeithSh","timestamp":"1721918880.0","upvote_count":"2","content":"So should be NO for the 4th Q."}],"comment_id":"1255045","upvote_count":"2","poster":"KeithSh"},{"timestamp":"1646651700.0","poster":"mattvasc","comments":[{"poster":"gmishra88","comment_id":"687683","content":"Bad that you cannot start a PR on this question from Microsoft :)","timestamp":"1665053520.0","upvote_count":"1"}],"comment_id":"562562","upvote_count":"8","content":"I have opened an PR, and now, the docs is correct:\n\"The following example shows a policy that deletes all block blobs that have not been modified in the last 365 days.\"\nPR:\nhttps://github.com/MicrosoftDocs/azure-docs/pull/89203\n\nDocs:\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview?tabs=azure-portal#expire-data-based-on-age"}],"comment_id":"488180","upvote_count":"3","timestamp":"1638021540.0","poster":"ucsdmiami2020"},{"poster":"yibuqian","comment_id":"566884","upvote_count":"1","content":"#2 rule conflict with #1, so #1ans - No\n#4ans is No, because the rule is not for created date","timestamp":"1647179580.0"},{"content":"4. No, It should be daysAfterCreationGreaterThan\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview?tabs=azure-portal","poster":"wangga","upvote_count":"5","timestamp":"1646533380.0","comment_id":"561744"},{"comments":[{"comment_id":"656188","content":"no, even it got back to warm due to \"accessed\", the \"modification\" >730 will directly delete it still regardless where the tier it lies.","poster":"Knightie","upvote_count":"1","timestamp":"1662031920.0"},{"poster":"Knightie","comment_id":"656195","upvote_count":"3","content":"sorry, you are correct... it's modified>730 not just older than 730, \n4. No","timestamp":"1662032100.0"}],"upvote_count":"15","content":"wrong - 4 is No. If a block has recently been modified then it will not be deleted despite being older than 730 days.","timestamp":"1646212380.0","comment_id":"559296","poster":"jasifu3"},{"poster":"ZodiaC","content":"1000000000000% FAILS NOT GOOD PLZ STOP","upvote_count":"5","comment_id":"415440","timestamp":"1627387560.0"}]},{"timestamp":"1738310580.0","upvote_count":"1","comment_id":"1349410","poster":"wafa_chaari","content":"yes yes yes no"},{"content":"Yes,Yes,No,Yes","comment_id":"1271025","upvote_count":"1","timestamp":"1724380920.0","poster":"4bd3116"},{"comment_id":"1182498","poster":"blpiek21","content":"So confused, Premium Block Blob storage does not support tiering. Or am I missing something?","timestamp":"1711373220.0","upvote_count":"7","comments":[{"poster":"cmmr","content":"https://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview \nit seems it does now","comment_id":"1323266","upvote_count":"1","timestamp":"1733605380.0"}]},{"upvote_count":"4","timestamp":"1707961980.0","content":"All No, as premium block blob wont support lifecycle management policies (Tiers) and access tiers\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/storage-feature-support-in-storage-accounts#premium-block-blob-accounts","comment_id":"1150692","poster":"SSR999"},{"poster":"Veeresh114","comment_id":"1134236","content":"The baseBlob element in a lifecycle management policy refers to the current version of a blob. The version element refers to a previous version.","upvote_count":"1","timestamp":"1706456520.0"},{"upvote_count":"4","poster":"manopeydakon","content":"NO,No,No,No - Tiering is not yet supported in a premium block blob storage account. For all other accounts, tiering is allowed only on block blobs and not for append and page blobs.\nSee: https://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview","comment_id":"1129979","timestamp":"1706037360.0"},{"upvote_count":"3","timestamp":"1702302240.0","content":"I got this question on my exam, 2023Dec, go with what I remember was the most voted answer. Score 902, most of the questions were here, slightly different on wording because the Azure Ad <-> Entra Id change. Case was City Power & Light. Good luck!\nImportant tip, you have access to microsoft learn during the exam!","comment_id":"1093520","poster":"CarlosTheBoldest"},{"poster":"ww","content":"Received this question on my test dated 28-11-2023, \nwent with \nNo,\nNo,\nNo,\nNo\nBecause as mentioned in the discussions here, Premium block blobs don't support tiering as of Nov-23.","comments":[{"poster":"cmmr","timestamp":"1733605140.0","comment_id":"1323263","upvote_count":"1","content":"they do now: Lifecycle management policies are supported for block blobs and append blobs in general-purpose v2, premium block blob, and Blob Storage accounts.\n\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview"}],"comment_id":"1085200","upvote_count":"10","timestamp":"1701433260.0"},{"content":"As of Oct2023, premium block blob storage account is not yet supported for tiering.\nThis is a tricky question, just because you see a code doesn't mean it will work. All answers are \"No\", unless the premium block blob storage account becomes available in the future. (If that's happen, I believe No.4 would still be no, due to the delete rule requirements)\n\nReference: Search the note for premium block blob storage account.\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview","poster":"dddddd111","comment_id":"1074666","timestamp":"1700404320.0","upvote_count":"6"},{"upvote_count":"9","content":"All of the answers should be \"No\" according to this paragraph in the docs:\n\"Data stored in a premium block blob storage account cannot be tiered to hot, cool, cold or archive by using Set Blob Tier or using Azure Blob Storage lifecycle management. To move data, you must synchronously copy blobs from the block blob storage account to the hot tier in a different account using the Put Block From URL API or a version of AzCopy that supports this API\"\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/access-tiers-overview#blob-lifecycle-management","comment_id":"1059662","comments":[{"upvote_count":"4","comment_id":"1074669","content":"Indeed. It was also mentioned in this site https://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview\n\nTiering is not yet supported in a premium block blob storage account. For all other accounts, tiering is allowed only on block blobs and not for append and page blobs.\n\nAll answers are \"NO\"","poster":"dddddd111","timestamp":"1700404620.0"}],"poster":"nanguer","timestamp":"1698839040.0"},{"upvote_count":"3","timestamp":"1695830880.0","comment_id":"1019033","content":"Got it today and went with \nNo\nNo\nNo\nYes\nPassed the exam with 749 score.","poster":"pandugadu009"},{"upvote_count":"1","timestamp":"1695654780.0","content":"Got this question in exam 2023.09.25. Contoso case Study","comment_id":"1016906","poster":"leviatas"},{"upvote_count":"2","poster":"SangeethaRamasamy","timestamp":"1694684460.0","comment_id":"1007437","content":"Got this in 14/09/2023 exam","comments":[{"poster":"Elbanna","timestamp":"1694937300.0","upvote_count":"1","content":"which answers did you choose?","comment_id":"1009659"}]},{"upvote_count":"11","content":"Answer should be : No, No ,No, No\nThe key is that this is premium storage account and moving between tiers are not supported using lifecycle management policy. \nI tested it by creating a premium storage account with the blob type as block blob. In the life cycle management window for adding rules in the portal, I only see option to delete the blob. No option to move to different tiers.","poster":"Dreamer999","comments":[{"upvote_count":"2","timestamp":"1693439520.0","comment_id":"994572","content":"I tested too and Premium Block Blob Storage Account only accept Delete lifecycle, not tierToCool neither tierToArchive.\nThe documentation says 1-NO, 2-NO, 3-NO\n\"Data stored in a premium block blob storage account cannot be tiered to hot, cool, cold or archive by using Set Blob Tier or using Azure Blob Storage lifecycle management. To move data, you must synchronously copy blobs from the block blob storage account to the hot tier in a different account using the Put Block From URL API or a version of AzCopy that supports this API.\"\n\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/access-tiers-overview","poster":"JogSte"}],"comment_id":"922458","timestamp":"1686681840.0"},{"upvote_count":"1","content":"Correct answer :\n1. Yes\n2. Yes\n3. Yes\n4. No.\n\nReference: -\n https://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview?tabs=azure-portal#move-aging-data-to-a-cooler-tier","timestamp":"1683439260.0","poster":"prakash007","comment_id":"891182"},{"upvote_count":"3","timestamp":"1680664080.0","content":"Got this in exam today (5 April 2023)","comment_id":"861719","poster":"[Removed]"},{"poster":"rasojol523","timestamp":"1678557900.0","upvote_count":"2","comment_id":"836361","content":"Box 1:\nNo. Premium block BLOBs cannot use the archive layer.\n\nBox2:\nNo.\nBox2 is \"if not 'accessed' for 30 days\". The tireToCool rule, on the other hand, is \"60-day modification\" because it is a tireToCool rule with a tireToCoolGraterThan 60, so the dates and conditions are different.\n\nBox 3:.\nYes. enableAutoTireToHotFromCool w/ dayAfterLastAccessTimeGreaterThan 30.\n\nBox4:\nPresumably Yes.\nIf \"older than 730 days\" has since been changed, then yes.\nIf since created, then no.","comments":[{"content":"Box 2: Yes.\nOops, I missed the second TireToCool. This is daysAfterLastAccessTimeGreaterThan : 30.\nNO if MS makes a clear distinction between \"Greater than 30\" and \"just 30\"...\nI'll go with this.\nNo,Yes,Yes,Yes","timestamp":"1678558440.0","poster":"rasojol523","upvote_count":"2","comment_id":"836377"}]},{"comments":[{"upvote_count":"2","comment_id":"909427","content":"D, is about a delete, not tiering, so it should be YES.","timestamp":"1685366280.0","poster":"kgy01"}],"upvote_count":"6","comment_id":"812894","content":"We have to be careful here since the question mentions a \"premium block blob storage account\" is being used here.\n\nTiering is NOT supported for this account type as the documentation clearly says:\n\"Tiering is not yet supported in a premium block blob storage account.\"\n(https://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview)\n\nWhat may be confusing is the fact that the documentation provided above also says the following:\n\"Lifecycle management policies are supported for block blobs and append blobs in general-purpose v2, premium block blob, and Blob Storage accounts\"\n\nFrom my understanding, lifecycle management can only be used for delete policies, but not for tiering. Hence the answers should all be NO.","timestamp":"1676719680.0","poster":"UniqueNickname"},{"timestamp":"1674906780.0","comment_id":"790561","comments":[{"content":"thats odd... but okay... I found something here, which tells the following -> \n\"Lifecycle management policies are supported for block blobs and append blobs in general-purpose v2, premium block blob, and Blob Storage accounts. Lifecycle management doesn't affect system containers such as the $logs or $web containers.\"","poster":"Michael2023","comment_id":"790565","timestamp":"1674907260.0","upvote_count":"2"}],"content":"what am I missing here?\nI thought Lifecycle Managment isnt supported for \"Premium block blob accounts\"\n\nI also created 2 storage accounts in Azure to check whats possible... the will be created with HOT or Cold Access Tier but only in Storage Account with \"Standard general-purpose v2\" you have the possibility of Lifecycle Management\n\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/storage-feature-support-in-storage-accounts#premium-block-blob-accounts","upvote_count":"2","poster":"Michael2023"},{"poster":"Trimack93","upvote_count":"11","comment_id":"735422","content":"It is stated in the question that we are using premium block blob storage account. For these, tiering is not supported:\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/access-tiers-overview#blob-lifecycle-management\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview#rule-actions\n\nSo the correct answer should be:\n1. NO\n2. NO\n3. NO\n4. NO","timestamp":"1670184660.0","comments":[{"upvote_count":"2","timestamp":"1671186000.0","content":"Great catch!\n\n\"Setting Tiers using Lifecycle Management Policy is supported for Block Blobs only under GPv2 Storage Accounts.\nDeletion using Lifecycle Management Policy is supported for Block/Append Blobs under GPv2 Storage Accounts and Block/Append Blobs under Premium Block Blob Storage Accounts.\n\nhttps://github.com/MicrosoftDocs/azure-docs/issues/94587\n&\nhttps://github.com/MicrosoftDocs/azure-docs/issues/100695","comment_id":"747043","poster":"aruni_mishra"},{"comments":[{"comments":[{"comments":[{"comment_id":"812892","timestamp":"1676719380.0","comments":[{"comment_id":"825832","content":"But the deletion rule is wrong","upvote_count":"2","timestamp":"1677674940.0","poster":"warchoon"}],"content":"The documentation mentions this: \n\"Tiering is not yet supported in a premium block blob storage account.\"\n(https://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview)\n\nFrom my understanding, this does not exclude Lifecycle Management since you should be able to delete blobs via rules.","poster":"UniqueNickname","upvote_count":"2"}],"timestamp":"1674907620.0","content":"but here it is saying the following -> \n\"Lifecycle management policies are supported for block blobs and append blobs in general-purpose v2, premium block blob, and Blob Storage accounts. Lifecycle management doesn't affect system containers such as the $logs or $web containers.\"...\n\nSo I am confused now... in Azure Storage Premium Block Blob Account, I couldnt find the Lifecycle Management menu hmm\n\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview","poster":"Michael2023","comment_id":"790567","upvote_count":"1"}],"comment_id":"790559","upvote_count":"1","timestamp":"1674906600.0","poster":"Michael2023","content":"Lifecycle management policies is not supported on Premium Block Blob Accounts\n\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/storage-feature-support-in-storage-accounts#premium-block-blob-accounts"}],"poster":"Igris","upvote_count":"1","content":"Lifecycle management policies are supported for block blobs and append blobs in general-purpose v2, premium block blob, and Blob Storage accounts. https://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview","comment_id":"755145","timestamp":"1671915780.0"}]},{"comment_id":"690009","timestamp":"1665306120.0","upvote_count":"2","content":"YES, YES, YES, NO\n4th Option is NO, because it's daysAfterModification, it should have daysAfterCreation to check OLDER than 730 days.","poster":"kampatra"},{"content":"Answer should be : YES, NO, YES, YES\n2nd All blob WON'T move to cool tier - only with given prefix","timestamp":"1663318560.0","comment_id":"670635","poster":"kampatra","upvote_count":"1"},{"upvote_count":"1","content":"4 is yes. You can't use \"daysAfterCreationGreaterThan\" for baseBlob delete. It is available only for snapshot or version blobs\nhttps://docs.microsoft.com/en-us/answers/questions/637936/error-updating-azure-blob-lifecycle-34could-not-fi.html","timestamp":"1650954000.0","comment_id":"592132","poster":"andrvelich"},{"comment_id":"583747","poster":"Azprep","timestamp":"1649604060.0","upvote_count":"4","content":"No\nNo, \nNo, \nYes"},{"content":"No.2 says \"have not been accessed for 30 days\" yet the json says \"greater than\" 30 days, not \"greater and equal to\", so that would be 31+?\nSounds like 2 is NO based on that","timestamp":"1648378500.0","comment_id":"576114","upvote_count":"1","poster":"Rockm0uld"},{"comment_id":"529337","upvote_count":"5","content":"got this on the exam!","timestamp":"1642794480.0","poster":"MasterQuestMaster"},{"poster":"lugospod","upvote_count":"4","content":"Got this one 01/2022. Went with most voted (to avoid writing answers again)","comment_id":"527608","timestamp":"1642603440.0","comments":[{"comment_id":"562587","comments":[{"timestamp":"1647316140.0","content":"4. No, buddies.","poster":"iamstudying","comment_id":"568099","upvote_count":"1"}],"poster":"laup4321","upvote_count":"1","content":"There are 2 different answers above - both tagged with Highly voted. One has 'Yes' for answer (4) one has 'No' which did you put?","timestamp":"1646654340.0"}]},{"timestamp":"1639485960.0","comment_id":"501355","poster":"biswajit29","content":"answer should be Yes, No, Yes, No","comments":[{"comment_id":"560444","upvote_count":"2","poster":"mattvasc","timestamp":"1646355840.0","content":"The second one is Yes, please check it again the second rule on json."}],"upvote_count":"1"},{"timestamp":"1636637820.0","upvote_count":"3","comment_id":"476233","poster":"alperc","content":"regarding question 3; can it be a tricky question and the answer be no, because there is a filter below that sets type to \"blockBlob\"."},{"content":"The given answer is correct for one reason that is the blob storage is a premium blockBlob storage so the blob types will be blockBlobs only \n\nSo The Answer is correct\n1. Yes\n2. Yes\n3. Yes\n4. Yes","upvote_count":"4","poster":"BeshoyRomany","timestamp":"1632657360.0","comment_id":"451822"},{"upvote_count":"4","comment_id":"451121","comments":[{"timestamp":"1647119700.0","upvote_count":"1","comment_id":"566399","poster":"sradev","comments":[{"comment_id":"566400","poster":"sradev","content":"https://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.management.storage.models.managementpolicybaseblob.enableautotiertohotfromcool?view=azure-dotnet","upvote_count":"1","timestamp":"1647119820.0"},{"poster":"Mal22002","comment_id":"571417","timestamp":"1647755580.0","content":"Read it again, the same link you provided above. It says:\nIn the following example, blobs are moved to cool storage if they haven't been accessed for 30 days. The enableAutoTierToHotFromCool property is a Boolean value that indicates whether a blob should automatically be tiered from cool back to hot if it is accessed again after being tiered to cool.","upvote_count":"1"}],"content":"I agree, in the link below are the same 3 examples of this question (1, 3, 4) - YES\n2nd is NO because the second rule is matching with 3rd proposal\n\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview?tabs=azure-portal#move-aging-data-to-a-cooler-tier"}],"poster":"Drummer","content":"YES-NO-YES-YES..Only \"Move to Cool\" is NO","timestamp":"1632521940.0"},{"upvote_count":"6","comment_id":"424790","timestamp":"1628945220.0","poster":"mcbc","content":"Do not confuse other, answer is correct, some people knows the correct one but intentinally creating confusion."},{"comments":[{"content":"After another careful read, I think the given answer is correct. This premium account for block blob, so block blob and blob are the same in this context. Other are premium accounts are file / page blob","timestamp":"1628869800.0","comment_id":"424414","poster":"ning","upvote_count":"1"}],"upvote_count":"1","content":"Very confusing, block blob vs just blob, is the a real question, or typo some where?","poster":"ning","timestamp":"1628792940.0","comment_id":"423808"},{"upvote_count":"3","comment_id":"417900","content":"Answer is correct. \n\"You are developing an application that uses a premium block blob storage account.\" So all blobs are block blob.\nCorrect answer: Yes,Yes,Yes,Yes","timestamp":"1627740780.0","comments":[{"poster":"BeshoyRomany","timestamp":"1632657060.0","comment_id":"451817","upvote_count":"1","content":"you are totally right :) because there's any other types instead of blockBlobs only\nThe answer is :\nYES -YES -YES -YES"}],"poster":"SaNagh"},{"poster":"wolf_lu","content":"yes，yes，yes，yes","timestamp":"1627614240.0","comment_id":"417146","upvote_count":"2"},{"upvote_count":"15","poster":"NoWayJosee123","content":"daysAfterModificationGreaterThan 730 != all block blobs older then 730 days\nHow come nobody seems to have an issue with that. What about a block blob that has been modified at his 729 day birthday? Will it be deleted tomorrow. That would be inhuman!","comment_id":"415488","timestamp":"1627392240.0","comments":[{"comments":[{"upvote_count":"1","comments":[{"content":"I created a PR for the docs, let's see if the Microsoft accepts it.\n\nhttps://github.com/MicrosoftDocs/azure-docs/pull/89203","poster":"mattvasc","timestamp":"1646356980.0","comments":[{"upvote_count":"2","timestamp":"1646651760.0","comment_id":"562563","poster":"mattvasc","content":"Yeah, seems now that the docs is fine."}],"upvote_count":"1","comment_id":"560455"}],"content":"I think that instead of going through the wrong answer because the docs is also wrong, we should go for the right answer and report the mistake for Microsoft so they can fix it.","poster":"mattvasc","timestamp":"1646356020.0","comment_id":"560446"}],"timestamp":"1637574720.0","upvote_count":"3","content":"I would agree with you, but from the official MS docs:\n\"The following example shows a policy that deletes all block blobs older than 365 days.\"\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview?tabs=azure-portal#move-aging-data-to-a-cooler-tier\n\nSays \"all\" while it's the exact same example.\nSo I think the answer is Yes, Yes, Yes, Yes even though the last one is vague.","poster":"BasAZ","comment_id":"484070"}]},{"upvote_count":"1","timestamp":"1625355960.0","poster":"TakumaK","content":"Given answer is WRONG!","comment_id":"397883"},{"content":"Answer is correct as tierToCool, enableAutoTierToHotFromCool, tierToArchive is only supported for block blobs. Only delete is supported for delete,\nLink: https://docs.microsoft.com/en-us/azure/storage/blobs/storage-lifecycle-management-concepts?tabs=template","comments":[{"poster":"kairavdp27","upvote_count":"1","comment_id":"397432","content":"* delete is supported for both block and append blobs. (sorry for typo).","timestamp":"1625302200.0"}],"comment_id":"397431","upvote_count":"3","timestamp":"1625302140.0","poster":"kairavdp27"},{"timestamp":"1625151900.0","comments":[{"upvote_count":"2","poster":"ensa","content":"Al roll will aply to base blob.\n all are Yesssssssss","timestamp":"1634361840.0","comment_id":"462881"},{"comment_id":"397882","poster":"TakumaK","upvote_count":"1","content":"i like this kind of comment!","timestamp":"1625355900.0"},{"content":"No the given answer is correct for one reason that is the blob storage is a premium blockBlob storage so the blob types will be blockBlobs only","comment_id":"451819","timestamp":"1632657240.0","poster":"BeshoyRomany","upvote_count":"1"},{"timestamp":"1626062940.0","poster":"jkes80","comments":[{"poster":"jkes80","comment_id":"404371","upvote_count":"1","timestamp":"1626063120.0","content":"Only I think it should be:\nNo, No, YES, Yes. Because accessed blobs are tiered from cool to hot, independent of their type.","comments":[{"timestamp":"1627011780.0","upvote_count":"1","content":"Actually, those actions are also filtered to BlockBlobs, but the filter shows up below the actions declaration. So this also applies only to BlockBlobs.","poster":"Kode","comment_id":"412091"}]}],"comment_id":"404369","upvote_count":"1","content":"Agree, the anwsers don't mention the specific type of blob, while the filter only allows block blobs. Also see:\nhttps://docs.microsoft.com/nl-nl/azure/storage/blobs/storage-lifecycle-management-concepts?tabs=azure-portal"},{"comment_id":"407668","upvote_count":"1","poster":"j888","timestamp":"1626420180.0","content":"I do not have an issue with the given answer. The first question does indicate containers 1 and 2 that will be moved to cool storage after 60 and archive storage after. So Yes.\n \nThe 2nd and 3rd question does have blob types \"block blob\". The statement would mean more than 30 days but not exactly 30 days, so I believe this is a no.\nAnd Yes and Yes for the rest."}],"upvote_count":"11","content":"Answer is incorrect imho.\n\n\"Block blobs are moved to cool after 60\" Yes that's true but the next line \"Blobs that have not been modified in 120 days are moved to the archive tier\" is incorrect as only blobs that have the container prefix as mentioned are moved to archive (also not all blobs just block blobs with the container prefix will be archived).\n\nThe second and third questions are specifically worded as such that the don't mention block blobs. But the rule states only block blobs are moved and not for example append blobs. Therefore both of them are No.\n\nFinally the last one is true.\n\nCorrect answer:\nNo\nNo\nNo\nYes","poster":"Jurgen1234","comment_id":"396086"},{"upvote_count":"3","poster":"aradice","timestamp":"1625073600.0","comment_id":"394996","content":"box 1: line 14 and 15 \nbox 2: line 29\nbox 3: line 27\nbox 4: line 50\ncorrect","comments":[{"comment_id":"396951","comments":[{"comments":[{"content":"Question mentions that this is block blob storage account, so we only deal with block blobs anyway. So this discussion about which exact words were used is kinda moot. Answer is correct.","timestamp":"1626971880.0","poster":"Arrrqqq","comment_id":"411803","upvote_count":"1"}],"poster":"TakumaK","upvote_count":"1","content":"I agree you both. people saying given answer is correct basically lack of English or policy rules","comment_id":"397884","timestamp":"1625356140.0"},{"upvote_count":"1","timestamp":"1632657300.0","content":"No the given answer is correct for one reason that is the blob storage is a premium blockBlob storage so the blob types will be blockBlobs only","comment_id":"451821","poster":"BeshoyRomany"}],"upvote_count":"1","content":"agree Jurgen1234 , NO NO NO YES. Block type is important","poster":"aradice","timestamp":"1625235180.0"}]},{"upvote_count":"1","timestamp":"1625054880.0","poster":"Percy2112","content":"Given answer is correct.","comment_id":"394674"},{"timestamp":"1625050080.0","content":"Correct Answer","poster":"Drazz04","comment_id":"394605","upvote_count":"1"}],"isMC":false,"question_id":263,"unix_timestamp":1625050080,"answer_ET":"","url":"https://www.examtopics.com/discussions/microsoft/view/56299-exam-az-204-topic-4-question-32-discussion/","answer_description":"","exam_id":48},{"id":"mnDRN1vWbWzyr7MLA1QF","answer_ET":"CD","answer_images":[],"unix_timestamp":1625074680,"exam_id":48,"discussion":[{"timestamp":"1625589120.0","comment_id":"400144","poster":"Zulhin","comments":[{"timestamp":"1644249540.0","comment_id":"542524","upvote_count":"4","comments":[{"content":"D is good - https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/read-change-feed - it says: \"However, there are some scenarios where you might want the additional low level control of the pull model. These include:\n\nReading changes from a particular partition key\"","upvote_count":"1","comment_id":"1243053","poster":"ProtossOR89144","timestamp":"1720212900.0"},{"content":"Agree with C & D\n\"NOTE: Each correct selection is worth one point.\"","upvote_count":"3","timestamp":"1644571380.0","comment_id":"545207","poster":"Baskman"}],"poster":"Chiboy","content":"C is the correct answer. Each answer has two possible ways that in combination, gives the solution. Moreover, because of the requirement to \"Process changes to all partitions immediately\", D cannot be the answer or part of it since it \"processes the change feed by using the pull model on the container\""}],"upvote_count":"43","content":"Answer C & D.\n\"What are two possible ways to achieve this goal?\""},{"upvote_count":"16","comment_id":"395028","comments":[{"comment_id":"396090","poster":"Jurgen1234","upvote_count":"3","timestamp":"1625152020.0","content":"I agree"}],"timestamp":"1625074680.0","poster":"aradice","content":"c and d ? https://docs.microsoft.com/en-us/azure/cosmos-db/read-change-feed#azure-functions\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/change-feed-pull-model#using-feedrange-for-parallelization"},{"comment_id":"1303836","content":"Selected Answer: CD\nAzure Function with Cosmos DB Trigger: Automatically handles partitioning and parallelization, making it easier to process changes in real-time.\nAzure Function with FeedIterator and FeedRange: Provides manual control over change feed processing and allows for efficient parallelization.","poster":"Vichu_1607","timestamp":"1730096640.0","upvote_count":"1"},{"content":"FeedIterator is meant to be implemented in a persistent process; it runs indefinitely. A serverless environment like Functions isn't really appropriate. It should be running e.g. as a daemon that auto starts and restarts on failure etc. Which makes me question if D.","timestamp":"1727800920.0","poster":"obllew","upvote_count":"1","comment_id":"1292031"},{"content":"It is not D. It says that it uses the pull model on the *container*, but a change processor should pull from Cosmos, not the storage container. Good answers are B and C.","poster":"0cc50bf","upvote_count":"1","comment_id":"1265088","timestamp":"1723542960.0"},{"timestamp":"1720092900.0","comment_id":"1242035","content":"Selected Answer: CD\nAnswer C & D.","upvote_count":"1","poster":"Munwalinwali"},{"timestamp":"1713931140.0","upvote_count":"1","content":"Selected Answer: CD\nC: \"Because Azure Functions uses the change feed processor behind the scenes, it automatically parallelizes change processing across your container's partitions.\"\nD: \"You can use the change feed pull model to consume the Azure Cosmos DB change feed at your own pace. Similar to the change feed processor, you can use the change feed pull model to parallelize the processing of changes across multiple change feed consumers.\"","comment_id":"1201118","poster":"carlosfaria82"},{"poster":"raymond_abcd","comment_id":"1132374","upvote_count":"1","timestamp":"1706258460.0","content":"Answer C and D\nC you need to implement the lease container in the function for dynamic scaling and works with multiple partitions. See: https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/change-feed-functions.\n\nD is also correct as it is described here: https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/read-change-feed"},{"timestamp":"1706086620.0","content":"Selected Answer: CD\nC. Azure Function with Cosmos DB Trigger\nAzure Functions can be triggered by changes in Cosmos DB, allowing for immediate processing of inserts and updates.\nD. Azure Function with FeedIterator and FeedRange for Change Feed\nThis method manually handles the change feed processing, allowing for detailed control over parallelization and processing logic.","comment_id":"1130413","poster":"FeriAZ","upvote_count":"1"},{"timestamp":"1705503060.0","content":"Both options B and D can be used to process Azure Cosmos DB operations efficiently:\nB. Create a background job in an Azure Kubernetes Service and implement the change feed feature of the SDK.This option involves creating a background job using Azure Kubernetes Service (AKS) and implementing the change feed feature of the Azure Cosmos DB SDK. AKS provides scalability, and you can parallelize the processing by distributing work across multiple pods in the AKS cluster.D. Create an Azure Function that uses a FeedIterator object that processes the change feed by using the pull model on the container. Use a FeedRange object to parallelize the processing of the change feed across multiple functions.\nThis option involves using Azure Functions with the change feed trigger for Azure Cosmos DB. By using the FeedIterator and FeedRange objects, you can parallelize the processing of the change feed across multiple Azure Functions.","poster":"manopeydakon","comment_id":"1125068","upvote_count":"1"},{"content":"B and C for me. AKS containers can scale and job just runs in background. Funcs can scale and trigger on cosmos.\nA is an api so whats it triggering on?\nD also doesnt mention what it would trigger on","poster":"lednari","upvote_count":"1","timestamp":"1702483980.0","comment_id":"1095632"},{"poster":"Dianahu","upvote_count":"2","comment_id":"963662","timestamp":"1690371000.0","content":"isn't the change feed estimator only for monitoring? it is the change feed processor who does the work https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-use-change-feed-estimator?tabs=dotnet so it is C&D"},{"poster":"adilkhan","comments":[{"comment_id":"1022404","timestamp":"1696173240.0","poster":"Ciupaz","content":"In my case chatGPT response is A and C.","upvote_count":"1","comments":[{"upvote_count":"1","content":"Bard, instead, returns: A - D","comments":[{"comment_id":"1302832","poster":"Mattt","upvote_count":"1","content":"My B,C","timestamp":"1729854300.0"}],"comment_id":"1076149","timestamp":"1700558040.0","poster":"Ciupaz"}]}],"comment_id":"858375","upvote_count":"2","content":"C,D chatGPT","timestamp":"1680393840.0"},{"content":"CD (36%)\nD (21%)\nA (21%)\nOther ...OMG :D","timestamp":"1677801240.0","poster":"adilkhan","comments":[{"content":"It's C and D, you can exclude A because it's sequential but in the question it's required to allow parallelization instead.","timestamp":"1720089420.0","comment_id":"1241974","upvote_count":"1","poster":"giuliohome"}],"comment_id":"827547","upvote_count":"7"},{"comment_id":"796261","poster":"mabdo","content":"similar was on 2/23","upvote_count":"1","timestamp":"1675357800.0"},{"upvote_count":"1","timestamp":"1674592320.0","comment_id":"786934","poster":"alexein74","content":"Selected Answer: CD\nI agree with Zulhin."},{"content":"Selected Answer: CD\nI agree with Zulhin.","upvote_count":"1","poster":"ldenouter","timestamp":"1673895300.0","comment_id":"778126"},{"upvote_count":"1","timestamp":"1672409340.0","comment_id":"762008","poster":"rotimislaw","content":"Selected Answer: AC\nA & C - simplicity is your best friend"},{"timestamp":"1668286080.0","poster":"AB1453","comment_id":"716923","content":"Selected Answer: AC\nA and C","upvote_count":"1"},{"comment_id":"710438","poster":"OPT_001122","timestamp":"1667473620.0","content":"Selected Answer: CD\nc and d","upvote_count":"2"},{"comment_id":"702361","timestamp":"1666546560.0","upvote_count":"2","poster":"VirusZer0","content":"Selected Answer: CD\nC and D"},{"timestamp":"1665054060.0","upvote_count":"1","poster":"gmishra88","content":"Another question created to confuse a person who knows change feed processor and did not notice the option had change feed estimator in an exam setting. When the pull model is not the recommended option I should also know that ?","comment_id":"687693"},{"content":"Selected Answer: D\nC & D, buddies.\n\nC: Push model, Az Functions automatically parallelizes change processing https://docs.microsoft.com/en-us/azure/cosmos-db/sql/read-change-feed#azure-functions\n\n\nD: Pull model, use FeedRange for parallelization https://docs.microsoft.com/en-us/azure/cosmos-db/sql/change-feed-pull-model#using-feedrange-for-parallelization","comment_id":"568103","timestamp":"1647316560.0","upvote_count":"4","poster":"iamstudying"},{"upvote_count":"3","content":"CD seems correct answer","timestamp":"1646854680.0","poster":"SivajiTheBoss","comment_id":"564270"},{"timestamp":"1646165040.0","poster":"Dev666","comment_id":"558985","content":"Selected Answer: A\nA and C ?","upvote_count":"1"},{"timestamp":"1645236600.0","content":"Selected Answer: C\nA seems to be the answer","comment_id":"550613","upvote_count":"1","poster":"Vantirup"},{"upvote_count":"2","poster":"ScubaDiver123456","content":"Selected Answer: A\nVoting for A and C\n\n\"A\" seems to come out of this explanation: https://docs.microsoft.com/en-us/azure/cosmos-db/sql/how-to-use-change-feed-estimator#implement-the-change-feed-estimator","timestamp":"1644727860.0","comment_id":"546227","comments":[{"poster":"Bogdan75","comment_id":"564826","upvote_count":"1","content":"I also originally considered A, but I think it's wrong – see the example in your link, and notice the change feed estimator triggers a delegate which is a C# function; using Azure App Service API in this context wouldn't make sense.","timestamp":"1646920320.0"}]},{"upvote_count":"1","comment_id":"463550","poster":"whymatter","comments":[{"poster":"mattvasc","upvote_count":"1","comment_id":"560459","timestamp":"1646357220.0","content":"To me seems like the solution is incomplete, didn't handle with the part \"Allow parallelization of change processing.\"\n\n(It is possible to do with AKS, but the answer didn't mention it.)"}],"content":"Why not the AKS solution?","timestamp":"1634476440.0"},{"content":"This question is for two options in the real exam.. C and D final answer","comment_id":"451122","timestamp":"1632522000.0","poster":"Drummer","upvote_count":"5"},{"comments":[{"comment_id":"423844","poster":"ning","content":"https://docs.microsoft.com/en-us/azure/cosmos-db/how-to-use-change-feed-estimator here is document for change feed estimator","comments":[{"comment_id":"457577","timestamp":"1633420260.0","content":"The purpose of the \"change feed estimator\" is \"to monitor the progress of your change feed processor instances as they read the change feed\". Just to know if your \"change feed processor is lagging behind or not\".\nSo C & D.","poster":"MiraA","upvote_count":"5"}],"upvote_count":"1","timestamp":"1628800860.0"}],"upvote_count":"8","comment_id":"423812","poster":"ning","content":"A & C tested with codes","timestamp":"1628793300.0"},{"comment_id":"412398","upvote_count":"1","poster":"ZodiaC","timestamp":"1627030380.0","content":"D says OBJEXT, I think is FAULT!"},{"content":"Answer is D\nChange-feed will save changes in \"lease\" container. and then function app will update storage account. \nhttps://docs.microsoft.com/en-us/azure/cosmos-db/change-feed-pull-model","comment_id":"397147","comments":[{"poster":"ReniRechner","comment_id":"560567","timestamp":"1646375400.0","upvote_count":"1","content":"what would be the trigger in the D case?\nWe require something that allows for scaling."}],"upvote_count":"1","poster":"jay158","timestamp":"1625256300.0"}],"answer_description":"","answers_community":["CD (50%)","D (20%)","A (15%)","Other"],"topic":"4","url":"https://www.examtopics.com/discussions/microsoft/view/56477-exam-az-204-topic-4-question-33-discussion/","answer":"CD","question_images":[],"choices":{"C":"Create an Azure Function to use a trigger for Azure Cosmos DB. Configure the trigger to connect to the container.","A":"Create an Azure App Service API and implement the change feed estimator of the SDK. Scale the API by using multiple Azure App Service instances.","D":"Create an Azure Function that uses a FeedIterator object that processes the change feed by using the pull model on the container. Use a FeedRange object to parallelize the processing of the change feed across multiple functions.","B":"Create a background job in an Azure Kubernetes Service and implement the change feed feature of the SDK."},"question_id":264,"question_text":"You are developing a solution that will use a multi-partitioned Azure Cosmos DB database. You plan to use the latest Azure Cosmos DB SDK for development.\nThe solution must meet the following requirements:\n✑ Send insert and update operations to an Azure Blob storage account.\n✑ Process changes to all partitions immediately.\n✑ Allow parallelization of change processing.\nYou need to process the Azure Cosmos DB operations.\nWhat are two possible ways to achieve this goal? Each correct answer presents a complete solution.\nNOTE: Each correct selection is worth one point.","isMC":true,"timestamp":"2021-06-30 19:38:00"},{"id":"qHkTbMKD75wEema9nz0e","timestamp":"2021-06-30 14:36:00","answer_description":"Box 1: No -\nYou set the highest, or maximum RU/s Tmax you don't want the system to exceed. The system automatically scales the throughput T such that 0.1* Tmax <= T <=\nTmax.\nIn this example we have autoscaleMaxThroughput = 5000, so the minimum throughput for the container is 500 R/Us.\n\nBox 2: No -\nFirst query: SELECT * FROM c WHERE c.EmployeeId > '12345'\nHere's a query that has a range filter on the partition key and won't be scoped to a single physical partition. In order to be an in-partition query, the query must have an equality filter that includes the partition key:\nSELECT * FROM c WHERE c.DeviceId > 'XMS-0001'\n\nBox 3: Yes -\nExample of In-partition query:\nConsider the below query with an equality filter on DeviceId. If we run this query on a container partitioned on DeviceId, this query will filter to a single physical partition.\nSELECT * FROM c WHERE c.DeviceId = 'XMS-0001'\nReference:\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/how-to-choose-offer https://docs.microsoft.com/en-us/azure/cosmos-db/how-to-query-container","question_id":265,"unix_timestamp":1625056560,"url":"https://www.examtopics.com/discussions/microsoft/view/56335-exam-az-204-topic-4-question-34-discussion/","discussion":[{"comment_id":"395050","timestamp":"1640894040.0","poster":"aradice","comments":[{"timestamp":"1662650700.0","upvote_count":"3","comment_id":"563424","poster":"xRiot007","content":"The documentation on the second point could be better. \nThey put the most important part at the end and that is that even if the query uses the partition key it MUST use an equality filter to be considered in-partition."},{"content":"100% correct!","timestamp":"1644429240.0","comment_id":"422223","poster":"finnishr","upvote_count":"2"}],"upvote_count":"44","content":"correct:\n1° no => line 6\n2° no => \nhttps://docs.microsoft.com/en-us/azure/cosmos-db/how-to-choose-offer#overview-of-provisioned-throughput-types\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/how-to-query-container#in-partition-query\n\"Here's a query that has a range filter on the partition key and won't be scoped to a single physical partition. In order to be an in-partition query, the query must have an equality filter that includes the partition key: SELECT * FROM c WHERE c.DeviceId > 'XMS-0001'\"\n3° : yes => partition key is EmployeeId. https://docs.microsoft.com/en-us/azure/cosmos-db/how-to-query-container#cross-partition-query"},{"content":"1. No : Because as question specifies max RUs = 5000, so minimum RUs = 5000/10 = 500\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/how-to-choose-offer#overview-of-provisioned-throughput-types\n2. No : In-partition query needs equality filter that is missing here\n3. Yes: Though we have equality filter here, 'UserId' is not a partition key here.\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/sql/how-to-query-container","timestamp":"1649851800.0","comment_id":"461528","poster":"HimanshuNankani","upvote_count":"27"},{"comment_id":"1203417","poster":"neelkanths","timestamp":"1730105820.0","upvote_count":"2","content":"Got it on 20 April 2024...Marks > 900...All questions from examtopics 400 questions...\nanswer is correct..."},{"poster":"FeriAZ","upvote_count":"5","comment_id":"1125799","timestamp":"1721296740.0","content":"Minimum Throughput for the Container is 400 R/Us:\nAnswer: No. In Cosmos DB, the minimum throughput for a container with autoscale is 10% of the maximum throughput. Since the maximum is set to 5000 RUs, the minimum would be 500 RUs (10% of 5000).\nThe First Query Statement is an In-Partition Query:\nAnswer: No. Though it filters on the partition key, it uses a range condition, potentially involving multiple partitions.\nThe Second Query Statement is a Cross-Partition Query:\nAnswer: Yes. It filters on a non-partition key (UserID), necessitating a scan across multiple partitions."},{"timestamp":"1719190920.0","comment_id":"1104427","upvote_count":"1","poster":"bgbgvfvf","content":"Given answers are correct"},{"content":"Y, N, Y\nMin is 400 RUs. (5000/100 = 50 which is smaller than 400)\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/concepts-limits#minimum-throughput-on-container","poster":"lednari","comment_id":"1095643","timestamp":"1718288760.0","upvote_count":"2"},{"upvote_count":"2","content":"Got this question in my exam 2023.09.25. Had contoso Case Study","timestamp":"1711386660.0","poster":"leviatas","comment_id":"1016903"},{"poster":"applepie","comment_id":"967170","content":"got this question today, answer NNY- 7/30/2023, score 895/1000","timestamp":"1706629020.0","upvote_count":"2"},{"poster":"NightshadeRC","upvote_count":"2","timestamp":"1706244420.0","comment_id":"963281","content":"Had this question in today's exam: 2023-07-26"},{"upvote_count":"3","poster":"[Removed]","timestamp":"1696475700.0","comment_id":"861722","content":"Got this in exam today (5 April 2023)"},{"poster":"Saluk_DE","upvote_count":"1","comment_id":"855457","timestamp":"1696060500.0","content":"Question was on exam 2023-03-30"},{"comment_id":"827813","poster":"proffesormuffin","comments":[{"poster":"Xardas","content":"Highest RU/s ever provisioned on the container * 0.1 = 500","comments":[{"comments":[{"content":"'max / 100', this one is for the manual throughput.\n'max / 10', this is for the autoscale throughput.","timestamp":"1725608940.0","upvote_count":"1","poster":"stlim83","comment_id":"1167050"}],"upvote_count":"1","poster":"Xardas","content":"This link says formula is max * 0.1\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/how-to-choose-offer#overview-of-provisioned-throughput-types\n\nBut this link says it is max / 100 \nhttps://learn.microsoft.com/en-us/azure/cosmos-db/concepts-limits\n\nWhich is right????","comment_id":"955379","timestamp":"1705587360.0"}],"upvote_count":"1","comment_id":"955367","timestamp":"1705586880.0"}],"upvote_count":"2","timestamp":"1693724940.0","content":"400 looks correct to me.\n\n\"To estimate the minimum throughput required of a container with manual throughput, find the maximum of:\n\n400 RU/s\nCurrent storage in GB * 1 RU/s\nHighest RU/s ever provisioned on the container / 100\"\n5000/100 = 50 not 500\nso MAX( 400 ,50) = 400 ?\n\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/concepts-limits"},{"comment_id":"796273","content":"on 2/23","timestamp":"1690990020.0","poster":"mabdo","upvote_count":"2"},{"content":"Given answers are correct.","comment_id":"787301","upvote_count":"1","poster":"Esward","timestamp":"1690256520.0"},{"comment_id":"687697","upvote_count":"3","timestamp":"1680779220.0","poster":"gmishra88","content":"First option is a question that punishes people who tried to set the RUs and remembered 400 RU as the minimum. If you never tried, you will find some relation with 5000 and 10% is a nice relation.","comments":[{"timestamp":"1693725480.0","content":"it's 1% not 10% so max 400,50 is 400.\n\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/concepts-limits","upvote_count":"1","poster":"proffesormuffin","comments":[{"poster":"fuji36850","content":"I think you looked on wrong part of the doc, in 'autoscale' (mentioned in question) it is 10%","upvote_count":"1","comment_id":"1205960","timestamp":"1730623380.0"}],"comment_id":"827820"}]},{"upvote_count":"1","content":"Answer\nNo, No, Yes, got this in the cosmos dp-420 exam","poster":"[Removed]","timestamp":"1678774860.0","comment_id":"668594"},{"upvote_count":"2","timestamp":"1665415320.0","comment_id":"583748","content":"No, \nNo, \nYes","poster":"Azprep"},{"timestamp":"1663035000.0","upvote_count":"2","content":"Got it on 03/2022, I chose as below:\nThe minimum throughput for the container is 400 R/Us = No\nThe first query statement is an in-partition query. = No\nThe second query statement is a cross-partiton query. = Yes","comment_id":"566539","poster":"meoukg"},{"upvote_count":"3","content":"No\nNo\nYes\n\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/sql/how-to-query-container#in-partition-query\n\"Here's a query that has a range filter on the partition key and won't be scoped to a single physical partition. In order to be an in-partition query, the query must have an equality filter that includes the partition key\"","comment_id":"517180","poster":"leonidn","timestamp":"1656990900.0"},{"poster":"xortan","timestamp":"1647173820.0","comment_id":"443902","upvote_count":"2","content":"\"Here's a query that has a range filter on the partition key and won't be scoped to a single physical partition. In order to be an in-partition query, the query must have an equality filter that includes the partition key.\nSELECT * FROM c WHERE c.DeviceId > 'XMS-0001'\"\n\nThis is from https://docs.microsoft.com/en-us/azure/cosmos-db/sql/how-to-query-container#in-partition-query\n\nSo based on this, the second cannot be an in-partition query, because it is not an equality filter."},{"comment_id":"424801","poster":"mcbc","timestamp":"1644852420.0","content":"No->Yes->Yes\n\nPartitionKey EmaployeeID. use common sense","upvote_count":"1"},{"poster":"MK22","comment_id":"422473","timestamp":"1644477300.0","upvote_count":"2","content":"Provided answer is correct"},{"poster":"kevifarr","timestamp":"1643810400.0","upvote_count":"7","content":"the answer should be \nNo \nYes\nYes\n\nIn this question EmployeeId is the partitionKeyPath\n\"In-partition query\nWhen you query data from containers, if the query has a partition key filter specified, Azure Cosmos DB automatically optimizes the query. It routes the query to the physical partitions corresponding to the partition key values specified in the filter.\nConsider the below query with an equality filter on DeviceId. If we run this query on a container partitioned on DeviceId,\nExample\nSELECT * FROM c WHERE c.DeviceId > 'XMS-0001'\"\n\n\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/how-to-query-container#cross-partition-query","comments":[{"content":"2 is No,\n\"In order to be an in-partition query, the query must have an ~equality filter~ that includes the partition key\"\n\"a query that has a ~range filter~ on the partition key and won't be scoped to a single physical partition\"\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/sql/how-to-query-container#cross-partition-query","upvote_count":"2","timestamp":"1653739020.0","poster":"aruni_mishra","comment_id":"489170"},{"content":"But it helps when find for equal operator. Here query is for range i.e. greater than, so it will be cross partition.","poster":"altafpatel1984","timestamp":"1653130380.0","upvote_count":"4","comment_id":"483253"},{"poster":"Quirkafleeg","upvote_count":"5","comment_id":"445834","content":"c.DeviceId > 'XMS-0001' is an example of a range filter, not an equality filter","timestamp":"1647433740.0"}],"comment_id":"418695"},{"content":"The answer should be N-N-N as c.UserID is not a partition key.","comment_id":"412465","comments":[{"content":"my bad, do not consider it.","comment_id":"412636","upvote_count":"5","timestamp":"1642958820.0","poster":"argoth"}],"upvote_count":"1","poster":"argoth","timestamp":"1642942020.0"},{"poster":"txbka","comments":[{"upvote_count":"4","content":"Minimum is not 400, it is 10% for max value. Answer is No","timestamp":"1641315720.0","comment_id":"398455","poster":"vtomy"},{"timestamp":"1641020040.0","comment_id":"395517","upvote_count":"1","comments":[{"poster":"LauraGF","content":"It does not ask what the minimum should be, if not what it is in this specific case. There is a variable that indicates \"$ autoscaleMaxThroughput = 5000\" therefore it is 500 R / us","comment_id":"429791","timestamp":"1645609620.0","upvote_count":"3"},{"poster":"Jurgen1234","comment_id":"396093","content":"Answer should be no, see https://docs.microsoft.com/en-us/azure/cosmos-db/concepts-limits#limits-for-autoscale-provisioned-throughput","upvote_count":"1","timestamp":"1641057240.0"}],"poster":"Brain","content":"400 is correct. https://docs.microsoft.com/hu-hu/azure/cosmos-db/concepts-limits"}],"comment_id":"394704","timestamp":"1640874960.0","upvote_count":"1","content":"First seems true \"A minimum of 400 RU/s throughput must be provisioned for Azure Cosmos DB containers and databases.\""}],"topic":"4","question_text":"HOTSPOT -\nYou have an Azure Web app that uses Cosmos DB as a data store. You create a CosmosDB container by running the following PowerShell script:\n$resourceGroupName = \"testResourceGroup\"\n$accountName = \"testCosmosAccount\"\n$databaseName = \"testDatabase\"\n$containerName = \"testContainer\"\n$partitionKeyPath = \"/EmployeeId\"\n$autoscaleMaxThroughput = 5000\n\nNew-AzCosmosDBSqlContainer -\n-ResourceGroupName $resourceGroupName\n-AccountName $accountName\n-DatabaseName $databaseName\n-Name $containerName\n-PartitionKeyKind Hash\n-PartitionKeyPath $partitionKeyPath\n-AutoscaleMaxThroughput $autoscaleMaxThroughput\nYou create the following queries that target the container:\nSELECT * FROM c WHERE c.EmployeeId > '12345'\nSELECT * FROM c WHERE c.UserID = '12345'\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","answer_images":["https://www.examtopics.com/assets/media/exam-media/04273/0037800002.png"],"exam_id":48,"answers_community":[],"question_images":["https://www.examtopics.com/assets/media/exam-media/04273/0037800001.png"],"answer":"","answer_ET":"","isMC":false}],"exam":{"lastUpdated":"12 Apr 2025","isMCOnly":false,"isBeta":false,"name":"AZ-204","isImplemented":true,"numberOfQuestions":452,"id":48,"provider":"Microsoft"},"currentPage":53},"__N_SSP":true}