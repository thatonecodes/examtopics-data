{"pageProps":{"questions":[{"id":"SsKRVsQqn0Nlu8SxNUFf","isMC":false,"unix_timestamp":1585736760,"answers_community":[],"question_images":["https://www.examtopics.com/assets/media/exam-media/03774/0019700001.png"],"question_text":"HOTSPOT -\nYou are designing a solution for a company. You plan to use Azure Databricks.\nYou need to recommend workloads and tiers to meet the following requirements:\n✑ Provide managed clusters for running production jobs.\n✑ Provide persistent clusters that support auto-scaling for analytics processes.\n✑ Provide role-based access control (RBAC) support for Notebooks.\nWhat should you recommend? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","answer_ET":"","timestamp":"2020-04-01 12:26:00","topic":"2","discussion":[{"content":"Based on MS documentation (https://azure.microsoft.com/en-us/pricing/details/databricks/) the answers should be: Box 1 = Data Engineering and Data Analytics, Box 2 = Data Analytics only, Box 3 = Standard, Box 4 = Data Engineering and Data Analytics, Box 5 = Premium","poster":"Filippo","comments":[{"timestamp":"1589415420.0","comment_id":"88568","upvote_count":"4","poster":"Niteen","content":"It's perfect.","comments":[{"timestamp":"1589415480.0","content":"Filippo - It's perfect.","poster":"Niteen","comment_id":"88569","upvote_count":"2"}]},{"comment_id":"140338","timestamp":"1595338380.0","content":"I did validate too. it is perfect.","poster":"rohitbinnani","upvote_count":"2"},{"timestamp":"1603187460.0","upvote_count":"2","content":"Yes, perfect!","comment_id":"203096","poster":"D_Duke"},{"poster":"cadio30","comment_id":"366828","comments":[{"poster":"cadio30","upvote_count":"2","content":"To justify this solution feel free to check out the url below\n\nReference: https://www.azure.cn/en-us/pricing/details/databricks/","timestamp":"1623299460.0","comment_id":"378714"}],"content":"Perfect answer with citation of reference. Cheers!","timestamp":"1622003460.0","upvote_count":"1"},{"timestamp":"1612648200.0","upvote_count":"4","content":"Since the ask is to run Production Jobs, why not for Box 1 ==> Data Engineering only? Data Analytics is for Data Scientists for interactive workloads...","comments":[],"poster":"rajneesharora","comment_id":"285105"}],"comment_id":"78329","upvote_count":"125","timestamp":"1587630600.0"},{"comment_id":"123817","poster":"ToNiOZ45","upvote_count":"20","timestamp":"1593564360.0","content":"After spending too much time on examtopics, I'm a robot!"},{"upvote_count":"1","poster":"hsetin","timestamp":"1630870140.0","content":"i thought Autoscaling requires premium??","comment_id":"439899"},{"timestamp":"1629349800.0","upvote_count":"2","poster":"Bhagya123456","content":"The pricing plans have different names now and many of the features has been combined. So this question is not valid today.","comment_id":"427227"},{"timestamp":"1626341640.0","poster":"RThakor","upvote_count":"1","content":"so many updates for same question so which answer is correct one ?","comment_id":"406954"},{"upvote_count":"1","content":"https://sql-stack.com/2018/11/29/azure-databricks-workloads-and-job-scheduling/\n\n1. Production Job (scheduled operations) - Data Engineering Only, Standard Tier\n2. Persistent for analytics, auto-scaling - Data Analytics Only, Standard Tier\n3. Role-based access - For both Data Engineering and Data Analytics, Premium Tier","comment_id":"386566","timestamp":"1624219920.0","poster":"vrmei"},{"comment_id":"314748","content":"https://azure.microsoft.com/en-us/pricing/details/databricks/\nPersistent clusters for analytics is only available for All Purpose(data Analyst) Tier","upvote_count":"1","poster":"sturcu","timestamp":"1616149200.0"},{"upvote_count":"7","comment_id":"270506","comments":[{"comment_id":"331941","upvote_count":"1","poster":"suman13","timestamp":"1617972060.0","content":"perfect"}],"content":"Best article I have found that explains this: https://sql-stack.com/2018/11/29/azure-databricks-workloads-and-job-scheduling/#:~:text=The%20Data%20Engineering%20workload%20is,the%20duration%20of%20the%20job.&text=This%20workload%20is%20also%20designed,the%20administrator%20in%20the%20workload.\n\n1. Data engineering and standard (data engineering is meant for jobs, will tear itself down)\n2. Data analytics and standard (is meant for ad-hoc analysis, will stay up)\n3. Data engineer and analytics and premium (RBAC is a premium feature)","timestamp":"1610993700.0","poster":"ThijsN"},{"content":"Box 1: Data Engineering (Jobs Compute) and Data Analytics (All-Purpose Compute)\nBox 2: Data Engineering (Jobs Compute) and Data Analytics (All-Purpose Compute)\nBox 3: Standard\nBox 4: Data Engineering (Jobs Compute) and Data Analytics (All-Purpose Compute)\nBox 5: Premium","timestamp":"1608998520.0","poster":"Ab5381","comment_id":"252740","upvote_count":"5"},{"content":"the original answer is correct","comment_id":"250311","timestamp":"1608658200.0","poster":"littlebear1","upvote_count":"2"},{"content":"https://azure.microsoft.com/en-us/pricing/details/databricks/\nCredit to Filippo for the link and mapping of answers to the details in the link","comment_id":"239027","poster":"syu31svc","timestamp":"1607502780.0","upvote_count":"1"},{"content":"from an efficiency point of view why cant we need Box 1 be Data Engineering only (Jobs Light Compute), as its less price and does the production job.","poster":"ttAsh","timestamp":"1607391240.0","upvote_count":"1","comment_id":"237778"},{"timestamp":"1598008140.0","upvote_count":"1","comment_id":"162892","poster":"Arsa","comments":[{"timestamp":"1598008920.0","content":"ignore this.\nBox1 = Data Engineering\n\nBox2 = Data Analytics only\nBox4 = Standard\n\nBox3 = Data Analytics only\nBox5 = Premium","upvote_count":"1","poster":"Arsa","comment_id":"162897","comments":[{"poster":"M0e","upvote_count":"6","timestamp":"1603461120.0","comment_id":"204696","content":"ignore this!\nBox 1: Data Engineering and Data Analytics\nBox 2: Data Analytics only\nBox 3: Standard\nBox 4: Data Engineering and Data Analytics\nBox 5: Premium\n\nsource: https://azure.microsoft.com/en-us/pricing/details/databricks/"}]},{"upvote_count":"1","poster":"dsyouness","timestamp":"1603181100.0","content":"True source : https://databricks.com/fr/product/azure-pricing","comment_id":"203047"}],"content":"Box1 = Data Analytics & Data Engineering\n\nBox2 = Data Analytics & Data Engineering\nBox4 = Standard\n\nBox3 = Data Analytics & Data Engineering\nBox5 = Premium"},{"comment_id":"140099","timestamp":"1595315280.0","comments":[{"comment_id":"215983","poster":"User27069","upvote_count":"5","content":"https://azure.microsoft.com/en-us/pricing/details/databricks/\n\nReading this link, it looks like Data Analytics has been rebranded to \"All purpose Compute\", and Data Engineering to \"Jobs Compute\". In which case, the answers given by wak are correct.","timestamp":"1604931300.0"}],"poster":"Mittleme","upvote_count":"3","content":"Phew . these original answers are messed up and confusing . even though we have correct answers in the link. the answers provided are totally different"},{"upvote_count":"11","content":"Box1 = Data Analytics & Data Engineering\nBox2 = Data Analytics\nBox3 = Data Analytics & Data Engineering\nBox4 = Standard\nBox5 = Premium\nAs per https://azure.microsoft.com/en-us/pricing/details/databricks/","poster":"wak","comment_id":"136812","timestamp":"1594946940.0"},{"upvote_count":"1","comments":[{"poster":"AhmedReda","content":"I think Box 4 = Standard as mentioned in the table and per @Filippo \nTable header is Standard tier features in the below link\n===============================================\nhttps://azure.microsoft.com/en-us/pricing/details/databricks/","comment_id":"119609","upvote_count":"1","timestamp":"1593102240.0","comments":[{"timestamp":"1596976740.0","comment_id":"153605","upvote_count":"1","content":"Persistent clusters for analytics is a standard tier (box 4) feature for data analytics (box 3) workload. Filippo has the provided the correct answer.","poster":"Treadmill"}]}],"poster":"vvt","content":"As per https://azure.microsoft.com/en-us/pricing/details/databricks/ box 1,2,4 should be Data Engineering and Data Analytics, 5,4=Premium","comment_id":"116315","timestamp":"1592822820.0"},{"poster":"drdean","upvote_count":"1","content":"https://databricks.com/product/azure-pricing","timestamp":"1591832580.0","comments":[{"comments":[{"content":"Box 3 can be Standard. See the \"Autopilot\" option in the Standard plan on this link: https://databricks.com/product/azure-pricing","upvote_count":"1","timestamp":"1610526720.0","poster":"mohowzeh","comment_id":"266118"}],"upvote_count":"2","content":"Box 2 should be premium for - Optimized autoscaling of compute","poster":"drdean","comment_id":"108039","timestamp":"1591904280.0"}],"comment_id":"107284"},{"content":"I think box 1 should be Data Engineering and Data Analytics.","upvote_count":"3","poster":"Tyrus429","comment_id":"77735","comments":[{"poster":"MamadouNiang","timestamp":"1588673580.0","content":"Production OK for both. But I am not sure about \"managed\" clusters. To me it means \"automated,workloads\" = Engineering","comment_id":"84047","upvote_count":"1"}],"timestamp":"1587529620.0"},{"comment_id":"72076","content":"2nd box in the tier section should be standard","upvote_count":"10","poster":"avestabrzn","timestamp":"1586255460.0"}],"answer":"","exam_id":66,"url":"https://www.examtopics.com/discussions/microsoft/view/17755-exam-dp-201-topic-2-question-43-discussion/","answer_description":"Box 1: Data Engineering Only -\nBox 2: Data Engineering and Data Analytics\n\nBox 3: Standard -\n\nBox 4: Data Analytics only -\n\nBox 5: Premium -\nPremium required for RBAC. Data Analytics Premium Tier provide interactive workloads to analyze data collaboratively with notebooks\nReference:\nhttps://azure.microsoft.com/en-us/pricing/details/databricks/","answer_images":["https://www.examtopics.com/assets/media/exam-media/03774/0019700002.png"],"question_id":106},{"id":"Jilqm6pDgMwSWvtTfD7Q","choices":{"A":"Azure Batch","B":"Azure Stream Analytics","D":"Azure HDInsight","C":"Azure Databricks"},"topic":"2","isMC":true,"answer":"C","answer_description":"A databrick job is a way of running a notebook or JAR either immediately or on a scheduled basis.\nAzure Databricks has two types of clusters: interactive and job. Interactive clusters are used to analyze data collaboratively with interactive notebooks. Job clusters are used to run fast and robust automated workloads using the UI or API.\nYou can visualize Data with Azure Databricks and Power BI Desktop.\nReference:\nhttps://docs.azuredatabricks.net/user-guide/clusters/index.html https://docs.azuredatabricks.net/user-guide/jobs.html","question_id":107,"answer_ET":"C","answer_images":[],"answers_community":[],"question_images":[],"question_text":"You design data engineering solutions for a company.\nA project requires analytics and visualization of large set of data. The project has the following requirements:\n✑ Notebook scheduling\n✑ Cluster automation\n✑ Power BI Visualization\nYou need to recommend the appropriate Azure service. Your solution must minimize the number of services required.\nWhich Azure service should you recommend?","exam_id":66,"discussion":[{"content":"No doubts.. Databricks.. Correct answer!!!","poster":"VG2007","upvote_count":"9","comment_id":"348130","timestamp":"1620000300.0"}],"url":"https://www.examtopics.com/discussions/microsoft/view/51623-exam-dp-201-topic-2-question-44-discussion/","timestamp":"2021-05-03 02:05:00","unix_timestamp":1620000300},{"id":"n3KAsRv9ZMlAIrdQGbGc","exam_id":66,"topic":"2","timestamp":"2021-03-15 12:15:00","discussion":[{"timestamp":"1616000280.0","content":"I would rather have\nIntegrate on premises data to Cloud : ADF\nDevelop notebooks to Transform Data : DataBricks\nRun Notebooks : ADF (Azure Databricks notebooks can be run within an ADF pipeline)\nLoad the Data : Use ADF to load the Data\nStore the Transformed Data: Azure Synapse Analyses","comment_id":"313457","upvote_count":"29","poster":"Needium","comments":[{"timestamp":"1617962220.0","poster":"maciejt","upvote_count":"1","content":"Exactly that was my take before seeing the solution.","comment_id":"331861"},{"comment_id":"366832","content":"Azure databricks can handle the loading of data from the notebook to the external tables of Azure Synapse unless the requirement is explicitly to export the file to another storage then use of ADF is the appropriate","upvote_count":"2","poster":"cadio30","timestamp":"1622004780.0"}]},{"poster":"Wendy_DK","comments":[{"poster":"BobFar","upvote_count":"1","timestamp":"1622925420.0","comment_id":"375433","content":"I am agree with you."}],"content":"Given answer is right.\nRemember requirement: Load the data into a massively parallel processing database for later analysis.\nADF and Batch can work together.\nref: https://docs.microsoft.com/en-us/azure/data-factory/v1/data-factory-data-processing-using-batch","comment_id":"356638","timestamp":"1620936600.0","upvote_count":"8"},{"comment_id":"427235","content":"Given Solution is 100% Correct.\n\nDo not confuse people with absurd arguments. I can do all the activities through Synapse Analysis also. That doesn't mean I will choose 5 times Synapse Analyses.","upvote_count":"2","timestamp":"1629351240.0","poster":"Bhagya123456"},{"poster":"tes","comment_id":"392240","content":"Just one change Run notebook is better done from ADF as we can orchestrate the sequence better. When run from databricks, it may not know the time of data retrieveal and also the next step, Azure Batch cannot be called from ADB","timestamp":"1624812420.0","upvote_count":"1"},{"upvote_count":"3","comment_id":"367571","poster":"Ous01","content":"Why note using Databricks to load the data? When the notebook finishes the process, it also can load the data into Synapse. Databricks can easily uploads results to Synapse, Azure SQL, and Azure Cosmos DB.","timestamp":"1622082480.0"},{"upvote_count":"4","timestamp":"1620000600.0","comment_id":"348133","poster":"VG2007","content":"Given Solution is correct.. no confusions..\nwhy anyone will use ADB to develop notebook and then use ADF to run them unless it is specifically specified ?","comments":[{"poster":"Larrave","upvote_count":"1","comment_id":"487646","content":"Because they were asking for a Data Engineering solution and having everything handled within one orchestration/etl tool makes definitely sense.","timestamp":"1637961660.0"}]},{"comment_id":"345472","poster":"davita8","timestamp":"1619708280.0","upvote_count":"3","content":"Load the data - Azure data factory\ntransformed data-azure sql data warehouse"},{"comment_id":"342596","timestamp":"1619359500.0","content":"Shouldn't Load the data (Box 4) be Azure Synapse Analytics ? It's the only one with a MPP engine, which is exactly what is mentioned in the question","poster":"aditya_064","upvote_count":"2"},{"comments":[{"upvote_count":"1","content":"I guess for loading the data into a massively parallel processing database , azure data batch is the better solution.\nhttps://docs.microsoft.com/en-us/azure/data-factory/v1/data-factory-data-processing-using-batch","timestamp":"1622925360.0","poster":"BobFar","comment_id":"375432"}],"content":"Why Azure Batch is better than ADF to load data?\nADF could be used to: Integrate from on-prem to azure, invoke notebook (developed in data bricks), then load data into warehouse, all within one pipeline.","upvote_count":"1","poster":"maciejt","comment_id":"331864","timestamp":"1617962340.0"},{"timestamp":"1615828620.0","upvote_count":"3","content":"Regarding loading the data, I think Azure Data Factory could also be an appropriate answer.","comment_id":"311607","poster":"Geo_Barros"},{"upvote_count":"3","timestamp":"1615806900.0","comment_id":"311347","content":"azure data factory could be used to load the data too","poster":"H_S"}],"question_text":"HOTSPOT -\nYou design data engineering solutions for a company.\nYou must integrate on-premises SQL Server data into an Azure solution that performs Extract-Transform-Load (ETL) operations have the following requirements:\n✑ Develop a pipeline that can integrate data and run notebooks.\n✑ Develop notebooks to transform the data.\n✑ Load the data into a massively parallel processing database for later analysis.\nYou need to recommend a solution.\nWhat should you recommend? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","answer_images":["https://www.examtopics.com/assets/media/exam-media/03774/0020100001.jpg"],"unix_timestamp":1615806900,"answer":"","isMC":false,"answers_community":[],"answer_description":"","question_images":["https://www.examtopics.com/assets/media/exam-media/03774/0020000001.jpg"],"question_id":108,"url":"https://www.examtopics.com/discussions/microsoft/view/47165-exam-dp-201-topic-2-question-45-discussion/","answer_ET":""},{"id":"gP4AjknkZ1DoUUcWoti9","url":"https://www.examtopics.com/discussions/microsoft/view/49711-exam-dp-201-topic-2-question-46-discussion/","discussion":[{"content":"this is typical use case for Azure databricks that can use spark analytics paltform. so the answer should be databricks","comment_id":"331950","poster":"suman13","comments":[{"content":"I agree: https://azure.microsoft.com/es-es/blog/three-critical-analytics-use-cases-with-microsoft-azure-databricks/","poster":"rahul_t","timestamp":"1618084980.0","upvote_count":"4","comment_id":"332797"},{"comment_id":"366838","poster":"cadio30","content":"Second agree with the propose solution","upvote_count":"1","timestamp":"1622007180.0"}],"timestamp":"1617972960.0","upvote_count":"28"},{"content":"Selected Answer: C\nAzure Databricks: Azure Databricks is a fast, easy, and collaborative Apache Spark-based analytics platform. It simplifies the deployment and management of Apache Spark clusters, making it an excellent choice for large-scale data processing, including analyzing network and system activities for security purposes. It integrates with various Azure services and provides collaborative notebooks for data scientists and analysts.","poster":"dakku987","timestamp":"1703611740.0","comment_id":"1106256","upvote_count":"1"},{"comment_id":"427236","upvote_count":"2","timestamp":"1629351480.0","poster":"Bhagya123456","content":"HDInsight is not in syllabus. So anytime you have a confusion with Databricks and HDInsight better go with Databricks."},{"comment_id":"426138","timestamp":"1629180360.0","upvote_count":"2","content":"I will go with the databricks for the analytics of intrusion data!","poster":"satyamkishoresingh"},{"content":"Answer should be Azure databricks.\nIntrusion detection is one of use case for Azure databricks. \nhttps://azure.microsoft.com/es-es/blog/three-critical-analytics-use-cases-with-microsoft-azure-databricks/","poster":"BobFar","upvote_count":"2","timestamp":"1622925720.0","comment_id":"375438"},{"comment_id":"364511","timestamp":"1621772640.0","upvote_count":"1","comments":[{"comments":[{"timestamp":"1622640180.0","content":"nope.. it's Databricks for sure","poster":"dbdev","upvote_count":"2","comment_id":"372721"}],"timestamp":"1622165400.0","upvote_count":"1","content":"are you sure?","comment_id":"368412","poster":"Dymize"}],"content":"The answer provided is correct.","poster":"dbdev"}],"choices":{"D":"Azure HDInsight","C":"Azure Databricks","A":"Azure Data Factory","B":"Azure Data Lake Storage"},"isMC":true,"answers_community":["C (100%)"],"unix_timestamp":1617972960,"question_id":109,"question_text":"A company plans to use Apache Spark Analytics to analyze intrusion detection data.\nYou need to recommend a solution to analyze network and system activities for malicious activities and policy violations. The solution must minimize administrative efforts.\nWhat should you recommend?","answer":"C","answer_ET":"D","answer_description":"With Azure HDInsight you can set up Azure Monitor alerts that will trigger when the value of a metric or the results of a query meet certain conditions. You can condition on a query returning a record with a value that is greater than or less than a certain threshold, or even on the number of results returned by a query. For example, you could create an alert to send an email if a Spark job fails or if a Kafka disk usage becomes over 90 percent full.\nReference:\nhttps://azure.microsoft.com/en-us/blog/monitoring-on-azure-hdinsight-part-4-workload-metrics-and-logs/","question_images":[],"timestamp":"2021-04-09 14:56:00","topic":"2","answer_images":[],"exam_id":66},{"id":"az40GF8vyCMavJHSMaTD","answer":"A","answer_description":"Append Mode: Only new rows appended in the result table since the last trigger are written to external storage. This is applicable only for the queries where existing rows in the Result Table are not expected to change.\nIncorrect Answers:\nB: Complete Mode: The entire updated result table is written to external storage. It is up to the storage connector to decide how to handle the writing of the entire table.\nC: Update Mode: Only the rows that were updated in the result table since the last trigger are written to external storage. This is different from Complete Mode in that Update Mode outputs only the rows that have changed since the last trigger. If the query doesn't contain aggregations, it is equivalent to Append mode.\nReference:\nhttps://docs.microsoft.com/en-us/azure/databricks/getting-started/spark/streaming","question_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/49487-exam-dp-201-topic-2-question-47-discussion/","timestamp":"2021-04-07 13:02:00","unix_timestamp":1617793320,"question_id":110,"answer_images":[],"exam_id":66,"discussion":[{"content":"Same question in DP 200","poster":"toandm","timestamp":"1621684080.0","upvote_count":"5","comment_id":"363653"},{"content":"there will be a new line for each updated transaction (record). So 'append' is correct","poster":"lorenzoV","comment_id":"644110","timestamp":"1659962160.0","upvote_count":"1"},{"timestamp":"1652893260.0","poster":"nefarious_smalls","upvote_count":"1","comment_id":"603380","content":"I think the answer is correct because it says data will be aggregated using Databricks. As far as the streaming mode The data is only being appended. Aggregations will be calculated separately."},{"poster":"MayankSh","timestamp":"1624792980.0","comment_id":"391996","content":"Sales transactions will never be updated --> No updates meaning, no need to perform merge operation or updates, Hence append is the correct answer","upvote_count":"1"},{"content":"The required conditions are confusing:\ncondition2-> update\ncondition3-> append","poster":"erssiws","comment_id":"384941","timestamp":"1624033680.0","upvote_count":"2"},{"content":"I think it should be update because of the possible new additions of new data to already copied rows. Any opinions?","upvote_count":"1","comments":[{"content":"sorry, I haven't read third condition. I think answer is correct.","upvote_count":"5","poster":"maynard13x8","comment_id":"330276","timestamp":"1617793440.0"}],"comment_id":"330275","timestamp":"1617793320.0","poster":"maynard13x8"}],"choices":{"A":"Append","B":"Complete","C":"Update"},"answers_community":[],"topic":"2","answer_ET":"A","isMC":true,"question_text":"You are planning a streaming data solution that will use Azure Databricks. The solution will stream sales transaction data from an online store. The solution has the following specifications:\n✑ The output data will contain items purchased, quantity, line total sales amount, and line total tax amount.\n✑ Line total sales amount and line total tax amount will be aggregated in Databricks.\n✑ Sales transactions will never be updated. Instead, new rows will be added to adjust a sale.\nYou need to recommend an output mode for the dataset that will be processed by using Structured Streaming. The solution must minimize duplicate data.\nWhat should you recommend?"}],"exam":{"provider":"Microsoft","lastUpdated":"12 Apr 2025","name":"DP-201","isBeta":false,"id":66,"isImplemented":true,"numberOfQuestions":206,"isMCOnly":false},"currentPage":22},"__N_SSP":true}