{"pageProps":{"questions":[{"id":"cltP4mCyLBSZvOWCiKAu","url":"https://www.examtopics.com/discussions/microsoft/view/104302-exam-dp-100-topic-4-question-46-discussion/","question_text":"DRAG DROP\n-\n\nYou have an Azure Machine Learning workspace that contains a training cluster and an inference cluster.\n\nYou plan to create a classification model by using the Azure Machine Learning designer.\n\nYou need to ensure that client applications can submit data as HTTP requests and receive predictions as responses.\n\nWhich three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\n\n//IMG//","exam_id":64,"answer_images":["https://img.examtopics.com/dp-100/image446.png"],"answers_community":[],"question_id":406,"answer":"","answer_ET":"","topic":"4","unix_timestamp":1680052380,"answer_description":"","timestamp":"2023-03-29 03:13:00","question_images":["https://img.examtopics.com/dp-100/image445.png"],"isMC":false,"discussion":[{"upvote_count":"18","poster":"avotofu","content":"Answer should be\n1.create training pipeline\n2.create inference pipeline\n3.deploy to inference cluster","comment_id":"867780","timestamp":"1712883900.0"},{"comment_id":"964814","poster":"phdykd","upvote_count":"3","timestamp":"1722090600.0","content":"The correct sequence of actions to ensure that client applications can submit data as HTTP requests and receive predictions as responses is:\n\nb) Create a pipeline that trains a classification model and run the pipeline on the compute cluster. You first need to create and run a training pipeline in the Azure Machine Learning Designer. This pipeline should train a classification model on your data.\nd) Create a real-time inference pipeline and run the pipeline on the compute cluster. After the model is trained, you can create a real-time inference pipeline. This type of pipeline will use your trained model to make predictions on new data in real time.\na) Deploy a service to the inference cluster. The last step is to deploy your real-time inference pipeline as a service to the inference cluster. This service will allow client applications to send data as HTTP requests and receive predictions as HTTP responses"},{"upvote_count":"1","comments":[{"content":"Shouldn't the third step be the second step in your answer?","comment_id":"861685","timestamp":"1712282580.0","poster":"Piddi","upvote_count":"3"}],"poster":"sap_dg","timestamp":"1711681980.0","comment_id":"853883","content":"Create pipeline that trains classification model -> deploy service to the inference cluster -> create real time inference pipeline"}]},{"id":"nH0EbGzJOPN6KwLtUNvY","timestamp":"2023-03-28 04:33:00","answer":"BE","exam_id":64,"answer_images":[],"isMC":true,"question_id":407,"discussion":[{"content":"Selected Answer: BE\nCorrect (I think)\n\nhttps://learn.microsoft.com/en-us/azure/machine-learning/how-to-mlflow-batch?tabs=cli\n\nMLflow models don't require you to indicate an environment or a scoring script when creating the deployments as it is created for you. However, you can specify them if you want to customize how the deployment does inference.","timestamp":"1711600380.0","poster":"Tommo565","upvote_count":"6","comment_id":"852691"},{"content":"Selected Answer: AE\nI think that is AE","comments":[{"content":"The MLflow model already describes the required environment, so there is no need to define it once again\nhttps://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-mlflow-models?view=azureml-api-2&tabs=azureml","poster":"vv_bb","comment_id":"1079905","timestamp":"1732529040.0","upvote_count":"2"}],"timestamp":"1730080740.0","comment_id":"1055912","poster":"Fercho5813","upvote_count":"1"}],"answers_community":["BE (86%)","14%"],"unix_timestamp":1679970780,"answer_ET":"BE","question_images":[],"topic":"4","answer_description":"","question_text":"You create an MLflow model.\n\nYou must deploy the model to Azure Machine Learning for batch inference.\n\nYou need to create the batch deployment.\n\nWhich two components should you use? Each correct answer presents a complete solution.\n\nNOTE: Each correct selection is worth one point.","url":"https://www.examtopics.com/discussions/microsoft/view/104161-exam-dp-100-topic-4-question-47-discussion/","choices":{"A":"Environment","E":"Compute target","C":"Online endpoint","D":"Kubernetes online endpoint","B":"Model files"}},{"id":"aE1AfVNaaQTY1rEffw3Q","choices":{"D":"compute_cluster","C":"compute instance","A":"workspaceblobstore datastore","B":"workspacefilestore datastore"},"exam_id":64,"question_text":"You create an Azure Machine Learning workspace. The workspace contains a dataset named sample_dataset, a compute instance, and a compute cluster.\n\nYou must create a two-stage pipeline that will prepare data in the dataset and then train and register a model based on the prepared data.\n\nThe first stage of the pipeline contains the following code:\n\n//IMG//\n\n\nYou need to identify the location containing the output of the first stage of the script that you can use as input for the second stage.\n\nWhich storage location should you use?","answer_ET":"A","question_id":408,"topic":"4","unix_timestamp":1679271240,"discussion":[{"timestamp":"1722091080.0","comment_id":"964816","upvote_count":"1","content":"The OutputFileDatasetConfig(\"stagel data\") in the first stage of the pipeline is used to configure a location in the workspace's default datastore to store the output from the step. The Azure Machine Learning workspace default datastore is typically an Azure blob storage, known as workspaceblobstore, and it is used to store the intermediate and output data of the pipeline stages.\n\nTherefore, the correct answer is:\n\nA. workspaceblobstore datastore","poster":"phdykd"},{"comment_id":"844360","upvote_count":"3","timestamp":"1710893640.0","content":"Selected Answer: A\nWhen you create a workspace, an Azure blob container and an Azure file share are automatically registered as datastores to the workspace. They're named workspaceblobstore and workspacefilestore, respectively. The workspaceblobstore is used to store workspace artifacts and your machine learning experiment logs. It's also set as the default datastore and can't be deleted from the workspace. The workspacefilestore is used to store notebooks and R scripts authorized via compute instance.\nhttps://learn.microsoft.com/en-us/azure/machine-learning/v1/how-to-access-data","poster":"oakmm"}],"isMC":true,"url":"https://www.examtopics.com/discussions/microsoft/view/103319-exam-dp-100-topic-4-question-48-discussion/","question_images":["https://img.examtopics.com/dp-100/image447.png"],"answer":"A","timestamp":"2023-03-20 01:14:00","answer_images":[],"answers_community":[],"answer_description":""},{"id":"bGDTTkM477xACOo4grJL","exam_id":64,"question_text":"DRAG DROP\n-\n\nYou are developing a machine learning solution by using the Azure Machine Learning designer.\n\nYou need to create a web service that applications can use to submit data feature values and retrieve a predicted label.\n\nWhich three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\n\n//IMG//","answer_ET":"","question_id":409,"unix_timestamp":1681967580,"topic":"4","discussion":[{"poster":"avotofu","upvote_count":"11","comments":[{"poster":"VeraKo","comments":[{"upvote_count":"1","content":"Batch inference is for non-time-sensitive jobs that are large and must scale well. Users expect a web service to respond promptly, so real-time inference is needed.","comment_id":"1325319","timestamp":"1733965080.0","poster":"justinm410"}],"timestamp":"1720606140.0","content":"Thanks for the info!\n\nI have one question. Why does it have to be a real-time inference pipeline? This was mentioned nowhere in the question. Can it be a batch inference pipeline instead?","comment_id":"1245416","upvote_count":"1"}],"comment_id":"875291","timestamp":"1681967580.0","content":"answer should be\n1.Create and run training pipeline\n2.Create and run a real-time inference pipeline\n3.Deploy a serivce to an inference cluster\n\nhttps://learn.microsoft.com/en-us/azure/machine-learning/tutorial-designer-automobile-price-deploy"},{"poster":"phdykd","comment_id":"964853","timestamp":"1690471500.0","content":"Create and run a training pipeline. This is the first step because before you can create a prediction model, you need to train it with existing data. This is done by creating and running a training pipeline, which takes in your data, applies a machine learning algorithm, and outputs a model that can be used to make predictions.\nCreate and run a real-time inference pipeline. Once the model has been trained, it's time to use it for prediction. This is done by creating a real-time inference pipeline. The inference pipeline takes in new data, applies the trained model, and outputs predictions.\nDeploy a service to an inference cluster. After you have a working inference pipeline, you can deploy it as a web service to an inference cluster. This allows applications to send data to the service and receive predictions in return. This is the last step because you need a trained model and a working inference pipeline before you can deploy a service.","upvote_count":"3"}],"isMC":false,"url":"https://www.examtopics.com/discussions/microsoft/view/106795-exam-dp-100-topic-4-question-49-discussion/","question_images":["https://img.examtopics.com/dp-100/image471.png"],"answer":"","answer_images":["https://img.examtopics.com/dp-100/image472.png"],"timestamp":"2023-04-20 07:13:00","answers_community":[],"answer_description":""},{"id":"tQfPNQ7DmwAQXEDw2RQe","choices":{"B":"service.state","D":"service.update_deployment_state()","C":"service.serialize()","A":"service.get_logs()"},"question_text":"You deploy a model as an Azure Machine Learning real-time web service using the following code.\n//IMG//\n\nThe deployment fails.\nYou need to troubleshoot the deployment failure by determining the actions that were performed during deployment and identifying the specific action that failed.\nWhich code segment should you run?","answer_images":[],"question_images":["https://www.examtopics.com/assets/media/exam-media/04274/0037600001.png"],"answers_community":[],"question_id":410,"answer_description":"You can print out detailed Docker engine log messages from the service object. You can view the log for ACI, AKS, and Local deployments. The following example demonstrates how to print the logs.\n# if you already have the service object handy\nprint(service.get_logs())\n# if you only know the name of the service (note there might be multiple services with the same name but different version number) print(ws.webservices['mysvc'].get_logs())\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-deployment","exam_id":64,"unix_timestamp":1623132180,"answer_ET":"A","isMC":true,"answer":"A","topic":"4","url":"https://www.examtopics.com/discussions/microsoft/view/54863-exam-dp-100-topic-4-question-5-discussion/","discussion":[{"timestamp":"1686204180.0","content":"A is the correct answer.","comment_id":"377258","poster":"SaulG","upvote_count":"10"},{"comment_id":"617994","timestamp":"1718668140.0","content":"On exam 18-06-22","upvote_count":"1","poster":"therealola"},{"content":"on exam 18/03/2022","poster":"kkkk_jjjj","timestamp":"1710751560.0","comment_id":"570392","upvote_count":"3"},{"upvote_count":"1","poster":"AjoseO","comment_id":"559824","content":"On 03 March 2022","timestamp":"1709444220.0"},{"content":"on Exam 6 Nov 2021","timestamp":"1699308300.0","upvote_count":"2","comment_id":"473653","poster":"JoshuaXu"}],"timestamp":"2021-06-08 08:03:00"}],"exam":{"provider":"Microsoft","isImplemented":true,"isBeta":false,"name":"DP-100","id":64,"isMCOnly":false,"lastUpdated":"12 Apr 2025","numberOfQuestions":512},"currentPage":82},"__N_SSP":true}