{"pageProps":{"questions":[{"id":"j5cteABB62Iw02AOQzXb","discussion":[{"comment_id":"332635","comments":[{"poster":"Pairon","timestamp":"1618335900.0","content":"I agree...with inspect you can also look at data types, you can't edit it. So I would edit data type for passengerCount.","upvote_count":"4","comment_id":"334847"}],"content":"passengerCount column type","poster":"tucho","timestamp":"1618066620.0","upvote_count":"6"},{"comment_id":"1109327","timestamp":"1703899200.0","upvote_count":"1","poster":"Shrutii","content":"passengerCount"},{"timestamp":"1623507960.0","content":"Config PassengerCount column type to number","upvote_count":"2","comment_id":"380512","poster":"hoangton"},{"comment_id":"364300","comments":[{"poster":"emski","upvote_count":"1","content":"https://docs.microsoft.com/en-us/azure/data-factory/data-flow-source","comment_id":"378723","timestamp":"1623300360.0"}],"poster":"maciejt","content":"The anwer is incorrect as you cannot solve the error using read-only tab. The question was which section to configure and you cannot configure the read-only inspect. You need to configure schema in projection","timestamp":"1621758900.0","upvote_count":"2"}],"isMC":false,"question_id":111,"answer":"","url":"https://www.examtopics.com/discussions/microsoft/view/49815-exam-dp-200-topic-2-question-40-discussion/","answer_images":["https://www.examtopics.com/assets/media/exam-media/03872/0022600001.jpg","https://www.examtopics.com/assets/media/exam-media/03872/0022700001.png"],"answer_description":"The Inspect tab provides a view into the metadata of the data stream that you're transforming. You can see column counts, the columns changed, the columns added, data types, the column order, and column references. Inspect is a read-only view of your metadata. You don't need to have debug mode enabled to see metadata in the Inspect pane.\n\nReference:\nhttps://docs.microsoft.com/en-us/azure/data-factory/concepts-data-flow-overview","answer_ET":"","question_text":"HOTSPOT -\nYou are implementing mapping data flows in Azure Data Factory to convert daily logs of taxi records into aggregated datasets.\nYou configure a data flow and receive the error shown in the following exhibit.\n//IMG//\n\nYou need to resolve the error.\nWhich setting should you configure? To answer, select the appropriate setting in the answer area.\nHot Area:\n//IMG//","question_images":["https://www.examtopics.com/assets/media/exam-media/03872/0022500001.jpg","https://www.examtopics.com/assets/media/exam-media/03872/0022500002.jpg"],"topic":"2","timestamp":"2021-04-10 16:57:00","answers_community":[],"unix_timestamp":1618066620,"exam_id":65},{"id":"hs9RAdGM7bGBRDvdhUk6","answer":"","discussion":[{"timestamp":"1621226700.0","upvote_count":"8","content":"It is correct Answer","poster":"hoangton","comment_id":"359251"}],"answer_description":"HubA: Stream -\n\nHubB: Stream -\n\nDatabase1: Reference -\nReference data (also known as a lookup table) is a finite data set that is static or slowly changing in nature, used to perform a lookup or to augment your data streams. For example, in an IoT scenario, you could store metadata about sensors (which don't change often) in reference data and join it with real time IoT data streams. Azure Stream Analytics loads reference data in memory to achieve low latency stream processing\nReference:\nhttps://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-use-reference-data","topic":"2","answers_community":[],"question_images":["https://www.examtopics.com/assets/media/exam-media/03872/0022700002.png","https://www.examtopics.com/assets/media/exam-media/03872/0022800001.jpg"],"exam_id":65,"question_text":"HOTSPOT -\nYou have an Azure SQL database named Database1 and two Azure event hubs named HubA and HubB. The data consumed from each source is shown in the following table.\n//IMG//\n\nYou need to implement Azure Stream Analytics to calculate the average fare per mile by driver.\nHow should you configure the Stream Analytics input for each source? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","unix_timestamp":1621226700,"answer_ET":"","isMC":false,"answer_images":["https://www.examtopics.com/assets/media/exam-media/03872/0022900001.jpg"],"question_id":112,"timestamp":"2021-05-17 06:45:00","url":"https://www.examtopics.com/discussions/microsoft/view/52922-exam-dp-200-topic-2-question-41-discussion/"},{"id":"Jf37IwkHeFSn82AfLHF5","timestamp":"2021-05-04 21:36:00","answer":"","unix_timestamp":1620156960,"url":"https://www.examtopics.com/discussions/microsoft/view/51836-exam-dp-200-topic-2-question-42-discussion/","discussion":[{"comment_id":"352486","comments":[{"timestamp":"1621068720.0","poster":"111222333","content":"Agree with \"raise\". \nIf we lower the number of concurrent jobs, the CPU will become even more *under*utilized. Because then when it reaches the limit number of concurrent jobs, it will occupy even less CPU -> CPU will never be optimally utilized.\nRAISE the number of concurrent jobs so that their CPU consumption comes closer to CPU's max.\n\nReference: https://docs.microsoft.com/en-us/azure/data-factory/create-self-hosted-integration-runtime#scale-up","upvote_count":"1","comment_id":"357700"},{"upvote_count":"1","content":"You are not increasing currently running jobs, but the limit of jobs that can run concurrently, which is 14 at the moment. So increasing it would only reduce cpu utilization.","comment_id":"431173","poster":"michalS","timestamp":"1629870780.0"}],"poster":"MMM777","content":"If each job is similar and each uses 3% CPU - then even at current max 14,only 42% CPU utilization. Should INCREASE the limit - which is what the answer is also saying.","timestamp":"1620485400.0","upvote_count":"12"},{"poster":"Simon2021","timestamp":"1623758100.0","comment_id":"382635","content":"It should lower the concurrent Jobs limit.","upvote_count":"1"},{"upvote_count":"2","timestamp":"1623656280.0","comment_id":"381677","poster":"Pierwiastek","content":"I agree with the answer. We should lower Concurrent Jobs (Running/Limit) value. It means we should lower the limit value. We don't need so big value if we use only 2 of 14."},{"comment_id":"349743","content":"Shouldn't the second option be \"left as is\" since the number of concurrent jobs is 2/14? The answer states that if the number of concurrent jobs reaches the limit (14 in this case) and the CPU is under utilized then we should increase the number of concurrent jobs that can run. In this case it seems that 6% is a good amount of utilization given that 2/14 jobs (14%) are running, no?","timestamp":"1620156960.0","poster":"dangal95","upvote_count":"3","comments":[{"upvote_count":"2","comment_id":"354389","content":"\"When the processor and available RAM aren't well utilized, but the execution of concurrent jobs reaches a node's limits, scale up by increasing the number of concurrent jobs that a node can run. You might also want to scale up when activities time out because the self-hosted IR is overloaded. As shown in the following image, you can increase the maximum capacity for a node.\" \n\nThe above statement was quoted from the link provided below and on this scenario, it requires to increase the concurrent jobs (running/limit)\n\nReference: https://docs.microsoft.com/en-us/azure/data-factory/create-self-hosted-integration-runtime","poster":"cadio30","timestamp":"1620714600.0","comments":[{"upvote_count":"1","comment_id":"391688","timestamp":"1624760820.0","poster":"lgtiza","content":"I agree with Dangal, \"left as is\", because here you are not reaching a node's limits (it's just using 6%). It it was using the 14 jobs and it would be using 20% then I would say do raise the number of possible jobs, otherwise not. And also I would not lower the number of possible jobs because I don't know how many concurrent jobs I would need to run, this is just a \"snapshot\" of what was happening at that moment."}]}]}],"question_id":113,"answer_ET":"","exam_id":65,"question_text":"HOTSPOT -\nYou have a self-hosted integration runtime in Azure Data Factory.\nThe current status of the integration runtime has the following configurations:\n✑ Status: Running\n✑ Type: Self-Hosted\n✑ Version: 4.4.7292.1\n✑ Running / Registered Node(s): 1/1\n✑ High Availability Enabled: False\n✑ Linked Count: 0\n✑ Queue Length: 0\n✑ Average Queue Duration: 0.00s\nThe integration runtime has the following node details:\n✑ Name: X-M\n✑ Status: Running\n✑ Version: 4.4.7292.1\n✑ Available Memory: 7697MB\n✑ CPU Utilization: 6%\n✑ Network (In/Out): 1.21KBps/0.83KBps\n✑ Concurrent Jobs (Running/Limit): 2/14\n✑ Role: Dispatcher/Worker\n✑ Credential Status: In Sync\nUse the drop-down menus to select the answer choice that completes each statement based on the information presented.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","isMC":false,"question_images":["https://www.examtopics.com/assets/media/exam-media/03872/0023100001.png"],"answer_description":"Box 1: fail until the node comes back online\nWe see: High Availability Enabled: False\nNote: Higher availability of the self-hosted integration runtime so that it's no longer the single point of failure in your big data solution or cloud data integration with\nData Factory.\n\nBox 2: lowered -\nWe see:\nConcurrent Jobs (Running/Limit): 2/14\nCPU Utilization: 6%\nNote: When the processor and available RAM aren't well utilized, but the execution of concurrent jobs reaches a node's limits, scale up by increasing the number of concurrent jobs that a node can run\nReference:\nhttps://docs.microsoft.com/en-us/azure/data-factory/create-self-hosted-integration-runtime","answers_community":[],"answer_images":["https://www.examtopics.com/assets/media/exam-media/03872/0023100002.png"],"topic":"2"},{"id":"PahTuGG5J2tqac9LLDNi","answer":"A","discussion":[{"comment_id":"350956","poster":"meswapnilspal","timestamp":"1620300840.0","upvote_count":"6","content":"answer is correct\n\nhttps://docs.microsoft.com/en-us/stream-analytics-query/tumbling-window-azure-stream-analytics"}],"answer_ET":"A","isMC":true,"question_images":[],"timestamp":"2020-09-21 15:21:00","choices":{"B":"SELECT Country, Count(*) AS Count FROM ClickStream TIMESTAMP BY CreatedAt GROUP BY Country, SessionWindow(second, 5, 10)","C":"SELECT Country, Avg(*) AS Average FROM ClickStream TIMESTAMP BY CreatedAt GROUP BY Country, SlidingWindow(second, 10)","A":"SELECT Country, Count(*) AS Count FROM ClickStream TIMESTAMP BY CreatedAt GROUP BY Country, TumblingWindow(second, 10)","D":"SELECT Country, Avg(*) AS Average FROM ClickStream TIMESTAMP BY CreatedAt GROUP BY Country, HoppingWindow(second, 10, 2)"},"exam_id":65,"unix_timestamp":1600694460,"topic":"2","answer_images":[],"answers_community":[],"url":"https://www.examtopics.com/discussions/microsoft/view/31840-exam-dp-200-topic-2-question-43-discussion/","answer_description":"Tumbling window functions are used to segment a data stream into distinct time segments and perform a function against them, such as the example below. The key differentiators of a Tumbling window are that they repeat, do not overlap, and an event cannot belong to more than one tumbling window.\nExample:\nIncorrect Answers:\nB: Session windows group events that arrive at similar times, filtering out periods of time where there is no data.\nC: Sliding windows, unlike Tumbling or Hopping windows, output events only for points in time when the content of the window actually changes. In other words, when an event enters or exits the window. Every window has at least one event, like in the case of Hopping windows, events can belong to more than one sliding window.\nD: Hopping window functions hop forward in time by a fixed period. It may be easy to think of them as Tumbling windows that can overlap, so events can belong to more than one Hopping window result set. To make a Hopping window the same as a Tumbling window, specify the hop size to be the same as the window size.\nReference:\nhttps://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-window-functions","question_text":"You have an Azure Stream Analytics job that receives clickstream data from an Azure event hub.\nYou need to define a query in the Stream Analytics job. The query must meet the following requirements:\n✑ Count the number of clicks within each 10-second window based on the country of a visitor.\n✑ Ensure that each click is NOT counted more than once.\nHow should you define the query?","question_id":114},{"id":"59szPz8bg2hNEWsbiyO6","answer":"D","answer_ET":"D","discussion":[{"content":"Hopping Window is the correct answer","upvote_count":"12","comments":[{"poster":"victor90","content":"https://docs.microsoft.com/en-us/azure/stream-analytics/media/stream-analytics-window-functions/stream-analytics-window-functions-hopping-intro.png","timestamp":"1638075660.0","upvote_count":"1","comment_id":"488842"}],"timestamp":"1623890700.0","poster":"SankarMG","comment_id":"383801"},{"comment_id":"381661","comments":[{"comment_id":"401634","timestamp":"1625729220.0","poster":"captainbee","upvote_count":"7","content":"Don't be ridiculous, doesn't help other people either. It's a hopping window as the windows will overlap."}],"content":"correct answer c only","poster":"dumpi","upvote_count":"1","timestamp":"1623654900.0"},{"comment_id":"363812","upvote_count":"4","content":"Hopping","poster":"Sudhansu21","timestamp":"1621701720.0"},{"timestamp":"1620972720.0","comment_id":"356944","poster":"kaigalmane","upvote_count":"1","content":"Sorry. Looks like D now."},{"poster":"kaigalmane","upvote_count":"1","comment_id":"356941","timestamp":"1620972480.0","content":"I think C. Tumbling"},{"content":"So what is the answer?","poster":"kaigalmane","upvote_count":"2","comment_id":"356938","timestamp":"1620972420.0"},{"upvote_count":"3","comment_id":"342760","poster":"Mily94","content":"correct answer: D","timestamp":"1619373180.0"},{"timestamp":"1617073380.0","content":"Tumbling window functions are used to segment a data stream into distinct time segments and perform\na function against them, such as the example below. The key differentiators of a Tumbling window are\nthat they repeat, do not overlap, and an event cannot belong to more than one tumbling window.","poster":"imkoomin","upvote_count":"3","comment_id":"323924"}],"isMC":true,"question_images":[],"timestamp":"2021-03-30 05:03:00","choices":{"A":"Sliding","D":"Hopping","C":"Tumbling","B":"Session"},"exam_id":65,"unix_timestamp":1617073380,"topic":"2","answer_images":[],"answers_community":[],"url":"https://www.examtopics.com/discussions/microsoft/view/48492-exam-dp-200-topic-2-question-44-discussion/","answer_description":"Hopping window functions hop forward in time by a fixed period.\nIncorrect Answers:\nA: Sliding windows, unlike Tumbling or Hopping windows, output events only for points in time when the content of the window actually changes. In other words, when an event enters or exits the window.\nB: Session window functions group events that arrive at similar times, filtering out periods of time where there is no data. A session window begins when the first event occurs. If another event occurs within the specified timeout from the last ingested event, then the window extends to include the new event. Otherwise if no events occur within the timeout, then the window is closed at the timeout.\nC: Tumbling window functions are used to segment a data stream into distinct time segments. A Tumbling windows do not overlap, and an event cannot belong to more than one tumbling window.\nReference:\nhttps://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-window-functions","question_text":"You use Azure Stream Analytics to receive Twitter data from Azure Event Hubs and to output the data to an Azure Blob storage account.\nYou need to output the count of tweets from the last five minutes every minute.\nWhich windowing function should you use?","question_id":115}],"exam":{"provider":"Microsoft","name":"DP-200","numberOfQuestions":228,"id":65,"isMCOnly":false,"lastUpdated":"12 Apr 2025","isImplemented":true,"isBeta":false},"currentPage":23},"__N_SSP":true}