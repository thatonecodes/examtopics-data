{"pageProps":{"questions":[{"id":"qbHxM0EG7pKNCVJvmOif","discussion":[{"content":"I think it should be feature engineering.","poster":"koni_","timestamp":"1635169740.0","comment_id":"467482","comments":[{"comment_id":"607147","upvote_count":"20","timestamp":"1653472260.0","content":"Agree. This is \"Normalization of Data\", it involves CHANGING values of input data, and can only be done AFTER feature selection -- i.e. this is feature engineering.","poster":"mishumashu"}],"upvote_count":"89"},{"comments":[{"content":"and what about feature transformation ?","comments":[{"comment_id":"620370","upvote_count":"1","timestamp":"1655895360.0","content":"Or feature scaling","poster":"Ayor"},{"content":"Good point and it would seem the most appropriate answer to this question would be Data Transformation. However, to my uneducated eye, that would still make the answer feature selection since you would select features from the transformed data.\nI'm guessing the key here it to recall feature engineering is applied first to generate additional features, and then feature selection is done to eliminate irrelevant, redundant, or highly correlated features.","comment_id":"473636","timestamp":"1636234920.0","upvote_count":"2","poster":"rfiuvcfns"}],"upvote_count":"3","timestamp":"1635341040.0","poster":"xiban","comment_id":"468627"}],"upvote_count":"26","content":"Based on this statement from the referenced article: Feature selection: The process of selecting the key subset of features to reduce the dimensionality of the training problem.\nFeature selection is the answer since feature engineering is the creation of NEW features from raw data to capture additional information not easily apparent in the original feature set.","timestamp":"1635208920.0","comment_id":"467742","poster":"rfiuvcfns"},{"content":"The answer is Feature engineering!\n\nFeature engineering involves transforming raw data into features suitable for machine learning algorithms.   \nOne crucial step is to ensure that numeric variables have a similar scale. This process, often called normalization or standardization, prevents features with larger scales from dominating the model's learning process.   \n\ne.g:\nImagine you have a dataset with two features: age (ranging from 18 to 65) and income (ranging from $10,000 to $200,000). Without scaling, the income feature might dominate the model's decision-making process, leading to biased results. By scaling both features to a similar range (e.g., 0 to 1), the model can treat both features equally.","comments":[{"comment_id":"1313483","upvote_count":"1","timestamp":"1731842160.0","content":"Perfect explanation. From my understanding: ensuring that the numeric variables are on a similar scale, is data normalization, which is one type of feature engineering.","poster":"Mgb106"}],"comment_id":"1255884","upvote_count":"6","timestamp":"1722023220.0","poster":"BobFar"},{"content":"Feature Engineering = Creation of NEW features from the given raw data. E.g creation of a \"seconds\" column from a \"days\" column. Here we are both normalizing and creating a new feature called \"seconds.\" Feature Engineering is the best answer here.\n\nMeanwhile Feature selection is choosing features that have (direct & measurable) impacts on the predictions. E.g. Choosing \"Driver's Age\" & \"Number of Years of Driving\" & ignoring \"Drivers Names\" for predicting the likely hood of having a road accident","poster":"60ties","timestamp":"1718544480.0","upvote_count":"2","comment_id":"1231383"},{"poster":"60ties","comment_id":"1231380","upvote_count":"2","timestamp":"1718544000.0","content":"Feature Engineering = Creation of NEW features from the given raw data. E.g creation of a \"seconds\" column from a \"days\" column. Here we are both normalizing and creating a new feature called \"seconds.\" Feature Engineering is the best answer here."},{"content":"feature selection is a process of reducing / dropping features, so it is not the correct answer.","timestamp":"1706179920.0","comment_id":"1131576","poster":"stepkurniawan","upvote_count":"1"},{"poster":"kd333200","timestamp":"1698343140.0","upvote_count":"6","content":"This is normalization. In the context of machine learning and data preprocessing, normalization is considered a feature engineering technique, not feature selection.","comment_id":"1054815"},{"content":"Normally feature engineering is applied first to generate additional features, and then feature selection is done to eliminate irrelevant, redundant, or highly correlated features.","upvote_count":"1","comment_id":"1020580","timestamp":"1695972900.0","poster":"katrang"},{"content":"the given answer is wrong. The correct one is feature engineering","poster":"mcalif","timestamp":"1692276480.0","comment_id":"983627","upvote_count":"8"},{"poster":"takusui","timestamp":"1688471640.0","content":"Feature engineering, as it is hinted here: https://learn.microsoft.com/en-us/azure/machine-learning/concept-automated-ml?view=azureml-api-2#feature-engineering","upvote_count":"5","comments":[{"comment_id":"984532","poster":"mciezak","upvote_count":"3","timestamp":"1692365760.0","content":"I agree: \"In Azure Machine Learning, scaling and normalization techniques are applied to facilitate feature engineering\""}],"comment_id":"942708"},{"comment_id":"909911","content":"Given answer is wrong.\nFeature engineering involves transforming or manipulating the input features (variables) in a way that improves the performance or interpretability of a machine learning model. One common technique in feature engineering is scaling or normalizing numeric variables to ensure they have a similar scale or range.\n\nWhen the numeric variables have different scales, it can negatively impact the performance of certain machine learning algorithms. For example, algorithms that are sensitive to the scale of variables, such as gradient descent-based optimization algorithms, may converge slowly or exhibit biased results if the variables have significantly different scales.\n\nhttps://towardsdatascience.com/feature-engineering-for-numerical-data-e20167ec18","poster":"rdemontis","upvote_count":"6","timestamp":"1685424480.0"},{"timestamp":"1685199960.0","poster":"leojadue","content":"Ensuring that the numeric variables in training data are on a similar scale is an example of feature engineering.\n\nFeature engineering involves transforming raw data into a format that is more suitable for modeling. It can involve a range of activities, such as dealing with missing values, creating new features from existing ones, encoding categorical variables, and normalizing numeric variables. Normalizing numeric variables, as you mentioned, is a common form of feature engineering to ensure all variables are on a similar scale. This can be particularly important for certain types of models, like neural networks and support vector machines, which can behave poorly if the features are not on similar scales.","upvote_count":"1","comment_id":"908063"},{"poster":"master_yoda","upvote_count":"3","timestamp":"1682340600.0","content":"Normalization is a **feature engineering** technique used to adjust the values of features in a dataset to a common scale. This is done to facilitate data analysis and modeling, and to reduce the impact of different scales on the accuracy of machine learning models ยน. Is there anything else you would like to know?\n\nSource: Conversation with Bing, 4/24/2023\n(1) Feature Engineering: Scaling, Normalization and Standardization. https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/ Accessed 4/24/2023.","comment_id":"879340"},{"timestamp":"1680671040.0","content":"Feature Engineering as per Chat GPT (dealing with data on a similar scale)","comment_id":"861763","poster":"XtraWest","upvote_count":"5"},{"upvote_count":"5","comment_id":"802283","poster":"p1zz4","timestamp":"1675876140.0","content":"feature engineering 100%"},{"upvote_count":"2","poster":"Romanhuki","timestamp":"1665792120.0","comments":[{"comment_id":"1226799","content":"No, correct answer is feature engineering. Ensuring that numeric variables are on similar scale involves normalization, which is a kind of feature engineering.","upvote_count":"1","timestamp":"1717860000.0","poster":"Alex_W"}],"comment_id":"695058","content":"Feature Selection is the right answer: Normally feature engineering is applied first to generate additional features, and then feature selection is done to eliminate irrelevant, redundant, or highly correlated features. (https://learn.microsoft.com/en-us/azure/architecture/data-science-process/create-features)"},{"upvote_count":"4","comment_id":"631163","timestamp":"1657773240.0","content":"A confusing question (with the given answers) for sure! I am not sure about whether this should be Feature Engineering or Feature Selection","poster":"sriram72"},{"timestamp":"1656667740.0","comment_id":"625668","content":"Feature engineering is the correct answer.\n\"In Azure Machine Learning, data-scaling and normalization techniques are applied to make feature engineering easier. Collectively, these techniques and this feature engineering are called featurization in automated ML experiments.\"\nFeature selection is only about selection.\nModifying features = Feature engineering\nhttps://docs.microsoft.com/en-us/azure/mach\nine-learning/how-to-configure-auto-features","poster":"The_General92","upvote_count":"8"},{"comment_id":"620369","poster":"Ayor","timestamp":"1655895300.0","content":"Feature Scaling is meant to be the right answer","upvote_count":"1"},{"comment_id":"613409","timestamp":"1654707780.0","upvote_count":"6","content":"Feature Selection = Keyword is 'ensure', not 'transform/normalize'. So no Feature Engineering.","poster":"Makei"},{"timestamp":"1653977820.0","poster":"cmohl2013","upvote_count":"3","comment_id":"609573","content":"I expected the answer 'data normalization' or 'data tranformation' which is not a choice. Normalization is definitely not included in feature selection, so FEATURE SELECTION is INCORRECT. Normalization can be seen as part of feature engineering, so FEATURE ENGINEERING is the best choice, in my opinion."},{"content":"The answer should be data ingestion, normalization is a transformation that you apply on the selected features. Data ingestion is the process of pulling data and applying the right transformation on it. Therefore, data ingestion is the right answer.","timestamp":"1653740820.0","upvote_count":"2","comment_id":"608388","poster":"aksace"},{"poster":"HURRICANEDATA","upvote_count":"3","timestamp":"1650222720.0","content":"FEATURE ENGINEERING","comment_id":"587359"},{"timestamp":"1650207660.0","poster":"heenak55","content":"In test on 17 April 2022","comment_id":"587287","upvote_count":"3"},{"content":"Feature Engineering and Featurization\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-features\n\nhttps://docs.microsoft.com/en-us/python/api/azureml-automl-core/azureml.automl.core.featurization.featurizationconfig.featurizationconfig?view=azure-ml-py","comment_id":"586062","upvote_count":"1","timestamp":"1649979960.0","poster":"baciga"},{"timestamp":"1647426900.0","upvote_count":"1","poster":"itelessons","comment_id":"569002","content":"First, feature selection often increases classification accuracy by eliminating irrelevant, redundant, or highly correlated features.\nSecond, it decreases the number of features, which makes the model training process more efficient. Efficiency is important for learners that are expensive to train such as support vector machines.\nhttps://docs.microsoft.com/en-us/azure/architecture/data-science-process/select-features\nAnswer is feature selection..."},{"comments":[{"comment_id":"567873","content":"so what is the correct answer ?","timestamp":"1647285120.0","upvote_count":"3","poster":"Monr"}],"upvote_count":"1","timestamp":"1646972520.0","poster":"Pravda","comment_id":"565199","content":"On exam 3.3.2022"},{"content":"This is feature engineering.Feature selection is just a basic process of which features to select rather than do some scaling on them.According to the qsn the 'scaling' is mentioned as a step which is only related to feature engineering and more specifically to the feature scaling aspect of it.\nNow it can be a bit true for feature selection as we can choose which features to sclae but that isnt actually feature selection,according to the ML community and my personal exp we term 'feature selection' for the last step before we pass the attributes/features to the model.","poster":"Shrek29","upvote_count":"4","timestamp":"1646223420.0","comment_id":"559393"},{"content":"Answer should be Feature Selection\nFeature selection: The process of selecting the key subset of features to reduce the dimensionality of the training problem.","comment_id":"553081","timestamp":"1645467240.0","upvote_count":"1","poster":"swapmaverick"},{"poster":"superalien75","comment_id":"538441","content":"I think the answer is correct: Feature Selection, is the process to select the key subsite of original data features in an attempt to reduce the dimensionality of the training problem. So you prep the data so that you won't get errors is how I read it (selection of the features)","timestamp":"1643788140.0","upvote_count":"1"},{"timestamp":"1642866480.0","comment_id":"529947","content":"Should be Feature Engineering","poster":"Sekierer","upvote_count":"1"},{"upvote_count":"1","timestamp":"1641582000.0","content":"Feature Engineering should be the correct answer ... because data engineering (normalization) is creating new features from raw data to increase the predictive power of the learning algorithm.","poster":"shuiho","comment_id":"519167"},{"poster":"Fred8690","comment_id":"514017","content":"Data Ingestion could be the right answer because it is the place where the data are transformed (normalized) : https://docs.microsoft.com/en-us/azure/machine-learning/concept-data-ingestion","upvote_count":"4","timestamp":"1640944800.0"},{"poster":"Rezaphp","upvote_count":"1","timestamp":"1640557260.0","content":"In my opinion, feature engineering is the correct answer","comment_id":"509866"},{"upvote_count":"2","poster":"MahimaSuresh","timestamp":"1639637640.0","comment_id":"502728","content":"It is Feature selection only. As per the definition in official website, \"Feature selection: The process of selecting the key subset of features to reduce the dimensionality of the training problem.\" Normally we will look for duplicate columns and do dimensionality reduction. So this answer is correct."},{"comment_id":"501924","content":"feature engineering.","timestamp":"1639551420.0","upvote_count":"1","poster":"pwy"},{"poster":"BillBaits","content":"I went to the MS url and there's no relevant content.","timestamp":"1639264620.0","comment_id":"499712","upvote_count":"1"},{"timestamp":"1638681120.0","content":"59. You are creating a training pipeline for a regression model, using a dataset that has multiple numeric columns in which the values are on different scales. You want to transform the numeric columns so that the values are all on a similar scale based relative to the minimum and maximum values in each column. Which module should you add to the pipeline?\nNormalize Data -> feature engineering","poster":"edengoforit","comment_id":"494085","upvote_count":"1"},{"upvote_count":"2","poster":"Umonk","timestamp":"1637680560.0","content":"The question is too vague. You can make sure data are on similar scale both by feature selection (only selecting features that are in a similar scale. This is, however, not a great approach as you will be left with few features in real-life situations). And by feature engineering (normalizing the data. This typically creates another features/column in the process)","comment_id":"485123"},{"comment_id":"485062","comments":[{"timestamp":"1642372260.0","poster":"TJ001","comment_id":"525298","comments":[{"content":"If we further think within numeric what scale it is mm , cm etc then to keep it under scale it requires transformation -> can vote for feature engineering in that case","timestamp":"1642506000.0","upvote_count":"1","comment_id":"526556","poster":"TJ001"}],"content":"it is talking about scale (numeric values, discard columns like email address) . i think selection make sense here if we dont think too much","upvote_count":"1"}],"content":"Feature engineering I think too. Log-transformation of numeric variables is an example. Or square root. Note! If numerically possible.","upvote_count":"1","timestamp":"1637674440.0","poster":"Marski"},{"poster":"SLTY","timestamp":"1637199180.0","comment_id":"480361","upvote_count":"1","content":"I think it's feature engineering because you are doing normalization here to ensure the features are on the same scale."},{"timestamp":"1636302840.0","poster":"Sf_","content":"I go with Feature Selection since there is no creation of new features","comment_id":"473967","upvote_count":"3"},{"timestamp":"1635299100.0","poster":"hkshado","upvote_count":"3","comment_id":"468314","content":"I vote for feature engineering too."}],"answer_ET":"","timestamp":"2021-10-25 15:49:00","unix_timestamp":1635169740,"answer":"","question_images":["https://www.examtopics.com/assets/media/exam-media/04234/0007100002.png"],"topic":"1","url":"https://www.examtopics.com/discussions/microsoft/view/64702-exam-ai-900-topic-1-question-62-discussion/","question_text":"HOTSPOT -\nTo complete the sentence, select the appropriate option in the answer area.\nHot Area:\n//IMG//","answer_description":"","answer_images":["https://img.examtopics.com/ai-900/image295.png"],"isMC":false,"exam_id":41,"question_id":206,"answers_community":[]},{"id":"1XSizBjbWM91zgNZppdS","unix_timestamp":1635422340,"discussion":[{"content":"labelling","timestamp":"1651748580.0","comment_id":"473058","poster":"crainos","upvote_count":"11"},{"poster":"Marskmen","timestamp":"1651506420.0","content":"Answer labelling is correct\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-label-data","comment_id":"471753","upvote_count":"7"},{"poster":"rdemontis","content":"correct answer","comment_id":"909919","timestamp":"1701329400.0","upvote_count":"2"},{"upvote_count":"4","comment_id":"510936","poster":"shogoleo","timestamp":"1656400620.0","content":"Correct"},{"comments":[{"content":"I'm sure","upvote_count":"5","comments":[{"comment_id":"968728","poster":"ToddW","timestamp":"1706770860.0","comments":[{"comments":[{"poster":"facilitator","content":"Person above the person above the person above me is sure.","upvote_count":"1","comment_id":"1156780","timestamp":"1724359560.0"}],"content":"Person above the person above me is sure.","comment_id":"1154274","timestamp":"1724092260.0","poster":"nwy_devops","upvote_count":"1"}],"content":"Person above me is sure.","upvote_count":"1"}],"timestamp":"1653393720.0","comment_id":"486028","poster":"aykhazri"},{"timestamp":"1725875280.0","poster":"frankokabbb","comment_id":"1169438","content":"Person above the person above the person above the person above me is sure.","upvote_count":"1"}],"comment_id":"469232","upvote_count":"1","timestamp":"1651147140.0","content":"Please who is sure of this answer?","poster":"phavour"}],"answers_community":[],"answer_description":"Reference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-label-data","question_id":207,"url":"https://www.examtopics.com/discussions/microsoft/view/65008-exam-ai-900-topic-1-question-63-discussion/","topic":"1","answer_images":["https://www.examtopics.com/assets/media/exam-media/04234/0007300001.jpg"],"answer_ET":"","question_images":["https://www.examtopics.com/assets/media/exam-media/04234/0007200002.png"],"answer":"","isMC":false,"exam_id":41,"timestamp":"2021-10-28 13:59:00","question_text":"HOTSPOT -\nTo complete the sentence, select the appropriate option in the answer area.\nHot Area:\n//IMG//"},{"id":"PT5PHaKBH7JRAVT3GtIE","answer_description":"Reference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/component-reference/filter-based-feature-selection","isMC":false,"unix_timestamp":1662224040,"exam_id":41,"question_id":208,"topic":"1","timestamp":"2022-09-03 18:54:00","question_images":["https://www.examtopics.com/assets/media/exam-media/04234/0007300002.png","https://www.examtopics.com/assets/media/exam-media/04234/0007400001.jpg"],"answer_images":["https://www.examtopics.com/assets/media/exam-media/04234/0007400002.jpg"],"answers_community":[],"question_text":"HOTSPOT -\nYou have an Azure Machine Learning model that predicts product quality. The model has a training dataset that contains 50,000 records. A sample of the data is shown in the following table.\n//IMG//\n\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","url":"https://www.examtopics.com/discussions/microsoft/view/79855-exam-ai-900-topic-1-question-64-discussion/","answer_ET":"","answer":"","discussion":[{"content":"Variables or measurements = Features\nClassifications/True/Falses= Labels","upvote_count":"18","poster":"vhogstad","comment_id":"820438","timestamp":"1677239640.0","comments":[{"poster":"MoneyStacking","upvote_count":"2","timestamp":"1730717400.0","content":"Also:\nFeature = input\nLabel = output","comment_id":"1306897"}]},{"content":"Yes Yes No","timestamp":"1742223180.0","upvote_count":"1","comment_id":"1399683","poster":"obidiya22"},{"timestamp":"1721691360.0","upvote_count":"2","content":"In essence, variables/measurements are the raw data, features are the processed data used for training, and labels are the target variable you're trying to predict in classification tasks.","comment_id":"1253332","poster":"BobFar"},{"upvote_count":"3","poster":"BXtheCoder","content":"Answer is correct.","comment_id":"1175586","timestamp":"1710650460.0"},{"upvote_count":"4","content":"On exam 08/01/2024","comment_id":"1118779","poster":"[Removed]","timestamp":"1704902160.0"},{"comment_id":"1045969","content":"I got this question in my exam - thanks for the support","poster":"saurabh_r","upvote_count":"3","timestamp":"1697544900.0"},{"upvote_count":"2","timestamp":"1697544480.0","comment_id":"1045960","content":"I got this question in my exam.","poster":"saurabh_r"},{"content":"last column in table is always label.","upvote_count":"2","timestamp":"1693128360.0","poster":"Ronyboy","comment_id":"991341"},{"poster":"tsk9921","timestamp":"1690308360.0","content":"Given answer is correct. Temp is also feature (like Mass) not a label. Quality test is classification based label.","upvote_count":"1","comment_id":"962987"},{"upvote_count":"2","timestamp":"1685424720.0","comment_id":"909921","poster":"rdemontis","content":"correct"},{"upvote_count":"2","content":"correct","comment_id":"751727","poster":"CloudWatcher420","timestamp":"1671584280.0"},{"comment_id":"662307","timestamp":"1662543720.0","upvote_count":"3","content":"The answer is correct.","poster":"BLUE_BUBBLES"},{"timestamp":"1662224040.0","upvote_count":"2","poster":"affhh2","comment_id":"658663","content":"I think the answer is correct"}]},{"id":"enhs5wt1yLzx7AESWL9N","answer_ET":"","topic":"1","answer_description":"Reference:\nhttps://docs.microsoft.com/en-us/learn/modules/create-regression-model-azure-machine-learning-designer/5-create-training-pipeline https://docs.microsoft.com/en-us/learn/modules/create-classification-model-azure-machine-learning-designer/introduction https://docs.microsoft.com/en-us/learn/modules/create-clustering-model-azure-machine-learning-designer/1-introduction","url":"https://www.examtopics.com/discussions/microsoft/view/80868-exam-ai-900-topic-1-question-65-discussion/","timestamp":"2022-09-07 11:42:00","answer_images":["https://www.examtopics.com/assets/media/exam-media/04234/0007500002.jpg"],"question_images":["https://www.examtopics.com/assets/media/exam-media/04234/0007500001.jpg"],"answers_community":[],"exam_id":41,"isMC":false,"question_text":"HOTSPOT -\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","discussion":[{"timestamp":"1683527520.0","poster":"sbs_2010","upvote_count":"14","comment_id":"891853","content":"Answer is correct and it was there in my todays exam"},{"timestamp":"1663962540.0","poster":"Vijayachakravarthy","upvote_count":"11","comment_id":"677416","content":"No, No, Yes"},{"poster":"BobFar","upvote_count":"3","comment_id":"1255866","comments":[{"timestamp":"1730717460.0","poster":"MoneyStacking","comment_id":"1306898","content":"Yes, I agree with you!","upvote_count":"2"}],"content":"Answer is correct \n\n-Regression predicts a continuous numerical value, which is exactly what you're doing when forecasting the next number in a sequence.   \n\n-Classification is for predicting categorical labels (e.g., spam or not spam). It doesn't fit the problem of predicting a numerical value.   \n\n-Clustering groups similar data points together, which is not applicable to predicting a specific number in a sequence.","timestamp":"1722021540.0"},{"content":"Key topics to learn and consider here is supervised vs unsupervised learning to understand the difference between using labeled vs unlabeled data.","comment_id":"1008057","timestamp":"1694745240.0","upvote_count":"3","poster":"propanther"},{"poster":"zellck","timestamp":"1687650420.0","comments":[{"timestamp":"1687650480.0","upvote_count":"2","poster":"zellck","content":"https://learn.microsoft.com/en-us/training/modules/create-classification-model-azure-machine-learning-designer/classification-scenarios\nClassification is a form of machine learning that is used to predict which category, or class, an item belongs to. This machine learning technique can be applied to binary and multi-class scenarios. For example, a health clinic might use the characteristics of a patient (such as age, weight, blood pressure, and so on) to predict whether the patient is at risk of diabetes. In this case, the characteristics of the patient are the features, and the label is a binary classification of either 0 or 1, representing non-diabetic or diabetic.","comment_id":"933026"}],"content":"NNY is the answer.\n\nhttps://learn.microsoft.com/en-us/training/modules/create-clustering-model-azure-machine-learning-designer/2-clustering-scenarios\nClustering is a form of machine learning that is used to group similar items into clusters based on their features. For example, a researcher might take measurements of penguins, and group them based on similarities in their proportions.","comment_id":"933023","upvote_count":"3"},{"content":"correct","upvote_count":"3","poster":"rdemontis","comment_id":"909924","timestamp":"1685424720.0"},{"poster":"BLUE_BUBBLES","comment_id":"662309","upvote_count":"4","content":"Answer is correct.","timestamp":"1662543720.0"}],"unix_timestamp":1662543720,"question_id":209,"answer":""},{"id":"xNXT7ErH2h7tiyeyjoNG","answers_community":["CE (100%)"],"topic":"1","url":"https://www.examtopics.com/discussions/microsoft/view/80870-exam-ai-900-topic-1-question-66-discussion/","answer_description":"","answer_images":[],"discussion":[{"upvote_count":"11","comment_id":"677417","content":"Selected Answer: CE\nC & E are correct","timestamp":"1663962600.0","poster":"Vijayachakravarthy"},{"upvote_count":"1","poster":"M2000F007fubar","comment_id":"1308354","content":"Selected Answer: CE\nyes makes sense C & E","timestamp":"1730982660.0"},{"poster":"BobFar","content":"Answer is correct \ningestion ==> data transformation/manipulation \nC. Combine multiple datasets.\nE. Remove records that have missing values.","comment_id":"1255859","upvote_count":"3","timestamp":"1722021300.0"},{"timestamp":"1685424900.0","upvote_count":"2","poster":"rdemontis","comment_id":"909928","content":"Selected Answer: CE\nanswer is correct"},{"poster":"alexein74","upvote_count":"4","timestamp":"1684157760.0","comment_id":"898327","content":"Selected Answer: CE\nC and E are correct"},{"timestamp":"1684024200.0","upvote_count":"1","content":"Select Datasets > Split the Data","poster":"LaurenArcudi","comment_id":"897155"},{"poster":"AdrienBnhm","content":"By elimnation, A B and D cannot be correct.\n\nAnswers are C and E","timestamp":"1679827800.0","upvote_count":"1","comment_id":"850908"},{"poster":"BLUE_BUBBLES","upvote_count":"2","comment_id":"662311","timestamp":"1662543840.0","content":"Selected Answer: CE\nAnswer is correct."}],"unix_timestamp":1662543840,"isMC":true,"answer":"CE","exam_id":41,"timestamp":"2022-09-07 11:44:00","question_text":"Which two actions are performed during the data ingestion and data preparation stage of an Azure Machine Learning process? Each correct answer presents part of the solution.\nNOTE: Each correct selection is worth one point.","answer_ET":"CE","choices":{"C":"Combine multiple datasets.","E":"Remove records that have missing values.","A":"Calculate the accuracy of the model.","B":"Score test data by using the model.","D":"Use the model for real-time predictions."},"question_images":[],"question_id":210}],"exam":{"name":"AI-900","numberOfQuestions":246,"isMCOnly":false,"id":41,"provider":"Microsoft","isBeta":false,"lastUpdated":"12 Apr 2025","isImplemented":true},"currentPage":42},"__N_SSP":true}