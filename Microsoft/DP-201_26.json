{"pageProps":{"questions":[{"id":"jpizGhT063NdzBsj4W8g","unix_timestamp":1621821300,"url":"https://www.examtopics.com/discussions/microsoft/view/53452-exam-dp-201-topic-20-question-3-discussion/","question_id":126,"answer_ET":"C","isMC":true,"choices":{"C":"Azure Cosmos DB that uses the SQL API","A":"Azure Synapse Analytics","B":"Azure SQL Database","D":"Azure Cosmos DB that uses the Table API"},"answer_description":"Scenario: ADatum identifies the following requirements for the Health Interface application:\n✑ Reduce the amount of development effort to rewrite existing SQL queries.\n✑ Upgrade to a data storage solution that will provide flexible schemas and increased throughput for writing data. Data must be regionally located close to each hospital, and reads must display be the most recent committed version of an item.\n✑ Reduce the amount of time it takes to add data from new hospitals to Health Interface.\n✑ Support a more scalable batch processing solution in Azure.","discussion":[{"comment_id":"381146","upvote_count":"2","timestamp":"1623593040.0","poster":"ZodiaC","content":"https://docs.microsoft.com/en-us/azure/cosmos-db/how-to-provision-database-throughput?tabs=dotnetv2"},{"poster":"ZodiaC","content":"100 % CORRECT","upvote_count":"2","timestamp":"1623592980.0","comment_id":"381144"},{"comment_id":"365129","timestamp":"1621821300.0","content":"%100 CORRECT","poster":"memo43","upvote_count":"2"}],"answers_community":[],"timestamp":"2021-05-24 03:55:00","answer":"C","exam_id":66,"question_images":[],"topic":"20","question_text":"You need to recommend a solution that meets the data platform requirements of Health Interface. The solution must minimize redevelopment efforts for the application.\nWhat should you include in the recommendation?","answer_images":[]},{"id":"ATtN29WT8FLLhaI0CSfW","answer":"D","question_text":"Which consistency level should you use for Health Interface?","timestamp":"2020-10-27 11:49:00","question_images":[],"unix_timestamp":1603795740,"answers_community":[],"question_id":127,"answer_ET":"D","isMC":true,"answer_images":[],"choices":{"C":"Bounded Staleness","A":"Consistent Prefix","D":"Strong","B":"Session"},"topic":"20","exam_id":66,"discussion":[{"comment_id":"301404","content":"\"and reads must display be the most recent committed version of an item\" --> Strong","poster":"watata","timestamp":"1614609480.0","upvote_count":"13"},{"poster":"savin","content":"surely strong should be the consistency level","comment_id":"376170","timestamp":"1622993940.0","upvote_count":"1"},{"timestamp":"1617953220.0","poster":"maynard13x8","upvote_count":"2","comment_id":"331804","content":"I think answer is correct if we assume all data is written only to Los Angeles (where are located all its apps) and the other regions only read from it. In this case (single writer/multiple readers), it may be. The problem is that is unclear."},{"upvote_count":"3","poster":"axelwest36","timestamp":"1614172500.0","comment_id":"298207","content":"The following requirements make sure that the answer must be Session: \"reads must display be the most recent committed version of an item.\" and \"reduce the amount of time it takes to add data from new hospitals to Health Interface\" \nWith Session consistency, reads will never be out of order and it minimizes the latency"},{"comment_id":"271821","upvote_count":"2","poster":"awitick","content":"We cant use Strong on Dallas, New York and Los Angeles at the same time so D is wrong. A is obviously wrong cause it doesn't talk about low write latency and we only have to choose between B and C. Although C gives higher write latency, the read operation is not exactly 15 minutes and depends upon the number of updates which can change from 5 minutes to 1 day where Session gives us the RPO of less than 15 minutes guarantee which is reliable accordingly to the requirements. So the answer is C.","timestamp":"1611129780.0"},{"timestamp":"1610901180.0","content":"Definitely Strong","comment_id":"269639","upvote_count":"2","poster":"ACSC"},{"timestamp":"1607421360.0","poster":"syu31svc","comment_id":"238104","comments":[{"upvote_count":"3","content":"My bad please disregard; Strong is the answer","comment_id":"238108","poster":"syu31svc","timestamp":"1607421600.0"}],"content":"I would pick Bounded staleness\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels\nFor multiple write regions, Bounded staleness is recommended; you can find the table towards the end","upvote_count":"1"},{"comment_id":"231907","content":"You can't have multi region writes and Strong Consistancy","timestamp":"1606825020.0","poster":"Bonzai","comments":[{"comment_id":"333265","poster":"maynard13x8","timestamp":"1618142160.0","upvote_count":"1","content":"Never was said all region were writers. If you replicate data to all regions (one writer - multiple readers) you can use strong consistency.","comments":[{"poster":"maynard13x8","comment_id":"333269","upvote_count":"1","content":"... but “increased throughput for writing data” may suggest multiple writers. In this case, I’ll get session consistency because is better than Bounded staleness.","timestamp":"1618142520.0"}]}],"upvote_count":"4"},{"content":"And \"reduce the amount of time it takes to add data from new hospitals to Health Interface\" by configuring multiple write-regions.","poster":"M0e","upvote_count":"2","comments":[{"poster":"datachamp","upvote_count":"4","content":"The given answer for this question is correct as the most recent committed version of an item so it is Strong Consistency.\nBut the reason you are providing is not. This sentence \"reduce the amount of time it takes to add data from new hospitals to Health Interface\" is a sign to use Cosmo DB as a database solution. This means that new hospital can be with variant columns and format and so we need to provide a flexible schema solution (JSON Document etc) and so Cosmo DB with SQL API is the answer. Don't confuse it with multiple write-region.","comment_id":"230220","timestamp":"1606640280.0"}],"timestamp":"1603795740.0","comment_id":"206975"}],"answer_description":"Scenario: ADatum identifies the following requirements for the Health Interface application:\n✑ ..reads must display be the most recent committed version of an item.\nAzure Cosmos DB consistency levels include:\nStrong: Strong consistency offers a linearizability guarantee. Linearizability refers to serving requests concurrently. The reads are guaranteed to return the most recent committed version of an item. A client never sees an uncommitted or partial write. Users are always guaranteed to read the latest committed write.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels","url":"https://www.examtopics.com/discussions/microsoft/view/35290-exam-dp-201-topic-20-question-4-discussion/"},{"id":"SG0n4CmM4Zuez9pF3f68","question_text":"HOTSPOT -\nYou need to design the storage for the Health Insights data platform.\nWhich types of tables should you include in the design? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","question_images":["https://www.examtopics.com/assets/media/exam-media/03774/0003300001.jpg"],"unix_timestamp":1615565520,"answer_description":"Box 1: Hash-distributed tables -\nThe new Health Insights application must be built on a massively parallel processing (MPP) architecture that will support the high performance of joins on large fact tables.\nHash-distributed tables improve query performance on large fact tables.\nBox 2: Round-robin distributed tables\nA round-robin distributed table distributes table rows evenly across all distributions. The assignment of rows to distributions is random.\nScenario:\nADatum identifies the following requirements for the Health Insights application:\n✑ The new Health Insights application must be built on a massively parallel processing (MPP) architecture that will support the high performance of joins on large fact tables.\nReference:\nhttps://docs.microsoft.com/en-us/azure/sql-data-warehouse/sql-data-warehouse-tables-distribute\nDesign Azure data storage solutions","exam_id":66,"topic":"20","discussion":[{"poster":"kz_data","comments":[{"poster":"maynard13x8","timestamp":"1617953700.0","comment_id":"331811","upvote_count":"2","content":"Round robin improve data loading, which is needed. Data from Interface and Review must be loading in less than 15 minutes."}],"timestamp":"1615565520.0","comment_id":"309001","content":"Data Dimension should be replicated tables","upvote_count":"28"},{"poster":"joegei","content":"Round Robin is used to increase staging performance. It doesn''t make sense to use this on Dimension tables who tend to be relatively small and don't change often. So load performance is less of an issue. Query performance however will benefit from replicated tables. Therefore I would go for replicated tables as well","comment_id":"348601","timestamp":"1620045780.0","upvote_count":"7"},{"poster":"arpit_dataguy","comment_id":"389548","content":"If the table size is < 2 GB, we should always go with Replicated Tables. As this is cached in all the nodes therefore reduces data movement across nodes.","timestamp":"1624535880.0","upvote_count":"1"},{"content":"Round Robin is bad option for Dim tables. Idea is to use replicated tables for dimensions to improve performance","timestamp":"1622994060.0","comment_id":"376171","poster":"savin","upvote_count":"1"},{"comment_id":"309310","upvote_count":"2","content":"I agree, unless the part says used with multiple fact tables' joins means something else","timestamp":"1615597140.0","poster":"felmasri"}],"url":"https://www.examtopics.com/discussions/microsoft/view/46737-exam-dp-201-topic-20-question-5-discussion/","answer_ET":"","question_id":128,"answer_images":["https://www.examtopics.com/assets/media/exam-media/03774/0003400001.jpg"],"answer":"","isMC":false,"answers_community":[],"timestamp":"2021-03-12 17:12:00"},{"id":"7tZqJfIBICge859nZafS","answer_description":"Azure Blobs: A massively scalable object store for text and binary data.\nAzure Cognitive Search supports fuzzy search. You can use Azure Cognitive Search to index blobs.\nScenario:\n✑ The visual monitoring system is a network of approximately 1,000 cameras placed near highways that capture images of vehicle traffic every 2 seconds. The cameras record high resolution images. Each image is approximately 3 MB in size.\n✑ The solution must allow for searches of vehicle images by license plate to support law enforcement investigations. Searches must be able to be performed using a query language and must support fuzzy searches to compensate for license plate detection errors.\nIncorrect Answers:\nB: Azure Tables: A NoSQL store for schemaless storage of structured data.\nReference:\nhttps://docs.microsoft.com/en-us/azure/storage/common/storage-introduction https://docs.microsoft.com/en-us/azure/search/search-howto-indexing-azure-blob-storage#how-azure-cognitive-search-indexes-blobs","question_text":"You need to design the storage for the visual monitoring system.\nWhich storage solution should you recommend?","answers_community":[],"topic":"21","exam_id":66,"question_images":[],"timestamp":"2021-04-24 14:38:00","unix_timestamp":1619267880,"discussion":[{"comment_id":"387534","upvote_count":"2","poster":"davem0193","timestamp":"1624325280.0","content":"Link provided in solution confirms blob storage as the answer - https://docs.microsoft.com/en-us/azure/search/search-howto-indexing-azure-blob-storage#how-azure-cognitive-search-indexes-blobs"},{"upvote_count":"1","comment_id":"376214","comments":[{"timestamp":"1624347720.0","content":"Azure BLOB Storage = Correct. Make confusion right know, Dymize is right.","comment_id":"387695","upvote_count":"1","poster":"ZodiaC"}],"content":"The correct answer : (D) Azure Cosmos DB \n\nCosmos DB is ideally suited for IoT solutions. Cosmos DB can ingest device telemetry data at high rates and can serve indexed queries back with low latency and high availability.\n\nhttps://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/iot-using-cosmos-db#:~:text=Cosmos%20DB%20is%20ideally%20suited,low%20latency%20and%20high%20availability.","timestamp":"1622997900.0","poster":"Qrm_1972"},{"poster":"AngelRio","comments":[{"upvote_count":"6","content":"You're right about what CosmosDB is used for but the visual monitoring system is capturing and storing images. Since ADLS isn't here for higher performance, Blob storage would be the answer","comment_id":"368937","poster":"Dymize","timestamp":"1622223480.0"}],"comment_id":"364256","upvote_count":"1","timestamp":"1621755780.0","content":"I think is Comos DB. According to Azure Documentation, Azure Cosmos DB is used for IoT and Telemetry..."},{"timestamp":"1619267880.0","comment_id":"342020","upvote_count":"4","poster":"anamaster","content":"correct","comments":[{"poster":"memo43","content":"i think adl2 will be better!\nevery 2 second 3GB data...","upvote_count":"1","comment_id":"367224","timestamp":"1622040600.0"}]}],"choices":{"C":"Azure SQL database","A":"Azure Blob storage","B":"Azure Table storage","D":"Azure Cosmos DB"},"question_id":129,"url":"https://www.examtopics.com/discussions/microsoft/view/50887-exam-dp-201-topic-21-question-1-discussion/","answer_images":[],"answer":"A","answer_ET":"A","isMC":true},{"id":"2YYvVsjl8FWu7uFBHHq7","answer_description":"Azure Cosmos DB is a globally distributed database service. You can associate any number of Azure regions with your Azure Cosmos account and your data is automatically and transparently replicated.\nScenario:\n\nTelemetry Capture -\nThe telemetry capture system records each time a vehicle passes in front of a sensor. The sensors run on a custom embedded operating system and record the following telemetry data:\n✑ Time\n✑ Location in latitude and longitude\n✑ Speed in kilometers per hour (kmph)\n✑ Length of vehicle in meters\nYou must write all telemetry data to the closest Azure region. The sensors used for the telemetry capture system have a small amount of memory available and so must write data as quickly as possible to avoid losing telemetry data.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/high-availability","choices":{"A":"Azure Synapse Analytics","C":"Azure Cosmos DB","B":"Azure Databricks"},"unix_timestamp":1619268180,"discussion":[{"timestamp":"1619268180.0","poster":"anamaster","upvote_count":"7","comment_id":"342022","content":"correct"}],"question_id":130,"answers_community":[],"isMC":true,"answer_ET":"C","exam_id":66,"question_text":"You need to design the storage for the telemetry capture system.\nWhat storage solution should you use in the design?","topic":"21","question_images":[],"timestamp":"2021-04-24 14:43:00","answer":"C","url":"https://www.examtopics.com/discussions/microsoft/view/50888-exam-dp-201-topic-21-question-2-discussion/","answer_images":[]}],"exam":{"lastUpdated":"12 Apr 2025","isMCOnly":false,"id":66,"numberOfQuestions":206,"isImplemented":true,"name":"DP-201","isBeta":false,"provider":"Microsoft"},"currentPage":26},"__N_SSP":true}