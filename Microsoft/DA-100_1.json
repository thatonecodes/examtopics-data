{"pageProps":{"questions":[{"id":"9UUZopNUpB98daQhGTIx","question_images":[],"discussion":[{"comments":[{"poster":"Regina18","upvote_count":"1","timestamp":"1702994160.0","comment_id":"1100672","content":"Option C: Implementing row-level security (RLS) is a more appropriate solution for controlling access to data based on the sender's email ID. While it doesn't directly address minimizing the model size, it provides a way to filter the data at runtime, ensuring that each user sees only the relevant information.","comments":[{"content":"Option A: Hiding columns in the model view doesn't necessarily minimize the model size. It only controls the visibility of columns in the report. The data is still present in the model.\n\nOption B: Removing unnecessary columns during import can reduce the model size, but it might not be the best solution if you need those columns for analysis. It also doesn't address the requirement of restricting access to the analyzed emails.","poster":"Regina18","timestamp":"1702994220.0","comment_id":"1100673","upvote_count":"1"}]}],"comment_id":"199968","poster":"vinothravi","content":"B. Remove the Subject and Body columns during the import.","upvote_count":"89","timestamp":"1602695100.0"},{"poster":"binah","upvote_count":"24","comments":[{"upvote_count":"2","timestamp":"1633634220.0","poster":"troydavidcook","comment_id":"458903","content":"What's the format of the case studies.?"}],"content":"Hi analysts. l took my exam on June 13 2021 and passed with 800+ score. All two case studies were from here and also 70% of the questions just verify your answers with discussions and on PowerBi as well. Thank you examtopics and thank you everyone!","comment_id":"409378","timestamp":"1626682920.0"},{"timestamp":"1711916100.0","poster":"vikiviki","comment_id":"1187002","upvote_count":"1","content":"vikiviki 0 minutes ago Awaiting moderator approval\nI think must be A because if you choose to remove Subject and Body columns you will have report based on whom they send emails , so the report and analyzed data (to whom..) of the rest part of the mails will still be visible."},{"timestamp":"1660040400.0","poster":"skaha","upvote_count":"1","comment_id":"644447","content":"B is correct. do not load unwanted columns in the model. \nQuestion: Can I use RLS to limit the columns or measures accessible by my users?\nAnswer: No, if a user has access to a particular row of data, they can see all the columns of data for that row.\nhttps://docs.microsoft.com/en-us/power-bi/enterprise/service-admin-rls"},{"upvote_count":"1","content":"Selected Answer: B\nOption B will reduce the model size","comment_id":"641543","timestamp":"1659497100.0","poster":"Nurgul"},{"upvote_count":"1","poster":"nuzzi","comment_id":"630842","content":"Selected Answer: B\nB. Remove the Subject and Body columns during the import.","timestamp":"1657701300.0"},{"upvote_count":"1","timestamp":"1646158500.0","content":"on exam 3/1/2022","comment_id":"558898","poster":"Ashley090521"},{"content":"Selected Answer: B\nCorrect","timestamp":"1642363500.0","comment_id":"525235","poster":"teeman001","upvote_count":"3"},{"timestamp":"1640623080.0","content":"On exam Dec 27, 2021 - answered B","comment_id":"510468","poster":"kwanalytics","upvote_count":"2"},{"timestamp":"1636660500.0","poster":"aguilartu1","upvote_count":"1","content":"on exam - Nov 11, 2021.","comment_id":"476459"},{"comment_id":"461354","poster":"bilearner","timestamp":"1634099400.0","upvote_count":"4","content":"B is the right ans"},{"content":"B removes the data & minimize the size also","poster":"Kiran37","timestamp":"1632406440.0","comment_id":"450339","upvote_count":"2"},{"poster":"Hope2000","upvote_count":"2","content":"B is the right option!","timestamp":"1629319620.0","comment_id":"427066"},{"comment_id":"425123","poster":"francis6170","upvote_count":"3","content":"Got this in the exam - Aug 15, 2021.","timestamp":"1629015660.0"},{"upvote_count":"2","content":"Answer is B","comment_id":"412937","poster":"adeyinkaamole","timestamp":"1627098960.0"},{"comment_id":"409089","poster":"tramynt","upvote_count":"1","timestamp":"1626632580.0","content":"B. \" The solution must minimize the model size \""},{"comment_id":"401430","upvote_count":"9","poster":"JustMurf","timestamp":"1625707440.0","content":"Can moderators please delete the request for people to send them the full pdf and answers. it defeats the purpose of contributors access.. \nThose that want the PDF, if you can afford to sit the exam you can afford to pay for the access stop being cheap..."},{"timestamp":"1625576160.0","upvote_count":"1","content":"Please send the correct answers here- shyenne96@yahoo.com","poster":"Shyanne","comment_id":"399990","comments":[{"upvote_count":"3","poster":"JustMurf","content":"Just pay like everyone else..SMH","timestamp":"1625707320.0","comment_id":"401428"}]},{"upvote_count":"1","content":"This question was in the exam.","poster":"Ps18","timestamp":"1624976580.0","comment_id":"393856"},{"poster":"Ps18","upvote_count":"1","timestamp":"1618845780.0","comment_id":"338914","content":"Will microsoft learn path and the exam topics 90 questions be enough to clear the exam ?\nCan anyone help me understand ?","comments":[{"content":"Yes, I had 0 experience with Power BI and did all the microsoft learn paths and these practice questions. I passed with a 77% score (minimum is 70%). Best of luck!!","poster":"Min5572","comment_id":"390602","timestamp":"1624635360.0","upvote_count":"4"},{"content":"Did was enough for you?","timestamp":"1621602540.0","comment_id":"363042","upvote_count":"1","poster":"Pombo"}]},{"content":"my answer would be B","upvote_count":"1","timestamp":"1618323660.0","comment_id":"334734","poster":"deepakbp"},{"content":"B. Remove the Subject and Body columns during the import.","timestamp":"1618318920.0","upvote_count":"1","comment_id":"334691","poster":"Triparna"},{"upvote_count":"1","poster":"Bamo","timestamp":"1617876180.0","comment_id":"331064","content":"B is the correct answer for me"},{"upvote_count":"1","poster":"jeffyeh","timestamp":"1616373780.0","comment_id":"316757","content":"B. This also minimize the model size and data size."},{"timestamp":"1615971840.0","comment_id":"313069","content":"correct B","upvote_count":"1","poster":"norly"},{"content":"B isthe right option","comment_id":"301706","timestamp":"1614647640.0","upvote_count":"1","poster":"omoty"},{"poster":"Refined","comments":[{"upvote_count":"2","timestamp":"1614613800.0","poster":"mainezes","content":"The solution B prevent the recipients from reading the e-mails because the body will be removed during the import. PS: The question does not mention that the recipients will only read the e-mails sent to them. It says the recipient must not read the e-mails, in general.","comment_id":"301429"}],"comment_id":"289375","upvote_count":"2","content":"There are two parts to the question 1. Recipients not seeing emails to them and 2. reduce data model B. will answer 2 but not 1 so I vote A. Correct me if am wrong.","timestamp":"1613205540.0"},{"upvote_count":"2","timestamp":"1608433560.0","comment_id":"248341","comments":[{"poster":"VesperKiw","comment_id":"251963","timestamp":"1608888540.0","upvote_count":"6","content":"The solution must minimize the model size and the requirement of the report doesn't indicate that the subject/body is required for the analysis. Therefore B is the best answer."}],"content":"I think A","poster":"tracytran"}],"exam_id":63,"question_id":1,"answer_description":"","question_text":"You have a custom connector that returns ID, From, To, Subject, Body, and Has Attachments for every email sent during the past year. More than 10 million records are returned.\nYou build a report analyzing the internal networks of employees based on whom they send emails to.\nYou need to prevent report recipients from reading the analyzed emails. The solution must minimize the model size.\nWhat should you do?","answer_images":[],"unix_timestamp":1602695100,"isMC":true,"answer_ET":"B","topic":"1","choices":{"C":"From Model view, set the Subject and Body columns to Hidden.","B":"Remove the Subject and Body columns during the import.","A":"Implement row-level security (RLS) so that the report recipients can only see results based on the emails they sent."},"url":"https://www.examtopics.com/discussions/microsoft/view/34484-exam-da-100-topic-1-question-1-discussion/","answers_community":["B (100%)"],"answer":"B","timestamp":"2020-10-14 19:05:00"},{"id":"FNWiBmAOFkuiVidxcU1r","topic":"1","answer_ET":"C","unix_timestamp":1619770080,"answer_description":"","choices":{"B":"Apply a transformation to extract the last 11 characters of the Logged column and set the data type of the new column to Date.","D":"Add a conditional column that outputs 2018 if the Logged column starts with 2018 and set the data type of the new column to Whole Number.","A":"Change the data type of the Logged column to Date.","C":"Create a column by example that starts with 2018-12-31 and set the data type of the new column to Date."},"timestamp":"2021-04-30 10:08:00","question_id":2,"exam_id":63,"url":"https://www.examtopics.com/discussions/microsoft/view/51192-exam-da-100-topic-1-question-10-discussion/","question_text":"You have a CSV file that contains user complaints. The file contains a column named Logged. Logged contains the date and time each complaint occurred. The data in Logged is in the following format: 2018-12-31 at 08:59.\nYou need to be able to analyze the complaints by the logged date and use a built-in date hierarchy.\nWhat should you do?","isMC":true,"discussion":[{"content":"is true c","timestamp":"1619866680.0","comment_id":"346860","poster":"DeathCaliberKnight","upvote_count":"35"},{"poster":"Cloudy_Dave","content":"This was in the exam on 28th May","upvote_count":"7","comment_id":"369636","timestamp":"1622308500.0"},{"upvote_count":"1","comment_id":"677807","timestamp":"1664022420.0","poster":"RichardOgoma","content":"Selected Answer: C\nSplitting columns by delimiter \" at \" is the best option though. Column by examples would do the same."},{"content":"Selected Answer: C\nC is the right one","upvote_count":"1","poster":"RamzanAnjum","timestamp":"1658801280.0","comment_id":"637064"},{"timestamp":"1655730720.0","upvote_count":"1","comment_id":"619295","poster":"Soksay","content":"Selected Answer: C\nC is the right answer"},{"comments":[{"upvote_count":"1","poster":"Tomasz1989","comment_id":"608562","content":"Because this feature creates dynamic formula based on your example.","timestamp":"1653782100.0"}],"upvote_count":"2","content":"if C is true, then this data column is created by ourselves, not actually contain the info from Logged data of the csv file? How would it connect to the Logged data?","comment_id":"411489","timestamp":"1626944520.0","poster":"midnight93"},{"timestamp":"1622753340.0","poster":"ThierryProsper","comment_id":"373889","comments":[{"upvote_count":"1","poster":"eurekamike","content":"Je suis d'accord","comment_id":"416977","timestamp":"1627582140.0"}],"content":"Pour créer une hiérarchie de date, il faut créer une nouvelle colonne . C est juste.","upvote_count":"4"},{"upvote_count":"4","content":"Yes, \"C\" is the correct answer.","timestamp":"1621954260.0","poster":"severalsun","comment_id":"366515"},{"comment_id":"361359","upvote_count":"4","poster":"Jonathan1726","comments":[{"upvote_count":"1","poster":"Canary_2021","content":"You are right! Should select C because of \"at\" word in this column.","comment_id":"383587","timestamp":"1623863940.0"}],"content":"I think that the reason for the answer to be C and not A is because of the format \"2018-12-31 at 08:59\" the \"at\" word makes the data type string which is not going to be able to parse as Date type.","timestamp":"1621426740.0"},{"timestamp":"1621349940.0","content":"Think A, just change the column type. Adding new column seems redundant","comments":[{"upvote_count":"1","content":"but there's the \"at\" word, so A can't work","comment_id":"383977","timestamp":"1623912360.0","poster":"Massy"}],"comment_id":"360592","upvote_count":"3","poster":"bankijey"},{"upvote_count":"1","comments":[{"content":"The best way to optimize dates is to split the columns to enable drill down. no redundancy here","comment_id":"361658","upvote_count":"2","timestamp":"1621457820.0","poster":"Amuzinde"}],"poster":"[Removed]","content":"Why not A?","comment_id":"359741","timestamp":"1621272600.0"},{"poster":"memo43","content":"Yes answer is C\nhttps://docs.microsoft.com/en-us/power-bi/create-reports/desktop-add-column-from-example","timestamp":"1620313200.0","upvote_count":"4","comment_id":"351103"}],"answers_community":["C (100%)"],"answer":"C","question_images":[],"answer_images":[]},{"id":"WvnjN78YGRhUXGQ9rxCT","exam_id":63,"unix_timestamp":1602691080,"answer":"B","url":"https://www.examtopics.com/discussions/microsoft/view/34480-exam-da-100-topic-1-question-11-discussion/","answer_description":"","isMC":true,"timestamp":"2020-10-14 17:58:00","choices":{"A":"Add a SQL statement.","B":"Set Data Connectivity mode to DirectQuery.","C":"Set the Command timeout in minutes setting.","D":"Set Data Connectivity mode to Import."},"discussion":[{"comments":[{"poster":"marciomanini","content":"Agreed","timestamp":"1602890700.0","comment_id":"201253","upvote_count":"1"}],"poster":"RajGoy","timestamp":"1602691080.0","upvote_count":"87","comment_id":"199910","content":"Direct mode is best option here."},{"timestamp":"1602717960.0","content":"B. Set Data Connectivity mode to DirectQuery.","poster":"vinothravi","comment_id":"200169","upvote_count":"25","comments":[{"content":"agreed","poster":"Bamo","upvote_count":"3","timestamp":"1617876840.0","comment_id":"331080"}]},{"timestamp":"1658801340.0","upvote_count":"1","poster":"RamzanAnjum","comment_id":"637066","content":"Agreed - DirectQuery"},{"upvote_count":"2","timestamp":"1650086280.0","comment_id":"586618","poster":"vineyvinni","content":"Selected Answer: B\nDirect Mode is correct option"},{"timestamp":"1648474020.0","upvote_count":"1","content":"B is correct. \n\nA new SQL query will not solve the issue. \nImport is better for infrequently updated tables.","comment_id":"576884","poster":"PowerBIAddict"},{"upvote_count":"1","comments":[{"poster":"claudeaboki","content":"how did you find the correct answers? the most voted are the best or the answers on the site? Thanks","timestamp":"1654557780.0","comment_id":"612511","upvote_count":"1"}],"content":"I got it on my exam 03/17/2022. 90-95% questions were from here.","comment_id":"569811","timestamp":"1647529440.0","poster":"TechDiva"},{"comments":[{"content":"Hello, can you send me an email? I will do my exam next week","comment_id":"630985","poster":"REINORK","upvote_count":"1","timestamp":"1657730580.0"}],"upvote_count":"1","timestamp":"1646668020.0","content":"In exam 07-03-2022","poster":"Letsgo9999","comment_id":"562728"},{"timestamp":"1643421480.0","poster":"battenarajesh","comment_id":"535081","upvote_count":"1","content":"Direct Mode"},{"timestamp":"1642896900.0","poster":"Pritam85","upvote_count":"1","comment_id":"530154","content":"B is correct answer"},{"comment_id":"510458","timestamp":"1640622540.0","poster":"kwanalytics","content":"On exam Dec 27, 2021 - answer B","upvote_count":"2"},{"upvote_count":"1","poster":"MustPassDA100","content":"on exam 12/25/2021","timestamp":"1640589840.0","comment_id":"510086"},{"timestamp":"1640301300.0","upvote_count":"2","content":"Answer is B for retrieve more recent data, import is for caching and performance","comment_id":"508187","poster":"kblee"},{"timestamp":"1639148160.0","upvote_count":"1","content":"on exam 12/10/2021","comment_id":"498724","poster":"PatrickStr"},{"upvote_count":"3","timestamp":"1637406960.0","content":"Selected Answer: B\nB: Azure SQL database supports DirectQuery","comment_id":"482444","poster":"klaudio92"},{"timestamp":"1636660200.0","upvote_count":"3","comment_id":"476453","content":"on exam - Nov 11, 2021. \nmy answer: \nSet Data Connectivity mode to DirectQuery.","poster":"aguilartu1"},{"content":"On exam 10/14/21","timestamp":"1634216880.0","comment_id":"462040","upvote_count":"1","poster":"kcwood94"},{"timestamp":"1629015780.0","comment_id":"425127","upvote_count":"6","comments":[{"upvote_count":"4","comment_id":"456919","content":"What is correct answer? that will be more helpful rather to know about you got this question in exam.","timestamp":"1633328700.0","poster":"HaliBrickclay"}],"content":"Got this in the exam - Aug 15, 2021.","poster":"francis6170"},{"content":"B is as obvious as\" Earth is not flat\".","poster":"JessieVuong","comment_id":"384697","upvote_count":"9","timestamp":"1624005960.0","comments":[{"content":"Haha..","upvote_count":"1","comment_id":"473160","poster":"sundeep2021","timestamp":"1636137420.0"},{"upvote_count":"2","poster":"troydavidcook","timestamp":"1633612260.0","content":"The Earth's not WHAT now..?","comment_id":"458753"}]},{"content":"This was in the exam on 28th May","comment_id":"369637","poster":"Cloudy_Dave","upvote_count":"6","timestamp":"1622308560.0"},{"content":"Direct query mode is correct","poster":"Waltmas","upvote_count":"2","comment_id":"345372","timestamp":"1619699880.0"},{"timestamp":"1619615760.0","upvote_count":"2","poster":"Mdve","content":"B. Set Data Connectivity mode to DirectQuery","comment_id":"344666"},{"timestamp":"1617537300.0","poster":"saditya1","comment_id":"327942","content":"Direct mode is the correct answer","upvote_count":"2"},{"content":"Correct","comment_id":"313099","poster":"norly","timestamp":"1615974180.0","upvote_count":"3"},{"comment_id":"292465","poster":"objecto","timestamp":"1613560560.0","upvote_count":"2","content":"B seems to be obvious"},{"comment_id":"262093","poster":"ElaineXavier","upvote_count":"2","content":"Yes, Agreed","timestamp":"1610047380.0"}],"question_text":"You have an Azure SQL database that contains sales transactions. The database is updated frequently.\nYou need to generate reports from the data to detect fraudulent transactions. The data must be visible within five minutes of an update.\nHow should you configure the data connection?","question_id":3,"answer_ET":"B","question_images":[],"answer_images":[],"answers_community":["B (100%)"],"topic":"1"},{"id":"6sRfLvjc8fOB7YieEgZw","answer_description":"","answer_images":[],"choices":{"B":"Hide unused columns in the model.","A":"Split the model into multiple models.","C":"Merge tables by using Power Query.","D":"Transpose."},"question_text":"You have a data model that contains many complex DAX expressions. The expressions contain frequent references to the RELATED and RELATEDTABLE functions.\nYou need to recommend a solution to minimize the use of the RELATED and RELATEDTABLE functions.\nWhat should you recommend?","exam_id":63,"isMC":true,"answers_community":["C (100%)"],"question_id":4,"answer_ET":"C","timestamp":"2020-10-15 01:28:00","topic":"1","unix_timestamp":1602718080,"discussion":[{"content":"C. Merge tables by using Power Query","upvote_count":"81","poster":"vinothravi","comment_id":"200170","timestamp":"1602718080.0"},{"comment_id":"200736","poster":"Talkabout_Me","timestamp":"1602790440.0","content":"C .should be the correct option here.","upvote_count":"15"},{"comment_id":"677810","poster":"RichardOgoma","content":"Selected Answer: C\nDenormalize the model by merging similar tables and eliminate redundancy and improve performance by reducing the data transfer path.","timestamp":"1664022600.0","upvote_count":"1"},{"poster":"halfway","content":"Selected Answer: C\nIt helps performance to merge tables.","upvote_count":"2","timestamp":"1662382080.0","comment_id":"660183"},{"content":"C but I think it's not very wise to do so. PowerBi is great with related tables. Using merge creates flat tables which are big and slow.","poster":"Tomasz1989","comment_id":"608564","upvote_count":"4","timestamp":"1653782340.0"},{"content":"Got this in the exam - Aug 15, 2021.","comment_id":"425128","comments":[{"timestamp":"1629532920.0","content":"Hi Francis,\nIn your Exam did you found many different questions from those we can find in here?","poster":"Vulkany","upvote_count":"1","comment_id":"428563"}],"poster":"francis6170","upvote_count":"2","timestamp":"1629015780.0"},{"poster":"prabhjot","upvote_count":"2","content":"Ans C is correct we can always merge tables in Querry builder stage, ( it is call as Transformation stage) just before Close and Apply","comment_id":"367714","timestamp":"1622103720.0"},{"poster":"fhqhfhqh","timestamp":"1621681980.0","content":"This question was in the exam.","comment_id":"363618","upvote_count":"7"},{"content":"C seems the reasonable answer","comment_id":"345376","timestamp":"1619699940.0","poster":"Waltmas","upvote_count":"3"},{"upvote_count":"4","content":"C. Merge tables by using Power Query.","poster":"Mdve","timestamp":"1619615820.0","comment_id":"344668"},{"poster":"objecto","upvote_count":"3","timestamp":"1613560680.0","comment_id":"292467","content":"C seems to be the correct model but if you got such a mess to need that your model sucks."},{"upvote_count":"2","timestamp":"1610047800.0","content":"C is correct","poster":"ElaineXavier","comment_id":"262106"},{"content":"agree C","timestamp":"1607930580.0","poster":"weezer77","upvote_count":"2","comment_id":"243352"},{"upvote_count":"4","poster":"Fatjan","timestamp":"1607714460.0","comment_id":"241158","content":"C. Correct answer"},{"upvote_count":"2","timestamp":"1606056900.0","content":"C is correct","poster":"Ruggero","comment_id":"225018"},{"poster":"HYBH","timestamp":"1604909880.0","content":"Answer C","comment_id":"215754","upvote_count":"2"}],"answer":"C","url":"https://www.examtopics.com/discussions/microsoft/view/34514-exam-da-100-topic-1-question-12-discussion/","question_images":[]},{"id":"Fk5HOAaWM8s68mrVjlKR","exam_id":63,"unix_timestamp":1619961540,"answer":"D","url":"https://www.examtopics.com/discussions/microsoft/view/51548-exam-da-100-topic-1-question-13-discussion/","isMC":true,"answer_description":"","timestamp":"2021-05-02 15:19:00","choices":{"C":"Trim the Date column.","D":"Split the Date column into two columns, one that contains only the time and another that contains only the date.","B":"Change the data type of the Date column to Text.","A":"Round the hour of the Date column to startOfHour."},"discussion":[{"timestamp":"1620191520.0","upvote_count":"59","content":"the answer is correct , its always better to separate date and time","comment_id":"349945","poster":"DeathCaliberKnight"},{"upvote_count":"22","timestamp":"1619961540.0","content":"D - Is the correct answer","comment_id":"347737","poster":"ThaboS"},{"upvote_count":"1","poster":"Samuel77","timestamp":"1661194020.0","comment_id":"650398","content":"D is the correct answer"},{"upvote_count":"2","poster":"TrevorK","timestamp":"1660751040.0","comment_id":"648140","content":"D reduces cardinality"},{"timestamp":"1660071000.0","comment_id":"644633","poster":"NUYO","upvote_count":"1","content":"D all the way"},{"timestamp":"1659539640.0","content":"D for sure","upvote_count":"1","poster":"knigmich","comment_id":"641979"},{"content":"the answer is correct","poster":"pimni","timestamp":"1657943460.0","upvote_count":"1","comment_id":"631987"},{"upvote_count":"1","timestamp":"1651732020.0","content":"D is Correct, because one other information in Date like time makes the process slower to identify unique patterns","poster":"dmnantilla9","comment_id":"597153"},{"content":"Selected Answer: D\nThe best thing is date and time to be separate columns","timestamp":"1650086580.0","upvote_count":"1","poster":"vineyvinni","comment_id":"586621"},{"timestamp":"1648474140.0","comment_id":"576886","upvote_count":"1","content":"D is correct. It keeps the data and reduces size as we have less unique rows.","poster":"PowerBIAddict"},{"timestamp":"1647529500.0","upvote_count":"3","comments":[{"comment_id":"639947","content":"Hi.......Pls do you have the complete exam package","upvote_count":"1","poster":"Darhmiee","timestamp":"1659251280.0"}],"poster":"TechDiva","comment_id":"569813","content":"I got it on my exam 03/17/2022. 90-95% questions were from here."},{"content":"In exam 07-03-2022","timestamp":"1646668080.0","comment_id":"562729","upvote_count":"1","poster":"Letsgo9999"},{"poster":"battenarajesh","content":"C is correct","timestamp":"1643421600.0","upvote_count":"1","comment_id":"535083"},{"upvote_count":"1","timestamp":"1642484100.0","poster":"Ajitk27","comment_id":"526318","content":"Yes, D seems to be the correct answer."},{"content":"Selected Answer: D\nD is correct","comment_id":"513270","timestamp":"1640862240.0","upvote_count":"2","poster":"creditiridium"},{"upvote_count":"1","timestamp":"1640622540.0","poster":"kwanalytics","content":"On exam Dec 27, 2021 - answer D","comment_id":"510459"},{"comment_id":"510307","content":"Selected Answer: D\nD is correct, the best practice is to split date and time to reduce size","upvote_count":"1","timestamp":"1640610000.0","poster":"DatBI"},{"poster":"PatrickStr","content":"on exam 12/10/2021","timestamp":"1639148160.0","upvote_count":"2","comment_id":"498725"},{"upvote_count":"1","content":"Certainly. D is the correct answer.","timestamp":"1637996820.0","poster":"mrdavezy","comment_id":"487917"},{"comment_id":"462041","poster":"kcwood94","upvote_count":"3","comments":[{"comment_id":"467685","content":"had this 25/10","timestamp":"1635195600.0","upvote_count":"3","poster":"Diginomad"}],"timestamp":"1634216880.0","content":"On exam 10/14/21"},{"upvote_count":"7","timestamp":"1629535980.0","content":"D - is the correct answer.\nIf you have a date time type column, probability you have much more unique values in each row, and consequently lower the compression capabilities of the engine.","comment_id":"428583","poster":"Vulkany"},{"upvote_count":"3","timestamp":"1627464780.0","poster":"AshuX4232","content":"Answer is D, its best practice to split datetime column to date and time to reduce the datamodel size and increase the performance","comment_id":"416116"},{"comment_id":"392512","upvote_count":"2","content":"D is correct!","poster":"cxGetter","timestamp":"1624846260.0"},{"upvote_count":"9","timestamp":"1624006260.0","content":"D as suggestion by Microsoft\nhttps://docs.microsoft.com/en-us/learn/modules/get-data/8-performance-issues\n\"Separate date and time, if bound together. If any of your tables have columns that combine date and time, make sure that you separate them into distinct columns before importing them into Power BI. This approach will increase compression abilities.\"","poster":"JessieVuong","comment_id":"384698"},{"timestamp":"1623996480.0","content":"How does splitting columns (answer D) solve the size reduction of the model?","poster":"mirzotti","upvote_count":"2","comment_id":"384603","comments":[{"upvote_count":"1","timestamp":"1633616400.0","poster":"troydavidcook","comment_id":"458777","content":"This is my question. It makes sense, but the \"reducing size bit\" threw me."},{"upvote_count":"10","timestamp":"1624535760.0","comment_id":"389545","content":"Once you split them, as well as the date column, Time dimension is the same principle as a Date dimension, except instead of a row for every day, you would have a row for every minute or every second. Now you can choose to not including the seconds since it greatly increases the number of rows you need - impacting performance. So, this reduce model size because we don’t need to put the time into the date table, because the time is repeated every day. I hope it helps","poster":"Ihueghian"}]},{"comment_id":"361820","poster":"andreimw","upvote_count":"5","content":"https://docs.microsoft.com/en-us/learn/modules/get-data/8-performance-issues \nbottom of the page","timestamp":"1621484160.0"},{"content":"correct","timestamp":"1621325160.0","upvote_count":"1","poster":"durgesh_gk","comment_id":"360233"},{"timestamp":"1621270320.0","upvote_count":"2","poster":"Pringle","content":"The correct answer is D","comment_id":"359711"}],"question_text":"You have a large dataset that contains more than 1 million rows. The table has a datetime column named Date.\nYou need to reduce the size of the data model without losing access to any data.\nWhat should you do?","question_id":5,"answer_ET":"D","question_images":[],"answer_images":[],"answers_community":["D (100%)"],"topic":"1"}],"exam":{"isBeta":false,"id":63,"lastUpdated":"12 Apr 2025","isMCOnly":false,"provider":"Microsoft","isImplemented":true,"numberOfQuestions":94,"name":"DA-100"},"currentPage":1},"__N_SSP":true}