{"pageProps":{"questions":[{"id":"QPtUnH2cVkAzf8G68gXb","question_id":366,"unix_timestamp":1618859640,"url":"https://www.examtopics.com/discussions/microsoft/view/50502-exam-dp-100-topic-4-question-1-discussion/","discussion":[{"comment_id":"357236","poster":"Lucario95","timestamp":"1620998880.0","upvote_count":"42","content":"So the right answers should be gpu-cluster for test and AKS for production?","comments":[{"content":"Why would you need a GPU cluster for testing? Isn't testing just comparing predictions with actual labels?","comment_id":"594365","poster":"Marnil","comments":[{"content":"Nvm, you need cluster (or aks) for gpu support. \nhttps://docs.microsoft.com/en-gb/azure/machine-learning/concept-compute-target\n\nHow come a third of answers on this site are incorrect, and that I cannot delete my own comments from discussions","comment_id":"594374","poster":"Marnil","timestamp":"1651226460.0","upvote_count":"7"}],"timestamp":"1651225800.0","upvote_count":"1"}]},{"comments":[{"comments":[{"comment_id":"347503","content":"Agree. Answer is AKS for both.","timestamp":"1619942400.0","poster":"ACSC","upvote_count":"2","comments":[{"poster":"SaudMeethal","timestamp":"1620547680.0","upvote_count":"4","content":"If security isn't required for testing, shouldn't the gpu-compute cluster do the job here? AKS should be used for production only.","comment_id":"352877"}]}],"comment_id":"339737","poster":"gamezone25","timestamp":"1618937580.0","upvote_count":"8","content":"I agree with the AKS cluster. The documentation says that AKS should be used for real-time inference, which is not supported by the GPU compute cluster.\nhttps://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target#deploy"},{"timestamp":"1619805480.0","poster":"dijaa","upvote_count":"1","content":"in which?","comment_id":"346358"},{"poster":"natrave","timestamp":"1619944380.0","upvote_count":"4","content":"I second this. It has to be AKS cluster as low latency and GPU are required in the question:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=azcli#choose-a-compute-target","comment_id":"347540"}],"comment_id":"339104","content":"Why not AKS cluster?","poster":"mtrdhar19841234","upvote_count":"15","timestamp":"1618859640.0"},{"upvote_count":"9","comments":[{"content":"THIS IS THE WAY!","comment_id":"1308882","timestamp":"1731089580.0","poster":"jl420","upvote_count":"2"}],"comment_id":"1110770","content":"Correct answers: \n- Test: ds-workstation notebook VM\n- Production: AKS-compute cluster\n\nTest: ds-workstation notebook VM\nSince the requirement for the testing environment is that it must not require an authenticated connection, then none of the cluster options (CPU, AKS, GPU) would be fit for use as a Testing resource. This is because these online cluster resources do not recommend and highly discourage to have unauthenticated connection due to obvious security concerns. DSVM offers an isolated or controlled environment, where unauthenticated access is temporarily allowed, but this would be an exception rather than the norm.\n\nProduction: AKS-compute cluster\nThe AKS (Azure Kubernetes Service) cluster is better for both (1) low latency and (2) scalability, unlike GPU cluster which is designed for low latency not for scalability, which is a requirement for the PROD env.","poster":"Lion007","timestamp":"1704048180.0"},{"comment_id":"1091672","timestamp":"1702113600.0","poster":"InversaRadice","content":"Another misleading question: there is no clue about cost requirements, which will lead to the proper answer...","upvote_count":"1"},{"comment_id":"1010867","timestamp":"1695071940.0","poster":"A_PL300","upvote_count":"4","content":"Question like this one on 4-Sept-2023 exam"},{"comment_id":"964068","content":"Test:\nA) ds-workstation notebook VM\n\nFor testing purposes, using a data science workstation notebook VM would be ideal. Since you're only testing the API responses and not focusing on large scale inferencing, a fully provisioned cluster would not be necessary.\n\nProduction:\nf) aks-compute cluster\n\nAzure Kubernetes Service (AKS) cluster is best suited for production deployment of your machine learning model. AKS offers capabilities like auto-scaling and load balancing, ensuring that your model can handle a large number of requests and perform with low latency during inferencing. It is also not necessary for the compute resource to have a GPU for inferencing, making the AKS cluster a cost-effective option.","upvote_count":"5","poster":"phdykd","timestamp":"1690394040.0"},{"timestamp":"1679933100.0","comment_id":"852247","content":"I would go for a cpu-compute cluster for testing","upvote_count":"1","poster":"sap_dg"},{"poster":"phdykd","content":"CB. \nExplanation:\nFor testing, a CPU-based compute cluster should be sufficient since the primary requirement is to verify that the web service returns predictions in the expected JSON format. A CPU-based compute cluster is relatively cheaper and can handle moderate to low traffic during testing.\n\nFor production, an AKS (Azure Kubernetes Service) cluster is recommended as it offers scalable and efficient orchestration of containers for high traffic applications. Since the mobile app is expected to receive multiple requests from end users, a scalable and reliable production environment is required. The AKS cluster provides an authenticated connection, and Kubernetes can scale the deployed model horizontally to handle a large number of requests.\n\nNote that GPU-based compute clusters may offer faster inferencing performance but are relatively expensive and may not be necessary for this specific project's requirements. Additionally, the deployment of GPU-based clusters may require additional configuration and setup, which may not be practical for testing and production.","timestamp":"1677081120.0","comment_id":"818002","upvote_count":"2"},{"content":"Box1: I think the answer is here: \"When using the Azure Machine Learning SDK v2 on a compute instance or on an Azure Virtual Machine, you can use a managed identity for Azure. This workflow allows the VM to connect to the workspace using the managed identity, without storing credentials in Python code or prompting the user to authenticate. Azure Machine Learning compute clusters can also be configured to use a managed identity to access the workspace when training models.\"\nSo VM sounds good, as we are talking about testing mode on an inference process\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-setup-authentication?tabs=sdk\n\nBox2: AKS. Definitely the best solution when dealing with low latency and scaling needs on inference process\n\nhttps://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target","timestamp":"1662550560.0","poster":"giusecozza","upvote_count":"8","comment_id":"662417"},{"upvote_count":"4","content":"PROD is AKS for sure, test 3 options \n-- local\n-- contain instance\n-- aks\nit does not required authentication, I will vote for local machine","comment_id":"613362","poster":"ning","timestamp":"1654703520.0"},{"timestamp":"1646716860.0","comment_id":"563034","upvote_count":"3","poster":"TheYazan","content":"\"Although compute targets like local, and Azure Machine Learning compute clusters support GPU for training and experimentation, using GPU for inference when deployed as a web service is supported only on AKS.\"\n\nhttps://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target#deploy"},{"poster":"AjoseO","timestamp":"1646285760.0","upvote_count":"3","content":"On 03 March 2022","comment_id":"559822"},{"comments":[{"comment_id":"555734","content":"I agree","poster":"Nand4","upvote_count":"1","timestamp":"1645759560.0"}],"comment_id":"502934","timestamp":"1639660440.0","poster":"Maskit12","upvote_count":"12","content":"Train: GPU, test: DS, Production: AKS"},{"content":"Azure compute cluster is not supporting real-time inference, only batch inference\nI think workstation notebook vm works with the question request\n\nhttps://docs.microsoft.com/en-gb/azure/machine-learning/concept-compute-target\n\nhttps://docs.microsoft.com/en-gb/azure/machine-learning/how-to-deploy-local-container-notebook-vm","timestamp":"1638959820.0","comment_id":"496730","poster":"dija123","upvote_count":"1"},{"poster":"ML_Novice","content":"what is the final good answer please?","upvote_count":"1","comment_id":"480828","timestamp":"1637250660.0"},{"comment_id":"466025","upvote_count":"1","content":"So the correct answers are AKS for both?","poster":"shiyu","timestamp":"1634885640.0"},{"timestamp":"1630647420.0","upvote_count":"2","comment_id":"438310","content":"on 2/9/21","poster":"snsnsnsn"},{"comment_id":"415968","upvote_count":"2","poster":"VJPrakash","content":"I think answer for second should be AKS based on the documentation","timestamp":"1627451760.0"},{"upvote_count":"2","comment_id":"394256","poster":"LPreethi","timestamp":"1625007540.0","content":"May I know the correct answer?"},{"upvote_count":"1","timestamp":"1624801560.0","content":"what is the answer for testing (CPU, GPU or AKS) and why?","comment_id":"392100","poster":"SajjR"},{"upvote_count":"7","comment_id":"391077","content":"agree on second answer \n\nThe answer should be DS note book VM and AKS cluster\nhttps://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target#deploy\n\nNote : Although compute targets like local, and Azure Machine Learning compute clusters support GPU for training and experimentation, using GPU for inference when deployed as a web service is supported only on AKS.","timestamp":"1624699140.0","poster":"SnowCheetah"},{"timestamp":"1623062160.0","comment_id":"376693","poster":"rishi_ram","content":"Question was there in June 2021 Exam","upvote_count":"6"},{"timestamp":"1622464320.0","comment_id":"371014","content":"what is the answer for test without authentication?","comments":[{"timestamp":"1630220160.0","content":"vm. you do not need to authenticate when running on vm.","comment_id":"434351","poster":"human_ai","upvote_count":"2"}],"poster":"novice16","upvote_count":"2"},{"content":"Low latency doesn't mean real-time inferencing, and it needs scalability and capacity to handle large number of requests, so choose gpu-compute cluster. The answer is correct.","comment_id":"347002","upvote_count":"2","poster":"iuolu","comments":[{"upvote_count":"5","content":"But it doesn't mean batch inferencing either !! The compute cluster description reads \n\"Run batch scoring on serverless compute. Supports normal and low-priority VMs. No support for real-time inference.\" I think the correct answer is AKS since that is the only recommended solution for a scalable production deployment.","poster":"chaudha4","comment_id":"349466","timestamp":"1620135300.0"}],"timestamp":"1619875140.0"}],"isMC":false,"answer_ET":"","topic":"4","answers_community":[],"timestamp":"2021-04-19 21:14:00","answer":"","question_text":"HOTSPOT -\nYou are a lead data scientist for a project that tracks the health and migration of birds. You create a multi-image classification deep learning model that uses a set of labeled bird photos collected by experts. You plan to use the model to develop a cross-platform mobile app that predicts the species of bird captured by app users.\nYou must test and deploy the trained model as a web service. The deployed model must meet the following requirements:\n✑ An authenticated connection must not be required for testing.\n✑ The deployed model must perform with low latency during inferencing.\n✑ The REST endpoints must be scalable and should have a capacity to handle large number of requests when multiple end users are using the mobile application.\nYou need to verify that the web service returns predictions in the expected JSON format when a valid REST request is submitted.\nWhich compute resources should you use? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","exam_id":64,"answer_description":"","answer_images":["https://img.examtopics.com/dp-100/image617.png"],"question_images":["https://www.examtopics.com/assets/media/exam-media/04274/0037200001.png"]},{"id":"w7wXFf9RB2Y3DFacb5iC","question_id":367,"answers_community":["B (63%)","D (38%)"],"url":"https://www.examtopics.com/discussions/microsoft/view/47169-exam-dp-100-topic-4-question-10-discussion/","answer_description":"","discussion":[{"timestamp":"1729745940.0","content":"I also thought it was D, but it is B for real time and endpoint","comment_id":"1302305","poster":"jefimija","upvote_count":"1"},{"poster":"james2033","timestamp":"1697097840.0","comment_id":"1041525","upvote_count":"1","content":"Selected Answer: B\nQuestion keyword 'it is important to be able to monitor \n\n- the data submitted to the web service and \n\n- the predictions the data generates'\n\nNew GUI is item 'Application Insights diagnostics' with toggle button 'Enabled'. You can practise with sample model Sample PyTorch model https://www.kaggle.com/code/xiedaicheng/download-pytorch-model/output\n , upload, then create new deployment, then see this option at step 2."},{"timestamp":"1677091620.0","comment_id":"818245","content":"B. To implement a monitoring solution for the deployed model that supports a business-critical application and requires minimal administrative effort, the best option is to enable Azure Application Insights for the service endpoint and view logged data in the Azure portal.\n\nOption B, to enable Azure Application Insights for the deployed model, provides a scalable and cost-effective way to monitor the data submitted to the web service and the predictions generated by the data. Azure Application Insights can be easily integrated into Azure Machine Learning and provides powerful analytics tools for tracking and analyzing usage, performance, and errors in real-time. With Azure Application Insights, you can quickly identify and troubleshoot issues, and you can set up alerts to notify you when specific events occur. ACD do not provide real-time monitoring capabilities for the deployed model.","poster":"phdykd","upvote_count":"2"},{"content":"Selected Answer: D\nI don't think this can be B because App Insights will now show prediction information, only utilization/traffic etc.\n\nThe answer has to be D. Review https://learn.microsoft.com/en-us/azure/machine-learning/v1/how-to-use-mlflow?tabs=azuremlsdk#track-runs-running-on-azure-machine-learning","upvote_count":"3","poster":"BTAB","comment_id":"773985","timestamp":"1673573100.0"},{"upvote_count":"4","poster":"synapse","comment_id":"566468","timestamp":"1647135900.0","content":"Selected Answer: B\nB is the correct answer. Only App Insights can be used here. The question does not talk about MlfLow model. So D is not in question."},{"poster":"[Removed]","comment_id":"552121","upvote_count":"1","content":"On 20Feb2022","timestamp":"1645381320.0"},{"timestamp":"1643101140.0","comment_id":"531987","poster":"ranjsi01","upvote_count":"2","content":"D is correct. B provides mostly telemetry data about the service itself."},{"upvote_count":"2","content":"I think both B and D could work but B is easier to setup","poster":"BleadFast","timestamp":"1615810440.0","comments":[{"upvote_count":"1","comment_id":"435020","timestamp":"1630294320.0","poster":"dushmantha","content":"I guess minimum administrative effort means that..."}],"comment_id":"311383"}],"isMC":true,"choices":{"D":"Create an ML Flow tracking URI that references the endpoint, and view the data logged by ML Flow.","A":"View the explanations for the registered model in Azure ML studio.","C":"View the log files generated by the experiment used to train the model.","B":"Enable Azure Application Insights for the service endpoint and view logged data in the Azure portal."},"question_text":"You deploy a real-time inference service for a trained model.\nThe deployed model supports a business-critical application, and it is important to be able to monitor the data submitted to the web service and the predictions the data generates.\nYou need to implement a monitoring solution for the deployed model using minimal administrative effort.\nWhat should you do?","timestamp":"2021-03-15 13:14:00","answer":"B","answer_images":[],"exam_id":64,"topic":"4","answer_ET":"B","unix_timestamp":1615810440,"question_images":[]},{"id":"7BgRODNnpFvYWyAfUgtI","answer_ET":"","topic":"4","answer_images":["https://www.examtopics.com/assets/media/exam-media/04274/0038600001.png"],"url":"https://www.examtopics.com/discussions/microsoft/view/54940-exam-dp-100-topic-4-question-11-discussion/","unix_timestamp":1623211980,"isMC":false,"timestamp":"2021-06-09 06:13:00","exam_id":64,"answer_description":"Box 1: AksCompute -\nExample:\naks_target = AksCompute(ws,\"myaks\")\n# If deploying to a cluster configured for dev/test, ensure that it was created with enough\n# cores and memory to handle this deployment configuration. Note that memory is also used by\n# things such as dependencies and AML components.\ndeployment_config = AksWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1) service = Model.deploy(ws, \"myservice\", [model], inference_config, deployment_config, aks_target)\n\nBox 2: AksWebservice -\n\nBox 3: token_auth_enabled=Yes -\nWhether or not token auth is enabled for the Webservice.\nNote: A Service principal defined in Azure Active Directory (Azure AD) can act as a principal on which authentication and authorization policies can be enforced in\nAzure Databricks.\nThe Azure Active Directory Authentication Library (ADAL) can be used to programmatically get an Azure AD access token for a user.\nIncorrect Answers:\nauth_enabled (bool): Whether or not to enable key auth for this Webservice. Defaults to True.\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-azure-kubernetes-service https://docs.microsoft.com/en-us/azure/databricks/dev-tools/api/latest/aad/service-prin-aad-token","question_text":"HOTSPOT -\nYou use Azure Machine Learning to train and register a model.\nYou must deploy the model into production as a real-time web service to an inference cluster named service-compute that the IT department has created in the\nAzure Machine Learning workspace.\nClient applications consuming the deployed web service must be authenticated based on their Azure Active Directory service principal.\nYou need to write a script that uses the Azure Machine Learning SDK to deploy the model. The necessary modules have been imported.\nHow should you complete the code? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","discussion":[{"comment_id":"403948","upvote_count":"11","timestamp":"1641910680.0","poster":"ljljljlj","content":"On exam 2021/7/10"},{"content":"given answer is correct\n\ntoken_auth_enabled\nbool\ndefault value: None\nWhether or not to enable Token auth for this Webservice. If this is enabled, users can access this Webservice by fetching an access token using their Azure Active Directory credentials. Defaults to False.\nhttps://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.webservice.akswebservice?view=azure-ml-py\nService principal: You create a service principal account in Azure Active Directory, and use it to authenticate or get a token. A service principal is used when you need an automated process to authenticate to the service without requiring user interaction. For example, a continuous integration and deployment script that trains and tests a model every time the training code changes.\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-setup-authentication","comment_id":"390485","upvote_count":"10","timestamp":"1640444160.0","poster":"azurecert2021"},{"timestamp":"1733660880.0","content":"amlcompute=>training\nAkscompute=>real time computing and scalable\nbatchcompute=>non real time","upvote_count":"1","comment_id":"1226676","poster":"evangelist"},{"upvote_count":"1","content":"Constructor azureml.core.compute.aks.AksCompute(workspace, name) \n\nhttps://learn.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.aks.akscompute?view=azure-ml-py#constructor\n\nazureml.core.webservice.aks.AksWebservice.deploy_configuration(...)\n\nhttps://learn.microsoft.com/en-us/python/api/azureml-core/azureml.core.webservice.aks.akswebservice?view=azure-ml-py#azureml-core-webservice-aks-akswebservice-deploy-configuration","comment_id":"1048377","poster":"james2033","timestamp":"1713588840.0"},{"content":"Given answer is correct. The third one might be confusing for some people but here is what Microsoft documentation says:\ntoken_auth_enabled: Whether or not to enable Token auth for this Webservice. If this is enabled, users can access this Webservice by fetching an access token using their Azure Active Directory credentials. Defaults to False.","upvote_count":"6","comment_id":"584380","poster":"pancman","timestamp":"1665514620.0"},{"poster":"kkkk_jjjj","comment_id":"570393","upvote_count":"3","content":"on exam 18/03/2022","timestamp":"1663483620.0"},{"upvote_count":"1","timestamp":"1662180900.0","poster":"AjoseO","comment_id":"559868","content":"On Exam: 03 March 2022"},{"upvote_count":"1","comment_id":"552122","timestamp":"1661012580.0","content":"On 20Feb2022","poster":"[Removed]"},{"upvote_count":"2","poster":"Tsardoz","content":"cpu_cores = 1, memory_gb=1 does not sound like AKS to me","timestamp":"1657872180.0","comment_id":"524066"},{"timestamp":"1651951380.0","upvote_count":"2","content":"on exam 05Nov 2021","poster":"AI247","comment_id":"474050"},{"poster":"JoshuaXu","comment_id":"473654","upvote_count":"2","timestamp":"1651867620.0","content":"on 6 Nov 2021"},{"content":"on 19Oct2021","poster":"hargur","comment_id":"465017","upvote_count":"1","timestamp":"1650441180.0"},{"upvote_count":"2","comment_id":"438312","timestamp":"1646293020.0","content":"on 2/9/21","poster":"snsnsnsn"},{"timestamp":"1639030380.0","comment_id":"377965","content":"Answer is correct!","poster":"SaulG","upvote_count":"5"}],"question_id":368,"question_images":["https://www.examtopics.com/assets/media/exam-media/04274/0038500001.png"],"answer":"","answers_community":[]},{"id":"AOA1AWSAsUhG9wAfiGWK","question_id":369,"topic":"4","answer_images":[],"exam_id":64,"question_text":"An organization creates and deploys a multi-class image classification deep learning model that uses a set of labeled photographs.\nThe software engineering team reports there is a heavy inferencing load for the prediction web services during the summer. The production web service for the model fails to meet demand despite having a fully-utilized compute cluster where the web service is deployed.\nYou need to improve performance of the image classification web service with minimal downtime and minimal administrative effort.\nWhat should you advise the IT Operations team to do?","answer":"B","choices":{"C":"Increase the minimum node count of the compute cluster where the web service is deployed.","D":"Increase the VM size of nodes in the compute cluster where the web service is deployed.","A":"Create a new compute cluster by using larger VM sizes for the nodes, redeploy the web service to that cluster, and update the DNS registration for the service endpoint to point to the new cluster.","B":"Increase the node count of the compute cluster where the web service is deployed."},"unix_timestamp":1624402800,"discussion":[{"content":"looks correct","comment_id":"388357","poster":"santoshpandit","timestamp":"1640221200.0","upvote_count":"10"},{"comment_id":"1226680","upvote_count":"1","poster":"evangelist","timestamp":"1733661120.0","content":"Selected Answer: B\nanything that touches VM specs caused downtime, only increasing node count does not cause downtime. B is correct"},{"timestamp":"1713589500.0","content":"Selected Answer: C\n'Increase the minimum node count of the compute cluster' . I choose C.","comments":[{"timestamp":"1732617120.0","upvote_count":"1","comment_id":"1218841","content":"The answer is incorrect because the heavy inferencing occurs only during the summer. The problem remains since we haven't upgraded the cluster's capabilities, leading to higher costs outside of summer due to always active nodes, even with no inferencing requests.","poster":"ahmednani015"}],"comment_id":"1048384","upvote_count":"1","poster":"james2033"},{"upvote_count":"2","timestamp":"1685171160.0","content":"Selected Answer: B\nIncreasing the node count has the least administrative effort compared to option A which describes a heavier solution.","comment_id":"728072","poster":"michaelmorar"},{"poster":"tchip","timestamp":"1661378340.0","content":"this is correct as it requires lesser downtime and minimal administrative effort","comment_id":"555653","upvote_count":"1"},{"upvote_count":"3","comment_id":"552123","poster":"[Removed]","timestamp":"1661012580.0","content":"On 20Feb2022"},{"timestamp":"1660963980.0","content":"correct","comment_id":"551531","upvote_count":"1","poster":"tchip"},{"timestamp":"1650040380.0","comment_id":"462703","poster":"nick234987","upvote_count":"1","content":"It is correct"}],"answers_community":["B (75%)","C (25%)"],"timestamp":"2021-06-23 01:00:00","answer_ET":"B","isMC":true,"url":"https://www.examtopics.com/discussions/microsoft/view/55870-exam-dp-100-topic-4-question-12-discussion/","answer_description":"","question_images":[]},{"id":"hMKoJHxqb08WWr5P2HQG","unix_timestamp":1613001960,"answers_community":["B (100%)"],"url":"https://www.examtopics.com/discussions/microsoft/view/44452-exam-dp-100-topic-4-question-13-discussion/","exam_id":64,"answer_images":[],"question_images":[],"isMC":true,"question_id":370,"answer_ET":"B","choices":{"B":"Azure Kubernetes Services","C":"HDInsight","E":"Azure Databricks","A":"a new Machine Learning Compute resource","D":"the existing Machine Learning Compute resource"},"answer":"B","discussion":[{"content":"On exam 2021/7/10","poster":"ljljljlj","timestamp":"1657541880.0","upvote_count":"7","comment_id":"403949"},{"timestamp":"1729400820.0","content":"Selected Answer: B\nB, for deployment phase, AKS. Not powerful computer for training model.","comment_id":"1048387","upvote_count":"1","poster":"james2033"},{"content":"D. the existing Machine Learning Compute resource\n\nSince you already have a single Azure Machine Learning service compute resource, it is recommended to use it to publish the inference pipeline as a web service. This will help you to minimize the cost and simplify the deployment process.","poster":"phdykd","upvote_count":"2","timestamp":"1708631640.0","comment_id":"818338"},{"poster":"michaelmorar","content":"Selected Answer: B\nAKS always the solution for these types of problems.","comment_id":"741924","upvote_count":"3","timestamp":"1702314960.0"},{"timestamp":"1676917380.0","content":"On 20Feb2022","poster":"[Removed]","upvote_count":"1","comment_id":"552124"},{"comment_id":"386797","timestamp":"1655789580.0","content":"The answer is correct: Azure Kubernetes Service (AKS) is used for Real-time inference.","poster":"andre999","upvote_count":"4"},{"timestamp":"1652700360.0","poster":"Lucario95","comment_id":"358629","content":"Doesn't the question refer to which compute to use to deploy the pipeline, thus answer D being correct?","comments":[{"timestamp":"1659335160.0","content":"It says you need to publish the model, thus Aks","comment_id":"418144","poster":"azure1000","upvote_count":"2"}],"upvote_count":"1"},{"upvote_count":"1","timestamp":"1644537960.0","comment_id":"287934","poster":"ZeeshanNawaz","comments":[{"content":"As per https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target only AKS can be used for real-time interference","comment_id":"299263","poster":"Zwi3b3l","timestamp":"1645810800.0","upvote_count":"6"}],"content":"Why the existing compute can't be used?"}],"answer_description":"","question_text":"You use Azure Machine Learning designer to create a real-time service endpoint. You have a single Azure Machine Learning service compute resource.\nYou train the model and prepare the real-time pipeline for deployment.\nYou need to publish the inference pipeline as a web service.\nWhich compute type should you use?","timestamp":"2021-02-11 01:06:00","topic":"4"}],"exam":{"provider":"Microsoft","numberOfQuestions":512,"isBeta":false,"isImplemented":true,"name":"DP-100","lastUpdated":"12 Apr 2025","id":64,"isMCOnly":false},"currentPage":74},"__N_SSP":true}