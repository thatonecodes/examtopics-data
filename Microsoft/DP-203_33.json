{"pageProps":{"questions":[{"id":"H8YplUqCIlmuYrb48ruN","answer":"","answer_description":"","question_images":["https://img.examtopics.com/dp-203/image401.png","https://img.examtopics.com/dp-203/image402.png"],"exam_id":67,"answer_ET":"","timestamp":"2025-01-15 03:38:00","unix_timestamp":1736908680,"isMC":false,"url":"https://www.examtopics.com/discussions/microsoft/view/154523-exam-dp-203-topic-2-question-137-discussion/","answer_images":["https://img.examtopics.com/dp-203/image403.png"],"question_text":"DRAG DROP\n-\n\nYou have an Azure subscription that contains an Azure Data Factory account named ADF1 and an Azure Data Lake Storage Gen2 account named storage1. ADF1 contains the objects shown in the following table.\n\n//IMG//\n\n\nYou need to configure DailyIngestion to perform the following actions:\n\n• Ingest 2,000 small files into storage1 once every 24 hours.\n• Output one large file once every 24 hours.\n\nWhich three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\n\n//IMG//","discussion":[{"timestamp":"1736908680.0","content":"Add a Copy data activity:\nThis is required to copy the data from the source files (2,000 small files) to the target (1 large file). It’s the primary activity for this task.\nConfigure datasets and parameters:\nThe SourceFiles dataset must point to the 2,000 small files, and the TargetFile dataset must point to the location for the large file. Dynamic parameters ensure scalability and reusability.\nConfigure Copy behavior:\nThe Copy behavior setting in the Copy Data activity allows you to specify how files are handled. In this case, choose \"Merge files\" to combine all small files into one large file.","comment_id":"1340625","upvote_count":"7","poster":"a6cb3b0"},{"content":"Configure datasets and parameters, Configure Copy behavior, Add a Copy data activity","timestamp":"1741470840.0","poster":"9370d83","comment_id":"1366700","upvote_count":"1"},{"poster":"Pey1nkh","timestamp":"1740573840.0","content":"Configure the datasets and parameters for SourceFile and TargetFile.\nAdd a Copy Data activity.\nConfigure the Copy behavior setting.","upvote_count":"1","comment_id":"1361915"}],"topic":"2","answers_community":[],"question_id":161},{"id":"6I46g0EcPs1BkhropiWx","answer":"","question_id":162,"question_text":"HOTSPOT\n-\n\nYou have an Azure Synapse Analytics pipeline named pipeline1 that has concurrency set to 1.\n\nTo run pipeline1, you create a new trigger as shown in the following exhibit.\n\n//IMG//\n\n\nUse the drop-down menus to select the answer choice that completes each statement based on the information presented in the graphic.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","answer_ET":"","answer_description":"","isMC":false,"exam_id":67,"timestamp":"2025-01-16 14:25:00","topic":"2","answers_community":[],"answer_images":["https://img.examtopics.com/dp-203/image406.png"],"question_images":["https://img.examtopics.com/dp-203/image404.png","https://img.examtopics.com/dp-203/image405.png"],"discussion":[{"content":"12.30 pm , Multiple instances of the same pipeline can run if concurrency is not set to 1","poster":"9370d83","upvote_count":"1","timestamp":"1741471860.0","comment_id":"1366704"},{"upvote_count":"1","comment_id":"1364980","timestamp":"1741103820.0","content":"why 12:30PM because the start date is 9:59PM so the first one will be 12:30AM?","poster":"ferentuske"},{"content":"12:30 PM / its gonna be Queued (if concurrency = 1) !","poster":"Pey1nkh","timestamp":"1740572280.0","comment_id":"1361893","upvote_count":"2"},{"comment_id":"1341709","content":"It should be \"12:30 PM\" and \"be Skipped\".","timestamp":"1737033900.0","poster":"arunyadav09","upvote_count":"4"}],"url":"https://www.examtopics.com/discussions/microsoft/view/154686-exam-dp-203-topic-2-question-138-discussion/","unix_timestamp":1737033900},{"id":"IxctTeDqDpn8II5CNHB0","answer_ET":"","answer":"","answers_community":[],"answer_description":"Range Left or Right, both are creating similar partition but there is difference in comparison\nFor example: in this scenario, when you use LEFT and 20100101,20110101,20120101\nPartition will be, datecol<=20100101, datecol>20100101 and datecol<=20110101, datecol>20110101 and datecol<=20120101, datecol>20120101\nBut if you use range RIGHT and 20100101,20110101,20120101\nPartition will be, datecol<20100101, datecol>=20100101 and datecol<20110101, datecol>=20110101 and datecol<20120101, datecol>=20120101\nIn this example, Range RIGHT will be suitable for calendar comparison Jan 1st to Dec 31st\nReference:\nhttps://docs.microsoft.com/en-us/sql/t-sql/statements/create-partition-function-transact-sql?view=sql-server-ver15","question_id":163,"discussion":[{"timestamp":"1639965900.0","poster":"Canary_2021","content":"Answer is correct.\nhttps://docs.microsoft.com/en-us/sql/t-sql/statements/create-partition-function-transact-sql?view=sql-server-ver15","comment_id":"505182","upvote_count":"27"},{"timestamp":"1639288620.0","upvote_count":"18","comment_id":"499810","poster":"victor90","comments":[{"upvote_count":"30","timestamp":"1639617600.0","poster":"TestMitch","comment_id":"502551","content":"No! That's wrong! Number of partitions created = Number of partition boundaries specified + 1."},{"poster":"onyerleft","content":"Choosing box 2 with range right would create five partitions. The first partition would be <20090101. So the provided answer is correct","comments":[{"upvote_count":"1","poster":"rlnd2000","content":"Incorrect you read the requirement: -Ensure that each partition contains all the orders placed during a given calendar year.- now as you said [time<2009-01-01] goes to the first partition and for sure in the second partition we will have only 2009","timestamp":"1722000960.0","comment_id":"1255737"}],"comment_id":"504478","upvote_count":"6","timestamp":"1639863780.0"}],"content":"I think the box 2 should be 20090101,2010101,20110101,20120101 since the question asked about 4 partitions. \nhttps://docs.microsoft.com/en-us/sql/t-sql/statements/create-partition-function-transact-sql?view=sql-server-ver15#c-creating-a-range-right-partition-function-on-a-datetime-column"},{"poster":"rlnd2000","timestamp":"1722000720.0","upvote_count":"2","comment_id":"1255734","content":"The given answer does not fully meet the requirement:\n\n\"\"Ensure\"\" that each partition contains all the orders placed during a given calendar year.\n\nUsing the values 2010101, 20110101, 20120101 means that all dates before 2010101 will go to the first partition. If, by any chance, a new date from the year 2008 is inserted into the table, it will go to the first partition together with 2009. Therefore, I believe 20090101, 2010101, 20110101, 20120101 is a better answer."},{"timestamp":"1712858100.0","poster":"Bakhtiyor","content":"RIGHT - [time<2010-01-01] [2010-01-01<=time<2011-01-01] [2011-01-01<=time<2012-01-01] [time<=2012-01-01]\nLEFT - [time<=2010-01-01] [2010-01-01<time<=2011-01-01] [2011-01-01<time<=2012-01-01] [time<2012-01-01]","comment_id":"1193951","upvote_count":"2"},{"content":"I stand with the chosen answer.\nFor me it is 100% correct \nIf you chose LEFT partition with 20090101,2010101,20110101,\nthen be aware that the fourth partition will not include 1st January 2012 which means the partition doesn't actually supports all the 12 calendar months is a particular year.","timestamp":"1707605160.0","poster":"moneytime","comment_id":"1146868","upvote_count":"1"},{"timestamp":"1693915740.0","content":"RIGHT :\nt<20100101, 20100101<=t<20110101, 20110101<=t<20120101\n20120101<=t\nLEFT\nt<=20100101, 20100101<t<=20110101,20110101<t<=20120101,\nt>20120101","comment_id":"999469","upvote_count":"2","poster":"kkk5566"},{"poster":"Maddhy","content":"Answer is \n1.right\n2. Last option becoz there they mentioned 4 partitions ( I'm sure that it is guarenteed)","comments":[{"content":"The reason we are using right that is here the values are not null","timestamp":"1669219260.0","poster":"Maddhy","upvote_count":"1","comment_id":"725246"}],"upvote_count":"4","timestamp":"1669218780.0","comment_id":"725242"},{"content":"IF use [RIGHT], it means : [time<20100101], [20100101<=time<20110101] and so on\nIF use [LEFT], it means: [time<=20100101], [20100101<time <= 20110101] and so on\nSee if you choose [LEFT] then will NOT include the 0101 value of current calendar year into the query, so GO with [RIGHT]","poster":"rzeng","timestamp":"1667019540.0","upvote_count":"9","comment_id":"706975"},{"comment_id":"639915","content":"Answer is correct.. given1st boundary value will be included in the 2nd partition (since right) so 1st partition will end at 20091231 and 2nd will start at 20100101 and end at 20101231 and so on..","timestamp":"1659244680.0","poster":"Deeksha1234","upvote_count":"2"},{"content":"Answer is correct","poster":"Deeksha1234","comment_id":"639762","timestamp":"1659201600.0","upvote_count":"1"},{"comment_id":"628876","poster":"dsp17","timestamp":"1657305420.0","upvote_count":"2","content":"How to remember LEFT / RIGHT concept, it's confusing, pls help","comments":[{"upvote_count":"7","comment_id":"652177","poster":"monibun","content":"I do that by initials of L(eft) means starting as \"Less than equal to first boundary value, there onwards greater than \" and for right, other way around.","timestamp":"1661507940.0"}]},{"poster":"PallaviPatel","content":"correct Answer.","upvote_count":"1","comment_id":"535481","timestamp":"1643463120.0"},{"comment_id":"527222","timestamp":"1642565700.0","poster":"dev2dev","upvote_count":"4","comments":[{"poster":"allagowf","comment_id":"684097","content":"the answer is correct, check the requirements:\n✑ Create four partitions based on the order date.\n✑ Ensure that each partition contains all the orders placed during a given calendar year.\nboth right an d left results in 4 partitions, but left will have mixed values from 2 years, check the clarification in the answer.\nso right will result in 4 partions each partition contains all the orders placed during a given calendar year.","upvote_count":"3","timestamp":"1664614920.0"}],"content":"where does 2009 year stored? i think the 1st choice should be LEFT so th"},{"timestamp":"1641216900.0","comment_id":"515786","poster":"VeroDon","content":"correct","upvote_count":"2"},{"timestamp":"1639094160.0","comment_id":"498129","content":"Respuesta correcta. RIGTH, [3 VALORES].","poster":"alexleonvalencia","upvote_count":"2"}],"question_images":["https://www.examtopics.com/assets/media/exam-media/04259/0017500001.jpg"],"unix_timestamp":1639094160,"answer_images":["https://www.examtopics.com/assets/media/exam-media/04259/0017600001.jpg"],"topic":"2","url":"https://www.examtopics.com/discussions/microsoft/view/67477-exam-dp-203-topic-2-question-14-discussion/","timestamp":"2021-12-10 00:56:00","question_text":"HOTSPOT -\nYou have an enterprise data warehouse in Azure Synapse Analytics that contains a table named FactOnlineSales. The table contains data from the start of 2009 to the end of 2012.\nYou need to improve the performance of queries against FactOnlineSales by using table partitions. The solution must meet the following requirements:\n✑ Create four partitions based on the order date.\n✑ Ensure that each partition contains all the orders placed during a given calendar year.\nHow should you complete the T-SQL command? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","isMC":false,"exam_id":67},{"id":"db3tVjLakagk6KUZN6Yz","isMC":false,"exam_id":67,"unix_timestamp":1738126800,"question_id":164,"answer_images":["https://img.examtopics.com/dp-203/image412.png"],"answer_description":"","question_text":"HOTSPOT\n-\n\nYou have an Azure Data Factory pipeline that has the logic flow shown in the following exhibit.\n\n//IMG//\n\n\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","answer_ET":"","timestamp":"2025-01-29 06:00:00","topic":"2","question_images":["https://img.examtopics.com/dp-203/image410.png","https://img.examtopics.com/dp-203/image411.png"],"url":"https://www.examtopics.com/discussions/microsoft/view/155632-exam-dp-203-topic-2-question-140-discussion/","answer":"","answers_community":[],"discussion":[{"content":"Skipped dependency -- Success for 3rd question","poster":"9370d83","comment_id":"1395735","timestamp":"1741994760.0","upvote_count":"2"},{"poster":"9370d83","timestamp":"1741472760.0","content":"Activity 4 is skipped activity on success path..therefore pipeline will return success","comment_id":"1366706","upvote_count":"2"},{"content":"the given answer is correct","timestamp":"1740570780.0","comment_id":"1361883","poster":"Pey1nkh","upvote_count":"3"},{"poster":"formacionkiteris","timestamp":"1738126800.0","upvote_count":"3","content":"I woul'd say the correct answer is:\nNo\nNo\nYes","comment_id":"1348381"}]},{"id":"gOOyew5mkpsq34a1JV4t","answers_community":[],"timestamp":"2025-01-25 02:09:00","isMC":false,"question_images":["https://img.examtopics.com/dp-203/image416.png"],"exam_id":67,"url":"https://www.examtopics.com/discussions/microsoft/view/155357-exam-dp-203-topic-2-question-142-discussion/","unix_timestamp":1737767340,"question_text":"DRAG DROP\n-\n\nYou have an Azure subscription that contains an Azure Synapse Analytics workspace named Workspace1. Workspace1 contains an Apache Spark pool named spark1 and a pipeline named Pipeline1.\n\nYou need to add an activity to Pipeline1 that will run a notebook. The solution must ensure that the activity overrides the value of a variable named inputFile when the notebook runs.\n\nWhich five actions should you perform in sequence in Synapse Studio? To answer move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\n\n//IMG//","answer_description":"","answer":"","answer_ET":"","topic":"2","question_id":165,"answer_images":["https://img.examtopics.com/dp-203/image417.png"],"discussion":[{"timestamp":"1743317460.0","content":"order Ad, Se, Co, pub, DragSy","poster":"Sathya_sree","comment_id":"1411945","upvote_count":"1"},{"comments":[{"timestamp":"1737888540.0","poster":"sakis213","upvote_count":"2","comment_id":"1346882","content":"1.Add a new notebook that declares and initializes inputFile.\n2.Select Toggle parameter cell in the notebook.\n3.Publish the notebook.\n4.Drag a Notebook activity from the Synapse section into Pipeline1 and link the Notebook activity to spark1 5.configure the base parameter setting."}],"comment_id":"1346880","poster":"sakis213","content":"Add a new notebook that declares and initializes inputFile.\nSelect Toggle parameter cell in the notebook.\nPublish the notebook.\nDrag a Notebook activity from the Synapse section into Pipeline1.\nLink the Notebook activity to spark1 and configure the base parameter setting.","upvote_count":"3","timestamp":"1737888420.0"},{"comment_id":"1346274","timestamp":"1737767340.0","content":"Actions in Order:\nAdd a new notebook that declares and initializes inputFile.\nCreate a notebook in Synapse Studio that includes logic and initializes the inputFile variable.\nSelect Toggle parameter cell.\nMark inputFile as a parameter by toggling the parameter cell in the notebook. This step ensures the variable is configurable and can accept external input.\nPublish the notebook.\nSave and publish the notebook to make it available for execution in the pipeline.\nDrag an activity from the Synapse section to Pipeline1 and link the activity to spark1.\n\nAdd a Notebook activity from the Synapse section to the pipeline and configure it to use the published notebook. Link the activity to the spark1 Spark pool.\nConfigure the Base parameters settings.\nConfigure the Base parameters in the Notebook activity to override the value of the inputFile parameter at runtime.","poster":"a6cb3b0","upvote_count":"3"}]}],"exam":{"lastUpdated":"12 Apr 2025","isMCOnly":false,"id":67,"provider":"Microsoft","numberOfQuestions":384,"isBeta":false,"name":"DP-203","isImplemented":true},"currentPage":33},"__N_SSP":true}