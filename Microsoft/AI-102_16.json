{"pageProps":{"questions":[{"id":"9f1dU6JmdvlbRkAZfqb6","question_id":76,"unix_timestamp":1638063300,"answer_description":"","timestamp":"2021-11-28 02:35:00","exam_id":40,"answer_images":[],"choices":{"A":"Make API queries to the autocomplete endpoint and include suggesterName in the body.","D":"Add a suggester for each of the three product name fields.","C":"Make API queries to the search endpoint and include the product name fields in the searchFields query parameter.","E":"Set the searchAnalyzer property for the three product name variants.","F":"Set the analyzer property for the three product name variants.","B":"Add a suggester that has the three product name fields as source fields."},"question_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/66853-exam-ai-102-topic-13-question-1-discussion/","answer_ET":"ABF","isMC":true,"question_text":"You are developing the smart e-commerce project.\nYou need to implement autocompletion as part of the Cognitive Search solution.\nWhich three actions should you perform? Each correct answer presents part of the solution.\nNOTE: Each correct selection is worth one point.","discussion":[{"poster":"ziggy1117","timestamp":"1686458520.0","content":"Selected Answer: ABF\nLet us eliminate the wrong answers:\nC. Make API queries to the search endpoint and include the product name fields in the searchFields query parameter. - as we need autocomplete endpoint, we rule this one out as this is for a search endpoint\nD. Add a suggester for each of the three product name fields. - we cannot have 3 suggesters.\nE. Set the searchAnalyzer property for the three product name variants. - searchAnalyzer helps in search not in autocomplete.\n\nSo A, B, F","upvote_count":"16","comment_id":"920410"},{"comment_id":"561544","content":"A , B , F\n\nB. Add a suggester that has the three product name fields as source fields\nF. Set the analyzer property for the three product name variants.\nA. Make API queries to the autocomplete endpoint and include suggesterName in the body.\n\nhttps://docs.microsoft.com/en-us/azure/search/index-add-suggesters\nhttps://docs.microsoft.com/en-us/azure/search/search-add-autocomplete-suggestions","upvote_count":"11","poster":"reachmymind","timestamp":"1646500920.0"},{"poster":"syupwsh","content":"Selected Answer: ABF\nMake API queries to the autocomplete endpoint and include suggesterName in the body is CORRECT because it specifies which suggester to use for autocompletion. This is essential for retrieving relevant suggestions based on user input, making the autocomplete functionality effective.\n\nAdd a suggester that has the three product name fields as source fields is CORRECT because a suggester is needed to define the fields from which autocomplete suggestions will be generated. By including all relevant product name fields, the system can provide comprehensive suggestions that account for different ways products might be named or referred to.\n\nSet the analyzer property for the three product name variants is CORRECT because it ensures that the text is processed correctly, considering the specific language or custom processing required. This helps in generating accurate autocomplete suggestions by applying the correct text analysis to the product name fields.\n\nABF","timestamp":"1739442300.0","comment_id":"1356069","upvote_count":"1"},{"comment_id":"1230486","timestamp":"1718368080.0","upvote_count":"2","content":"Selected Answer: ABF\nABF is the correct answer.","poster":"nanaw770"},{"upvote_count":"1","content":"Is this question still available on May 21, 2024?","comment_id":"1214423","poster":"takaimomoGcup","timestamp":"1716215580.0"},{"poster":"evangelist","upvote_count":"1","content":"let me explain why C D E are incorrect:\n\nC. This action is more relevant to refining search results based on specific fields rather than implementing autocompletion. For autocompletion, the focus is on the autocomplete endpoint, not the search endpoint.\n\nD. - Typically, you would add a single suggester that includes multiple fields as source fields rather than creating a separate suggester for each field. Therefore, this action is not as efficient or necessary if you can accomplish your goal with one suggester that encompasses all relevant fields.\n\nE. Set the searchAnalyzer property for the three product name variants. - Setting the searchAnalyzer property is relevant for controlling how text is analyzed during search queries. it's not directly involved in setting up autocompletion.","timestamp":"1707534840.0","comment_id":"1145907"},{"upvote_count":"2","poster":"rdemontis","timestamp":"1699635480.0","content":"Selected Answer: ABF\nprovided answer and explanation are correct","comment_id":"1067395"},{"poster":"zellck","content":"Selected Answer: ABF\nABF is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/search/index-add-suggesters#use-a-suggester\nFirst, as with all queries, the operation is against the documents collection of an index and the query includes a \"search\" parameter, which in this case provides the partial query. Second, you must add \"suggesterName\" to the request. If a suggester isn't defined in the index, a call to autocomplete or suggestions will fail.\n\nhttps://learn.microsoft.com/en-us/azure/search/index-add-suggesters#choose-analyzers","timestamp":"1688474100.0","comment_id":"942756","upvote_count":"4"},{"poster":"KingChuang","timestamp":"1673931840.0","content":"on my exam. (2023-01-16 passed)\nMy Answer:ABF","comment_id":"778576","upvote_count":"6"},{"content":"Selected Answer: ABF\nA, B and F are correct answers.","upvote_count":"3","poster":"Eltooth","timestamp":"1658316060.0","comment_id":"634007"},{"timestamp":"1638063300.0","poster":"Ravnit","upvote_count":"2","content":"Was on exam 27/11/2021","comment_id":"488684"}],"answers_community":["ABF (100%)"],"topic":"13","answer":"ABF"},{"id":"P4nMr5NK2YJrJJeM7imu","isMC":true,"unix_timestamp":1654258500,"question_text":"You are developing the document processing workflow.\nYou need to identify which API endpoints to use to extract text from the financial documents. The solution must meet the document processing requirements.\nWhich two API endpoints should you identify? Each correct answer presents part of the solution.\nNOTE: Each correct selection is worth one point.","answer_images":[],"answers_community":["BC (53%)","BE (23%)","B (17%)","8%"],"discussion":[{"comments":[{"poster":"mustafaalhnuty","upvote_count":"1","timestamp":"1726480500.0","content":"BC you need receipt model as requerment say","comment_id":"1284582"},{"comments":[{"comment_id":"1286865","poster":"mrg998","timestamp":"1726840380.0","upvote_count":"1","content":"B & E I would say are correct. C would be limited to just recipts where as E would allow loads of document types."}],"content":"B E is the right answer","timestamp":"1724820780.0","upvote_count":"3","poster":"JakeCallham","comment_id":"1273818"}],"comment_id":"639192","upvote_count":"17","content":"guys so what is the correct answer","poster":"rupert1o1N","timestamp":"1659095880.0"},{"comment_id":"611072","timestamp":"1654258500.0","comments":[{"poster":"sdokmak","content":"Agreed, also the receipt text extraction is separate to the financial documents, question is only about the financial documents.\n\"The document processing solution must be able to extract tables and text from the financial documents.\nThe document processing solution must be able to extract information from receipt images.\"","timestamp":"1655858340.0","comment_id":"620071","upvote_count":"2"}],"poster":"Moody_L","content":"Selected Answer: B\nContoso have a distinct standard for each office. Is the customized form recognizer more appropriate?","upvote_count":"9"},{"comment_id":"1363835","timestamp":"1740895560.0","content":"Selected Answer: BC\n\"extract text from the financial documents\"\n\nBC since Azure Form Recognizer fits the use case","upvote_count":"1","poster":"syupwsh"},{"poster":"mustafaalhnuty","timestamp":"1726480560.0","comment_id":"1284583","upvote_count":"3","content":"BC 100%"},{"upvote_count":"1","content":"B, E\nhttps://learn.microsoft.com/en-us/rest/api/aiservices/custom-models/analyze-document?view=rest-aiservices-v2.1&tabs=HTTP\nhttps://learn.microsoft.com/en-us/rest/api/computervision/read/read?view=rest-computervision-v3.1&tabs=HTTP","comment_id":"1284226","timestamp":"1726420860.0","poster":"flist"},{"timestamp":"1721755380.0","poster":"SorinGav","upvote_count":"1","content":"B, C: Need to extract receipts and tables. So the endpoints format are actually from a 2.x version of the doc intelligence form recognizer API which can be found here: https://learn.microsoft.com/en-us/rest/api/aiservices/custom-models/analyze-document?view=rest-aiservices-v2.1&tabs=HTTP\nTo extract tables, a call to a custom model could be used if the layout one is not between the options.","comment_id":"1253818"},{"content":"Selected Answer: BC\nSelected Answer: BC","comment_id":"1246786","poster":"krzkrzkra","timestamp":"1720791540.0","upvote_count":"2"},{"upvote_count":"4","poster":"nanaw770","comment_id":"1230488","content":"Selected Answer: BC\nBC is the correct answer.","timestamp":"1718368140.0"},{"content":"Is this question still available on May 21, 2024?","poster":"takaimomoGcup","comment_id":"1214428","upvote_count":"1","timestamp":"1716215640.0"},{"poster":"azure_bimonster","upvote_count":"2","content":"Selected Answer: BC\nB and C are correct as they are part of Azure Form Recognizer.","comment_id":"1198624","timestamp":"1713532800.0"},{"comment_id":"1188867","upvote_count":"3","timestamp":"1712172120.0","content":"Please note that these endpoints are part of Azure‚Äôs Form Recognizer service, which is designed for extracting text, key/value pairs, and tables from documents. It‚Äôs a great fit for your document processing requirements. The other endpoints listed (Option A, D, and E) are part of the Computer Vision service and are more suited for different tasks such as analyzing results of Read operation, describing an image, and running Read operation respectively. They might not be the best fit for your specific document processing needs.","poster":"Murtuza"},{"comment_id":"1181754","content":"Selected Answer: BC\nTo meet Contoso‚Äôs document processing requirements for standardized financial documents, consider the following two API endpoints:\n\n/formrecognizer/v2.0/custom/models/{modelId}/analyze: This endpoint is ideal for extracting information from financial documents. It allows you to analyze custom models specifically designed for invoices and receipts. With this API, you can extract both tables and text from documents that adhere to distinct standards for each office1.\n/formrecognizer/v2.0/prebuilt/receipt/analyze: Designed for receipt analysis, this endpoint simplifies the extraction of relevant data from receipt images. It‚Äôs well-suited for handling financial paperwork in PDF or JPEG formats, especially when dealing with documents containing fewer than 20 pages1.\nBy utilizing these endpoints, you can efficiently process financial documents, extract essential information, and enhance your document processing workflow.","poster":"Murtuza","upvote_count":"3","timestamp":"1711292940.0"},{"timestamp":"1707534420.0","comment_id":"1145904","upvote_count":"4","content":"Selected Answer: BC\nB for customization C for prebuilt receipt with minimum efforts","poster":"evangelist"},{"content":"According to Windows Copilot:\nB) /formrecognizer/v2.0/custom/models/{modelId}/analyze: This endpoint is part of the Form Recognizer service. It allows you to create custom models for extracting structured data from documents. By training a custom model with examples of financial documents, you can extract relevant information such as tables and text. Since the solution needs to process standardized financial documents with distinct standards for each office, using a custom model tailored to your specific requirements is a suitable choice.\n\nC) /formrecognizer/v2.0/prebuilt/receipt/analyze: This endpoint is also part of the Form Recognizer service. It is specifically designed for extracting information from receipt images. Given that the solution must handle receipt data, this prebuilt receipt analysis endpoint is a good fit.","timestamp":"1707364140.0","comment_id":"1144026","upvote_count":"1","poster":"PCRamirez"},{"upvote_count":"3","comment_id":"1121716","timestamp":"1705155240.0","poster":"lastget","content":"Selected Answer: BC\nAccroding to the problem, we need:\nThe document processing solution must be able to extract tables and text from the financial documents.\nThe document processing solution must be able to extract information from receipt images.\n\nSo the answer I will choose BC"},{"comment_id":"1114994","poster":"123aash","timestamp":"1704521940.0","upvote_count":"4","content":"Selected Answer: BC\nB - Members of a group named Management-Bookkeeper must define how to extract tables from the financial documents\nC - Extract text for \"receipt\" images"},{"content":"Selected Answer: BE\n1. Here the requirement involves only Financial documents, receipts are not included. \n2. For financial documents we need to extract tables and text.\n3. Extract Tables --> Form recognizer\n4. Extract Text --> Computer Vision\n\nSo according to me the correct answer is B to extract the data from the tables and E to extract from the texts\n\nhttps://westus.dev.cognitive.microsoft.com/docs/services/form-recognizer-api-v2/operations/GetCustomModel\n\nhttps://learn.microsoft.com/en-us/rest/api/computervision/read/read?view=rest-computervision-v3.1&tabs=HTTP","poster":"rdemontis","upvote_count":"1","comment_id":"1067755","timestamp":"1699697820.0"},{"content":"Selected Answer: BC\nYou need to analyze the receipt images and retrieve tables from the documents. E won‚Äôt work. You can simply check what the outputs look like. https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/call-read-api","upvote_count":"1","comments":[{"upvote_count":"1","comment_id":"1055957","poster":"sl_mslconsulting","content":"Check the requirements carefully and verify what each solution can do.","timestamp":"1698463020.0"}],"timestamp":"1698462900.0","comment_id":"1055955","poster":"sl_mslconsulting"},{"timestamp":"1690093080.0","comment_id":"960144","comments":[{"timestamp":"1693972080.0","content":"Correct! It is specifically for fin. doc., not receipts (excl. C)\n\nhttps://westus.dev.cognitive.microsoft.com/docs/services/form-recognizer-api-v2/operations/GetCustomModel\nhttps://thedavidmasters.com/2020/05/18/demo-azure-form-recognizers-without-labels/","comment_id":"1000140","poster":"M25","comments":[{"content":"exactly","comment_id":"1067743","upvote_count":"1","poster":"rdemontis","timestamp":"1699696320.0"}],"upvote_count":"1"}],"content":"Selected Answer: BE\nBased on ChatGPT:\nB. /formrecognizer/v2.0/custom/models/{modelId}/analyze\nThis endpoint is part of Azure's Form Recognizer service. It's particularly useful for extracting text and tables from financial documents because it can use custom models trained on your specific document types, enabling it to handle the distinct standards for each office as mentioned in the requirements.\n\nE. /vision/v3.1/read/analyze\nThe Azure Computer Vision API's Read operation, which is executed by making a POST request to the /read/analyze endpoint, can analyze text in images, PDF documents, and TIFF files, recognizing both printed and handwritten text. It is designed to handle large documents and extracts the text and structure (such as tables) in the document.","poster":"EliteAllen","upvote_count":"2"},{"timestamp":"1686494820.0","upvote_count":"4","comment_id":"920787","content":"Selected Answer: BC\nB: https://learn.microsoft.com/en-us/azure/applied-ai-services/form-recognizer/concept-analyze-document-response?view=form-recog-3.0.0\nC: Form Recognizer Receipts","poster":"ziggy1117"},{"poster":"ziggy1117","upvote_count":"2","content":"B: https://learn.microsoft.com/en-us/azure/applied-ai-services/form-recognizer/concept-analyze-document-response?view=form-recog-3.0.0\nC: Form Recognizer Receipts","timestamp":"1686297540.0","comment_id":"919063"},{"comment_id":"782129","timestamp":"1674211560.0","upvote_count":"2","content":"Selected Answer: BE\nB is sure and E is because : \nThe /vision/v3.1/read/analyze endpoint can be used to extract information from tables in images. The endpoint uses optical character recognition (OCR) technology to extract text from images. The extracted text includes information from tables, and the location of the text in the image can be used to identify where the text came from in the table.","poster":"Pyguy"},{"upvote_count":"2","content":"Selected Answer: BE\nBE seems correct","poster":"ap1234pa","timestamp":"1673903820.0","comment_id":"778283"},{"timestamp":"1670416500.0","content":"Selected Answer: BE\nB. Each office has distinct standard for their finacial document\nE. computer vision api to analyze images","upvote_count":"3","poster":"halfway","comment_id":"737851"},{"comment_id":"642307","upvote_count":"4","content":"Selected Answer: CE\nI think the answers are correct.","poster":"not_a_robot","timestamp":"1659607440.0"}],"answer":"BC","question_id":77,"timestamp":"2022-06-03 14:15:00","choices":{"D":"/vision/v3.1/describe","C":"/formrecognizer/v2.0/prebuilt/receipt/analyze","B":"/formrecognizer/v2.0/custom/models/{modelId}/analyze","A":"/vision/v3.1/read/analyzeResults","E":"/vision/v3.1/read/analyze"},"topic":"14","answer_description":"","answer_ET":"BC","question_images":[],"exam_id":40,"url":"https://www.examtopics.com/discussions/microsoft/view/76535-exam-ai-102-topic-14-question-1-discussion/"},{"id":"y9Zi9GjzdrqTnPW8taVo","exam_id":40,"isMC":false,"url":"https://www.examtopics.com/discussions/microsoft/view/77702-exam-ai-102-topic-14-question-2-discussion/","question_text":"HOTSPOT -\nYou are developing the knowledgebase by using Azure Cognitive Search.\nYou need to build a skill that will be used by indexers.\nHow should you complete the code? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","answers_community":[],"topic":"14","timestamp":"2022-07-24 02:35:00","answer_ET":"","answer":"","unix_timestamp":1658622900,"discussion":[{"poster":"Eltooth","timestamp":"1658650740.0","upvote_count":"22","comments":[{"comment_id":"1343275","timestamp":"1737335580.0","poster":"BenALGuhl","content":"In the new V3 model you link to (https://learn.microsoft.com/en-us/azure/search/cognitive-search-skill-entity-recognition), namedEntities are not including any external source links like wiki. So namedEntities cannot be the answer. This functionality has been moved into a separate skill Entity Linking:\nhttps://learn.microsoft.com/en-us/azure/search/cognitive-search-skill-entity-linking-v3\nSo as it stands now, I would say the question would require alteration so that a second skill can be called to satisfy the requirement of supplying the sources in the output.","upvote_count":"2"},{"timestamp":"1711015800.0","poster":"rober13","comment_id":"1179100","upvote_count":"5","content":"So, the second option should be nameEntities, isn't it ??"},{"upvote_count":"4","poster":"rdemontis","comment_id":"1067769","timestamp":"1699699080.0","content":"thanks for your contribution"}],"comment_id":"635932","content":"Answer is correct however... the Entity Recognition skill is now discontinued replaced by Microsoft.Skills.Text.V3.EntityRecognitionSkill. \n\nAlso categories will only allow \"Person\" as valid category type - not \"Persons\".\n\nThis (old) version allows output to be either \"entities\" or \"namedEntities\"\nNew version only allows \"namedEntities\" from answer list.\n\nhttps://docs.microsoft.com/en-us/azure/search/cognitive-search-skill-entity-reco"},{"timestamp":"1689816180.0","upvote_count":"10","comment_id":"957041","content":"I also got this on July 3 2023 exam, but it's changed to Skills.Text.V3.","poster":"az999999"},{"content":"Dropdown 1 is \"categories\": [\"Locations\", \"Person\", \"Organization\"] because it specifies the categories of entities that the EntityRecognitionSkill should extract from the text. This matches the outputs defined in the skill, which are \"person,\" \"locations,\" and \"organization.\"\n\nDropdown 2 is { \"name\": \"namedEntities\" } because it aligns with the standard naming convention used in Azure Cognitive Search for storing the results of entity recognition. Using \"namedEntities\" makes it clear that the output includes various types of recognized entities, which can include persons, locations, organizations, etc.","poster":"syupwsh","comment_id":"1354829","timestamp":"1739245560.0","upvote_count":"2"},{"content":"person and namedEntity","upvote_count":"3","timestamp":"1726840560.0","comment_id":"1286875","poster":"mrg998"},{"content":"This question was in the test I took in August 2024","upvote_count":"4","comment_id":"1267915","poster":"JuneRain","timestamp":"1723949820.0"},{"content":"Is this question still available on May 21, 2024?","poster":"takaimomoGcup","upvote_count":"2","timestamp":"1716215580.0","comment_id":"1214426"},{"upvote_count":"2","timestamp":"1711293960.0","poster":"Murtuza","content":"The document processing solution aims to extract information related to persons, locations, and organizations.\nAdditionally, it should recognize named entities and assign them to appropriate categories.","comment_id":"1181778"},{"timestamp":"1703114280.0","content":"A modified version of this was in the exam today.","poster":"Gvalli","upvote_count":"5","comment_id":"1102019"},{"poster":"zellck","timestamp":"1688715900.0","upvote_count":"5","content":"Gotten this in Jul 2023 exam.","comment_id":"945452"},{"comment_id":"635818","upvote_count":"2","timestamp":"1658622900.0","poster":"RamonKaus","content":"Agreed"}],"answer_images":["https://www.examtopics.com/assets/media/exam-media/04271/0021800001.png"],"answer_description":"Box 1: \"categories\": [\"Locations\", \"Persons\", \"Organizations\"],\nLocations, Persons, Organizations are in the outputs.\nScenario: Contoso plans to develop a searchable knowledgebase of all the intellectual property\nNote: The categories parameter is an array of categories that should be extracted. Possible category types: \"Person\", \"Location\", \"Organization\", \"Quantity\",\n\"Datetime\", \"URL\", \"Email\". If no category is provided, all types are returned.\nBox 2: {\"name\": \" entities\"}\nThe include wikis, so should include entities in the outputs.\nNote: entities is an array of complex types that contains rich information about the entities extracted from text, with the following fields name (the actual entity name. This represents a \"normalized\" form) wikipediaId wikipediaLanguage wikipediaUrl (a link to Wikipedia page for the entity) etc.\nReference:\nhttps://docs.microsoft.com/en-us/azure/search/cognitive-search-skill-entity-recognition","question_id":78,"question_images":["https://www.examtopics.com/assets/media/exam-media/04271/0021700001.png"]},{"id":"TIRfo1NkZiPklmEauSnC","question_images":[],"answer":"D","isMC":true,"question_text":"You are developing the knowledgebase by using Azure Cognitive Search.\nYou need to process wiki content to meet the technical requirements.\nWhat should you include in the solution?","answer_ET":"D","question_id":79,"choices":{"C":"an indexer for Azure Cosmos DB attached to a skillset that contains the document extraction skill and the text translation skill","D":"an indexer for Azure Cosmos DB attached to a skillset that contains the language detection skill and the text translation skill","B":"an indexer for Azure Blob storage attached to a skillset that contains the language detection skill","A":"an indexer for Azure Blob storage attached to a skillset that contains the language detection skill and the text translation skill"},"answer_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/75979-exam-ai-102-topic-14-question-3-discussion/","answers_community":["D (81%)","C (19%)"],"topic":"14","unix_timestamp":1653070440,"timestamp":"2022-05-20 20:14:00","answer_description":"","exam_id":40,"discussion":[{"timestamp":"1708124940.0","poster":"evangelist","upvote_count":"15","content":"Selected Answer: D\nThe correct answer is D. Use an indexer connected to Azure Cosmos DB that includes language detection and text translation skills. This solution meets the requirement for handling multiple languages and supports content transformation for English, French, and Portuguese by using the text translation skill, which aligns with the technical requirement for multilingual support. Additionally, using Azure Cosmos DB and associated skill sets ensures content security and role-based access control (RBAC), meeting the requirements for content approval and security.","comments":[{"poster":"mrg998","upvote_count":"1","content":"but you can apply RBAC to blob also so that makes no sense why you would go cosmos just for that","timestamp":"1726840920.0","comment_id":"1286884"}],"comment_id":"1152280"},{"timestamp":"1653070440.0","upvote_count":"11","poster":"g2000","comments":[{"comment_id":"620076","content":"so A?..","timestamp":"1655859840.0","poster":"sdokmak","comments":[{"upvote_count":"1","content":"nvm i get it now","comment_id":"620080","timestamp":"1655860080.0","poster":"sdokmak"}],"upvote_count":"2"},{"poster":"AzureJobsTillRetire","timestamp":"1677964260.0","comment_id":"829417","upvote_count":"2","content":"This is not correct. \nAzure Cosmos DB is a globally distributed multi-model database with support for multiple APIs.\nThe Get Document operation retrieves a document by its partition key and document key.\nMethod Request URI Description\nGET https://{databaseaccount}.documents.azure.com/dbs/{db-id}/colls/{coll-id}/docs/{doc-id} Note that the {databaseaccount} is the name of the Azure Cosmos DB account created under your subscription. The {db-id} value is the user generated name/ID of the database, not the system generated ID (rid). The {coll-id} value is the name of the collection. The {doc-id} value is the ID of the document to be retrieved.\nhttps://learn.microsoft.com/en-us/rest/api/cosmos-db/get-a-document"}],"comment_id":"604593","content":"Selected Answer: D\nDocument extraction skill only works for files. It's less likely to work with CosmoDB."},{"comment_id":"1354878","upvote_count":"1","timestamp":"1739256540.0","content":"Selected Answer: D\nThe wiki material is saved on Azure Cosmos DB, which is the correct target of this option. It consists of two skills: text translation, which converts the content into the necessary languages, and language detection, which determines the language of the content. This satisfies all requirements for appropriate content processing and multilingual support.\n\nD is the answer","poster":"syupwsh"},{"comment_id":"1287433","content":"Is this question checking if I can spot in the table that the wiki content is kept in CosmosDB and not in Blob storage? Is that the skill an AI-engineer should possess? |\nNext level is to know that the data in cosmosDB stored for wiki are not documents or images. Just assume based on language skills?","upvote_count":"1","timestamp":"1726942620.0","poster":"famco"},{"upvote_count":"1","timestamp":"1726481040.0","content":"Selected Answer: D\nD 100%","poster":"mustafaalhnuty","comment_id":"1284584"},{"timestamp":"1723949880.0","upvote_count":"3","content":"This question was in the test I took in August 2024","comment_id":"1267916","poster":"JuneRain"},{"comment_id":"1235333","timestamp":"1719053220.0","content":"Selected Answer: D\nD is the answer.","poster":"reiwanotora","upvote_count":"1"},{"upvote_count":"1","comment_id":"1231489","timestamp":"1718561640.0","poster":"fba825b","content":"Selected Answer: D\nIt is D and not C. Document extraction skill is not needed because the format of content is text (as stated in the table above)"},{"timestamp":"1716215640.0","comment_id":"1214429","content":"Selected Answer: D\nIs this question still available on May 21, 2024?","poster":"takaimomoGcup","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: D\nmust be D","timestamp":"1713229200.0","poster":"chandiochan","comment_id":"1196282"},{"timestamp":"1711307640.0","comment_id":"1181932","poster":"Murtuza","content":"Selected Answer: D\nTherefore, A. an indexer for Cosmos DB attached to a skillset that contains the language detection skill and the text translation skill aligns with the technical requirements for content approval, multilingual support, and RBAC1","comments":[{"comment_id":"1323217","poster":"chrillelundmark","timestamp":"1733592420.0","content":"Don't foget the requirement where it says the searchable knowledgebase should contain all intellectual property. Another argument for A since Azure Cosmos DB is typically used for structured or semi-structured data, not for handling diverse formats like video or audio.","upvote_count":"1"}],"upvote_count":"4"},{"timestamp":"1710733020.0","comment_id":"1176236","poster":"chandiochan","upvote_count":"4","content":"Selected Answer: D\nMust be D"},{"comment_id":"1144029","comments":[{"content":"Language Detection Skill: This skill detects the language of the content. It ensures that the appropriate language-specific processing (such as translation) can be applied.\n\nBy using the language detection skill, you‚Äôll be able to handle content in different languages and transcribe jargon accurately. Additionally, the Azure Cognitive Search service supports full-text search, semantic search, vector search, and hybrid search, which aligns with your requirements for searching content in various formats, including video.\n\nRemember that the semantic search and vector search features are currently in public preview in Azure Cognitive Search. The solution will also provide relevant links to external resources for further research, enhancing the overall knowledgebase experience. üìöüîçüåê\n\nFor more details, you can refer to the official documentation.","comment_id":"1144031","upvote_count":"1","poster":"PCRamirez","timestamp":"1707364680.0"},{"timestamp":"1707364740.0","comment_id":"1144032","upvote_count":"1","poster":"PCRamirez","content":"(1) Search and query an enterprise knowledge base by using Azure OpenAI or .... https://learn.microsoft.com/en-us/azure/architecture/ai-ml/openai/idea/search-and-query-using-openai-service.\n(2) Create a knowledge store with Azure AI Search - Training. https://learn.microsoft.com/en-us/training/modules/create-knowledge-store-azure-cognitive-search/.\n(3) Implement knowledge mining with Azure Cognitive Search. https://learn.microsoft.com/en-us/training/paths/implement-knowledge-mining-azure-cognitive-search/.\n(4) Knowledge store concepts - Azure AI Search | Microsoft Learn. https://learn.microsoft.com/en-us/azure/search/knowledge-store-concept-intro.\n(5) Index file content and metadata by using Azure Cognitive Search. https://learn.microsoft.com/en-us/azure/architecture/ai-ml/architecture/search-blob-metadata."}],"upvote_count":"1","content":"Windows Copilot:\nB. An indexer for Azure Blob storage attached to a skillset that contains the language detection skill.\n\nHere‚Äôs the explanation:\n\nAzure Blob Storage: You‚Äôll use Azure Blob storage to store your content, including wiki articles and other relevant documents.\n\nIndexer: An indexer in Azure Cognitive Search automatically discovers new content from supported data sources (such as blob storage) and adds it to the search index. In your case, you‚Äôll create an indexer to process the wiki content.\n\nSkillset: A skillset defines a set of cognitive skills (such as language detection, text translation, and more) that can be applied during indexing. Since your knowledgebase needs to support multiple languages (English, French, and Portuguese), you‚Äôll attach a skillset to the indexer.\n\n...","poster":"PCRamirez","timestamp":"1707364680.0"},{"timestamp":"1705155840.0","comment_id":"1121726","upvote_count":"2","poster":"lastget","content":"Selected Answer: D\nYou only need to detect language and translate form wiki"},{"content":"It is confusing because the table mentions wikis are in Text format, but on the other hand, wikis (and blog entries) usually contain HTML.\nIf they do contain HTML is should be C (extract text from html - dont translate tags)\nIf they don't it should be D\n\nAt the end I choose D because we shouldn't assume stuff, the questions says \"Text\" not \"Text/HTML\"","timestamp":"1704790080.0","comment_id":"1117317","upvote_count":"1","poster":"dimsok"},{"poster":"rdemontis","timestamp":"1699700100.0","comment_id":"1067775","content":"Selected Answer: D\nIMHO the correct answer should be D.\nYou don't need Document Extraction to extract text from files. You have already the text in wikis.\n\nhttps://learn.microsoft.com/en-us/azure/search/cognitive-search-skill-document-extraction\n\nIt's true that Text Translation could also detect the source language but reading the documentation seems it could be not so accurate.\n\nhttps://learn.microsoft.com/en-us/azure/search/cognitive-search-skill-text-translation\n\nFor sure you need two operations here: detect and translate.","upvote_count":"3"},{"poster":"sl_mslconsulting","upvote_count":"3","timestamp":"1698532440.0","comment_id":"1056474","comments":[{"comments":[{"timestamp":"1711785180.0","content":"Where does it say wikis are available in three languages? All it says is ' All planned projects must support English, French, and Portuguese.'.","poster":"idcanymore","comment_id":"1185949","upvote_count":"1"}],"timestamp":"1698532560.0","poster":"sl_mslconsulting","content":"Correction: Wikis are already in text format and available in three languages so what do you need the document extraction and translation for? What you need is to detect the language of the text and translate it to English if you want to normalize the text to a single language before indexing for search. Only in this case it would make sense to use text translation skill.","comment_id":"1056475","upvote_count":"1"}],"content":"Selected Answer: D\nWikis are already in text format and available in three languages so what do you need the document extraction and translation normalize the text to a single language before indexing for? What you need is to detect the language of the text and translate it to English if you want to normalize the text to a single language before indexing for search. Only in this case it would make sense to use text translation skill."},{"content":"Gotten this in Jul 2023 exam.","upvote_count":"3","poster":"zellck","comment_id":"945453","timestamp":"1688715960.0"},{"comments":[{"content":"Correct! Even if: \nhttps://learn.microsoft.com/en-us/azure/search/cognitive-search-concept-intro\nA skillset that's assembled using built-in skills is well suited for the following application scenarios:\n‚Ä¢ Machine translation is provided by the Text Translation skill, often paired with language detection for multi-language solutions.","poster":"M25","timestamp":"1693981200.0","upvote_count":"1","comment_id":"1000249"},{"timestamp":"1693981380.0","comments":[{"comment_id":"1000259","content":"Indexer\nhttps://learn.microsoft.com/en-us/azure/search/search-indexer-overview\nAn indexer in Azure Cognitive Search is a crawler that extracts searchable content from cloud data sources and populates a search index using field-to-field mappings between source data and a search index. This approach is sometimes referred to as a 'pull model' because the search service pulls data in without you having to write any code that adds data to an index.\nhttps://learn.microsoft.com/en-us/azure/search/tutorial-multiple-data-sources#create-azure-cosmos-db-data-source-and-indexer\nAfter the data source is created, the program sets up an Azure Cosmos DB indexer named hotel-rooms-cosmos-indexer.","upvote_count":"1","poster":"M25","timestamp":"1693981380.0"}],"poster":"M25","comment_id":"1000257","upvote_count":"1","content":"Data Source vs. Destination (see also Topic 6 Q#1)\nhttps://learn.microsoft.com/en-us/azure/search/search-indexer-overview#document-cracking\nDepending on the data source, the indexer will try different operations to extract potentially indexable content:\n‚Ä¢ When the document is a record in Azure Cosmos DB, the indexer will extract non-binary content from fields and subfields from the Azure Cosmos DB document.\n\nhttps://learn.microsoft.com/en-us/azure/search/cognitive-search-concept-intro\nExploration is the last step. Output is always a search index that you can query from a client app. Output can optionally be a knowledge store consisting of blobs and tables in Azure Storage that are accessed through data exploration tools or downstream processes."},{"comment_id":"1000254","timestamp":"1693981260.0","content":"https://learn.microsoft.com/en-us/azure/search/cognitive-search-skill-document-extraction\nThe Document Extraction skill extracts content from a file within the enrichment pipeline. This allows you to take advantage of the document extraction step that normally happens before the skillset execution with files that may be generated by other skills.\nThis skill extracts text and images. Text extraction is free. Image extraction is metered by Azure Cognitive Search.","upvote_count":"1","poster":"M25"}],"comment_id":"920419","timestamp":"1686459420.0","content":"Selected Answer: C\nLanguage Detection is not needed. The capability is especially useful when you need to provide the language of the text as input to other skills (for example, the Sentiment Analysis skill or Text Split skill). But it is not required for Text Translation","poster":"ziggy1117","upvote_count":"3"},{"comment_id":"779472","content":"Selected Answer: C\nC is correct","poster":"ap1234pa","timestamp":"1674004620.0","upvote_count":"1"},{"timestamp":"1673440440.0","comments":[{"content":"nevermind","poster":"am20","upvote_count":"3","timestamp":"1673440740.0","comment_id":"772485"}],"content":"Selected Answer: C\nI'm assuming Cosmos DB will be used for output not as an input","upvote_count":"1","poster":"am20","comment_id":"772477"},{"poster":"not_a_robot","content":"Selected Answer: C\nThe answer is correct.\nIt's to extract the content from the inputs. It supports a lot of formats of documents, including JOSN.\n\nhttps://docs.microsoft.com/en-us/azure/search/cognitive-search-skill-document-extraction","upvote_count":"6","comment_id":"642312","timestamp":"1659608640.0"}]},{"id":"MjSWjHmpS3B0PzzepA7t","answers_community":["A (100%)"],"answer_description":"","isMC":true,"question_images":[],"answer_images":[],"answer_ET":"A","choices":{"C":"a custom analyzer","A":"synonym map","D":"a built-in key phrase extraction skill","B":"a suggester"},"answer":"A","timestamp":"2022-07-25 10:26:00","exam_id":40,"topic":"14","question_text":"You are developing the knowledgebase by using Azure Cognitive Search.\nYou need to meet the knowledgebase requirements for searching equivalent terms.\nWhat should you include in the solution?","question_id":80,"url":"https://www.examtopics.com/discussions/microsoft/view/77728-exam-ai-102-topic-14-question-4-discussion/","discussion":[{"comment_id":"1331954","upvote_count":"5","comments":[{"upvote_count":"1","poster":"Mattt","content":"for 6 hours?","timestamp":"1742390160.0","comment_id":"1400534"}],"timestamp":"1735224060.0","content":"Selected Answer: A\nI wrote this exam on 25 Dec 2024\nNo simulation \nand this was one for the question I got in Case study.\n\nScore 805 (all I did was study this and revise from number 1 to 333 for 6hours) memorize the case study question and answers too.\n\nIn all Pray for God's direction.\nJesus Christ is Lord and our guide","poster":"kennynelcon"},{"timestamp":"1723949880.0","upvote_count":"5","content":"This question was in the test I took in August 2024","poster":"JuneRain","comment_id":"1267917"},{"comment_id":"1354879","upvote_count":"1","content":"Selected Answer: A\nSynonym map allows the search index to recognize equivalent terms, ensuring that searches for different but related terms return the same results.\n\nhttps://learn.microsoft.com/en-us/azure/search/search-synonyms\n\nA for answer","poster":"syupwsh","timestamp":"1739256660.0"},{"content":"Selected Answer: A\nA is right answer.\nFrom Takedajuku perspective, if you study for 4 days and spend 2 days reviewing, you will have a better chance of passing the exam.","poster":"nanaw770","comment_id":"1220349","upvote_count":"1","timestamp":"1716906720.0"},{"upvote_count":"1","comment_id":"1214424","poster":"takaimomoGcup","timestamp":"1716215580.0","content":"Is this question still available on May 21, 2024?"},{"upvote_count":"3","poster":"evangelist","content":"Selected Answer: A\nA is correct","comment_id":"1145901","timestamp":"1707533280.0"},{"poster":"rdemontis","upvote_count":"1","content":"Selected Answer: A\ncorrect\nhttps://learn.microsoft.com/en-us/azure/search/search-synonyms","timestamp":"1700069040.0","comment_id":"1071705"},{"upvote_count":"4","content":"Selected Answer: A\nQuote \"In Azure Cognitive Search, a synonym map contains a list of rules for expanding or rewriting a search query to equivalent terms.\" at https://learn.microsoft.com/en-us/rest/api/searchservice/create-synonym-map .","comment_id":"984296","poster":"james2033","timestamp":"1692347340.0"},{"content":"Selected Answer: A\nA is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/search/search-synonyms\nWithin a search service, synonym maps are a global resource that associate equivalent terms, expanding the scope of a query without the user having to actually provide the term. For example, assuming \"dog\", \"canine\", and \"puppy\" are mapped synonyms, a query on \"canine\" will match on a document containing \"dog\".","comment_id":"940956","poster":"zellck","comments":[{"poster":"zellck","content":"Gotten this in Jul 2023 exam.","timestamp":"1688715960.0","upvote_count":"4","comment_id":"945454"}],"timestamp":"1688307240.0","upvote_count":"3"},{"comment_id":"636569","poster":"Eltooth","timestamp":"1658737560.0","upvote_count":"2","content":"Selected Answer: A\nA is correct answer. \n\nSynonym maps are a global resource that associate equivalent terms, expanding the scope of a query without the user having to actually provide the term.\nYou might create multiple synonym maps for different languages, such as English and French versions, or lexicons if your content includes technical or obscure terminology.\nhttps://docs.microsoft.com/en-us/azure/search/search-synonyms"}],"unix_timestamp":1658737560}],"exam":{"id":40,"isMCOnly":false,"lastUpdated":"12 Apr 2025","numberOfQuestions":329,"provider":"Microsoft","isBeta":false,"name":"AI-102","isImplemented":true},"currentPage":16},"__N_SSP":true}