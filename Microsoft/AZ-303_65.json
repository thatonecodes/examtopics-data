{"pageProps":{"questions":[{"id":"MtQXxwLVBwOjJMI41OBu","answers_community":[],"unix_timestamp":1610807940,"answer_images":[],"discussion":[{"timestamp":"1610807940.0","poster":"Kraviecc","comments":[{"content":"But would it 'scale to thousands of users' if we have only a single instance of each microservice?","poster":"pentium75","upvote_count":"2","comment_id":"419140","timestamp":"1627980840.0"}],"content":"According to the https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-quickstart-containers (Running an existing application in a Windows container on a Service Fabric cluster doesn't require any changes to your application) should be YES.","comment_id":"268875","upvote_count":"12"},{"content":"Not a part of AZ-303","upvote_count":"12","poster":"as0912","timestamp":"1615701600.0","comment_id":"310311"},{"timestamp":"1641685680.0","content":"Yes is correct \nhttps://docs.microsoft.com/en-us/azure/architecture/guide/technology-choices/compute-decision-tree","comment_id":"519832","poster":"Inland","upvote_count":"1"},{"content":"Service Fabric would only be the logical choice if it was about DOTNET applications within the containers. It's not mentioned in the question.","poster":"gizda2","upvote_count":"1","timestamp":"1633926120.0","comment_id":"460359"},{"timestamp":"1631448660.0","content":"This is out of syllabus for AZ-303. As per my understanding containers are stateless and Distributed Microservices are stateful. Also , we should use stateful services when we want data to persist and stateless services when data must not persist. In the current scenario, we are providing a stateless solution (Windows Container deployment) for stateful microservices (Distributed Microservices). So answer should be \"No\".","poster":"subbu3071988","comment_id":"443439","upvote_count":"3"},{"poster":"syu31svc","upvote_count":"2","content":"https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-overview\n\nI would take yes","timestamp":"1630750260.0","comment_id":"439050"},{"upvote_count":"3","timestamp":"1619942220.0","poster":"nguyenhung1121990","comment_id":"347498","content":"A - Yes: is correct Answer"},{"upvote_count":"2","timestamp":"1617636060.0","content":"Should be Yes","poster":"demonite","comment_id":"328804"},{"content":"Likely Yes. Key is stateful and stateless. Both are supported in containers in the service fabric\nhttps://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-choose-framework\nContainers\nBy default, Service Fabric deploys and activates services as processes. Service Fabric can also deploy services in containers. Service Fabric supports deployment of Linux containers and Windows containers on Windows Server 2016 and later. Container images can be pulled from any container repository and deployed to the machine. You can deploy existing applications as guest executables, Service Fabric stateless or stateful Reliable services or Reliable Actors in containers, and you can mix services in processes and services in containers in the same application.","upvote_count":"2","comments":[{"content":"thanks for your explanation","poster":"rdemontis","timestamp":"1626691920.0","upvote_count":"1","comment_id":"409463"}],"comment_id":"274862","timestamp":"1611434760.0","poster":"inf"}],"answer_ET":"B","isMC":true,"question_id":321,"answer":"B","url":"https://www.examtopics.com/discussions/microsoft/view/42559-exam-az-303-topic-6-question-5-discussion/","choices":{"A":"Yes","B":"No"},"topic":"6","exam_id":52,"question_images":[],"question_text":"You develop an entertainment application where users can buy and trade virtual real estate. The application must scale to support thousands of users.\nThe current architecture includes five Azure virtual machines (VM) that connect to an Azure SQL Database for account information and Azure Table Storage for backend services. A user interacts with these components in the cloud at any given time.\n✑ Routing Service `\" Routes a request to the appropriate service and must not persist data across sessions.\n✑ Account Service `\" Stores and manages all account information and authentication and requires data to persist across sessions\n✑ User Service `\" Stores and manages all user information and requires data to persist across sessions.\n✑ Housing Network Service `\" Stores and manages the current real-estate economy and requires data to persist across sessions.\n✑ Trade Service `\" Stores and manages virtual trade between accounts and requires data to persist across sessions.\nDue to volatile user traffic, a microservices solution is selected for scale agility.\nYou need to migrate to a distributed microservices solution on Azure Service Fabric.\nSolution: Deploy a Windows container to Azure Service Fabric for each component.\nDoes the solution meet the goal?","answer_description":"","timestamp":"2021-01-16 15:39:00"},{"id":"xtcwXWtPp59QJxO6HMZN","answers_community":[],"answer_images":["https://www.examtopics.com/assets/media/exam-media/03862/0068700002.png"],"answer":"","answer_ET":"","answer_description":"VM2: West US -\nIn RG2, which is in West US, you need to create a new virtual machine named VM2.\n\nVM2_interface: East US -\nVM2 will use a network interface named VM2_Interface to connect to VNET1, which is in East US.\nReferences:\nhttps://docs.microsoft.com/en-us/azure/virtual-network/associate-public-ip-address-vm","url":"https://www.examtopics.com/discussions/microsoft/view/56938-exam-az-303-topic-6-question-50-discussion/","unix_timestamp":1625232720,"question_images":["https://www.examtopics.com/assets/media/exam-media/03862/0068600002.png","https://www.examtopics.com/assets/media/exam-media/03862/0068700001.png"],"discussion":[{"comment_id":"397011","upvote_count":"36","content":"Both East US\nEach NIC attached to a VM must exist in the same location and subscription as the VM. Each NIC must be connected to a VNet that exists in the same Azure location and subscription as the NIC. You can change the subnet a VM is connected to after it's created, but you cannot change the VNet","poster":"Yiannisthe7th","timestamp":"1625240520.0"},{"poster":"Pinto","timestamp":"1627140780.0","upvote_count":"4","comment_id":"413264","content":"repeat https://www.examtopics.com/discussions/microsoft/view/41200-exam-az-303-topic-2-question-12-discussion/"},{"content":"Both East US. Repeated question","timestamp":"1626272820.0","upvote_count":"3","comment_id":"406317","poster":"rdemontis"},{"comments":[{"poster":"7demonsrising","comment_id":"464031","upvote_count":"1","content":"Yes agree completely","timestamp":"1634552580.0"}],"poster":"Tripp_F","upvote_count":"4","comment_id":"400922","content":"Both East US. Interface and VM must be in same region. Resource Group is not really relevant. Both should be same region as VNET.","timestamp":"1625663700.0"},{"poster":"Farid77","timestamp":"1625232720.0","upvote_count":"3","comment_id":"396912","content":"Both East US"}],"timestamp":"2021-07-02 15:32:00","question_text":"DRAG DROP -\nYou have an Azure subscription that contains the resources shown in the following table.\n//IMG//\n\nIn RG2, you need to create a new virtual machine named VM2 that will connect to VNET1. VM2 will use a network interface named VM2_Interface.\nIn which region should you create VM2 and VM2_Interface? To answer, drag the appropriate regions to the correct targets. Each region may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.\nNOTE: Each correct selection is worth one point.\nSelect and Place:\n//IMG//","isMC":false,"topic":"6","question_id":322,"exam_id":52},{"id":"9yTpNKwIU26xjVeQf8DE","question_id":323,"topic":"6","question_text":"You create an Azure Time Series Insights event handler. You need to send data over the network as efficiently as possible and optimize query performance.\nWhat should you do?","url":"https://www.examtopics.com/discussions/microsoft/view/56951-exam-az-303-topic-6-question-51-discussion/","answers_community":[],"question_images":[],"exam_id":52,"answer_images":[],"timestamp":"2021-07-02 17:39:00","answer":"D","answer_ET":"D","unix_timestamp":1625240340,"choices":{"C":"Use a Tag ID","D":"Use reference data","B":"Send all properties","A":"Create a query plan"},"discussion":[{"content":"D - Use reference data - correct\nReference data is used to reduce the number of bytes transferred over the network. The two attributes messageId and deviceLocation are joined by using the key property deviceId. This data is joined with the telemetry data at ingress time and is then stored in Time Series Insights for querying","poster":"Yiannisthe7th","comment_id":"397007","timestamp":"1625240340.0","upvote_count":"14"},{"upvote_count":"4","timestamp":"1630125360.0","comment_id":"433525","content":"Incorrect Answers:\n\nCreate a query plan – This option is to query the events. This will not optimize the data sent over network efficiently.\n\nSend all properties - This option will increase the data set size.\n\nUse a Tag ID – This is an identifier.\n\nAnswer is D","poster":"syu31svc"}],"isMC":true,"answer_description":"References:\nhttps://docs.microsoft.com/en-us/azure/time-series-insights/how-to-shape-query-json"},{"id":"TfLJmuGzrUdFe2I31mjf","answer":"B","answer_images":[],"question_id":324,"question_text":"You are creating an IoT solution using Azure Time Series Insights.\nYou configure the environment to ensure that all data for the current year is available.\nWhat should you do?","discussion":[{"comment_id":"397003","poster":"Yiannisthe7th","timestamp":"1625240040.0","upvote_count":"24","content":"B is the correct answer\nIn the Time Series Insights environment pane, under Settings, select Storage configuration.\n\nIn the Data retention time (in days) box, enter a value between 1 and 400.\nhttps://docs.microsoft.com/en-us/azure/time-series-insights/time-series-insights-how-to-configure-retention"},{"upvote_count":"1","poster":"moon2351","content":"Selected Answer: B\nAnswer is B","comment_id":"543825","timestamp":"1644416640.0"},{"comment_id":"534439","content":"Selected Answer: B\nB is the correct answer","timestamp":"1643349300.0","poster":"[Removed]","upvote_count":"1"},{"content":"B is correct \n\nEach of your Azure Time Series Insights environments has a setting that controls Data retention time. The value spans from 1 to 400 days. The data is deleted based on the environment storage capacity or retention duration, whichever comes first.","poster":"xyz213","comment_id":"512644","upvote_count":"1","timestamp":"1640806620.0"},{"timestamp":"1630239300.0","content":"https://docs.microsoft.com/en-us/azure/time-series-insights/time-series-insights-concepts-retention\n\nEach of your Azure Time Series Insights environments has a setting that controls Data retention time\n\nAnswer is B","upvote_count":"4","comment_id":"434568","poster":"syu31svc"},{"poster":"Tripp_F","upvote_count":"4","content":"From AZ-300: Answer is B\n\nEach of your Azure Time Series Insights environments has a setting that controls Data retention time. The value spans from 1 to 400 days. The data is deleted based on the environment storage capacity or retention duration, whichever comes first.\n\nRef: https://docs.microsoft.com/en-us/azure/time-series-insights/time-series-insights-concepts-retention","comment_id":"400931","timestamp":"1625664000.0"}],"unix_timestamp":1625240040,"isMC":true,"url":"https://www.examtopics.com/discussions/microsoft/view/56949-exam-az-303-topic-6-question-52-discussion/","timestamp":"2021-07-02 17:34:00","answers_community":["B (100%)"],"answer_description":"","question_images":[],"answer_ET":"D","exam_id":52,"topic":"6","choices":{"A":"Add a disaster recovery (DR) strategy.","C":"Change the pricing tier.","D":"Create a reference data set.","B":"Set a value for the Data retention time setting."}},{"id":"pZinyM3gLtLIcRXNDyss","discussion":[{"poster":"Yiannisthe7th","timestamp":"1625240040.0","content":"Correct answer","comment_id":"397004","upvote_count":"6"},{"poster":"syu31svc","timestamp":"1630328580.0","comment_id":"435513","content":"https://docs.microsoft.com/en-us/azure/import-export/storage-import-export-service\n\nDetermine data to be imported, number of drives you need, destination blob location for your data in Azure storage.\nUse the WAImportExport tool to copy data to disk drives. Encrypt the disk drives with BitLocker.\nCreate an import job in your target storage account in Azure portal. Upload the drive journal files.\nProvide the return address and carrier account number for shipping the drives back to you.\nShip the disk drives to the shipping address provided during job creation.\nUpdate the delivery tracking number in the import job details and submit the import job.\nThe drives are received and processed at the Azure data center.\nThe drives are shipped using your carrier account to the return address provided in the import job.\n\nAnswer is correct","upvote_count":"3"}],"isMC":false,"answer":"","answers_community":[],"question_id":325,"unix_timestamp":1625240040,"exam_id":52,"timestamp":"2021-07-02 17:34:00","answer_ET":"","question_images":["https://www.examtopics.com/assets/media/exam-media/03862/0068900001.jpg"],"answer_images":["https://www.examtopics.com/assets/media/exam-media/03862/0069000001.jpg"],"url":"https://www.examtopics.com/discussions/microsoft/view/56950-exam-az-303-topic-6-question-53-discussion/","topic":"6","question_text":"DRAG DROP -\nYou have an Azure subscription that contains a storage account.\nYou have an on-premises server named Server1 that runs Windows Server 2016. Server1 has 2 TB of data.\nYou need to transfer the data to the storage account by using the Azure Import/Export service.\nIn which order should you perform the actions? To answer, move all actions form the list of actions to the answer area and arrange them in the correct order.\nNOTE: More than one order of answer choices is correct. You will receive credit for any of the correct orders you select.\nSelect and Place:\n//IMG//","answer_description":"At a high level, an import job involves the following steps:\nStep 1: Attach an external disk to Server1 and then run waimportexport.exe\nDetermine data to be imported, number of drives you need, destination blob location for your data in Azure storage.\nUse the WAImportExport tool to copy data to disk drives. Encrypt the disk drives with BitLocker.\nStep 2: From the Azure portal, create an import job.\nCreate an import job in your target storage account in Azure portal. Upload the drive journal files.\nStep 3: Detach the external disks from Server1 and ship the disks to an Azure data center.\nProvide the return address and carrier account number for shipping the drives back to you.\nShip the disk drives to the shipping address provided during job creation.\nStep 4: From the Azure portal, update the import job\nUpdate the delivery tracking number in the import job details and submit the import job.\nThe drives are received and processed at the Azure data center.\nThe drives are shipped using your carrier account to the return address provided in the import job."}],"exam":{"numberOfQuestions":334,"id":52,"isMCOnly":false,"lastUpdated":"12 Apr 2025","name":"AZ-303","isBeta":false,"isImplemented":true,"provider":"Microsoft"},"currentPage":65},"__N_SSP":true}