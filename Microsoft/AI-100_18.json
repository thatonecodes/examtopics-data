{"pageProps":{"questions":[{"id":"T7yDBDmWOAbcMmaOE4Mu","answers_community":[],"url":"https://www.examtopics.com/discussions/microsoft/view/13452-exam-ai-100-topic-2-question-44-discussion/","timestamp":"2020-02-05 16:10:00","answer_images":[],"question_images":[],"isMC":true,"question_id":86,"unix_timestamp":1580915400,"answer_description":"You can use HDInsight to process streaming data that's received in real time from a variety of devices.\nInternet of Things (IoT)\nYou can use HDInsight to build applications that extract critical insights from data. You can also use Azure Machine Learning on top of that to predict future trends for your business.\nBy combining enterprise-scale R analytics software with the power of Apache Hadoop and Apache Spark, Microsoft R Server for HDInsight gives you the scale and performance you need. Multi-threaded math libraries and transparent parallelization in R Server handle up to 1000x more data and up to 50x faster speeds than open-source R, which helps you to train more accurate models for better predictions.\nReferences:\nhttps://docs.microsoft.com/en-us/azure/hdinsight/hadoop/apache-hadoop-introduction","question_text":"You plan to design a solution for an AI implementation that uses data from IoT devices.\nYou need to recommend a data storage solution for the IoT devices that meets the following requirements:\n✑ Allow data to be queried in real-time as it streams into the solution.\n✑ Provide the lowest amount of latency for loading data into the solution.\nWhat should you include in the recommendation?","topic":"2","choices":{"D":"a Microsoft Azure SQL database that has In-Memory OLTP enabled","C":"a Microsoft Azure HDInsight Hadoop cluster","B":"a Microsoft Azure HDInsight R Server cluster","A":"a Microsoft Azure Table Storage solution"},"exam_id":39,"discussion":[{"comment_id":"75279","comments":[{"poster":"NickRafe","comment_id":"393158","upvote_count":"1","content":"If you want to do some Real Time Analytics, where you are expecting result quickly, Hadoop should not be used directly. It is because Hadoop works on batch processing, hence response time is high.\nThis excerpt is from the same link.","timestamp":"1624903260.0"}],"content":"The question ask for storage solution not processing solution, so we can use hadoop cluster as storage (HDFS) and spark for processing.\n https://www.edureka.co/blog/5-reasons-when-to-use-and-not-to-use-hadoop/","poster":"Mfweuydg","timestamp":"1587034740.0","upvote_count":"14"},{"upvote_count":"13","comment_id":"185104","content":"The answer is D\n\nIn-Memory OLTP increases number of transactions per second and reduces latency for transaction processing. Scenarios that benefit from In-Memory OLTP are: high-throughput transaction processing such as trading and gaming, data ingestion from events or IoT devices, caching, data load, and temporary table and table variable scenarios.\n\nLink for the above para: https://docs.microsoft.com/en-us/azure/azure-sql/in-memory-oltp-overview#overview","comments":[{"content":"I agree with this","upvote_count":"1","timestamp":"1607945340.0","comment_id":"243500","poster":"Distinctive"},{"poster":"awron_durat","comment_id":"254851","upvote_count":"2","timestamp":"1609256940.0","content":"Is OLTP considered \"real-time as it streams into the server\"? I thought it was real-time but you could only query it after it was streamed into the server specifically because it's transactional and the transaction has to finish before you can query it."}],"timestamp":"1600847400.0","poster":"sayak17"},{"upvote_count":"1","poster":"rveney","timestamp":"1687244820.0","comment_id":"928223","content":"D. a Microsoft Azure SQL database that has In-Memory OLTP enabled\n\nExplanation:\n\nA Microsoft Azure SQL database with In-Memory OLTP enabled would be the best choice for this scenario. In-Memory OLTP, also known as Hekaton, is an in-memory processing technology in Azure SQL Database that provides high-performance and low-latency access to data.\n\nBy utilizing In-Memory OLTP, the IoT data can be stored and queried in real-time as it streams into the solution. This technology enables the database to keep the entire dataset in memory, resulting in significantly reduced latency for loading and accessing the data."},{"timestamp":"1629723360.0","upvote_count":"2","comment_id":"429970","poster":"dijaa","content":"B Definitely"},{"poster":"vilas94","content":"Answer is D a \"Microsoft Azure SQL database that has In-Memory OLTP enabled\"\nCommon application patterns are:\nIngesting sensor readings and events, and allow notifications as well as historical analysis.\nManaging batch updates, even from multiple sources, while minimizing the impact on the concurrent read workload.\n\nhttps://docs.microsoft.com/en-us/sql/relational-databases/in-memory-oltp/overview-and-usage-scenarios?view=sql-server-ver15#data-ingestion-including-iot-internet-of-things","upvote_count":"5","timestamp":"1603011840.0","comment_id":"201909"},{"upvote_count":"8","comment_id":"75737","comments":[{"poster":"giusecozza","comment_id":"98694","timestamp":"1590823560.0","comments":[{"timestamp":"1599940380.0","upvote_count":"3","poster":"Nova077","comment_id":"178402","content":"R server is not a storage solution. So why is this an answer?"},{"poster":"allanm","timestamp":"1622022420.0","upvote_count":"1","content":"You're not evaluating a processing solution, you are recommending a data storage solution. Why is this an answer?","comment_id":"367018"}],"upvote_count":"1","content":"Agree. RevoScaleR compute contexts (ex. Spark) enable faster processing than Hadoop, with the same storage\nhttps://docs.microsoft.com/it-it/azure/hdinsight/r-server/r-server-compute-contexts\nhttps://docs.microsoft.com/it-it/azure/hdinsight/r-server/r-server-storage"}],"content":"Should be R Server:\n\nBy combining enterprise-scale R analytics software with the power of Apache Hadoop and Apache Spark, Microsoft R Server for HDInsight gives you the scale and performance you need. Multi-threaded math libraries and transparent parallelization in R Server handle up to 1000x more data and up to 50x faster speeds than open-source R, which helps you to train more accurate models for better predictions.","timestamp":"1587130140.0","poster":"lchvce"},{"comment_id":"72217","timestamp":"1586280120.0","content":"Hadoop is more for batch processing, so I wouldn't recommend this solution.","upvote_count":"2","poster":"Miles19"},{"upvote_count":"7","comment_id":"72216","poster":"Miles19","content":"As we need to query data in real-time, I believe that the answer should be Microsoft Azure HDInsight R Server cluster.","timestamp":"1586280060.0"},{"poster":"sassa","content":"Shouldn't this be the R server?","upvote_count":"4","timestamp":"1580915400.0","comments":[{"comments":[{"upvote_count":"1","poster":"UpsetUser","timestamp":"1610769900.0","comment_id":"268547","content":"somewhere moderator is responsible for this . Why he approves such comments who dont have any justification."}],"content":"justify your statement please, don't just throw options around","timestamp":"1582957080.0","upvote_count":"14","comment_id":"56743","poster":"junkz"}],"comment_id":"46916"}],"answer":"C","answer_ET":"C"},{"id":"be5SWFqE3IfFNojSyygs","topic":"2","isMC":true,"answers_community":[],"answer_images":[],"answer_description":"With Azure Data Lake Store (ADLS) serving as the hyper-scale storage layer and HDInsight serving as the Hadoop-based compute engine services. It can be used for prepping large amounts of data for insertion into a Data Warehouse\nReferences:\nhttps://www.blue-granite.com/blog/azure-data-lake-analytics-holds-a-unique-spot-in-the-modern-data-architecture","choices":{"E":"Azure Data Lake","D":"Azure Batch","A":"Azure Stream Analytics","B":"Azure Data Factory","C":"an Azure HDInsight cluster"},"question_images":[],"discussion":[{"poster":"T0p1cs","comments":[{"comment_id":"12968","content":"Here is the supporting argument for that... https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-define-outputs","poster":"T0p1cs","timestamp":"1569626280.0","upvote_count":"5"}],"content":"I think it is Stream Analytics and Data Lake","comment_id":"12967","timestamp":"1569626220.0","upvote_count":"19"},{"comment_id":"201918","content":"The solution should ingest the data from the IoT devices into a data warehouse\n• Azure Stream Analytics cannot ingest IoT Data on its own it need Iot Hub to do it .\n• Azure HDInsight cluster with kafka will work.\n• Azure data Factory will work if IoT devices are storing data local on prem data store and ADF can pull data form on prem data store and ingest to a data warehouse\n• Azure Batch cannot ingest IoT Data on its own.\n• Azure Data Lake is a scalable data storage and analytics service need some help to ingest IoT Data.","poster":"vilas94","timestamp":"1603012980.0","comments":[{"upvote_count":"5","comment_id":"287277","timestamp":"1612923000.0","poster":"Cornholioz","content":"Good stuff. But here's the issue:\n1. Question says \"Each correct answer presents part of the solution\", while you are looking at each solution to independently solve the case.\n2. I don't understand what this entails: \"The devices present status and trending data on a dashboard\". Should the solution account for a tech that can output to a dashboard such as Power BI? Unclear.\n\nIn fact, \"ingesting data\" from IoT Devices is not possible with any of these. It needs IoT Hub, Event Hub etc. or Streaming services such as Kafka or Akka.\n\nLooks like this question was framed by a 6-yr old!"}],"upvote_count":"8"},{"comment_id":"928226","timestamp":"1687245060.0","poster":"rveney","content":"A. Azure Stream Analytics\nB. Azure Data Factory\n\nExplanation:\n\nA. Azure Stream Analytics:\nAzure Stream Analytics is a real-time analytics and event processing service in Azure. It is designed to handle streaming data from various sources, such as IoT devices, and process it in real-time. You can use Azure Stream Analytics to ingest data from the IoT devices as it streams in, perform real-time analytics, filtering, aggregation, and transformation, and then load the processed data into a data warehouse.\n\nB. Azure Data Factory:\nAzure Data Factory is a cloud-based data integration service that enables you to orchestrate and automate the movement and transformation of data across various data sources and destinations. With Azure Data Factory, you can create data pipelines to ingest data from different sources, including IoT devices, and then load it into your data warehouse. It provides","upvote_count":"1"},{"poster":"gctejwani","timestamp":"1615267800.0","upvote_count":"1","content":"I think ans is correct.\n\nWith Azure Data Lake Store (ADLS) serving as the hyper-scale storage layer and HDInsight serving as the Hadoop-based compute engine services. It can be used for prepping large amounts of data for insertion into a Data Warehouse","comment_id":"306141"},{"content":"It' A & E as below.\nhttps://docs.microsoft.com/en-us/azure/architecture/reference-architectures/iot","poster":"blackdeath","comment_id":"235545","timestamp":"1607159820.0","upvote_count":"1"},{"upvote_count":"3","content":"should be A and E since the data trends gonna show on a dashboard but HDInsight can not output to powerbi. refer:https://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/stream-processing","timestamp":"1597445340.0","poster":"magic22cn","comment_id":"158350"},{"poster":"damirbek369","upvote_count":"2","comment_id":"112299","content":"I also believe the answer is Stream Analytics and Data Lake. https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-define-outputs","timestamp":"1592384760.0"},{"timestamp":"1588576980.0","upvote_count":"1","content":"i think this solution requires a lambda architecture\ndashboard to monitor devices mean we need real time processing i.e. Azure Stream Analytics, however not all data requires real time processing ,some data may need further processing, that's when we need Azure Data Lake to store data for further processing or just initial batch processing","comment_id":"83487","poster":"abbam"},{"timestamp":"1587460680.0","comment_id":"77368","poster":"Atanu","upvote_count":"5","content":"A and E"},{"comment_id":"67073","timestamp":"1584908100.0","poster":"putriafebriana","content":"You can use Hive to output data to a variety of targets including:\nA relational database, such as SQL Server or AzureSQL Database.\nA data warehouse, such as AzureSQL Data Warehouse.\nso, also correct that Azure HDInsight is included","upvote_count":"1"},{"upvote_count":"1","content":"I believe it should be stream analytics and an HDInsights cluster.","timestamp":"1565366760.0","comments":[{"upvote_count":"7","content":"Stream Analytics would be the answer IF there was any pre-processing involved. There is none that can be inferred from the Question statement, hence ADL might be more correct.","comment_id":"9179","poster":"Bharat","timestamp":"1567325820.0"}],"comment_id":"6401","poster":"exam_taker5"}],"question_id":87,"question_text":"Your company has factories in 10 countries. Each factory contains several thousand IoT devices.\nThe devices present status and trending data on a dashboard.\nYou need to ingest the data from the IoT devices into a data warehouse.\nWhich two Microsoft Azure technologies should you use? Each correct answer presents part of the solution.\nNOTE: Each correct selection is worth one point.","timestamp":"2019-08-09 18:06:00","answer_ET":"CE","url":"https://www.examtopics.com/discussions/microsoft/view/3402-exam-ai-100-topic-2-question-45-discussion/","exam_id":39,"unix_timestamp":1565366760,"answer":"CE"},{"id":"Ck3PLRcRvaYPi1JuS3FG","answer_images":[],"discussion":[{"timestamp":"1687245120.0","content":"To comply with your company's policy of storing all data used by the bot in the on-premises network, the most suitable recommendation for a compute solution to support the planned bot would be:\n\nB. a Docker container\n\nExplanation:\n\nA Docker container provides a lightweight and portable runtime environment that can be deployed on-premises. By packaging the bot and its dependencies into a Docker container, you can ensure that the bot's compute resources are isolated and can be deployed and run within your on-premises network.","upvote_count":"1","comment_id":"928227","poster":"rveney"},{"upvote_count":"1","poster":"renuka1234","timestamp":"1613997600.0","content":"Answer is correct. \nFor More information https://docs.microsoft.com/en-us/azure/cognitive-services/cognitive-services-container-support","comment_id":"296639"}],"answer_description":"You can deploy LUIS on-premise as Docker Image in a container.\nNote: Azure Cognitive LUIS service can be deployed on any hardware or on any host (Linus, Windows and IOS). This feature allows enterprises to quickly train the LUIS model on the cloud and deploy it anywhere which makes Cognitive services to be available truly to every person and every Organization -\nג€Democratizing AIג€.\nReference:\nhttps://www.linkedin.com/pulse/deploying-microsoft-azure-cognitive-luis-service-on-premise-s","question_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/45416-exam-ai-100-topic-2-question-46-discussion/","question_id":88,"choices":{"A":"an Azure Databricks cluster","B":"a Docker container","C":"Microsoft Machine Learning Server","D":"the Azure Machine Learning service"},"unix_timestamp":1613997600,"question_text":"You plan to deploy a bot that will use the following Azure Cognitive Services:\n✑ Language Understanding (LUIS)\n✑ Text Analytics\nYour company's compliance policy states that all data used by the bot must be stored in the on-premises network.\nYou need to recommend a compute solution to support the planned bot.\nWhat should you include in the recommendation?","topic":"2","timestamp":"2021-02-22 13:40:00","exam_id":39,"answers_community":[],"isMC":true,"answer_ET":"B","answer":"B"},{"id":"7NQYovLsXxRn0WbcdUT7","answers_community":[],"question_id":89,"question_images":["https://www.examtopics.com/assets/media/exam-media/03857/0011500001.png"],"discussion":[{"content":"Looks right.\nFirst uses in-built Date entity. Second is a list of movies and hence Simple entity. The last one consists of multiple entities (tickets, location), hence composite.","upvote_count":"2","comment_id":"390729","timestamp":"1624647840.0","poster":"kolakone"}],"answer_images":["https://www.examtopics.com/assets/media/exam-media/03857/0011600001.png"],"exam_id":39,"url":"https://www.examtopics.com/discussions/microsoft/view/56079-exam-ai-100-topic-2-question-47-discussion/","topic":"2","timestamp":"2021-06-25 21:04:00","question_text":"HOTSPOT -\nYour company is building a cinema chatbot by using the Bot Framework and Language Understanding (LUIS).\nYou are designing of the intents and the entities for LUIS.\nThe following are utterances that customers might provide:\n✑ Which movies are playing on December 8?\n✑ What time is the performance of Movie1?\n✑ I would like to purchase two adult tickets in the balcony section for Movie2.\nYou need to identify which entity types to use. The solution must minimize development effort.\nWhich entry type should you use for each entity? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","answer":"","answer_description":"Box 1: Prebuilt -\nDatetime is prebuilt.\nLanguage Understanding (LUIS) provides prebuilt entities. When a prebuilt entity is included in your application, LUIS includes the corresponding entity prediction in the endpoint response.\n\nBox 2: Simple -\n\nBox 3: Composite -\nA composite entity is made up of other entities, such as prebuilt entities, simple, regular expression, and list entities. The separate entities form a whole entity.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/luis/luis-reference-prebuilt-entities https://docs.microsoft.com/en-us/azure/cognitive-services/luis/reference-entity-composite","isMC":false,"unix_timestamp":1624647840,"answer_ET":""},{"id":"Sx8siSZhS4O971Z4l3pR","question_id":90,"answer_description":"Use the Reader role on the bot service to limit access and scope.\nNote: Access management for cloud resources is a critical function for any organization that is using the cloud. Azure role-based access control (Azure RBAC) helps you manage who has access to Azure resources, what they can do with those resources, and what areas they have access to.\nAzure includes several built-in roles that you can use. The Reader Role can view existing Azure resources.\nScope is the set of resources that the access applies to. When you assign a role, you can further limit the actions allowed by defining a scope. In Azure, you can specify a scope at multiple levels: management group, subscription, resource group, or resource.\nReference:\nhttps://docs.microsoft.com/en-us/azure/role-based-access-control/overview","exam_id":39,"isMC":true,"timestamp":"2021-03-19 21:47:00","answer_images":[],"question_text":"Your company uses several bots. The bots use Azure Bot Service.\nSeveral users report that some of the bots fail to return the expected results.\nYou plan to view the service health of the bot service.\nYou need to request the appropriate role to access the service health of the bot service. The solution must use the principle of least privilege.\nWhich role should you request?","unix_timestamp":1616186820,"topic":"2","answers_community":[],"url":"https://www.examtopics.com/discussions/microsoft/view/47769-exam-ai-100-topic-2-question-48-discussion/","question_images":[],"answer":"B","discussion":[{"poster":"rveney","timestamp":"1687246260.0","content":"To access the service health of the Azure Bot Service while following the principle of least privilege, you should request the following role:\n\nB. The Reader role on the bot service\n\nExplanation:\n\nThe Reader role on the bot service provides read-only access to the specific Azure Bot Service instance. This role allows you to view the service health and related information without the ability to make any changes or modifications to the service.","upvote_count":"1","comment_id":"928240"},{"comment_id":"315153","timestamp":"1616186820.0","poster":"Nickname__for__discussions","upvote_count":"4","content":"correct"}],"answer_ET":"B","choices":{"B":"The Reader role on the bot service","C":"The Owner role on the bot service","A":"The Contributor role on the Azure subscription","D":"The Reader role on the Azure subscription"}}],"exam":{"provider":"Microsoft","isMCOnly":false,"numberOfQuestions":206,"lastUpdated":"12 Apr 2025","name":"AI-100","isBeta":false,"id":39,"isImplemented":true},"currentPage":18},"__N_SSP":true}