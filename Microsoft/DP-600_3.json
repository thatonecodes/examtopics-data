{"pageProps":{"questions":[{"id":"ldX9DLMuLEucaTO0jR93","answer_description":"","url":"https://www.examtopics.com/discussions/microsoft/view/138108-exam-dp-600-topic-1-question-108-discussion/","answer_images":[],"isMC":true,"answer_ET":"A","choices":{"A":"Yes","B":"No"},"discussion":[{"comment_id":"1220993","content":"Selected Answer: A\nThe original query uses the COUNTROWS function inside a CALCULATE function to count the number of rows in the 'Order Item' table. This approach can be inefficient because it involves counting rows even if just one row exists, which might be resource-intensive especially with large datasets.\n\nThe suggested solution NOT ISEMPTY ( CALCULATETABLE ( 'Order Item' ) ) simplifies the logic to check if the 'Order Item' table related to the customer is empty or not. This approach can be faster as it stops as soon as it finds one row, rather than counting all rows.","upvote_count":"11","timestamp":"1732895340.0","poster":"282b85d"},{"timestamp":"1734973620.0","comment_id":"1330886","poster":"nappi1","comments":[{"comment_id":"1330888","timestamp":"1734973680.0","content":"as shown in DAX Studio under \"Server Timings\" --> \"Query\".","poster":"nappi1","upvote_count":"1"}],"content":"Selected Answer: A\nThinking about the option in SQL-like terms, we filter out the customers without the need for an aggregation step, but by using a boolean condition after a join. Aggregations are generally one of the most computationally intensive operations, so I expect the performance to diverge as the fact table grows.\nIndeed, when running the DAX code, the SQL queries executed by the PBI engine underneath are:\n\n***DAX\nCALCULATE( COUNTROWS( Sales ) ) > 0\n\n***SQL\nSELECT\n 'Customer'[Customer Name],\n COUNT ( )\nFROM 'Order Item'\n LEFT OUTER JOIN 'Customer'\n ON 'Order Item'[CustomerKey]='Customer'[CustomerKey];\n\n\n***DAX\nNOT ISEMPTY( CALCULATETABLE( Sales ) )\n\n***SQL\nSELECT\n 'Customer'[Customer Name]\nFROM 'Order Item'\n LEFT OUTER JOIN 'Customer'\n ON 'Order Item'[CustomerKey]='Customer'[CustomerKey];","upvote_count":"1"},{"poster":"stilferx","timestamp":"1731463560.0","upvote_count":"1","comment_id":"1210459","content":"IMHO, YES, \n\nBecause IS NOT EMPTY replicates the logic"},{"comment_id":"1208224","timestamp":"1731055740.0","upvote_count":"3","poster":"bigdave987","content":"Selected Answer: A\nYes. Answer is correct.\nCALCULATETABLE will accept the row context for each of the rows returned by VALUES, and in turn NOT ISEMPTY will check if the calculated table has rows. This is like using EXISTS in T-SQL. It will check if any rows exists, but doesn't return rows, thus improving performance."},{"comment_id":"1205742","poster":"klashxx","content":"A — The proposed solution improves efficiency by reducing the number of calculations required. Instead of counting all the rows for each customer and then checking if the count is greater than zero, it simply checks if there are any rows at all, which requires fewer computational resources and execution time","timestamp":"1730575200.0","upvote_count":"1"},{"content":"Selected Answer: A\nIt's correct, it returns the ones with values (not isempty).","poster":"dp600","comment_id":"1203516","upvote_count":"2","timestamp":"1730118360.0"},{"comments":[{"comment_id":"1203326","timestamp":"1730081760.0","upvote_count":"1","poster":"Test_1132","content":"oh nvm it is count LOL Sorry"}],"comment_id":"1203325","poster":"Test_1132","content":"what if order item is negative?","upvote_count":"1","timestamp":"1730081700.0"},{"content":"Selected Answer: A\nYes, replacing CALCULATE ( COUNTROWS( 'Order Item' ) ) > 0 with NOT ISEMPTY ( CALCULATETABLE ( 'Order Item ' ) ) should reduce the execution time of the query. It is a simpler, more meaningful, and faster way to check if a table is empty. https://www.sqlbi.com/articles/check-empty-table-condition-with-dax/","poster":"hello2tomoki","comment_id":"1200957","upvote_count":"4","timestamp":"1729713060.0"},{"comment_id":"1199866","upvote_count":"2","poster":"andrewkravchuk97","content":"answer is correct. its faster because it only needs to check if at least one row exists that meets the filter criteria, rather than counting all rows that do.","timestamp":"1729554540.0"},{"upvote_count":"4","comment_id":"1191244","content":"Selected Answer: B\nisnt the syntax incorrect? \nNOT(ISEMPTY(Calculate ... \n\nthere should be a ( after NOT","timestamp":"1728342480.0","comments":[{"poster":"nappi1","content":"NOT in DAX can be used without parenthesis. \nNOT ISEMPTY() = NOT(ISEMPTY)\nas well as TRUE = TRUE()","upvote_count":"1","timestamp":"1734963420.0","comment_id":"1330833"},{"timestamp":"1728342480.0","content":"https://learn.microsoft.com/en-us/dax/isempty-function-dax#example","comment_id":"1191245","upvote_count":"2","poster":"neoverma"},{"poster":"Lucetmi","comment_id":"1198422","timestamp":"1729325100.0","upvote_count":"1","content":"It's not mandatory, so I'd answer Yes. \nPs: CALCULATETABLE triggers context transition so it's crucial to use it this example."}],"poster":"neoverma"}],"answers_community":["A (84%)","B (16%)"],"topic":"1","answer":"A","question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou have a Fabric tenant that contains a semantic model named Model1.\n\nYou discover that the following query performs slowly against Model1.\n\n//IMG//\n\n\nYou need to reduce the execution time of the query.\n\nSolution: You replace line 4 by using the following code:\n\nNOT ISEMPTY ( CALCULATETABLE ( 'Order Item ' ) )\n\nDoes this meet the goal?","exam_id":71,"question_images":["https://img.examtopics.com/dp-600/image126.png"],"question_id":11,"timestamp":"2024-04-08 01:08:00","unix_timestamp":1712531280},{"id":"YAabezaFm4xbucip8jUP","exam_id":71,"question_images":["https://img.examtopics.com/dp-600/image126.png"],"timestamp":"2024-04-24 19:16:00","unix_timestamp":1713978960,"isMC":true,"url":"https://www.examtopics.com/discussions/microsoft/view/139526-exam-dp-600-topic-1-question-109-discussion/","answer_ET":"B","discussion":[{"poster":"Test_1132","upvote_count":"13","timestamp":"1714313700.0","comment_id":"1203598","content":"No - Good luck everyone :)"},{"comment_id":"1220997","timestamp":"1716990660.0","content":"Selected Answer: B\nThe provided solution does not meet the goal as it does not correctly filter out customers without orders and does not provide an optimization in terms of performance.","poster":"282b85d","upvote_count":"8"},{"poster":"Mitchell12345","upvote_count":"3","content":"Well, we made it boys!","comment_id":"1281647","timestamp":"1725982440.0"},{"poster":"b6daab0","comment_id":"1234031","timestamp":"1718918400.0","content":"A silly question..","upvote_count":"4"},{"upvote_count":"3","poster":"stilferx","comment_id":"1210460","content":"Selected Answer: B\nIMHO, NO, as below in comments","timestamp":"1715558820.0"},{"upvote_count":"3","content":"Selected Answer: B\nNo, adding the = does not improve performance.","timestamp":"1715150460.0","comment_id":"1208217","poster":"bigdave987"},{"upvote_count":"4","timestamp":"1713978960.0","poster":"VAzureD","content":"Selected Answer: B\nNo.\nBy adding the = the only thing we achieve is changing the logic, not the performance.","comment_id":"1201535"}],"topic":"1","answers_community":["B (100%)"],"answer_images":[],"answer_description":"","choices":{"B":"No","A":"Yes"},"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou have a Fabric tenant that contains a semantic model named Model1.\n\nYou discover that the following query performs slowly against Model1.\n\n//IMG//\n\n\nYou need to reduce the execution time of the query.\n\nSolution: You replace line 4 by using the following code:\n\nCALCULATE ( COUNTROWS ( 'Order Item' ) ) >= 0\n\nDoes this meet the goal?","question_id":12,"answer":"B"},{"id":"fjaoLC1jciTK7Szyj2b5","question_images":["https://img.examtopics.com/dp-600/image18.png"],"answer_description":"","unix_timestamp":1707746640,"answer_images":[],"topic":"1","question_text":"HOTSPOT -\nYou have a data warehouse that contains a table named Stage.Customers. Stage.Customers contains all the customer record updates from a customer relationship management (CRM) system. There can be multiple updates per customer.\nYou need to write a T-SQL query that will return the customer ID, name. postal code, and the last updated time of the most recent row for each customer ID.\nHow should you complete the code? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\n//IMG//","exam_id":71,"question_id":13,"timestamp":"2024-02-12 15:04:00","discussion":[{"upvote_count":"34","comments":[{"comment_id":"1305452","poster":"semauni","content":"Thanks, this makes sense. I was already wondering where the X was coming from, it appears part of the syntax is missing in the question.","timestamp":"1730380860.0","upvote_count":"2","comments":[{"content":"In the CTE, the X = is assigning the alias \"X\" to the value returned from the ROW_NUMBER statement. It's the same as using \"AS X\" to assign an alias.","upvote_count":"1","timestamp":"1733857440.0","comment_id":"1324715","poster":"AdventureChick"}]}],"comment_id":"1148170","poster":"R3D_ENGINEER","content":"The correct query is:\nWITH CUSTOMERBASE AS (\n SELECT CustomerID, CustomerName, PostalCode, LastUpdated,\n ROW_NUMBER() OVER(PARTITION BY CustomerID ORDER BY LastUpdated DESC) as X\n FROM LakehousePOC.dbo.CustomerChanges\n )\n\nSELECT CustomerID, CustomerName, PostalCode, LastUpdated\nFROM CUSTOMERBASE\nWHERE X = 1","timestamp":"1707746640.0"},{"upvote_count":"14","poster":"varun_r","timestamp":"1710468420.0","comment_id":"1173966","content":"Answer is RowNumber and X=1 -- No Brainer"},{"content":"calm down guys, the given answer is correct!","comment_id":"1363637","poster":"rohitrc8521","upvote_count":"1","timestamp":"1740846000.0"},{"poster":"Rakesh16","upvote_count":"1","comment_id":"1312425","timestamp":"1731650160.0","content":"ROW_NUMBER() and where X=1"},{"content":"ROW_NUMBER(), WHERE X =1","poster":"jass007_k","comment_id":"1303296","upvote_count":"1","timestamp":"1729950960.0"},{"timestamp":"1721316900.0","content":"The answer is correct \n RowNumber and X=1","comment_id":"1250514","upvote_count":"1","poster":"7d97b62"},{"poster":"Darshan6232","content":"Its straight forwarded. Provided answer is correct.","comment_id":"1227087","upvote_count":"1","timestamp":"1717913640.0"},{"content":"IMHO,\n1. Row_Number()\n2. x = 1\n\nIt is a typical pattern. We are numerating by desc, and then filtering the first one (actually the last because of DESC order)","timestamp":"1715118660.0","poster":"stilferx","comment_id":"1208053","upvote_count":"3"},{"content":"ROW_NUMBER() + X = 1","timestamp":"1708876320.0","poster":"TashaP","comment_id":"1158930","upvote_count":"5"},{"comment_id":"1155372","timestamp":"1708505160.0","poster":"David_Webb","content":"First drop-down box: ROW_NUMBER()\nSecond drop-down box: WHERE X = 1 \nAs ORDER BY LastUpdated DESC was used, the first row will be the most recent row.","upvote_count":"5"},{"timestamp":"1708206900.0","comment_id":"1152856","content":"Row_number\nX=1\n\nRow_number give row position and start from 1","poster":"Momoanwar","upvote_count":"5"}],"answer_ET":"Box 1: ROW_NUMBER()\nBox 2: WHERE X = 1","url":"https://www.examtopics.com/discussions/microsoft/view/133613-exam-dp-600-topic-1-question-11-discussion/","isMC":false,"answer":"Box 1: ROW_NUMBER()\nBox 2: WHERE X = 1","answers_community":[]},{"id":"wGh8pZbGwFNWikuAjM6z","unix_timestamp":1730508540,"answer":"","question_id":14,"answers_community":[],"exam_id":71,"timestamp":"2024-11-02 01:49:00","topic":"1","isMC":false,"url":"https://www.examtopics.com/discussions/microsoft/view/150637-exam-dp-600-topic-1-question-110-discussion/","discussion":[{"timestamp":"1730508540.0","poster":"Jowalkr","upvote_count":"10","comment_id":"1306028","content":"Correct. Delta & Tables/ProductLine2."}],"answer_ET":"","answer_description":"","answer_images":["https://img.examtopics.com/dp-600/image128.png"],"question_images":["https://img.examtopics.com/dp-600/image127.png"],"question_text":"HOTSPOT\n-\n\n\nCase study\n-\n\nThis is a case study. Case studies are not timed separately. You can use as much exam time as you would like to complete each case. However, there may be additional case studies and sections on this exam. You must manage your time to ensure that you are able to complete all questions included on this exam in the time provided.\n\nTo answer the questions included in a case study, you will need to reference information that is provided in the case study. Case studies might contain exhibits and other resources that provide more information about the scenario that is described in the case study. Each question is independent of the other questions in this case study.\n\nAt the end of this case study, a review screen will appear. This screen allows you to review your answers and to make changes before you move to the next section of the exam. After you begin a new section, you cannot return to this section.\n\n\nTo start the case study\n-\nTo display the first question in this case study, click the Next button. Use the buttons in the left pane to explore the content of the case study before you answer the questions. Clicking these buttons displays information such as business requirements, existing environment, and problem statements. If the case study has an All Information tab, note that the information displayed is identical to the information displayed on the subsequent tabs. When you are ready to answer a question, click the Question button to return to the question.\n\n\nOverview\n-\n\nContoso, Ltd. is a US-based health supplements company. Contoso has two divisions named Sales and Research. The Sales division contains two departments named Online Sales and Retail Sales. The Research division assigns internally developed product lines to individual teams of researchers and analysts.\n\n\nExisting Environment\n-\n\n\nIdentity Environment\n-\n\nContoso has a Microsoft Entra tenant named contoso.com. The tenant contains two groups named ResearchReviewersGroup1 and ResearchReviewersGroup2.\n\n\nData Environment\n-\n\nContoso has the following data environment:\n\n• The Sales division uses a Microsoft Power BI Premium capacity.\n• The semantic model of the Online Sales department includes a fact table named Orders that uses Import made. In the system of origin, the OrderID value represents the sequence in which orders are created.\n• The Research department uses an on-premises, third-party data warehousing product.\n• Fabric is enabled for contoso.com.\n• An Azure Data Lake Storage Gen2 storage account named storage1 contains Research division data for a product line named Productline1. The data is in the delta format.\n• A Data Lake Storage Gen2 storage account named storage2 contains Research division data for a product line named Productline2. The data is in the CSV format.\n\n\nRequirements\n-\n\n\nPlanned Changes\n-\n\nContoso plans to make the following changes:\n\n• Enable support for Fabric in the Power BI Premium capacity used by the Sales division.\n• Make all the data for the Sales division and the Research division available in Fabric.\n• For the Research division, create two Fabric workspaces named Productline1ws and Productline2ws.\n• In Productline1ws, create a lakehouse named Lakehouse1.\n• In Lakehouse1, create a shortcut to storage1 named ResearchProduct.\n\n\nData Analytics Requirements\n-\n\nContoso identifies the following data analytics requirements:\n\n• All the workspaces for the Sales division and the Research division must support all Fabric experiences.\n• The Research division workspaces must use a dedicated, on-demand capacity that has per-minute billing.\n• The Research division workspaces must be grouped together logically to support OneLake data hub filtering based on the department name.\n• For the Research division workspaces, the members of ResearchReviewersGroup1 must be able to read lakehouse and warehouse data and shortcuts by using SQL endpoints.\n• For the Research division workspaces, the members of ResearchReviewersGroup2 must be able to read lakehouse data by using Lakehouse explorer.\n• All the semantic models and reports for the Research division must use version control that supports branching.\n\n\nData Preparation Requirements\n-\n\nContoso identifies the following data preparation requirements:\n\n• The Research division data for Productline1 must be retrieved from Lakehouse1 by using Fabric notebooks.\n• All the Research division data in the lakehouses must be presented as managed tables in Lakehouse explorer.\n\n\nSemantic Model Requirements\n-\n\nContoso identifies the following requirements for implementing and managing semantic models:\n\n• The number of rows added to the Orders table during refreshes must be minimized.\n• The semantic models in the Research division workspaces must use Direct Lake mode.\n\n\nGeneral Requirements\n-\n\nContoso identifies the following high-level requirements that must be considered for all solutions:\n\n• Follow the principle of least privilege when applicable.\n• Minimize implementation and maintenance effort when possible.\n\n\nYou need to migrate the Research division data for Productline2. The solution must meet the data preparation requirements.\n\nHow should you complete the code? To answer, select the appropriate options in the answer area.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//"},{"id":"BjA3PpaEgWbV6SU4gDXA","discussion":[{"timestamp":"1743337920.0","upvote_count":"1","poster":"4e5cf3d","comment_id":"1412393","content":"Selected Answer: B\nA is wrong: Table not Files"},{"upvote_count":"1","poster":"jackjack1","comment_id":"1341221","content":"Selected Answer: A\nShortcut hasn't been created yet, don't think B would be correct for that reason.","timestamp":"1736968260.0"},{"timestamp":"1736096400.0","upvote_count":"1","poster":"pk07","comment_id":"1336819","content":"Selected Answer: A\nThe key change is understanding that shortcuts do not behave like managed tables in Spark SQL. To read data from a shortcut you need to use spark.read.format and use Files/ path, since it's a shortcut it behaves like a file in the filesystem.\n\nCorrected Answer:\n\nA. spark.read.format(\"delta\").load(\"Files/ResearchProduct\")"},{"poster":"f0dd605","upvote_count":"3","timestamp":"1735393800.0","comment_id":"1332981","content":"Selected Answer: A\nA according to ChatGPT:\nThe question requires accessing Research division data for Productline1 stored in delta format from the lakehouse (Lakehouse1) in a Fabric notebook. Here’s why option A is the correct choice:\n\nDelta Format Access in Spark:\nThe data for Productline1 is stored in Delta format, as per the scenario.\nWhen working with Delta format in Spark notebooks, the standard way to read data is using spark.read.format(\"delta\").load(<path>).\nFiles/ResearchProduct Path:\n\nA shortcut named ResearchProduct has been created in Lakehouse1. In Microsoft Fabric, the Files/ResearchProduct path refers to the shortcut to the Delta Lake storage (storage1), which makes the data available within the lakehouse."},{"poster":"MAKI911","timestamp":"1735274640.0","upvote_count":"3","comment_id":"1332226","content":"Selected Answer: A\nThe main reason why options B and C are incorrect is that they assume “ResearchProduct” has already been registered as a table in Lakehouse1. In this scenario, however, “ResearchProduct” is simply a shortcut (folder) pointing to Delta files. Because no managed table has been created for that folder yet, you cannot use SQL syntax like\n• spark.sql(\"SELECT * FROM Lakehouse1.ResearchProduct\") or\n• spark.sql(\"SELECT * FROM Lakehouse1.Tables.ResearchProduct\")\nto query the data.\nInstead, you must read directly from the underlying Delta files by referencing the “Files/ResearchProduct” path. That is why option A (spark.read.format(\"delta\").load(\"Files/ResearchProduct\")) is the correct choice in a Fabric notebook."},{"poster":"4b35503","comment_id":"1325592","upvote_count":"3","timestamp":"1734005880.0","content":"Selected Answer: B\nREF https://learn.microsoft.com/en-us/fabric/onelake/access-onelake-shortcuts\n\nCorrect Sintax\nspark.sql(\"SELECT * FROM <LH>.<Shortcut_Name>\")"},{"timestamp":"1733846040.0","poster":"RickyK","comment_id":"1324636","upvote_count":"1","content":"Selected Answer: C\nIf the requirement is \"For the Research division workspaces, the members of ResearchReviewersGroup1 must be able to read lakehouse and warehouse data and shortcuts by using SQL endpoints\" then the shortcut would need to be created in the \"Tables\" section."},{"poster":"chq23","upvote_count":"3","timestamp":"1732862880.0","comment_id":"1319582","content":"Selected Answer: B\nResearchProduct is a shortcut"},{"comment_id":"1306275","content":"Since the file is in Delta format, it should be a straight forward read and I think the answer should be A.","upvote_count":"1","timestamp":"1730571420.0","poster":"Jowalkr"}],"answer":"A","topic":"1","question_text":"Case study -\n\nThis is a case study. Case studies are not timed separately. You can use as much exam time as you would like to complete each case. However, there may be additional case studies and sections on this exam. You must manage your time to ensure that you are able to complete all questions included on this exam in the time provided.\n\nTo answer the questions included in a case study, you will need to reference information that is provided in the case study. Case studies might contain exhibits and other resources that provide more information about the scenario that is described in the case study. Each question is independent of the other questions in this case study.\n\nAt the end of this case study, a review screen will appear. This screen allows you to review your answers and to make changes before you move to the next section of the exam. After you begin a new section, you cannot return to this section.\n\n\nTo start the case study -\nTo display the first question in this case study, click the Next button. Use the buttons in the left pane to explore the content of the case study before you answer the questions. Clicking these buttons displays information such as business requirements, existing environment, and problem statements. If the case study has an All Information tab, note that the information displayed is identical to the information displayed on the subsequent tabs. When you are ready to answer a question, click the Question button to return to the question.\n\n\nOverview -\n\nContoso, Ltd. is a US-based health supplements company. Contoso has two divisions named Sales and Research. The Sales division contains two departments named Online Sales and Retail Sales. The Research division assigns internally developed product lines to individual teams of researchers and analysts.\n\n\nExisting Environment -\n\n\nIdentity Environment -\n\nContoso has a Microsoft Entra tenant named contoso.com. The tenant contains two groups named ResearchReviewersGroup1 and ResearchReviewersGroup2.\n\n\nData Environment -\n\nContoso has the following data environment:\n\n• The Sales division uses a Microsoft Power BI Premium capacity.\n• The semantic model of the Online Sales department includes a fact table named Orders that uses Import made. In the system of origin, the OrderID value represents the sequence in which orders are created.\n• The Research department uses an on-premises, third-party data warehousing product.\n• Fabric is enabled for contoso.com.\n• An Azure Data Lake Storage Gen2 storage account named storage1 contains Research division data for a product line named Productline1. The data is in the delta format.\n• A Data Lake Storage Gen2 storage account named storage2 contains Research division data for a product line named Productline2. The data is in the CSV format.\n\n\nRequirements -\n\n\nPlanned Changes -\n\nContoso plans to make the following changes:\n\n• Enable support for Fabric in the Power BI Premium capacity used by the Sales division.\n• Make all the data for the Sales division and the Research division available in Fabric.\n• For the Research division, create two Fabric workspaces named Productline1ws and Productline2ws.\n• In Productline1ws, create a lakehouse named Lakehouse1.\n• In Lakehouse1, create a shortcut to storage1 named ResearchProduct.\n\n\nData Analytics Requirements -\n\nContoso identifies the following data analytics requirements:\n\n• All the workspaces for the Sales division and the Research division must support all Fabric experiences.\n• The Research division workspaces must use a dedicated, on-demand capacity that has per-minute billing.\n• The Research division workspaces must be grouped together logically to support OneLake data hub filtering based on the department name.\n• For the Research division workspaces, the members of ResearchReviewersGroup1 must be able to read lakehouse and warehouse data and shortcuts by using SQL endpoints.\n• For the Research division workspaces, the members of ResearchReviewersGroup2 must be able to read lakehouse data by using Lakehouse explorer.\n• All the semantic models and reports for the Research division must use version control that supports branching.\n\n\nData Preparation Requirements -\n\nContoso identifies the following data preparation requirements:\n\n• The Research division data for Productline1 must be retrieved from Lakehouse1 by using Fabric notebooks.\n• All the Research division data in the lakehouses must be presented as managed tables in Lakehouse explorer.\n\n\nSemantic Model Requirements -\n\nContoso identifies the following requirements for implementing and managing semantic models:\n\n• The number of rows added to the Orders table during refreshes must be minimized.\n• The semantic models in the Research division workspaces must use Direct Lake mode.\n\n\nGeneral Requirements -\n\nContoso identifies the following high-level requirements that must be considered for all solutions:\n\n• Follow the principle of least privilege when applicable.\n• Minimize implementation and maintenance effort when possible.\n\n\nWhich syntax should you use in a notebook to access the Research division data for Productline1?","exam_id":71,"answer_ET":"A","answer_description":"","answer_images":[],"answers_community":["A (50%)","B (44%)","6%"],"choices":{"D":"external_table(ResearchProduct)","A":"spark.read.format(“delta”).load(“Files/ResearchProduct”)","C":"spark.sql(“SELECT * FROM Lakehouse1.Tables.ResearchProduct ”)","B":"spark.sql(“SELECT * FROM Lakehouse1.ResearchProduct ”)"},"unix_timestamp":1730571420,"url":"https://www.examtopics.com/discussions/microsoft/view/150649-exam-dp-600-topic-1-question-111-discussion/","timestamp":"2024-11-02 19:17:00","isMC":true,"question_images":[],"question_id":15}],"exam":{"isMCOnly":false,"lastUpdated":"12 Apr 2025","id":71,"isBeta":false,"numberOfQuestions":179,"isImplemented":true,"provider":"Microsoft","name":"DP-600"},"currentPage":3},"__N_SSP":true}