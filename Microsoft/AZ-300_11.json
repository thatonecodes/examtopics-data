{"pageProps":{"questions":[{"id":"TZvVV1Z2nw3QDLScw05r","question_id":51,"exam_id":50,"answers_community":[],"answer_images":[],"answer":"A","question_text":"You have an Azure subscription that contains two storage accounts named storagecontoso1 and storagecontoso2. Each storage account contains a queue service, a table service, and a blob service.\nYou develop two apps named App1 and App2. You need to configure the apps to store different types of data to all the storage services on both the storage accounts.\nHow many endpoints should you configure for each app?","isMC":true,"url":"https://www.examtopics.com/discussions/microsoft/view/6893-exam-az-300-topic-1-question-55-discussion/","unix_timestamp":1571667060,"topic":"1","choices":{"D":"12","B":"3","A":"2","C":"6"},"timestamp":"2019-10-21 16:11:00","discussion":[{"comments":[{"poster":"dayakadam","comments":[{"content":"You need to configure the apps to store different types of data to all the storage services on *both* the storage accounts - so answer is 6 not 3. Hence C is correct","comment_id":"130919","timestamp":"1594320840.0","upvote_count":"2","poster":"unknown4noone"}],"timestamp":"1589750340.0","upvote_count":"8","content":"Question is \"for each app\"","comment_id":"90857"},{"upvote_count":"5","comment_id":"96174","comments":[{"upvote_count":"1","poster":"rupayan87","comment_id":"722518","timestamp":"1668938760.0","content":"question is for each app"}],"poster":"jivom","content":"3 endpoints for each storage account are required so answer B.","timestamp":"1590504480.0"},{"content":"Agree with Ekramy. Correct answer is C - 6 end points.","poster":"praveen97","timestamp":"1595469120.0","upvote_count":"1","comment_id":"141541"},{"upvote_count":"1","content":"need 6 endpoints that right, 上面提到的http://***is auto config by azure after config the endpoints.\nquestion is how many should you config, answer is 2,one account need one.","poster":"chenzhe8395","timestamp":"1598188740.0","comment_id":"164411"}],"content":"The combination of the unique account name and the Azure Storage service endpoint forms the endpoints for your storage account.\n\nFor example, if your storage account is named mystorageaccount, then the default endpoints for that account are:\nBlob storage: http://mystorageaccount.blob.core.windows.net\nTable storage: http://mystorageaccount.table.core.windows.net\nQueue storage: http://mystorageaccount.queue.core.windows.net\nAzure Files: http://mystorageaccount.file.core.windows.net\n\nBased on that, you will need 6 endpoints as we have 2 different storage accounts, and each has 3 storage types.\n\nSo correct answer is : C","poster":"Ekramy_Elnaggar","timestamp":"1576328820.0","comment_id":"29561","upvote_count":"55"},{"comment_id":"19268","timestamp":"1572934080.0","comments":[{"comments":[{"timestamp":"1575961860.0","comment_id":"28491","content":"But if its not an Endpoint then its just a public connection. The questions ask for endpoints.","upvote_count":"1","poster":"chris46"}],"timestamp":"1574792460.0","upvote_count":"3","content":"The question doesn't say anything about secure access, so private endpoints is not requested as part of the solutions. Based on the lack of information in the question, the answer should be 2 (A).","comment_id":"24668","poster":"MarcoZ"}],"poster":"piotr","upvote_count":"31","content":"A is wrong, answer is C. Two storage accounts, each with 3 services (blob, file, table). Each app need to connect to all services on each account so total number is 6.\n\n\"You need a separate private endpoint for each storage service in a storage account that you need to access, namely Blobs, Data Lake Storage Gen2, Files, Queues, Tables, or Static Websites.\"\n\nhttps://docs.microsoft.com/en-us/azure/storage/common/storage-private-endpoints"},{"poster":"rupayan87","upvote_count":"1","content":"guys... it is asking how many end points which is either a service or private end point. To my knowledge we only open endpoint to the subnet either a private one or a service one(public IP based).\n\nBased on options available we consider two apps in two subnets then one endpoint for each subnet thats it.\ncorrect me if wrong.\nhttps://www.youtube.com/watch?v=4v-9zGHxVeI","timestamp":"1668977340.0","comment_id":"722998"},{"comment_id":"302018","timestamp":"1614692640.0","poster":"SriRamS","upvote_count":"1","content":"If they are talking about Service Endpoints, then you need one per subnet. So, assuming the 2 apps are in different V-Nets, the answer is 2.\n\nIf they are talking about Private Endpoints, then you need one per sub resource per subnet. So, 3 x 2 = 6."},{"poster":"azurecert2021","timestamp":"1610738520.0","content":"Answer 2 will be true only under the following assumptions which we can not hence asnwer is 6.\n1) Applications App1 and App2 reside in its own subnet/VNET (this is not stated in the question)\n2) Each VNET has Microsoft.storage endpoint enabled. (this will make 2 the correct answer)\n3) Each storage account is configured with the firewall to allow traffic for 2 VNETs\\subnet only.","upvote_count":"1","comment_id":"268206"},{"poster":"Kiwino","timestamp":"1600179600.0","content":"Guys, storage account name itself says it's account and not service. so I would definitely go with 6 end points","upvote_count":"3","comment_id":"179896"},{"comment_id":"167574","content":"Need more clarification on questions since services are changed now.\nIf it is private end points ... answer is 6. One each for service instance.\nIf it is service end points ... answer is 2. One service end point for each service (two storage accounts)","timestamp":"1598535180.0","upvote_count":"4","poster":"PANANI"},{"timestamp":"1595867580.0","content":"You need a separate private endpoint for each storage service in a storage account that you need to access, namely Blobs, Data Lake Storage Gen2, Files, Queues, Tables, or Static Websites. - So Answer is 6","poster":"aurora21","comment_id":"145142","upvote_count":"2"},{"comment_id":"140979","upvote_count":"4","poster":"zeelie","content":"so whats the correct answer so bloody confusing","timestamp":"1595404980.0"},{"timestamp":"1595339640.0","upvote_count":"1","content":"I believe this question is before private end point general availability hence it is asking service end points. So the answer is 2 endpoints per each APP. If it was private end points then it would be 8.","comment_id":"140348","comments":[{"timestamp":"1596810480.0","poster":"ercank","content":"correction: it should be 6 since 3 storage services only mentoned in the question","upvote_count":"1","comment_id":"152592"}],"poster":"ercank"},{"content":"The question is: How many endpoints should you configure ***for each app***?\nCorrect Answer is B","comments":[{"comments":[{"poster":"mackc13","upvote_count":"1","timestamp":"1595061300.0","comment_id":"137752","content":"there is two storage accounts. question mention that to configure different types of data to all storage services on both storage accounts.\n\nanswer is C, 6 endpoints per App."}],"content":"Indeed! It's asking how many endpoints for each app so the answer is 3!","timestamp":"1594878180.0","poster":"Duyons","comment_id":"136218","upvote_count":"1"}],"comment_id":"132358","timestamp":"1594502820.0","upvote_count":"6","poster":"Luiza"},{"comment_id":"130795","upvote_count":"1","poster":"dwild","content":"Answer 2x3 =6 \nYou need a separate private endpoint for each storage service in a storage account that you need to access, namely Blobs, Data Lake Storage Gen2, Files, Queues, Tables, or Static Websites.","timestamp":"1594312920.0"},{"upvote_count":"2","comments":[{"comment_id":"125297","upvote_count":"1","poster":"angelsrp","content":"In iaas you need 1 endpoint per subnet","timestamp":"1593734220.0"}],"poster":"angelsrp","timestamp":"1593734160.0","content":"I'll take ans A here, you only need to stablish 1 endpoint per storage acc if the app is delevoped in paas. In iaas you need 1.","comment_id":"125296"},{"poster":"tanito83","timestamp":"1593478620.0","content":"Gentlemen. The answer is B. Please, modify it.","comment_id":"123144","upvote_count":"2"},{"poster":"rkrau","comment_id":"112960","timestamp":"1592460060.0","upvote_count":"2","content":"sorry, my fault\nCorrect Answer is C=6"},{"content":"Private endpoints are mapped to a specific resource in Azure and not the entire service...\nhttps://docs.microsoft.com/en-us/azure/synapse-analytics/security/synapse-workspace-managed-private-endpoints\nCorrect Answer should be B=3","timestamp":"1592459700.0","comment_id":"112956","poster":"rkrau","upvote_count":"1"},{"upvote_count":"3","poster":"epomatti","timestamp":"1592346600.0","content":"\"A\" is correct, the problem is that the question means \"private\" endpoints that are created inside the Storage and assigned to each app, but doesn't make it clear.","comment_id":"111920"},{"comment_id":"106300","upvote_count":"1","content":"According to the link below, multiple storage accounts are accessible through a service endpoint -- if true, then answer A is valid.\nhttps://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-service-endpoint-policies-overview\nTrue or false? Regardless the question is ambiguous.","timestamp":"1591743060.0","poster":"tmurfet"},{"content":"Go to Access keys in Storage account .You can find Connection string as end point.\nConnection string is enough to access storage account.\nso for two storage account you need two end points.\nso Answer is A.2","timestamp":"1590894120.0","upvote_count":"3","comments":[{"comment_id":"105456","content":"Those are connection strings not endpoints. These are querystring parameters that are appended to the URL to permit access.","upvote_count":"1","poster":"Test_Taker","timestamp":"1591644780.0"}],"comment_id":"99107","poster":"kondapaturi"},{"comments":[{"timestamp":"1591645020.0","poster":"Test_Taker","content":"Authorization types are not the same as endpoints.\n\n@petermogaka91 is correct, see his answer.\nif we want to assume the storeage is replicated with RA, then we need to consider the secondary endpoints mentioned by Santosh43 above, thus the total would be 12.The question didn't specify replication so that's the only reason i wouldn't choose it.","comment_id":"105457","upvote_count":"1"}],"upvote_count":"4","timestamp":"1590503400.0","content":"Endpoint is the authorzation type like, OAuth, OpenID, Microsoft Graph API, WS Federation Sign-on or federation metadata. \nFor each App need only one 1 endpoint Oauth2.0 and total 2 endpoints. Answer correct","comment_id":"96159","poster":"P0d"},{"poster":"petermogaka91","upvote_count":"4","timestamp":"1590498480.0","comment_id":"96089","content":"\"Storage account endpoints\n\nA storage account provides a unique namespace in Azure for your data. Every object that you store in Azure Storage has an address that includes your unique account name. The combination of the account name and the Azure Storage service endpoint forms the endpoints for your storage account.\nFor example, if your general-purpose storage account is named mystorageaccount, then the default endpoints for that account are:\nBlob storage: https://*mystorageaccount*.blob.core.windows.net\nTable storage: https://*mystorageaccount*.table.core.windows.net\nQueue storage: https://*mystorageaccount*.queue.core.windows.net\nAzure Files: https://*mystorageaccount*.file.core.windows.net\" \n\nSo answer is 6, if we follow this ms docs."},{"content":"Please have a look at Connection strings on below page:\nhttps://docs.microsoft.com/en-us/learn/modules/connect-an-app-to-azure-storage/7-connect-to-your-azure-storage-account","poster":"Sam_samules","timestamp":"1590342840.0","comment_id":"95045","upvote_count":"1"},{"upvote_count":"1","poster":"HeyYou","timestamp":"1589896620.0","comments":[{"content":"I thought SAS allowed for multiple services, so you could also get away with 2 per app.","comment_id":"93654","upvote_count":"1","timestamp":"1590105480.0","poster":"ron_b"}],"content":"The question doesn't specify that requirement of SAS tokens. MS should make the questions a bit more explicit. If SAS tokens are required, then the answer is 6 else it is 2 (using Key1 or Key2).","comment_id":"92146"},{"timestamp":"1588442880.0","poster":"milind8451","content":"2 is right ans as when you enable private endpoint you get 1 endpoint for whole storage acconut not its subunits (blob, file, table, queue). So 2 endpoints for each app and \"A\" is right answer. I checked in lab.","comment_id":"82697","upvote_count":"8"},{"comment_id":"77108","upvote_count":"1","content":"each storage service require its own endpoint, like blob.core.windows.net and .file.core.windows.net, .table.core.windows.ney. each one has secondary endpoint too. My answer will 12","comments":[{"upvote_count":"1","poster":"Test_Taker","timestamp":"1591644360.0","comment_id":"105449","content":"secondary endpoint is only if replicated to a secondary region (assuming with RA), correct?"}],"timestamp":"1587415740.0","poster":"Santosh43"},{"comment_id":"75807","timestamp":"1587141840.0","upvote_count":"7","content":"It's 2 as you need only 1 for the whole storage account.\n\nhttps://github.com/Azure/azure-sdk-for-net/blob/5e30a0ca3873d54a310924925e35043dd9f3b6a0/sdk/storage/Azure.Storage.Blobs/README.md\n\nhttps://github.com/Azure/azure-sdk-for-net/blob/44e3a885d76ef753b2dd7bb177639c036c585617/sdk/storage/Azure.Storage.Queues/README.md","poster":"Mvii"},{"timestamp":"1586864280.0","upvote_count":"9","content":"I believe the answer is 3 Endpoint. The question asks how many endpoints per app, not total number of endpoints. These are endpoints in the app, not storage account endpoints\n\n3 endpoints per app - 1 for table storage, 1 for queue storage and 1 for blob storage","comments":[{"poster":"TYT","comment_id":"74762","upvote_count":"2","content":"There are two storage accounts. so three end points for one storage account and three for the other. so 6 is correct.","timestamp":"1586935680.0"},{"upvote_count":"1","content":"it's 6: \"You need to configure the apps to store different types of data to __all__ the storage services on __both__ the storage accounts\"","timestamp":"1593823980.0","comment_id":"125859","poster":"Test_Taker"}],"poster":"BigTone","comment_id":"74467"},{"comment_id":"70638","poster":"Allon","upvote_count":"11","comments":[{"content":"and then twice (for each storage account) makes the total 6.","upvote_count":"1","timestamp":"1585893120.0","comment_id":"70640","poster":"Allon"},{"content":"It's 6: \"You need to configure the apps to store different types of data to __all__ the storage services on __both__ the storage accounts\"","poster":"Test_Taker","comment_id":"125857","upvote_count":"3","timestamp":"1593823920.0"}],"content":"The question states 'for each app'. That would be 3, one for storage, one for blob and one for table. Not 6 as it is requesting per app.","timestamp":"1585893000.0"},{"poster":"Gorha","content":"C is correct","upvote_count":"2","timestamp":"1585821600.0","comment_id":"70393"},{"upvote_count":"1","content":"The questions seems pretty clear to me (except that you may think of the File service as they say \"all storage services\" ) but since the question does not mention File service, I would not consider it. Not sure why would anyone think of service endpoints which is a completely different thing ?!?!? So the answer is 6: 1 endpoint for each storage service (blob,table,queue) for each account.","comment_id":"63191","poster":"Daren","timestamp":"1584034440.0"},{"content":"From an app perspective if we use only 2 endpoints where the data will go? Randomly on tables or queues? I think that 6 endpoints are needed to correctly map the destinations.https://docs.microsoft.com/en-us/azure/storage/common/storage-configure-connection-string","poster":"Jt909","timestamp":"1583330220.0","upvote_count":"1","comment_id":"58749"},{"timestamp":"1579050660.0","comment_id":"39171","poster":"SJAz300","content":"Answer is D - 12\n1 sets for 2 storage acc\n1.Blob storage: http://mystorageaccount.blob.core.windows.net\n2.Table storage: http://mystorageaccount.table.core.windows.net\n3.Queue storage: http://mystorageaccount.queue.core.windows.net\n4.Azure Files: http://mystorageaccount.file.core.windows.net\n5.Data Lake Storage\n6.Static website","upvote_count":"1","comments":[{"comment_id":"43721","upvote_count":"1","poster":"bootyholeman","timestamp":"1580211960.0","content":"I don't see azure files, data loake and static website here \". Each storage account contains a queue service, a table service, and a blob service.\", do you?"}]},{"poster":"Adrian1405","comment_id":"25990","content":"Each Storage account service has its own endpoint:\nhttps://docs.microsoft.com/en-us/azure/storage/common/storage-account-overview#storage-account-endpoints\nSo i would say that C is the correct answer.","timestamp":"1575294960.0","upvote_count":"11"},{"content":"The question as it is fomulated here is ambiguous.\n\nService Endpoints exist to allow you to communicate directly from a vNet to a number of Azure public services. Creating a service endpoint in a vNet allows you to communicate privately with the relevant Azure service (a storage account for example). The service endpoint provides a secure and fast route between your vNet and the Azure service.\n\nhttps://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-service-endpoints-overview\n\nAnswer 2 is under the following assumptions.\n\n1) Applications App1 and App2 reside in its own subnet/VNET (this is not stated in the question)\n2) Each VNET has Microsoft.storage endpoint enabled. (this will make 2 the correct answer)\n3) Each storage account is configured with the firewall to allow traffic for 2 VNETs\\subnet only","comments":[{"comment_id":"29744","poster":"Musk","comments":[{"comment_id":"175768","timestamp":"1599557340.0","upvote_count":"1","poster":"tartar","content":"A is ok"}],"timestamp":"1576411260.0","upvote_count":"5","content":"Because it only referes to endpoints, not to service endpoints, it refers to the URLs that you need to configure in the app, which is 3 x 2 = 6. The right answer is C"}],"comment_id":"16443","timestamp":"1571667060.0","upvote_count":"2","poster":"Oz"}],"answer_ET":"A","question_images":[],"answer_description":"Each app needs a service endpoint in each Storage Account.\nReferences:\nhttps://docs.microsoft.com/en-us/azure/storage/common/storage-network-security"},{"id":"3KmOOEotzNNz8PdvMFsZ","question_id":52,"answers_community":[],"question_images":["https://www.examtopics.com/assets/media/exam-media/02758/0016100001.png","https://www.examtopics.com/assets/media/exam-media/02758/0016200001.png","https://www.examtopics.com/assets/media/exam-media/02758/0016300001.jpg"],"answer_images":["https://www.examtopics.com/assets/media/exam-media/02758/0016400001.jpg"],"topic":"1","url":"https://www.examtopics.com/discussions/microsoft/view/9616-exam-az-300-topic-1-question-56-discussion/","discussion":[{"upvote_count":"15","poster":"vik291","content":"Server 2 must be VMA, VMB and VMC, considering 8TB is allowed for VmWare.","timestamp":"1583430060.0","comments":[{"comment_id":"63199","timestamp":"1584036540.0","poster":"Daren","upvote_count":"3","content":"That`s true. But I`m not sure if this is something they added only recently (support for 8TB data disk VMware)."}],"comment_id":"59496"},{"content":"Same as Question53\nhttps://azure.microsoft.com/en-us/updates/site-recovery-large-disks-8tb/","timestamp":"1575306300.0","poster":"Cern77","comments":[{"comments":[{"comments":[{"upvote_count":"1","comment_id":"171427","poster":"ipvaid","timestamp":"1598973660.0","content":"VMC has data disk of 6TB and data disk more than 4Tb is not supported for HyperV. For VMware, data disk upto 8Tb are supported. So correct answer for Server 2 is VMA & VMB"}],"poster":"jcarlos","content":"So, from Server1 only VM3 and from Server2 VMA,VMB and VMC","upvote_count":"15","comment_id":"47272","timestamp":"1580988540.0"}],"content":"Just to clarify, data disks up to 8TB are only supported for VM Ware, not for Hyper-V. Hyper-V is still limited to 4TB. https://docs.microsoft.com/en-us/azure/site-recovery/hyper-v-azure-support-matrix#azure-vm-requirements","timestamp":"1580076300.0","poster":"Sweb","upvote_count":"4","comment_id":"43050"},{"poster":"ChePunk","timestamp":"1582764060.0","content":"@Cern77 This is not the same as Question 53, because the table 1 is different. But, I think the answer is correct though.","upvote_count":"2","comment_id":"55746"},{"upvote_count":"1","poster":"rdy4u","timestamp":"1594662720.0","comment_id":"134157","content":"not the same question"},{"comment_id":"151016","timestamp":"1596616920.0","upvote_count":"1","poster":"francisco91","content":"don't think so. #53 states that VM1,VM2,VM3 are VMware and NOT Hyper-V. Watch out for that."},{"upvote_count":"1","comment_id":"211854","timestamp":"1604400240.0","content":"Not same question","poster":"Haykhay"}],"comment_id":"26025","upvote_count":"7"},{"upvote_count":"1","content":"Given answer is correct","timestamp":"1710835980.0","poster":"tashakori","comment_id":"1177087"},{"upvote_count":"1","comment_id":"182816","content":"In this question VM3 is a Gen 2 which cannot be migrated, could be a typo but the question does not make sense from that perspective,","poster":"Ziggybooboo","timestamp":"1600590480.0"},{"comments":[{"upvote_count":"1","content":"That's correct!","comment_id":"176732","timestamp":"1599685320.0","poster":"magpi"},{"comment_id":"254677","upvote_count":"1","comments":[{"poster":"RasiR","timestamp":"1609561080.0","content":"No wait! VMC is in VMware so it will support up to 2 TB\n\nhttps://docs.microsoft.com/en-us/azure/site-recovery/vmware-physical-azure-support-matrix#azure-vm-requirements","comment_id":"257254","upvote_count":"1"}],"timestamp":"1609236900.0","content":"But VMC also has a 500 GB OS Disk. It only supports up to 300 GB for generation 2 VMs.\n\nhttps://docs.microsoft.com/en-us/azure/site-recovery/hyper-v-azure-support-matrix#azure-vm-requirements","poster":"RasiR"}],"upvote_count":"6","poster":"francisco91","content":"My answer is:\n- VM3 only\n- VMA, VMB and VMC, assuming that we're talking about Managed Disks (questions omits this) and the limit is now 8TB (4TB for Storage Account Replication)\n\nSource - https://docs.microsoft.com/en-us/azure/site-recovery/vmware-physical-azure-support-matrix#azure-vm-requirements","comment_id":"151017","timestamp":"1596617040.0"},{"comment_id":"145151","poster":"aurora21","timestamp":"1595868360.0","upvote_count":"3","content":"For VMWare\nUp to 8,192 GB when replicating to managed disks (9.26 version onwards)\nUp to 4,095 GB when replicating to storage accounts\nSince nothing specifically mentioned what does ASR typically use ?"},{"content":"The answer is Right.\n\nI did this Summary to this kind of questions.\n\nSummary Hyper-v and VMWare\n- OS Architecture Both 64 Bits, except WS2008 in Hyper-v\n- OS Disk Size Both up to 2TB, except VM G2 up to 300GB in Hyper-v\n- Data Disk Both up to 4TB, except replication MHDD up to 8TB in VMWare\n- Shared VHD Both not supported\n- FC disk Both not supported\n- BitLocker Both not supported\n- Hard disk format VHD, VHDX only in Hyper-v\n\nSo: \nVM1 exclude, BitLocker enabled.\nVM2 exclude, it have 3TB of OS, up to 2TB.\nVMC exclude, it have Data Disk 6TB, up to 4TB.","poster":"tundervirld","timestamp":"1594828980.0","upvote_count":"3","comment_id":"135854"},{"upvote_count":"4","content":"Given Answer is correct","poster":"gboyega","timestamp":"1594741380.0","comment_id":"134997"},{"comment_id":"125729","content":"Server1: \nVM1 - Can't be migrated because BitLocker is enabled\nVM2 - Can't be migrated because the OS disk is larger then the allowed 2048 GB for Generation 1 VMs (max. of 300 GB for gen 2)\nVM3 - Can be migrated\n\nServer2: \nVMA - Can be migrated\nVMB - Can be migrated\nVMC - Can't be migrated as data disk is larger then the allowed 4095 GB\n\nSource: https://docs.microsoft.com/en-us/azure/site-recovery/hyper-v-azure-support-matrix#azure-vm-requirements","poster":"[Removed]","timestamp":"1593798300.0","upvote_count":"4"},{"timestamp":"1593431280.0","poster":"PTC","upvote_count":"1","content":"Even though VM1 falls under 2TB (OS Disk) and 4TB (Data Disk) limitation, it has bitlocker enabled. So it can't be moved.","comment_id":"122737"},{"comment_id":"113545","upvote_count":"3","timestamp":"1592526780.0","content":"VMC does not meet the azure VM requirement. Data disk is only up to 4095GB\n\nhttps://docs.microsoft.com/en-us/azure/site-recovery/hyper-v-azure-support-matrix#azure-vm-requirements","poster":"Chokies"}],"answer":"","answer_description":"Incorrect Answers:\nVM1 cannot be migrates as it has BitLocker enabled.\nVM2 cannot be migrates as the OS disk on VM2 is larger than 2TB.\nVMC cannot be migrates as the Data disk on VMC is larger than 4TB.\nReferences:\nhttps://docs.microsoft.com/en-us/azure/site-recovery/hyper-v-azure-support-matrix#azure-vm-requirements","isMC":false,"unix_timestamp":1575306300,"question_text":"HOTSPOT -\nYou have an Azure subscription named Subscription1.\nYou have a virtualization environment that contains the virtualization servers in the following table.\n//IMG//\n\nThe virtual machines are configured as shown in the following table.\n//IMG//\n\nAll the virtual machines use basic disks. VM1 is protected by using BitLocker Drive Encryption (BitLocker).\nYou plan to use Azure Site Recovery to migrate the virtual machines to Azure.\nWhich virtual machines can you migrate? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","timestamp":"2019-12-02 18:05:00","answer_ET":"","exam_id":50},{"id":"yHq63aFP4D78wHxZtD8U","answer_ET":"See solution below.","question_text":"SIMULATION -\nClick to expand each objective. To connect to the Azure portal, type https://portal.azure.com in the browser address bar.\n//IMG//\n\n//IMG//\n\n//IMG//\n\n//IMG//\n\n//IMG//\n\n//IMG//\n\nWhen you are finished performing all the tasks, click the \"˜Next' button.\nNote that you cannot return to the lab once you click the \"˜Next' button. Scoring occur in the background while you complete the rest of the exam.\n\nOverview -\nThe following section of the exam is a lab. In this section, you will perform a set of tasks in a live environment. While most functionality will be available to you as it would be in a live environment, some functionality (e.g., copy and paste, ability to navigate to external websites) will not be possible by design.\nScoring is based on the outcome of performing the tasks stated in the lab. In other words, it doesn't matter how you accomplish the task, if you successfully perform it, you will earn credit for that task.\nLabs are not timed separately, and this exam may have more than one lab that you must complete. You can use as much time as you would like to complete each lab. But, you should manage your time appropriately to ensure that you are able to complete the lab(s) and all other sections of the exam in the time provided.\nPlease note that once you submit your work by clicking the Next button within a lab, you will NOT be able to return to the lab.\n\nTo start the lab -\nYou may start the lab by clicking the Next button.\nYou plan to migrate a large amount of corporate data to Azure Storage and to back up files stored on old hardware to Azure Storage.\nYou need to create a storage account named corpdata8548984n1, in the corpdatalod8548984 resource group. The solution must meet the following requirements:\n- corpdata8548984n1 must be able to host the virtual disk files for Azure virtual machines\n- The cost of accessing the files must be minimized\n- Replication costs must be minimized\nWhat should you do from the Azure portal?","discussion":[{"content":"The requirement is \"Replication cost should be minimized\"\nIt means that data redundancy should be set to LRS not RA-GRS.\nRA-GRS cost is the highest.","poster":"Oz","comments":[{"timestamp":"1599557940.0","comment_id":"175774","upvote_count":"3","poster":"tartar","content":"Standard\nStorage V2\nLocally Redundant Storage (LRS)\nHot"}],"comment_id":"16446","upvote_count":"60","timestamp":"1571667600.0"},{"poster":"Karls","upvote_count":"35","comments":[{"poster":"GSH","comment_id":"81006","content":"You got it, same as 2 other prep sites...and this site's AZ:103 test answer...","timestamp":"1588101960.0","upvote_count":"2"}],"content":"- corpdata8548984n1 host the virtual disk files >>> BLOB (I would choose V2)\n- The cost of accessing the files must be minimized >>> HOT\n- Replication costs must be minimized >>> LRS","timestamp":"1579947840.0","comment_id":"42523"},{"content":"Set up Storage v2 Premium with LRS enabled for best cost. Yes Premium is more than standard, but the question states that it will need to house the VHD files for virtual machines therefore it will be access frequently and Premium is better suited for VHDs than standard is due to having SSDs vs standard HDD.","timestamp":"1597015620.0","upvote_count":"1","poster":"macco455","comment_id":"153998"},{"poster":"[Removed]","comment_id":"125745","content":"1. Cost of accessing must be minimized\n - This rules out cool tiers (hot tiers are cheaper when it comes to access the data)\n\n2. Replication cost must be minized \n - This only allows for LRS which is the cheapest\n - This also means \"Standard\" performance over \"Premium\" as this doesn't support other replication scenarios then LRS\n \n3. Must be able to host Azure VM disk files\n - This calls for page blob support \n - Rules out \"BlobStorage\" as this only supports block and append blobs\n \nResult:\n\nPerformance = Standard\nAccount kind = StorageV2 (Microsoft recommends V2 over V1 for new accounts) \nReplication = LRS \nAccess tier = Hot","comments":[{"content":"Exactly correct.","poster":"praveen97","timestamp":"1594573260.0","upvote_count":"1","comment_id":"133085"}],"timestamp":"1593800640.0","upvote_count":"9"},{"poster":"gsbence","timestamp":"1592310540.0","comment_id":"111559","upvote_count":"1","content":"GPv2 LRS is clear (BlobStorage is not applicable because VM disks are usually Page blobs) But if I want to eliminate file access costs I can use a Premium Storage Account.. that would be a technically correct, but stupid move.."},{"content":"\"corpdata8548984n1 must be able to host the virtual disk files for Azure virtual machines\"\nShouldn't we create a file share in storage account ?","poster":"daniel840829","comment_id":"99131","upvote_count":"2","timestamp":"1590902700.0","comments":[{"timestamp":"1592016540.0","upvote_count":"1","comment_id":"109142","content":"Azure-managed disks are stored as page blobs","poster":"NKnab"}]},{"content":"don't forget to create a Container to store the VHD :)","timestamp":"1590849360.0","poster":"quokka","comment_id":"98886","upvote_count":"4"},{"upvote_count":"9","content":"You don't speak about \"Performance\" to \"Standard\".\n\n- Storage account : corpdatalod7523690n2\n- Performance : Standard (The cost of accessing the files must be minimized))\n- Account kind : StorageV2 (Must be able to host the virtual disk files for Azure virtual machines)\n- Replication : LRS (Replication costs must be minimized)\n- Access tier : Hot (The cost of accessing the files must be minimized)","timestamp":"1589781540.0","poster":"PierroD","comment_id":"91036"},{"timestamp":"1588466040.0","poster":"lepperboy","comment_id":"82824","content":"Agree it should be LRS - not RA-GRS. No mention of requirements for cross region replication and this will drive up costs also.","upvote_count":"2"},{"content":"create a storage account with GPv2 (allows blob storage), LRS (to save costs), hot tier.That's it.","timestamp":"1587691920.0","upvote_count":"4","comments":[{"content":"it is for backup , so hot is not required .. cool would be better.","comment_id":"102488","timestamp":"1591286700.0","upvote_count":"1","poster":"kondapaturi","comments":[{"poster":"gboyega","timestamp":"1594521000.0","comment_id":"132580","content":"you are wrong. \nIT SAYS COST FOR ACCESSING FILES MUST BE MINIMIZED. SO HOT IS CORRECT","upvote_count":"1"}]}],"poster":"TYT","comment_id":"78901"},{"content":"Bloob + LRS + COOL","poster":"silverdeath","timestamp":"1585044780.0","upvote_count":"2","comment_id":"67641","comments":[{"comment_id":"67642","upvote_count":"2","content":"delete","timestamp":"1585045020.0","poster":"silverdeath"}]},{"content":"The ask is simple and straight forward\n1. Replication cost should be minimized - For this we should choose LRS and not RA-GRS\n2. he cost of accessing the files must be minimized - This is possible when the access tier is set to Cool Tier.","timestamp":"1580680800.0","comment_id":"45947","comments":[{"poster":"Myk","comment_id":"51218","content":"For your 2nd answer i think it should also be hot not cool as hot tiers are cheaper to \"access\" than cool ones. \nhttps://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers?tabs=azure-portal \n\nData access costs: Data access charges increase as the tier gets cooler. For data in the cool and archive access tier, you're charged a per-gigabyte data access charge for reads.","timestamp":"1581858780.0","upvote_count":"4"},{"content":"The question asks : the cost of accessing should be minimized in this case the tier would be hot.\n\nCool would be the case when it is asked that \"Cost of storing the data should be minimized\"","upvote_count":"5","comment_id":"76743","timestamp":"1587358680.0","poster":"Noor001"}],"upvote_count":"1","poster":"NeerajKS"},{"comments":[{"content":"Technically yes, but MS is trying to depreciate it. So not a valid strategy.","timestamp":"1575962220.0","poster":"chris46","upvote_count":"4","comment_id":"28492"}],"timestamp":"1575585720.0","upvote_count":"2","poster":"Tom_A","comment_id":"26991","content":"Wouldn’t storage account general-purpose v1 be the cheapest option in terms of the replication charges and access (cheaper storage transactions)"},{"poster":"sasi","comment_id":"19237","comments":[{"content":"requirement: The cost of accessing the files must be minimized \naccessing \"cool access tier\" is more expensive therefore i suppose correct answer is HOT access tier storage\n\nData in the cool access tier can tolerate slightly lower availability, but still requires high durability, retrieval latency, and throughput characteristics similar to hot data. For cool data, a slightly lower availability service-level agreement (SLA) and higher access costs compared to hot data are acceptable trade-offs for lower storage costs.\n\nfrom: https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers","comment_id":"24231","poster":"Sategi","upvote_count":"20","timestamp":"1574670840.0"},{"upvote_count":"7","comment_id":"29781","timestamp":"1576422180.0","poster":"Amrinder101","content":"Access data cost should be minimize. Cannot select cold","comments":[{"content":"you mean cool :-) and should be Hot","poster":"aimar047","comment_id":"88491","upvote_count":"3","timestamp":"1589403420.0"}]}],"upvote_count":"9","timestamp":"1572913440.0","content":"I believe access tier should be selected as cool to reduce cost as access to backup files will be categorized with infrequent access."}],"timestamp":"2019-10-21 16:20:00","unix_timestamp":1571667600,"question_id":53,"question_images":["https://www.examtopics.com/assets/media/exam-media/02758/0016500001.png","https://www.examtopics.com/assets/media/exam-media/02758/0016600001.jpg","https://www.examtopics.com/assets/media/exam-media/02758/0016700001.jpg","https://www.examtopics.com/assets/media/exam-media/02758/0016800001.jpg","https://www.examtopics.com/assets/media/exam-media/02758/0016900001.jpg","https://www.examtopics.com/assets/media/exam-media/02758/0017000001.jpg"],"isMC":false,"answers_community":[],"answer_images":["https://www.examtopics.com/assets/media/exam-media/02758/0017200001.jpg"],"url":"https://www.examtopics.com/discussions/microsoft/view/6895-exam-az-300-topic-1-question-57-discussion/","answer":"See solution below.","answer_description":"Step 1: In the Azure portal, click All services. In the list of resources, type Storage Accounts. As you begin typing, the list filters based on your input. Select\nStorage Accounts.\nStep 2: On the Storage Accounts window that appears, choose Add.\nStep 3: Select the subscription in which to create the storage account.\nStep 4: Under the Resource group field, select corpdatalod8548984.\n\nStep 5: Enter a name for your storage account: corpdata8548984n1\nStep 6: For Account kind select: General-purpose v2 accounts (recommended for most scenarios)\nGeneral-purpose v2 accounts is recommended for most scenarios. General-purpose v2 accounts deliver the lowest per-gigabyte capacity prices for Azure\nStorage, as well as industry-competitive transaction prices.\nStep 7: For replication select: Read-access geo-redundant storage (RA-GRS)\nRead-access geo-redundant storage (RA-GRS) maximizes availability for your storage account. RA-GRS provides read-only access to the data in the secondary location, in addition to geo-replication across two regions.\nReferences:\nhttps://docs.microsoft.com/en-us/azure/storage/common/storage-quickstart-create-account https://docs.microsoft.com/en-us/azure/storage/common/storage-account-overview","topic":"1","exam_id":50},{"id":"2sBJRRm5h877XHaL389U","question_id":54,"answer_description":"Step 1: In the Azure portal, click All services. In the list of resources, type Storage Accounts. As you begin typing, the list filters based on your input. Select\nStorage Accounts.\nStep 2: On the Storage Accounts window that appears, choose Add.\nStep 3: Select the subscription in which to create the storage account.\nStep 4: Under the Resource group field, select Create New. Create a new Resource\n\nStep 5: Enter a name for your storage account: corpdata8548984n2\nStep 6: For Account kind select: General-purpose v2 accounts (recommended for most scenarios)\nGeneral-purpose v2 accounts is recommended for most scenarios. General-purpose v2 accounts deliver the lowest per-gigabyte capacity prices for Azure\nStorage, as well as industry-competitive transaction prices.\nStep 7: For replication select: Read-access geo-redundant storage (RA-GRS)\nRead-access geo-redundant storage (RA-GRS) maximizes availability for your storage account. RA-GRS provides read-only access to the data in the secondary location, in addition to geo-replication across two regions.\nReferences:\nhttps://docs.microsoft.com/en-us/azure/storage/common/storage-quickstart-create-account https://docs.microsoft.com/en-us/azure/storage/common/storage-account-overview","answer_ET":"See solution below.","question_images":["https://www.examtopics.com/assets/media/exam-media/02758/0017400001.png","https://www.examtopics.com/assets/media/exam-media/02758/0017500001.jpg","https://www.examtopics.com/assets/media/exam-media/02758/0017600001.jpg","https://www.examtopics.com/assets/media/exam-media/02758/0017700001.jpg","https://www.examtopics.com/assets/media/exam-media/02758/0017800001.jpg","https://www.examtopics.com/assets/media/exam-media/02758/0017900001.jpg"],"answer_images":["https://www.examtopics.com/assets/media/exam-media/02758/0018100001.jpg"],"discussion":[{"timestamp":"1576330140.0","poster":"Ekramy_Elnaggar","content":"Create Sotrage account with the following specs:\n1- Drive mappings from Azure virtual machines ( So: GPV2 )\n2- Minimize storage access costs (So: Hot access tier )\n3- Provide the highest possible redundancy for the documents ( So: GRS )","comment_id":"29563","upvote_count":"43","comments":[{"content":"-Minimize storage access costs: Hot tier has expensive storage cost and cheaper access cost whereas cold tier has expensive access cost and cheaper storage cost so I need t to choose cold tier for storage","comment_id":"42452","timestamp":"1579910040.0","poster":"[Removed]","upvote_count":"2"},{"content":"For highest redundancy RA-GRS will be required as in GRS manual failover will be required.Where in RA-GRS automatically document will be available from secondary region if main region fail.","comment_id":"68543","timestamp":"1585298340.0","upvote_count":"5","poster":"Russel"},{"comment_id":"69398","poster":"codeoptimus","timestamp":"1585529280.0","content":"for minimizing storage cost the best option is Cool access tier; Host access tier actually provides a high storage cost with a lower cost of accessing data","upvote_count":"1"},{"comment_id":"75462","poster":"Ahmed911","content":"a7ebak wenta betgeeb men el akher :)","timestamp":"1587071820.0","upvote_count":"2"},{"upvote_count":"3","timestamp":"1594216740.0","comment_id":"129803","poster":"X_L","content":"GZRS would actually provide the highest redundancy, not GRS"},{"upvote_count":"1","comment_id":"133089","poster":"praveen97","content":"Agree with Ekramy","timestamp":"1594573620.0"}]},{"content":"Should also be GRS and not RA-GRS, right. Says to minimise costs and maximise redundancy, RA-GRS doesn’t increase redundancy over GRS but is more costly.","upvote_count":"20","poster":"Benkyoujin","comment_id":"29038","timestamp":"1576153980.0"},{"upvote_count":"1","timestamp":"1601455860.0","content":"Here is the solution.. \n1- Drive mappings from Azure virtual machines ( So: GPV2 ) \n2- 2- Minimize storage access costs (So: Hot access tier ) \n3- 3- Provide the highest possible redundancy for the documents ( So: RA-GZRS )\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers?tabs=azure-portal\nhttps://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy","comment_id":"190217","comments":[{"timestamp":"1601559180.0","comment_id":"191008","upvote_count":"1","content":"Shiraz I agree with your steps. but would add 2 more steps.\n4. Create a File Share from the File Service Blade for documents. Since drive mapping is not possible from blob service, File service needs to be used.\n5. Create a container under Blob service blade for backups.","poster":"Himanshu27"}],"poster":"ShirazTech"},{"content":"so is this final ? \n Performance = Standard\nAccount kind = StorageV2\nReplication = GA-GZRS\nAccess Tier = Hot","timestamp":"1600796160.0","upvote_count":"1","poster":"rs_s","comment_id":"184635"},{"poster":"KCjoe","comments":[{"upvote_count":"1","comment_id":"176737","content":"Incorrect. The source you give us remarks that \"GZRS and RA-GZRS support block blobs, page blobs (except for VHD disks), FILES, tables, and queues\".","timestamp":"1599685740.0","poster":"magpi"}],"upvote_count":"4","content":"\"Azure Files does not support read-access geo-redundant storage (RA-GRS) and read-access geo-zone-redundant storage (RA-GZRS).\" So it has to be GZRS, instead of RA-GZRS\n https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy","timestamp":"1595635680.0","comment_id":"143036"},{"timestamp":"1595443980.0","content":"It does not say minimize replication cost to choose GRS over RA-GRS hence RA-GRS is better option considering the task given. By choosing HOT tier, storage access cost is minimized.\n\nGPV2\nHot Tier\nRA-GRS","poster":"smsulai","upvote_count":"2","comment_id":"141341"},{"content":"1. GPV2+File share\n2. Minimize access cost - Hot\n3. Highest redundancy GRS","timestamp":"1594430400.0","comment_id":"131838","upvote_count":"1","poster":"ExamWynner"},{"timestamp":"1594043400.0","poster":"X_L","upvote_count":"1","comment_id":"127857","content":"GZRS would actually be the highest redundancy option; and as we are actually taking about a file share (drive mapping required) access tier (cool/hot) is irelevant. A Premium File share Storage account would be the best option, as data access is free for those."},{"content":"https://docs.microsoft.com/en-us/azure/storage/blobs/storage-how-to-mount-container-linux","poster":"irvingsale2011","comment_id":"127807","upvote_count":"1","timestamp":"1594038480.0"},{"content":"1. Must be usable with drive mappings \n - This rules out BlobStorage, as it doesn't support file shares \n - So only StorageV2 left \n\n2. Highest possible redundancy for documents \n - This would ask for RA-GZRS. Data is still accessible\n - if a storage node goes down\n - if an availabilty zone goes down \n - if an azure region goes down (manual failover trigger)\n - RA-GZRS is not available in all locations \n \n3. Minimize storage access costs \n - This rules out the cool access tier \n\nResult => \n\nPerformance = Standard\nAccount kind = StorageV2\nReplication = GA-GZRS\nAccess Tier = Hot","comment_id":"125752","upvote_count":"3","poster":"[Removed]","timestamp":"1593801720.0"},{"comment_id":"111962","poster":"epomatti","timestamp":"1592351760.0","upvote_count":"1","content":"Let's break it down:\n\n1. It's a backup storage\n2. Must reduce storage costs (again, backup)\n3. Highest redundancy possible\n\nI vote for \"Cool tier\" and (as of today) \"GZRS\" instead of GRS because it is not on preview anymore.\n\nUsing RA-GRS and RA-GZRS will NOT increase redundancy.\nHot tier does NOT decrease storage costs (again, they say backup in the question, it is not meant to be a hot tier)"},{"comment_id":"102492","content":"highest possible redundancy - Redundancy is same for GRS and RA-GRS , can go with GRS\nCost - cool is less cost as it is for backup","poster":"kondapaturi","timestamp":"1591287120.0","upvote_count":"1"},{"comment_id":"98929","poster":"quokka","content":"If you read the question again, you'll notice it said \"The backup files will be stored as blobs.\" It did NOT say you have to store in a blob storage. It also said you need to \"accessible via drive mappings from Azure virtual machines that run Windows Server 2016\". That means File storage (unless you use 3rd party tool to map to blob storage). So the right answer should be:\n1. Create corpdata8548984n2 storage account with:\n a. account kind=GPV2\n b. access tier=hot (minimize ACCESS cost, not storage cost)\n c. replication=RA-GZRS (if primary is down, still can get from secondary)\n2. Create a File shares so you can map drive to whatever VM","upvote_count":"4","timestamp":"1590856500.0"},{"comment_id":"89587","content":"Create Sotrage account with the following specs:\n1- Drive mappings from Azure virtual machines ( So: GPV2 )\n2- Minimize storage access costs (So: Hot access tier )\n3- Provide the highest possible redundancy for the documents ( So: RA_GZRS )","poster":"MukeshKhamparia","comments":[{"upvote_count":"2","poster":"PatMan","content":"GZRS provides the same document redundancy as RA-GZRS.\nRA-GZRS does add the ability to read the documents in the secondary location in case of failure. This option adds to the availability of the documents (not redundancy).\nDocument redundancy is the same between GZRS & RA_GZRS. Since you need to keep minimize the costs, it has to be GZRS.","timestamp":"1589711880.0","comment_id":"90492"},{"poster":"HeyYou","comment_id":"92168","timestamp":"1589898780.0","content":"Wouldn't GRS provide the highest redundancy? The only difference is the RA-GRS provides read-only access. The question doesn't say anything about access the secondary locations. So, we can simply use GRS correct?","upvote_count":"1"}],"timestamp":"1589560680.0","upvote_count":"3"},{"comment_id":"84410","poster":"huyhoang8344","timestamp":"1588735500.0","content":"1.GRZ-hot (v2)\n2.Create fileshare","upvote_count":"2"},{"upvote_count":"3","content":"Actually, I read the question again.\n\nCreate a storage account, GPV2, hot tier and select GRS. It says minimize costs so you don't have to use RA-GRS. Both performance are identical.","poster":"TYT","timestamp":"1587691680.0","comment_id":"78899"},{"upvote_count":"1","poster":"TYT","comment_id":"75776","timestamp":"1587138000.0","content":"Why not RA-GRS?"},{"content":"\"Microsoft recommends using GZRS for applications requiring maximum consistency, durability, and availability, excellent performance, and resilience for disaster recovery.\"(https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy)\nSo I guess the answer is GZRS","upvote_count":"2","poster":"Protonenpaule","timestamp":"1585726620.0","comments":[{"timestamp":"1585853460.0","content":"Geo-zone-redundant storage (GZRS) (preview) is still in the preview stage so it is not applicable to the exam. GRS is the best option so far.","comment_id":"70506","poster":"Mokaw","upvote_count":"3"}],"comment_id":"70045"},{"upvote_count":"2","comment_id":"48030","poster":"FailureIsnotAnOption","content":"The scenario requires a solution for backups and documents. Blobs storage was specifically mentioned and I associate them with backups. Blobs haven't been addressed. I think you have to create both a file share for the documents, and a container for the backups.","timestamp":"1581187080.0"},{"comments":[{"content":"Task is asking you to create a storage account only, so I believe MS will only check how did you configure it regardless of what you created in that storage account later.","upvote_count":"3","timestamp":"1581107820.0","comment_id":"47815","poster":"dfrye"}],"content":"Correct Answer is \"HOT\" you have to differ between storage and access cost. The storage cost are higher in hot but the access costs are lower. (Compared to \"cool\"). The question asks for the access not storage.\n\nBut we have to ensure that the files should be accessd by drive mappings, so i think we have to create a file share, too? No one?","upvote_count":"10","timestamp":"1581009540.0","poster":"N3v3rmann","comment_id":"47419"},{"timestamp":"1580608260.0","upvote_count":"1","poster":"Rafael1984","content":"Correct anwer is \"Cool\" because Data storage prices Hot is more expensive than Cool, but Hot is more expensive in Operations and data transfer prices than cool.\n\n\n\nhttps://www.apptio.com/emerge/essential-guide-azure-blob-storage-pricing/","comments":[{"comment_id":"181297","upvote_count":"1","poster":"andyR","content":"no no - hot","timestamp":"1600391820.0"}],"comment_id":"45743"},{"upvote_count":"14","poster":"JatinA","timestamp":"1575370920.0","comments":[{"comments":[{"timestamp":"1592088660.0","poster":"jonnybugaloo","comment_id":"109740","upvote_count":"5","content":"Ensure that the documents are accessible via drive mappings. What our mate try to say is that after you create the Storage V2 Account, you should also create a file share service inside of it.\nI agree with him."}],"content":"Nope, we have 3 types of storage accounts:\n1- GPV2: supports all types including File shares\n2- GPV1: supports all types including File shares [ but it is not recommended anymore ]\n3- Blob: supports blobs only [ don't support File shares ]\n\nso this statement is mentioned in order to direct you to the GPV2 choice :)","timestamp":"1576330320.0","poster":"Ekramy_Elnaggar","upvote_count":"13","comment_id":"29565"}],"comment_id":"26222","content":"\"Ensure that the documents are accessible via drive mappings from Azure virtual machines that run Windows Server 2016\". This seems to be missing in solution. So, we need to create a File Share as well."},{"content":"To minimize storage access cost, we should set this to \"Cool\" instead of \"Hot\"","comments":[{"content":"Access costs in Cool Storage are higher than in Hot.\nhttps://azure.microsoft.com/en-us/pricing/calculator/?service=storage","comment_id":"26027","upvote_count":"36","timestamp":"1575307440.0","poster":"Cern77","comments":[{"poster":"tartar","content":"GPV2\nHot Tier\nGRS","upvote_count":"1","timestamp":"1599558780.0","comment_id":"175785"}]}],"upvote_count":"10","comment_id":"23144","timestamp":"1574281080.0","poster":"[Removed]"}],"unix_timestamp":1574281080,"question_text":"SIMULATION -\nClick to expand each objective. To connect to the Azure portal, type https://portal.azure.com in the browser address bar.\n//IMG//\n\n//IMG//\n\n//IMG//\n\n//IMG//\n\n//IMG//\n\n//IMG//\n\nWhen you are finished performing all the tasks, click the \"˜Next' button.\nNote that you cannot return to the lab once you click the \"˜Next' button. Scoring occur in the background while you complete the rest of the exam.\n\nOverview -\nThe following section of the exam is a lab. In this section, you will perform a set of tasks in a live environment. While most functionality will be available to you as it would be in a live environment, some functionality (e.g., copy and paste, ability to navigate to external websites) will not be possible by design.\nScoring is based on the outcome of performing the tasks stated in the lab. In other words, it doesn't matter how you accomplish the task, if you successfully perform it, you will earn credit for that task.\nLabs are not timed separately, and this exam may have more than one lab that you must complete. You can use as much time as you would like to complete each lab. But, you should manage your time appropriately to ensure that you are able to complete the lab(s) and all other sections of the exam in the time provided.\nPlease note that once you submit your work by clicking the Next button within a lab, you will NOT be able to return to the lab.\n\nTo start the lab -\nYou may start the lab by clicking the Next button.\nYou plan to move backup files and documents from an on-premises Windows file server to Azure Storage. The backup files will be stored as blobs.\nYou need to create a storage account named corpdata8548984n2. The solution must meet the following requirements:\n- Ensure that the documents are accessible via drive mappings from Azure virtual machines that run Windows Server 2016\n- Provide the highest possible redundancy for the documents\n- Minimize storage access costs\nWhat should you do from the Azure portal?","answers_community":[],"topic":"1","answer":"See solution below.","url":"https://www.examtopics.com/discussions/microsoft/view/8737-exam-az-300-topic-1-question-58-discussion/","timestamp":"2019-11-20 21:18:00","exam_id":50,"isMC":false},{"id":"FE6RQ8gBuLDgl5JTiZqm","isMC":false,"unix_timestamp":1569238620,"question_text":"SIMULATION -\nClick to expand each objective. To connect to the Azure portal, type https://portal.azure.com in the browser address bar.\n//IMG//\n\n//IMG//\n\n//IMG//\n\n//IMG//\n\n//IMG//\n\n//IMG//\n\nWhen you are finished performing all the tasks, click the \"˜Next' button.\nNote that you cannot return to the lab once you click the \"˜Next' button. Scoring occur in the background while you complete the rest of the exam.\n\nOverview -\nThe following section of the exam is a lab. In this section, you will perform a set of tasks in a live environment. While most functionality will be available to you as it would be in a live environment, some functionality (e.g., copy and paste, ability to navigate to external websites) will not be possible by design.\nScoring is based on the outcome of performing the tasks stated in the lab. In other words, it doesn't matter how you accomplish the task, if you successfully perform it, you will earn credit for that task.\nLabs are not timed separately, and this exam may have more than one lab that you must complete. You can use as much time as you would like to complete each lab. But, you should manage your time appropriately to ensure that you are able to complete the lab(s) and all other sections of the exam in the time provided.\nPlease note that once you submit your work by clicking the Next button within a lab, you will NOT be able to return to the lab.\n\nTo start the lab -\nYou may start the lab by clicking the Next button.\nYou need to deploy two Azure virtual machines named VM1003a and VM1003b based on an Ubuntu Server image. The deployment must meet the following requirements:\n- Provide a Service Level Agreement (SLA) of 99.95 percent availability\n- Use managed disks\nWhat should you do from the Azure portal?","answer":"See solution below.","timestamp":"2019-09-23 13:37:00","discussion":[{"comments":[{"poster":"praveen97","timestamp":"1594574040.0","comment_id":"133095","upvote_count":"2","content":"Agree with NS."}],"poster":"NS","content":"Additional to Step 5: Under Availibility options select Availibility Set (next field you have to create a new as if not any present), because of the requirement (\"- Provide a Service Level Agreement (SLA) of 99.95 percent availability\"). Availibility Set has a SLA of 99.95%. Avalibility zone of 2 even 99.99%. But you need 99.95% as stated in the requirement.\n\nhttps://azure.microsoft.com/en-us/support/legal/sla/virtual-machines/v1_8/\n\nNext tab \"Disks\" open the advanced drop down menu and ensure that \"use managed disks\" is selected to \"Yes\"","comment_id":"12286","timestamp":"1569238620.0","upvote_count":"70"},{"upvote_count":"13","comment_id":"16448","timestamp":"1571668320.0","poster":"Oz","content":"Agree, availability set should be configured to achieve 99.95% SLA and both VMs should be in the same availability set.\nSee section \"Configure multiple virtual machines in an availability set for redundancy\" from the reference.\nhttps://docs.microsoft.com/en-us/azure/virtual-machines/windows/manage-availability"},{"content":"I agree. Before this SLA was updated it would have been an availability set, but given this SLA Just creating both virtual machines with managed SSD disks will accomplish the 99.95 up time\nSo the given answer is on track, just need to make sure you select Standard SSD for disk type","comment_id":"154003","poster":"macco455","upvote_count":"1","timestamp":"1597016940.0"},{"poster":"francisco91","content":"As of July 2020, there's no need to create Availability Set to get the SLA of 99.5%.\nJust choose a Standard SSD:\n\"For any Single Instance Virtual Machine using Standard SSD Managed Disks for Operating System Disk and Data Disks, we guarantee you will have Virtual Machine Connectivity of at least 99.5%.\"\n- https://azure.microsoft.com/en-us/support/legal/sla/virtual-machines/v1_9/","timestamp":"1596618480.0","comments":[{"comment_id":"161519","content":"The question here says 99.95% SLA, hence two or more instances of Virtual machine has to be deployed in the same availability set or host group to achieve that SLA.\n\"For all Virtual Machines that have two or more instances deployed in the same Availability Set or in the same Dedicated Host Group, we guarantee you will have Virtual Machine Connectivity to at least one instance at least 99.95% of the time.\"\nhttps://azure.microsoft.com/en-us/support/legal/sla/virtual-machines/v1_9/","poster":"ananthkamath","timestamp":"1597842960.0","upvote_count":"3"}],"comment_id":"151033","upvote_count":"1"},{"content":"I think you just need to deploy the 2 VMs in the same AV Set....\n For all Virtual Machines that have two or more instances deployed across two or more Availability Zones in the same Azure region, we guarantee you will have Virtual Machine Connectivity to at least one instance at least 99.99% of the time.\n For all Virtual Machines that have two or more instances deployed in the same Availability Set or in the same Dedicated Host Group, we guarantee you will have Virtual Machine Connectivity to at least one instance at least 99.95% of the time.\n For any Single Instance Virtual Machine using Premium SSD or Ultra Disk for all Operating System Disks and Data Disks, we guarantee you will have Virtual Machine Connectivity of at least 99.9%.\n For any Single Instance Virtual Machine using Standard SSD Managed Disks for Operating System Disk and Data Disks, we guarantee you will have Virtual Machine Connectivity of at least 99.5%.\n For any Single Instance Virtual Machine using Standard HDD Managed Disks for Operating System Disks and Data Disks, we guarantee you will have Virtual Machine Connectivity of at least 95%.","timestamp":"1595018040.0","upvote_count":"2","poster":"dpinlaguna","comment_id":"137434"},{"poster":"kondapaturi","timestamp":"1590897720.0","upvote_count":"5","comment_id":"99118","content":"SLA for Virtual Machines\nLast updated: January 2020\n\nFor all Virtual Machines that have two or more instances deployed across two or more Availability Zones in the same Azure region, we guarantee you will have Virtual Machine Connectivity to at least one instance at least 99.99% of the time.\nFor all Virtual Machines that have two or more instances deployed in the same Availability Set or in the same Dedicated Host Group, we guarantee you will have Virtual Machine Connectivity to at least one instance at least 99.95% of the time.\nFor any Single Instance Virtual Machine using Premium SSD or Ultra Disk for all Operating System Disks and Data Disks, we guarantee you will have Virtual Machine Connectivity of at least 99.9%."},{"timestamp":"1590866400.0","poster":"quokka","upvote_count":"1","comment_id":"99004","content":"Incomplete solution as you can't get 99.95% SLA without a load balancer in front of the 2 VMs in the same Availability Set:\n1. Create an Availability Set for 99.95% (can't create after VM has been created)\n2. Create the 2 VMs in the same region and subnet as the avset and specify:\n a. avail option=Availability Set, select the AVSET\n b. use Premium SSD as managed disk (default)\n c. don't specify public IP\n3. Create a Standard SKU load balancer in the same region and specify the 2 VMs in the avset as the backpool."},{"content":"Incomplete solution as you can't get 99.95% SLA without a load balancer in front of the 2 VMs in the same Availability Set:\n1. Create an Availability Set for 99.95% (can't create after VM has been created)\n2. Create the 2 VMs in the same region and subnet as the avset and specify:\n a. avail option=Availability Set, select the AVSET\n b. use Premium SSD as managed disk (default)\n c. don't specify public IP\n3. Create a Standard SKU load balancer in the same region and specify the 2 VMs in the avset as the backpool.","upvote_count":"1","timestamp":"1590863700.0","poster":"quokka","comment_id":"98979"},{"poster":"TYT","upvote_count":"2","comment_id":"78904","timestamp":"1587692220.0","content":"Go to Virtual Machines, +New or create, Select Ubuntu Image, Select Size, Create a new availability set with (2,3 or any domains) to get 99.95% availability. \nGo to create a new VM, Ubuntu Image, Add it to the same availability set that you created above, select size, save.","comments":[{"upvote_count":"1","poster":"kumar123","comment_id":"83694","content":"Once VM created, go to Disk blade and add a managed disk.","comments":[{"upvote_count":"1","timestamp":"1589239200.0","content":"VM created default with managed disk only","poster":"crossroads","comment_id":"87360"}],"timestamp":"1588609080.0"}]}],"answers_community":[],"url":"https://www.examtopics.com/discussions/microsoft/view/5604-exam-az-300-topic-1-question-59-discussion/","question_id":55,"answer_images":[],"question_images":["https://www.examtopics.com/assets/media/exam-media/02758/0018300001.png","https://www.examtopics.com/assets/media/exam-media/02758/0018400001.jpg","https://www.examtopics.com/assets/media/exam-media/02758/0018500001.jpg","https://www.examtopics.com/assets/media/exam-media/02758/0018600001.jpg","https://www.examtopics.com/assets/media/exam-media/02758/0018700001.jpg","https://www.examtopics.com/assets/media/exam-media/02758/0018800001.jpg"],"topic":"1","answer_description":"Step 1: Open the Azure portal.\nStep 2: On the left menu, select All resources. You can sort the resources by Type to easily find your images.\nStep 3: Select the image you want to use from the list. The image Overview page opens.\nStep 4: Select Create VM from the menu.\nStep 5: Enter the virtual machine information. Select VM1003a as the name for the first Virtual machine.The user name and password entered here will be used to log in to the virtual machine. When complete, select OK. You can create the new VM in an existing resource group, or choose Create new to create a new resource group to store the VM.\nStep 6: Select a size for the VM. To see more sizes, select View all or change the Supported disk type filter.\nStep 7: Under Settings, make changes as necessary and select OK.\nStep 8: On the summary page, you should see your image name listed as a Private image. Select Ok to start the virtual machine deployment.\nRepeat the procedure for the second VM and name it VM1003b.\nReferences:\nhttps://docs.microsoft.com/en-us/azure/virtual-machines/windows/create-vm-generalized-managed","exam_id":50,"answer_ET":"See solution below."}],"exam":{"numberOfQuestions":241,"provider":"Microsoft","isBeta":false,"id":50,"isMCOnly":false,"name":"AZ-300","lastUpdated":"12 Apr 2025","isImplemented":true},"currentPage":11},"__N_SSP":true}