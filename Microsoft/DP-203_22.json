{"pageProps":{"questions":[{"id":"DQAuNroNbKsHo0SiDzD8","answer_images":["https://img.examtopics.com/dp-203/image315.png"],"question_text":"HOTSPOT\n-\n\nYou are incrementally loading data into fact tables in an Azure Synapse Analytics dedicated SQL pool.\n\nEach batch of incoming data is staged before being loaded into the fact tables.\n\nYou need to ensure that the incoming data is staged as quickly as possible.\n\nHow should you configure the staging tables? To answer, select the appropriate options in the answer area.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","question_images":["https://img.examtopics.com/dp-203/image314.png"],"answer_ET":"","answer_description":"","unix_timestamp":1686229680,"discussion":[{"timestamp":"1718937900.0","poster":"orionduo","upvote_count":"23","content":"Correct!\nThe ROUND_ROBIN distribution distributes the data evenly across all distribution nodes in the SQL pool. This distribution type is suitable for loading data quickly into the staging tables because it minimizes the data movement during the loading process.\n\nUse a HEAP table: Instead of creating a clustered index on the staging table, it is recommended to create a HEAP table. A HEAP table does not have a clustered index, which eliminates the need for maintaining the index and improves the data loading performance. It allows for faster insert operations.","comment_id":"928988"},{"upvote_count":"1","poster":"kkk5566","content":"correct","timestamp":"1725441240.0","comments":[{"comment_id":"998410","poster":"kkk5566","timestamp":"1725441360.0","content":"For the staging data","upvote_count":"1"}],"comment_id":"998408"},{"content":"ans is correct","comment_id":"982046","timestamp":"1723761540.0","poster":"Deeksha1234","upvote_count":"2"},{"upvote_count":"3","poster":"mehroosali","content":"correct","comment_id":"920291","timestamp":"1718058000.0"},{"comment_id":"919286","poster":"abdallaissa","upvote_count":"2","content":"Correct","timestamp":"1717935060.0"},{"content":"Correct","poster":"IanKwok81","timestamp":"1717852080.0","comment_id":"918304","upvote_count":"2"}],"topic":"1","timestamp":"2023-06-08 15:08:00","isMC":false,"question_id":106,"url":"https://www.examtopics.com/discussions/microsoft/view/111555-exam-dp-203-topic-1-question-89-discussion/","exam_id":67,"answer":"","answers_community":[]},{"id":"qqZH8TzGFnoTxmxTeCQt","unix_timestamp":1631737620,"url":"https://www.examtopics.com/discussions/microsoft/view/62129-exam-dp-203-topic-1-question-9-discussion/","answer_ET":"","answer_images":["https://www.examtopics.com/assets/media/exam-media/04259/0003300001.png"],"isMC":false,"question_text":"HOTSPOT -\nYou have a data model that you plan to implement in a data warehouse in Azure Synapse Analytics as shown in the following exhibit.\n//IMG//\n\nAll the dimension tables will be less than 2 GB after compression, and the fact table will be approximately 6 TB. The dimension tables will be relatively static with very few data inserts and updates.\nWhich type of table should you use for each table? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","exam_id":67,"question_images":["https://www.examtopics.com/assets/media/exam-media/04259/0003000001.png","https://www.examtopics.com/assets/media/exam-media/04259/0003100001.png"],"answer":"","discussion":[{"comments":[{"comments":[{"poster":"berserksap","timestamp":"1635495600.0","content":"Normally for big tables we use clustered columnstore index for optimal performance and compression. Since the table mentioned here is in TBs we can safely assume using this index is the best choice\nhttps://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-index","upvote_count":"3","comment_id":"469657","comments":[{"timestamp":"1635495840.0","comment_id":"469659","upvote_count":"1","poster":"berserksap","content":"https://docs.microsoft.com/en-us/azure/synapse-analytics/sql/develop-tables-overview"}]}],"timestamp":"1633365000.0","content":"Thanks, but where in the question does it indicate about Fact table has clustered columnstore index.?","poster":"GameLift","comment_id":"457256","upvote_count":"3"},{"poster":"Tara123","comments":[{"timestamp":"1703089860.0","poster":"lisa710","content":"exceeding 10 gigabytes (GB) are often considered large","comment_id":"1101738","upvote_count":"5"}],"comment_id":"1095808","upvote_count":"1","timestamp":"1702500000.0","content":"Can you please explain for Dimension table it is mentioned that \"If tables are too large\" use Hash distribution. Here Too large means how much?I am waiting for your reply🙏🙏🙏🙏"},{"upvote_count":"7","comment_id":"613385","timestamp":"1654706340.0","poster":"virendrapsingh","content":"This is a wonderful explanation. Worth giving a like."}],"content":"The answer is correct.\nThe Dims are under 2gb so no point in use hash.\n\nCommon distribution methods for tables:\n\nThe table category often determines which option to choose for distributing the table.\nTable category Recommended distribution option\nFact -Use hash-distribution with clustered columnstore index. Performance improves when two hash tables are joined on the same distribution column.\nDimension - Use replicated for smaller tables. If tables are too large to store on each Compute node, use hash-distributed.\nStaging - Use round-robin for the staging table. The load with CTAS is fast. Once the data is in the staging table, use INSERT...SELECT to move the data to production tables.\nhttps://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-overview#common-distribution-methods-for-tables","timestamp":"1631737620.0","poster":"ian_viana","upvote_count":"240","comment_id":"445456"},{"comment_id":"466756","poster":"ohana","upvote_count":"49","content":"Took the exam today, this question came out. \nAns: All the Dim tables --> Replicated\nFact Tables --> Hash Distributed","timestamp":"1635024960.0"},{"content":"Replicated\nReplicated\nReplicated\nHash Dist","timestamp":"1743019620.0","poster":"technoguy","comment_id":"1410544","upvote_count":"1"},{"comment_id":"1342469","poster":"krishna1303","upvote_count":"1","timestamp":"1737194880.0","content":"Dim_customers,Dim_Employees,Dim_time are replicated\nand Fact_DailyBooking table is hash distributed"},{"content":"The answer is correct.","comment_id":"1317936","poster":"EmnCours","timestamp":"1732600920.0","upvote_count":"1"},{"upvote_count":"1","content":"this explains better\nhttps://www.youtube.com/watch?v=seiJ2xpW0h8","comment_id":"1258553","poster":"RookieCloudEngineer","timestamp":"1722398760.0"},{"upvote_count":"4","timestamp":"1710414840.0","poster":"Bakachi55","content":"Dear Community,\n\nI would like to express my heartfelt gratitude for the thoughtful mock questions that have been shared. Your generosity in providing these valuable resources has been immensely helpful. As we engage in discussions and learn together, I am reminded of the strength and camaraderie that exists within our community.\n\nTo everyone who has contributed, whether by creating questions, participating in discussions, or simply offering encouragement, thank you. Your collective efforts make this community a vibrant and supportive place for learning and growth.\n\nLet us continue to share knowledge, support one another, and celebrate our shared passion for learning","comment_id":"1173323"},{"poster":"Alongi","comment_id":"1172379","upvote_count":"3","timestamp":"1710319080.0","content":"All Dim Tables, if less than 2 GB, will be REPLICATED.\nFor Fact Table, if major than 10 GB, will be HASH DIST."},{"content":"REplicated,REplicated,REplicated and hash","timestamp":"1702890600.0","upvote_count":"1","comment_id":"1099558","poster":"dakku987"},{"comment_id":"1001213","poster":"hassexat","timestamp":"1694065860.0","content":"Replicated / Replicated / Replicated / Hash","upvote_count":"1"},{"timestamp":"1693315440.0","upvote_count":"1","comment_id":"993136","content":"Ans: All the Dim tables --> Replicated Fact Tables --> Hash Distributed\nis correct","poster":"kkk5566"},{"comment_id":"946611","content":"https://learn.microsoft.com/en-us/training/modules/design-multidimensional-schema-to-optimize-analytical-workloads/3-create-tables","poster":"DataEngDP","timestamp":"1688831460.0","upvote_count":"2"},{"comment_id":"946608","content":"https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-best-practices#batch-jobs-structure \n\nDimension tables: Replicated distribution since data movement is absent here.\nFact Table: Hash distribution to improve performance of moving data.","poster":"DataEngDP","upvote_count":"1","timestamp":"1688831100.0"},{"upvote_count":"3","content":"Dim_*: Replicated\nSince dimension tables are less likely to get frequent updates and are usually smaller in size, replicating them across all partitions makes logical sense. Also, Tables less than 2gb size should be replicated.\n\nFact_*: Hash Distributed\nSince Fact tables are huge and have frequent insert/delete/updates going on, hash distribution is the perfect distribution candidate. Also, Tables greater than 2gb size should be hash distributed.","comment_id":"746812","timestamp":"1671165720.0","poster":"vigilante89"},{"comment_id":"646416","content":"correct","timestamp":"1660410180.0","poster":"Deeksha1234","upvote_count":"1"},{"content":"Just a better link that explains the decisions. Also watch the video, it's cool.\nhttps://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/massively-parallel-processing-mpp-architecture","poster":"objecto","upvote_count":"2","comment_id":"609113","timestamp":"1653903600.0"},{"content":"The answer is correct.","upvote_count":"1","comment_id":"600066","poster":"Dothy","timestamp":"1652266560.0"},{"poster":"PallaviPatel","comment_id":"532059","content":"correct answer","upvote_count":"2","timestamp":"1643109240.0"},{"content":"Ans is correct","poster":"Mahesh_mm","upvote_count":"2","comment_id":"509986","timestamp":"1640576220.0"},{"timestamp":"1635755160.0","upvote_count":"1","comment_id":"471084","poster":"alfonsodisalvo","content":"Dimension are Replicated : \n\"Since the table has multiple copies, replicated tables work best when the table size is less than 2 GB compressed.\"\n\"Replicated tables may not yield the best query performance when:\n\nThe table has frequent insert, update, and delete operations\"\n\" We recommend using replicated tables instead of round-robin tables in most cases\"\nhttps://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/design-guidance-for-replicated-tables"},{"upvote_count":"1","comment_id":"466528","poster":"gssd4scoder","content":"Correct: https://docs.microsoft.com/en-us/azure/synapse-analytics/sql/develop-tables-overview#common-distribution-methods-for-tables","timestamp":"1634988420.0"}],"answers_community":[],"question_id":107,"answer_description":"Box 1: Replicated -\nReplicated tables are ideal for small star-schema dimension tables, because the fact table is often distributed on a column that is not compatible with the connected dimension tables. If this case applies to your schema, consider changing small dimension tables currently implemented as round-robin to replicated.\n\nBox 2: Replicated -\n\nBox 3: Replicated -\n\nBox 4: Hash-distributed -\nFor Fact tables use hash-distribution with clustered columnstore index. Performance improves when two hash tables are joined on the same distribution column.\nReference:\nhttps://azure.microsoft.com/en-us/updates/reduce-data-movement-and-make-your-queries-more-efficient-with-the-general-availability-of-replicated-tables/ https://azure.microsoft.com/en-us/blog/replicated-tables-now-generally-available-in-azure-sql-data-warehouse/","timestamp":"2021-09-15 22:27:00","topic":"1"},{"id":"Fd11gLnBvZJTXwjRdF08","timestamp":"2023-08-04 09:34:00","answer":"ACD","isMC":true,"exam_id":67,"question_text":"You have an Azure subscription that contains an Azure Synapse Analytics workspace named ws1 and an Azure Cosmos DB database account named Cosmos1. Cosmos1 contains a container named container1 and ws1 contains a serverless SQL pool.\n\nYou need to ensure that you can query the data in container1 by using the serverless SQL pool.\n\nWhich three actions should you perform? Each correct answer presents part of the solution.\n\nNOTE: Each correct selection is worth one point.","answer_ET":"ACD","url":"https://www.examtopics.com/discussions/microsoft/view/117304-exam-dp-203-topic-1-question-90-discussion/","answers_community":["ACD (100%)"],"question_images":[],"unix_timestamp":1691134440,"choices":{"E":"Disable indexing for container1.","A":"Enable Azure Synapse Link for Cosmos1.","B":"Disable the analytical store for container1.","D":"Enable the analytical store for container1.","C":"In ws1, create a linked service that references Cosmos1."},"answer_description":"","question_id":108,"topic":"1","discussion":[{"upvote_count":"5","poster":"pramod4lk","timestamp":"1691134440.0","content":"The answer is correct. We need to enable an analytical store in container1.","comment_id":"971796"},{"content":"Selected Answer: ACD\nA C D are correct","upvote_count":"1","timestamp":"1739002800.0","poster":"owl29208","comment_id":"1353289"},{"upvote_count":"1","timestamp":"1733425560.0","content":"Selected Answer: ACD\nActivez Azure Synapse Link pour Cosmos1 :\n\nA. Activez Azure Synapse Link pour Cosmos1. Cela permet d'intégrer Azure Synapse Analytics avec Azure Cosmos DB pour l'analyse des donnée\nActivez le magasin analytique pour le conteneur 1 :\n\nD. Activez le magasin analytique pour le conteneur 1. Le magasin analytique doit être activé pour permettre l'interrogation des données à l'aide de Synapse SQL\nDans ws1, créez un service lié qui référence Cosmos1 :\n\nC. Dans ws1, créez un service lié qui référence Cosmos1. Cela permet de configurer la connexion entre Azure Synapse Analytics et Azure Cosmos DB","comment_id":"1322495","poster":"moize"},{"poster":"EmnCours","timestamp":"1732910700.0","upvote_count":"1","comment_id":"1319901","content":"Selected Answer: ACD\nCorrect Answer: ACD"},{"upvote_count":"1","poster":"rocky48","content":"To enable querying data in container1 using the serverless SQL pool, you should perform the following actions:\n\nEnable Azure Synapse Link for Cosmos1: This allows seamless integration between Azure Synapse Analytics and Cosmos DB, enabling efficient querying of data stored in Cosmos DB containers 1.\nCreate a linked service in ws1 that references Cosmos1: By creating a linked service, you establish a connection to your Cosmos DB account, allowing the serverless SQL pool to access data from Cosmos1 2.\nDisable the analytical store for container1: Since we want to query data using the serverless SQL pool, we don’t need the analytical store feature for this specific scenario 3.\nTherefore, the correct actions are A, C, and B.","comments":[{"timestamp":"1711851720.0","poster":"lcss27","comment_id":"1186535","content":"\"Make sure that you have prepared Analytical store\" is a prerequisite.\nhttps://learn.microsoft.com/en-us/azure/synapse-analytics/sql/query-cosmos-db-analytical-store?tabs=openrowset-key#prerequisites","upvote_count":"2"}],"comment_id":"1148896","timestamp":"1707801720.0"},{"timestamp":"1706164620.0","upvote_count":"1","comment_id":"1131384","comments":[{"poster":"MBRSDG","content":"If you need also synapse pipelines, adding a linked service is a requirement. It is a little trap, I think.","comment_id":"1188520","timestamp":"1712130720.0","upvote_count":"1"}],"content":"There are only 2 Correct answers.\nA & D. You don't need a linked Service to query Cosmos DB from Serverless Pool.\nhttps://learn.microsoft.com/en-us/azure/synapse-analytics/sql/query-cosmos-db-analytical-store?tabs=openrowset-key#prerequisites","poster":"ChrisGe1234"},{"poster":"AvSUN","upvote_count":"1","timestamp":"1693982460.0","content":"Correct","comment_id":"1000296"},{"upvote_count":"1","poster":"kkk5566","timestamp":"1693819020.0","comment_id":"998412","content":"Selected Answer: ACD\ncorrect"},{"timestamp":"1692818340.0","upvote_count":"1","poster":"gusztimm","content":"Selected Answer: ACD\nCorrect","comment_id":"988636"},{"comment_id":"982048","poster":"Deeksha1234","content":"The answer is correct","timestamp":"1692139260.0","upvote_count":"2"}],"answer_images":[]},{"id":"tUXZVplzbUmhFrM3X4nf","answer_ET":"","question_images":["https://img.examtopics.com/dp-203/image324.png","https://img.examtopics.com/dp-203/image325.png","https://img.examtopics.com/dp-203/image326.png","https://img.examtopics.com/dp-203/image327.png","https://img.examtopics.com/dp-203/image328.png"],"answer_description":"","url":"https://www.examtopics.com/discussions/microsoft/view/117107-exam-dp-203-topic-1-question-91-discussion/","isMC":false,"question_id":109,"timestamp":"2023-08-02 13:59:00","answer":"","answer_images":["https://img.examtopics.com/dp-203/image329.png"],"exam_id":67,"question_text":"HOTSPOT\n-\n\nYou have an Azure subscription that contains the resources shown in the following table.\n\n//IMG//\n\n\nThe storage1 account contains a container named container1. The container1 container contains the following files.\n\n//IMG//\n\n\nIn Pool1, you run the following script.\n\n//IMG//\n\n\nIn the Built-in serverless SQL pool, you run the following script.\n\n//IMG//\n\n\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","topic":"1","answers_community":[],"discussion":[{"comment_id":"971798","content":"The answer is No, Yes, No\nIt will ignore \"_\" and \".\"","upvote_count":"54","timestamp":"1691134740.0","poster":"pramod4lk"},{"timestamp":"1691042040.0","poster":"pc1337xd","content":"Both Hadoop(dedicated) and native(serverless) external tables will skip the files with the names that begin with an underline (_) or a period (.).","upvote_count":"12","comment_id":"970777"},{"upvote_count":"2","timestamp":"1741963020.0","content":"NO YES NO\n\nYou can't read hidden files on both hadoop and native query tables . i.e _xxxx or .xxxxx will be hidden","poster":"AMJB","comment_id":"1395621"},{"upvote_count":"1","timestamp":"1719402840.0","poster":"CezarioAbrantesPP","comment_id":"1237428","content":"Both Hadoop and native external tables will skip the files with the names that begin with an underline (_) or a period (.)"},{"upvote_count":"2","timestamp":"1713960960.0","content":"No No No","comment_id":"1201339","poster":"Dusica"},{"poster":"shadow2332","timestamp":"1707815700.0","upvote_count":"6","comment_id":"1149026","content":"No, No, No\nBecause names that begin with an underline (_) or a period (.) are ignored and in the mentioned location, it will not be going to read subfolders, until '/**' is mentioned.","comments":[{"poster":"5a939c2","upvote_count":"3","comment_id":"1252823","timestamp":"1721623260.0","content":"No, Yes, No\nIn serverless SQL pools must be specified /** at the end of the location path. In Dedicated pool the folders are always scanned recursively."},{"timestamp":"1711852920.0","comment_id":"1186546","poster":"lcss27","content":"when you use DATA SOURCE to create an External Table you also use LOCATION (where you specified the relative path e.g. '/directory/**')\nhttps://learn.microsoft.com/en-us/sql/t-sql/statements/create-external-table-transact-sql?view=azure-sqldw-latest&tabs=dedicated#b-import-data-from-parquet-into-","upvote_count":"1"}]},{"content":"Réponse trouvée : Non - Oui - Non. Lien de référence est : https://learn.microsoft.com/en-us/sql/t-sql/statements/create-external-table-transact-sql?view=azure-sqldw-latest&tabs=dedicated#location--folder_or_filepath-1","comment_id":"1117748","upvote_count":"1","timestamp":"1704824880.0","poster":"moize"},{"poster":"hcq31818","timestamp":"1701931440.0","content":"No, Yes, No","comment_id":"1089999","upvote_count":"1"},{"poster":"AvSUN","comment_id":"1000307","timestamp":"1693982940.0","upvote_count":"5","content":"NO, YES, NO\n\nhttps://learn.microsoft.com/en-us/sql/t-sql/statements/create-external-table-transact-sql?view=azure-sqldw-latest&tabs=dedicated#location--folder_or_filepath-1"},{"upvote_count":"4","poster":"kkk5566","content":"NO\nYES\nNO\nsee previous quizs.","timestamp":"1693819440.0","comment_id":"998416"},{"upvote_count":"3","poster":"subhraz","content":"NO\nYES\nNO","timestamp":"1693358880.0","comment_id":"993635"},{"poster":"g2000","timestamp":"1690977540.0","content":"The last one is No. File is prefxied with a period and therefore can't be returned.\nhttps://learn.microsoft.com/en-us/sql/t-sql/statements/create-external-table-transact-sql?view=azure-sqldw-latest&tabs=dedicated#location--folder_or_filepath-1","upvote_count":"4","comment_id":"970126"}],"unix_timestamp":1690977540},{"id":"gUubqAjxVDl3ZdsT9GsH","answer_description":"","answer_images":["https://img.examtopics.com/dp-203/image331.png"],"question_images":["https://img.examtopics.com/dp-203/image330.png"],"answer":"","discussion":[{"content":"correct!\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-access-control#levels-of-permission","timestamp":"1706882760.0","upvote_count":"21","comment_id":"970133","poster":"g2000"},{"upvote_count":"6","timestamp":"1722583800.0","comment_id":"1138371","poster":"saqib839","content":"Execute permission to container1 to navigate to folder1 and Read & Execute permission to folder1 to list and read all files present in there."},{"poster":"Alongi","content":"Correct, execute is to navigate folders","upvote_count":"1","comment_id":"1182799","timestamp":"1727292780.0"},{"poster":"TuxBingo","upvote_count":"1","timestamp":"1720296600.0","comment_id":"1115468","content":"Correct"},{"content":"correct","poster":"kkk5566","timestamp":"1709551620.0","comment_id":"998418","upvote_count":"2"}],"url":"https://www.examtopics.com/discussions/microsoft/view/117108-exam-dp-203-topic-1-question-92-discussion/","exam_id":67,"unix_timestamp":1690977960,"answers_community":[],"answer_ET":"","topic":"1","timestamp":"2023-08-02 14:06:00","question_text":"DRAG DROP\n-\n\nYou have an Azure subscription that contains an Azure Data Lake Storage Gen2 account named account1 and a user named User1.\n\nIn account1, you create a container named container1. In container1, you create a folder named folder1.\n\nYou need to ensure that User1 can list and read all the files in folder1. The solution must use the principle of least privilege.\n\nHow should you configure the permissions for each folder? To answer, drag the appropriate permissions to the correct folders. Each permission may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","isMC":false,"question_id":110}],"exam":{"isMCOnly":false,"lastUpdated":"12 Apr 2025","provider":"Microsoft","id":67,"isBeta":false,"isImplemented":true,"numberOfQuestions":384,"name":"DP-203"},"currentPage":22},"__N_SSP":true}