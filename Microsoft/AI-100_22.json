{"pageProps":{"questions":[{"id":"Mu2GBO4k2aEgymfLwgPL","discussion":[{"content":"A. Yes\n\nMigrating all the entries to the LargePersonGroup object for Ben Smith would meet the goal of allowing additional entries to be added. The LargePersonGroup object has a higher capacity than the regular PersonGroup object, allowing for more entries to be stored. By migrating all the entries from the existing PersonGroup object to the LargePersonGroup object, you would be able to accommodate additional entries for Ben Smith while ensuring that he can be identified by all the entries.","poster":"rveney","upvote_count":"1","timestamp":"1687420200.0","comment_id":"930263"},{"upvote_count":"1","content":"this was in the AI-100 exam i took today, May 31","poster":"berserkguts","timestamp":"1622444220.0","comment_id":"370736"},{"content":"The answer is correct. https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395244","comment_id":"259149","timestamp":"1609738020.0","poster":"nohaph","upvote_count":"3"}],"exam_id":39,"question_id":106,"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou have an app named App1 that uses the Face API.\nApp1 contains several PersonGroup objects.\nYou discover that a PersonGroup object for an individual named Ben Smith cannot accept additional entries. The PersonGroup object for Ben Smith contains\n10,000 entries.\nYou need to ensure that additional entries can be added to the PersonGroup object for Ben Smith. The solution must ensure that Ben Smith can be identified by all the entries.\nSolution: You migrate all the entries to the LargePersonGroup object for Ben Smith.\nDoes this meet the goal?","choices":{"A":"Yes","B":"No"},"isMC":true,"answer_description":"LargePersonGroup and LargeFaceList are collectively referred to as large-scale operations. LargePersonGroup can contain up to 1 million persons, each with a maximum of 248 faces. LargeFaceList can contain up to 1 million faces. The large-scale operations are similar to the conventional PersonGroup and FaceList but have some differences because of the new architecture.\nReferences:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/how-to-use-large-scale","answer_ET":"A","answer_images":[],"unix_timestamp":1609738020,"answers_community":[],"answer":"A","timestamp":"2021-01-04 06:27:00","url":"https://www.examtopics.com/discussions/microsoft/view/41453-exam-ai-100-topic-2-question-7-discussion/","topic":"2","question_images":[]},{"id":"24Tr8AMBIelasxYGFwnl","answer_description":"The first step is to create voice signatures for the conversation participants. Creating voice signatures is required for efficient speaker identification.\nNote: In addition to the standard baseline model used by the Speech Services, you can customize models to your needs with available data, to overcome speech recognition barriers such as speaking style, vocabulary and background noise.\nReferences:\nhttps://docs.microsoft.com/bs-latn-ba/azure/cognitive-services/speech-service/how-to-use-conversation-transcription-service","answer_images":[],"answer":"B","url":"https://www.examtopics.com/discussions/microsoft/view/24530-exam-ai-100-topic-2-question-8-discussion/","answer_ET":"B","answers_community":[],"question_images":[],"discussion":[{"content":"recommended task to ensure that the transcripts can identify all participants is to create a voice signature (Option B).","poster":"rveney","comment_id":"927510","upvote_count":"1","timestamp":"1687179840.0"},{"content":"This question was in the exam.","upvote_count":"1","comment_id":"362053","poster":"fhqhfhqh","timestamp":"1621506480.0"},{"timestamp":"1616489760.0","comment_id":"317910","upvote_count":"3","poster":"AlfuryDB","content":"\"The first step is to create voice signatures for the conversation participants so that they can be identified as unique speakers. The input .wav audio file for creating voice signatures should be 16-bit, 16 kHz sample rate, and single channel (mono) format....\" link: https://docs.microsoft.com/bs-latn-ba/azure/cognitive-services/speech-service/how-to-use-conversation-transcription?pivots=programming-language-javascript"},{"timestamp":"1613267520.0","poster":"Cornholioz","content":"Wrong IMO. This is what I could infer:\nThe prerequisite (mentioned in the article too) is to \"Sign up for Speech Services\". To use the REST API to create a Voice Signature, you need to sign up first.\nhttps://docs.microsoft.com/bs-latn-ba/azure/cognitive-services/speech-service/how-to-use-conversation-transcription?pivots=programming-language-javascript#prerequisites","comment_id":"289909","comments":[{"timestamp":"1613764080.0","poster":"Cornholioz","comment_id":"294573","content":"I may be wrong. Retracting. \nThe questions says, \"You need to recommend which task EACH MEETING PARTICIPANT must perform\", and not what YOU would do. YOU would sign up for Speech Services. But wouldn't recommend each participant to sign up. Each participant would Create a Voice Signature.\nGiven answer is correct.","upvote_count":"5"}],"upvote_count":"1"},{"content":"correct","upvote_count":"4","poster":"xing","comment_id":"124267","timestamp":"1593609720.0"}],"timestamp":"2020-07-01 15:22:00","exam_id":39,"unix_timestamp":1593609720,"question_id":107,"question_text":"Your company plans to develop a mobile app to provide meeting transcripts by using speech-to-text. Audio from the meetings will be streamed to provide real-time transcription.\nYou need to recommend which task each meeting participant must perform to ensure that the transcripts of the meetings can identify all participants.\nWhich task should you recommend?","choices":{"A":"Record the meeting as an MP4.","C":"Sign up for Azure Speech Services.","B":"Create a voice signature.","D":"Sign up as a guest in Azure Active Directory (Azure AD)"},"isMC":true,"topic":"2"},{"id":"HgrbGnePSoYtKPuGaNjg","answer":"A","question_images":[],"choices":{"D":"LuDown","A":"Chatdown","C":"Dispatch","B":"QnAMaker"},"url":"https://www.examtopics.com/discussions/microsoft/view/44644-exam-ai-100-topic-2-question-9-discussion/","exam_id":39,"question_id":108,"discussion":[{"timestamp":"1687179840.0","poster":"rveney","content":"recommended botbuilder CLI tool to use for creating a prototype of a bot to demonstrate a user performing a task in the Bot Framework Emulator is Chatdown (Option A).","upvote_count":"1","comment_id":"927511"},{"poster":"123aditya","upvote_count":"1","comment_id":"393772","timestamp":"1624969620.0","content":"https://github.com/microsoft/botframework-cli/blob/main/packages/chatdown/docs/chatdown-format.md"},{"timestamp":"1622586000.0","upvote_count":"1","comment_id":"372225","content":"Ok - so this was in my exam. I got this wrong. It is chatdown i choose dispatch lol","poster":"PinkUnicorns"},{"upvote_count":"1","comment_id":"370737","timestamp":"1622444220.0","poster":"berserkguts","content":"this was in the AI-100 exam i took today, May 31"},{"timestamp":"1613268480.0","content":"Correct","poster":"Cornholioz","upvote_count":"1","comment_id":"289916"}],"answers_community":[],"answer_images":[],"topic":"2","isMC":true,"answer_description":"Use Chatdown to produce prototype mock conversations in markdown and convert the markdown to transcripts you can load and view in the new V4 Bot\nFramework Emulator.\nIncorrect Answers:\nB: QnA Maker is a cloud-based API service that lets you create a conversational question-and-answer layer over your existing data. Use it to build a knowledge base by extracting questions and answers from your semi-structured content, including FAQs, manuals, and documents. Answer users' questions with the best answers from the QnAs in your knowledge baseג€\"automatically. Your knowledge base gets smarter, too, as it continually learns from user behavior.\nC: Dispatch lets you build language models that allow you to dispatch between disparate components (such as QnA, LUIS and custom code).\nD: LuDown build LUIS language understanding models using markdown files\nReferences:\nhttps://github.com/microsoft/botframework/blob/master/README.md","answer_ET":"A","question_text":"You need to create a prototype of a bot to demonstrate a user performing a task. The demonstration will use the Bot Framework Emulator.\nWhich botbuilder CLI tool should you use to create the prototype?","timestamp":"2021-02-14 03:08:00","unix_timestamp":1613268480},{"id":"G4IkY58iRCOR5qPaWgsC","topic":"3","question_id":109,"question_text":"You need to build an API pipeline that analyzes streaming data. The pipeline will perform the following:\n✑ Visual text recognition\n✑ Audio transcription\n✑ Sentiment analysis\n✑ Face detection\nWhich Azure Cognitive Services should you use in the pipeline?","answer_images":[],"unix_timestamp":1591042080,"answer_description":"Azure Video Indexer is a cloud application built on Azure Media Analytics, Azure Search, Cognitive Services (such as the Face API, Microsoft Translator, the\nComputer Vision API, and Custom Speech Service). It enables you to extract the insights from your videos using Video Indexer video and audio models described below:\n✑ Visual text recognition (OCR): Extracts text that is visually displayed in the video.\n✑ Audio transcription: Converts speech to text in 12 languages and allows extensions.\n✑ Sentiment analysis: Identifies positive, negative, and neutral sentiments from speech and visual text.\n✑ Face detection: Detects and groups faces appearing in the video.\nReferences:\nhttps://docs.microsoft.com/en-us/azure/media-services/video-indexer/video-indexer-overview","discussion":[{"comment_id":"100325","content":"The Question should be \"...which Azure Cognitive Service (without the plural s), otherwise it could be misunderstood that multiple solutions are right.","poster":"Egosyntonic","comments":[{"content":"radio button!!!... can you select more than 1 radio buttons!!!!","upvote_count":"2","poster":"UpsetUser","timestamp":"1610854320.0","comment_id":"269275"}],"upvote_count":"9","timestamp":"1591042080.0"},{"comment_id":"928507","timestamp":"1687270980.0","poster":"rveney","upvote_count":"1","content":"Based on the requirements listed, the appropriate Azure Cognitive Services for the API pipeline would be:\n\nFace API: for face detection\nText Analytics: for sentiment analysis\nTherefore, the correct options are B. Face API and C. Text Analytics."},{"timestamp":"1621128720.0","comment_id":"358271","poster":"PinkUnicorns","upvote_count":"2","content":"This question did appear in my exam that I took a few days ago"},{"comment_id":"298727","poster":"zzxl","content":"As of June 2020 the video indexer is not available for customers. So a high chance that this question will not appear in the exam ;)","comments":[{"comment_id":"385621","content":"I think, the question might still come up, since they have only changed the name of the service. https://docs.microsoft.com/en-us/azure/azure-video-analyzer/video-analyzer-for-media-docs/video-indexer-overview","poster":"damirbek369","upvote_count":"1","timestamp":"1624119600.0"},{"comment_id":"369153","poster":"BwandoWando","upvote_count":"1","content":"someone took an exam 1 week ago and this question is in the exam as per him, so you're incorrect based on the latest developments.","timestamp":"1622261640.0"}],"upvote_count":"2","timestamp":"1614224640.0"},{"content":"The answer is correct","timestamp":"1607242140.0","comment_id":"236272","poster":"blackdeath","upvote_count":"2"}],"answers_community":[],"exam_id":39,"answer":"D","timestamp":"2020-06-01 22:08:00","answer_ET":"D","isMC":true,"question_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/21838-exam-ai-100-topic-3-question-1-discussion/","choices":{"C":"Text Analytics","B":"Face API","D":"Video Indexer","A":"Custom Speech Service"}},{"id":"0PPpDscZRfMWq4dao5dj","answer":"C","question_images":[],"choices":{"C":"Experiments","D":"Pipelines","E":"Deployments","B":"Activities","A":"Models"},"url":"https://www.examtopics.com/discussions/microsoft/view/14691-exam-ai-100-topic-3-question-10-discussion/","exam_id":39,"question_id":110,"discussion":[{"upvote_count":"10","comment_id":"67858","timestamp":"1585076580.0","content":"will be E. To retrieve logs from a previously deployed web service, \n\nexperiments are only logging for code to a training script","poster":"putriafebriana"},{"poster":"bego310","upvote_count":"9","timestamp":"1600148340.0","comment_id":"179681","comments":[{"timestamp":"1622349540.0","poster":"BwandoWando","content":"no, the official Microsoft DP-100 reviewer from GITHUB which you can see here https://github.com/MicrosoftLearning/mslearn-dp100 uses experiment to do that. \n\nAlso, the link you shared, which shows the designer + code, still uses the experiment object beneath it , but rather than creating a simple run object, what gets created in the background is a pipeline_run, which is also still from the experiment object\n\nso answer is EXPERIMENT object","upvote_count":"1","comment_id":"369858"}],"content":"It is ML Pipelines https://docs.microsoft.com/en-us/azure/machine-learning/concept-ml-pipelines"},{"content":"c. Experiments - Based on the retrieved documents, the Azure Machine Learning service application that you should use to configure versioning and logging for Azure Machine Learning models is Experiments. Experiments allow you to track and manage the versions of your models and log the results of your experiments","poster":"rveney","timestamp":"1687284300.0","comment_id":"928671","upvote_count":"1"},{"comment_id":"429989","upvote_count":"1","content":"pipelines","poster":"dijaa","timestamp":"1629724200.0"},{"timestamp":"1623779940.0","poster":"shaimaalmeer","comment_id":"382832","upvote_count":"2","content":"Deployments is the correct answer"},{"timestamp":"1622344380.0","comment_id":"369829","upvote_count":"3","content":"if you download the official Microsoft DP-100 reviewer from GITHUB which you can see here https://github.com/MicrosoftLearning/mslearn-dp100\n\nyou can navigate to these notebooks\n\nYou can register a trained model using 2 approaches\n\n1. using the run.register_model() method which you get when you call experiment.submit() which was used in this notebook 05 - Train Models.ipynb\n2. the other method using the Model.register() method which was used in this notebook 08 - Create a Pipeline.ipynb\n\nNow regarding logging, you the run object has a number of logging methods\n\n1. run.log()\n2. run.log_image()\n3. run.log_table()\n4. run.log_row()\n5. run.log_list()\n\nthis is all from the \"run\" object that you get when invoking the experiment.submit() method, and we usually use the run.get_metrics() method to get all the logged metrics using the run.log() method when logging accuracy, f1, etc.\n\non the other hand, MODEL doesn't have any method that \"logs\" model performance\n\nso the answer is definitely EXPERIMENT","poster":"BwandoWando"},{"comment_id":"275370","timestamp":"1611499980.0","upvote_count":"5","poster":"TheMCT","content":"The answer is, C. Experiments, \nhttps://docs.microsoft.com/en-us/azure/machine-learning/studio/version-control"},{"timestamp":"1609790160.0","comment_id":"259683","upvote_count":"1","poster":"ahmed812","content":"https://docs.microsoft.com/en-us/azure/machine-learning/how-to-enable-app-insights\nDeployments??"},{"comments":[{"upvote_count":"1","timestamp":"1613055900.0","poster":"Cornholioz","comment_id":"288368","content":"Isn't this MLOps page talking more about Pipelines than Models? Model Registration is a process/step. Doesn't say how logging is achieved. Creating pipelines though makes way for both versioning and logging.\nI wouldn't call the question tricky... I call it poorly framed."}],"content":"It should be Models. 'Model registration allows you to store and version your models in the Azure cloud, in your workspace. The model registry makes it easy to organize and keep track of your trained models. After registration, you can then download or deploy the registered model and receive all the files that were registered.' \nhttps://docs.microsoft.com/en-us/azure/machine-learning/concept-model-management-and-deployment","timestamp":"1604013000.0","upvote_count":"5","poster":"nepketo","comment_id":"208925"},{"timestamp":"1600935540.0","comment_id":"185991","content":"for versioning I suppose you have to register the model by using the Model class like shown in the code snippet here https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.model?view=azure-ml-py\n\nand for logging you use Run class","comments":[{"comment_id":"185992","content":"so not sure what to mark here.","timestamp":"1600935540.0","upvote_count":"2","poster":"sayak17"}],"poster":"sayak17","upvote_count":"1"},{"timestamp":"1590840120.0","comment_id":"98812","poster":"giusecozza","upvote_count":"3","content":"The question is very tricky, as it is asking for logging and versioning for models, not experiment runs. Thinking about model versioning, it reminds me to model registry, which keeps multiple models versions and it comes with Model service:\nhttps://docs.microsoft.com/it-it/azure/machine-learning/concept-azure-machine-learning-architecture#models\n\nTalking about logging, it could be referred to logs from deployed models, as stated in the answer.\nAre we sure it is to select only one option? I would have said both Models and Deployments."},{"upvote_count":"2","timestamp":"1582378980.0","poster":"Vrage","comment_id":"53794","content":"I think this would be experiments?\nhttps://docs.microsoft.com/en-gb/azure/machine-learning/how-to-enable-logging#logging-for-deployed-models"}],"answers_community":[],"answer_images":[],"topic":"3","isMC":true,"answer_description":"Reference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/studio/version-control https://docs.microsoft.com/en-us/azure/machine-learning/how-to-track-experiments#logging-for-deployed-models","answer_ET":"C","timestamp":"2020-02-22 14:43:00","question_text":"You need to configure versioning and logging for Azure Machine Learning models.\nWhich Machine Learning service application should you use?","unix_timestamp":1582378980}],"exam":{"provider":"Microsoft","isBeta":false,"id":39,"isImplemented":true,"lastUpdated":"12 Apr 2025","isMCOnly":false,"numberOfQuestions":206,"name":"AI-100"},"currentPage":22},"__N_SSP":true}