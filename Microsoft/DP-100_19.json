{"pageProps":{"questions":[{"id":"G5RpCbA26ElqNq4fyRUv","question_id":91,"answer_images":[],"question_images":[],"unix_timestamp":1592819940,"timestamp":"2020-06-22 11:59:00","choices":{"C":"Build the environment in Apache Spark for HDInsight and use Azure Container Instances for orchestration.","A":"Build the environment in Apache Hive for HDInsight and use Azure Data Factory for orchestration.","B":"Build the environment in Azure Databricks and use Azure Data Factory for orchestration.","D":"Build the environment in Azure Databricks and use Azure Container Instances for orchestration."},"answer":"B","question_text":"Your team is building a data engineering and data science development environment.\nThe environment must support the following requirements:\n✑ support Python and Scala\n✑ compose data storage, movement, and processing services into automated data pipelines\n✑ the same tool should be used for the orchestration of both data engineering and data science\n✑ support workload isolation and interactive workloads\n✑ enable scaling across a cluster of machines\nYou need to create the environment.\nWhat should you do?","answer_description":"","topic":"2","answer_ET":"B","exam_id":64,"answers_community":["B (100%)"],"discussion":[{"poster":"Adi06","comments":[{"timestamp":"1652790360.0","content":"Agreed. If it was production environment, it should be Kubernetes services. Since it's development it should be container services. \n\nhttps://docs.microsoft.com/en-us/learn/modules/register-and-deploy-model-with-amls/2-deploy-model","comment_id":"359522","upvote_count":"1","poster":"allanm","comments":[{"timestamp":"1655533440.0","content":"you cant do orchestration with ACI, only with data factory, answer is correct.","poster":"levm39","upvote_count":"8","comment_id":"384615"}]},{"timestamp":"1653934320.0","upvote_count":"2","comment_id":"370385","content":"definitely d","poster":"prashantjoge"},{"comment_id":"420222","upvote_count":"1","poster":"strikchao","timestamp":"1659697020.0","content":"Not D. There is no autoscaling with ACI"}],"content":"Is the answer not D?? They are trying to build a development environment (line 1). Nowhere it says its for production environment.","timestamp":"1636761480.0","upvote_count":"9","comment_id":"218192"},{"poster":"phdykd","timestamp":"1706837700.0","content":"B.\nAzure Databricks is a fast, easy, and collaborative Apache Spark-based analytics platform that provides a complete environment for data engineering, machine learning, and data science. It supports Python and Scala, and allows you to compose data storage, movement, and processing services into automated data pipelines. Azure Data Factory, on the other hand, is a cloud-based data integration service that allows you to create, schedule, and orchestrate your data pipelines. By using both Databricks and Data Factory together, you can have a unified platform for both data engineering and data science that also supports workload isolation and interactive workloads, as well as enables scaling across a cluster of machines.","comment_id":"795670","upvote_count":"8"},{"timestamp":"1721048580.0","upvote_count":"4","content":"Selected Answer: B\nAzure Databricks is an obvious choice for the environment. To decide between Data Factory vs Container Instances for orchestration makes the difference here. ADF would be a more suitable choice compared to ACI for orchestration in this scenario due to\n\n1. Native Orchestration Capabilities\n2. Visual Workflow Designer\n3. Integration with Diverse Data Sources and Services\n4. Built-in Monitoring and Management\n\nTherefore, for the purpose of orchestrating data pipelines in a data engineering and data science environment, ADF would be the recommended choice due to its dedicated orchestration features, data integration capabilities, visual workflow designer, and integration with diverse data sources and services.","poster":"phydev","comment_id":"952399"},{"poster":"dija123","timestamp":"1669829340.0","content":"Selected Answer: B\nB without doubts","comment_id":"490879","upvote_count":"3"},{"content":"B is the right answer.\nC and D are out as there is need for data engineering \nSince there is need for \"both data engineering and data science\", there is need for Data Factory, hence C and D are out.\nDue to need for Scala and Python support, Databricks (B) is the correct answer.","timestamp":"1657923360.0","upvote_count":"6","poster":"kolakone","comment_id":"407452"},{"comment_id":"396453","timestamp":"1656722820.0","content":"B is correct","upvote_count":"3","poster":"Navishmamta1111111111111"},{"upvote_count":"1","comment_id":"390559","timestamp":"1656168240.0","poster":"okeyken1","content":"the correct answer is B"},{"content":"Previewed last year, Microsoft's Azure Container Instances (ACI) is now ready for production usage, according to the company. ... Microsoft promises an uptime service level agreement of 99.9 percent for any container group. Each container is secured and isolated through a VM hypervisor.","upvote_count":"1","timestamp":"1653857880.0","comment_id":"369729","poster":"MAGGCol"},{"upvote_count":"5","timestamp":"1653062820.0","comment_id":"362332","poster":"prashantjoge","content":"azure databricks support clustering while azure data factory supports orchestration (https://docs.microsoft.com/en-us/azure/databricks/clusters/configure). The orchestration here should be in the context of data processing (think SSIS, ETL, informatica etc.) Answer should be B. Azure containers instances provide some basic orchestration capabilities, but then again the context is different. https://docs.microsoft.com/en-us/azure/container-instances/container-instances-orchestrator-relationship"},{"content":"I think the best answer is B. ACI is used to deploy a model. ACI is just like docker - for orchestration you would need something like kubernetes not docker.","comment_id":"348846","upvote_count":"5","poster":"chaudha4","timestamp":"1651597620.0"},{"timestamp":"1649490180.0","comment_id":"331816","poster":"LakeSky","content":"Wow, so what's the correct answer really? Why is Azure Container not an option?","upvote_count":"2","comments":[{"upvote_count":"2","poster":"cab123","comment_id":"335584","timestamp":"1649949540.0","content":"I think Azure Container instances cannot do orchestration"}]}],"isMC":true,"url":"https://www.examtopics.com/discussions/microsoft/view/23701-exam-dp-100-topic-2-question-2-discussion/"},{"id":"DOn5ZZTli6bGxUPxbLmO","isMC":false,"answer_images":["https://www.examtopics.com/assets/media/exam-media/04274/0007600001.png"],"answers_community":[],"discussion":[{"upvote_count":"13","content":"was on exam 01/03/2023","poster":"MattAnya","timestamp":"1720064100.0","comment_id":"765281"},{"upvote_count":"9","poster":"atyagi55","content":"give answer is correct.Please refer link\nhttps://azure.github.io/azureml-sdk-for-r/reference/register_azure_blob_container_datastore.html\n\ncreate_if_not_exists \"If TRUE, creates the blob container if it does not exists.\"","comment_id":"344041","timestamp":"1666881360.0"},{"comment_id":"882309","content":"Answer is correct. We are not creating a container, only registering it and we need an error message if it does not exist. If we set \"create_if_not_exists\" to true, it will not display the error message but create the container and we dont want that.","upvote_count":"3","poster":"MarinaMijailovic","timestamp":"1730019120.0"},{"content":"You can resolve this by thinking logically. overwrite = False would mean, that we don't overwrite the existing file, but that we create a copy! create_if_not_exists = False won't create anything if there is an existing folder.","timestamp":"1697739780.0","comment_id":"588329","upvote_count":"3","poster":"ougullamaija"},{"poster":"azurelearner666","timestamp":"1696939560.0","comment_id":"583673","upvote_count":"4","content":"Correct,\nA: Register_azure_blob_container\nB: Create_if_not_exists = False\n\nFirst is easy, we are talking about storage accounts and a blob container.\nSecond too, It should raise an error if the container does not exist, so it should not create it in that case, as there would be no error then."},{"upvote_count":"2","comment_id":"570366","content":"on exam 18/03/2022","poster":"kkkk_jjjj","timestamp":"1695019140.0"},{"timestamp":"1692547380.0","comment_id":"552090","poster":"[Removed]","upvote_count":"2","content":"on 20Feb2022"},{"content":"on 19Oct2021","comment_id":"464978","upvote_count":"2","poster":"hargur","timestamp":"1681976460.0"},{"content":"On Exam 01 Oct 2021","upvote_count":"3","comment_id":"456716","poster":"kisskeo","timestamp":"1680545640.0"},{"content":"on exam 11/9/2021","poster":"mthombenindhl84","upvote_count":"2","comment_id":"443160","timestamp":"1678571820.0"},{"comment_id":"438283","content":"on exam 2/9/21","upvote_count":"1","poster":"snsnsnsn","timestamp":"1677828180.0"},{"content":"On exam 2021/08/31","timestamp":"1677556260.0","poster":"dushmantha","upvote_count":"1","comment_id":"435927"},{"upvote_count":"3","content":"on 2/8/2021","poster":"datamijn","timestamp":"1675327200.0","comment_id":"418545"},{"content":"on 17/7/2021","comment_id":"408385","upvote_count":"2","timestamp":"1673959800.0","poster":"Rosh4yuh"},{"poster":"ljljljlj","timestamp":"1673444880.0","content":"On exam 2021/7/10","comment_id":"403880","upvote_count":"3"},{"upvote_count":"2","comment_id":"366056","timestamp":"1669352640.0","content":"the answer does not satisfy the question\n\"ensure that an error will be raised if the container does not exist.\"","poster":"prashantjoge"},{"upvote_count":"4","timestamp":"1663948200.0","comment_id":"318325","content":"Answer is correct. There is a mistake in the documentation. Where it says 'file share', it is 'container'.","poster":"ACSC"},{"poster":"dev2dev","content":"2nd option should be overwrite = False create_if_not_exists is for the file share.","timestamp":"1663038180.0","comments":[{"upvote_count":"4","timestamp":"1663755360.0","poster":"Anty85","content":"Agreed. Incredible how many wrong answers can be found here.","comment_id":"316318"},{"comment_id":"332653","timestamp":"1665415440.0","upvote_count":"12","poster":"jamessnow","content":"the answer is correct don't comment if you not sure !"},{"comment_id":"325110","upvote_count":"13","content":"Answer is correct, if you are not sure don't post anything, you are adding to the confusion.\nHave a look at the documentation instead:\nhttps://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.datastore(class)?view=azure-ml-py#register-azure-blob-container-workspace--datastore-name--container-name--account-name--sas-token-none--account-key-none--protocol-none--endpoint-none--overwrite-false--create-if-not-exists-false--skip-validation-false--blob-cache-timeout-none--grant-workspace-access-false--subscription-id-none--resource-group-none-","poster":"l2azure","timestamp":"1664544060.0"}],"comment_id":"309439","upvote_count":"3"}],"question_text":"HOTSPOT -\nThe finance team asks you to train a model using data in an Azure Storage blob container named finance-data.\nYou need to register the container as a datastore in an Azure Machine Learning workspace and ensure that an error will be raised if the container does not exist.\nHow should you complete the code? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","question_id":92,"question_images":["https://www.examtopics.com/assets/media/exam-media/04274/0007500001.png"],"unix_timestamp":1615611780,"answer_ET":"","url":"https://www.examtopics.com/discussions/microsoft/view/46837-exam-dp-100-topic-2-question-20-discussion/","topic":"2","answer_description":"Box 1: register_azure_blob_container\nRegister an Azure Blob Container to the datastore.\nBox 2: create_if_not_exists = False\nCreate the file share if it does not exist, defaults to False.\nReference:\nhttps://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.datastore.datastore","answer":"","timestamp":"2021-03-13 06:03:00","exam_id":64},{"id":"nEKzQ1eFxjLZ0PAL8ES9","answer_ET":"ACE","choices":{"B":"Create an Azure Kubernetes Service (AKS) inference cluster.","A":"Create a Compute Instance and use it to run code in Jupyter notebooks.","D":"Create a tabular dataset that supports versioning.","C":"Use the designer to train a model by dragging and dropping pre-defined modules.","E":"Use the Automated Machine Learning user interface to train a model."},"answer_images":[],"answer_description":"","isMC":true,"question_id":93,"discussion":[{"timestamp":"1634202420.0","poster":"brendal89","upvote_count":"18","comment_id":"335338","comments":[{"content":"Thanks. That makes me a bit nervous. I was ignoring outdated questions like this. There are many more question on Studio(classic) that I have ignore hoping that similar question will get asked for designer instead.","upvote_count":"4","comment_id":"345621","poster":"chaudha4","timestamp":"1635534540.0"}],"content":"I can confirm that I had this question on the exam in april 2021"},{"comment_id":"1094351","content":"Selected Answer: ACE\nAs of December 2023, you can use \nA) Create a Compute Instance and use it to run code in Jupyter notebooks.\nC) Use the designer to train a model by dragging and dropping pre-defined modules.\nE) Use the Automated Machine Learning user interface to train a model.\n\nCurrently, Create AKS deployment clusters, and Create versioned tabular datasets are not supported in Azure ML studio. If you want to access these services then you will have to go to AKS (Azure Kubernetes Service) for AKS-related stuff.","upvote_count":"12","poster":"NullVoider_0","timestamp":"1718180580.0"},{"timestamp":"1741928820.0","comment_id":"1395519","content":"Selected Answer: AD\nCan Anyone please confirm correct ans based on latest update ?","poster":"Sam2213","upvote_count":"1"},{"content":"I am Agree","comments":[{"timestamp":"1705738080.0","content":"Hi, Agree!","comment_id":"957198","upvote_count":"9","poster":"phydev"}],"poster":"Edriv","timestamp":"1689425640.0","upvote_count":"2","comment_id":"776690"},{"content":"No idea, just set up an Azure Machine Learning Studio, all are available, also, I have never seem anything version selection there","poster":"ning","upvote_count":"5","comment_id":"600021","comments":[{"timestamp":"1669528920.0","content":"Yes, this comment is correct. There is also data versioning available when you create datasets.","comment_id":"607889","poster":"Saurabhjain507","upvote_count":"1"}],"timestamp":"1668167280.0"},{"content":"all are correct\nbecause now its just basic","timestamp":"1651164960.0","upvote_count":"1","comment_id":"469379","poster":"azayra"},{"comment_id":"403883","poster":"ljljljlj","content":"On exam 2021/7/10","timestamp":"1641908940.0","upvote_count":"5"},{"comment_id":"339864","poster":"chaudha4","upvote_count":"10","content":"This seems like an outdated question (as of April 2021). There is no mention of any basic or enterprise options. There is only one and based on what I see, you can do everything listed in the question.","timestamp":"1634759760.0"},{"comment_id":"318299","timestamp":"1632411180.0","content":"Beginning December 21st, all Enterprise Edition workspaces will be automatically set to Basic Edition, which has the same capabilities. No downtime will occur during this process. On January 1, 2021, Enterprise Edition will be formally retired.\nhttps://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace#what-happened-to-enterprise-edition","poster":"ACSC","upvote_count":"8"},{"timestamp":"1628806920.0","content":"I don't think they have a premium offering now.","comment_id":"289241","upvote_count":"2","poster":"vippi66"}],"exam_id":64,"url":"https://www.examtopics.com/discussions/microsoft/view/44571-exam-dp-100-topic-2-question-21-discussion/","answers_community":["ACE (92%)","8%"],"topic":"2","timestamp":"2021-02-13 01:22:00","answer":"ACE","unix_timestamp":1613175720,"question_images":[],"question_text":"You plan to provision an Azure Machine Learning Basic edition workspace for a data science project.\nYou need to identify the tasks you will be able to perform in the workspace.\nWhich three tasks will you be able to perform? Each correct answer presents a complete solution.\nNOTE: Each correct selection is worth one point."},{"id":"joKTQS5v9DXSOqK1XxJS","answer_ET":"","answer":"","answer_images":["https://www.examtopics.com/assets/media/exam-media/04274/0007800002.png"],"unix_timestamp":1620997680,"topic":"2","exam_id":64,"isMC":false,"discussion":[{"content":"Seems correct","upvote_count":"14","comment_id":"357219","poster":"Lucario95","timestamp":"1636902480.0"},{"poster":"MattAnya","comment_id":"765283","timestamp":"1688441760.0","content":"0n 03 Jan2023","upvote_count":"10"},{"content":"Correct answer is: 'Datastore', 'ws', 'blob_datastore_name'\nEx:blob_datastore = Datastore.get(ws, blob_datastore_name)\nLink: https://learn.microsoft.com/en-us/python/api/azureml-core/azureml.core.datastore.datastore?view=azure-ml-py","upvote_count":"1","timestamp":"1730582700.0","comment_id":"1205802","poster":"thisiston"},{"content":"answer is correct","timestamp":"1665999180.0","comment_id":"587141","poster":"k1ngs1zed","upvote_count":"1"},{"content":"On 20Feb2022","timestamp":"1661011440.0","comment_id":"552091","upvote_count":"4","poster":"[Removed]"},{"content":"On Exam 01 Oct 2021","timestamp":"1649010240.0","comment_id":"456717","upvote_count":"2","poster":"kisskeo"},{"timestamp":"1646292180.0","content":"on exam 2/9/21","upvote_count":"1","comment_id":"438285","poster":"snsnsnsn"},{"content":"on 2/8/2021","upvote_count":"2","comment_id":"418547","timestamp":"1643791200.0","poster":"datamijn"},{"upvote_count":"4","comment_id":"408386","content":"on 17/7/2021\n\nAnswer is correct","timestamp":"1642423800.0","poster":"Rosh4yuh"},{"timestamp":"1641909000.0","comment_id":"403884","content":"On exam 2021/7/10","upvote_count":"2","poster":"ljljljlj"},{"upvote_count":"4","content":"yes correct","poster":"okeyken1","timestamp":"1639837620.0","comment_id":"384807"}],"answers_community":[],"question_id":94,"url":"https://www.examtopics.com/discussions/microsoft/view/52696-exam-dp-100-topic-2-question-22-discussion/","question_images":["https://www.examtopics.com/assets/media/exam-media/04274/0007700001.png","https://www.examtopics.com/assets/media/exam-media/04274/0007800001.png"],"timestamp":"2021-05-14 15:08:00","answer_description":"Box 1: DataStore -\nTo get a specific datastore registered in the current workspace, use the get() static method on the Datastore class:\n# Get a named datastore from the current workspace\ndatastore = Datastore.get(ws, datastore_name='your datastore name')\n\nBox 2: ws -\n\nBox 3: demo_datastore -\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-access-data","question_text":"HOTSPOT -\nA coworker registers a datastore in a Machine Learning services workspace by using the following code:\n//IMG//\n\nYou need to write code to access the datastore from a notebook.\nHow should you complete the code segment? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//"},{"id":"37qI2RtJqr4EA37OfUcu","answer_ET":"D","answer":"D","answer_images":[],"unix_timestamp":1615787940,"topic":"2","exam_id":64,"isMC":true,"answers_community":["D (100%)"],"discussion":[{"timestamp":"1634664660.0","comments":[{"content":"I guess you can by using module like Split or Filter data? You can specify the condition to get data before a particular month","poster":"chevyli","upvote_count":"3","comment_id":"651628","timestamp":"1677303480.0"},{"comment_id":"503891","timestamp":"1655489640.0","content":"But D don't satisfy the last requirement that register minimal data set possible since each specific sales file need to register in option D. Given answer B seems correct as it fulfils all conditions.","poster":"Shailen","upvote_count":"4"},{"timestamp":"1635536340.0","content":"I agree. The example shown in the link below does exactly what is being asked in the question. \nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-version-track-datasets#versioning-best-practice","comments":[{"poster":"levm39","upvote_count":"4","comments":[{"content":"But B you can't select by (each) Month.","poster":"YipingRuan","upvote_count":"1","comment_id":"398827","timestamp":"1641363180.0"}],"comment_id":"374189","timestamp":"1638613020.0","content":"You must register the minimum number of datasets possible. D is not correct, because you will have to do this manually each month,?"}],"upvote_count":"2","comment_id":"345637","poster":"chaudha4"}],"upvote_count":"28","comment_id":"338975","content":"D seems to be the correct answer. B does not allow you to get the data from before a specific month. With D you create only one dataset with multiple versions (1 version per month).\nSimilar example in 'Versioning best practice':\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-version-track-datasets","poster":"gamezone25"},{"comment_id":"521972","upvote_count":"19","poster":"TheCyanideLancer","timestamp":"1657605240.0","content":"Quick update, verified, correct ans is D. Cross checked in coursera and validated there."},{"poster":"Lion007","content":"Selected Answer: D\nThe Correct answer is: D\n\nOption D is the most appropriate choice because it allows for both the inclusion of all data to date for general training and the ability to use specific versions for experiments that require data up to a particular month. The \"minimum number of datasets\" can be interpreted as the minimum number of distinct dataset entities registered in the workspace. With versioning (Option D), you're still working with one dataset entity, but with multiple versions, which aligns with the requirement of minimal dataset registration.\n\nJustification:\n- Versioning in Azure Machine Learning allows you to handle the evolving data by creating new versions of the dataset each month, without increasing the number of dataset entities in the workspace.\n- By using version tags, you can manage and reference the appropriate data snapshot for experiments as needed.\n- This approach offers a balance between efficient data management and the ability to run experiments on specific subsets of the data as of a given date, thus meeting all the stated requirements.","timestamp":"1719598740.0","comment_id":"1108089","upvote_count":"3"},{"comment_id":"992448","content":"On exam 28/08/2023..","timestamp":"1709148300.0","upvote_count":"4","poster":"Kanwal001"},{"content":"Selected Answer: D\nOption D","poster":"Depayser","upvote_count":"1","timestamp":"1700325120.0","comment_id":"901298","comments":[{"timestamp":"1705738200.0","comment_id":"957199","upvote_count":"1","poster":"phydev","content":"ChatGPT agrees."}]},{"poster":"MarinaMijailovic","timestamp":"1698392160.0","upvote_count":"1","comment_id":"882345","content":"Selected Answer: D\nA: *replaces* the the existing dataset -> can't directly filter data before the specific month\nB: captures all the sales data from different folders in *one dataset* -> can't can't directly filter data before the specific month\nC: requires registering multiple datasets\n\nD: satisfies all the requirements"},{"timestamp":"1694164020.0","upvote_count":"2","poster":"Yuriy_Ch","comment_id":"832859","content":"Exactly this question was on exam 07/03/2023","comments":[{"timestamp":"1695790740.0","comment_id":"851725","content":"Is Answer B or D?","poster":"Jit1981","upvote_count":"2"}]},{"timestamp":"1691861520.0","content":"B. Create a tabular dataset that references the datastore and specifies the path 'sales/*/sales.csv', register the dataset with the name sales_dataset and a tag named month indicating the month and year it was registered, and use this dataset for all experiments.\n\nThis option meets all the requirements of the problem statement:\n✑ The dataset loads all of the sales data to date into a structure that can be easily converted to a dataframe.\n✑ You can create experiments that use only data that was created before a specific previous month, ignoring any data that was added after that month by filtering the dataset based on the \"month\" tag.\n✑ The minimum number of datasets possible is registered (only one).","poster":"mamau","upvote_count":"2","comment_id":"806737"},{"comment_id":"796237","upvote_count":"2","poster":"phdykd","timestamp":"1690987140.0","content":"Option D satisfies the last requirement of registering the minimum number of datasets possible.\nWhile option B uses a single dataset that references the entire path 'sales/*/sales.csv', it still requires registering the dataset every month with a new tag indicating the month and year. In comparison, option D registers each month's sales data as a new version of the same dataset with a tag indicating the month and year. This allows you to only have to register one dataset instead of multiple datasets, minimizing the number of registered datasets.\n\nOption B does not satisfy the requirement of being able to create experiments that use only data that was created before a specific previous month as it only references the entire path and not individual files for each month"},{"comment_id":"743783","upvote_count":"2","poster":"Edriv","timestamp":"1686639540.0","content":"Option C"},{"timestamp":"1686136920.0","content":"If I look at the explanation for the \"correct\" (?) answer B, it seems that they mean to ask \"How to load CSVs form the appropriate folders using the least amount of lines?\" In the explanation they use an asterix. Not a very clear question i.m.o.","upvote_count":"1","comment_id":"737895","poster":"Arend78"},{"timestamp":"1683462780.0","content":"On exam 07/11/2022","comment_id":"713104","poster":"fvil","upvote_count":"1"},{"content":"on exam 16/10/2022 I've answer D","comment_id":"702168","upvote_count":"3","poster":"victorafb","timestamp":"1682253420.0"},{"content":"Selected Answer: D\nAbsolutely correct, one dataset with different versions. Versions are NOT the same as different dataset!","upvote_count":"2","poster":"ning","comment_id":"600024","timestamp":"1668167520.0"},{"timestamp":"1666428120.0","upvote_count":"1","poster":"JTWang","comment_id":"589831","content":"on exam 04/22/2022"},{"upvote_count":"3","content":"Correct answer is D,\nEven this question is really very badly written to promote misunderstanding and confusion.","comment_id":"583680","timestamp":"1665404340.0","poster":"azurelearner666"},{"content":"on exam 18/03/2022","poster":"kkkk_jjjj","upvote_count":"2","timestamp":"1663483140.0","comment_id":"570367"},{"timestamp":"1662749400.0","upvote_count":"1","content":"On march-9-2022","comment_id":"564319","poster":"TheYazan"},{"content":"B is wrong, in Coursera practice test by MS, I gave the exact same ans and the feedback I got was this ans is wrong. Can anyone confirm the right answer?","upvote_count":"2","timestamp":"1657604940.0","comment_id":"521967","poster":"TheCyanideLancer"},{"comment_id":"500034","upvote_count":"1","timestamp":"1655034540.0","poster":"dija123","content":"Choosing D means we are actually registering ALL the datasets, Yes it is the same dataset with different versions but still we will make the registration each month!!\n which is against the question request \"You must register the minimum number of datasets possible\"\nI think B makes more sense"},{"poster":"tunaktunak","timestamp":"1653556260.0","comment_id":"487289","content":"On exam 26/11/2021","upvote_count":"2"},{"upvote_count":"2","poster":"JoshuaXu","comment_id":"473632","content":"on exam 6 Nov 2021, the same question but different choice range, understanding the discussion is vital important","timestamp":"1651865640.0"},{"comment_id":"467401","upvote_count":"6","poster":"adamwar","content":"It is not clear whether a new dataset is registered each month with B but assuming this is the case it seems correct. D also seems correct but it doesn't make sense to not use wildcard in the filename.","timestamp":"1650882540.0","comments":[{"comment_id":"500035","content":"Totally agree with you","timestamp":"1655034660.0","poster":"dija123","upvote_count":"1"}]},{"poster":"VJPrakash","content":"on exam in August 2021","comment_id":"423355","upvote_count":"3","timestamp":"1644596160.0"},{"upvote_count":"3","timestamp":"1641909000.0","poster":"ljljljlj","content":"On exam 2021/7/10","comment_id":"403885"},{"comment_id":"311179","comments":[{"upvote_count":"3","poster":"treadst0ne","content":"It's the same dataset with multiple versions and tags.","timestamp":"1640276220.0","comment_id":"388883"}],"upvote_count":"5","poster":"dev2dev","timestamp":"1631678340.0","content":"Answer D could be the solution. Because we dont want to add data before specific month. So the option B adding everything is not desirable."}],"question_id":95,"question_images":["https://www.examtopics.com/assets/media/exam-media/04274/0007900001.png"],"url":"https://www.examtopics.com/discussions/microsoft/view/47144-exam-dp-100-topic-2-question-23-discussion/","timestamp":"2021-03-15 06:59:00","answer_description":"","question_text":"A set of CSV files contains sales records. All the CSV files have the same data schema.\nEach CSV file contains the sales record for a particular month and has the filename sales.csv. Each file is stored in a folder that indicates the month and year when the data was recorded. The folders are in an Azure blob container for which a datastore has been defined in an Azure Machine Learning workspace. The folders are organized in a parent folder named sales to create the following hierarchical structure:\n//IMG//\n\nAt the end of each month, a new folder with that month's sales file is added to the sales folder.\nYou plan to use the sales data to train a machine learning model based on the following requirements:\n✑ You must define a dataset that loads all of the sales data to date into a structure that can be easily converted to a dataframe.\n✑ You must be able to create experiments that use only data that was created before a specific previous month, ignoring any data that was added after that month.\n✑ You must register the minimum number of datasets possible.\nYou need to register the sales data as a dataset in Azure Machine Learning service workspace.\nWhat should you do?","choices":{"B":"Create a tabular dataset that references the datastore and specifies the path 'sales/*/sales.csv', register the dataset with the name sales_dataset and a tag named month indicating the month and year it was registered, and use this dataset for all experiments.","A":"Create a tabular dataset that references the datastore and explicitly specifies each 'sales/mm-yyyy/sales.csv' file every month. Register the dataset with the name sales_dataset each month, replacing the existing dataset and specifying a tag named month indicating the month and year it was registered. Use this dataset for all experiments.","D":"Create a tabular dataset that references the datastore and explicitly specifies each 'sales/mm-yyyy/sales.csv' file. Register the dataset with the name sales_dataset each month as a new version and with a tag named month indicating the month and year it was registered. Use this dataset for all experiments, identifying the version to be used based on the month tag as necessary.","C":"Create a new tabular dataset that references the datastore and explicitly specifies each 'sales/mm-yyyy/sales.csv' file every month. Register the dataset with the name sales_dataset_MM-YYYY each month with appropriate MM and YYYY values for the month and year. Use the appropriate month-specific dataset for experiments."}}],"exam":{"provider":"Microsoft","id":64,"isMCOnly":false,"isImplemented":true,"isBeta":false,"lastUpdated":"12 Apr 2025","numberOfQuestions":512,"name":"DP-100"},"currentPage":19},"__N_SSP":true}