{"pageProps":{"questions":[{"id":"q8OpBy899xTPmbD2LG1I","exam_id":68,"choices":{"A":"log shipping","D":"auto-failover groups","C":"Microsoft SQL Server failover clusters","B":"active geo-replication"},"question_id":296,"question_text":"You have an Azure subscription that contains an Azure SQL database named SQL1.\n\nSQL1 is in an Azure region that does not support availability zones.\n\nYou need to ensure that you have a secondary replica of SQL1 in the same region.\n\nWhat should you use?","answer_ET":"B","topic":"6","discussion":[{"content":"Selected Answer: B\nActive geo-replication is a feature that lets you create a continuously synchronized readable secondary database for a primary database. The readable secondary database may be in the same Azure region as the primary, or, more commonly, in a different region. This kind of readable secondary database is also known as a geo-secondary or geo-replica.\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/active-geo-replication-overview?source=recommendations&view=azuresql","timestamp":"1730021400.0","upvote_count":"2","comment_id":"882342","poster":"OBIJUAN88"},{"poster":"BrenFa101","content":"Answer is correct. You can create a new logical server in the same region and use geo-replication to add a replica to it. The 2 logical servers will exist in the same datacenter","timestamp":"1723663380.0","upvote_count":"2","comment_id":"808864"}],"answers_community":["B (100%)"],"answer_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/99217-exam-dp-300-topic-6-question-30-discussion/","answer":"B","question_images":[],"timestamp":"2023-02-14 22:23:00","unix_timestamp":1676409780,"isMC":true,"answer_description":""},{"id":"mxsqR2mW3oG9rO4Ug1Ub","discussion":[{"poster":"voodoo_sh","comment_id":"1352092","timestamp":"1738790760.0","content":"Selected Answer: A\nA. COMPRESS function.\nIt uses GZIP algorithm and typically is better for compressing text (and JSON) data, compared to columnstore archival compression.","upvote_count":"1"},{"poster":"Oga_DBA","upvote_count":"1","comment_id":"1319242","timestamp":"1732799220.0","content":"Selected Answer: B\nthe COMPRESS() function is not available in Azure Sql database"},{"content":"A. over B or D as columnstore compression is not available for nvarchar(max) datatypes.","comment_id":"1211908","timestamp":"1715772420.0","upvote_count":"2","poster":"a387354"},{"timestamp":"1711823760.0","content":"Answer is B. Question is to minimize storage used. A and D will compress data but B will provide best compression. Question also says nothing about performance.","comment_id":"1186260","upvote_count":"1","poster":"Ben999"},{"content":"COMPRESS ( expression ) not only applies to Azure SQL DB but also supports the following expressions:\n\nbinary(n)\nchar(n)\nnchar(n)\nnvarchar(max)\nnvarchar(n)\nvarbinary(max)\nvarbinary(n)\nvarchar(max)\nvarchar(n)\n\nhttps://learn.microsoft.com/en-us/sql/t-sql/functions/compress-transact-sql?view=sql-server-ver16","comment_id":"1008773","timestamp":"1694824020.0","upvote_count":"1","poster":"igorclapa","comments":[{"comment_id":"1062847","content":"Output of Compress function is varbinary(max), the column is nvarchar(max), it is incompatible.","timestamp":"1699185540.0","upvote_count":"1","poster":"SamBalbij"}]},{"comment_id":"978518","poster":"testdumps2017","timestamp":"1691749800.0","upvote_count":"1","content":"https://learn.microsoft.com/en-us/sql/t-sql/functions/compress-transact-sql?view=sql-server-ver16 - so it is the COMPRESS() function, available starting SQL 2016.\nPage and row compression DO NOT work on BLOBs, fyi.\nNeither is columnstore, it seems."},{"poster":"duzee","comment_id":"953617","content":"Selected Answer; D , \nTo compress the JSON data in Column1 in the Azure SQL Database named SQLDb1 while minimizing storage usage, the recommended option would be D. columnstore compression.\n\nColumnstore compression is designed specifically for reducing the storage footprint of large datasets. It provides efficient compression algorithms that work well with columnar data storage, enabling significant storage savings. Columnstore compression organizes and compresses the data at the column level, resulting in improved query performance and reduced storage requirements.\n\nIn this case, since you have JSON data in Column1, columnstore compression would be an appropriate choice. It will compress the data within the column, optimizing storage usage while maintaining query performance.","upvote_count":"1","timestamp":"1689538980.0"},{"poster":"duzee","upvote_count":"1","content":"D. columnstore compression\n\nTo minimize the amount of storage used while compressing Column1, you should use columnstore compression. Columnstore compression is specifically designed for columnar storage and provides high compression ratios for large datasets. It reduces the storage footprint by compressing and encoding the data within each column. This compression technique is well-suited for data warehousing and analytical workloads where the focus is on query performance rather than transactional operations. Therefore, using columnstore compression is the most appropriate option in this scenario.","timestamp":"1689372240.0","comment_id":"951868"},{"content":"Selected Answer: A\nhttps://learn.microsoft.com/es-es/sql/t-sql/functions/compress-transact-sql?view=sql-server-ver16","timestamp":"1682581380.0","poster":"OBIJUAN88","upvote_count":"3","comment_id":"882350"},{"comment_id":"864758","upvote_count":"3","timestamp":"1680964140.0","poster":"U_C","content":"To compress Column1, which contains JSON data, you should use the COMPRESS() function. This function can be used to compress data stored in an NVARCHAR(MAX) column1. So the correct answer is A. the COMPRESS() function."},{"upvote_count":"4","comment_id":"828802","content":"Correct Answer: C\n\nALTER TABLE dbo.Table1 REBUILD PARTITION = ALL \nWITH (DATA_COMPRESSION = ROW); \nGO","timestamp":"1677923940.0","poster":"HSQL"}],"url":"https://www.examtopics.com/discussions/microsoft/view/101495-exam-dp-300-topic-6-question-31-discussion/","answer":"A","choices":{"C":"row compression","A":"the COMPRESS() function","B":"columnstore archive compression","D":"columnstore compression"},"unix_timestamp":1677923940,"question_text":"You have an Azure SOI database named SQLDb1 that contains the resources shown in the following table.\n\n//IMG//\n\n\nColumn1 contains JSON data.\n\nYou need to compress Column1. The solution must minimize the amount of storage used.\n\nWhat should you use?","exam_id":68,"answer_description":"","answer_images":[],"timestamp":"2023-03-04 10:59:00","answer_ET":"A","isMC":true,"answers_community":["A (80%)","B (20%)"],"topic":"6","question_images":["https://img.examtopics.com/dp-300/image254.png"],"question_id":297},{"id":"Vi5wjtTxRAvjxDhqRDoE","discussion":[{"upvote_count":"1","content":"Selected Answer: A\nWhen creating a SQL Failover Cluster Instance (FCI) in Azure, it is generally better to use a cloud witness rather than a disk witness based on Azure shared disks. The cloud witness provides better resilience for several reasons:\n\nHigh Availability: A cloud witness utilizes Azure Blob Storage, which is distributed across multiple data centers and regions. This ensures that the witness remains accessible even during regional outages or failures, providing higher availability.\n\nFault Tolerance: Azure Blob Storage is designed to be resilient against various types of failures, including hardware failures and network disruptions. This makes it a more reliable option for maintaining quorum in a failover cluster.\n\nOn the other hand, a disk witness relies on shared storage, which may not provide the same level of resiliency and fault tolerance as a cloud witness. If the shared disk or the storage node experiences issues, the cluster quorum could be affected.","timestamp":"1738861020.0","comment_id":"1352526","poster":"voodoo_sh"},{"comment_id":"1298153","upvote_count":"1","poster":"bingomutant","timestamp":"1728982380.0","content":"chat insists answer is A - While disk witness might still be a technically valid option, it doesn't fully leverage the benefits of Azure's cloud architecture. If the shared disk experiences any issues or outages, a disk witness may fail to provide the expected resiliency compared to a cloud witness.\nFor this reason, cloud witness remains the recommended approach for Azure FCIs using shared disks."},{"poster":"bsk1983","content":"Selected Answer: D\nD is correct answer, quorum with disk witness. \nDisk witness is the most resilient quorum option when using Azure shared disks\nhttps://learn.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/hadr-cluster-best-practices?view=azuresql&tabs=windows2012","timestamp":"1693436340.0","comment_id":"994522","upvote_count":"2"},{"content":"Selected Answer: D\nD is correct.\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/hadr-cluster-best-practices?view=azuresql&tabs=windows2012#quorum\n\nThe disk witness is the most resilient quorum option, but to use a disk witness on a SQL Server on Azure VM, you must use an Azure Shared Disk which imposes some limitations to the high availability solution. As such, use a disk witness when you're configuring your failover cluster instance with Azure Shared Disks, otherwise use a cloud witness whenever possible.","timestamp":"1682556660.0","poster":"Pranava_GCP","upvote_count":"3","comment_id":"882123"},{"comments":[{"upvote_count":"2","comment_id":"870568","poster":"U_C","timestamp":"1681525440.0","comments":[{"comments":[{"comment_id":"870573","upvote_count":"3","poster":"U_C","content":"Sorry, D is the correct answer. LOL","timestamp":"1681525980.0"}],"content":"For more details:\n\nThe cloud witness is ideal for deployments in multiple sites, multiple zones, and multiple regions. Use a cloud witness whenever possible, unless you're using a shared-storage cluster solution.\nThe disk witness is the most resilient quorum option and is preferred for any cluster that uses Azure Shared Disks (or any shared-disk solution like shared SCSI, iSCSI, or fiber channel SAN). A Clustered Shared Volume cannot be used as a disk witness.\nThe fileshare witness is suitable for when the disk witness and cloud witness are unavailable options.","timestamp":"1681525500.0","comment_id":"870569","poster":"U_C","upvote_count":"1"}],"content":"Sorry, according to this MS statement, https://learn.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/hadr-cluster-best-practices?view=azuresql&tabs=windows2012#quorum, the correct answer is A.\n\nThe disk witness is the most resilient quorum option, but to use a disk witness on a SQL Server on Azure VM, you must use an Azure Shared Disk which imposes some limitations to the high availability solution. As such, use a disk witness when you're configuring your failover cluster instance with Azure Shared Disks, otherwise use a cloud witness whenever possible."}],"comment_id":"864903","content":"A, (node majority with a cloud witness) is not recommended since it doesn't meet the requirement of using Azure shared disks. \nB, (node majority with no witness) is not recommended since it does not provide resiliency in the event of a network split. \nC, (node majority with a file share witness) is a valid option but may have limitations on scalability and availability. \nD, (node majority with a disk witness) is a highly recommended configuration for FCI when using Azure shared disks since it provides the required resiliency and high availability in case of any failure.\n\nThe correct answer is D.","poster":"U_C","upvote_count":"4","timestamp":"1680976800.0"},{"content":"Selected Answer: D\n\nThe disk witness is the recommended quorum option when used with a shared storage high availability solution, such as the failover cluster instance with Azure shared disks.\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/hadr-cluster-quorum-configure-how-to?view=azuresql&tabs=fcm-gui#disk-witness","upvote_count":"1","timestamp":"1677929580.0","poster":"HSQL","comment_id":"828854"},{"poster":"MLCLUB","timestamp":"1675658940.0","comment_id":"799419","upvote_count":"1","content":"Selected Answer: A\nTo maximize resilliency, set a quorum mode as cloud witness where the storage account is located in other Azure region."},{"poster":"louisaok","timestamp":"1675148100.0","comment_id":"793743","upvote_count":"1","content":"Selected Answer: A\nnode majority with a cloud witness is the option to use. In a node majority quorum configuration, the cluster requires a majority of nodes to be online in order to function. Adding a cloud witness, which is a Microsoft-managed disk in Azure Storage, helps ensure that the quorum configuration has the necessary number of votes to be functional, even if one of the cluster nodes fails.\n\nThis option maximizes resiliency because the cloud witness helps ensure that the cluster continues to function even if one of the cluster nodes fails, which helps prevent data loss and minimizes downtime."},{"timestamp":"1674343680.0","poster":"jtu363","comment_id":"783816","content":"Selected Answer: D\nThe cloud witness is ideal for deployments in multiple sites, multiple zones, and multiple regions. Use a cloud witness whenever possible, unless you're using a shared-storage cluster solution.\nThe disk witness is the most resilient quorum option and is preferred for any cluster that uses Azure Shared Disks (or any shared-disk solution like shared SCSI, iSCSI, or fiber channel SAN). A Clustered Shared Volume cannot be used as a disk witness.\nThe fileshare witness is suitable for when the disk witness and cloud witness are unavailable options.","upvote_count":"3"}],"answers_community":["D (73%)","A (27%)"],"answer":"D","question_images":[],"answer_images":[],"answer_ET":"D","question_id":298,"isMC":true,"choices":{"C":"node majority with a file share witness","D":"node majority with a disk witness","A":"node majority with a cloud witness","B":"node majority with no witness"},"timestamp":"2023-01-22 00:28:00","question_text":"You have an Azure subscription that contains two instances of SQL Server on Azure Virtual Machines named VM1 and VM2. Both instances run Microsoft SQL Server 2019 CU8.\n\nYou need to deploy a failover cluster instance (FCI) to VM1 and VM2 that will use Azure shared disks. The solution must maximize resiliency.\n\nWhich quorum option should you use?","exam_id":68,"url":"https://www.examtopics.com/discussions/microsoft/view/96405-exam-dp-300-topic-6-question-32-discussion/","unix_timestamp":1674343680,"topic":"6","answer_description":""},{"id":"pTUZ1eWpmPdW6r67OpBt","answer_ET":"A","choices":{"C":"Azure SQL Database Basic","B":"Azure SQL Database serverless","A":"Azure SQL Database Premium","D":"Azure SQL Database Hyperscale"},"answer_description":"","answer":"A","answer_images":[],"topic":"6","url":"https://www.examtopics.com/discussions/microsoft/view/103250-exam-dp-300-topic-6-question-33-discussion/","question_text":"You have an Azure SQL database named DB1.\n\nYou need to ensure that DB1 will support automatic failover without data loss if a datacenter fails. The solution must minimize costs.\n\nWhich deployment option and pricing tier should you configure?","question_images":[],"question_id":299,"exam_id":68,"unix_timestamp":1679241240,"isMC":true,"answers_community":["A (100%)"],"discussion":[{"content":"A - The best option for automatic failover without data loss is typically one that supports business continuity features like active geo-replication or auto-failover groups, which require Premium or Business Critical tiers. Among the given options:\n\nThe correct option would be:\nA. Azure SQL Database Premium","comment_id":"1298154","upvote_count":"1","poster":"bingomutant","timestamp":"1728982560.0"},{"upvote_count":"4","content":"Selected Answer: A\nCorrect answer is A:\nTo ensure automatic failover without data loss if a datacenter fails, you should choose the Business Critical deployment option and the Premium pricing tier for the Azure SQL database named DB1. The Business Critical deployment option provides a 99.995% availability SLA, and the Premium pricing tier includes features such as advanced security, high availability, and business continuity. This option also offers the ability to use a failover group with multiple readable secondary replicas.","comment_id":"843903","timestamp":"1679241240.0","poster":"TheMCT"}],"timestamp":"2023-03-19 16:54:00"},{"id":"OXk7yfL80Tx1SJQGl1GX","answer_description":"","choices":{"D":"Azure SQL Database Hyperscale","C":"Azure SQL Database managed instance General Purpose","B":"Azure SQL Database Standard","A":"Azure SQL Database Business Critical"},"discussion":[{"upvote_count":"6","content":"Selected Answer: A\nCorrect answer is A:\nTo ensure automatic failover without data loss if a datacenter fails, you should choose the Business Critical deployment option and the Premium pricing tier for the Azure SQL database named DB1","timestamp":"1679241480.0","comment_id":"843907","poster":"TheMCT"},{"poster":"c80f499","timestamp":"1737426000.0","comment_id":"1343970","content":"Selected Answer: B\ncost effective and full fill the minimum requirements","upvote_count":"2"},{"comment_id":"1319774","content":"Selected Answer: B\nautomatic failover without data loss if a datacenter fails - supported by Standard, Premium and Business critical so based on minimum price Standard should consider.","poster":"Pavan_Gupta","upvote_count":"2","timestamp":"1732893780.0"},{"poster":"bingomutant","content":"A - Business Critical - This pricing tier includes built-in high availability with zone-redundant replicas (if configured) and can support automatic failover within the region, which helps meet the requirement for automatic failover without data loss.\n\nBusiness Critical is optimized for mission-critical workloads, offering both high availability and minimal data loss while providing strong performance.","upvote_count":"1","comment_id":"1298157","timestamp":"1728982860.0"},{"comments":[{"upvote_count":"1","content":"Or you could just lookup the documentation...and find out the answer is indeed A:\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/high-availability-sla?view=azuresql&tabs=azure-powershell#premium-and-business-critical-service-tier-locally-redundant-availability","timestamp":"1713432240.0","poster":"Dalamain","comment_id":"1197820"}],"upvote_count":"1","content":"This one is tough. While standard may seem like the obvious choice given the requirements, I feel that the question implies a level of urgency as far as being able to auto failover with no data loss. My gut says A, despite it costing more than standard.","comment_id":"1008776","poster":"igorclapa","timestamp":"1694824680.0"},{"comment_id":"864978","poster":"U_C","content":"Azure SQL Database Standard can minimize the costs. The correct answer is B.","timestamp":"1680980940.0","upvote_count":"3","comments":[{"content":"Standard tier doesn't have any replicas, so the automatic failover is impossible.\nYou need to choose BusinessCritical (vCore) or Premium (DTU) tier","poster":"sca88","upvote_count":"1","comment_id":"1199505","timestamp":"1713684480.0"}]}],"url":"https://www.examtopics.com/discussions/microsoft/view/103253-exam-dp-300-topic-6-question-34-discussion/","question_images":[],"answers_community":["A (60%)","B (40%)"],"answer_ET":"A","question_id":300,"topic":"6","unix_timestamp":1679241480,"exam_id":68,"question_text":"You have an Azure SQL database named DB1.\n\nYou need to ensure that DB1 will support automatic failover without data loss if a datacenter fails. The solution must minimize costs.\n\nWhich deployment option and pricing tier should you configure?","answer":"A","answer_images":[],"isMC":true,"timestamp":"2023-03-19 16:58:00"}],"exam":{"isBeta":false,"provider":"Microsoft","id":68,"isImplemented":true,"lastUpdated":"12 Apr 2025","numberOfQuestions":360,"name":"DP-300","isMCOnly":false},"currentPage":60},"__N_SSP":true}