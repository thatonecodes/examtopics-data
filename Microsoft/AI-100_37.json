{"pageProps":{"questions":[{"id":"yc5pwhNbzbGnuUt5YnbJ","exam_id":39,"answer":"B","answer_images":[],"question_id":181,"topic":"5","answers_community":[],"discussion":[{"content":"A. Yes, it does.\n\nBy creating one instance of Language Understanding (LUIS) that supports all five languages, and five instances of QnA Maker to handle the common customer questions in each language, you have fulfilled the requirement of supporting five languages in the bot. This approach ensures that you have the necessary Azure resources in place to handle the language detection and question answering functionalities for each language.","timestamp":"1687462860.0","upvote_count":"1","poster":"rveney","comment_id":"930971"}],"choices":{"B":"No, it does not","A":"Yes, it does"},"answer_ET":"B","isMC":true,"timestamp":"2023-06-22 21:41:00","answer_description":"You need to have a new QnA Maker resource for each language.\nIf LUIS supports all the languages, you develop a LUIS app for each language. Each LUIS app has a unique app ID, and endpoint log. If you need to provide language understanding for a language LUIS does not support, you can use Microsoft Translator API to translate the utterance into a supported language, submit the utterance to the LUIS endpoint, and receive the resulting scores.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/qnamaker/overview/language-support https://docs.microsoft.com/en-us/azure/cognitive-services/luis/luis-language-support","question_text":"You are developing a bot for an ecommerce application. The bot will support five languages.\nThe bot will use Language Understanding (LUIS) to detect the language of the customer, and QnA Maker to answer common customer questions. LUIS supports all the languages.\nYou need to determine the minimum number of Azure resources that you must create for the bot.\nYou create five instances of QnA Maker and one instance Language Understanding (LUIS).\nDoes this action accomplish your objective?","url":"https://www.examtopics.com/discussions/microsoft/view/112999-exam-ai-100-topic-5-question-28-discussion/","question_images":[],"unix_timestamp":1687462860},{"id":"j7Rle3F2yrjfsqA7z4gP","answer":"D","answer_ET":"D","topic":"5","question_text":"You are developing a Microsoft Bot Framework app that consumes structured NoSQL data.\nThe app has the following data storage requirements:\nData must be stored in Azure.\nData persistence must be ensured.\nYou want to keep costs at a minimum.\nWhich of the following actions should you take?","question_id":182,"isMC":true,"discussion":[{"poster":"rveney","upvote_count":"1","content":"B. Make use of Azure Cosmos DB\n\nAzure Cosmos DB is a globally distributed, multi-model database service that supports NoSQL data storage. It provides high availability, scalability, and automatic data replication across multiple regions. Azure Cosmos DB ensures data persistence and offers various consistency models to choose from based on your application's requirements.","comment_id":"930930","timestamp":"1687459860.0"}],"url":"https://www.examtopics.com/discussions/microsoft/view/112980-exam-ai-100-topic-5-question-3-discussion/","answer_description":"Table Storage is a NoSQL key-value store for rapid development using massive semi-structured datasets.\nYou can develop applications on Cosmos DB using popular NoSQL APIs.\nBoth services have a different scenario and pricing model.\nWhile Azure Storage Tables is aimed at high capacity on a single region (optional secondary read only region but no failover), indexing by PK/RK and storage- optimized pricing; Azure Cosmos DB Tables aims for high throughput (single-digit millisecond latency), global distribution (multiple failover), SLA-backed predictive performance with automatic indexing of each attribute/property and a pricing model focused on throughput.\nReference:\nhttps://db-engines.com/en/system/Microsoft+Azure+Cosmos+DB%3BMicrosoft+Azure+Table+Storage","answers_community":[],"question_images":[],"exam_id":39,"choices":{"D":"Make use of Azure Table storage","C":"Make use of Azure Databricks","B":"Make use of Azure Cosmos DB","A":"Make use of Azure Blob storage"},"timestamp":"2023-06-22 20:51:00","answer_images":[],"unix_timestamp":1687459860},{"id":"pIdY0DI1JMTKExeUfWXg","discussion":[{"timestamp":"1687463280.0","content":"C. Azure Data Factory\n\nAzure Data Factory is a fully managed data integration service that allows you to orchestrate and automate data movement and data transformation workflows. It provides a visual interface for building complex data pipelines and supports various data sources and destinations, including on-premises databases and Azure Blob storage. With Azure Data Factory, you can easily move data from your on-premises database to Azure Blob storage and then connect to Azure Machine Learning service for further processing using the Computer Vision API.","comment_id":"930977","poster":"rveney","upvote_count":"1"}],"question_images":[],"question_text":"You are developing an application that uses the Computer Vision API.\nYour application will perform the following steps:\nTake data from an on-premises database and load it to an Azure Blob storage account.\nConnect to an Azure Machine Learning service.\nYou need to orchestrate the workflow.\nWhat should you use?","exam_id":39,"answer_description":"With Azure Data Factory you can use workflows to orchestrate data integration and data transformation processes at scale.\nBuild data integration, and easily transform and integrate big data processing and machine learning with the visual interface.\nReference:\nhttps://azure.microsoft.com/en-us/services/data-factory/","answer":"C","answer_ET":"C","answers_community":[],"answer_images":[],"topic":"5","choices":{"B":"Azure Pipelines","C":"Azure Data Factory","E":"Azure Data Lake","D":"An Azure HDInsight cluster","A":"Azure Kubernetes Service (AKS)"},"url":"https://www.examtopics.com/discussions/microsoft/view/113001-exam-ai-100-topic-5-question-30-discussion/","timestamp":"2023-06-22 21:48:00","question_id":183,"isMC":true,"unix_timestamp":1687463280},{"id":"CqjX1MlpcVGPnZpH9IEG","isMC":true,"choices":{"C":"Make use of Azure HDInsight with Apache Storm","A":"Make use of Azure HDInsight with Apache HBase","B":"Make use of Azure HDInsight with Apache Spark","D":"Make use of Azure HDInsight with Microsoft Machine Learning Server"},"question_text":"You are designing an AI system for your company. Your system will consume several Apache Kafka data streams.\nYou want your system to be able to process the data streams at scale and in real-time.\nWhich of the following actions should you take?","answer_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/113002-exam-ai-100-topic-5-question-31-discussion/","answer":"C","discussion":[{"poster":"rveney","content":"C. Make use of Azure HDInsight with Apache Storm\n\nAzure HDInsight is a cloud-based big data analytics service that allows you to process and analyze large volumes of data. It supports various open-source big data technologies, including Apache Kafka, Apache HBase, Apache Spark, and Apache Storm.\n\nApache Storm is a distributed real-time processing system designed for processing high-velocity streaming data. It provides a scalable and fault-tolerant platform for processing data streams in real-time. By using Azure HDInsight with Apache Storm, you can effectively process and analyze your Apache Kafka data streams at scale and in real-time.","comment_id":"930979","upvote_count":"1","timestamp":"1687463400.0"}],"question_id":184,"answer_ET":"C","answers_community":[],"question_images":[],"timestamp":"2023-06-22 21:50:00","topic":"5","unix_timestamp":1687463400,"answer_description":"Apache Storm is a distributed, fault-tolerant, open-source computation system. You can use Storm to process streams of data in real time with Apache Hadoop.\nStorm solutions can also provide guaranteed processing of data, with the ability to replay data that wasn't successfully processed the first time.\nReference:\nhttps://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-streaming-at-scale-overview https://docs.microsoft.com/en-us/azure/hdinsight/storm/apache-storm-overview","exam_id":39},{"id":"Z2rpI9HwuUxTYkxFoB9P","question_images":[],"answer":"C","unix_timestamp":1687463520,"answer_description":"Custom Translator is a feature of the Microsoft Translator service. With Custom Translator, enterprises, app developers, and language service providers can build neural translation systems that understand the terminology used in their own business and industry. The customized translation system will then seamlessly integrate into existing applications, workflows and websites.\nCustom Translator allows users to customize Microsoft Translator's advanced neural machine translation for Translator's supported neural translation languages.\nCustom Translator can be used for customizing text when using the Microsoft Translator Text API, and speech translation using the Microsoft Speech services.\nReference:\nhttps://www.microsoft.com/en-us/translator/business/customization/","answer_images":[],"choices":{"C":"Perform the translations by training a custom model using Custom Translator.","D":"Use the Computer Vision API to perform the translations.","A":"Use Text Analytics to perform the translations.","B":"Use the Language Understanding (LUIS) API to perform the translations."},"answer_ET":"C","answers_community":[],"question_id":185,"exam_id":39,"topic":"5","isMC":true,"question_text":"You are developing an app for a conference provider. The app will use speech-to-text to provide transcription at a conference in English. It will also use the\nTranslator Text API to translate the transcripts to the language preferred by the conference attendees.\nYou test the translation features on the app and discover that the translations are fairly poor.\nYou want to improve the quality of the translations.\nWhich of the following actions should you take?","discussion":[{"poster":"rveney","timestamp":"1687463520.0","content":"C. Perform the translations by training a custom model using Custom Translator.\n\nTo improve the quality of translations in your app, you can utilize the Custom Translator feature. Custom Translator allows you to train a custom translation model using your own data. By training the model with specific content related to the conference domain or using additional high-quality translated data, you can enhance the accuracy and relevance of the translations provided by the Translator Text API.","comment_id":"930981","upvote_count":"1"}],"timestamp":"2023-06-22 21:52:00","url":"https://www.examtopics.com/discussions/microsoft/view/113003-exam-ai-100-topic-5-question-32-discussion/"}],"exam":{"lastUpdated":"12 Apr 2025","name":"AI-100","isImplemented":true,"isBeta":false,"provider":"Microsoft","numberOfQuestions":206,"id":39,"isMCOnly":false},"currentPage":37},"__N_SSP":true}