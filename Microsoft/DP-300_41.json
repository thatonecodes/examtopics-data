{"pageProps":{"questions":[{"id":"d7slrDGEiYzBAWKp9M6W","topic":"3","answer":"D","question_id":201,"question_images":["https://img.examtopics.com/dp-300/image306.png"],"question_text":"Case study -\n\nThis is a case study. Case studies are not timed separately. You can use as much exam time as you would like to complete each case. However, there may be additional case studies and sections on this exam. You must manage your time to ensure that you are able to complete all questions included on this exam in the time provided.\n\nTo answer the questions included in a case study, you will need to reference information that is provided in the case study. Case studies might contain exhibits and other resources that provide more information about the scenario that is described in the case study. Each question is independent of the other questions in this case study.\n\nAt the end of this case study, a review screen will appear. This screen allows you to review your answers and to make changes before you move to the next section of the exam. After you begin a new section, you cannot return to this section.\n\n\nTo start the case study -\n\nTo display the first question in this case study, click the Next button. Use the buttons in the left pane to explore the content of the case study before you answer the questions. Clicking these buttons displays information such as business requirements, existing environment, and problem statements. If the case study has an All Information tab, note that the information displayed is identical to the information displayed on the subsequent tabs. When you are ready to answer a question, click the Question button to return to the question.\n\n\nOverview -\n\nADatum Corporation is a financial services company that has a main office in New York City.\n\nExisting Environment. Licensing Agreement\n\nADatum has a Microsoft Volume Licensing agreement that includes Software Assurance.\n\nExisting Environment. Network Infrastructure\n\nADatum has an on-premises datacenter and an Azure subscription named Sub1.\n\nSub1 contains a virtual network named Network1 in the East US Azure region.\n\nThe datacenter is connected to Network1 by using a Site-to-Site (S2S) VPN.\n\nExisting Environment. Identity Environment\n\nThe on-premises network contains an Active Directory Domain Services (AD DS) forest.\n\nThe forest contains a single domain named corp.adatum.com.\n\nThe corp.adatum.com domain syncs with a Microsoft Entra tenant named adatum.com.\n\nExisting Environment. Database Environment\n\nThe datacenter contains the servers shown in the following table.\n\n//IMG//\n\n\nDB1 and DB2 are used for transactional and analytical workloads by an application named App1.\n\nApp1 runs on Microsoft Entra hybrid joined servers that run Windows Server 2022. App1 uses Kerberos authentication.\n\nDB3 stores compliance data used by two applications named App2 and App3.\n\nDB3 performance is monitored by using Extended Events sessions, with the event_file target set to a file share on a local disk of SVR3.\n\nResource allocation for DB3 is managed by using Resource Governor.\n\n\nRequirements. Planned Changes -\n\nADatum plans to implement the following changes:\n\n• Deploy an Azure SQL managed instance named Instance1 to Network1.\n• Migrate DB1 and DB2 to Instance1.\n• Migrate DB3 to Azure SQL Database.\n• Following the migration of DB1 and DB2, hand over database development to remote developers who use Microsoft Entra joined Windows 11 devices.\n• Following the migration of DB3, configure the database to be part of an auto-failover group.\n\nRequirements. Availability Requirements\n\nADatum identifies the following post-migration availability requirements:\n\n• For DB1 and DB2, offload analytical workloads to a read-only database replica in the same Azure region.\n• Ensure that if a regional disaster occurs, DB1 and DB2 can be recovered from backups.\n• After the migration, App1 must maintain access to DB1 and DB2.\n• For DB3, manage potential performance issues caused by resource demand changes by App2 and App3.\n• Ensure that DB3 will still be accessible following a planned failover.\n• Ensure that DB3 can be restored if the logical server is deleted.\n• Minimize downtime during the migration of DB1 and DB2.\n\nRequirements. Security Requirements\n\nADatum identifies the following security requirements for after the migration:\n\n• Ensure that only designated developers who use Microsoft Entra joined Windows 11 devices can access DB1 and DB2 remotely.\n• Ensure that all changes to DB3, including ones within individual transactions, are audited and recorded.\n\nRequirements. Management Requirements\n\nADatum identifies the following post-migration management requirements:\n\n• Continue using Extended Events to monitor DB3.\n• In Azure SQL Database, automate the management of DB3 by using elastic jobs that have database-scoped credentials.\n\nRequirements. Business Requirements\n\nADatum identifies the following business requirements:\n\n• Minimize costs whenever possible, without affecting other requirements.\n• Minimize administrative effort.\n\n\nYou need to recommend a solution to meet the security requirements and the business requirements for DB3.\n\nWhat should you recommend as the first step of the solution?","url":"https://www.examtopics.com/discussions/microsoft/view/139666-exam-dp-300-topic-3-question-59-discussion/","exam_id":68,"answers_community":["D (75%)","C (25%)"],"discussion":[{"content":"CDC vs CT\nhttps://learn.microsoft.com/en-us/previous-versions/sql/sql-server-2008-r2/cc280519(v=sql.105)?redirectedfrom=MSDN","poster":"2f5c7cd","upvote_count":"1","comment_id":"1300319","timestamp":"1729408080.0"},{"timestamp":"1728590700.0","upvote_count":"1","poster":"bingomutant","comment_id":"1295728","content":"Chat - D - sp_addarticle is used for replication, which is not relevant for this scenario.\nChange Tracking (options B and C) is focused on tracking which rows have changed, but it does not provide a detailed audit trail of all changes within individual transactions, unlike CDC.\nTherefore, enabling Change Data Capture with the sys.sp_cdc_enable_db stored procedure aligns with the requirement to audit and record changes."},{"poster":"Vitos25","upvote_count":"1","comment_id":"1290669","content":"Selected Answer: C\nAnswer Correct C\nAccording to implementation, DB3 should move to Azure SQL Databases.\nChange Data Capture (CDC) is enabled by default in Azure SQL Database,Azure SQL Managed Instance.\nHence, there is no need to enable it!","timestamp":"1727533560.0"},{"content":"You need cdc, not cdtjavascript:void(0). Correct answer is D.","comment_id":"1257652","timestamp":"1722279000.0","poster":"st1a","upvote_count":"1"},{"content":"Selected Answer: D\nThe answer is D.\n\nBefore you can create a capture instance for individual tables, you must enable CDC for your Azure SQL Database.\n\nTo enable CDC, connect to your Azure SQL Database through Azure Data Studio or SQL Server Management Studio (SSMS). Open a new query window, then enable CDC by running the following T-SQL:\nEXEC sys.sp_cdc_enable_db;\nGO\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/change-data-capture-overview?view=azuresql#enable-cdc-for-azure-sql-database","comment_id":"1208074","upvote_count":"3","poster":"JJJR","timestamp":"1715122800.0"},{"comment_id":"1202727","timestamp":"1714152960.0","poster":"angelvenkovicch","upvote_count":"1","content":"I think it's actually D"}],"timestamp":"2024-04-26 19:36:00","answer_ET":"D","isMC":true,"choices":{"C":"Run the ALTER DATABASE statement and specify the SET CHANGE_TRACKING = ON Clause.","A":"Run the sp_addarticle stored procedure.","B":"Run the ALTER TABLE statement and specify the ENABLE CHANGE_TRACKING Clause.","D":"Run the sys.sp_cdc_enable_db stored procedure."},"unix_timestamp":1714152960,"answer_description":"","answer_images":[]},{"id":"KXD4Amfz8iq8uTsju5Nd","url":"https://www.examtopics.com/discussions/microsoft/view/46842-exam-dp-300-topic-3-question-6-discussion/","answer_images":[],"timestamp":"2021-03-13 07:29:00","question_id":202,"topic":"3","answers_community":["C (100%)"],"question_images":[],"answer_ET":"C","answer_description":"","discussion":[{"upvote_count":"18","comment_id":"421806","poster":"learnazureportal","timestamp":"1628452080.0","content":"16 vCPUs = 8 CPUs = 8 Tempdb data files."},{"comments":[{"upvote_count":"7","comment_id":"381781","content":"Please ignore my above comment, confused with RAM. \nI go with 8.","poster":"Mend","timestamp":"1623666840.0"}],"content":"In my view, we need to focus on last sentence - \"What is the total number of data files that tempdb should contain?\" \nWhile 8 is best practice, we can reach up to 64 (in this scenario) during the course of minimizing contention. So answer is 64.","poster":"Mend","comment_id":"381180","upvote_count":"9","timestamp":"1623598560.0"},{"timestamp":"1726775160.0","upvote_count":"1","content":"Selected Answer: C\nC: 8 Temp data files","comment_id":"1286578","poster":"Vitos25"},{"upvote_count":"2","poster":"VikJo1978","content":"Selected Answer: C\nWhen scaling tempdb in SQL Server, it's recommended to have a number of data files equal to or less than the number of CPU cores, but not exceeding 8 files. In your scenario, after scaling to 8 vCPUs, it would be appropriate to have 8 data files for tempdb.\nAnswer: C. 8","timestamp":"1698742680.0","comment_id":"1058604"},{"upvote_count":"2","timestamp":"1650655860.0","comment_id":"590222","poster":"Chunchi","content":"Selected Answer: C\n8 tempdb files is correct answer"},{"poster":"cusman","content":"Selected Answer: C\nGeneral rule:\nWhen < 8 CPU, use same number of tempdb files as CPU\nWhen >=8 CPU, use 8 tempdb files (as first step)\nGo higher than 8 tempdb files in multiples of 4 only if contention persists","timestamp":"1648758780.0","comment_id":"579156","upvote_count":"4"},{"timestamp":"1642258680.0","content":"Selected Answer: C\nMore than 8 vCPUs -> 8 files for TemDB","comment_id":"524241","poster":"Soiram","upvote_count":"3"},{"upvote_count":"6","timestamp":"1637763900.0","comment_id":"486034","poster":"jddc","content":"Selected Answer: C\n>=8 to <32 = No. of Cores/2\n>=32 = No. of Cores/4\n\nSo here answer is 8"},{"timestamp":"1634558100.0","poster":"TheSwedishGuy","upvote_count":"2","comment_id":"464102","content":"The answer D. 64 is correct. You have 16 vCPUS. You cannot divide 8 files by 16 CPUs and get a full number. Are you going to have 0.5 tempdb-files per CPU? No, you should not. 64 files divided by 16vCPUS means 4 tempDB files per vCPU.\n\nKeep a 1:1 ratio between CPUs and tempdb files up to 8. Thereafter, add files if you continue to see allocation contention or if you’re looking to push the I/O subsystem harder."},{"poster":"hdenryardila105t00","upvote_count":"4","content":"64 Gb is the memory no the number of cpus, Cpus is 16 which number of datafiles should be 8.","comment_id":"413492","timestamp":"1627165680.0"},{"upvote_count":"5","comment_id":"371471","content":"Based on this article , the answer should be 8\nhttps://docs.microsoft.com/en-US/troubleshoot/sql/performance/recommendations-reduce-allocation-contention","poster":"[Removed]","timestamp":"1622509740.0"},{"upvote_count":"4","content":"The correct answer should be C...","timestamp":"1622128620.0","poster":"Burrielito","comment_id":"368086"},{"content":"It is multiplication of 4. There was 4 first and then 16 and then 64.","timestamp":"1621653900.0","upvote_count":"1","poster":"gills","comment_id":"363373"},{"timestamp":"1617852360.0","content":"According to MOC , it should be 8 as upper.","poster":"YJC","upvote_count":"1","comment_id":"330844"},{"content":"basically they said it was 4 and then they increased to 16, so following best practice first time when cpu increased, DBA will set 8tempdb files. if there is contention after then more files will be added. so this question refers to the first step after cpu increased. tricky","upvote_count":"2","comments":[{"comment_id":"363370","timestamp":"1621653420.0","upvote_count":"3","poster":"gills","content":"The number of files depends on the number of (logical) processors on the machine. As a general rule, if the number of logical processors is less than or equal to eight, use the same number of data files as logical processors. If the number of logical processors is greater than eight, use eight data files and then if contention continues, increase the number of data files by multiples of 4 until the contention is reduced to acceptable levels or make changes to the workload/code."}],"comment_id":"314385","timestamp":"1616099460.0","poster":"Jas_dandiwal"},{"content":"i think that the correct answer is 8....","upvote_count":"1","poster":"Starshow","timestamp":"1615814760.0","comment_id":"311465"},{"upvote_count":"4","comment_id":"309473","timestamp":"1615616940.0","content":"should be 8","poster":"anurag1p"}],"exam_id":68,"choices":{"D":"64","C":"8","A":"2","B":"4"},"question_text":"You have SQL Server 2019 on an Azure virtual machine that runs Windows Server 2019. The virtual machine has 4 vCPUs and 28 GB of memory.\nYou scale up the virtual machine to 8 vCPUSs and 64 GB of memory.\nYou need to provide the lowest latency for tempdb.\nWhat is the total number of data files that tempdb should contain?","isMC":true,"unix_timestamp":1615616940,"answer":"C"},{"id":"uoUnJZgpypI9ea4zPqwi","timestamp":"2024-04-26 19:39:00","answer_description":"","unix_timestamp":1714153140,"answers_community":["A (100%)"],"answer_images":[],"choices":{"B":"a custom resource pool","A":"vertical scaling","D":"horizontal scaling","C":"Resource Governor"},"exam_id":68,"question_images":["https://img.examtopics.com/dp-300/image306.png"],"isMC":true,"question_text":"Case study -\n\nThis is a case study. Case studies are not timed separately. You can use as much exam time as you would like to complete each case. However, there may be additional case studies and sections on this exam. You must manage your time to ensure that you are able to complete all questions included on this exam in the time provided.\n\nTo answer the questions included in a case study, you will need to reference information that is provided in the case study. Case studies might contain exhibits and other resources that provide more information about the scenario that is described in the case study. Each question is independent of the other questions in this case study.\n\nAt the end of this case study, a review screen will appear. This screen allows you to review your answers and to make changes before you move to the next section of the exam. After you begin a new section, you cannot return to this section.\n\n\nTo start the case study -\n\nTo display the first question in this case study, click the Next button. Use the buttons in the left pane to explore the content of the case study before you answer the questions. Clicking these buttons displays information such as business requirements, existing environment, and problem statements. If the case study has an All Information tab, note that the information displayed is identical to the information displayed on the subsequent tabs. When you are ready to answer a question, click the Question button to return to the question.\n\n\nOverview -\n\nADatum Corporation is a financial services company that has a main office in New York City.\n\nExisting Environment. Licensing Agreement\n\nADatum has a Microsoft Volume Licensing agreement that includes Software Assurance.\n\nExisting Environment. Network Infrastructure\n\nADatum has an on-premises datacenter and an Azure subscription named Sub1.\n\nSub1 contains a virtual network named Network1 in the East US Azure region.\n\nThe datacenter is connected to Network1 by using a Site-to-Site (S2S) VPN.\n\nExisting Environment. Identity Environment\n\nThe on-premises network contains an Active Directory Domain Services (AD DS) forest.\n\nThe forest contains a single domain named corp.adatum.com.\n\nThe corp.adatum.com domain syncs with a Microsoft Entra tenant named adatum.com.\n\nExisting Environment. Database Environment\n\nThe datacenter contains the servers shown in the following table.\n\n//IMG//\n\n\nDB1 and DB2 are used for transactional and analytical workloads by an application named App1.\n\nApp1 runs on Microsoft Entra hybrid joined servers that run Windows Server 2022. App1 uses Kerberos authentication.\n\nDB3 stores compliance data used by two applications named App2 and App3.\n\nDB3 performance is monitored by using Extended Events sessions, with the event_file target set to a file share on a local disk of SVR3.\n\nResource allocation for DB3 is managed by using Resource Governor.\n\n\nRequirements. Planned Changes -\n\nADatum plans to implement the following changes:\n\n• Deploy an Azure SQL managed instance named Instance1 to Network1.\n• Migrate DB1 and DB2 to Instance1.\n• Migrate DB3 to Azure SQL Database.\n• Following the migration of DB1 and DB2, hand over database development to remote developers who use Microsoft Entra joined Windows 11 devices.\n• Following the migration of DB3, configure the database to be part of an auto-failover group.\n\nRequirements. Availability Requirements\n\nADatum identifies the following post-migration availability requirements:\n\n• For DB1 and DB2, offload analytical workloads to a read-only database replica in the same Azure region.\n• Ensure that if a regional disaster occurs, DB1 and DB2 can be recovered from backups.\n• After the migration, App1 must maintain access to DB1 and DB2.\n• For DB3, manage potential performance issues caused by resource demand changes by App2 and App3.\n• Ensure that DB3 will still be accessible following a planned failover.\n• Ensure that DB3 can be restored if the logical server is deleted.\n• Minimize downtime during the migration of DB1 and DB2.\n\nRequirements. Security Requirements\n\nADatum identifies the following security requirements for after the migration:\n\n• Ensure that only designated developers who use Microsoft Entra joined Windows 11 devices can access DB1 and DB2 remotely.\n• Ensure that all changes to DB3, including ones within individual transactions, are audited and recorded.\n\nRequirements. Management Requirements\n\nADatum identifies the following post-migration management requirements:\n\n• Continue using Extended Events to monitor DB3.\n• In Azure SQL Database, automate the management of DB3 by using elastic jobs that have database-scoped credentials.\n\nRequirements. Business Requirements\n\nADatum identifies the following business requirements:\n\n• Minimize costs whenever possible, without affecting other requirements.\n• Minimize administrative effort.\n\n\nYou need to recommend a solution to ensure that the performance of DB3 is optimized after the migration to Azure SQL Database. The solution must meet availability requirements.\n\nWhat should you include in the recommendation?","url":"https://www.examtopics.com/discussions/microsoft/view/139667-exam-dp-300-topic-3-question-60-discussion/","question_id":203,"discussion":[{"content":"A - vertical scaling - Azure SQL Database supports vertical scaling, which allows you to adjust the compute resources (such as CPU and memory) for a database based on the workload demands. This is essential for managing performance issues, especially if App2 and App3's resource demands increase over time.\nResource Governor (Option C) is used in on-premises SQL Server to manage SQL resources and is not available in Azure SQL Database.\nHorizontal scaling (Option D) is typically used in distributed systems, but Azure SQL Database does not support native horizontal scaling in the same sense. Instead, you can scale up or down vertically.\nA custom resource pool (Option B) applies to SQL Server but is not available for Azure SQL Database.","upvote_count":"1","poster":"bingomutant","comment_id":"1295730","timestamp":"1728590940.0"},{"comment_id":"1213014","content":"I stand correct option A is the best choice","upvote_count":"3","poster":"ae8a90c","timestamp":"1715971440.0"},{"poster":"ae8a90c","comment_id":"1213010","upvote_count":"2","comments":[{"timestamp":"1722786480.0","poster":"Natali","comment_id":"1260718","upvote_count":"1","content":"no, its A. You cannot have custom resource pool in VM"},{"poster":"Sr18","upvote_count":"2","timestamp":"1719607560.0","content":"Consider these two also \n• Minimize costs whenever possible, without affecting other requirements.\n• Minimize administrative effort.\n\nSo overall Vertical Scaling can be more costly, but instant boost. Less admin effort. So I will go with A","comment_id":"1238914"}],"timestamp":"1715971140.0","content":"I think the option B is correct"},{"timestamp":"1715123520.0","comment_id":"1208083","content":"Selected Answer: A\nAnswer is A\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/failover-group-configure-sql-db?view=azuresql&tabs=azure-portal%2Cazure-powershell-manage&pivots=azure-sql-single-db#upgrading-or-downgrading-primary-database\n\nAnswer is NOT C because you cannot use resource governor with Azure SQL Database.","poster":"JJJR","upvote_count":"3"},{"timestamp":"1714153140.0","upvote_count":"1","poster":"angelvenkovicch","content":"Resource governor - C","comment_id":"1202729"}],"answer_ET":"A","answer":"A","topic":"3"},{"id":"fUzlmUVkrxP9y1yuyT2m","topic":"3","answers_community":["D (100%)"],"unix_timestamp":1714153860,"answer_description":"","question_id":204,"url":"https://www.examtopics.com/discussions/microsoft/view/139669-exam-dp-300-topic-3-question-61-discussion/","answer_ET":"D","answer":"D","timestamp":"2024-04-26 19:51:00","question_text":"Case study -\n\nThis is a case study. Case studies are not timed separately. You can use as much exam time as you would like to complete each case. However, there may be additional case studies and sections on this exam. You must manage your time to ensure that you are able to complete all questions included on this exam in the time provided.\n\nTo answer the questions included in a case study, you will need to reference information that is provided in the case study. Case studies might contain exhibits and other resources that provide more information about the scenario that is described in the case study. Each question is independent of the other questions in this case study.\n\nAt the end of this case study, a review screen will appear. This screen allows you to review your answers and to make changes before you move to the next section of the exam. After you begin a new section, you cannot return to this section.\n\n\nTo start the case study -\n\nTo display the first question in this case study, click the Next button. Use the buttons in the left pane to explore the content of the case study before you answer the questions. Clicking these buttons displays information such as business requirements, existing environment, and problem statements. If the case study has an All Information tab, note that the information displayed is identical to the information displayed on the subsequent tabs. When you are ready to answer a question, click the Question button to return to the question.\n\n\nOverview -\n\nADatum Corporation is a financial services company that has a main office in New York City.\n\nExisting Environment. Licensing Agreement\n\nADatum has a Microsoft Volume Licensing agreement that includes Software Assurance.\n\nExisting Environment. Network Infrastructure\n\nADatum has an on-premises datacenter and an Azure subscription named Sub1.\n\nSub1 contains a virtual network named Network1 in the East US Azure region.\n\nThe datacenter is connected to Network1 by using a Site-to-Site (S2S) VPN.\n\nExisting Environment. Identity Environment\n\nThe on-premises network contains an Active Directory Domain Services (AD DS) forest.\n\nThe forest contains a single domain named corp.adatum.com.\n\nThe corp.adatum.com domain syncs with a Microsoft Entra tenant named adatum.com.\n\nExisting Environment. Database Environment\n\nThe datacenter contains the servers shown in the following table.\n\n//IMG//\n\n\nDB1 and DB2 are used for transactional and analytical workloads by an application named App1.\n\nApp1 runs on Microsoft Entra hybrid joined servers that run Windows Server 2022. App1 uses Kerberos authentication.\n\nDB3 stores compliance data used by two applications named App2 and App3.\n\nDB3 performance is monitored by using Extended Events sessions, with the event_file target set to a file share on a local disk of SVR3.\n\nResource allocation for DB3 is managed by using Resource Governor.\n\n\nRequirements. Planned Changes -\n\nADatum plans to implement the following changes:\n\n• Deploy an Azure SQL managed instance named Instance1 to Network1.\n• Migrate DB1 and DB2 to Instance1.\n• Migrate DB3 to Azure SQL Database.\n• Following the migration of DB1 and DB2, hand over database development to remote developers who use Microsoft Entra joined Windows 11 devices.\n• Following the migration of DB3, configure the database to be part of an auto-failover group.\n\nRequirements. Availability Requirements\n\nADatum identifies the following post-migration availability requirements:\n\n• For DB1 and DB2, offload analytical workloads to a read-only database replica in the same Azure region.\n• Ensure that if a regional disaster occurs, DB1 and DB2 can be recovered from backups.\n• After the migration, App1 must maintain access to DB1 and DB2.\n• For DB3, manage potential performance issues caused by resource demand changes by App2 and App3.\n• Ensure that DB3 will still be accessible following a planned failover.\n• Ensure that DB3 can be restored if the logical server is deleted.\n• Minimize downtime during the migration of DB1 and DB2.\n\nRequirements. Security Requirements\n\nADatum identifies the following security requirements for after the migration:\n\n• Ensure that only designated developers who use Microsoft Entra joined Windows 11 devices can access DB1 and DB2 remotely.\n• Ensure that all changes to DB3, including ones within individual transactions, are audited and recorded.\n\nRequirements. Management Requirements\n\nADatum identifies the following post-migration management requirements:\n\n• Continue using Extended Events to monitor DB3.\n• In Azure SQL Database, automate the management of DB3 by using elastic jobs that have database-scoped credentials.\n\nRequirements. Business Requirements\n\nADatum identifies the following business requirements:\n\n• Minimize costs whenever possible, without affecting other requirements.\n• Minimize administrative effort.\n\n\nYou need to identify the event_file target for monitoring DB3 after the migration to Azure SQL Database. The solution must meet the management requirements.\n\nWhat should you use as the event_file target?","discussion":[{"upvote_count":"2","content":"D. an Azure Blob Storage container\n\nExplanation:\nIn Azure SQL Database, when you need to use Extended Events and store the event file target, Azure Blob Storage is the recommended option. It allows you to store the generated event data securely and access it later for analysis.\nAzure SQL Database does not support direct access to a SQL Server filegroup (Option A) or the use of a local file system like in on-premises environments, which eliminates Options B and C.","timestamp":"1728591180.0","comment_id":"1295731","poster":"bingomutant"},{"content":"Selected Answer: D\nD. an Azure Blob Storage container","comment_id":"1202738","upvote_count":"1","timestamp":"1714153860.0","poster":"angelvenkovicch"}],"choices":{"A":"a SQL Server filegroup","D":"an Azure Blob Storage container","B":"an Azure SQL database","C":"an Azure Files share"},"exam_id":68,"answer_images":[],"isMC":true,"question_images":["https://img.examtopics.com/dp-300/image306.png"]},{"id":"HAHRND57ZdHfrcGgkSv5","isMC":false,"answer_ET":"","topic":"3","question_text":"HOTSPOT\n-\n\nYou have an Azure virtual machine named Server1 that has Microsoft SQL Server installed. Server1 contains a database named DB1.\n\nYou have a logical SQL server named ASVR1 that contains an Azure SQL database named ADB1.\n\nYou plan to use SQL Data Sync to migrate DB1 from Server1 to ASVR1.\n\nYou need to prepare the environment for the migration. The solution must ensure that the connection from Server1 to ADB1 does NOT use a public endpoint.\n\nWhat should you do? To answer, select the appropriate options in the answer area.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","question_images":["https://img.examtopics.com/dp-300/image343.png"],"answer":"","answer_description":"","timestamp":"2024-10-10 22:21:00","answer_images":["https://img.examtopics.com/dp-300/image344.png"],"question_id":205,"exam_id":68,"answers_community":[],"discussion":[{"comment_id":"1314024","content":"https://learn.microsoft.com/en-us/azure/azure-sql/database/sql-data-sync-data-sql-server-sql-database?view=azuresql\n\nPrivate link for Data Sync\nThe SQL Data Sync private link is different from the Azure Private Link.\nThe new private link feature allows you to choose a service managed private endpoint to establish a secure connection between the sync service and your member/hub databases during the data synchronization process. A service managed private endpoint is a private IP address within a specific virtual network and subnet. Within Data Sync, the service managed private endpoint is created by Microsoft and is exclusively used by the Data Sync service for a given sync operation.\n\nSnapshot isolation must be enabled for both Sync members and hub. For more info, see Snapshot Isolation in SQL Server.","upvote_count":"1","timestamp":"1731939480.0","poster":"voodoo_sh"},{"timestamp":"1729408860.0","upvote_count":"1","poster":"2f5c7cd","comment_id":"1300324","content":"SQL Data Sync private link and SNAPSHOT ISOLATION"},{"timestamp":"1728591660.0","comment_id":"1295733","content":"agree with given answer - Azure Private Link allows private connectivity to Azure services from within a private virtual network without exposing your data to the public internet, which aligns with the requirement of avoiding public endpoints - and Snapshot Isolation helps in minimizing locking issues and ensures that the data reads during the migration are consistent without blocking operations. This isolation level is well-suited for data synchronization tasks, as it prevents long locks on tables during the sync operation, enhancing performance and concurrency","poster":"bingomutant","upvote_count":"1"}],"unix_timestamp":1728591660,"url":"https://www.examtopics.com/discussions/microsoft/view/149006-exam-dp-300-topic-3-question-62-discussion/"}],"exam":{"lastUpdated":"12 Apr 2025","provider":"Microsoft","id":68,"name":"DP-300","isImplemented":true,"isMCOnly":false,"numberOfQuestions":360,"isBeta":false},"currentPage":41},"__N_SSP":true}