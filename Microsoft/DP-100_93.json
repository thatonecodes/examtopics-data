{"pageProps":{"questions":[{"id":"nVmD1GgzJoASxyy4bECu","url":"https://www.examtopics.com/discussions/microsoft/view/46440-exam-dp-100-topic-5-question-2-discussion/","discussion":[{"timestamp":"1663573620.0","upvote_count":"50","poster":"jiglesia22","comment_id":"314725","content":"The correct answer is: \n1. client = ExplanationClient.from_run_id() (from_run requires just one parameter and three are being passed here)\n2. explanation = client.download_model_explanation()\n3. explanation.get_feature_importance_dict()\n\nAs dev2dev pointed out: https://github.com/MicrosoftDocs/azure-docs/blob/master/articles/machine-learning/how-to-machine-learning-interpretability-automl.md\n\nCheck out in addition: https://docs.microsoft.com/es-es/python/api/azureml-interpret/azureml.interpret.explanationclient?view=azure-ml-py"},{"poster":"rishi_ram","upvote_count":"8","timestamp":"1670146020.0","comment_id":"374155","comments":[{"upvote_count":"1","poster":"SnowCheetah","content":"https://docs.microsoft.com/en-us/python/api/azureml-interpret/azureml.interpret.explanationclient?view=azure-ml-py#from-run-id-workspace--experiment-name--run-id-\nfor more detail how to use explaination module","timestamp":"1671957540.0","comment_id":"390186"}],"content":"client = ExplanationClient.from_run_id()# as run_id is passed as parmaeter\nexplanation = client.download_model_explanation()# as it is mentioned in question it has #been uploaded\nfeature_importances = explanation .get_feature_importance_dict()"},{"content":"client = ExplanationClient.from_run_id(workspace=ws,\n experiment_name=experiment.experiment_name, \n run_id=run.id)\nexplanation = client.download_model_explanation()\nfeature_importances = explanation.get_feature_importance_dict()","comment_id":"819941","timestamp":"1724452260.0","upvote_count":"1","poster":"phdykd"},{"upvote_count":"1","poster":"therealola","comment_id":"617997","content":"On exam 18-06-22","timestamp":"1702864260.0"},{"timestamp":"1695019680.0","upvote_count":"3","comment_id":"570396","content":"on exam 18/03/2022","poster":"kkkk_jjjj"},{"poster":"JoshuaXu","upvote_count":"2","content":"on Exam 6 Nov 2021, the variable should be \"client\" in the first statement. However, the exam gives exactly the same typo.","timestamp":"1683403980.0","comment_id":"473660"},{"content":"after reading all the comments there is confusion in from_run and froun_run_id (correct answer)so if you follow the below link ExplanationClient.from_run(run) , it is expecting only 1 parameter and it is used to get an Explanation Client and upload the explanation whereas \nfrom_run_id is expecting 3 parameter and used to download the explanation\nfrom azureml.contrib.interpret.explanation.explanation_client import ExplanationClient\n\nclient = ExplanationClient.from_run_id(workspace=ws,\n experiment_name=experiment.experiment_name, \n run_id=run.id)\nexplanation = client.download_model_explanation()\nfeature_importances = explanation.get_feature_importance_dict()","comment_id":"391393","upvote_count":"5","poster":"azurecert2021","timestamp":"1672078560.0"},{"timestamp":"1668482820.0","upvote_count":"2","comment_id":"357526","content":"Agree with other posters' answers. Link for reference: https://docs.microsoft.com/en-us/learn/modules/explain-machine-learning-models-with-azure-machine-learning/4-create-explanations (Viewing the explanation section)","poster":"Q95"},{"poster":"htiwari","comment_id":"348937","timestamp":"1667513520.0","content":"from azureml.interpret import ExplanationClient\n\n# Get the feature explanations\nclient = ExplanationClient.from_run(run)\nengineered_explanations = client.download_model_explanation()\nfeature_importances = engineered_explanations.get_feature_importance_dict()\n\n# Overall feature importance\nprint('Feature\\tImportance')\nfor key, value in feature_importances.items():\n print(key, '\\t', value)","upvote_count":"1"},{"upvote_count":"3","poster":"BilJon","timestamp":"1664430660.0","comment_id":"323140","content":"from_run_id(workspace, experiment_name, run_id)"},{"poster":"BilJon","comment_id":"323131","comments":[{"upvote_count":"2","comment_id":"342984","timestamp":"1666758360.0","content":"I upvoted incorrectly - the code is correct, but it look at the arguments in the associated question brackets - https://docs.microsoft.com/en-us/python/api/azureml-interpret/azureml.interpret.explanationclient?view=azure-ml-py#from-run-id-workspace--experiment-name--run-id-","poster":"anjurad"}],"upvote_count":"4","timestamp":"1664429880.0","content":"Correct answer:\nfrom azureml.interpret import ExplanationClient\n\n# Get the feature explanations\nclient = ExplanationClient.from_run(run)\nengineered_explanations = client.download_model_explanation()\nfeature_importances = engineered_explanations.get_feature_importance_dict()"},{"upvote_count":"4","content":"client = ExplanationClient.from_run_id(workspace=ws,\n experiment_name=experiment.experiment_name, \n run_id=run.id)\nexplanation = client.download_model_explanation()\nfeature_importances = explanation.get_feature_importance_dict()","timestamp":"1663578000.0","comment_id":"314775","poster":"stonefl"},{"timestamp":"1663479420.0","content":"The correct answer is : \n\nclient = ExplanationClient.from_run(run)\nexplanation = client.download_model_explanation()\nfeature_importances = explanation .get_feature_importance_dict()","comments":[{"upvote_count":"6","comment_id":"318963","content":"sorry, it is from_run_id()\n\nclient = ExplanationClient.from_run_id()\nexplanation = client.download_model_explanation()\nfeature_importances = explanation .get_feature_importance_dict()","poster":"kty","timestamp":"1664003220.0"}],"comment_id":"313912","upvote_count":"1","poster":"kty"},{"comment_id":"313387","timestamp":"1663420920.0","comments":[{"poster":"bruce","content":"It should be Run_id since the arguments for the first line has run_id instead of run.","comment_id":"330986","upvote_count":"1","timestamp":"1665216360.0"}],"upvote_count":"3","content":"1 and 2 should be corrected\nFull example here: https://github.com/MicrosoftDocs/azure-docs/blob/master/articles/machine-learning/how-to-machine-learning-interpretability-automl.md\n\nfrom azureml.interpret import ExplanationClient\n\nclient = ExplanationClient.from_run(best_run)\nraw_explanations = client.download_model_explanation(raw=True)\nprint(raw_explanations.get_feature_importance_dict())","poster":"dev2dev"},{"content":"1. from_run()\n2. client.download_model_explanation()\n3. explanation.get_feature_importance_dict()","upvote_count":"2","timestamp":"1663407840.0","poster":"Anty85","comment_id":"313186"},{"comment_id":"311655","poster":"OmarF","timestamp":"1663259160.0","content":"I think this solution is not correct the correct one is: \n1. client = ExplanationClient.from_run_id()\n2. explanation = client.download_model_explanation()\n3. explanation.get_feature_importance_dict()","upvote_count":"1"},{"poster":"ImogenW","upvote_count":"2","comment_id":"308037","content":"I think this is incorrect, \n1 should be client = Explanation.from_run_id()\n2. explanation = client.download_model_explanation()\n3. explanation.get_feature_importance_dict()","timestamp":"1662905460.0"}],"question_images":["https://www.examtopics.com/assets/media/exam-media/04274/0041500001.png","https://www.examtopics.com/assets/media/exam-media/04274/0041600001.png"],"unix_timestamp":1615479060,"question_id":461,"answer":"","answer_ET":"","answer_description":"","isMC":false,"answer_images":["https://img.examtopics.com/dp-100/image619.png"],"question_text":"HOTSPOT -\nYou write code to retrieve an experiment that is run from your Azure Machine Learning workspace.\nThe run used the model interpretation support in Azure Machine Learning to generate and upload a model explanation.\nBusiness managers in your organization want to see the importance of the features in the model.\nYou need to print out the model features and their relative importance in an output that looks similar to the following.\n//IMG//\n\nHow should you complete the code? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","timestamp":"2021-03-11 17:11:00","topic":"5","answers_community":[],"exam_id":64},{"id":"cxqdRJ1DgkCDSSI38JQB","answers_community":[],"discussion":[{"upvote_count":"5","comment_id":"320742","poster":"Carkeys","timestamp":"1632619020.0","content":"some of the metrics are useful for evaluating the model and some are not, it says as much in the provided answer\n\nThe question being, how is this a Y/N question? anybody else get tripped up by this?\n\nDo I answer no if I can find one evaluation method that doesn't make sense? etc."},{"content":"what would be the answer if there were R2 aswell as an options?","comment_id":"1143999","timestamp":"1723077540.0","upvote_count":"1","poster":"deyoz"},{"content":"Agree with the answer","comment_id":"218150","timestamp":"1620846660.0","upvote_count":"1","poster":"Andrexx"},{"comments":[{"content":"You do not have Precision, Recall, F1 score for a linear regression model. You will have it for only classification. Don't get confused with Logistic Regression","upvote_count":"7","timestamp":"1620617880.0","comment_id":"216382","poster":"shivaborusu"}],"content":"... but this is asking for a linear regression model, so the answer should be TRUE","poster":"clownfishman","timestamp":"1617060900.0","upvote_count":"3","comment_id":"189953"}],"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou are creating a model to predict the price of a student's artwork depending on the following variables: the student's length of education, degree type, and art form.\nYou start by creating a linear regression model.\nYou need to evaluate the linear regression model.\nSolution: Use the following metrics: Mean Absolute Error, Root Mean Absolute Error, Relative Absolute Error, Accuracy, Precision, Recall, F1 score, and AUC.\nDoes the solution meet the goal?","unix_timestamp":1601422500,"isMC":true,"exam_id":64,"answer":"B","question_images":[],"timestamp":"2020-09-30 01:35:00","choices":{"A":"Yes","B":"No"},"topic":"5","question_id":462,"url":"https://www.examtopics.com/discussions/microsoft/view/33239-exam-dp-100-topic-5-question-20-discussion/","answer_images":[],"answer_description":"Accuracy, Precision, Recall, F1 score, and AUC are metrics for evaluating classification models.\nNote: Mean Absolute Error, Root Mean Absolute Error, Relative Absolute Error are OK for the linear regression model.\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/evaluate-model","answer_ET":"B"},{"id":"gBAk15gzupuZTiUGGRpu","isMC":true,"timestamp":"2021-07-11 14:25:00","unix_timestamp":1626006300,"answer_ET":"ABD","question_id":463,"topic":"5","answer_description":"","question_images":[],"choices":{"B":"Resample the dataset using undersampling or oversampling","C":"Normalize the training feature set","E":"Use accuracy as the evaluation metric of the model","D":"Generate synthetic samples in the minority class","A":"Penalize the classification"},"answers_community":["ABD (100%)"],"url":"https://www.examtopics.com/discussions/microsoft/view/57627-exam-dp-100-topic-5-question-21-discussion/","answer_images":[],"question_text":"You are building a binary classification model by using a supplied training set.\nThe training set is imbalanced between two classes.\nYou need to resolve the data imbalance.\nWhat are three possible ways to achieve this goal? Each correct answer presents a complete solution.\nNOTE: Each correct selection is worth one point.","discussion":[{"content":"On exam 2021/7/10","comment_id":"403963","poster":"ljljljlj","upvote_count":"6","timestamp":"1641911100.0"},{"poster":"Matt2000","timestamp":"1722935760.0","upvote_count":"1","comment_id":"1142074","content":"This reference might be useful: https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/"},{"content":"Selected Answer: ABD\nusing accuracy as a metric hardly answers the question, and normalising the feature set won't help the class imbalance.","poster":"michaelmorar","comment_id":"745768","timestamp":"1686803460.0","upvote_count":"2"},{"upvote_count":"2","content":"Selected Answer: ABD\ncorrect","poster":"AP_15","comment_id":"730914","timestamp":"1685393700.0"},{"comment_id":"569095","timestamp":"1663329600.0","upvote_count":"4","content":"Selected Answer: ABD\nPenalize model\nUse over/under sampling\nSMOTE.\n\nThere's another question of similar type which ignore Penalizing Sample as an option. This answer is correct.","poster":"synapse"},{"upvote_count":"3","comment_id":"433566","content":"correct!","timestamp":"1646033820.0","poster":"dijaa"}],"exam_id":64,"answer":"ABD"},{"id":"6JeXhPDWI16brtSxxOEx","question_id":464,"answer_images":["https://img.examtopics.com/dp-100/image620.png"],"url":"https://www.examtopics.com/discussions/microsoft/view/57101-exam-dp-100-topic-5-question-22-discussion/","isMC":false,"unix_timestamp":1625411460,"answer_description":"","answers_community":[],"question_text":"HOTSPOT -\nYou train a classification model by using a decision tree algorithm.\nYou create an estimator by running the following Python code. The variable feature_names is a list of all feature names, and class_names is a list of all class names. from interpret.ext.blackbox import TabularExplainer explainer = TabularExplainer(model, x_train, features=feature_names, classes=class_names)\nYou need to explain the predictions made by the model for all classes by determining the importance of all features.\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","timestamp":"2021-07-04 17:11:00","topic":"5","exam_id":64,"question_images":["https://www.examtopics.com/assets/media/exam-media/04274/0044800001.png"],"discussion":[{"comments":[{"content":"Y,Y,N. - For MimicExplainer you would need to import the MimicExplainer class, which is not the case here.","timestamp":"1735448400.0","comment_id":"1333332","upvote_count":"1","poster":"Ben999"}],"comment_id":"459625","timestamp":"1649507160.0","upvote_count":"16","content":"Answer is : Yes: No doubt - 2 - Yes: feature and class are optional arguments - 3 - Yes: Mimic also supports Tree based algorithms.","poster":"claudiapatricia777"},{"comments":[{"content":"field classes is optional","comment_id":"1144006","comments":[{"comment_id":"1144009","upvote_count":"1","content":"oh yes i overlooked the phrase \"as expected\" . i totally agree with your answer. the tone of the question give some hint that the model works without these parameters , but might not work as expected.","poster":"deyoz","timestamp":"1723078440.0"}],"upvote_count":"1","timestamp":"1723078200.0","poster":"deyoz"}],"upvote_count":"8","poster":"dushmantha","timestamp":"1646040300.0","content":"Answer should be\nyes: no doubt\nno: there is no way that explainer knows what is class variable\nyes: explainers has no restrictions to be used in a tree based method","comment_id":"435217"},{"timestamp":"1719072120.0","poster":"haby","comment_id":"1103605","upvote_count":"1","comments":[{"poster":"haby","upvote_count":"1","comment_id":"1103607","content":"My bad, 2nd is Yes. features and classes only change visualization result.","timestamp":"1719072300.0"}],"content":"1- Yes\n2- No - features and classes fields are optional, true, but without adding them, they work but can't work \"as expected\"\n3- Yes"},{"upvote_count":"2","content":"YYY.\n2 - Yes: feature and class are optional arguments","comment_id":"820083","poster":"phdykd","timestamp":"1692841620.0"},{"comment_id":"820082","timestamp":"1692841560.0","content":"YES YES YES","poster":"phdykd","upvote_count":"1"},{"timestamp":"1686556380.0","content":"1-Yes\n2-Yes\n3-No\n\n3- could be a NO because for a MimicExplainer you would need to specify the argument: explainable_model. Otherwise, a MimicExplainer is a valid choice.\n\nEx:\nexplainer = MimicExplainer(model, x_train, explainable_model=DecisionTreeExplainableModel, features=feature_names, classes=class_names)","poster":"casiopa","comment_id":"742627","upvote_count":"1"},{"poster":"pancman","timestamp":"1665624000.0","upvote_count":"1","content":"You can refer to TabularExplainer documentation here:\nhttps://interpret-community.readthedocs.io/en/latest/api_reference/interpret_community.html?highlight=tabularexplainer#interpret_community.TabularExplainer","comment_id":"584947"},{"upvote_count":"3","timestamp":"1654704000.0","content":"1- Yes\n2- Yes as \"features\" and \"classes\" fields are optional\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability-aml\n3- Yes","comment_id":"497036","poster":"dija123"},{"timestamp":"1651134960.0","poster":"azayra","comment_id":"469108","upvote_count":"2","content":"yes , yes and yes"},{"timestamp":"1646293320.0","comment_id":"438315","upvote_count":"1","poster":"snsnsnsn","content":"on 2/9/21"},{"upvote_count":"3","timestamp":"1642777920.0","poster":"saurabh288","content":"MimicExplainer can also be used here.","comment_id":"410931"},{"upvote_count":"6","comment_id":"403964","content":"On exam 2021/7/10","poster":"ljljljlj","timestamp":"1641911100.0"},{"timestamp":"1641316260.0","upvote_count":"3","comments":[{"upvote_count":"1","timestamp":"1643124720.0","poster":"YipingRuan","content":"You can use one of the following interpretable models as your surrogate model: LightGBM (LGBMExplainableModel), Linear Regression (LinearExplainableModel)\n\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability","comments":[{"comment_id":"417930","poster":"thhvancouver","content":"According to the documentation: You can use one of the following interpretable models as your surrogate model: LightGBM (LGBMExplainableModel), Linear Regression (LinearExplainableModel), Stochastic Gradient Descent explainable model (SGDExplainableModel), and Decision Tree (DecisionTreeExplainableModel). So a MimicExplainer can also be used with Decision Tree.","upvote_count":"5","timestamp":"1643650080.0"}],"comment_id":"413945"}],"content":"Why cant MIMIC be used here , they also can be used for Linerar Regression black box models","poster":"Srik33","comment_id":"398462"}],"answer":"","answer_ET":""},{"id":"b52lXQ3m1gDR9HDOnB8d","answer_ET":"","discussion":[{"comments":[{"content":"Yes, it seems the right order. Just take a look at the notebook from MS Learn:\n\nhttps://microsoftlearning.github.io/mslearn-dp100/instructions/15-detect-unfairness.html","comment_id":"663256","upvote_count":"1","poster":"giusecozza","timestamp":"1662619020.0"},{"content":"Answers do not need to be in order.\nSmple Code:\nsf = { 'Race': A_test.race, 'Sex': A_test.sex }\n\nfrom fairlearn.metrics._group_metric_set import _create_group_metric_set\n\ndash_dict = _create_group_metric_set(y_true=Y_test,\n predictions=ys_pred,\n sensitive_features=sf,\n prediction_type='binary_classification')\n\nhttps://learn.microsoft.com/zh-tw/azure/machine-learning/how-to-machine-learning-fairness-aml","poster":"JTWang","comment_id":"703537","upvote_count":"3","timestamp":"1666670820.0","comments":[{"upvote_count":"2","comment_id":"703540","content":"My fault, the answers need to be in order.","timestamp":"1666671000.0","poster":"JTWang"}]}],"timestamp":"1643137920.0","comment_id":"532353","poster":"ranjsi01","upvote_count":"11","content":"model, feature, metric (just switch a and b in answer area)"},{"poster":"phdykd","timestamp":"1677211740.0","content":"The three actions that you should perform in sequence to use the Fairlearn dashboard to assess fairness in a selected model are:\n\nSelect a binary classification or regression model: Fairlearn is a toolkit for assessing and improving fairness in binary classification and regression models. Therefore, you need to select a model that falls into one of these two categories.\n\nSelect a metric to be measured: After selecting the model, you need to choose a metric to be measured. Fairlearn provides a range of fairness metrics, such as demographic parity, equalized odds, and equal opportunity, that can be used to assess how the model performs across different groups.\n\nSelect a model feature to be evaluated: Once you have selected the model and the metric, you need to choose a model feature to be evaluated. This could be any feature that you believe may have an impact on the fairness of the model, such as race, gender, or age. You can use Fairlearn to analyze the model's performance across different subgroups based on this feature.","upvote_count":"6","comment_id":"820095"},{"comments":[{"upvote_count":"1","timestamp":"1733072580.0","comment_id":"1320632","content":"I agree","poster":"gunn_m"}],"upvote_count":"3","comment_id":"1236178","poster":"evangelist","timestamp":"1719214740.0","content":"Fairlearn works with binary classification or regression models, so you need to select one of these first.\nNext, you need to choose what metric you want to use to measure fairness.\nFinally, you select which feature of the model you want to evaluate for fairness."},{"comment_id":"1080602","poster":"vv_bb","timestamp":"1700999340.0","content":"model, feature, metric\n\nhttps://youtu.be/1Au1z9CtLq4?si=lIJumgmRfsC7Ad2V&t=2346","upvote_count":"1"},{"timestamp":"1655509920.0","poster":"therealola","upvote_count":"2","content":"On exam 18-06-22","comment_id":"618001"},{"upvote_count":"1","comment_id":"616293","content":"it can be only binary classifier or regression model\nselect a feature\nselect a performance metric\nselect a fairness metric","poster":"ning","timestamp":"1655220360.0"},{"content":"on exam 18/03/2022","timestamp":"1647593280.0","upvote_count":"4","comment_id":"570397","poster":"kkkk_jjjj"}],"unix_timestamp":1643137920,"exam_id":64,"answer_description":"Step 1: Select a model feature to be evaluated.\nStep 2: Select a binary classification or regression model.\nRegister your models within Azure Machine Learning. For convenience, store the results in a dictionary, which maps the id of the registered model (a string in name:version format) to the predictor itself.\nExample:\nmodel_dict = {}\nlr_reg_id = register_model(\"fairness_logistic_regression\", lr_predictor) model_dict[lr_reg_id] = lr_predictor svm_reg_id = register_model(\"fairness_svm\", svm_predictor) model_dict[svm_reg_id] = svm_predictor\nStep 3: Select a metric to be measured\nPrecompute fairness metrics.\nCreate a dashboard dictionary using Fairlearn's metrics package.\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-fairness-aml","question_images":["https://www.examtopics.com/assets/media/exam-media/04274/0044900001.png"],"question_text":"DRAG DROP -\nYou have several machine learning models registered in an Azure Machine Learning workspace.\nYou must use the Fairlearn dashboard to assess fairness in a selected model.\nWhich three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\nSelect and Place:\n//IMG//","topic":"5","timestamp":"2022-01-25 20:12:00","isMC":false,"answer_images":["https://www.examtopics.com/assets/media/exam-media/04274/0045000001.png"],"answers_community":[],"answer":"","url":"https://www.examtopics.com/discussions/microsoft/view/70563-exam-dp-100-topic-5-question-23-discussion/","question_id":465}],"exam":{"numberOfQuestions":512,"provider":"Microsoft","id":64,"name":"DP-100","lastUpdated":"12 Apr 2025","isMCOnly":false,"isBeta":false,"isImplemented":true},"currentPage":93},"__N_SSP":true}