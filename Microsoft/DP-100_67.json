{"pageProps":{"questions":[{"id":"2gHzq9wO95TIQ9KFxILO","answer_images":[],"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou have a Python script named train.py in a local folder named scripts. The script trains a regression model by using scikit-learn. The script includes code to load a training data file which is also located in the scripts folder.\nYou must run the script as an Azure ML experiment on a compute cluster named aml-compute.\nYou need to configure the run to ensure that the environment includes the required packages for model training. You have instantiated a variable named aml- compute that references the target compute cluster.\nSolution: Run the following code:\n//IMG//\n\nDoes the solution meet the goal?","topic":"3","choices":{"A":"Yes","B":"No"},"timestamp":"2021-03-20 08:47:00","question_images":["https://www.examtopics.com/assets/media/exam-media/04274/0025800001.png"],"isMC":true,"unix_timestamp":1616226420,"question_id":331,"answer_description":"The scikit-learn estimator provides a simple way of launching a scikit-learn training job on a compute target. It is implemented through the SKLearn class, which can be used to support single-node CPU training.\nExample:\nfrom azureml.train.sklearn import SKLearn\n}\nestimator = SKLearn(source_directory=project_folder,\ncompute_target=compute_target,\nentry_script='train_iris.py'\n)\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-train-scikit-learn","answers_community":[],"exam_id":64,"url":"https://www.examtopics.com/discussions/microsoft/view/47794-exam-dp-100-topic-3-question-68-discussion/","discussion":[{"timestamp":"1724456940.0","poster":"folkmusic99","content":"from azureml.core import ScriptRunConfig, Experiment\n\n # create or load an experiment\n experiment = Experiment(workspace, 'MyExperiment')\n # create or retrieve a compute target\n cluster = workspace.compute_targets['MyCluster']\n # create or retrieve an environment\n env = Environment.get(ws, name='MyEnvironment')\n # configure and submit your training run\n config = ScriptRunConfig(source_directory='.',\n script='train.py',\n arguments=['--arg1', arg1_val, '--arg2', arg2_val],\n compute_target=cluster,\n environment=env)\n script_run = experiment.submit(config)\n\nScriptRunConfig and Experiment are two imp keys","comment_id":"430372","upvote_count":"3"},{"timestamp":"1712061120.0","content":"Question is outdated:\nhttps://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.sklearn.sklearn?view=azure-ml-py","poster":"medsimus","comment_id":"326596","upvote_count":"3"},{"upvote_count":"3","timestamp":"1710920820.0","poster":"dev2dev","comment_id":"315452","content":"how is this correct answer? we need to use experiment class to run experiments."}],"answer":"B","answer_ET":"B"},{"id":"jqoREifqGntsBjUhO7UC","answer_images":[],"isMC":true,"choices":{"B":"No","A":"Yes"},"answers_community":["A (100%)"],"question_images":["https://www.examtopics.com/assets/media/exam-media/04274/0025900001.png"],"answer":"A","question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou have a Python script named train.py in a local folder named scripts. The script trains a regression model by using scikit-learn. The script includes code to load a training data file which is also located in the scripts folder.\nYou must run the script as an Azure ML experiment on a compute cluster named aml-compute.\nYou need to configure the run to ensure that the environment includes the required packages for model training. You have instantiated a variable named aml- compute that references the target compute cluster.\nSolution: Run the following code:\n//IMG//\n\nDoes the solution meet the goal?","answer_description":"The scikit-learn estimator provides a simple way of launching a scikit-learn training job on a compute target. It is implemented through the SKLearn class, which can be used to support single-node CPU training.\nExample:\nfrom azureml.train.sklearn import SKLearn\n}\nestimator = SKLearn(source_directory=project_folder,\ncompute_target=compute_target,\nentry_script='train_iris.py'\n)\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-train-scikit-learn","discussion":[{"comments":[{"upvote_count":"1","timestamp":"1680438600.0","content":"Indeed","poster":"medsimus","comment_id":"326590"}],"timestamp":"1678806180.0","upvote_count":"11","poster":"hendriktytgatpwc","comment_id":"310604","content":"Question is outdated: Estimator is being replaced by ScriptRunConfig\nhttps://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.sklearn.sklearn?view=azure-ml-py"},{"upvote_count":"5","comment_id":"373623","poster":"Lucario95","content":"Doesn't the solution still meet requirements? (Even if not using SKLearn object)","timestamp":"1685800560.0"},{"timestamp":"1733691180.0","content":"Selected Answer: A\nThis one is correct as opposed to 67 which does not specify scikit learn in the conda_environment packages.","comment_id":"739461","poster":"michaelmorar","upvote_count":"2"},{"timestamp":"1691327520.0","poster":"AkashV","upvote_count":"1","content":"Don't we have to copy the scripts folders for them to be accessible in the computer cluster ?","comment_id":"420824"}],"exam_id":64,"topic":"3","timestamp":"2021-03-14 16:03:00","unix_timestamp":1615734180,"answer_ET":"B","url":"https://www.examtopics.com/discussions/microsoft/view/47062-exam-dp-100-topic-3-question-69-discussion/","question_id":332},{"id":"NSkNpUITF9CrUQE4pB9L","isMC":false,"discussion":[{"comment_id":"349437","poster":"chaudha4","comments":[{"timestamp":"1652694420.0","upvote_count":"5","comment_id":"358506","poster":"scipio","content":"You're right, but if you replace the estimator with the ScriptRunConfig this question still holds, as the method to pass Dataset, mount vs. download, by argument, etc.. are relevant"}],"upvote_count":"13","timestamp":"1651669740.0","content":"The use of estimator is deprecated. Use the ScriptRunConfig object with your own defined environment. Hope we don't see this question going forward !!\n\nhttps://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.estimator.estimator?view=azure-ml-py"},{"timestamp":"1731445080.0","poster":"vv_bb","comment_id":"1068868","content":"Even though the Estimator is deprecated in favor for ScriptRunConfig (google - \"Migrating from Estimators to ScriptRunConfig\") , I tried to understand the correct answer for the question as it is defined here.\n\n1) For Estimator class both \"script_params\" and \"arguments\" parameters are acceptable\ncheck here - https://learn.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.estimator.estimator?view=azure-ml-py\n\n2) So how to define which of them is valid in our case?\nThe answer is here: \n(be aware for PythonScriptStep \"arguments\" is the same as \"script_params\" for Estimator)\nhttps://learn.microsoft.com/en-us/azure/machine-learning/how-to-move-data-in-out-of-pipelines?view=azureml-api-1#access-datasets-within-your-script\n\nMeaning because in our script we use the ArgParser we have to pass the dataset using the \"script_params\"","upvote_count":"3"},{"upvote_count":"2","timestamp":"1716897660.0","poster":"iai","content":"Shouldn't it be D.? for local compute_target not sure if as_mount will work. better as_download","comment_id":"908617"},{"timestamp":"1708988640.0","comment_id":"823029","poster":"danishanis","upvote_count":"2","content":"Answer is B.\nI typed the question as it is in ChatGPT and it gave the answer where the 'script_params' argument is configured to read data from 'data_ref' (and data_ref.as_mount() is being used to specify the file path in datastore) that references a 'csv_files' folder."},{"content":"Seen on the exam 20Feb2023","upvote_count":"3","timestamp":"1708460040.0","poster":"jpalaci22","comment_id":"815800"},{"comment_id":"746979","upvote_count":"1","timestamp":"1702716600.0","content":"can be A,C,E - what do you thing?","poster":"Edriv"},{"comment_id":"603224","timestamp":"1684405740.0","poster":"ning","content":"B should be correct!","upvote_count":"3"},{"poster":"TheYazan","content":"on march 2022","comment_id":"564535","timestamp":"1678423860.0","upvote_count":"4"},{"upvote_count":"4","timestamp":"1676916840.0","content":"On 20Feb2022","poster":"[Removed]","comment_id":"552101"},{"timestamp":"1664915040.0","poster":"kisskeo","content":"On Exam 01 Oct 2021","comment_id":"457343","upvote_count":"3"},{"upvote_count":"3","timestamp":"1657540740.0","content":"On exam 2021/7/10","comment_id":"403901","poster":"ljljljlj"},{"upvote_count":"1","comments":[{"comments":[{"poster":"iai","content":"Notice however, that compute target is local, will mounting work?","comment_id":"908618","timestamp":"1716897720.0","upvote_count":"1"}],"content":"as_download, which copies the files to a temporary location on the compute where the script is being run. as_mount to stream the files directly from their source.","poster":"vhx","timestamp":"1655131380.0","comment_id":"381163","upvote_count":"3"}],"comment_id":"378098","content":"what is the correct answer? Why its not D.","timestamp":"1654762020.0","poster":"sarahmoin"},{"upvote_count":"2","poster":"iuolu","comment_id":"346947","content":"Nobody checked this question? The answer should be A, using to_pandas_dataframe() for tabular files instead","timestamp":"1651408560.0","comments":[{"comment_id":"349432","poster":"chaudha4","timestamp":"1651669320.0","content":"No, you are wrong. Several problems in A. \n1) Parameter is being passed as named input. That is wrong since it is not being accessed using named input in t he script.\n2) You convert to dataframe in the script not when you pass it.\nSo A is definitely not the correct answer.","upvote_count":"10"}]}],"timestamp":"2021-05-01 14:36:00","unix_timestamp":1619872560,"exam_id":64,"question_images":["https://www.examtopics.com/assets/media/exam-media/04274/0015100001.png","https://www.examtopics.com/assets/media/exam-media/04274/0015100002.png","https://www.examtopics.com/assets/media/exam-media/04274/0015200001.png","https://www.examtopics.com/assets/media/exam-media/04274/0015200002.png","https://www.examtopics.com/assets/media/exam-media/04274/0015200003.png","https://www.examtopics.com/assets/media/exam-media/04274/0015200004.png","https://www.examtopics.com/assets/media/exam-media/04274/0015200005.png"],"answer_description":"Besides passing the dataset through the input parameters in the estimator, you can also pass the dataset through script_params and get the data path (mounting point) in your training script via arguments. This way, you can keep your training script independent of azureml-sdk. In other words, you will be able use the same training script for local debugging and remote training on any cloud platform.\nExample:\nfrom azureml.train.sklearn import SKLearn\nscript_params = {\n# mount the dataset on the remote compute and pass the mounted path as an argument to the training script\n'--data-folder': mnist_ds.as_named_input('mnist').as_mount(),\n'--regularization': 0.5\n}\nest = SKLearn(source_directory=script_folder,\nscript_params=script_params,\ncompute_target=compute_target,\nenvironment_definition=env,\nentry_script='train_mnist.py')\n# Run the experiment\nrun = experiment.submit(est)\nrun.wait_for_completion(show_output=True)\nIncorrect Answers:\nA: Pandas DataFrame not used.\nReference:\nhttps://docs.microsoft.com/es-es/azure/machine-learning/how-to-train-with-datasets","topic":"3","answer":"B","answer_ET":"B","question_id":333,"answers_community":[],"url":"https://www.examtopics.com/discussions/microsoft/view/51412-exam-dp-100-topic-3-question-7-discussion/","answer_images":[],"question_text":"You create a datastore named training_data that references a blob container in an Azure Storage account. The blob container contains a folder named csv_files in which multiple comma-separated values (CSV) files are stored.\nYou have a script named train.py in a local folder named ./script that you plan to run as an experiment using an estimator. The script includes the following code to read data from the csv_files folder:\n//IMG//\n\nYou have the following script.\n//IMG//\n\nYou need to configure the estimator for the experiment so that the script can read the data from a data reference named data_ref that references the csv_files folder in the training_data datastore.\nWhich code should you use to configure the estimator?\nA.\n//IMG//\n\nB.\n//IMG//\n\nC.\n//IMG//\n\nD.\n//IMG//\n\nE.\n//IMG//"},{"id":"Fx3cGiyFpvoqFyHejIIm","question_id":334,"answer_ET":"","answer_images":["https://www.examtopics.com/assets/media/exam-media/04274/0026100001.png"],"discussion":[{"content":"This is the correct answer : \n\nCompute\nInference\nAttached\nInference","comment_id":"403783","comments":[{"comment_id":"1327048","content":"We deploy the model to an inference cluster, but to perform the deployment action we need a cluster or an instance.","poster":"gunn_m","timestamp":"1734294420.0","upvote_count":"1"},{"comment_id":"425420","timestamp":"1644959220.0","content":"Agreed. When deploying in AML Designer you have to select inference cluster. See example where they use AKS.\nhttps://docs.microsoft.com/en-us/azure/machine-learning/tutorial-designer-automobile-price-deploy","poster":"DennisWitjes","upvote_count":"2"}],"upvote_count":"51","timestamp":"1641897000.0","poster":"syed_ahmed"},{"content":"This answer is correct!\n\nhttps://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target","poster":"htiwari","timestamp":"1636033680.0","upvote_count":"7","comment_id":"349367"},{"comments":[{"comment_id":"1329736","timestamp":"1734735480.0","poster":"isa_ismail","upvote_count":"1","content":"It should be inference if it is mentioned that deployment is for real time process."}],"poster":"deyoz","content":"For the deployment is it inference or compute cluster, I understand as inference but folks are saying compute cluster.","timestamp":"1722633780.0","comment_id":"1138903","upvote_count":"1"},{"upvote_count":"2","comment_id":"1006669","poster":"A_PL300","timestamp":"1710343920.0","content":"Question like this one on September 4, 2023 exam"},{"content":"on exam 07/March/2023","upvote_count":"1","comment_id":"832880","poster":"Yuriy_Ch","timestamp":"1694164860.0"},{"comment_id":"811286","timestamp":"1692228360.0","content":"Requirement A: To train models by using the Azure Machine Learning designer, you can use a compute cluster. This will allow you to allocate resources to run your training jobs in a distributed fashion, enabling you to complete training faster and at a lower cost.\n\nRequirement B: To score new data through a trained model published as a real-time web service, you can use an inference cluster. This will allow you to deploy your model as a scalable web service that can handle incoming requests for real-time predictions.\n\nRequirement C: To train models by using an Azure Databricks cluster, you can use both an attached compute and a compute cluster. An attached compute allows you to connect your Azure Machine Learning workspace to your Databricks workspace, while a compute cluster allows you to allocate resources to run your training jobs in a distributed fashion.\n\nRequirement D: To deploy models by using the Azure Machine Learning Designer, you can use a compute cluster. This will allow you to allocate resources to run your deployment job, enabling you to complete the deployment faster and at a lower cost.","poster":"phdykd","comments":[{"comment_id":"1149753","poster":"deyoz","content":"but realtime deployment doesn't work in compute cluster. Hence, inference cluster. In my opinion. i am still not sure tough.","upvote_count":"1","timestamp":"1723592340.0"}],"upvote_count":"1"},{"poster":"phdykd","content":"Requirement A:\n3- Compute cluster\n\nRequirement B:\n2- Inference cluster\n\nRequirement C:\n1-Attached compute\n3- Compute cluster\n\nRequirement D:\n3- Compute cluster","comment_id":"811283","timestamp":"1692228240.0","upvote_count":"2"},{"comment_id":"603642","content":"on exam 18-5-22","timestamp":"1668844680.0","upvote_count":"3","poster":"racnaoamo"},{"comment_id":"570381","content":"on exam 18/03/2022","timestamp":"1663483440.0","upvote_count":"2","poster":"kkkk_jjjj"},{"timestamp":"1651866960.0","comment_id":"473645","content":"on Exam 6 Nov 2021","upvote_count":"2","poster":"JoshuaXu"},{"poster":"pkal","content":"on exam 9/24/2021","upvote_count":"1","timestamp":"1648164000.0","comment_id":"451110"},{"content":"https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-model-designer\n\nlast one is Inference cluster\n\n**In the Models asset page, select the registered model.\n\nSelect the Deploy button.\n\nIn the configuration menu, enter the following information:\n\nInput a name for the endpoint.\nSelect to deploy the model to Azure Kubernetes Service or Azure Container Instance. **","upvote_count":"6","timestamp":"1644036480.0","poster":"azure1000","comment_id":"420021"},{"poster":"erp31","upvote_count":"3","timestamp":"1643598120.0","comment_id":"417656","content":"on exam 30/07/2021"},{"timestamp":"1633757220.0","upvote_count":"3","poster":"ACSC","content":"Answer is correct. See the link https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-attach-compute-studio","comment_id":"331745"},{"upvote_count":"7","poster":"ac45863","comment_id":"330702","timestamp":"1633640700.0","content":"In my opinion:\n- Compute cluster\n- Compute cluster\n- Attached compute\n- Inference cluster"}],"timestamp":"2021-04-07 23:05:00","unix_timestamp":1617829500,"answers_community":[],"url":"https://www.examtopics.com/discussions/microsoft/view/49548-exam-dp-100-topic-3-question-70-discussion/","question_text":"DRAG DROP -\nYou create machine learning models by using Azure Machine Learning.\nYou plan to train and score models by using a variety of compute contexts. You also plan to create a new compute resource in Azure Machine Learning studio.\nYou need to select the appropriate compute types.\nWhich compute types should you select? To answer, drag the appropriate compute types to the correct requirements. Each compute type may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.\nNOTE: Each correct selection is worth one point.\nSelect and Place:\n//IMG//","isMC":false,"question_images":["https://www.examtopics.com/assets/media/exam-media/04274/0026000001.png"],"exam_id":64,"answer_description":"Box 1: Compute cluster -\nCreate a single or multi node compute cluster for your training, batch inferencing or reinforcement learning workloads.\n\nBox 2: Inference cluster -\n\nBox 3: Attached compute -\nThe compute types that can currently be attached for training include:\n\nA remote VM -\nAzure Databricks (for use in machine learning pipelines)\nAzure Data Lake Analytics (for use in machine learning pipelines)\n\nAzure HDInsight -\n\nBox 4: Compute cluster -\nNote: There are four compute types:\n\nCompute instance -\n\nCompute clusters -\n\nInference clusters -\n\nAttached compute -\nNote 2:\n\nCompute clusters -\nCreate a single or multi node compute cluster for your training, batch inferencing or reinforcement learning workloads.\n\nAttached compute -\nTo use compute targets created outside the Azure Machine Learning workspace, you must attach them. Attaching a compute target makes it available to your workspace. Use Attached compute to attach a compute target for training. Use Inference clusters to attach an AKS cluster for inferencing.\n\nInference clusters -\nCreate or attach an Azure Kubernetes Service (AKS) cluster for large scale inferencing.\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-attach-compute-studio","topic":"3","answer":""},{"id":"kOOdbtEgkld6ZrbqlEmb","question_id":335,"question_text":"DRAG DROP -\nYou are building an experiment using the Azure Machine Learning designer.\nYou split a dataset into training and testing sets. You select the Two-Class Boosted Decision Tree as the algorithm.\nYou need to determine the Area Under the Curve (AUC) of the model.\nWhich three modules should you use in sequence? To answer, move the appropriate modules from the list of modules to the answer area and arrange them in the correct order.\nSelect and Place:\n//IMG//","discussion":[{"comment_id":"330704","timestamp":"1633640820.0","upvote_count":"15","content":"It's correct","poster":"ac45863"},{"content":"You can identify what should work by looking at the inputs and outputs of the models in designer. \n\n\"Train, Score, Evaluate\" should work but also \"Tune Model Hyperparameter, Score, Evaluate\". The latter should give yield an improved model compared to the former.","timestamp":"1723700580.0","upvote_count":"1","comment_id":"1150796","poster":"Matt2000"},{"poster":"deyoz","upvote_count":"1","timestamp":"1722634140.0","content":"correct.","comment_id":"1138905"},{"comment_id":"1047454","content":"In sequence\n\n1. Train\n2. Score model\n3. Evaluate","upvote_count":"1","poster":"james2033","timestamp":"1713492480.0"},{"comment_id":"765295","timestamp":"1688442540.0","content":"on 03 Jan 2023","poster":"MattAnya","upvote_count":"3"},{"poster":"ning","timestamp":"1669990320.0","comments":[{"poster":"Matt2000","upvote_count":"1","timestamp":"1723700220.0","content":"you need only one, the second one is optional","comment_id":"1150795"}],"comment_id":"610580","upvote_count":"3","content":"not sure about the evaluate step ...\nfor this step you will need two scored test sets ...\none is from two class boosted decision tree ...\nwhere is the other one from ..."},{"timestamp":"1668844680.0","comment_id":"603643","upvote_count":"1","content":"on exam 18-5-22","poster":"racnaoamo"},{"poster":"hargur","content":"on 19Oct2021","timestamp":"1650441000.0","comment_id":"465003","upvote_count":"2"},{"content":"Exam 01 Oct 2021","upvote_count":"1","comment_id":"456214","timestamp":"1648926960.0","poster":"kisskeo"},{"content":"on exam 30/07/2021","timestamp":"1643598180.0","poster":"erp31","comment_id":"417657","upvote_count":"4"}],"answer":"","url":"https://www.examtopics.com/discussions/microsoft/view/49549-exam-dp-100-topic-3-question-71-discussion/","isMC":false,"answers_community":[],"unix_timestamp":1617829620,"answer_ET":"","answer_description":"Step 1: Train Model -\n\nTwo-Class Boosted Decision Tree -\nFirst, set up the boosted decision tree model.\n1. Find the Two-Class Boosted Decision Tree module in the module palette and drag it onto the canvas.\n2. Find the Train Model module, drag it onto the canvas, and then connect the output of the Two-Class Boosted Decision Tree module to the left input port of the\nTrain Model module.\nThe Two-Class Boosted Decision Tree module initializes the generic model, and Train Model uses training data to train the model.\n3. Connect the left output of the left Execute R Script module to the right input port of the Train Model module (in this tutorial you used the data coming from the left side of the Split Data module for training).\nThis portion of the experiment now looks something like this:\n\n\nStep 2: Score Model -\n\nScore and evaluate the models -\nYou use the testing data that was separated out by the Split Data module to score our trained models. You can then compare the results of the two models to see which generated better results.\n\nAdd the Score Model modules -\n1. Find the Score Model module and drag it onto the canvas.\n2. Connect the Train Model module that's connected to the Two-Class Boosted Decision Tree module to the left input port of the Score Model module.\n3. Connect the right Execute R Script module (our testing data) to the right input port of the Score Model module.\n\n\nStep 3: Evaluate Model -\nTo evaluate the two scoring results and compare them, you use an Evaluate Model module.\n1. Find the Evaluate Model module and drag it onto the canvas.\n2. Connect the output port of the Score Model module associated with the boosted decision tree model to the left input port of the Evaluate Model module.\n3. Connect the other Score Model module to the right input port.","exam_id":64,"question_images":["https://www.examtopics.com/assets/media/exam-media/04274/0026200001.png"],"answer_images":["https://www.examtopics.com/assets/media/exam-media/04274/0026300001.png","https://www.examtopics.com/assets/media/exam-media/04274/0026400001.png","https://www.examtopics.com/assets/media/exam-media/04274/0026500001.png","https://www.examtopics.com/assets/media/exam-media/04274/0026500002.png"],"timestamp":"2021-04-07 23:07:00","topic":"3"}],"exam":{"isMCOnly":false,"provider":"Microsoft","numberOfQuestions":512,"id":64,"lastUpdated":"12 Apr 2025","isBeta":false,"name":"DP-100","isImplemented":true},"currentPage":67},"__N_SSP":true}