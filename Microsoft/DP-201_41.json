{"pageProps":{"questions":[{"id":"iqbbdchkvnfPnDKn36wm","question_images":["https://www.examtopics.com/assets/media/exam-media/03774/0013900001.png"],"isMC":false,"unix_timestamp":1586769960,"answer_description":"Box1: API App -\n\n1. Events generated from the IoT data sources are sent to the stream ingestion layer through Azure HDInsight Kafka as a stream of messages. HDInsight Kafka stores streams of data in topics for a configurable of time.\n2. Kafka consumer, Azure Databricks, picks up the message in real time from the Kafka topic, to process the data based on the business logic and can then send to Serving layer for storage.\n3. Downstream storage services, like Azure Cosmos DB, Azure Synapse Analytics, or Azure SQL DB, will then be a data source for presentation and action layer.\n4. Business analysts can use Microsoft Power BI to analyze warehoused data. Other applications can be built upon the serving layer as well. For example, we can expose APIs based on the service layer data for third party uses.\n\nBox 2: Cosmos DB Change Feed -\nChange feed support in Azure Cosmos DB works by listening to an Azure Cosmos DB container for any changes. It then outputs the sorted list of documents that were changed in the order in which they were modified.\nThe change feed in Azure Cosmos DB enables you to build efficient and scalable solutions for each of these patterns, as shown in the following image:\n\nReference:\nhttps://docs.microsoft.com/bs-cyrl-ba/azure/architecture/example-scenario/data/realtime-analytics-vehicle-iot?view=azurermps-4.4.1","answers_community":[],"answer_ET":"","answer":"","timestamp":"2020-04-13 11:26:00","question_text":"HOTSPOT -\nYou need to ensure that emergency road response vehicles are dispatched automatically.\nHow should you design the processing system? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","topic":"8","url":"https://www.examtopics.com/discussions/microsoft/view/18341-exam-dp-201-topic-8-question-3-discussion/","exam_id":66,"question_id":201,"discussion":[{"timestamp":"1586769960.0","comment_id":"74013","comments":[{"content":"where has Auzre Logic App Connector in Azure Databrick","upvote_count":"3","comment_id":"134897","comments":[{"content":"https://docs.microsoft.com/en-us/azure/connectors/apis-list#managed-api-connectors","upvote_count":"1","timestamp":"1594734960.0","poster":"envy","comment_id":"134898"}],"timestamp":"1594734900.0","poster":"envy"},{"timestamp":"1621433580.0","content":"Indeed, according to logo on the right (sink) it's 'Logic App'.","upvote_count":"2","comment_id":"361449","poster":"alain2"}],"poster":"Luke97","content":"As the Aid Dispatcher is an Azure Logic App, so the data pipe line is from Cosmos DB via Databricks to Azure Logic App. The right answer should be, Box 1 - Cosmos DB Change Feed. Box 2 - Auzre Logic App Connector.","upvote_count":"74"},{"upvote_count":"18","comment_id":"103558","poster":"akhilyadav","content":"I think first box should be Cosmos DB change, and second box should be API call","timestamp":"1591417620.0"},{"upvote_count":"1","content":"The correct answer is : Box 1 - Cosmos DB Change Feed. Box 2 - Azure API.\n* You can check the answer about Box 2 in the second fig.","poster":"Qrm_1972","timestamp":"1623267360.0","comment_id":"378499"},{"upvote_count":"2","timestamp":"1613390700.0","poster":"sturcu","content":"I think for triggering Logic up we need to use WebHook\nhttps://docs.microsoft.com/en-us/connectors/custom-connectors/create-webhook-trigger","comment_id":"290930"},{"content":"Change Feed and then API app. https://docs.microsoft.com/en-us/azure/cosmos-db/change-feed","poster":"Az301301X","upvote_count":"1","timestamp":"1611924180.0","comment_id":"279308"},{"timestamp":"1602328080.0","content":"The first box should be Cosmos Change feed and the second box should be webhook. Logic apps cannot be triggered by API calls","comment_id":"197266","poster":"knightkkd","upvote_count":"2","comments":[{"comments":[{"timestamp":"1616906940.0","comment_id":"322376","poster":"jms309","content":"But we have databricks instead of adf in that case ... So I think the webhook should be okay","upvote_count":"2"}],"comment_id":"201146","timestamp":"1602866580.0","content":"Logic Apps can be triggered by ADF http activity","upvote_count":"2","poster":"Sureei"}]}],"answer_images":["https://www.examtopics.com/assets/media/exam-media/03774/0013900002.png","https://www.examtopics.com/assets/media/exam-media/03774/0014000001.jpg","https://www.examtopics.com/assets/media/exam-media/03774/0014100001.jpg"]},{"id":"PEgRGIHVO1EY9kbvyM4Y","answer_images":["https://www.examtopics.com/assets/media/exam-media/03774/0014200002.jpg"],"question_id":202,"discussion":[{"comment_id":"240113","timestamp":"1607605260.0","poster":"syu31svc","content":"Indexing for reporting is right\nTTL for security is correct\nOther listed options don't tie in","upvote_count":"11"},{"poster":"tvs_examtopics","upvote_count":"1","content":"BackTrack - The solution must report changes in real time.\nBox1 - would this be Cosmos DB change feed?","comment_id":"393570","timestamp":"1624949340.0"},{"poster":"Exam_pas","comment_id":"390885","content":"Indexing - For retrieving reports fast\nTTL - To purge data once retention period is over","upvote_count":"1","timestamp":"1624677420.0"},{"upvote_count":"4","timestamp":"1588696320.0","comment_id":"84187","comments":[{"upvote_count":"13","timestamp":"1589546460.0","comment_id":"89503","content":"Might have to do with this line\n\n\"Data must only be stored for seven years\"\n\nsee\n\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/time-to-live","poster":"vistran"}],"content":"What does TTL have to do with security?","poster":"runningman"}],"topic":"8","answers_community":[],"exam_id":66,"question_images":["https://www.examtopics.com/assets/media/exam-media/03774/0014200001.jpg"],"url":"https://www.examtopics.com/discussions/microsoft/view/19681-exam-dp-201-topic-8-question-4-discussion/","timestamp":"2020-05-05 18:32:00","answer_ET":"","answer_description":"Box 1: Cosmos DB indexes -\nThe report for Backtrack must execute as quickly as possible.\nYou can override the default indexing policy on an Azure Cosmos container, this could be useful if you want to tune the indexing precision to improve the query performance or to reduce the consumed storage.\n\nBox 2: Cosmos DB TTL -\nThis solution reports on all data related to a specific vehicle license plate. The report must use data from the SensorData collection. Users must be able to filter vehicle data in the following ways:\n✑ vehicles on a specific road\n✑ vehicles driving above the speed limit\nNote: With Time to Live or TTL, Azure Cosmos DB provides the ability to delete items automatically from a container after a certain time period. By default, you can set time to live at the container level and override the value on a per-item basis. After you set the TTL at a container or at an item level, Azure Cosmos DB will automatically remove these items after the time period, since the time they were last modified.\nIncorrect Answers:\nCosmos DB stored procedures: Stored procedures are best suited for operations that are write heavy. When deciding where to use stored procedures, optimize around encapsulating the maximum amount of writes possible. Generally speaking, stored procedures are not the most efficient means for doing large numbers of read operations so using stored procedures to batch large numbers of reads to return to the client will not yield the desired benefit.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/index-policy https://docs.microsoft.com/en-us/azure/cosmos-db/time-to-live\nDesign data processing solutions","question_text":"DRAG DROP -\nYou need to ensure that performance requirements for Backtrack reports are met.\nWhat should you recommend? To answer, drag the appropriate technologies to the correct locations. Each technology may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.\nNOTE: Each correct selection is worth one point.\nSelect and Place:\n//IMG//","isMC":false,"answer":"","unix_timestamp":1588696320},{"id":"SgQIdpgDsUzVMTWi0E0N","url":"https://www.examtopics.com/discussions/microsoft/view/16582-exam-dp-201-topic-9-question-1-discussion/","question_id":203,"unix_timestamp":1584199140,"question_text":"What should you recommend to prevent users outside the Litware on-premises network from accessing the analytical data store?","topic":"9","answer":"A","answer_ET":"A","isMC":true,"answer_description":"Scenario: Ensure that the analytical data store is accessible only to the company's on-premises network and Azure services.\nVirtual network rules are one firewall security feature that controls whether the database server for your single databases and elastic pool in Azure SQL Database or for your databases in SQL Data Warehouse accepts communications that are sent from particular subnets in virtual networks.\nServer-level, not database-level: Each virtual network rule applies to your whole Azure SQL Database server, not just to one particular database on the server. In other words, virtual network rule applies at the server-level, not at the database-level.\nReference:\nhttps://docs.microsoft.com/en-us/azure/sql-database/sql-database-vnet-service-endpoint-rule-overview","answers_community":[],"answer_images":[],"discussion":[{"poster":"nelson000","upvote_count":"55","content":"I think that corrcet response should be D because this \"Litware does not plan to implement Azure ExpressRoute or a VPN between the on-premises network and Azure\"","comment_id":"63896","timestamp":"1584199140.0"},{"comments":[{"timestamp":"1587829140.0","content":"Azure is a Paas and there is no way to implement vNet for a SQL database unless you're using a Private Link, which is not mentioned in the question. So the answer should be D.","upvote_count":"9","comment_id":"79558","poster":"Tombarc"}],"comment_id":"73056","timestamp":"1586541180.0","upvote_count":"18","content":"The answer should be A which is implementing VNet for SQL database server level. VNet is not \"Azure ExpressRoute or a VPN between the on-premises and Azure\".","poster":"Luke97"},{"content":"D. a server-level firewall IP rule","comment_id":"345638","timestamp":"1619725320.0","poster":"davita8","upvote_count":"3"},{"comment_id":"341406","poster":"rmk4ever","content":"Ans : D\n\"By default, Azure service resources secured to virtual networks aren't reachable from on-premises networks. If you want to allow traffic from on-premises, you must also allow public (typically, NAT) IP addresses from your on-premises or ExpressRoute. You can add these IP addresses through the IP firewall configuration for Azure service resources.\"\n\nref: https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-service-endpoints-overview","timestamp":"1619158020.0","upvote_count":"2"},{"upvote_count":"1","poster":"syu31svc","comments":[{"content":"but the requirement states that the company does not plan to implement a virtual network, D is correct","poster":"chaoxes","comment_id":"247651","upvote_count":"3","timestamp":"1608330060.0"}],"content":"Virtual network rules are one firewall security feature that controls whether the server for your databases and elastic pools in Azure SQL Database or for your databases in Azure Synapse accepts communications that are sent from particular subnets in virtual networks\nA is correct","comment_id":"240000","timestamp":"1607596740.0"},{"content":"Don't read the above comments and get confused, given answer is correct,\nA. a server-level virtual network rule","comments":[{"comment_id":"268916","content":"No it's not. How would you peer you virtual network with the on premise network? You need someway to tie them together. Virtual network rule only makes sense if you have some gateway in azure as well. Or EspressRoute","timestamp":"1610810820.0","upvote_count":"5","poster":"ThijsN"}],"timestamp":"1601502420.0","comment_id":"190602","poster":"groy","upvote_count":"5"},{"poster":"oku","content":"As long as there is no VPN between On prim and azure , you should go for IP rule based , it should applied to Server\nso Answer is D","upvote_count":"9","comment_id":"139336","timestamp":"1595238720.0"},{"timestamp":"1594709160.0","comment_id":"134633","comments":[{"upvote_count":"1","comment_id":"345936","content":"Azure Synapse does support server-level IP firewall. The link provided by you is common for both Azure SQL and Synapse.","poster":"karma_wins","timestamp":"1619764500.0","comments":[{"comments":[{"upvote_count":"1","timestamp":"1634177820.0","content":"Important\n\nThis article does not apply to Azure SQL Managed Instance. For information about network configuration, see Connect your application to Azure SQL Managed Instance.\n>>>>>>>>>>>\nAzure Synapse only supports server-level IP firewall rules. It doesn't support database-level IP firewall rules.","poster":"kimalto452","comment_id":"461791"}],"timestamp":"1619764560.0","comment_id":"345937","content":"I mean it does support database-level IP firewall rule","poster":"karma_wins","upvote_count":"1"}]}],"content":"Azure Synapse only supports server-level IP firewall rules. It doesn't support database-level IP firewall rules. https://docs.microsoft.com/en-us/azure/azure-sql/database/firewall-configure","poster":"envy","upvote_count":"4"},{"content":"The Correct answer is D : \"A SERVER LEVEL IP FIREWALL RULE\"","comment_id":"133769","poster":"Rohit77","timestamp":"1594629360.0","upvote_count":"7"},{"upvote_count":"2","comment_id":"127051","poster":"Tommy65","content":"The answer is correct according to https://docs.microsoft.com/en-us/azure/azure-sql/database/vnet-service-endpoint-rule-overview.\nIn particular there is one point that says: On the firewall, IP address ranges do apply to the following networking items, but virtual network rules do not:\nSite-to-Site (S2S) virtual private network (VPN)\nOn-premises via ExpressRoute\nAnd the brief clearly said not to use Express Route and VPN","timestamp":"1593969180.0"},{"content":"Vpn and Vnet are two different things, The former is a gateway to establish a secure and encrypted connection whereas Vnet is a logical isolation of the Azure cloud dedicated to your subscription and completely private. If 'outside users' implies the user over the public domain then Vnet is the right approach.","timestamp":"1592869560.0","upvote_count":"3","comments":[{"content":"How users from on-premises would connect to the database with server-level virtual network rule? Nowhere in the documentation it is said that VNet is a valid configuration to give the on-premises network access to the database? -> D is the answer","timestamp":"1603719480.0","upvote_count":"1","poster":"M0e","comment_id":"206282"}],"comment_id":"116909","poster":"Abhilvs"},{"upvote_count":"4","timestamp":"1587886140.0","content":"The answer is correct. \nAccording to the scenario: \"Ensure that the analytical data store is accessible only to the company's on-premises network and Azure services.\"\nFor users outside on-premise, they should only access data through other Azure services. In that case, VNET rule should be better choice. It's difficult to use server level firewall rule to manage network access from other Azure services by IP addresses.","comment_id":"79780","comments":[{"content":"To use vNet for on premise users, you need some kind of VPN solution - to join on premise network with Azure network. And as clear stated , no VPN here. So Server level firewall that will whitelist on premise address space will do.","timestamp":"1588426260.0","upvote_count":"8","comment_id":"82619","comments":[{"timestamp":"1589865120.0","upvote_count":"1","content":"usinga server-level firewall IP rule, we can only restrict or allow specific IP. to ensure org only access we need vnet firewall","comment_id":"91821","poster":"azurearch"}],"poster":"Leonido"},{"content":"No it isn't. Just allow access from 0.0.0.0 to allow all Azure services.","timestamp":"1610810880.0","poster":"ThijsN","comment_id":"268919","upvote_count":"1"}],"poster":"AaronZ"},{"timestamp":"1587494220.0","upvote_count":"9","content":"D should be the clear answer.\nIP firewall rules: Use this feature to explicitly allow connections from a specific IP address, for example from on-premises machines\nVirtual Network firewall rules: Use this feature to allow traffic from a specific Virtual Network within the Azure boundary\nhttps://docs.microsoft.com/en-us/azure/sql-database/sql-database-networkaccess-overview","poster":"Yuri1101","comment_id":"77557"},{"poster":"Sam9999","content":"Agree, it should be Server Level IP rule, https://docs.microsoft.com/en-us/azure/sql-database/sql-database-networkaccess-overview","comment_id":"67888","timestamp":"1585082880.0","upvote_count":"5"}],"exam_id":66,"question_images":[],"timestamp":"2020-03-14 16:19:00","choices":{"C":"a database-level firewall IP rule","D":"a server-level firewall IP rule","B":"a database-level virtual network rule","A":"a server-level virtual network rule"}},{"id":"vNUcXUeCGxu0HtFKXCg9","isMC":false,"url":"https://www.examtopics.com/discussions/microsoft/view/59818-exam-dp-201-topic-9-question-2-discussion/","answers_community":[],"answer_images":["https://www.examtopics.com/assets/media/exam-media/03774/0021900001.jpg"],"answer":"","answer_ET":"","question_id":204,"unix_timestamp":1629126240,"timestamp":"2021-08-16 17:04:00","question_text":"DRAG DROP -\nYou discover that the highest chance of corruption or bad data occurs during nightly inventory loads.\nYou need to ensure that you can quickly restore the data to its state before the nightly load and avoid missing any streaming data.\nWhich three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\nSelect and Place:\n//IMG//","question_images":["https://www.examtopics.com/assets/media/exam-media/03774/0021800001.jpg"],"exam_id":66,"answer_description":"Scenario: Daily inventory data comes from a Microsoft SQL server located on a private network.\nStep 1: Before the nightly load, create a user-defined restore point\nSQL Data Warehouse performs a geo-backup once per day to a paired data center. The RPO for a geo-restore is 24 hours. If you require a shorter RPO for geo- backups, you can create a user-defined restore point and restore from the newly created restore point to a new data warehouse in a different region.\nStep 2: Restore the data warehouse to a new name on the same server.\nStep 3: Swap the restored database warehouse name.\nReference:\nhttps://docs.microsoft.com/en-us/azure/sql-data-warehouse/backup-and-restore","topic":"9","discussion":[{"upvote_count":"2","timestamp":"1629126240.0","content":"Correct!","poster":"lgtiza","comment_id":"425862"}]},{"id":"S5kUGbZiPeb4BP6LvwEN","isMC":true,"url":"https://www.examtopics.com/discussions/microsoft/view/46893-exam-dp-201-topic-9-question-3-discussion/","discussion":[{"upvote_count":"23","timestamp":"1615647180.0","comment_id":"309780","content":"https://azure.microsoft.com/en-ca/updates/column-level-security-is-now-supported-in-azure-sql-data-warehouse/\nYou can use CLS to manage user access to specific columns in your tables in a simpler manner, without having to redesign your data warehouse. CLS eliminates the need to maintain access restriction logic away from the data in another application or introduce views for filtering out sensitive columns for a subset of users.","comments":[{"comment_id":"339421","content":"https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/column-level-security","timestamp":"1618907280.0","upvote_count":"1","poster":"Devendra00023"}],"poster":"AlexD332"},{"upvote_count":"11","content":"Wrong answer the correct one is B\nclassification used at the audit level, but does not hide any information.","timestamp":"1616503860.0","poster":"H_S","comment_id":"318091"},{"content":"Should be column level security","poster":"savin","comment_id":"375971","upvote_count":"1","timestamp":"1622979720.0"},{"upvote_count":"4","comment_id":"345647","timestamp":"1619725980.0","content":"B. column-level security","poster":"davita8"},{"content":"Data Discovery & Classification provides basic capabilities for discovering, classifying, labeling, and reporting the sensitive data in your databases.\nI don't see words protect, encrypt...","poster":"AlexD332","timestamp":"1615647060.0","comment_id":"309777","upvote_count":"3"}],"answer_images":[],"answers_community":[],"answer_ET":"A","choices":{"A":"data sensitivity labels","D":"Transparent Data Encryption (TDE)","B":"column-level security","C":"row-level security"},"answer":"A","question_text":"What should you recommend using to secure sensitive customer contact information?","exam_id":66,"unix_timestamp":1615647060,"question_id":205,"topic":"9","answer_description":"Scenario: Limit the business analysts' access to customer contact information, such as phone numbers, because this type of data is not analytically relevant.\nLabeling: You can apply sensitivity-classification labels persistently to columns by using new metadata attributes that have been added to the SQL Server database engine. This metadata can then be used for advanced, sensitivity-based auditing and protection scenarios.\nIncorrect Answers:\nD: Transparent Data Encryption (TDE) encrypts SQL Server, Azure SQL Database, and Azure Synapse Analytics data files, known as encrypting data at rest.\nTDE does not provide encryption across communication channels.\nReference:\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/data-discovery-and-classification-overview https://docs.microsoft.com/en-us/azure/sql-database/sql-database-security-overview","question_images":[],"timestamp":"2021-03-13 15:51:00"}],"exam":{"lastUpdated":"12 Apr 2025","isImplemented":true,"numberOfQuestions":206,"name":"DP-201","id":66,"provider":"Microsoft","isBeta":false,"isMCOnly":false},"currentPage":41},"__N_SSP":true}