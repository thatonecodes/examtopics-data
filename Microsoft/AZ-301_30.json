{"pageProps":{"questions":[{"id":"6gulCxeCEmVshElxDjpg","unix_timestamp":1572388440,"question_images":["https://www.examtopics.com/assets/media/exam-media/02744/0010200008.png"],"answer_ET":"B","question_text":"You have 100 servers that run Windows Server 2012 R2 and host Microsoft SQL Server 2012 R2 instances. The instances host databases that have the following characteristics:\n✑ The largest database is currently 3 TB. None of the databases will ever exceed 4 TB.\n✑ Stored procedures are implemented by using CLR.\nYou plan to move all the data from SQL Server to Azure.\nYou need to recommend an Azure service to host the databases. The solution must meet the following requirements:\n✑ Whenever possible, minimize management overhead for the migrated databases.\n✑ Minimize the number of database changes required to facilitate the migration.\nEnsure that users can authenticate by using their Active Directory credentials.\n//IMG//\n\nWhat should you include in the recommendation?","isMC":true,"timestamp":"2019-10-29 23:34:00","exam_id":51,"answers_community":[],"discussion":[{"upvote_count":"39","comment_id":"19586","content":"Key to the solution is mentioning of CLR (common language runtime). CLR is not supported for Single Database or Elastic pool.\nWhich makes Managed Instance (and instance pools) the only correct answer","timestamp":"1573066680.0","poster":"Oz"},{"timestamp":"1572388440.0","poster":"MyLord","content":"Quite helpful for this question\nhttps://docs.microsoft.com/en-us/azure/sql-database/sql-database-features","comment_id":"18299","upvote_count":"11","comments":[{"content":"B is ok","upvote_count":"3","poster":"tartar","comment_id":"181522","timestamp":"1600421340.0"}]},{"content":"B. Azure SQL Database Managed Instance","upvote_count":"2","timestamp":"1612191180.0","comment_id":"281313","poster":"glam"},{"upvote_count":"1","content":"B is correct answer.","timestamp":"1609469760.0","comment_id":"256634","poster":"sanketshah"},{"comments":[{"upvote_count":"1","timestamp":"1596068340.0","poster":"KCjoe","content":"I don't understand, can you explain why it is not D if there is minimize number of changes, everything should be exactly the same if using VM","comment_id":"147003","comments":[{"upvote_count":"2","timestamp":"1597184040.0","content":"I guess due to management overhead as mentioned in criteria","poster":"satya22","comment_id":"155904"}]}],"comment_id":"145929","upvote_count":"4","timestamp":"1595952780.0","content":"As i've seen with this questions and AZ-300 questions, almost every time it states \"Minimize the number of database changes required to facilitate the migration\" the answer is managed instances.","poster":"Yannor"},{"content":"Answer is correct , here is the reference \nhttps://docs.microsoft.com/en-us/azure/azure-sql/managed-instance/sql-managed-instance-paas-overview","upvote_count":"3","comment_id":"116151","timestamp":"1592812140.0","poster":"Baranli"},{"timestamp":"1589416800.0","poster":"pandeya442","upvote_count":"1","comment_id":"88578","content":"ans in correct"},{"upvote_count":"4","poster":"starnb","comment_id":"64803","content":"Instance Pools support CLR and can reduce management overhead. https://docs.microsoft.com/en-us/azure/sql-database/sql-database-features","comments":[{"comment_id":"64807","timestamp":"1584384180.0","content":"However, \"Minimize the number of database changes required to facilitate the migration\" makes Managed Instance the most suitable answer.","poster":"starnb","upvote_count":"6"}],"timestamp":"1584384060.0"}],"answer_images":[],"topic":"3","url":"https://www.examtopics.com/discussions/microsoft/view/7460-exam-az-301-topic-3-question-4-discussion/","answer":"B","question_id":146,"choices":{"B":"Azure SQL Database Managed Instance","A":"Azure SQL Database single databases","D":"SQL Server 2016 on Azure virtual machines","C":"Azure SQL Database elastic pools"},"answer_description":"References:\nhttps://docs.microsoft.com/en-us/azure/sql-database/sql-database-managed-instance"},{"id":"KCeKkr85jsqF33Y6gsOg","question_images":["https://www.examtopics.com/assets/media/exam-media/02744/0010400001.png"],"url":"https://www.examtopics.com/discussions/microsoft/view/11318-exam-az-301-topic-3-question-5-discussion/","question_id":147,"topic":"3","answer":"","answers_community":[],"unix_timestamp":1578051000,"isMC":false,"question_text":"DRAG DROP -\nYou are designing a virtual machine that will run Microsoft SQL Server and will contain two data disks. The first data disk will store log files, and the second data disk will store data. Both disks are P40 managed disks.\nYou need to recommend a caching policy for each disk. The policy must provide the best overall performance for the virtual machine.\nWhich caching policy should you recommend for each disk? To answer, drag the appropriate policies to the correct disks. Each policy may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.\nNOTE: Each correct selection is worth one point.\nSelect and Place:\n//IMG//","discussion":[{"upvote_count":"13","timestamp":"1588466820.0","comment_id":"82827","poster":"nieuw","content":"As an example, you can apply these guidelines to SQL Server running on Premium Storage by doing the following,\nConfigure \"ReadOnly\" cache on premium storage disks hosting data files.\na. The fast reads from cache lower the SQL Server query time since data pages are retrieved much faster from the cache compared to directly from the data disks.\nb. Serving reads from cache, means there is additional Throughput available from premium data disks. SQL Server can use this additional Throughput towards retrieving more data pages and other operations like backup/restore, batch loads, and index rebuilds.\nConfigure \"None\" cache on premium storage disks hosting the log files.\na. Log files have primarily write-heavy operations. Therefore, they do not benefit from the ReadOnly cache.\n\nhttps://docs.microsoft.com/en-us/azure/virtual-machines/windows/premium-storage-performance#disk-caching"},{"timestamp":"1587893760.0","comment_id":"79817","upvote_count":"9","comments":[{"poster":"AJ_Galosmo","comment_id":"157891","content":"This is correct.","upvote_count":"1","timestamp":"1597390200.0"}],"poster":"Rajuuu","content":"Caching is for Data only and not for Log files."},{"upvote_count":"2","comment_id":"281314","poster":"glam","timestamp":"1612191240.0","content":"Log - None\nData - Read only"},{"comment_id":"256635","poster":"sanketshah","upvote_count":"1","content":"given answer is correct.","timestamp":"1609469760.0"},{"comment_id":"131898","upvote_count":"1","poster":"Neetiniti","timestamp":"1594443780.0","content":"Box1-Log-None-Configure \"None\" cache on premium storage disks hosting the log files. Log files have primarily write-heavy operations. Therefore, they do not benefit from the ReadOnly cache. Box2-Read Only-Configure \"ReadOnly\" cache on premium storage disks hosting data files. https://docs.microsoft.com/en-us/azure/virtual-machines/windows/premium-storage-performance#disk-caching"},{"timestamp":"1589416860.0","upvote_count":"2","content":"given ans is correct","poster":"pandeya442","comment_id":"88580"},{"timestamp":"1578051000.0","content":"Read only Cache for Data disk recommend only for Premium, as Q has P40, its valid.\nhttps://docs.microsoft.com/en-us/azure/virtual-machines/windows/sql/virtual-machines-windows-sql-performance#disks-guidance","poster":"onlyfunmails","comments":[{"content":"Log - None\nData - Read only","poster":"tartar","comment_id":"181523","timestamp":"1600421580.0","upvote_count":"4"}],"upvote_count":"5","comment_id":"34912"}],"answer_images":["https://www.examtopics.com/assets/media/exam-media/02744/0010400002.png"],"answer_description":"References:\nhttps://docs.microsoft.com/en-us/azure/virtual-machines/windows/sql/virtual-machines-windows-sql-performance","answer_ET":"","exam_id":51,"timestamp":"2020-01-03 12:30:00"},{"id":"loiaXiOqKIgks3AGqEzf","question_text":"You plan to create an Azure Cosmos DB account that uses the SQL API. The account will contain data added by a web application. The web application will send data daily.\nYou need to recommend a notification solution that meets the following requirements:\n✑ Sends email notification when data is received from IoT devices.\n✑ Minimizes compute cost.\nWhat should you include in the recommendation?","timestamp":"2019-12-10 11:13:00","question_images":[],"answer_description":"","isMC":true,"discussion":[{"comment_id":"64813","timestamp":"1584384540.0","poster":"starnb","upvote_count":"12","content":"Answer A seems correct. Answer B is wrong - Why would you bind a function to SendGrid instead of Event Source i.e. IoT device.","comments":[{"upvote_count":"1","poster":"asdfgh1234567","comment_id":"140726","content":"you can have a input and output binding.","timestamp":"1595375400.0"}]},{"comments":[{"poster":"jimmyjose","upvote_count":"1","timestamp":"1599413460.0","content":"Functions is cheaper than Logic Apps. Hence, the correct answer is B.\n1. https://azure.microsoft.com/en-us/pricing/details/logic-apps/\n2. https://azure.microsoft.com/en-us/pricing/details/functions/","comment_id":"174727"}],"poster":"beriz","timestamp":"1591681080.0","comment_id":"105705","content":"I'm going with B:\n- functions are cheaper than logic apps (The first 400,000 GB/s of execution and 1,000,000 executions are free.)\n- you can easily create a cosmosdb trigger (https://docs.microsoft.com/en-us/azure/azure-functions/functions-create-cosmos-db-triggered-function)","upvote_count":"10"},{"comment_id":"295296","upvote_count":"1","timestamp":"1613845380.0","poster":"lodalasan","content":"Question is not properly described."},{"poster":"glam","timestamp":"1612191780.0","upvote_count":"2","comment_id":"281322","content":"B. Deploy a function app that is configured to use the Consumption plan and a SendGrid binding."},{"poster":"sanketshah","comment_id":"256636","timestamp":"1609469880.0","content":"B is correct answer.","upvote_count":"2"},{"timestamp":"1601406300.0","poster":"sidbarker","content":"B is correct.\nThere is not such thing like SendGrid binding.","comments":[{"upvote_count":"1","content":"Yes it is there. Refer https://learn.microsoft.com/en-us/azure/azure-functions/functions-bindings-sendgrid?tabs=isolated-process%2Cfunctionsv2&pivots=programming-language-csharp","comment_id":"1076506","timestamp":"1700588460.0","poster":"MiniLa92"}],"comment_id":"189883","upvote_count":"2"},{"comment_id":"181747","timestamp":"1600442040.0","content":"i will go with A","poster":"Rooh","upvote_count":"1"},{"timestamp":"1600091040.0","comment_id":"179320","upvote_count":"4","content":"https://docs.microsoft.com/en-us/azure/cosmos-db/serverless-computing-database\n\nI think: B","poster":"user_name","comments":[{"poster":"toja1234","timestamp":"1601311920.0","upvote_count":"1","comments":[{"comment_id":"189180","content":"I cant delete it. its a function trigger and the cosmoc-db binding is not mentioned","timestamp":"1601312100.0","poster":"toja1234","upvote_count":"1"}],"comment_id":"189176","content":"Yes B. The only difference to the example in the link is that we have to send an extra Email\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/serverless-computing-database#iot-use-case---azure-functions-trigger-and-output-binding-for-cosmos-db"}]},{"comment_id":"173475","timestamp":"1599231300.0","content":"Following Azure doc says Logic App is the right connector for Azure cosmos DB SQL APi \nhttps://docs.microsoft.com/en-us/connectors/documentdb/\nDon't you guys think about option A?\n\nThanks","upvote_count":"3","poster":"bobby2"},{"content":"There is no trigger for CosmosDB availabe in Logics Apps, so B is correct answer","timestamp":"1597412340.0","comment_id":"158132","upvote_count":"3","poster":"PawanGupta"},{"comment_id":"151661","content":"The correct answer is B.\nYou can send email by using SendGrid bindings in Azure Functions. Azure Functions supports an output binding for SendGrid.\nNote: When you're using the Consumption plan, instances of the Azure Functions host are dynamically added and removed based on the number of incoming events.\nReference: https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-sendgrid https://docs.microsoft.com/en-us/azure/azure-functions/functions-scale#consumption-plan","poster":"zarl","timestamp":"1596687480.0","upvote_count":"2"},{"content":"Correct Answer: B. \nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-triggers-bindings","comment_id":"138540","poster":"Neetiniti","timestamp":"1595148180.0","upvote_count":"6"},{"content":"I'll go with B. Logic Apps Cosmos DB connector is for creating and updating documents, there's no cosmos DB trigger in Logic apps. But you can use a cosmos DB trigger in a function.","poster":"Wildsheep","comment_id":"131872","timestamp":"1594437360.0","upvote_count":"6","comments":[{"upvote_count":"1","content":"^^^ This ^^^ There are no Cosmos DB triggers in Logic apps, which rules A & C out. B with send grid makes more sense.\n\nAnswer - B","timestamp":"1595919840.0","comment_id":"145521","poster":"BiggusJiggus"}]},{"content":"I think both Azure logic app and Azure function works well, https://docs.microsoft.com/en-us/azure/cosmos-db/serverless-computing-database#iot-use-case---azure-functions-trigger-and-output-binding-for-cosmos-db, https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-sendgrid?tabs=csharp, and Azure function & consumption plan should be cheaper, I will go with B.","poster":"freeheart","upvote_count":"2","comment_id":"128520","timestamp":"1594088400.0"},{"upvote_count":"2","content":"i think key word here is sendgrid action and sendgrid binding","poster":"kumar123","timestamp":"1593635640.0","comment_id":"124521"},{"timestamp":"1593259500.0","poster":"dev2dev","comment_id":"121199","content":"Isn't Logic app comes with hidden charges which requires polling? so functions app in consumption plan could be cheaper?","upvote_count":"1"},{"comment_id":"119426","upvote_count":"1","content":"Agree on above . A. Deploy an Azure logic app that has the Azure Cosmos DB connector configured to use a SendGrid action","timestamp":"1593087600.0","poster":"DeveshSolanki"},{"comment_id":"119055","timestamp":"1593054660.0","poster":"chaudh","upvote_count":"2","content":"The architect is weird. In IoT model, Web App should get data from Cosmos DB (https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/iot-using-cosmos-db). In question, looks like the web app will get IoT data and feed Cosmos DB (The account will contain data added by a web application)."},{"timestamp":"1593038700.0","comment_id":"118917","poster":"jonnybugaloo","upvote_count":"1","content":"You can send email by using SendGrid bindings in Azure Functions. Azure Functions supports an output binding for SendGrid.\nWhen you're using the Consumption plan, instances of the Azure Functions host are dynamically added and removed based on the number of incoming events, reducing the costs:\nReference:\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-sendgrid\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-scale#consumption-plan"},{"poster":"DrM","content":"\"Sends email notification when data is received from IoT devices\" . Who is receiving data from IoT? It's the webapp not CosmosDB. WebApp can trigger a function which has SenGridBinding. \"B\" looks correct.","timestamp":"1592874420.0","upvote_count":"3","comment_id":"116942"},{"content":"B is right answer. Cosmos DB cannot have any trigger in Logic app. There is only action item available at this time. Functions are cheaper than Logic Apps.","comments":[{"comment_id":"278644","poster":"arseyam","upvote_count":"1","timestamp":"1611847560.0","content":"https://docs.microsoft.com/en-us/azure/azure-functions/functions-create-cosmos-db-triggered-function"}],"timestamp":"1592468820.0","upvote_count":"3","poster":"mynk29","comment_id":"113020"},{"comment_id":"104586","upvote_count":"2","timestamp":"1591539540.0","content":"A. https://docs.microsoft.com/en-us/connectors/documentdb/","poster":"crossroads"},{"upvote_count":"3","poster":"corona2020","comment_id":"99886","content":"I wll go with A\n\nB-> Doesn't mention how the event is consumed\nD-> Doesn't mention how the notification is sent\n\nwe need a solution that can consume the event and then send notification. Basically acts as intermediator.","timestamp":"1591006200.0"},{"content":"A. Deploy an Azure logic app that has the Azure Cosmos DB connector configured to use a SendGrid action.","upvote_count":"2","comments":[{"upvote_count":"1","timestamp":"1590305580.0","content":"agreed","poster":"STFN2019","comment_id":"94743"}],"timestamp":"1589369040.0","poster":"pandeya442","comment_id":"88226"},{"comments":[{"timestamp":"1666842780.0","comment_id":"705198","poster":"Chang401","content":"NOPE! Microsoft recommends using Azure IoT Hub to connect IoT devices to Azure check it out!!!!!","upvote_count":"1"}],"poster":"Yanzhi","comment_id":"76656","timestamp":"1587347520.0","content":"I think key phases is \"when data is received from IoT devices\", only event hub can get IoT devices data, you can send email notification through SendGrid *OR* custom code in function app, so I think answer D seems correct, D is only one answer that contains \"Event Hub\"","upvote_count":"6"},{"upvote_count":"4","content":"the answer B, is correct we can send email by using SendGrid binding to Azure function .\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-sendgrid?tabs=csharp","poster":"mlourh","timestamp":"1586394480.0","comment_id":"72509"},{"content":"Agree with A","upvote_count":"1","comment_id":"72421","timestamp":"1586361660.0","poster":"Daren"},{"content":"It should be A. Logic apps also uses consumption plan. Option B does not talk about how function app will connect to CosmosDB.","upvote_count":"7","timestamp":"1583737380.0","comment_id":"60964","poster":"JatinA"},{"content":"Why is not D?\nhttps://docs.microsoft.com/en-us/azure/connectors/connectors-create-api-azure-event-hubs","comments":[{"comment_id":"51457","content":"event hub doesn't send emails but sendgrid does","poster":"bootyholeman","timestamp":"1581905340.0","upvote_count":"2"}],"comment_id":"50414","upvote_count":"3","timestamp":"1581666960.0","poster":"Anthony_P"},{"comments":[{"comments":[{"comments":[{"content":"B is ok","comment_id":"181527","timestamp":"1600422060.0","upvote_count":"4","poster":"tartar"}],"comment_id":"51455","content":"Hm, logic apps is also kinda a consumption plan - you pay per usage. I guess whichever is cheaper. On the other hand, B doesn't have \"Cosmos DB trigger\" but A has \"Cosmos DB Connector\" which includes triggers and actions. I'd go with A","upvote_count":"3","timestamp":"1581905280.0","poster":"bootyholeman"}],"content":"I think because B uses the consumption plan it minimises costs since it will only charge while running, that meets that requirement.","comment_id":"28825","timestamp":"1576079640.0","upvote_count":"13","poster":"TeaPot91"},{"upvote_count":"1","timestamp":"1590043020.0","comment_id":"93219","content":"But then how would you identify if the data was received from IOT device or soume other client.","poster":"justraj"}],"poster":"kewl","timestamp":"1575972780.0","content":"Why not A. Azure logic app with Azure Cosmos DB connector?","upvote_count":"2","comment_id":"28525"}],"url":"https://www.examtopics.com/discussions/microsoft/view/10101-exam-az-301-topic-3-question-6-discussion/","answer":"B","topic":"3","answer_images":[],"unix_timestamp":1575972780,"answer_ET":"B","exam_id":51,"choices":{"A":"Deploy an Azure logic app that has the Azure Cosmos DB connector configured to use a SendGrid action.","D":"Deploy a function app that is configured to use the Consumption plan and an Azure Event Hubs binding.","B":"Deploy a function app that is configured to use the Consumption plan and a SendGrid binding.","C":"Deploy an Azure logic app that has a SendGrid connector configured to use an Azure Cosmos DB action."},"answers_community":[],"question_id":148},{"id":"lGWCG8IItp7TnCki6Pem","unix_timestamp":1590358140,"answer_images":[],"question_images":[],"question_id":149,"url":"https://www.examtopics.com/discussions/microsoft/view/21272-exam-az-301-topic-3-question-7-discussion/","answer_ET":"A","question_text":"You have Azure virtual machines that run a custom line-of-business web application.\nYou plan to use a third-party solution to parse event logs from the virtual machines stored in an Azure storage account.\nYou need to recommend a solution to save the event logs from the virtual machines to the Azure Storage account. The solution must minimize costs and complexity.\nWhat should you include in the recommendation?","answer":"A","exam_id":51,"topic":"3","answers_community":[],"isMC":true,"timestamp":"2020-05-25 00:09:00","answer_description":"References:\nhttps://docs.microsoft.com/en-us/azure/virtual-machines/windows/extensions-diagnostics","discussion":[{"content":"correct.\nhttps://docs.microsoft.com/en-us/azure/virtual-machines/windows/extensions-diagnostics","comment_id":"95111","upvote_count":"19","timestamp":"1590358140.0","comments":[{"content":"Azure diagnostics extension works with windows VM only. It does not specify anywhere in the question that the VMs are windows based only.","poster":"maheshwary","comment_id":"149989","comments":[{"timestamp":"1600422120.0","comment_id":"181530","poster":"tartar","upvote_count":"2","content":"A is ok"},{"comment_id":"189090","upvote_count":"1","poster":"fatmaphil","timestamp":"1601301300.0","content":"Two versions exist: WAD for Windows and LAD for Linux - ref:\nhttps://docs.microsoft.com/en-us/azure/azure-monitor/platform/agents-overview"}],"upvote_count":"1","timestamp":"1596486840.0"}],"poster":"satgo"},{"poster":"FloJoe","upvote_count":"11","timestamp":"1592482800.0","content":"Seems correct, as \"The key differences to consider are:\nAzure Diagnostics Extension can be used only with Azure virtual machines. The Log Analytics agent can be used with virtual machines in Azure, other clouds, and on-premises.\n---> Azure Diagnostics extension sends data to Azure Storage, Azure Monitor Metrics (Windows only) and Event Hubs. The Log Analytics agent collects data to Azure Monitor Logs. <---\nThe Log Analytics agent is required for solutions, Azure Monitor for VMs, and other services such as Azure Security Center.\" \n\nhttps://docs.microsoft.com/en-us/azure/azure-monitor/platform/diagnostics-extension-overview","comment_id":"113154"},{"poster":"glam","comment_id":"281335","upvote_count":"1","timestamp":"1612192560.0","content":"A. Azure VM Diagnostics Extension"},{"content":"Was thinking so hard about the options, decided to go with A.\nSince the requirement is to \"save the VM logs to an Azure Storage Account\".\nThe destination is already determined, the only thing to do now is to get a solution to \"save\" the logs.","timestamp":"1601341800.0","comment_id":"189355","upvote_count":"1","poster":"colinquek"},{"poster":"zarl","timestamp":"1596687780.0","content":"The correct answer is A\nThe Azure Diagnostics VM extension enables you to collect monitoring data, such as performance counters and event logs, from your Windows VM. You can granularly specify what data you want to collect and where you want the data to go, such as an Azure Storage account or an Azure Event Hub.","upvote_count":"6","comment_id":"151668"},{"upvote_count":"2","poster":"Yannor","comment_id":"145934","timestamp":"1595953380.0","content":"\"You need to recommend a solution to save the event logs from the virtual machines to the Azure Storage account\" -> It is asking about a way to send logs from VM to a storage account"},{"content":"I think answer is Azure Log Analytics","timestamp":"1591668660.0","comments":[{"comment_id":"295375","upvote_count":"2","comments":[{"poster":"AKumar","comment_id":"317084","timestamp":"1616412120.0","content":"Agree with Levo017, here is the comparison between the two.\n\nhttps://docs.microsoft.com/en-us/azure/azure-monitor/agents/diagnostics-extension-overview#comparison-to-log-analytics-agent\nAs question aske to send the logs to Storage Acoount , answer given is correct.","upvote_count":"1"}],"timestamp":"1613852880.0","content":"Log Analytics sends to Azure Monitor Logs, not Storage Account.","poster":"levo017"}],"comment_id":"105649","upvote_count":"3","poster":"joydeep002"}],"choices":{"C":"event log subscriptions","B":"Azure Monitor","D":"Azure Log Analytics","A":"Azure VM Diagnostics Extension"}},{"id":"7dmmjuAX3IQSR3xpGy9X","question_id":150,"url":"https://www.examtopics.com/discussions/microsoft/view/18935-exam-az-301-topic-3-question-8-discussion/","unix_timestamp":1587576000,"answer_description":"","answer":"","answer_images":["https://www.examtopics.com/assets/media/exam-media/02744/0010700001.png"],"topic":"3","timestamp":"2020-04-22 19:20:00","discussion":[{"comment_id":"88249","upvote_count":"21","poster":"pandeya442","comments":[{"timestamp":"1590931860.0","comment_id":"99313","comments":[{"content":"The given answer has LRS for the backups","comment_id":"174744","poster":"Jimmer","upvote_count":"3","timestamp":"1599416400.0"}],"upvote_count":"2","content":"why not LRS for the Backups ?","poster":"mbelferagui"}],"content":"Premium Managed Disks\nPremium Managed Disks\nStandard Managed Disks","timestamp":"1589371800.0"},{"upvote_count":"20","timestamp":"1591006680.0","poster":"corona2020","content":"Given answers are correct.\n\nChoose LRS over standard managed disk because of price difference\nhttps://azure.microsoft.com/en-us/pricing/details/storage/","comments":[{"comment_id":"632475","poster":"JayBee65","content":"But that does not meet the speed requirements","timestamp":"1658039820.0","upvote_count":"1"}],"comment_id":"99889"},{"upvote_count":"1","content":"Premium\nPremium\nLRS","comment_id":"306300","poster":"glam","timestamp":"1615284240.0"},{"content":"given answer is correct.","poster":"sanketshah","upvote_count":"3","comment_id":"256638","timestamp":"1609470000.0"},{"upvote_count":"1","comment_id":"178586","poster":"CloudDummyDude","comments":[{"upvote_count":"1","content":"and there is requirement for lowest cost in the table..","poster":"CloudDummyDude","comment_id":"178588","timestamp":"1599978900.0","comments":[{"comment_id":"277284","timestamp":"1611695460.0","upvote_count":"2","content":"LRS is lowest cost not GRS so LRS is right choice for backup.","poster":"milind8451"}]}],"timestamp":"1599978540.0","content":"I would suggest:\nPremium\nPremium\nGRS. GRS because of servers are using two zones. If LRS is used and one of the zones goes down, it might be that backups are in that case unavailable. The guestion does not require most cost effective solution, so select best solution that won't cause weakest link the any part of solution"},{"poster":"tromek","content":"on different data centers in the same Azure region -means ZRS not LRS and not GRS.","timestamp":"1598954640.0","upvote_count":"6","comment_id":"171287"},{"comment_id":"162457","content":"Given answers are correct and available on AZ-301 exam","timestamp":"1597950840.0","upvote_count":"3","poster":"Duva"},{"timestamp":"1595348340.0","comment_id":"140428","upvote_count":"13","poster":"gboyega","content":"Premium\nPremium\nLRS"},{"poster":"krosbonz","comment_id":"118337","content":"Based on this website SQL backups require a storage account, so Standard Managed wouldn't apply.\nhttps://docs.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/automated-backup-sql-2014\nAnswer given is correct","timestamp":"1592996880.0","upvote_count":"9"},{"comment_id":"77998","comments":[{"comment_id":"82104","poster":"Rajuuu","content":"Because servers are deployed to different data centers in the same Azure region.As it is within a single region GRS is not needed due to cost.","comments":[{"poster":"nieuw","upvote_count":"4","timestamp":"1588469580.0","comments":[{"poster":"tartar","content":"Premium\nPremium\nLRS","timestamp":"1600422420.0","upvote_count":"3","comment_id":"181531"}],"content":"Premium Managed Disks allow either LRS or ZRS options","comment_id":"82835"}],"upvote_count":"11","timestamp":"1588324140.0"},{"upvote_count":"2","poster":"AJ_Galosmo","comment_id":"159700","content":"\"will be deployed to different data centers in the same Azure region\"","timestamp":"1597647300.0"}],"poster":"ElSharif","timestamp":"1587576000.0","content":"For Databases and logs, why it's not GRS?","upvote_count":"1"}],"exam_id":51,"isMC":false,"question_text":"DRAG DROP -\nYou are planning an Azure solution that will host production databases for a high-performance application. The solution will include the following components:\n✑ Two virtual machines that will run Microsoft SQL Server 2016, will be deployed to different data centers in the same Azure region, and will be part of an Always\nOn availability group.\n✑ SQL Server data that will be backed up by using the Automated Backup feature of the SQL Server IaaS Agent Extension (SQLIaaSExtension)\nYou identify the storage priorities for various data types as shown in the following table.\n//IMG//\n\nWhich storage type should you recommend for each data type? To answer, drag the appropriate storage types to the correct data types. Each storage type may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.\nNOTE: Each correct selection is worth one point.\nSelect and Place:\n//IMG//","answers_community":[],"answer_ET":"","question_images":["https://www.examtopics.com/assets/media/exam-media/02744/0010600003.png","https://www.examtopics.com/assets/media/exam-media/02744/0010600004.png"]}],"exam":{"isImplemented":true,"id":51,"name":"AZ-301","lastUpdated":"12 Apr 2025","isBeta":false,"provider":"Microsoft","isMCOnly":false,"numberOfQuestions":232},"currentPage":30},"__N_SSP":true}