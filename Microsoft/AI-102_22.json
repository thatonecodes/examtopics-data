{"pageProps":{"questions":[{"id":"lbvU8kjpmEBbth3PjpoY","question_text":"HOTSPOT -\nYou have a Computer Vision resource named contoso1 that is hosted in the West US Azure region.\nYou need to use contoso1 to make a different size of a product photo by using the smart cropping feature.\nHow should you complete the API URL? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","timestamp":"2021-08-23 08:13:00","isMC":false,"answer_images":["https://img.examtopics.com/ai-102/image208.png"],"answers_community":[],"url":"https://www.examtopics.com/discussions/microsoft/view/60330-exam-ai-102-topic-2-question-3-discussion/","answer":"","question_images":["https://www.examtopics.com/assets/media/exam-media/04271/0008300001.png"],"exam_id":40,"unix_timestamp":1629699180,"answer_ET":"","topic":"2","discussion":[{"comments":[{"poster":"ziizai","comments":[{"comments":[{"poster":"rdemontis","comment_id":"1060933","upvote_count":"1","content":"however, I don't understand how I do using the generic endpoint to meet the requirement, \"You need to use contoso1 to make a different size of a product photo\". I'm not so sure to use the generic endpoint.","comments":[{"poster":"rdemontis","content":"Clarified. If you go on the API documentation https://westus.dev.cognitive.microsoft.com/docs/services/computer-vision-v3-2/operations/56f91f2e778daf14a499f20c/console (here is the version 3.2 but it's the same) you can verify that both type of endpoint are supported. If you choose a custom endpoint named contos1 you'll get the following url request:\nhttps://westus.dev.cognitive.microsoft.com/docs/services/computer-vision-v3-2/operations/56f91f2e778daf14a499f20c/console.\n\nSo correct answers are \nhttps://contoso1.cognitiveservices.azure.com/\ngenerateThumbnail","comments":[{"timestamp":"1698961680.0","upvote_count":"1","comment_id":"1060936","poster":"rdemontis","content":"sorry i pasted twice the same url in the message before:\nwith the custom endpoint the url of the service is:\nhttps://contoso1.cognitiveservices.azure.com/vision/v3.2/generateThumbnail?width=300&height=200&smartCropping=true&model-version=latest"}],"timestamp":"1698961560.0","comment_id":"1060934","upvote_count":"9"}],"timestamp":"1698961200.0"}],"timestamp":"1698960840.0","poster":"rdemontis","content":"agree with you","comment_id":"1060930","upvote_count":"1"}],"content":"yes, the question is exactly the sample here \nhttps://docs.microsoft.com/en-us/rest/api/computervision/3.1/generate-thumbnail/generate-thumbnail#examples","timestamp":"1630647840.0","upvote_count":"15","comment_id":"438316"}],"poster":"czmiel24","comment_id":"430905","upvote_count":"63","content":"The second one should be generate Thumbnail imho.","timestamp":"1629822780.0"},{"timestamp":"1635266280.0","comment_id":"468165","comments":[{"content":"I agree with generateThumbnail, however first answer provided by ET should be correct https://westus.api.cognitive.microsoft.com as shown in https://docs.microsoft.com/en-us/rest/api/computervision/3.1/generate-thumbnail/generate-thumbnail?tabs=HTTP#examples","upvote_count":"10","poster":"ppo12","timestamp":"1657793700.0","comment_id":"631290"},{"poster":"MDawson","comment_id":"862962","content":"contoso1 is a Computer Vision resource, so you would not specify /vision in the URL. Therefore I think the correct answer must be westus.api.cognitive.microsoft.com","upvote_count":"3","timestamp":"1680784920.0"},{"timestamp":"1676159760.0","comments":[{"comment_id":"959313","poster":"dazdzadzadzaazd","content":"Today (july 2023), both regional and resource endpoints are supported. So both are correct : \nhttps://contoso1.cognitiveservices.azure.com/ \nAND \nhttps://westus.api.cognitive.microsoft.com\n\nDoc : https://learn.microsoft.com/en-us/azure/ai-services/cognitive-services-custom-subdomains#what-if-an-sdk-asks-me-for-the-region-for-a-resource\n\"Regional endpoints and custom subdomain names are both supported and can be used interchangeably.\"\n\nI tested it by creating a custom vision resource and used it with both endpoints.","upvote_count":"11","comments":[{"timestamp":"1711070220.0","content":"Yes, I think the key thing is that the key is specified.","upvote_count":"1","comment_id":"1179755","poster":"Ody"}],"timestamp":"1690009140.0"}],"poster":"AzureJobsTillRetire","comment_id":"805762","upvote_count":"1","content":"I agree with both answers here. The example https://westus.api.cognitive.microsoft.com is just an example and it needs to be changed to use the source in real which is contoso1."}],"content":"Both answers are incorrect.\n\nThe correct answers are:\nhttps://contoso1.cognitiveservices.azure.com/\nAND\ngenerateThumbnail\n\nwestus.dev.cognitive.microsoft.com wouldn't be a correct Computer Vision endpoint if the resource name is contoso1.\n\nAlso, per the documentation, areaOfInterest \"returns a bounding box around the most important area of the image\", it doesn't return a different size photo (https://docs.microsoft.com/en-us/rest/api/computervision/3.1/get-area-of-interest).","upvote_count":"48","poster":"VulcanMXNY"},{"upvote_count":"1","timestamp":"1743307620.0","content":"For this one, there is an update since 1st of July 2019: New resources will use custom subdomain names. therefore the endpoint will be contoso1.xxx","poster":"ouhshuo","comment_id":"1411931"},{"content":"The correct answers are:\nhttps://contoso1.cognitiveservices.azure.com/\nAND\ngenerateThumbnail","poster":"Jaspal","upvote_count":"1","comment_id":"1400194","timestamp":"1742312400.0"},{"comment_id":"1363326","poster":"syupwsh","content":"\"West US Azure region\" --> https://westus.api.cognitive.microsoft.com\n\"smart cropping \" --> generateThumbnail\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-generating-thumbnails","upvote_count":"1","timestamp":"1740789180.0"},{"timestamp":"1719053520.0","comment_id":"1235337","poster":"SAMBIT","upvote_count":"3","content":"POST https://westus.api.cognitive.microsoft.com/vision/v3.2/generateThumbnail?width=500&height=500&smartCropping=True\n\n\n{\n \"url\": \"{url}\"\n}"},{"poster":"hatanaoki","content":"1. contoso1\n2. gererateThumbnail","upvote_count":"3","comment_id":"1220251","timestamp":"1716900660.0"},{"upvote_count":"4","timestamp":"1711593600.0","comment_id":"1184513","poster":"varinder82","content":"Final Answer:\n1. https://contoso1.cognitiveservices.azure.com/\n2. generateThumbnail"},{"comment_id":"1175057","poster":"Murtuza","content":"API URL:\nThe base URL for the Analyze Image 4.0 API is typically:\nhttps://<region>.api.cognitive.microsoft.com/vision/v4.0/analyze\n\nReplace <region> with the appropriate Azure region (in this case, West US).","upvote_count":"2","timestamp":"1710603360.0"},{"content":"\"You need to use contoso1 to make a different size of a product photo by using the smart cropping feature.\" -> You need to use contoso1 to make.... that is hosted in the west us....","timestamp":"1692960540.0","poster":"[Removed]","upvote_count":"1","comment_id":"989963"},{"content":"1. https://contoso1.cognitiveservices.azure.com\n2. generateThumbnail\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-generating-thumbnails\nA thumbnail is a reduced-size representation of an image. Thumbnails are used to represent images and other data in a more economical, layout-friendly way. The Computer Vision API uses smart cropping to create intuitive image thumbnails that include the most important regions of an image with priority given to any detected faces.\n\nThe Computer Vision thumbnail generation algorithm works as follows:\n- Remove distracting elements from the image and identify the area of interestâ€”the area of the image in which the main object(s) appears.\n- Crop the image based on the identified area of interest.\n- Change the aspect ratio to fit the target thumbnail dimensions.","comment_id":"939706","poster":"zellck","upvote_count":"13","timestamp":"1688196120.0"},{"upvote_count":"4","comment_id":"936149","content":"was on exam 28/06/2023","poster":"Pixelmate","timestamp":"1687929540.0"},{"content":"I simulated this in Azure Portal:\n1. endpoint is https://contoso1.cognitiveservices.azure.com/\n2. thumbnail","comment_id":"914836","timestamp":"1685899260.0","upvote_count":"3","poster":"ziggy1117"},{"upvote_count":"5","comment_id":"865932","poster":"Sachz88","timestamp":"1681091340.0","content":"https://contoso1.cognitiveservices.azure.com/ is correct.\n\nContext from ChatGPT:\nwestus.api.cognitive.microsoft.com is also a valid endpoint for the Cognitive Services APIs, including the Computer Vision API. However, it is important to note that this endpoint is deprecated and will be retired on October 31, 2024.\n\nTherefore, it is recommended to use the newer endpoint format https://<resource-name>.cognitiveservices.azure.com/ for any new development work. This endpoint format follows a more standard Azure resource URL pattern and is also more flexible in terms of geographic distribution and availability.\n\nHope it helps."},{"upvote_count":"1","content":"The first is https://contoso1.cognitiveservices.azure.com the second is generateThumbnail\nPOST https://*.cognitiveservices.azure.com/vision/v3.2/generateThumbnail?width=100&height=100&smartCropping=true&model-version=latest HTTP/1.1\nHost: *.cognitiveservices.azure.com\nContent-Type: application/json\n\n{\"url\":\"http://example.com/images/test.jpg\"}","poster":"NNU","comment_id":"819537","timestamp":"1677176400.0"},{"timestamp":"1673918100.0","comments":[{"upvote_count":"1","content":"Hello.. I have exam tomorrow. Can you suggest if ET questions were on exam?","comment_id":"779223","poster":"ap1234pa","timestamp":"1673981220.0"}],"content":"on my exam (2023-01-16 Passed)\n\nMy Answer:\nhttps://westus.api.cognitive.microsoft.com\nBut I think this is wrong.Because Question request use contoso1!\nSo correct answer is :\nhttps://contoso1.cognitiveservices.azure.com/","poster":"KingChuang","upvote_count":"3","comment_id":"778439"},{"timestamp":"1658739600.0","upvote_count":"4","comment_id":"636584","content":"Westus\ngenerateThumbnail\n\nhttps://docs.microsoft.com/en-gb/azure/cognitive-services/computer-vision/how-to/generate-thumbnail#call-the-generate-thumbnail-api\n\ncurl -H \"Ocp-Apim-Subscription-Key: <subscriptionKey>\" -o <thumbnailFile> -H \"Content-Type: application/json\" \"https://westus.api.cognitive.microsoft.com/vision/v3.2/generateThumbnail?width=100&height=100&smartCropping=true\" -d \"{\\\"url\\\":\\\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Shorkie_Poo_Puppy.jpg/1280px-Shorkie_Poo_Puppy.jpg\\\"}\"","poster":"Eltooth"},{"comments":[{"poster":"RamonKaus","timestamp":"1658666040.0","content":"Second one is obv. generateThumbnail","upvote_count":"1","comment_id":"636048"}],"poster":"RamonKaus","timestamp":"1658666040.0","content":"First one is contoso.cognitive services. Just checked my own script and cognitiive services uses ur rg name in the endpoint URI.","comment_id":"636047","upvote_count":"1"},{"timestamp":"1658208540.0","content":"For first dropdown, 3rd option works with cognitive service key and computer vision key as well. whereas 2nd option works with only computer vision key. so answer 3rd works in both situation. therefor i'll go with https://westus.api.cognitive.microsoft.com/vision/v3.1/generateThumbnail?width=500&height=500&smartCropping=True","poster":"JDarshan","comment_id":"633371","upvote_count":"1"},{"comment_id":"632013","poster":"Eltooth","content":"Contoso1\nGeneratethumbnail","timestamp":"1657946760.0","comments":[{"poster":"Eltooth","timestamp":"1658739480.0","content":"Correction: New resources created after July 1, 2019, will use custom subdomain names, therefore:\nwestus and generateThumbnail are correct answers. \n\nExact copy here from MS docs: \ncurl -H \"Ocp-Apim-Subscription-Key: <subscriptionKey>\" -o <thumbnailFile> -H \"Content-Type: application/json\" \"https://westus.api.cognitive.microsoft.com/vision/v3.2/generateThumbnail?width=100&height=100&smartCropping=true\" -d \"{\\\"url\\\":\\\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Shorkie_Poo_Puppy.jpg/1280px-Shorkie_Poo_Puppy.jpg\\\"}\"\n\n\nhttps://docs.microsoft.com/en-gb/azure/cognitive-services/computer-vision/how-to/generate-thumbnail#call-the-generate-thumbnail-api","comment_id":"636582","upvote_count":"4"}],"upvote_count":"1"},{"comment_id":"596337","timestamp":"1651577760.0","upvote_count":"3","poster":"satishk4u","content":"Was on exam on 03-May-2022"},{"content":"the 2nd one should be generate thumbnail\nGet Thumbnail\nThis operation generates a thumbnail image with the user-specified width and height. By default, the service analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on the ROI","comment_id":"585119","upvote_count":"1","poster":"2ez4Zane","timestamp":"1649841780.0"},{"timestamp":"1647581160.0","upvote_count":"3","content":"I tested this solution. I create a compute vision by azure portal for a West USA region and It was created the endpoint \"https://contoso1.cognitiveservices.azure.com/\" For mi this is correct. The other url \"https://westus.api.cognitive.microsoft.com\" than mention in this chat is an example.","comment_id":"570258","poster":"catalene"},{"content":"Ask: make a different size of a product photo by using the smart cropping feature\nSelection 1: https://westus.api.cognitive.microsoft.com\nSelecting 2: Generate Thumbnail\n\nAlthought Using the API for generating thumbnail feature is available through both the Get Thumbnail and Get Area of Interest APIs both leveraging smart cropping, the ask is only to resize the entire image.\n\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-generating-thumbnails\n\nGenerate Thumbnail\nThis operation generates a thumbnail image with the user-specified width and height.\nPOST https://westus.api.cognitive.microsoft.com/vision/v3.1/generateThumbnail?width=500&height=500&smartCropping=True\nOcp-Apim-Subscription-Key: {API key}","comment_id":"558558","timestamp":"1646107980.0","upvote_count":"1","poster":"reachmymind"},{"content":"GenerateThumbnail takes in Height Width and SmartCropping = True/false and returns the actual binary image data. It is the correct answer in this case.\n\nArea of Interest does not accept smartCropping true/false and only returns a bounding box not an image so it is definately the wrong answer.","comment_id":"534125","timestamp":"1643317680.0","poster":"timmayy54","upvote_count":"1"},{"timestamp":"1641344520.0","poster":"sumanshu","comment_id":"517089","content":"https://westus.api.congnitive.microsoft.com and Generate Thumbnail\n\nhttps://docs.microsoft.com/en-us/rest/api/computervision/3.1/generate-thumbnail/generate-thumbnail","upvote_count":"1"},{"timestamp":"1641314400.0","comment_id":"516819","poster":"Contactfornitish","content":"Was on exam 02/01/2022","upvote_count":"1"},{"upvote_count":"1","content":"Second is generateThumbnail : Check code\n\nPOST https://westus.api.cognitive.microsoft.com/vision/v3.1/generateThumbnail?width=500&height=500&smartCropping=True\n\nhttps://docs.microsoft.com/de-de/rest/api/computervision/3.1/generate-thumbnail/generate-thumbnail","comment_id":"501662","timestamp":"1639514160.0","poster":"alexAlvatroz"},{"comment_id":"488658","upvote_count":"1","content":"Was on exam 27/11/2021","timestamp":"1638062820.0","poster":"Ravnit"},{"content":"The second one should be generateThumbnail?\n\nProof:\ncurl -v -X POST \"https://westus.api.cognitive.microsoft.com/vision/v3.2/generateThumbnail?width={number}&height={number}&smartCropping=true&model-version=latest\"\n-H \"Content-Type: application/json\"\n-H \"Ocp-Apim-Subscription-Key: {subscription key}\"\n\n--data-ascii \"{body}\" \n\nhttps://westus.dev.cognitive.microsoft.com/docs/services/computer-vision-v3-2/operations/56f91f2e778daf14a499f20c","timestamp":"1635014880.0","poster":"Adedoyin_Simeon","upvote_count":"1","comment_id":"466718"},{"upvote_count":"1","poster":"SuperPetey","comment_id":"429708","comments":[{"comment_id":"431201","timestamp":"1629873840.0","upvote_count":"4","poster":"SuperPetey","content":"disregard my previous comment; czmiel24 is correct - only generateThumbnail has the available query parameters present in the question: https://docs.microsoft.com/en-us/rest/api/computervision/3.1/generate-thumbnail/generate-thumbnail"}],"content":"correct: https://westus.dev.cognitive.microsoft.com/docs/services/computer-vision-v3-2/operations/b156d0f5e11e492d9f64418d","timestamp":"1629699180.0"}],"question_id":106,"answer_description":""},{"id":"0loncNLBL5EonWMa0n5x","discussion":[{"timestamp":"1688190900.0","comments":[{"comment_id":"958051","poster":"dazdzadzadzaazd","content":"1. I was about to say Classification, but they say \"and provide the location of the defects\" so it is definitively Object Detection.\n2. General (compact)","upvote_count":"3","timestamp":"1689914100.0"},{"poster":"rdemontis","upvote_count":"2","timestamp":"1699096140.0","content":"agree with you","comment_id":"1062034"}],"content":"1. Object detection\n2. General (compact)\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/get-started-build-detector\n- Select Object Detection under Project Types.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/select-domain#compact-domains\nThe models generated by compact domains can be exported to run locally.","comment_id":"939629","poster":"zellck","upvote_count":"25"},{"upvote_count":"8","comment_id":"933417","timestamp":"1687685160.0","poster":"rveney","content":"This was on my exam"},{"comment_id":"1355489","poster":"syupwsh","content":"Object detection is CORRECT because it identifies and provides the location of multiple objects within an image. In this case, you need to identify defects and ensure that each package contains four products. Object detection can not only identify the defects but also locate them within the packaging, which is crucial for providing actionable feedback to an operator.\n\nGeneral (compact) is CORRECT because it is optimized for devices with limited resources and can be deployed locally, making it suitable for environments with intermittent internet connectivity. This domain supports object detection, which is necessary for identifying and locating defects in packaging as well as ensuring that each package contains four products.","upvote_count":"1","timestamp":"1739341320.0"},{"timestamp":"1726560900.0","comment_id":"1285089","content":"project - object detection because it needs to detect errors.\nDomain - compact as it needs to be run on a container offline","upvote_count":"2","poster":"mrg998"},{"upvote_count":"2","poster":"krzkrzkra","comment_id":"1248478","content":"1. Object detection\n2. General (compact)","timestamp":"1721064480.0"},{"timestamp":"1718981700.0","content":"1. Object detection\n2. General(compact)","poster":"HaraTadahisa","upvote_count":"1","comment_id":"1234512"},{"poster":"taiwan_is_not_china","timestamp":"1716905580.0","comment_id":"1220325","upvote_count":"1","content":"This answer is as follows.\n1. Object detection\n2. General (compact)"},{"content":"1. Object detection\n2. General(compact)","upvote_count":"1","timestamp":"1716637320.0","poster":"nanaw770","comment_id":"1218269"},{"content":"Project type is Object detection. Domain is General(compact).","poster":"takaimomoGcup","upvote_count":"1","timestamp":"1716213060.0","comment_id":"1214366"},{"timestamp":"1708123560.0","content":"lcoally==>mean general(compact)\ndetect =>object detection","poster":"evangelist","comment_id":"1152268","upvote_count":"2"},{"comment_id":"1132970","upvote_count":"4","content":"The factory has intermittent internet connectivity:====> this merans an edge deployment of the model without internet connectivity is needed and then edge model using General(compact) domain suits the demands","timestamp":"1706317620.0","poster":"evangelist"},{"poster":"[Removed]","content":"The answer is correct!","timestamp":"1694492340.0","comment_id":"1005350","upvote_count":"1"},{"upvote_count":"6","poster":"Pixelmate","timestamp":"1687904700.0","comment_id":"935875","content":"Asked in 28/06/2023 exam"},{"poster":"Rob77","content":"Correct - https://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/select-domain#compact-domains","timestamp":"1683345300.0","comment_id":"890456","upvote_count":"3"}],"answer":"","unix_timestamp":1683345300,"question_images":["https://img.examtopics.com/ai-102/image31.png"],"answers_community":[],"exam_id":40,"answer_images":["https://img.examtopics.com/ai-102/image32.png"],"question_id":107,"topic":"2","url":"https://www.examtopics.com/discussions/microsoft/view/108602-exam-ai-102-topic-2-question-30-discussion/","timestamp":"2023-05-06 05:55:00","isMC":false,"answer_description":"","answer_ET":"","question_text":"DRAG DROP\n-\n\nYou have a factory that produces cardboard packaging for food products. The factory has intermittent internet connectivity.\n\nThe packages are required to include four samples of each product.\n\nYou need to build a Custom Vision model that will identify defects in packaging and provide the location of the defects to an operator. The model must ensure that each package contains the four products.\n\nWhich project type and domain should you use? To answer, drag the appropriate options to the correct targets. Each option may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//"},{"id":"1IhMIusZQjm3PHw6CiTC","answer_description":"","answer_images":["https://img.examtopics.com/ai-102/image51.png"],"discussion":[{"comment_id":"939625","poster":"zellck","timestamp":"1688190420.0","content":"1. 0\n2. 25\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/language-service/custom-text-classification/concepts/evaluation-metrics\n\n- Precision: Measures how precise/accurate your model is. It's the ratio between the correctly identified positives (true positives) and all identified positives. The precision metric reveals how many of the predicted classes are correctly labeled.\nPrecision = #True_Positive / (#True_Positive + #False_Positive)\n\n- Recall: Measures the model's ability to predict actual positive classes. It's the ratio between the predicted true positives and what was actually tagged. The recall metric reveals how many of the predicted classes are correct.\nRecall = #True_Positive / (#True_Positive + #False_Negatives)","comments":[{"content":"thanks for explanation","upvote_count":"2","comment_id":"1062043","timestamp":"1699097040.0","poster":"rdemontis"}],"upvote_count":"26"},{"poster":"Pixelmate","content":"Asked in 28/06/2023 exam","timestamp":"1687904760.0","comment_id":"935876","upvote_count":"6"},{"content":"The percentage of false positives is 0 because the precision of the model is 100%, which indicates that there are no false positives. Precision is calculated as the number of true positives divided by the sum of true positives and false positives. A precision of 100% means that all detected objects were correct, implying there were no false positives.\n\nThe value for the number of true positives by the total number of true positives and false negatives is 25 because recall is calculated as the number of true positives divided by the sum of true positives and false negatives. The recall in the graphic is 25%, which indicates that the true positives are 25% of the total true positives and false negatives.","timestamp":"1739341620.0","upvote_count":"1","comment_id":"1355491","poster":"syupwsh"},{"upvote_count":"2","content":"got this in Oct 2024 exam","poster":"4371883","comment_id":"1297459","timestamp":"1728901980.0"},{"poster":"mrg998","timestamp":"1726560960.0","content":"0 & 25","comment_id":"1285090","upvote_count":"1"},{"upvote_count":"1","comment_id":"1225484","poster":"NagaoShingo","content":"1. 0\n2. 25","timestamp":"1717677180.0"},{"poster":"takaimomoGcup","timestamp":"1716636840.0","upvote_count":"1","comment_id":"1218259","content":"1. 0\n2. 25"},{"poster":"Tin_Tin","content":"The answer is correct. \nSee https://learn.microsoft.com/en-us/azure/cognitive-services/Custom-Vision-Service/get-started-build-detector","timestamp":"1686892080.0","upvote_count":"1","comment_id":"924864"},{"content":"It is true.\n#1:Precision = 100%\n#2:recall = 25%","timestamp":"1686725640.0","upvote_count":"1","poster":"973b658","comment_id":"922817"}],"question_text":"HOTSPOT\n-\n\nYou are building a model to detect objects in images.\n\nThe performance of the model based on training data is shown in the following exhibit.\n\n//IMG//\n\n\nUse the drop-down menus to select the answer choice that completes each statement based on the information presented in the graphic.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","question_images":["https://img.examtopics.com/ai-102/image49.png","https://img.examtopics.com/ai-102/image50.png"],"answer":"","isMC":false,"answers_community":[],"topic":"2","question_id":108,"url":"https://www.examtopics.com/discussions/microsoft/view/112135-exam-ai-102-topic-2-question-31-discussion/","exam_id":40,"timestamp":"2023-06-14 08:54:00","unix_timestamp":1686725640,"answer_ET":""},{"id":"N4ZmG8ix9L69N9JUWV13","choices":{"A":"Computer Vision Image Analysis","D":"Azure Cognitive Service for Language","B":"the Read API in Computer Vision","C":"Form Recognizer"},"unix_timestamp":1696465500,"url":"https://www.examtopics.com/discussions/microsoft/view/122477-exam-ai-102-topic-2-question-32-discussion/","discussion":[{"poster":"rdemontis","timestamp":"1699097520.0","comment_id":"1062051","content":"Selected Answer: B\nTo me the correct answer is B. With the new Image Analysis API 4.0 (in preview) you could use OCR feature too, but as i said, it is in preview. And i don't think it is considered in the exam. \n\nhttps://learn.microsoft.com/en-us/azure/ai-services/computer-vision/overview-image-analysis?tabs=4-0\n\nInstead the Read API is particularly adapted for text-heavy documents and it seems this is the case\n\nhttps://learn.microsoft.com/en-us/rest/api/computervision/read/read?view=rest-computervision-v3.1&tabs=HTTP","upvote_count":"11"},{"upvote_count":"9","comment_id":"1025226","poster":"jangotango","timestamp":"1696465680.0","content":"All answers should have a reference to prove the answer is true"},{"timestamp":"1740805560.0","upvote_count":"2","content":"Selected Answer: B\nThe Read API in Computer Vision is CORRECT because it is specifically designed for extracting printed and handwritten text from images. This API is optimized for handling a large number of images and is suitable for scenarios where text needs to be extracted from scanned documents or magazine articles.\n\nB is the answer","comment_id":"1363388","poster":"syupwsh"},{"content":"Selected Answer: B\nComputer Vision is now Azure AI Vision. You can use the Read API of it's OCR service.\n\nThe Optical Character Recognition (OCR) service extracts text from images. You can use the Read API to extract printed and handwritten text from photos and documents.\nhttps://learn.microsoft.com/en-us/azure/ai-services/computer-vision/overview","poster":"DriftKing","comment_id":"1348113","timestamp":"1738090860.0","upvote_count":"1"},{"poster":"shanakrs","upvote_count":"2","comment_id":"1289262","timestamp":"1727318760.0","content":"Answer is C\nForm Recognizer\n\nThere is note in below microsoft doc mentioning about document images for text extraction\n\nOCR for images (version 4.0)\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-ocr\n\nPlease refer important section to Select the Read edition that best fits your requirements.\nhttps://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/call-read-api"},{"content":"Azure AI Document Intelligence is a more sophisticated solution. For example, it can identify key/value pairs, tables, and context-specific fields. If you want to deploy a complete document analysis solution for both extracting AND understanding text, Azure AI Document Intelligence is a good solution. In this case, Document Intelligence is a too advanced solution as the question doesn't provide any information about what to do with the extracted text, the focus here is on text extraction alone. So the answer is B","poster":"mrg998","comment_id":"1285092","upvote_count":"1","comments":[{"upvote_count":"1","timestamp":"1726561200.0","comment_id":"1285093","content":"so answer is B","poster":"mrg998"}],"timestamp":"1726561200.0"},{"comment_id":"1248316","content":"A. Computer vision does not have read model. Read model is document intelligence (formregnize) model","timestamp":"1721045220.0","poster":"CellCS","upvote_count":"3"},{"comment_id":"1246818","upvote_count":"1","content":"Selected Answer: B\nSelected Answer: B","timestamp":"1720794240.0","poster":"krzkrzkra"},{"poster":"HaraTadahisa","content":"Selected Answer: B\nsee if you can spot this one B.","comment_id":"1235168","timestamp":"1719036720.0","upvote_count":"1"},{"timestamp":"1718536500.0","poster":"MarceloManhaes","comment_id":"1231324","content":"This is a good explanation from chat GPT why B is the correct fit and A is not:\n\nA - Computer Vision Image Analysis: This is a service provided by Azure that can extract a wide variety of visual features from your images. It can determine whether an image contains adult content, find specific brands or objects, or find human faces. However, while it does have OCR capabilities, it is not specifically designed for large-scale text extraction from images.\n\nB - Read API in Computer Vision: This is a part of the Azure Computer Vision service that is designed to extract printed and handwritten text from images. It uses state-of-the-art Optical Character Recognition (OCR) algorithms optimized for text-heavy documents2. This could be a good fit for your needs as it is designed to handle large amounts of text in images.\n\nthe key here is option A it is not specifically designed for large-scale text extraction from images.","upvote_count":"2"},{"comment_id":"1218257","content":"Selected Answer: B\nthe Read API in Computer Vision is right.","timestamp":"1716636780.0","upvote_count":"2","poster":"takaimomoGcup"},{"content":"Concordo com o @jangotango sobre as referÃªncias. Tem que evidenciar.","timestamp":"1713518160.0","poster":"[Removed]","comment_id":"1198471","upvote_count":"1"},{"upvote_count":"2","poster":"Murtuza","timestamp":"1712499840.0","content":"Selected Answer: B\nRead API is particularly adapted for text-heavy documents and it seems this is the case","comment_id":"1191012"},{"comments":[{"comment_id":"1183828","timestamp":"1711510800.0","content":"No I don't think so. Azure AI Document Intelligence is a more sophisticated solution. For example, it can identify key/value pairs, tables, and context-specific fields. If you want to deploy a complete document analysis solution for both extracting AND understanding text, Azure AI Document Intelligence is a good solution. In this case, Document Intelligence is a too advanced solution as the question doesn't provide any information about what to do with the extracted text, the focus here is on text extraction alone. So the answer is B.","poster":"Mehe323","upvote_count":"1"}],"upvote_count":"3","content":"Selected Answer: C\nDocument Intelligence(Previously Form Recognizer) reads small to large volume of text from images and PDF documents. For example: receipts, articles, and invoices","timestamp":"1711266120.0","poster":"AlviraTony","comment_id":"1181359"},{"upvote_count":"2","content":"i think it should be B \nbased on ChatGpt \nusing Azure Read API if:\n\nYour primary focus is on text extraction from documents, forms, or images with printed text.\nYou have a batch processing requirement, and you need to process a large number of documents or images at once.\nYou need highly accurate text extraction with structured output.","timestamp":"1698533880.0","poster":"devilsole","comment_id":"1056483"},{"comment_id":"1026261","poster":"JDKJDKJDK","upvote_count":"5","timestamp":"1696570020.0","content":"Selected Answer: B\ni also think its B\n\nUse this interface to get the result of a Read operation, employing the state-of-the-art Optical Character Recognition (OCR) algorithms optimized for text-heavy documents.\n\nhttps://learn.microsoft.com/en-us/rest/api/computervision/3.2preview2/read/read?tabs=HTTP"},{"content":"Why not B?","poster":"jangotango","timestamp":"1696465500.0","upvote_count":"1","comment_id":"1025225"}],"exam_id":40,"answer":"B","timestamp":"2023-10-05 02:25:00","topic":"2","isMC":true,"answer_images":[],"question_images":[],"question_id":109,"answer_ET":"B","answers_community":["B (89%)","11%"],"question_text":"You are building an app that will include one million scanned magazine articles. Each article will be stored as an image file.\n\nYou need to configure the app to extract text from the images. The solution must minimize development effort.\n\nWhat should you include in the solution?","answer_description":""},{"id":"biGTrsccoCIkhWC8AQzq","discussion":[{"timestamp":"1696572180.0","upvote_count":"20","comments":[{"timestamp":"1713000600.0","poster":"[Removed]","content":"I saw it there too :)","comment_id":"1194831","upvote_count":"1"},{"content":"because that is the correct option","upvote_count":"2","poster":"Student2023","comment_id":"1026726","timestamp":"1696603620.0"}],"poster":"suryakalla","content":"This question is part of free assessment given by Microsoft and the answer in that was C.","comment_id":"1026290"},{"content":"Selected Answer: C\nUpload file size and video duration\nIf uploading a file from your device, the file size limit is 2 GB.\nIf the video is uploaded from a URL, the file size limit is 30 GB. The URL must lead to an online media file with a media file extension (for example myvideo.MP4) and not a webpage such as https://www.youtube.com.\n\nThe file duration limit is 4 hours.\n\nhttps://learn.microsoft.com/en-us/azure/azure-video-indexer/avi-support-matrix","timestamp":"1711511280.0","poster":"Mehe323","comment_id":"1183832","upvote_count":"5"},{"content":"Selected Answer: C\nOption C because direct upload to Azure Video Indexer is limited to 2GB.","comment_id":"1329338","poster":"pabsinaz","upvote_count":"2","timestamp":"1734679980.0"},{"content":"got this in Oct 2024 exam","poster":"4371883","comments":[{"poster":"Slapp1n","upvote_count":"1","content":"did you get any labs/simulations?","comment_id":"1299110","timestamp":"1729150020.0"}],"upvote_count":"2","timestamp":"1728902040.0","comment_id":"1297460"},{"timestamp":"1726561320.0","comment_id":"1285094","content":"Selected Answer: C\nmax size for direct upload is 2GB so tou have to have it uploaded somewhere else.","upvote_count":"3","poster":"mrg998"},{"comment_id":"1282925","timestamp":"1726191840.0","poster":"AzureGeek79","upvote_count":"1","content":"ChatGPT says, \"The correct option is B. Upload File1.avi to the Azure Video Indexer website. This is the appropriate first step to index your video file using Azure Video Indexer.\""},{"upvote_count":"1","timestamp":"1725027300.0","poster":"chani_","comment_id":"1275101","content":"Answer C: For large files, Azure Video Indexer supports uploading through a linked storage service like OneDrive."},{"comment_id":"1235167","upvote_count":"1","content":"Selected Answer: C\nsee if you can spot this one C.","poster":"HaraTadahisa","timestamp":"1719036720.0"},{"timestamp":"1716636660.0","comment_id":"1218255","upvote_count":"1","content":"Selected Answer: C\nC is right answer.","poster":"takaimomoGcup"},{"content":"Max file size for direct upload is 2 GB . 30 GB is through url.so answer C","upvote_count":"4","timestamp":"1716191820.0","poster":"TJ001","comment_id":"1214199"},{"poster":"Jimmy1017","comment_id":"1202824","timestamp":"1714167240.0","upvote_count":"1","content":"B. Upload File1.avi to the Azure Video Indexer website.\n\nExplanation:\n\nThe Azure Video Indexer website is specifically designed to analyze and index video files, extracting insights such as keywords, faces, sentiments, and more.\nUploading File1.avi directly to the Azure Video Indexer website allows the platform to process the video file and generate the necessary metadata and insights.\nOptions A, C, and D are not relevant for indexing File1.avi using the Azure Video Indexer website. Uploading to Azure Storage queue (option A) is not appropriate for indexing videos. Microsoft OneDrive (option C) is a cloud storage service and doesn't provide video indexing capabilities like the Azure Video Indexer. Uploading to YouTube (option D) is also not relevant as the task is to index the video using the Azure Video Indexer website. Therefore, option B is the correct choice."},{"timestamp":"1712499960.0","upvote_count":"2","poster":"Murtuza","content":"Selected Answer: C\nC is correct","comment_id":"1191013"},{"upvote_count":"1","content":"Final Answer:\nC","comment_id":"1183110","poster":"varinder82","timestamp":"1711439760.0"},{"poster":"schmoofed","content":"Selected Answer: C\nLooks like C is correct due to the large size of the file being 20GB in the question. See article here: https://learn.microsoft.com/en-us/azure/azure-video-indexer/odrv-download","timestamp":"1708386720.0","comment_id":"1154358","comments":[{"upvote_count":"1","timestamp":"1733327040.0","content":"Doesn't that article clearly state that the file size can't be bigger than 2 GB, if you upload via URL? See section -> Troubleshoot uploading issuses, second from bottom.","comment_id":"1322000","poster":"chrillelundmark"}],"upvote_count":"2"},{"poster":"evangelist","upvote_count":"3","timestamp":"1708123860.0","comment_id":"1152270","comments":[{"poster":"gyaansastra","upvote_count":"1","timestamp":"1741529700.0","content":"The first step is to upload the video file directly to the Azure Video Indexer website. Azure Video Indexer will process the video, extract metadata, and generate insights.\n\nBy uploading the video file to the Azure Video Indexer website, you initiate the indexing process, which allows the service to analyze and create an index of the content in the video.","comment_id":"1371550"}],"content":"Selected Answer: B\nB is correct and B"},{"content":"C: There is a max byte array of 2gb when uploading direct to the indexer so it has to be via a url","timestamp":"1706188980.0","upvote_count":"2","comment_id":"1131694","poster":"suzanne_exam"},{"upvote_count":"1","content":"Selected Answer: C\nhttps://learn.microsoft.com/en-us/azure/azure-video-indexer/considerations-when-use-at-scale","comment_id":"1091851","poster":"MelMac","timestamp":"1702132860.0"},{"timestamp":"1700831100.0","comment_id":"1079271","poster":"ccampagna","upvote_count":"1","content":"Selected Answer: C\nhttps://learn.microsoft.com/en-us/azure/azure-video-indexer/odrv-download?tabs=With-classic-account\n\nAs rdemontis explained , only 2GB files are accepted to upload directly to ACI. So the correct answer should be load the file in OneDrive and generate an URL"},{"comment_id":"1062058","upvote_count":"3","content":"Selected Answer: C\nhttps://learn.microsoft.com/it-it/azure/azure-video-indexer/considerations-when-use-at-scale","poster":"rdemontis","timestamp":"1699098120.0"},{"upvote_count":"2","timestamp":"1698495960.0","content":"B IS THE CORRECT ANSWER","comment_id":"1056185","poster":"DEXTER1022"},{"poster":"chenglim","timestamp":"1698321000.0","upvote_count":"2","content":"Selected Answer: C\nhttps://learn.microsoft.com/en-us/azure/azure-video-indexer/upload-index-videos","comment_id":"1054515"},{"comment_id":"1052278","timestamp":"1698097500.0","upvote_count":"2","content":"Selected Answer: B\nB - chat GPT\nB - working with Azure video indexer you can upload the media directly","poster":"_LAW_"},{"upvote_count":"1","content":"Selected Answer: B\nhttps://learn.microsoft.com/en-us/azure/azure-video-indexer/upload-index-videos","timestamp":"1697790720.0","comment_id":"1048555","poster":"AnonymousJhb"},{"comments":[{"content":"Even in the article you posted, it says the following:\n\"If the upload from file system failed, make sure that the file size isn't larger than 2 GB\"\n\nDo the research indeed.","comment_id":"1124031","timestamp":"1705395120.0","upvote_count":"1","poster":"JonHanes"}],"timestamp":"1697628180.0","content":"Selected Answer: C\nhttps://learn.microsoft.com/en-us/azure/azure-video-indexer/upload-index-videos :\n\nIf the upload from file system failed, make sure that the file size isn't larger than 2 GB. Make sure that you have a stable internet connection.","poster":"katrang","comment_id":"1046852","upvote_count":"1"},{"upvote_count":"1","timestamp":"1696999980.0","content":"Selected Answer: B\nTo index a video using the Azure Video Indexer website, you should choose option B: Upload File1.avi to the Azure Video Indexer website.\n\nHere's a precise answer to your question.","poster":"[Removed]","comment_id":"1040207"},{"comment_id":"1026725","content":"Selected Answer: C\nUploading Guidelines:\n\nUploading files to Video Indexer\nUploading a local file from your device\nSupported file formats include: .wmv, .avi, .mov.\nThe file should be up to 2GB and up to 4 hours.\nYou can upload up to 10 files at a time.\n\nUploading an online file\nThe URL should lead to an online media file (for example a OneDrive file),\nnot a webpage (like www.youtube.com).\nThe file should be up to 30GB and up to 4 hours.\nYou can upload up to 10 files at a time.","upvote_count":"4","poster":"Student2023","timestamp":"1696603560.0"},{"poster":"JDKJDKJDK","content":"Selected Answer: B\nhttps://learn.microsoft.com/en-us/azure/azure-video-indexer/upload-index-videos\n\nSign in to the Video Indexer website.\nSelect Upload.\nSelect the file source. You can upload up to 10 files at a time.","timestamp":"1696570200.0","comment_id":"1026264","upvote_count":"1"}],"answer":"C","unix_timestamp":1696570200,"question_images":[],"answers_community":["C (78%)","B (22%)"],"exam_id":40,"answer_images":[],"question_id":110,"topic":"2","url":"https://www.examtopics.com/discussions/microsoft/view/122636-exam-ai-102-topic-2-question-33-discussion/","timestamp":"2023-10-06 07:30:00","isMC":true,"answer_ET":"C","answer_description":"","choices":{"A":"Upload File1.avi to an Azure Storage queue.","C":"Upload File1.avi to Microsoft OneDrive.","D":"Upload File1.avi to the www.youtube.com webpage.","B":"Upload File1.avi to the Azure Video Indexer website."},"question_text":"You have a 20-GB video file named File1.avi that is stored on a local drive.\n\nYou need to index File1.avi by using the Azure Video Indexer website.\n\nWhat should you do first?"}],"exam":{"isBeta":false,"isImplemented":true,"lastUpdated":"12 Apr 2025","name":"AI-102","isMCOnly":false,"id":40,"provider":"Microsoft","numberOfQuestions":329},"currentPage":22},"__N_SSP":true}