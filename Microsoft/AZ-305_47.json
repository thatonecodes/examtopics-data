{"pageProps":{"questions":[{"id":"XQVDkVuoWjXHBhelTYJ6","url":"https://www.examtopics.com/discussions/microsoft/view/80703-exam-az-305-topic-4-question-63-discussion/","answer_ET":"CE","question_images":[],"isMC":true,"exam_id":54,"answer_images":[],"topic":"4","question_text":"You have an on-premises application named App1 that uses an Oracle database.\nYou plan to use Azure Databricks to transform and load data from App1 to an Azure Synapse Analytics instance.\nYou need to ensure that the App1 data is available to Databricks.\nWhich two Azure services should you include in the solution? Each correct answer presents part of the solution.\nNOTE: Each correct selection is worth one point.","answers_community":["CE (88%)","12%"],"question_id":231,"discussion":[{"content":"Selected Answer: CE\nThe correct answer should be C and E\nADF moves data from on-prem Oracle to Data Lake storage, which makes data ready for DataBrick\nhttps://docs.microsoft.com/en-us/azure/data-factory/load-azure-data-lake-storage-gen2\nDataBricks \"ETL\" data to Synapse:\nhttps://docs.microsoft.com/en-us/azure/databricks/scenarios/databricks-extract-load-sql-data-warehouse","comments":[{"comment_id":"681578","poster":"mufflon","content":"yes, this is the only answer if they dont ask for how to get the data to azure","timestamp":"1664361180.0","upvote_count":"3"},{"timestamp":"1676391960.0","poster":"np2021","content":"I thought this also at first, but the first line of the question indicates on-premises Oracle data. So i think the question is suggesting \"getting the data to Azure/into a lake so DataBricks can process it\". In which case this is Import/DataFactory requirement.\nTHis is very difficult call to make, i think when sitting the test just assume you will get 1/2 points on this one.","comment_id":"808571","upvote_count":"4","comments":[{"upvote_count":"1","content":"Indeed, but Data Factory has a lot of connectors, including one that makes it possible to extract data from an Oracle DB :) So you can simply set up a data pipeline is Data Factory that extracts the data from Oracle, and saves it to ADLS - therefore I believe CE is right.\n\nMore info here: https://learn.microsoft.com/en-us/azure/data-factory/connector-oracle?tabs=data-factory","comments":[{"timestamp":"1725954600.0","poster":"Arthur_zw","upvote_count":"1","comment_id":"1281419","content":"You install the Self-Hosted Integration Runtime to connect ADF to the Oracle DB then set up a linked service then data pipelines. So I believe C&E"}],"comment_id":"1165263","timestamp":"1709522820.0","poster":"Fidel_104"}]}],"comment_id":"665702","upvote_count":"39","poster":"Snownoodles","timestamp":"1662849600.0"},{"comment_id":"746567","poster":"d365ppp","comments":[{"upvote_count":"8","content":"Azure lake storage is a cloud \"service\" offered by MS","poster":"pkkalra","comment_id":"812426","timestamp":"1676670660.0"}],"upvote_count":"8","content":"Selected Answer: BE\nTwo Services not storage","timestamp":"1671143580.0"},{"upvote_count":"2","timestamp":"1731513840.0","content":"Selected Answer: CE\nC & E are correct","poster":"[Removed]","comment_id":"1311428"},{"upvote_count":"3","timestamp":"1723200360.0","poster":"Len83","content":"This question appeared in the exam, August 2024. I gave this same answers listed here. I scored 870","comment_id":"1262884"},{"content":"Selected Answer: CE\nTo ensure that the data from App1 is available to Azure Databricks, you should include the following Azure services in your solution:\n1. Azure Data Factory (E): Azure Data Factory can be used to create a data pipeline for ETL (Extract, Transform, Load) processes, which can move your data from the on-premises Oracle database to Azure¹⁴.\n2. Azure Data Lake Storage (C): Azure Data Lake Storage can act as the intermediary storage area where the transformed data can be placed. Azure Databricks is tightly integrated with Azure Data Lake Storage, making it an ideal choice for storing your data.\nPlease note that while Azure Data Box Gateway and Azure Data Box Edge are used for offline transfer of large amounts of data, and Azure Import/Export service is used for importing large amounts of data into Azure, they might not be necessary if your data can be transferred online or isn't extremely large.","upvote_count":"3","timestamp":"1701274200.0","comment_id":"1083634","poster":"Paul_white"},{"poster":"FurnishedFlapjack","comment_id":"988369","comments":[{"timestamp":"1695061320.0","upvote_count":"2","content":"Yes - you can connect ADF to pretty much anything for ETL/ELT","poster":"AdventureChick","comment_id":"1010810"}],"content":"Selected Answer: CE\nFrom this link it looks like you can directly link to an Oracle DB from ADF, doesn't look like import/export would be required. I'm going with CE\nhttps://learn.microsoft.com/en-us/azure/data-factory/connector-oracle?tabs=data-factory","upvote_count":"2","timestamp":"1692798360.0"},{"timestamp":"1692295320.0","upvote_count":"1","content":"Selected Answer: CE\nADF - to extract and load data to Data Lake\nData Lake - as it's the only storage generally supported by Databricks","comment_id":"983897","poster":"sawanti"},{"content":"Selected Answer: CE\nC. Azure Data Lake Storage\nE. Azure Data Factory\n\nAzure Data Lake Storage is a secure, scalable and reliable data lake that allows you to perform analytics on large amounts of data. It's a great choice for storing large volumes of data, like what App1 might produce.\n\nAzure Data Factory is a cloud-based data integration service that allows you to create data-driven workflows for moving and transforming data at scale. In this case, it can be used to create a pipeline to move the data from your on-premises Oracle database to Azure Data Lake Storage, making it available for further processing with Azure Databricks. Azure Data Factory has built-in support for a wide range of data sources, including Oracle.\n\nAfter the data is stored in Azure Data Lake Storage, you can use Azure Databricks to transform the data and load it into the Azure Synapse Analytics instance.","comment_id":"952334","upvote_count":"6","poster":"NotMeAnyWay","timestamp":"1689422340.0"},{"comment_id":"901501","poster":"wpestan","timestamp":"1684444380.0","comments":[{"content":"Databricks can only read data from Data Lake (and some external sources, but that's not the case). Where do you have Data Lake in your solution??? CE is correct (ADF to Extract data from on-premise system and load to Data Lake, and then Data Lake to be mounted to Databricks)","upvote_count":"1","comment_id":"983893","timestamp":"1692295260.0","poster":"sawanti"}],"upvote_count":"1","content":"Selected Answer: BE\nB and E, teacher correct in question in Azure Course"},{"comment_id":"901391","poster":"Tr619899","timestamp":"1684428720.0","content":"Azure Data Lake Storage (Option C): Azure Data Lake Storage provides a scalable and secure repository for storing large amounts of data. You can ingest data from App1 into Azure Data Lake Storage, and then make it available for processing in Azure Databricks.\n\nAzure Data Factory (Option E): Azure Data Factory is a fully managed data integration service that allows you to orchestrate and automate data movement and data transformation workflows. You can use Azure Data Factory to extract data from App1, transform it using Azure Databricks, and then load it into Azure Synapse Analytics.","upvote_count":"1"},{"content":"Selected Answer: CE\nIn AZ-304 it was ADL and ADF meaning CE\nhttps://www.examtopics.com/discussions/microsoft/view/51579-exam-az-304-topic-3-question-20-discussion/","comment_id":"882718","poster":"yonie","timestamp":"1682604660.0","upvote_count":"7"},{"upvote_count":"2","poster":"rex303","content":"Selected Answer: CE\nThis scenario should be consistent with using C and E. \n\nAzure Data Factory is a recommended solution for migrating Oracle data. \nAzure Data Lake storage can then hold the data in a useable format for the chosen solution: Azure Databricks.\n\nAzure Data Box Gateway does not natively support Oracle. Azure Data Box Edge is an appliance not a service. And the azure import/export service is for one-shot migrations not really suitable for this scenario.","timestamp":"1680711780.0","comment_id":"862284"},{"timestamp":"1677175200.0","poster":"cp2323","upvote_count":"2","content":"Selected Answer: CE\nCE should be the answer, why somone want to use Azure Import/Export service!","comment_id":"819518"},{"upvote_count":"5","poster":"zellck","comments":[{"timestamp":"1676792400.0","comment_id":"813830","poster":"zellck","upvote_count":"2","content":"https://learn.microsoft.com/en-us/azure/synapse-analytics/migration-guides/oracle/7-beyond-data-warehouse-migration\nA key reason to migrate your existing data warehouse to Azure Synapse Analytics is to utilize a globally secure, scalable, low-cost, cloud-native, pay-as-you-use analytical database. With Azure Synapse, you can integrate your migrated data warehouse with the complete Microsoft Azure analytical ecosystem to take advantage of other Microsoft technologies and modernize your migrated data warehouse. Those technologies include:\n- Azure Data Lake Storage for cost effective data ingestion, staging, cleansing, and transformation. Data Lake Storage can free up the data warehouse capacity occupied by fast-growing staging tables.\n- Azure Data Factory for collaborative IT and self-service data integration with connectors to cloud and on-premises data sources and streaming data."}],"comment_id":"813827","content":"Selected Answer: CE\nCE is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction#designed-for-enterprise-big-data-analytics\nData Lake Storage Gen2 makes Azure Storage the foundation for building enterprise data lakes on Azure. Designed from the start to service multiple petabytes of information while sustaining hundreds of gigabits of throughput, Data Lake Storage Gen2 allows you to easily manage massive amounts of data.\n\nhttps://learn.microsoft.com/en-us/azure/data-factory/introduction\nBig data requires a service that can orchestrate and operationalize processes to refine these enormous stores of raw data into actionable business insights. Azure Data Factory is a managed cloud service that's built for these complex hybrid extract-transform-load (ETL), extract-load-transform (ELT), and data integration projects.","timestamp":"1676792220.0"},{"comment_id":"813565","timestamp":"1676762580.0","content":"Selected Answer: BE\nI remember answering another question Topic 1 Q26 https://www.examtopics.com/exams/microsoft/az-305/view/6/\nThe solution suggests import/export might be good option to ingest on-premise data continuously upstream to processing the data with ADF pipeline.","poster":"Rams_84zO6n","upvote_count":"1"},{"timestamp":"1676762100.0","poster":"Rams_84zO6n","comment_id":"813560","content":"Selected Answer: BE\non-premise data => Azure Synapse Link for dataverse (import/export) => Data Factory (data pipeline) => data bricks","upvote_count":"1"},{"timestamp":"1676391780.0","upvote_count":"1","content":"Selected Answer: CE\nIs Correct\nC. Azure Data Lake Storage \nE. Azure Data Factory","comment_id":"808569","poster":"Eusouzati"},{"timestamp":"1676389380.0","content":"Selected Answer: CE\nAzure Data Lake Storage can be used to store the transformed data from App1 to be loaded into Azure Synapse Analytics instance.\nAzure Data Factory can be used to extract the data from the Oracle database and load it into Azure Data Lake Storage. The transformed data can then be loaded into Azure Synapse Analytics using Databricks","comment_id":"808533","poster":"VBK8579","upvote_count":"1"},{"upvote_count":"1","content":"I guess the question is what is MSFT asking with this question? Are they asking what services you would use to actually get the data to an Azure storage account? Or are they asking for a complete package of what you would use to get it to an Azure storage account and what kind of storage account to use? Very tricky and I don't have a good feel for it. \n\nObviously, if the former, then it will be Import/Export & ADF. \nIf the latter then technically you could use either import/export or ADF for the mechanism to get the data up and then Data lake as the storage type. \n\nAs a side note there is a very similar question to this earlier in the dump where import/export is the consensus.","poster":"SvenHorsheim","comment_id":"807541","timestamp":"1676302140.0"},{"timestamp":"1675270620.0","poster":"OPT_001122","comment_id":"795337","upvote_count":"1","content":"Selected Answer: CE\nC. Azure Data Lake Storage\nE. ADF"},{"comment_id":"746566","content":"The question is two services.So, definitely imp/exp & ADF","timestamp":"1671143520.0","poster":"d365ppp","upvote_count":"2"},{"timestamp":"1663897380.0","upvote_count":"3","content":"To be honest, databricks can directly inject data from oracle.","comment_id":"676685","poster":"Xinx"},{"comment_id":"667543","upvote_count":"6","timestamp":"1663028400.0","content":"Selected Answer: CE\nC & E.","poster":"kay000001"},{"poster":"ROLLINGROCKS","content":"Id say Data Factory and Data lake Storage.\nFirst dump data in the data lake then ingest with data factory onto Synapse.\nClassic ETL stuff.","comment_id":"664612","upvote_count":"1","timestamp":"1662729960.0"},{"content":"I'm confused why import/export service is required when an IR should be used in conjunction with the ADF.","comment_id":"661568","poster":"icklenutter","timestamp":"1662489120.0","upvote_count":"1"}],"timestamp":"2022-09-06 20:32:00","answer_description":"","answer":"CE","choices":{"D":"Azure Data Box Edge","A":"Azure Data Box Gateway","E":"Azure Data Factory","B":"Azure Import/Export service","C":"Azure Data Lake Storage"},"unix_timestamp":1662489120},{"id":"JlvRE7XQBjr4YgYUOTHf","exam_id":54,"unix_timestamp":1662856980,"answers_community":[],"discussion":[{"timestamp":"1663552440.0","comment_id":"672846","content":"I agree with the given answer. \n- Low Priority VMs\n- batch service and dedicated VMs\n\nLow priority VMs are being phased out by Spot VMs, but it does exist.\nhttps://learn.microsoft.com/en-us/azure/batch/batch-spot-vms\n\nI feel like the mention of Hybrid Benefit is a red herring here. Without knowing your linux variant, that may not even factor into the decision. You can enable it on RHEL or SUSE on a VM.\nI'm not entirely clear how licensing factors into batch, but the functionality of the batch pool is the most important thing here.","comments":[{"comments":[{"poster":"Snownoodles","content":"Low Priority VM can only be supported in Batch Service\nSpot VMs can only be supported in user subscription","timestamp":"1666579860.0","upvote_count":"5","comment_id":"702642"}],"poster":"Nicklaas","timestamp":"1664731200.0","upvote_count":"1","comment_id":"684968","content":"Good point about the licensing, also uncertain how it factors (if at all)."}],"poster":"jellybiscuit","upvote_count":"33"},{"upvote_count":"9","poster":"Snownoodles","timestamp":"1662856980.0","comments":[{"comments":[{"comment_id":"753914","upvote_count":"1","content":"There is Hybrid benefits for Linux :\nhttps://learn.microsoft.com/en-us/azure/virtual-machines/linux/azure-hybrid-benefit-byos-linux\nLow priority virtual machines is an Azure Batch concept (Batch computing at a fraction of the price). Low priority virtual machines get allocated from the surplus of compute capacity in each region and are offered at a substantially reduced price. This comes with the understanding that there may not be capacity available to satisfy your request. In some rare cases, Azure may have to take some of this capacity back to satisfy other compute allocation requests.\n\nLow priority virtual machines are well suited for batch activities like media processing / encoding\n\nIf you are looking at deploying an A-Series virtual machine in Azure then there are two tiers to choose from:\n\nBasic\nStandard","timestamp":"1671776580.0","poster":"Villa76"},{"poster":"Snownoodles","timestamp":"1666579740.0","comment_id":"702638","upvote_count":"2","content":"\"Azure Hybrid Benefit now provides software updates and integrated support directly from Azure infrastructure for Red Hat Enterprise Linux (RHEL) and SUSE Linux Enterprise Server (SLES) virtual machines\"\nhttps://learn.microsoft.com/en-us/azure/virtual-machines/linux/azure-hybrid-benefit-byos-linux"}],"upvote_count":"2","timestamp":"1666526160.0","poster":"Galron","comment_id":"702132","content":"But there is not Hybrid Benefit as OS is Linux and needs to be Windows OS."}],"content":"The answer should be:\n\"User Subscription and Dedicated virtual machines\" \n\"User Subscription and Dedicated virtual machines\"\n\n1. To use \"Azure Hybrid Benefit\", the pool allocation mode has to be \"User Subscription\"\n2. \"User Subscription\" doesn't support low-priority VMs(Batch service does)","comment_id":"665736"},{"comment_id":"1311429","content":"CORRECT","upvote_count":"1","poster":"[Removed]","timestamp":"1731514080.0"},{"poster":"Teerawee","comment_id":"1282665","content":"User subscription and low-priority virtual machines \nBatch service and dedicated virtual machines","timestamp":"1726148880.0","upvote_count":"1"},{"upvote_count":"2","timestamp":"1702320060.0","content":"https://learn.microsoft.com/en-us/azure/batch/batch-spot-vms\n\nWith user subscription pool allocation pool will always have either dedicated or SPOT VMs but not low priority VMs. With Batch managed pool allocation, pool may have either dedicated or low-priority VMs. So, \"user subscription & low-priority VM\" option is ruled out for both answers. 1st job needs to be run by \"specific\" department - development for short running tasks so \" User Subscription & dedicated VMs\" can meet that requirement. For 2nd job opting for \"batch service & dedicated VMs\" would successfully complete long-running Message Passing Interface (MPI) applications for a production environment in a timely fashion.","poster":"BShelat","comment_id":"1093750"},{"content":"Got this on Aug 5th, 2023.","comment_id":"973492","poster":"InvalidNickname","upvote_count":"4","timestamp":"1691290740.0"},{"upvote_count":"3","poster":"NotMeAnyWay","content":"For the first job, which consists of short-running tasks for a development environment, we can indeed use \"User subscription and low-priority virtual machines\". This choice allows us to take advantage of the cost benefits of low-priority VMs, as these tasks are short-running and the job completion time is flexible.\n\nFor the second job, which consists of long-running MPI applications for a production environment, we should indeed use \"Batch service and dedicated virtual machines\". This choice ensures that the VMs are not preempted, which is important for long-running applications and a production environment where timely job completion is required.","timestamp":"1688401260.0","comment_id":"942040"},{"content":"Short-running tasks for development environment:\n\n Pool type: On-demand\n Node type: Low-priority VMs\n Explanation: Since the job type consists of short-running tasks for a development environment, it's recommended to use On-demand pool type and Low-priority VMs as they are the most cost-effective option.\n\nLong-running MPI applications for production environment:\n\n Pool type: Batch service\n Node type: Dedicated VMs\n Explanation: Since the job type consists of long-running MPI applications for a production environment, it's recommended to use Batch service pool type and Dedicated VMs as they provide better performance and reliability. Using Azure Hybrid Benefit will help to minimize compute charges.","timestamp":"1683023700.0","comment_id":"887224","upvote_count":"4","poster":"lombri"},{"poster":"zellck","comments":[{"timestamp":"1677630780.0","upvote_count":"8","poster":"zellck","content":"Got this in Feb 2023 exam.","comment_id":"825414"},{"timestamp":"1677422880.0","content":"https://learn.microsoft.com/en-us/azure/batch/best-practices#pool-configuration-and-naming\nPool allocation mode: When creating a Batch account, you can choose between two pool allocation modes: Batch service or user subscription. For most cases, you should use the default Batch service mode, in which pools are allocated behind the scenes in Batch-managed subscriptions. In the alternative user subscription mode, Batch VMs and other resources are created directly in your subscription when a pool is created. User subscription accounts are primarily used to enable a small but important subset of scenarios.","upvote_count":"8","comment_id":"822549","poster":"zellck"}],"comment_id":"822547","content":"1. User subscription and low-priority virtual machines\n2. Batch service and dedicate virtual machines\n\nhttps://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-low-priority-batch?tabs=cli\nAzure Batch Deployments supports low priority VMs to reduce the cost of batch inference workloads. Low priority VMs enable a large amount of compute power to be used for a low cost. Low priority VMs take advantage of surplus capacity in Azure. When you specify low priority VMs in your pools, Azure can use this surplus, when available.\n\nThe tradeoff for using them is that those VMs may not always be available to be allocated, or may be preempted at any time, depending on available capacity. For this reason, they are most suitable for batch and asynchronous processing workloads where the job completion time is flexible and the work is distributed across many VMs.\n\nLow priority VMs are offered at a significantly reduced price compared with dedicated VMs.","upvote_count":"6","timestamp":"1677422700.0"},{"content":"For the first job type: User subscription and low-priority virtual machines\nFor the second job type: Batch service and dedicated virtual machines","poster":"VBK8579","timestamp":"1675661160.0","upvote_count":"4","comment_id":"799442"},{"poster":"RandomNickname","upvote_count":"1","content":"Given answer looks correct to me.\nFirst questions fairly straight forward\n\nSecond see article;\nhttps://learn.microsoft.com/en-us/azure/batch/batch-mpi","comment_id":"796012","timestamp":"1675339500.0"},{"upvote_count":"1","comment_id":"782892","poster":"LeeVee","content":"The key here states that \"The solution must minimize compute charges and leverage Azure Hybrid Benefit **whenever** possible. So Job1= low prio VMs, Job2 Batchw/dedicatedVMs. It's pointless to have dedicated VMs for a short-run job1.","timestamp":"1674261480.0"},{"content":"Appear in exam.\nAnswer is correct","comment_id":"772370","poster":"Malik007","timestamp":"1673431980.0","upvote_count":"4"},{"poster":"rocroberto","timestamp":"1671115440.0","comment_id":"746204","upvote_count":"1","content":"Probably because it is talking about dev rather prod, low priority/spot instances are not a bad idea ?"},{"upvote_count":"1","timestamp":"1670054220.0","comment_id":"734274","content":"I guess - the question is not complete, that's why - the answers are not logical:\n\nThe first job type will consist of short-running tasks for a development environment:\nbatch service and low-priority virtual machines\nYou don't need reserved instances and can go for this option.\n \nthe second productive job is a long runner and needs relatively much compute power\nTherefore you need user sub dedicated prio virtual machines:\nThis option gives you the ability to reserve instances with relatively strong compute power.","poster":"in_da_cloud"},{"poster":"randomaccount123","timestamp":"1667504040.0","comment_id":"710757","upvote_count":"2","content":"\"User Subscription and Dedicated virtual machines\"\n\"User Subscription and Dedicated virtual machines\""},{"content":"Answer should be -\n\nFirst Job:\nUser Subscription and dedicated virtual machines.\n\nSecond Job:\nBatch service and dedicated virtual machines.\n\nhttps://docs.microsoft.com/en-us/azure/batch/batch-quota-limit","upvote_count":"6","poster":"kay000001","timestamp":"1663029060.0","comment_id":"667548"}],"isMC":false,"timestamp":"2022-09-11 02:43:00","url":"https://www.examtopics.com/discussions/microsoft/view/81601-exam-az-305-topic-4-question-64-discussion/","topic":"4","question_images":["https://www.examtopics.com/assets/media/exam-media/04224/0025500001.jpg"],"answer_ET":"","answer_images":["https://www.examtopics.com/assets/media/exam-media/04224/0025600001.jpg"],"question_id":232,"answer":"","question_text":"HOTSPOT -\nYou are designing a cost-optimized solution that uses Azure Batch to run two types of jobs on Linux nodes. The first job type will consist of short-running tasks for a development environment. The second job type will consist of long-running Message Passing Interface (MPI) applications for a production environment that requires timely job completion.\nYou need to recommend the pool type and node type for each job type. The solution must minimize compute charges and leverage Azure Hybrid Benefit whenever possible.\nWhat should you recommend? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","answer_description":"Box 1: User subscription and low-priority virtual machines\nThe first job type will consist of short-running tasks for a development environment.\nAmong the many ways to purchase and consume Azure resources are Azure low priority VMs and Spot VMs. These virtual machines are compute instances allocated from spare capacity, offered at a highly discounted rate compared to ג€on demandג€ VMs. This means they can be a great option for cost savings ג€\" for the right workloads\nBox 2: Batch service and dedicate virtual machines\nThe second job type will consist of long-running Message Passing Interface (MPI) applications for a production environment that requires timely job completion.\nAzure Batch Service is a cloud based job scheduling and compute management platform that enables running large-scale parallel and high performance computing applications efficiently in the cloud. Azure Batch Service provides job scheduling and in automatically scaling and managing virtual machines running those jobs.\nReference:\nhttps://www.parkmycloud.com/blog/azure-low-priority-vms\nhttps://azure.microsoft.com/en-us/pricing/details/batch/"},{"id":"yjXYTmYiwqcHgj6dkjHA","unix_timestamp":1662177780,"timestamp":"2022-09-03 06:03:00","exam_id":54,"question_images":[],"topic":"4","answer_ET":"C","answers_community":["C (96%)","4%"],"url":"https://www.examtopics.com/discussions/microsoft/view/79671-exam-az-305-topic-4-question-65-discussion/","choices":{"A":"Azure Notification Hubs","C":"Azure Queue Storage","D":"Azure Data Lake","B":"Azure Service Fabric"},"question_text":"You are developing a sales application that will contain several Azure cloud services and handle different components of a transaction. Different cloud services will process customer orders, billing, payment, inventory, and shipping.\nYou need to recommend a solution to enable the cloud services to asynchronously communicate transaction information by using XML messages.\nWhat should you include in the recommendation?","answer":"C","answer_description":"","isMC":true,"discussion":[{"upvote_count":"50","poster":"yonie","comment_id":"882780","content":"Selected Answer: C\nThere are 15 variations of this question, each offerings different answers. In all 15 questions, there is always only one out of two answers: either its Azure Queue Storage or its Azure Service Bus.\nI havent seen a question where both of them are a possibility.","timestamp":"1682609880.0"},{"timestamp":"1662177780.0","upvote_count":"10","comments":[{"comment_id":"691023","timestamp":"1665398640.0","upvote_count":"1","poster":"Teab91","content":"Not so sure about that"}],"poster":"shubhary25","content":"Selected Answer: C\nAzure Queue Storage is the correct answer","comment_id":"658049"},{"content":"Selected Answer: C\nC is correct\n\nAzure Queue Storage or Azure Service Bus","comment_id":"1311431","timestamp":"1731514200.0","poster":"[Removed]","upvote_count":"1"},{"upvote_count":"1","poster":"23169fd","timestamp":"1719344100.0","comment_id":"1237071","content":"Selected Answer: C\nAzure Queue Storage is designed for large-scale, asynchronous messaging between application components. It allows you to store large numbers of messages that can be accessed from anywhere via authenticated calls using HTTP or HTTPS.\nIt supports decoupling different components of a transaction, enabling them to communicate asynchronously by placing messages in a queue.\nThis makes it suitable for handling various transaction components like customer orders, billing, payment, inventory, and shipping, where each component can process messages at its own pace."},{"timestamp":"1708685100.0","content":"The answer is technically correct, but in the real world, it depends. \nI would not advise splitting your transaction in multiple messages. \nBetter to use a Blob in that case.","comment_id":"1157058","poster":"xRiot007","upvote_count":"2"},{"upvote_count":"2","poster":"NotMeAnyWay","content":"Selected Answer: C\nThe appropriate service for this requirement is Azure Queue Storage. Azure Queue Storage is a service for storing large numbers of messages that can be accessed from anywhere in the world via authenticated calls using HTTP or HTTPS. It offers asynchronous message queueing for communication between application components, whether they are running in the cloud, on the desktop, on-premises, or on mobile devices.\n\nSo, the answer is:\nC. Azure Queue Storage","timestamp":"1688401380.0","comment_id":"942042"},{"poster":"lombri","upvote_count":"4","comment_id":"887232","content":"Selected Answer: C\nAzure Queue Storage is a messaging service that allows decoupling of components in an application by providing a reliable way to pass messages between them asynchronously. It can handle messages in a first-in-first-out (FIFO) order and can scale to handle millions of messages per second.\n\nBy using Azure Queue Storage, each component of the transaction process can push messages to the queue with relevant transaction information in XML format, which can be retrieved by the receiving component. This allows for loose coupling between the components, as they do not need to know about each other to communicate.\n\nAzure Notification Hubs and Azure Service Fabric are not messaging services but rather services for pushing notifications and deploying microservices, respectively. Azure Data Lake is a storage service for big data processing and analytics and does not provide messaging capabilities.","timestamp":"1683023940.0"},{"poster":"zellck","content":"Same as Question 83.\nhttps://www.examtopics.com/discussions/microsoft/view/99750-exam-az-305-topic-4-question-83-discussion","comment_id":"818057","upvote_count":"2","timestamp":"1677084000.0"},{"timestamp":"1676530500.0","poster":"cp2323","upvote_count":"1","content":"Selected Answer: B\nASB. this is repeated question","comment_id":"810335","comments":[{"upvote_count":"2","timestamp":"1682338380.0","content":"There is no ASB in answers. Think!","comment_id":"879302","poster":"Bigbluee"}]},{"poster":"moshos","comment_id":"800368","content":"Selected Answer: C\nCorrect Answer: C","upvote_count":"1","timestamp":"1675726920.0"},{"upvote_count":"1","comment_id":"799444","timestamp":"1675661220.0","content":"Selected Answer: C\nC. Azure Queue Storage","poster":"VBK8579"},{"poster":"OPT_001122","content":"Selected Answer: C\nC. Azure Queue Storage","comment_id":"795340","upvote_count":"1","timestamp":"1675270920.0"},{"poster":"VBK8579","content":"C. Azure Queue Storage","upvote_count":"1","timestamp":"1674601560.0","comment_id":"787060"},{"comment_id":"782894","poster":"LeeVee","timestamp":"1674261660.0","content":"In absence of ASB in the choose, next solution to be look at is Azure Storage Queue. In my opinion though, ASB is more durable than a Storage queue.","upvote_count":"3","comments":[{"timestamp":"1708685160.0","comment_id":"1157059","content":"More durable, no, but it provides a bigger message size limit, which might benefit some businesses.","upvote_count":"1","poster":"xRiot007"}]},{"timestamp":"1674110160.0","content":"Selected Answer: C\nI'm going to have to go with C on this one.","upvote_count":"1","comment_id":"780792","poster":"janvandermerwer"},{"poster":"yeanlingmedal71","comment_id":"779613","content":"Selected Answer: B\nAsynchronous messaging options.\nThere are different types of messages and the entities that participate in a messaging infrastructure. Based on the requirements of each message type, Microsoft recommends Azure messaging services. The options include Azure Service Bus, Event Grid, and Event Hubs.\nAzure Service Bus queues are well suited for transferring commands from producers to consumers.\nData is transferred between different applications and services using messages. A message is a container decorated with metadata, and contains data. The data can be any kind of information, including structured data encoded with the common formats such as the following ones: JSON, XML, Apache Avro, Plain Text.\nReference:\nhttps://docs.microsoft.com/en-us/azure/architecture/guide/technology-choices/messaging\n https://learn.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messaging-overview","timestamp":"1674018060.0","upvote_count":"2","comments":[{"upvote_count":"2","timestamp":"1674119220.0","poster":"Tash95","content":"Azure Service Fabric is a distributed systems platform that makes it easy to package, deploy, and manage scalable and reliable microservices and containers. Azure Service Fabric enables you to create Service Fabric clusters on premises or in other clouds. Azure Service Fabric is low-latency and scales up to thousands of machines.\n\nSo nothing to do with messaging","comment_id":"780939"}]},{"upvote_count":"5","comment_id":"765659","content":"Appeared 2023/01/03 in the exam","poster":"honzar","timestamp":"1672837680.0"},{"poster":"gg112022","comments":[{"content":"how can azure queue storage be an answer? as AQS doesnt support First in first out and doesnt guarantee non duplication either.","poster":"lvz","timestamp":"1684961520.0","comment_id":"906152","upvote_count":"1"}],"upvote_count":"9","content":"Topic 4 and Question 13 choices are different and the answer there is \"Azure Service Bus\". For this question \"Azure Queue Storage\" is the answer.","comment_id":"700721","timestamp":"1666346280.0"}],"answer_images":[],"question_id":233},{"id":"h0erkimSnPXy5oLKeHfy","isMC":true,"answer_ET":"C","exam_id":54,"question_images":[],"timestamp":"2022-08-31 13:14:00","answer_description":"","discussion":[{"poster":"lolo13698","comments":[{"upvote_count":"3","comment_id":"713142","comments":[{"content":"As far as I see only option D is different, the rest looks identical","upvote_count":"2","comments":[{"comment_id":"766457","poster":"ServerBrain","content":"Therefore, it's not duplicate..","timestamp":"1672911360.0","upvote_count":"5"}],"comment_id":"746968","poster":"Guest","timestamp":"1671180000.0"}],"poster":"meinekarte","timestamp":"1667835360.0","content":"The answers are different, read again"},{"content":"Monello","timestamp":"1668008760.0","comment_id":"714698","upvote_count":"2","poster":"luke996"}],"timestamp":"1665648420.0","content":"Seriously, duplicate question again. What is the contributor access advantage exactly ?!","comment_id":"693729","upvote_count":"15"},{"poster":"[Removed]","timestamp":"1731514260.0","content":"Selected Answer: C\nC is correct","upvote_count":"2","comment_id":"1311432"},{"poster":"jojorabbit2021","upvote_count":"1","comments":[{"upvote_count":"1","comment_id":"1157060","content":"The keyword is to go to the Azure site and learn the basics of what a queue and a service bus are. Then you won't have to memorize all this silly stuff.","poster":"xRiot007","timestamp":"1708685280.0"}],"comment_id":"983090","content":"azure service bus is different than azure service fabric .... If you had memorized blindly you'd choose service fabric but answer is queue storage. But then you'll memorize blindly again that the keyword is 'bus' otherwise 'storage queue' and problem solved!","timestamp":"1692227160.0"},{"timestamp":"1683024180.0","comment_id":"887237","poster":"lombri","content":"Selected Answer: C\nAnswer: Azure Queue Storage\n\nReasons:\n- Azure Queue Storage is a messaging solution that enables asynchronous communication between different components of a distributed system.\n- It supports message-based communication using XML and other formats.\n- It is a cost-effective solution for managing message queues, and it scales automatically based on demand.","upvote_count":"3"},{"poster":"zellck","timestamp":"1677084000.0","comment_id":"818055","upvote_count":"1","content":"Same as Question 83.\nhttps://www.examtopics.com/discussions/microsoft/view/99750-exam-az-305-topic-4-question-83-discussion"},{"comment_id":"818052","upvote_count":"1","timestamp":"1677083940.0","poster":"zellck","content":"Selected Answer: C\nC is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/storage/queues/storage-queues-introduction\nAzure Queue Storage is a service for storing large numbers of messages. You access messages from anywhere in the world via authenticated calls using HTTP or HTTPS. A queue message can be up to 64 KB in size. A queue may contain millions of messages, up to the total capacity limit of a storage account. Queues are commonly used to create a backlog of work to process asynchronously."},{"timestamp":"1676459700.0","poster":"Eusouzati","upvote_count":"1","comment_id":"809409","content":"Selected Answer: C\nC. Azure Queue Storage"},{"timestamp":"1675661280.0","upvote_count":"1","content":"Selected Answer: C\nC. Azure Queue Storage","poster":"VBK8579","comment_id":"799445"},{"upvote_count":"1","poster":"OPT_001122","content":"Selected Answer: C\nC. Azure Queue Storage","comment_id":"794443","timestamp":"1675185960.0"},{"upvote_count":"1","poster":"Zeppoonstream","content":"Selected Answer: C\nC. Azure Queue Storage.\n\nAzure Queue Storage can be used to asynchronously communicate transaction information between cloud services by using XML messages. Azure Queue Storage is a fully managed message queue that can store and retrieve large numbers of messages. Messages can be stored in a queue for a specified period of time and can be retrieved by multiple consumers. This allows different cloud services to process customer orders, billing, payment, inventory, and shipping in parallel and asynchronously, without having to wait for a response from other services.","comment_id":"786260","timestamp":"1674545520.0"},{"comment_id":"785139","timestamp":"1674463260.0","content":"I want a refund or a convincing explaination.","poster":"tfulanchan","upvote_count":"1"},{"poster":"bacms","timestamp":"1674377040.0","content":"Selected Answer: C\nDuplicated with #65, should be Azure Queue Storage","upvote_count":"1","comment_id":"784084"},{"comment_id":"779614","poster":"yeanlingmedal71","timestamp":"1674018180.0","upvote_count":"1","content":"Selected Answer: B\nAsynchronous messaging options.\nThere are different types of messages and the entities that participate in a messaging infrastructure. Based on the requirements of each message type, Microsoft recommends Azure messaging services. The options include Azure Service Bus, Event Grid, and Event Hubs.\nAzure Service Bus queues are well suited for transferring commands from producers to consumers.\nData is transferred between different applications and services using messages. A message is a container decorated with metadata, and contains data. The data can be any kind of information, including structured data encoded with the common formats such as the following ones: JSON, XML, Apache Avro, Plain Text.\nReference:\nhttps://docs.microsoft.com/en-us/azure/architecture/guide/technology-choices/messaging\n https://learn.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messaging-overview","comments":[{"poster":"FabrityDev","timestamp":"1674649200.0","comment_id":"787590","upvote_count":"2","content":"Option B is Service Fabric, not Service Bus"}]},{"timestamp":"1673267700.0","poster":"70mach1","content":"The question is worded the same and the answer is the same. Just because you changed one answer does not make then different questions. Really puts the \"185 questions\" in doubt.","comment_id":"770362","upvote_count":"3"}],"unix_timestamp":1661944440,"topic":"4","answer":"C","choices":{"A":"Azure Notification Hubs","C":"Azure Queue Storage","D":"Azure Application Gateway","B":"Azure Service Fabric"},"answers_community":["C (92%)","8%"],"question_id":234,"answer_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/78681-exam-az-305-topic-4-question-66-discussion/","question_text":"You are developing a sales application that will contain several Azure cloud services and handle different components of a transaction. Different cloud services will process customer orders, billing, payment, inventory, and shipping.\nYou need to recommend a solution to enable the cloud services to asynchronously communicate transaction information by using XML messages.\nWhat should you include in the recommendation?"},{"id":"SCbxYssdLIubOgQOmeEM","answer_description":"","unix_timestamp":1672929720,"discussion":[{"poster":"mVic","timestamp":"1673336580.0","upvote_count":"19","comment_id":"771163","content":"Selected Answer: B\nPremium should be the answer.\nWhenever zone-redundancy (availability within the same region) is required you can only choose:\n-General Purpose\n-Premium\n-Business Critical\n\nSee:\nhttps://learn.microsoft.com/en-GB/azure/azure-sql/database/high-availability-sla?view=azuresql&tabs=azure-powershell"},{"timestamp":"1672929900.0","poster":"ServerBrain","upvote_count":"6","comment_id":"766726","content":"Actually About 23 questions added today..","comments":[{"content":"Some look like they are duplicates","poster":"[Removed]","upvote_count":"4","comment_id":"767016","timestamp":"1672948860.0"}]},{"timestamp":"1731514320.0","upvote_count":"2","content":"Selected Answer: B\nB is correct\n\n1. Azure SQL Database Premium\n2. Azure SQL Database Serverless\n3. Azure SQL Database Business Critical","comment_id":"1311434","poster":"[Removed]"},{"comment_id":"847407","content":"Selected Answer: B\nCorrect answer is \"Azure SQL Database Premium\".\n\nBasic and Standard do not support zone-redundancy:\nhttps://learn.microsoft.com/en-GB/azure/azure-sql/database/high-availability-sla","upvote_count":"3","poster":"steel72","timestamp":"1679510880.0"},{"poster":"zellck","comment_id":"813669","upvote_count":"1","content":"Same as Question 16.\nhttps://www.examtopics.com/discussions/microsoft/view/79423-exam-az-305-topic-2-question-16-discussion","timestamp":"1676773440.0"},{"content":"Selected Answer: B\nB is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/sql-database-paas-overview?view=azuresql#service-tiers\nThe Premium service tier is designed for OLTP applications with high transaction rates and low latency I/O requirements. It offers the highest resilience to failures by using several isolated replicas.","timestamp":"1676773380.0","upvote_count":"1","comment_id":"813668","poster":"zellck"},{"poster":"VBK8579","content":"Selected Answer: B\nB. Azure SQL Database Premium","upvote_count":"1","timestamp":"1675661400.0","comment_id":"799446"},{"upvote_count":"1","poster":"OPT_001122","comment_id":"794445","content":"Selected Answer: B\nB. Azure SQL Database Premium","timestamp":"1675186020.0"},{"upvote_count":"1","content":"Selected Answer: B\nPremium for failover without data loss.","poster":"janvandermerwer","timestamp":"1674110280.0","comment_id":"780796"},{"poster":"yeanlingmedal71","upvote_count":"3","comment_id":"779617","content":"Selected Answer: B\nAzure SQL Database Premium tier supports multiple redundant replicas for each database that are automatically provisioned in the same datacenter within a region. This design leverages the SQL Server AlwaysON technology and provides resilience to server failures with 99.99% availability SLA and RPO=0.\nWith the introduction of Azure Availability Zones, we are happy to announce that SQL Database now offers built-in support of Availability Zones in its Premium service tier.\n\n\n\nhttps://azure.microsoft.com/en-us/blog/azure-sql-database-now-offers-zone-redundant-premium-databases-and-elastic-pools/\n\n\nZone-redundant configuration is not available in SQL Managed Instance. In SQL Database this feature is only available when the Gen5 hardware is selected.\n\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/high-availability-sla?view=azuresql&tabs=azure-powershell","timestamp":"1674018420.0"},{"comment_id":"778780","timestamp":"1673950620.0","comments":[{"upvote_count":"1","comment_id":"784750","timestamp":"1674427260.0","poster":"diego84","content":"check this\n\nBasic, Standard, and General Purpose service tier locally redundant availability.\nHowever, General Purpose service tier zone redundant availability\n\n\nhttps://learn.microsoft.com/en-GB/azure/azure-sql/database/high-availability-sla?view=azuresql&tabs=azure-powershell"}],"content":"The deployment option that should be used to meet the requirements of a highly available Azure SQL database with minimal data loss and minimal cost is option D, Azure SQL Database Standard. This option provides active-passive failover capabilities and also allows for read-access to secondary replicas, which can help minimize costs. Additionally, it also provides zone-redundant databases, so in case of zone outage, the database will remain available","upvote_count":"1","poster":"uacanillo"},{"upvote_count":"4","content":"Selected Answer: D\nAzure SQL database standard as we have to minimize costs:\nhttps://azure.microsoft.com/en-us/blog/azure-sql-database-standard-geo-replication/","timestamp":"1672945620.0","comment_id":"766968","poster":"mscbgslt"},{"poster":"maku067","comment_id":"766920","timestamp":"1672942500.0","content":"Selected Answer: B\nseems correct.","upvote_count":"1"},{"poster":"ServerBrain","upvote_count":"2","comment_id":"766723","timestamp":"1672929720.0","content":"This question was added today 05Jan2023. Serves as update confirmation .."}],"question_id":235,"url":"https://www.examtopics.com/discussions/microsoft/view/94032-exam-az-305-topic-4-question-67-discussion/","answer_images":[],"topic":"4","choices":{"D":"Azure SQL Database Standard","B":"Azure SQL Database Premium","C":"Azure SQL Database Basic","A":"Azure SQL Database Hyperscale"},"exam_id":54,"timestamp":"2023-01-05 15:42:00","question_images":[],"answers_community":["B (89%)","11%"],"isMC":true,"question_text":"You need to design a highly available Azure SQL database that meets the following requirements:\n\n• Failover between replicas of the database must occur without any data loss.\n• The database must remain available in the event of a zone outage.\n• Costs must be minimized.\n\nWhich deployment option should you use?","answer":"B","answer_ET":"B"}],"exam":{"id":54,"provider":"Microsoft","lastUpdated":"12 Apr 2025","name":"AZ-305","isMCOnly":false,"isBeta":false,"isImplemented":true,"numberOfQuestions":286},"currentPage":47},"__N_SSP":true}