{"pageProps":{"questions":[{"id":"owg8D0kgp49Z2AFmjyS4","answer":"","exam_id":67,"question_id":11,"unix_timestamp":1704530340,"url":"https://www.examtopics.com/discussions/microsoft/view/130450-exam-dp-203-topic-1-question-108-discussion/","answer_description":"","discussion":[{"comments":[{"upvote_count":"1","timestamp":"1722154920.0","comment_id":"1133975","poster":"vernillen","content":"Agreed"}],"content":"Correct:\nAdd to a delta table => format is delta\nAdd the rows to existing table => append","comment_id":"1115066","upvote_count":"8","timestamp":"1720247940.0","poster":"jongert"},{"poster":"Alongi","comment_id":"1184401","timestamp":"1727465940.0","upvote_count":"1","content":"Correct"},{"content":"correct\nhttps://learn.microsoft.com/en-us/training/modules/use-delta-lake-azure-synapse-analytics/3-create-delta-tables","upvote_count":"3","poster":"Khadija10","comment_id":"1142162","timestamp":"1722942840.0"},{"comment_id":"1138426","poster":"Alongi","timestamp":"1722587280.0","upvote_count":"1","content":"Correct"}],"question_images":["https://img.examtopics.com/dp-203/image357.png"],"answers_community":[],"answer_images":["https://img.examtopics.com/dp-203/image358.png"],"timestamp":"2024-01-06 09:39:00","answer_ET":"","question_text":"HOTSPOT\n-\n\nYou have an Azure Databricks workspace.\n\nYou read data from a CSV file by using a notebook, and then load the data to a DataFrame.\n\nYou need to add rows from the DataFrame to an existing Delta table by using Python code.\n\nHow should you complete the code? To answer, select the appropriate options in the answer area.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","isMC":false,"topic":"1"},{"id":"n8sW5hlGyve3dEIoVroK","answer_description":"","unix_timestamp":1704530940,"question_images":["https://img.examtopics.com/dp-203/image359.png"],"question_text":"DRAG DROP\n-\n\nYou have an Azure subscription that contains an Azure Cosmos DB for NoSQL account named account1. The account1 account contains a container named Container1 that has the following configurations:\n• Analytical store: On\n• TTL: 3600\n\nYou need to remove analytical store support from Container1. The solution must meet the following requirements:\n• Minimize the impact on the apps that reference Container1.\n• Minimize storage usage.\n\nWhich four actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\n\n//IMG//","topic":"1","discussion":[{"poster":"jongert","comment_id":"1115072","timestamp":"1704530940.0","content":"Correct","comments":[{"upvote_count":"1","comment_id":"1309088","timestamp":"1731157320.0","poster":"seranvijay","content":"Agreed"},{"poster":"vernillen","comment_id":"1133977","comments":[{"timestamp":"1708627200.0","comments":[{"comments":[{"comments":[{"comment_id":"1261730","upvote_count":"2","poster":"paffy","content":"agreed","timestamp":"1722958620.0"},{"upvote_count":"3","content":"Agreed","timestamp":"1715974320.0","poster":"jpgsa11","comment_id":"1213028"}],"upvote_count":"2","content":"agreed","timestamp":"1712755140.0","comment_id":"1193014","poster":"ItsNikMon"}],"upvote_count":"3","timestamp":"1709359080.0","poster":"Sumanth567","content":"Agreed","comment_id":"1163942"}],"poster":"efeee333","upvote_count":"3","content":"agreed","comment_id":"1156616"}],"upvote_count":"3","timestamp":"1706437380.0","content":"Agreed"}],"upvote_count":"11"},{"poster":"KarlGardnerDataEngineering","comment_id":"1218571","comments":[{"poster":"Danweo","timestamp":"1720883460.0","comment_id":"1247358","content":"Analytical store cannot be turned off after it has been enabled. A new container is needed to transfer","upvote_count":"2"}],"upvote_count":"2","content":"Why couldn't we just simply turn off the analytical store on Container1?","timestamp":"1716672360.0"},{"upvote_count":"1","comment_id":"1184407","content":"Correct way","timestamp":"1711576260.0","poster":"Alongi"},{"poster":"Ekueaf","upvote_count":"1","content":"Correct!","comment_id":"1177652","timestamp":"1710875520.0"}],"answer_ET":"","url":"https://www.examtopics.com/discussions/microsoft/view/130452-exam-dp-203-topic-1-question-109-discussion/","answer_images":["https://img.examtopics.com/dp-203/image360.png"],"answer":"","answers_community":[],"timestamp":"2024-01-06 09:49:00","question_id":12,"isMC":false,"exam_id":67},{"id":"CmnGpo0dX6MvTTrIpC1P","answer_ET":"","exam_id":67,"question_text":"DRAG DROP -\nYou need to create a partitioned table in an Azure Synapse Analytics dedicated SQL pool.\nHow should you complete the Transact-SQL statement? To answer, drag the appropriate values to the correct targets. Each value may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.\nNOTE: Each correct selection is worth one point.\nSelect and Place:\n//IMG//","answers_community":[],"answer_images":["https://www.examtopics.com/assets/media/exam-media/04259/0003800002.png"],"question_images":["https://www.examtopics.com/assets/media/exam-media/04259/0003800001.png"],"timestamp":"2021-06-04 15:04:00","answer":"","topic":"1","answer_description":"Box 1: DISTRIBUTION -\nTable distribution options include DISTRIBUTION = HASH ( distribution_column_name ), assigns each row to one distribution by hashing the value stored in distribution_column_name.\n\nBox 2: PARTITION -\nTable partition options. Syntax:\nPARTITION ( partition_column_name RANGE [ LEFT | RIGHT ] FOR VALUES ( [ boundary_value [,...n] ] ))\nReference:\nhttps://docs.microsoft.com/en-us/sql/t-sql/statements/create-table-azure-sql-data-warehouse\n?","url":"https://www.examtopics.com/discussions/microsoft/view/54529-exam-dp-203-topic-1-question-11-discussion/","isMC":false,"unix_timestamp":1622811840,"question_id":13,"discussion":[{"timestamp":"1726814760.0","comment_id":"472183","content":"Correct answer by how to remember? Distribution option before the Partition option because… ‘D’ comes before ‘P’ or because the system needs to know the algorithm (hash, round-robin, replicate) before it can start to Partition or segment the data. (seem reasonable?)","upvote_count":"122","poster":"Sasha_in_San_Francisco"},{"comment_id":"374337","timestamp":"1622811840.0","content":"Answer is correct","upvote_count":"67","poster":"Sunnyb"},{"content":"distribution and partition","poster":"krishna1303","upvote_count":"1","timestamp":"1737272400.0","comment_id":"1342908"},{"content":"Distribution \nPartition","comment_id":"1183096","timestamp":"1711437540.0","poster":"dgerok","upvote_count":"2"},{"comment_id":"1001218","timestamp":"1694066280.0","content":"Distribution & Partition","upvote_count":"1","poster":"hassexat"},{"upvote_count":"1","comment_id":"993680","timestamp":"1693367400.0","content":"correct","poster":"kkk5566"},{"content":"The answer is correct. Here you can find an example: https://learn.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-partition#syntax-differences-from-sql-server","poster":"TestingCRM","upvote_count":"3","timestamp":"1684731960.0","comment_id":"903719"},{"comment_id":"746832","upvote_count":"5","timestamp":"1671168420.0","poster":"vigilante89","content":"Answer is:\n\nDISTRIBUTION = HASH (id)\nPARTITION (ID RANGE LEFT\n FOR VALUES (1, 1000000, 2000000) )\n\n----------------------------------------------------------\nThe table option syntax for creating a partitioned table within Dedicated SQL pool:\n\n<table_option> ::=\n {\n CLUSTERED COLUMNSTORE INDEX -- default for Azure Synapse Analytics \n } \n {\n DISTRIBUTION = HASH ( distribution_column_name )\n }\n | PARTITION ( partition_column_name RANGE [ LEFT | RIGHT ] -- default is LEFT \n FOR VALUES ( [ boundary_value [,...n] ] ) )"},{"timestamp":"1660408440.0","poster":"Deeksha1234","content":"correct","upvote_count":"2","comment_id":"646403"},{"content":"Go with a logical explanation guys..what is this D before P..if u take it like that then C comes before D as well.. Try to grasp the logics.. answer is correct.","comments":[{"comment_id":"991047","poster":"topggggggg","timestamp":"1693083900.0","upvote_count":"1","content":"SAVAGE XD"}],"poster":"gursimran_s","comment_id":"612320","upvote_count":"3","timestamp":"1654514880.0"},{"poster":"Dothy","comment_id":"600068","timestamp":"1652266800.0","upvote_count":"1","content":"Answer is correct"},{"comment_id":"586976","timestamp":"1650147780.0","upvote_count":"1","poster":"Egocentric","content":"provided answer is correct"},{"content":"correct","comment_id":"532061","upvote_count":"1","timestamp":"1643109420.0","poster":"PallaviPatel"},{"upvote_count":"1","timestamp":"1640948220.0","content":"Wouldn't VALUES(1,1000000, 200000) create a partition for records with ID <= 1 which would mean 1 row?","comments":[{"upvote_count":"3","timestamp":"1644168660.0","comments":[{"timestamp":"1645101060.0","content":"but only <= and >. it is range left for values, right","comment_id":"549376","poster":"nastyaaa","upvote_count":"2"}],"comment_id":"541899","poster":"ploer","content":"Having three boundaries will lead to four partitions:\n1. Partition for values < 1\n2. Partition for values from 1 to 999999\n3. Partition for values from 1000000 to 199999\n4. Partition for values >= 2000000"}],"comment_id":"514039","poster":"Jaws1990"},{"comment_id":"509994","poster":"Mahesh_mm","content":"Answer is correct","upvote_count":"1","timestamp":"1640576760.0"},{"timestamp":"1632730860.0","poster":"hugoborda","comment_id":"452261","content":"Answer is correct","upvote_count":"1"},{"content":"Indeed! Answer is correct","upvote_count":"1","poster":"hsetin","comment_id":"437236","timestamp":"1630508760.0"}]},{"id":"7oGKkZKzTDKDnixXbs2o","answer_ET":"","timestamp":"2024-01-14 03:37:00","topic":"1","answers_community":[],"isMC":false,"discussion":[{"upvote_count":"8","comments":[{"content":"Agreed!","comment_id":"1133978","upvote_count":"2","poster":"vernillen","timestamp":"1722155040.0","comments":[{"upvote_count":"1","comments":[{"content":"Agreed!","comment_id":"1162323","poster":"efeee333","timestamp":"1724911860.0","upvote_count":"1"}],"content":"https://learn.microsoft.com/en-us/azure/search/search-howto-reindex","poster":"moneytime","comment_id":"1142884","timestamp":"1722988500.0"}]}],"timestamp":"1720917420.0","content":"Answers are correct.\nDropping the index or running pdw_showspaceused is not required.","poster":"Gman1986","comment_id":"1122206"},{"poster":"Sathya_sree","timestamp":"1743426000.0","content":"Create old, rename old","comment_id":"1415129","upvote_count":"1"}],"unix_timestamp":1705199820,"question_text":"DRAG DROP\n-\n\nYou have an Azure Synapse Analytics dedicated SQL pool named SQL1 that contains a hash-distributed fact table named Table1.\n\nYou need to recreate Table1 and add a new distribution column. The solution must maximize the availability of data.\n\nWhich four actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\n\n//IMG//","url":"https://www.examtopics.com/discussions/microsoft/view/131140-exam-dp-203-topic-1-question-110-discussion/","answer":"","question_images":["https://img.examtopics.com/dp-203/image361.png"],"question_id":14,"answer_images":["https://img.examtopics.com/dp-203/image362.png"],"exam_id":67,"answer_description":""},{"id":"BJ3oMEo8S93UFRCY5FCP","timestamp":"2024-01-06 09:53:00","answer_ET":"B","topic":"1","answer_images":[],"answers_community":["B (100%)"],"answer":"B","question_id":15,"exam_id":67,"url":"https://www.examtopics.com/discussions/microsoft/view/130453-exam-dp-203-topic-1-question-111-discussion/","choices":{"A":"Yes","B":"No"},"discussion":[{"comment_id":"1133980","upvote_count":"3","timestamp":"1722155160.0","poster":"vernillen","content":"Selected Answer: B\nAgreed with the others: Git is needed to save the changes, and triggers have nothing to do with saving the pipeline logic. Answer is NO."},{"comment_id":"1116557","poster":"dakku987","upvote_count":"1","timestamp":"1720428900.0","content":"Selected Answer: B\nIT NEED GIT CONFIG TO SAVE THE CHANGES"},{"timestamp":"1720248780.0","comment_id":"1115077","upvote_count":"2","content":"Selected Answer: B\nCorrect, triggers have nothing to do with saving the pipeline logic.","poster":"jongert"}],"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou have an Azure subscription that contains an Azure data factory named ADF1.\n\nFrom Azure Data Factory Studio, you build a complex data pipeline in ADF1.\n\nYou discover that the Save button is unavailable, and there are validation errors that prevent the pipeline from being published.\n\nYou need to ensure that you can save the logic of the pipeline.\n\nSolution: You disable all the triggers for ADF1.\n\nDoes this meet the goal?","answer_description":"","unix_timestamp":1704531180,"question_images":[],"isMC":true}],"exam":{"provider":"Microsoft","id":67,"isImplemented":true,"numberOfQuestions":384,"isMCOnly":false,"isBeta":false,"lastUpdated":"12 Apr 2025","name":"DP-203"},"currentPage":3},"__N_SSP":true}