{"pageProps":{"questions":[{"id":"7Ig53v9XCalxENv7mo5J","timestamp":"2019-09-28 01:11:00","unix_timestamp":1569625860,"answer":"B","topic":"2","question_text":"Your company has a data team of Transact-SQL experts.\nYou plan to ingest data from multiple sources into Azure Event Hubs.\nYou need to recommend which technology the data team should use to move and query data from Event Hubs to Azure Storage. The solution must leverage the data team's existing skills.\nWhat is the best recommendation to achieve the goal? More than one answer choice may achieve the goal.","exam_id":39,"discussion":[{"poster":"T0p1cs","timestamp":"1569625860.0","comment_id":"12966","upvote_count":"35","content":"This answer is wrong, it is Stream Analytics... https://docs.microsoft.com/en-us/azure/architecture/example-scenario/ai/intelligent-apps-image-processing","comments":[{"timestamp":"1576209840.0","poster":"Ubaid","content":"I agree. Stream analytics used T-SQL","upvote_count":"7","comment_id":"29208"}]},{"upvote_count":"7","poster":"drew2020","content":"I concur , because stream analytics uses a T-SQL API","comment_id":"37938","timestamp":"1578812820.0"},{"timestamp":"1687203060.0","poster":"rveney","content":"D. Azure Stream Analytics\n\nAzure Stream Analytics is a real-time analytics and complex event processing engine that is well-suited for ingesting, processing, and storing data from various sources, including Azure Event Hubs. It provides a familiar SQL-like language (Transact-SQL) for querying and transforming data, making it a suitable choice for a data team of Transact-SQL experts. With Azure Stream Analytics, the data team can easily define queries and transformations to move and query data from Event Hubs to Azure Storage.","upvote_count":"1","comment_id":"927847"},{"upvote_count":"2","timestamp":"1629723300.0","poster":"dijaa","comment_id":"429967","content":"DDDDDDDDDDDDDDDDDDDDDDDDdd"},{"comment_id":"287233","content":"Stream Analytics for sure.\nAdditionally, if I can overthink this, you could use the Azure Data Explorer to have the SQL guys write KQL to flow it through Event Grid too.\nhttps://docs.microsoft.com/en-us/azure/data-explorer/data-explorer-overview","upvote_count":"1","timestamp":"1612918200.0","poster":"Cornholioz"},{"upvote_count":"2","poster":"varga123akos","comment_id":"151022","content":"Event Grid do not use SQL, while Stream Analytics does. Both could do the job, but as it is required to use T-SQL knowledge, ASA is the best solution: https://docs.microsoft.com/en-us/azure/event-hubs/process-data-azure-stream-analytics","timestamp":"1596617400.0"},{"comment_id":"117419","upvote_count":"3","timestamp":"1592913240.0","poster":"Egosyntonic","content":"\" More than one answer choice may achieve the goal.\", so Stream Analytics and Event Grid could achieve the goal"},{"timestamp":"1585500600.0","poster":"bizolus","upvote_count":"6","content":"Azure Stream Analytics is the answer","comment_id":"69301"}],"answer_ET":"B","question_images":[],"answers_community":[],"isMC":true,"url":"https://www.examtopics.com/discussions/microsoft/view/5784-exam-ai-100-topic-2-question-35-discussion/","answer_images":["https://www.examtopics.com/assets/media/exam-media/03857/0010200001.jpg"],"question_id":76,"choices":{"C":"Apache Kafka streams","A":"Azure Notification Hubs","B":"Azure Event Grid","D":"Azure Stream Analytics"},"answer_description":"Event Hubs Capture is the easiest way to automatically deliver streamed data in Event Hubs to an Azure Blob storage or Azure Data Lake store. You can subsequently process and deliver the data to any other storage destinations of your choice, such as SQL Data Warehouse or Cosmos DB.\nYou to capture data from your event hub into a SQL data warehouse by using an Azure function triggered by an event grid.\nExample:\n\nFirst, you create an event hub with the Capture feature enabled and set an Azure blob storage as the destination. Data generated by WindTurbineGenerator is streamed into the event hub and is automatically captured into Azure Storage as Avro files.\nNext, you create an Azure Event Grid subscription with the Event Hubs namespace as its source and the Azure Function endpoint as its destination.\nWhenever a new Avro file is delivered to the Azure Storage blob by the Event Hubs Capture feature, Event Grid notifies the Azure Function with the blob URI. The\nFunction then migrates data from the blob to a SQL data warehouse.\nReferences:\nhttps://docs.microsoft.com/en-us/azure/event-hubs/store-captured-data-data-warehouse"},{"id":"NPnPwbV5b3qrHnJHf7Hl","answer_images":[],"exam_id":39,"topic":"2","choices":{"A":"a containerized Computer Vision API on Azure Kubernetes Service (AKS) that has autoscaling configured","D":"a containerized Computer Vision API on Azure Kubernetes Service (AKS) that has virtual nodes configured","C":"an Azure Container Service","B":"the Computer Vision API as a single resource"},"discussion":[{"comment_id":"930317","content":"D. a containerized Computer Vision API on Azure Kubernetes Service (AKS) that has virtual nodes configured\n\nTo deploy a Computer Vision AI application that scales linearly without any upfront costs, you should use a containerized Computer Vision API on Azure Kubernetes Service (AKS) that has virtual nodes configured","upvote_count":"1","timestamp":"1687424400.0","poster":"rveney"},{"upvote_count":"1","poster":"iyiola_daniel","content":"This was in my exam 15th of June, 2021.","comment_id":"384167","timestamp":"1623931800.0"}],"isMC":true,"question_images":[],"timestamp":"2021-06-17 14:10:00","unix_timestamp":1623931800,"url":"https://www.examtopics.com/discussions/microsoft/view/55503-exam-ai-100-topic-2-question-36-discussion/","answer_ET":"A","question_text":"You are designing a Computer Vision AI application.\nYou need to recommend a deployment solution for the application. The solution must ensure that costs scale linearly without any upfront costs.\nWhat should you recommend?","answers_community":[],"answer_description":"Containers enable you to run the Computer Vision APIs in your own environment.\nNote: The host is a x64-based computer that runs the Docker container. It can be a computer on your premises or a Docker hosting service in Azure, such as:\n✑ Azure Container Instances.\n✑ Azure Kubernetes Service.\n✑ A Kubernetes cluster deployed to Azure Stack.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/computer-vision-how-to-install-containers","answer":"A","question_id":77},{"id":"5lTxIFBRQx3zPBuOfLCV","isMC":true,"topic":"2","discussion":[{"comment_id":"297057","upvote_count":"6","timestamp":"1614042540.0","content":"Answer should be \"B\"\nhttps://romsbotframeworkarr.azurewebsites.net/2018/04/23/general-data-protection-regulation-gdpr/\n\nGDPR is not deleting the data. It is giving the user the option to view, export and or delete user data.","poster":"renuka1234","comments":[{"poster":"YipingRuan","content":"But deleting data also surely works.","upvote_count":"1","comment_id":"414981","timestamp":"1627344720.0"}]},{"comment_id":"927853","content":"C. Delete the utterances from Review endpoint utterances.\n\nTo ensure GDPR compliance with the Language Understanding (LUIS) API in the context of a Bot Framework implementation, it is important to handle user data appropriately. Deleting the utterances from the Review endpoint utterances helps to remove any personal data that may have been collected during the interaction with the bot. This step ensures that user data is not stored or retained longer than necessary, aligning with GDPR principles of data minimization and data retention.","poster":"rveney","upvote_count":"1","timestamp":"1687203300.0"},{"timestamp":"1613353560.0","comment_id":"290610","content":"Correct. Another option is to *Disable* Active Learning.","upvote_count":"2","poster":"Cornholioz"}],"answer_images":[],"answer_description":"Deleting personal data from the device or service and can be used to support your obligations under the GDPR.\nReferences:\nhttps://docs.microsoft.com/bs-latn-ba/azure/cognitive-services/luis/luis-user-privacy","exam_id":39,"answer_ET":"C","answers_community":[],"unix_timestamp":1613353560,"timestamp":"2021-02-15 02:46:00","answer":"C","question_id":78,"question_images":[],"question_text":"You are implementing the Language Understanding (LUIS) API and are building a GDPR-compliant bot by using the Bot Framework.\nYou need to recommend a solution to ensure that the implementation of LUIS is GDPR-compliant.\nWhat should you include in the recommendation?","choices":{"C":"Delete the utterances from Review endpoint utterances.","A":"Enable active learning for the bot.","B":"Configure the bot to send the active learning preference of a user."},"url":"https://www.examtopics.com/discussions/microsoft/view/44724-exam-ai-100-topic-2-question-37-discussion/"},{"id":"GoIjD506oI0j2aizxBZo","timestamp":"2021-02-23 01:30:00","answer_images":[],"question_text":"You need to build a reputation monitoring solution that reviews Twitter activity about your company. The solution must identify negative tweets and tweets that contain inappropriate images.\nYou plan to use Azure Logic Apps to build the solution.\nWhich two additional Azure services should you include in the solution? Each correct answer presents part of the solution.\nNOTE: Each correct selection is worth one point.","isMC":true,"discussion":[{"content":"To identify negative tweets and tweets that contain inappropriate images, you can use Azure Content Moderator. Azure Content Moderator is a cognitive service that checks text, image, and video content for material that is potentially offensive, risky, or otherwise undesirable. You can use the Text Analytics connector in Azure Logic Apps to analyze the sentiment of tweets[1]. You can then use Azure Content Moderator to check the images in the tweets for inappropriate content. Therefore, you should include Azure Content Moderator and Text Analytics in the solution.","poster":"rveney","upvote_count":"1","comment_id":"927859","timestamp":"1687203540.0"},{"comments":[{"comment_id":"353942","timestamp":"1620665940.0","upvote_count":"3","poster":"DonGeo","content":"It is definitely Content Moderator and not Computer Vision"},{"timestamp":"1621854360.0","content":"inappropriate images are captured via COntent Moderator\nhttps://azure.microsoft.com/en-us/services/cognitive-services/content-moderator/","comment_id":"365521","upvote_count":"3","poster":"ruslyal"}],"poster":"Romesh","comment_id":"332448","upvote_count":"2","content":"For inappropriate images we need computer vision, I would go with text analytics along with it","timestamp":"1618050300.0"},{"content":"Correct","comment_id":"297041","timestamp":"1614040200.0","poster":"renuka1234","upvote_count":"3"}],"topic":"2","answer_ET":"CD","question_images":[],"answer":"CD","choices":{"B":"Azure Blueprint","D":"Text Analytics","C":"Content Moderator","E":"Azure Machine Learning Service","A":"Computer Vision","F":"Form Recognizer"},"unix_timestamp":1614040200,"answers_community":[],"url":"https://www.examtopics.com/discussions/microsoft/view/45456-exam-ai-100-topic-2-question-38-discussion/","answer_description":"C: You can filter your tweets using Azure Logic Apps & Content Moderation. Azure Content Moderator is a cognitive service that checks text, image, and video content for material that is potentially offensive, risky, or otherwise undesirable. When this material is found, the service applies appropriate labels (flags) to the content. Your app can then handle flagged content in order to comply with regulations or maintain the intended environment for users.\nD: You can write an application so that when a user tweets with configured Twitter Hashtag, Logic App gets triggered and passed to Cognitive Text Analytics\nConnector for detecting the sentiments of the tweet (text). If the tweeted text is found to be harsh or with bad or abusive language, the tweet can be handled appropriately.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/content-moderator/overview https://www.c-sharpcorner.com/article/role-of-text-analytics-service-as-a-connector-in-azure-logic-apps/","exam_id":39,"question_id":79},{"id":"sshbesNPJl5nieBa0aCH","question_images":[],"isMC":true,"exam_id":39,"unix_timestamp":1616186700,"timestamp":"2021-03-19 21:45:00","answer_images":[],"answer":"D","question_text":"Your company uses an internal blog to share news with employees.\nYou use the Translator Text API to translate the text in the blog from English to several other languages used by the employees.\nSeveral employees report that the translations are often inaccurate.\nYou need to improve the accuracy of the translations.\nWhat should you add to the translation solution?","topic":"2","discussion":[{"upvote_count":"1","timestamp":"1687203600.0","comment_id":"927860","content":"D. Custom Translator\n\nTo improve the accuracy of translations in your scenario, you should add the Custom Translator service to your translation solution. Custom Translator allows you to customize and fine-tune the translation models according to your specific domain and language requirements. By training the translation models with your company-specific terminology and style, you can enhance the accuracy of translations and ensure that the translations align with the context and preferences of your employees.","poster":"rveney"},{"timestamp":"1616186700.0","poster":"Nickname__for__discussions","comment_id":"315149","content":"correct","upvote_count":"3"}],"answers_community":[],"answer_ET":"D","question_id":80,"choices":{"A":"Text Analytics","D":"Custom Translator","B":"Language Understanding (LUIS)","C":"Azure Media Services"},"url":"https://www.examtopics.com/discussions/microsoft/view/47766-exam-ai-100-topic-2-question-39-discussion/","answer_description":"Custom Translator is a feature of the Microsoft Translator service. With Custom Translator, enterprises, app developers, and language service providers can build neural translation systems that understand the terminology used in their own business and industry. The customized translation system will then seamlessly integrate into existing applications, workflows and websites.\nCustom Translator allows users to customize Microsoft Translator's advanced neural machine translation for Translator's supported neural translation languages.\nCustom Translator can be used for customizing text when using the Microsoft Translator Text API , and speech translation using the Microsoft Speech services.\nReferences:\nhttps://www.microsoft.com/en-us/translator/business/customization/"}],"exam":{"name":"AI-100","isImplemented":true,"isBeta":false,"numberOfQuestions":206,"lastUpdated":"12 Apr 2025","provider":"Microsoft","isMCOnly":false,"id":39},"currentPage":16},"__N_SSP":true}