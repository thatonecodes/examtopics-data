{"pageProps":{"questions":[{"id":"7U635sBPXBJl2yUHep7f","answer_images":["https://www.examtopics.com/assets/media/exam-media/04271/0007800001.png"],"topic":"8","url":"https://www.examtopics.com/discussions/microsoft/view/78040-exam-ai-102-topic-8-question-1-discussion/","timestamp":"2022-08-15 19:08:00","question_images":["https://www.examtopics.com/assets/media/exam-media/04271/0007700003.png"],"isMC":false,"exam_id":40,"unix_timestamp":1660583280,"question_id":316,"discussion":[{"content":"1. Cognitive Service User\n2. QnA Maker Editor\n3. QnA Maker Read\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/qnamaker/concepts/role-based-access-control#access-is-provided-by-a-defined-role\n- Cognitive Service User (read/write/publish)\n- QnA Maker Editor (read/write)\n- QnA Maker Read (read)","comments":[{"content":"Chatbot requirements: Ensure that the members of a group named Management-Accountants can approve the FAQs. The role that can approve FAQs in a system leveraging Cognitive Services QnA Maker is likely the Cognitive Services QnA Maker Editor. This role typically allows users to create, edit, and manage content, including approving FAQs. Hence, 1. QnA Maker Editor","timestamp":"1733614200.0","poster":"friendlyvlad","upvote_count":"2","comment_id":"1323293"}],"comment_id":"942793","poster":"zellck","timestamp":"1688476560.0","upvote_count":"26"},{"comment_id":"1145961","timestamp":"1707548580.0","content":"management account should use \"Cognitive Service User\" since only this role has permission to publish. Consultant should be able to edit and Agent should be only able to read","upvote_count":"6","poster":"evangelist"},{"upvote_count":"1","timestamp":"1739253720.0","comment_id":"1354861","content":"Cognitive Services User is CORRECT because it allows the Management-Accountants group to publish FAQs. This role provides the necessary permissions to use and manage the QnA Maker knowledge base, including publishing content, which aligns with the requirement for Management-Accountants to approve FAQs.\n\nCognitive Services QnA Maker Editor is CORRECT because it allows the Consultant-Accountants group to create and amend the FAQs. This role provides the necessary permissions to edit the QnA Maker knowledge base without providing excessive permissions such as those needed for managing the entire resource or publishing content.\n\nCognitive Services QnA Maker Read is CORRECT because it allows the Agent-CustomerServices group to browse and read the FAQs without making any modifications. This role provides read-only access to the QnA Maker knowledge base, which is appropriate for their requirement to browse FAQs.\n\nProvided answer is right","poster":"syupwsh"},{"upvote_count":"1","comment_id":"1287407","timestamp":"1726937160.0","content":"The dysfunctional Microsoft makes this question an English comprehension question. How much text to read and to check what knowledge, roles? How does the scenario become important.","poster":"famco"},{"timestamp":"1726298940.0","content":"no longer in exam, all bots stuff is out https://trainingsupport.microsoft.com/en-us/mcp/forum/all/azure-ai102-chatbots-service/798c0cfa-3475-474e-b4ec-8ab7fc790e81","comment_id":"1283528","poster":"mrg998","upvote_count":"3"},{"poster":"rdemontis","upvote_count":"2","timestamp":"1699652100.0","comment_id":"1067534","content":"correct"},{"upvote_count":"4","timestamp":"1660583280.0","content":"The answer is correct, based on \nhttps://docs.microsoft.com/en-us/azure/cognitive-services/qnamaker/concepts/role-based-access-control","poster":"ninjia","comment_id":"647293"}],"answer":"","question_text":"HOTSPOT -\nYou build a QnA Maker resource to meet the chatbot requirements.\nWhich RBAC role should you assign to each group? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","answer_description":"Box 1: Cognitive Service User -\nEnsure that the members of a group named Management-Accountants can approve the FAQs.\nApprove=publish.\nCognitive Service User (read/write/publish): API permissions: All access to Cognitive Services resource except for ability to:\n1. Add new members to roles.\n2. Create new resources.\nBox 2: Cognitive Services QnA Maker Editor\nEnsure that the members of a group named Consultant-Accountants can create and amend the FAQs.\nQnA Maker Editor: API permissions:\n1. Create KB API\n2. Update KB API\n3. Replace KB API\n4. Replace Alterations\n5. \"Train API\" [in new service model v5]\nBox 3: Cognitive Services QnA Maker Read\nEnsure that the members of a group named the Agent-CustomerServices can browse the FAQs.\nQnA Maker Read: API Permissions:\n1. Download KB API\n2. List KBs for user API\n3. Get Knowledge base details\n4. Download Alterations\n\nGenerate Answer -\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/qnamaker/concepts/role-based-access-control","answer_ET":"","answers_community":[]},{"id":"RnGP79KbQUm00tjg4HTi","url":"https://www.examtopics.com/discussions/microsoft/view/150483-exam-ai-102-topic-8-question-10-discussion/","unix_timestamp":1730239920,"answers_community":["D (100%)"],"choices":{"D":"a blocklist","A":"a text classifier","B":"language detection","C":"text moderation"},"topic":"8","answer_ET":"D","exam_id":40,"question_images":[],"discussion":[{"upvote_count":"1","poster":"syupwsh","comment_id":"1354825","timestamp":"1739244960.0","content":"Selected Answer: D\nA blocklist allows you to define a custom list of offensive terms, including terms specific to local language dialects, to be flagged during content analysis. Blocklists are specifically designed for scenarios where predefined moderation models may not cover region-specific terms. Using a blocklist minimizes development effort as it integrates directly with Azure AI Content Safety.\n\nD is correct"},{"content":"Selected Answer: D\nTo handle a custom dictionary of offensive terms in Azure AI Content Safety, the blocklist feature is designed for exactly that scenario. You can supply your own list of obscure or custom offensive terms as a blocklist, and Content Safety will flag or block content containing those terms.","poster":"kennynelcon","timestamp":"1734937500.0","comment_id":"1330710","upvote_count":"2"},{"comment_id":"1304733","upvote_count":"3","timestamp":"1730239920.0","poster":"a8da4af","content":"Selected Answer: D\nBlocklist is what you would use: https://learn.microsoft.com/en-us/azure/ai-services/content-safety/how-to/use-blocklist?tabs=windows%2Crest"}],"answer":"D","isMC":true,"question_id":317,"question_text":"You have an Azure subscription that contains an Azure AI Content Safety resource named CS1.\n\nYou plan to build an app that will analyze user-generated documents and identify obscure offensive terms.\n\nYou need to create a dictionary that will contain the offensive terms. The solution must minimize development effort.\n\nWhat should you use?","timestamp":"2024-10-29 23:12:00","answer_images":[],"answer_description":""},{"id":"XuMpFyQ4xtBPPFSYd3Sg","discussion":[{"comment_id":"1304734","content":"Answer is ContentSafetyClient and AnalyzeTextOptions : https://learn.microsoft.com/en-us/azure/ai-services/content-safety/how-to/use-blocklist?tabs=windows%2Crest","timestamp":"1730240160.0","comments":[{"upvote_count":"2","comment_id":"1331753","content":"Correct: \nContentSafetyClient\nAnalyzeTextOptions","poster":"pabsinaz","timestamp":"1735177800.0"}],"upvote_count":"5","poster":"a8da4af"},{"poster":"syupwsh","timestamp":"1740894900.0","content":"ContentSafetyClient is CORRECT. This class is used to connect to the Azure AI Content Safety resource and perform operations such as analyzing text for harmful or objectionable content. By initializing the client with the correct endpoint and key, you can call the AnalyzeText method to assess the content.\n\nAnalyzeTextOptions is CORRECT. This class is used to configure the options for analyzing text, such as specifying the content to be evaluated for harmful or objectionable material. In this case, it is needed to create a request for the AnalyzeText method, which checks the input for content violations.","comment_id":"1363826","upvote_count":"1"}],"answer_images":["https://img.examtopics.com/ai-102/image198.png"],"isMC":false,"question_images":["https://img.examtopics.com/ai-102/image197.png"],"answer":"","question_text":"HOTSPOT\n-\n\nYou have an Azure subscription that contains an Azure AI Content Safety resource named CS1.\n\nYou need to use the SDK to call CS1 to identify requests that contain harmful content.\n\nHow should you complete the code? To answer, select the appropriate options in the answer area.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","topic":"8","question_id":318,"unix_timestamp":1729493100,"answers_community":[],"timestamp":"2024-10-21 08:45:00","url":"https://www.examtopics.com/discussions/microsoft/view/149922-exam-ai-102-topic-8-question-11-discussion/","answer_ET":"","answer_description":"","exam_id":40},{"id":"rlGQ6A3tAYPB3kCynqv4","answer_ET":"B","isMC":true,"timestamp":"2024-10-21 17:21:00","topic":"8","unix_timestamp":1729524060,"question_id":319,"choices":{"A":"Monitor online activity","C":"Moderate text content","B":"Jailbreak risk detection","D":"Protected material text detection"},"answers_community":["B (100%)"],"question_text":"You have an Azure subscription that contains an Azure OpenAI resource named AI1.\n\nYou build a chatbot that uses AI1 to provide generative answers to specific questions.\n\nYou need to ensure that questions intended to circumvent built-in safety features are blocked.\n\nWhich Azure AI Content Safety feature should you implement?","answer":"B","question_images":[],"discussion":[{"upvote_count":"5","poster":"mbsff","comment_id":"1324743","comments":[{"content":"Azure OpenAI offers a feature called Prompt Shields (formerly known as Jailbreak Risk Detection) to protect against harmful or inappropriate content generated by AI models. This feature helps detect and mitigate risks associated with both User Prompt Attacks and Document Attacks","poster":"pabsinaz","timestamp":"1735177920.0","comment_id":"1331755","upvote_count":"1"}],"content":"Selected Answer: B\nNow called Prompt shields for user Prompts\nhttps://learn.microsoft.com/en-us/azure/ai-services/content-safety/concepts/jailbreak-detection#prompt-shields-for-user-prompts","timestamp":"1733863080.0"},{"comment_id":"1366482","content":"Update to prompt shield","timestamp":"1741406580.0","poster":"swap_c11","upvote_count":"1"},{"upvote_count":"1","comment_id":"1363828","timestamp":"1740894960.0","content":"Selected Answer: B\nB is CORRECT because it is specifically designed to detect and block user attempts to manipulate or circumvent the built-in safety mechanisms of an AI model. Here, the chatbot using AI1 relies on Azure OpenAI to provide generative responses. However, some users may try to bypass content restrictions by rephrasing their inputs, using adversarial prompts, or employing indirect queries to elicit responses that the AI is programmed to block.","poster":"syupwsh"}],"exam_id":40,"answer_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/149971-exam-ai-102-topic-8-question-12-discussion/","answer_description":""},{"id":"8AyoQ3NA0S2HTGyKMKSy","answer_ET":"A","url":"https://www.examtopics.com/discussions/microsoft/view/149577-exam-ai-102-topic-8-question-2-discussion/","unix_timestamp":1729011900,"answers_community":["A (100%)"],"question_text":"You have an Azure subscription that contains an Azure AI Content Safety resource named CS1.\n\nYou create a test image that contains a circle.\n\nYou submit the test image to CS1 by using the curl command and the following command-line parameters.\n\n//IMG//\n\n\nWhat should you expect as the output?","question_images":["https://img.examtopics.com/ai-102/image192.png"],"topic":"8","isMC":true,"answer":"A","answer_description":"","timestamp":"2024-10-15 19:05:00","discussion":[{"upvote_count":"2","timestamp":"1739244300.0","comment_id":"1354816","content":"Selected Answer: A\n0 is CORRECT because the image being submitted contains only a simple circle, which does not contain any violent content. When using Azure AI Content Safety with the \"Violence\" category and the outputType set to \"EightSeverityLevels,\" the service evaluates the image for signs of violence. The \"EightSeverityLevels\" output ranges from 0 to 7, where 0 indicates \"Non-offensive\" and 7 represents \"Very High\" severity. Since a circle is considered harmless, the expected severity score is 0, indicating no detection of violent content.\n\nA is correct","poster":"syupwsh"},{"timestamp":"1731966660.0","poster":"3fbc31b","comment_id":"1314250","content":"Selected Answer: A\nThe severity levels are from 0 - 7, with 0 being the lowest, if any form of offensive material, and 7 being very naughty/offensive.\n\nGiven this, A is the answer.","upvote_count":"3"},{"timestamp":"1730158500.0","upvote_count":"3","comment_id":"1304222","poster":"a8da4af","content":"Selected Answer: A\nA is correct."},{"upvote_count":"1","comment_id":"1298785","poster":"mrg998","content":"In this scenario, you are submitting an image to an Azure AI Content Safety resource for evaluation, specifically looking for violent content using the \"EightSeverityLevels\" output type. The image you submitted contains a simple circle, which likely doesn't depict any violent or harmful content.\n\nGiven that the image is non-violent, the expected severity level for violence should be the lowest possible score. In the \"EightSeverityLevels\" configuration, the scores range from 0 to 7, with 0 representing the least severe and 7 representing the most severe.\n\nThus, the correct output in this case would be:\n\nA. 0","timestamp":"1729089900.0"},{"comment_id":"1298360","comments":[{"comment_id":"1298363","poster":"jafaca","content":"0: Non-offensive\n1: Very Low\n2: Low\n3: Moderate-Low\n4: Moderate\n5: Moderate-High\n6: High\n7: Very High","timestamp":"1729012140.0","upvote_count":"4"}],"upvote_count":"2","timestamp":"1729011900.0","content":"Selected Answer: A\n0: Non-offensive\n1-2: Very Low\n3-4: Low\n5-6: Moderate\n7-8: High\n9-10: Very High","poster":"jafaca"}],"exam_id":40,"answer_images":[],"choices":{"B":"0.0","A":"0","D":"100","C":"7"},"question_id":320}],"exam":{"isBeta":false,"numberOfQuestions":329,"isMCOnly":false,"name":"AI-102","id":40,"isImplemented":true,"provider":"Microsoft","lastUpdated":"12 Apr 2025"},"currentPage":64},"__N_SSP":true}