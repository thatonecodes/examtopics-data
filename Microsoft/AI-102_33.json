{"pageProps":{"questions":[{"id":"VMHYZXsnql9NJTG2Vixd","answers_community":["C (76%)","A (24%)"],"answer_images":[],"question_text":"You are building a retail kiosk system that will use a custom neural voice.\n\nYou acquire audio samples and consent from the voice talent.\n\nYou need to create a voice talent profile.\n\nWhat should you upload to the profile?","exam_id":40,"question_images":[],"discussion":[{"poster":"tdctdc","content":"Selected Answer: C\nThe question is about the profile, not data.","upvote_count":"6","comment_id":"1085028","timestamp":"1701414960.0"},{"content":"Selected Answer: C\na .wav or .mp3 file of the voice talent consenting to the creation of a synthetic version of their voice is CORRECT because creating a custom neural voice requires explicit consent from the voice talent, which should be recorded and uploaded to ensure compliance with ethical and legal standards. This consent recording is necessary to create the voice talent profile.\n\nAnswer is C","poster":"syupwsh","upvote_count":"1","timestamp":"1740808380.0","comment_id":"1363413"},{"upvote_count":"1","comment_id":"1362550","timestamp":"1740665880.0","content":"Selected Answer: A\nA. a .zip file that contains 10-second .wav files and the associated transcripts as .txt files\n\nExplanation:\nThis option aligns with the typical requirements for creating a custom neural voice. The system needs short, segmented audio samples along with their corresponding transcripts to accurately train the model and generate the synthetic voice.\n\nBy providing multiple short audio files and their transcripts, you ensure that the voice model can learn the nuances of the voice talent's speech and generate a high-quality custom voice.","poster":"gyaansastra"},{"timestamp":"1735943040.0","comment_id":"1336172","content":"Selected Answer: A\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/record-custom-voice-samples","upvote_count":"1","poster":"VitaliiKurishko"},{"timestamp":"1727450580.0","poster":"fawzi008","content":"Selected Answer: A\nuploaded testing data must be A collection (.zip) of either .wave +.txt (if samples and transcripts are available)or .wave/.mp3 (if samples only available)\nin both cases must be .zip","comments":[{"timestamp":"1727983680.0","upvote_count":"1","poster":"fawzi008","content":"wrong answer \nas per https://learn.microsoft.com/en-us/azure/ai-services/speech-service/professional-voice-create-consent?pivots=speech-studio\nfile should be .wave or .mp3","comment_id":"1292913"}],"comment_id":"1290106","upvote_count":"1"},{"comment_id":"1282155","timestamp":"1726062000.0","poster":"mrg998","content":"Selected Answer: C\nanwser is C, see here - https://learn.microsoft.com/en-us/azure/ai-services/speech-service/professional-voice-create-consent?pivots=speech-studio","upvote_count":"1"},{"content":"Selected Answer: A\nBoth me and ChatGPT agree with A","upvote_count":"1","timestamp":"1723644360.0","comment_id":"1265816","poster":"anto69"},{"poster":"anto69","comment_id":"1260537","content":"Selected Answer: A\na .zip file that contains 10-second .wav files and the associated transcripts as .txt files","timestamp":"1722751320.0","upvote_count":"1"},{"upvote_count":"2","poster":"HaraTadahisa","timestamp":"1719037440.0","comment_id":"1235193","content":"Selected Answer: C\nI say this answer is C."},{"content":"Selected Answer: C\nC is answer.","timestamp":"1718201700.0","poster":"reigenchimpo","upvote_count":"3","comment_id":"1229220"},{"timestamp":"1716983760.0","poster":"omankoman","comment_id":"1220891","content":"Selected Answer: C\nC is correct answer.","upvote_count":"4"},{"comment_id":"1191185","upvote_count":"2","poster":"Murtuza","timestamp":"1712521860.0","content":"Selected Answer: C\nC is the correct answer"},{"upvote_count":"2","comment_id":"1141381","timestamp":"1707160740.0","poster":"Tactable","content":"Selected Answer: C\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-custom-voice-talent"},{"poster":"evangelist","upvote_count":"3","timestamp":"1706960880.0","content":"Selected Answer: C\nBased on the Azure AI documentation, the correct option for creating a voice talent profile for a custom neural voice is:\n\nC. a .wav or .mp3 file of the voice talent consenting to the creation of a synthetic version of their voice.\n\nThis is because the documentation specifies the need for a recording of the voice talent's consent statement, acknowledging the use of their voice recordings by a specified company to create and use a synthetic version of their voice","comment_id":"1139197"},{"upvote_count":"2","content":"C is the correct answer as only wav & mp3 formats are allowed. Zip is not allowed.","poster":"RupRizal","comment_id":"1084398","timestamp":"1701350760.0"},{"timestamp":"1699193640.0","upvote_count":"1","content":"Selected Answer: C\nhere we are requested to add a new voice talent profile. So a consent statement is needed.\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-custom-voice-talent","poster":"rdemontis","comment_id":"1062965"},{"content":"Selected Answer: C\nI initially thought A, but now think it is C\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-custom-voice-talent","upvote_count":"1","poster":"katrang","timestamp":"1697696460.0","comment_id":"1047598"},{"comment_id":"1023947","poster":"AnonymousJhb","timestamp":"1696337640.0","content":"Selected Answer: C\nzip is not allowed. only wav & mp3.\nAnd made synthetic. =C\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-custom-voice-talent\nfollow the pictures very carefully.","upvote_count":"3"},{"upvote_count":"1","comment_id":"1005637","poster":"[Removed]","content":"Selected Answer: A\nThe correct answer is A! From the documentation: https://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-custom-voice-training-data\n\nFollow these guidelines when preparing audio.\nProperty Value\nFile format RIFF (.wav), grouped into a .zip file\nFile name File name characters supported by Windows OS, with .wav extension.\nThe characters \\ / : * ? \" < > | aren't allowed.\nIt can't start or end with a space, and can't start with a dot.\nNo duplicate file names are allowed.\nSampling rate When creating a custom neural voice, 24,000 Hz is required.\nSample format PCM, at least 16-bit\nAudio length Shorter than 15 seconds\nArchive format .zip\nMaximum archive size 2048 MB","timestamp":"1694513400.0"},{"upvote_count":"1","comment_id":"996762","content":"Selected Answer: C\nIn Q#13 (How should you upload the samples?), the selected answer as option B (for speech samples to be used in training) corresponds to this Q#43’s option A.\n\nQ#43 (What should you upload to the profile?) though, refers specifically to the voice talent’s profile, that should contain an audio sample of the given consent, and hereto “Only .wav and .mp3 files are accepted” (at the bottom of the screenshot provided in the link).\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-custom-voice-talent#add-voice-talent","poster":"M25","timestamp":"1693646580.0"},{"upvote_count":"3","poster":"[Removed]","content":"Selected Answer: C\nI would have choosen A but it's actually C because of https://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-custom-voice-talent\n\n\"A voice talent is an individual or target speaker whose voices are recorded and used to create neural voice models.\n\nBefore you can train a neural voice, you must submit a recording of the voice talent's consent statement. The voice talent statement is a recording of the voice talent reading a statement that they consent to the usage of their speech data to train a custom voice model. The consent statement is also used to verify that the voice talent is the same person as the speaker in the training data.\"","timestamp":"1691912940.0","comment_id":"979844"},{"content":"Selected Answer: C\nC should be the correct answer instead.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/how-to-custom-voice-talent#add-voice-talent\n- On the Upload voice talent statement page, follow the instructions to upload the voice talent statement you've recorded beforehand. Make sure the verbal statement was recorded with the same settings, environment, and speaking style as your training data.\n- Enter the voice talent name and company name. The voice talent name must be the name of the person who recorded the consent statement. The company name must match the company name that was spoken in the recorded statement.","upvote_count":"4","timestamp":"1688010360.0","comment_id":"937447","poster":"zellck"},{"upvote_count":"2","timestamp":"1688010180.0","comment_id":"937444","poster":"zellck","content":"Selected Answer: A\nA is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/how-to-custom-voice-training-data#types-of-training-data\nA voice training dataset includes audio recordings, and a text file with the associated transcriptions. Each audio file should contain a single utterance (a single sentence or a single turn for a dialog system), and be less than 15 seconds long.\n\n- Individual utterances + matching transcript\nA collection (.zip) of audio files (.wav) as individual utterances. Each audio file should be 15 seconds or less in length, paired with a formatted transcript (.txt)."},{"timestamp":"1687832880.0","comment_id":"934974","poster":"Pixelmate","content":"A is correct answer. Training data for custom-neaural-voice format has to be in .wav and .zip files as per the below documentation. https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/how-to-custom-voice-training-data","upvote_count":"1"},{"poster":"EliteAllen","content":"Selected Answer: A\nA. a .zip file that contains 10-second .wav files and the associated transcripts as .txt files\n\nWhen creating a voice talent profile for a custom neural voice in Azure Cognitive Services, you need to upload a .zip file that contains audio samples from the voice talent and the associated transcripts. The audio samples should be in .wav format and each sample should be approximately 10 seconds long. The transcripts should be in .txt format and should match the spoken content in the audio samples. This data is used to train the custom neural voice model to mimic the voice talent's unique speech patterns.","upvote_count":"4","comment_id":"923298","timestamp":"1686753060.0"},{"comment_id":"917900","upvote_count":"3","poster":"sheldon73","timestamp":"1686205980.0","content":"Selected Answer: C\nSource : https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/custom-neural-voice"},{"comment_id":"904805","poster":"mVic","timestamp":"1684836900.0","upvote_count":"4","content":"Selected Answer: C\nC is correct, as per below documentation.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/how-to-custom-voice-talent"},{"comment_id":"886866","poster":"hcgkzsf","content":"Selected Answer: A\nA is correct.","timestamp":"1682986800.0","upvote_count":"2"}],"isMC":true,"topic":"3","unix_timestamp":1682986800,"choices":{"A":"a .zip file that contains 10-second .wav files and the associated transcripts as .txt files","B":"a five-minute .flac audio file and the associated transcript as a .txt file","D":"a five-minute .wav or .mp3 file of the voice talent describing the kiosk system","C":"a .wav or .mp3 file of the voice talent consenting to the creation of a synthetic version of their voice"},"answer_description":"","answer_ET":"C","question_id":161,"url":"https://www.examtopics.com/discussions/microsoft/view/108161-exam-ai-102-topic-3-question-43-discussion/","timestamp":"2023-05-02 02:20:00","answer":"C"},{"id":"Kr0tXN44ovjHPcXJpl8H","answer_images":["https://img.examtopics.com/ai-102/image38.png"],"discussion":[{"comment_id":"940087","timestamp":"1704128400.0","upvote_count":"46","content":"1. From portal, export solution as package file.\n2. From host computer, move package file to Docker input directory.\n3. From host computer, run container and specify input directory.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/luis/luis-container-howto?tabs=v3#how-to-use-the-container\n- Export package for container from LUIS portal or LUIS APIs.\n- Move package file into the required input directory on the host computer. Do not rename, alter, overwrite, or decompress the LUIS package file.\n- Run the container, with the required input mount and billing settings.","comments":[{"poster":"M25","content":"@zellck: You’re a role model for contributing to community discussions, love this style! Well-documented answers, plus the corresponding links to follow-up and form an opinion independently!","timestamp":"1709379720.0","upvote_count":"21","comment_id":"996774"},{"timestamp":"1714911300.0","comment_id":"1062966","poster":"rdemontis","upvote_count":"3","content":"thanks for explanation"}],"poster":"zellck"},{"comment_id":"1358520","poster":"syupwsh","timestamp":"1739925600.0","upvote_count":"1","content":"1) From the Language Understanding portal, export the solution as a package file is CORRECT. This step is necessary to export the trained model from the portal, which will be used as a package file to be deployed within the Docker container.\n\n2) From the host computer, move the package file to the Docker input directory is CORRECT. After exporting the solution as a package file, the next step is to move the file to the Docker input directory where it will be accessed by the container.\n\n3) From the host computer, run the container and specify the input directory is CORRECT. Running the container and specifying the input directory ensures that the model package can be loaded and executed properly within the container."},{"comment_id":"1215795","content":"export\nmove\nrun","timestamp":"1732292100.0","upvote_count":"3","poster":"takaimomoGcup"},{"upvote_count":"1","content":"Export the LUIS application as a package file from the Azure portal: This involves downloading the LUIS model you've developed and want to run locally in a container.\n\nMove the exported package file to the Docker input directory on the host computer: This step involves transferring the downloaded LUIS application package to a specific directory that the Docker container will use as its input source.\n\nRun the Docker container and specify the input directory: This involves using Docker commands to start the container with the necessary parameters, including the location of the LUIS application package file in the input directory.\n\nRetraining the model is not mentioned as a step for deploying the container image to a host computer because the model should already be trained and exported from the LUIS portal before deployment.","poster":"evangelist","timestamp":"1722678720.0","comment_id":"1139198"},{"comment_id":"934021","poster":"Tin_Tin","upvote_count":"2","timestamp":"1703570520.0","content":"The answer seems correct.\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/luis/luis-container-howto?tabs=v3"},{"comment_id":"920313","content":"No.\nExport,Docker,Output directory.","upvote_count":"1","timestamp":"1702258020.0","poster":"973b658"},{"timestamp":"1701857520.0","upvote_count":"3","poster":"ziggy1117","content":"answer is correct","comment_id":"916038"}],"answers_community":[],"answer_description":"","question_id":162,"answer":"","answer_ET":"","timestamp":"2023-06-06 10:12:00","url":"https://www.examtopics.com/discussions/microsoft/view/111250-exam-ai-102-topic-3-question-44-discussion/","topic":"3","exam_id":40,"unix_timestamp":1686039120,"question_text":"DRAG DROP\n-\n\nYou have a Language Understanding solution that runs in a Docker container.\n\nYou download the Language Understanding container image from the Microsoft Container Registry (MCR).\n\nYou need to deploy the container image to a host computer.\n\nWhich three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\n\n//IMG//","question_images":["https://img.examtopics.com/ai-102/image37.png"],"isMC":false},{"id":"pOzZ9dbpzU00CIH9hExI","answer_images":["https://img.examtopics.com/ai-102/image40.png"],"question_text":"HOTSPOT\n-\n\nYou are building a text-to-speech app that will use a custom neural voice.\n\nYou need to create an SSML file for the app. The solution must ensure that the voice profile meets the following requirements:\n\n• Expresses a calm tone\n• Imitates the voice of a young adult female\n\nHow should you complete the code? To answer, select the appropriate options in the answer area.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","discussion":[{"content":"1. role\n2. style\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/speech-synthesis-markup-voice#speaking-styles-and-roles\nBy default, neural voices have a neutral speaking style. You can adjust the speaking style, style degree, and role at the sentence level.\n\nThe following table has descriptions of each supported style attribute.\n- style=\"gentle\"\nExpresses a mild, polite, and pleasant tone, with lower pitch and vocal energy.\n\nThe following table has descriptions of each supported role attribute.\n- role=\"YoungAdultFemale\"\nThe voice imitates a young adult female.","timestamp":"1688223420.0","poster":"zellck","comment_id":"940085","upvote_count":"23"},{"content":"correct https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/speech-synthesis-markup-voice","comment_id":"895235","upvote_count":"9","poster":"WinzigWeich","timestamp":"1683823620.0"},{"content":"role = \"YoungAdultFemale\" is CORRECT because this attribute is used in SSML to specify the intended role or persona of the voice. In this case, you want the voice to imitate a young adult female, so using role=\"YoungAdultFemale\" correctly specifies this persona.\n\nstyle = \"gentle\" is CORRECT because this attribute is used in SSML to specify the speaking style or tone. In this case, you want the voice to express a calm tone, so using style=\"gentle\" correctly specifies this speaking style.","upvote_count":"1","poster":"syupwsh","timestamp":"1739925960.0","comment_id":"1358525"},{"poster":"krzkrzkra","timestamp":"1720978920.0","comment_id":"1247883","upvote_count":"1","content":"1. role\n2. style"},{"poster":"NagaoShingo","comment_id":"1225506","timestamp":"1717677960.0","content":"1. role\n2. style","upvote_count":"1"},{"comment_id":"1217360","timestamp":"1716543720.0","poster":"funny_penguin","content":"on exam, role and style.","upvote_count":"2"},{"poster":"takaimomoGcup","upvote_count":"1","timestamp":"1716387420.0","comment_id":"1215797","content":"role and style"},{"comment_id":"1062967","poster":"rdemontis","content":"correct answer\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup-voice","timestamp":"1699193760.0","upvote_count":"2"},{"comment_id":"984582","upvote_count":"2","poster":"james2033","content":"role\n\nstyle\n\nsee role at https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup-voice#role-example . May styles at https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup-voice#speaking-styles-and-roles","timestamp":"1692369720.0"}],"url":"https://www.examtopics.com/discussions/microsoft/view/108985-exam-ai-102-topic-3-question-45-discussion/","answer_description":"","timestamp":"2023-05-11 18:47:00","question_images":["https://img.examtopics.com/ai-102/image39.png"],"answers_community":[],"question_id":163,"unix_timestamp":1683823620,"exam_id":40,"topic":"3","isMC":false,"answer":"","answer_ET":""},{"id":"YS1qtqZ1dPmy2vbweB2F","timestamp":"2023-05-01 14:33:00","answer_ET":"AC","question_id":164,"isMC":true,"url":"https://www.examtopics.com/discussions/microsoft/view/108116-exam-ai-102-topic-3-question-47-discussion/","exam_id":40,"choices":{"B":"the adult classification score","E":"the racy classification score","C":"text classification","A":"personal data","D":"optical character recognition (OCR)"},"answers_community":["AC (76%)","BE (24%)"],"answer_description":"","topic":"3","answer":"AC","unix_timestamp":1682944380,"answer_images":[],"question_images":[],"discussion":[{"poster":"zellck","upvote_count":"16","content":"Selected Answer: AC\nAC is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/content-moderator/text-moderation-api\nUse Content Moderator's text moderation models to analyze text content, such as chat rooms, discussion boards, chatbots, e-commerce catalogs, and documents.\n\nThe service response includes the following information:\n- Profanity: term-based matching with built-in list of profane terms in various languages\n- Classification: machine-assisted classification into three categories\n- Personal data\n- Auto-corrected text\n- Original text\n- Language","comment_id":"937442","comments":[{"poster":"zellck","comment_id":"946497","content":"Gotten this in Jul 2023 exam.","upvote_count":"3","timestamp":"1688821560.0"},{"upvote_count":"4","comment_id":"996833","comments":[{"upvote_count":"1","timestamp":"1725908340.0","comment_id":"1281205","poster":"famco","content":"So, the two product team from Microsoft did not talk to each other and created an inconsistency. Now we have to remember that?!!"}],"timestamp":"1693652880.0","content":"Correct! While A, C belong to Text Moderation\nhttps://learn.microsoft.com/en-us/azure/ai-services/content-moderator/text-moderation-api,\n\nB, E belong to Vision AI\nhttps://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-detecting-adult-content#content-flag-definitions","poster":"M25"}],"timestamp":"1688009760.0"},{"upvote_count":"8","content":"Selected Answer: BE\nB. the adult classification score\nE. the racy classification score\n\nTo enable content moderation in a text-based chatbot using the Text Moderation API of Content Moderator, you should use the adult classification score (B) and the racy classification score (E). These scores will help you determine if the content is adult or racy in nature, enabling you to take appropriate action for moderation purposes.","timestamp":"1682944380.0","poster":"EliteAllen","comment_id":"886225"},{"poster":"syupwsh","upvote_count":"1","timestamp":"1740808440.0","comment_id":"1363414","content":"Selected Answer: AC\npersonal data is CORRECT because it helps identify and potentially mask sensitive information like names, addresses, and phone numbers, ensuring user privacy during conversations.\n\n\n\ntext classification is CORRECT because it allows the API to analyze the text for potentially harmful content like hate speech, bullying, and threats, which is crucial for maintaining a safe and positive environment in your chatbot.\n\nAC"},{"upvote_count":"1","content":"Selected Answer: BE\n* B. the adult classification score\n* E. the racy classification score\n\nThese two responses from the Content Moderator API will help you detect and filter potentially inappropriate content in your chatbot:\n\nThe adult classification score provides a probability rating for sexually explicit or adult content, while the racy classification score indicates potentially suggestive or provocative content that might not be explicitly adult but could still be inappropriate depending on your audience.\n\nTogether, these scores allow you to implement appropriate content filtering rules based on your chatbot's usage context and audience requirements.","poster":"gyaansastra","comment_id":"1362558","timestamp":"1740666660.0"},{"timestamp":"1720979040.0","content":"Selected Answer: AC\nAC is the answer.","poster":"krzkrzkra","comment_id":"1247886","upvote_count":"1"},{"poster":"reigenchimpo","comment_id":"1229219","timestamp":"1718201700.0","content":"Selected Answer: AC\nAC is answer.","upvote_count":"2"},{"upvote_count":"3","content":"C. Text classification\nA. Personal data\n\nHere's why these two are important:\n\nText classification: This functionality allows the API to analyze the text for potentially harmful content like hate speech, bullying, threats, etc. This is crucial for ensuring a safe and positive environment in your chatbot.\nPersonal data: This helps identify and potentially mask sensitive information like names, addresses, phone numbers, etc., which users might accidentally or intentionally reveal during conversations. This protects user privacy.\nLet's break down the other options:\n\nB. The adult classification score: This functionality is not available in the Text Moderation API. It's likely part of the Content Moderator's Image Moderation API for identifying inappropriate visuals.\nD. Optical character recognition (OCR): This is not relevant for text-based chatbots as OCR deals with converting images containing text into machine-readable format.\nE. The racy classification score: Similar to adult classification score, this functionality is likely intended for image moderation and not directly applicable to text analysis.","comment_id":"1202917","poster":"Jimmy1017","timestamp":"1714183320.0"},{"poster":"evangelist","timestamp":"1706961480.0","comment_id":"1139199","upvote_count":"1","content":"Selected Answer: AC\nThe appropriate service responses for content moderation using the Text Moderation API of Content Moderator are:\n\nA. Personal Data and C. Text Classification.\n\nThese features help identify sensitive information and categorize text content based on its potential appropriateness, including detecting profanity, personal data, and classifying text into categories related to potentially undesired content\n\nPLEASE DO NOT SELECT A,C!!!"},{"timestamp":"1699194480.0","content":"Selected Answer: AC\nBased on the official documentation correct answer seems to be AC\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/content-moderator/text-moderation-api","poster":"rdemontis","comment_id":"1062976","upvote_count":"1"},{"comment_id":"920314","timestamp":"1686439800.0","poster":"ziggy1117","content":"Selected Answer: AC\nanswer is correct:\nhttps://westus.dev.cognitive.microsoft.com/docs/services/57cf753a3f9b070c105bd2c1/operations/57cf753a3f9b070868a1f66f\n\nrequest parameters: PII and classify","upvote_count":"3"},{"poster":"ziggy1117","timestamp":"1686040260.0","content":"answer is correct:\nhttps://westus.dev.cognitive.microsoft.com/docs/services/57cf753a3f9b070c105bd2c1/operations/57cf753a3f9b070868a1f66f\n\nrequest parameters: PII and classify","upvote_count":"2","comment_id":"916052"},{"comment_id":"910961","upvote_count":"4","poster":"EliteAllen","content":"Selected Answer: AC\nBased on the information from the official Azure Cognitive Services documentation, it seems that the Text Moderation API indeed returns profanity terms and personal data (A), which can be used for content moderation. It also performs text classification (C), which can be used to categorize and filter content.\n\nSo, the correct answers according to the official Azure documentation are A. personal data and C. text classification.","timestamp":"1685517720.0"},{"poster":"examworld","content":"Image Moderation API\n\nScan images and detect potential adult and racy content by using tags, confidence scores, and other extracted information. \n\nText Moderation API\n\nScan text content. Profanity terms and personal data are returned.","timestamp":"1685411100.0","upvote_count":"1","comment_id":"909811"},{"content":"Answer is correct. \nThe reference URL:\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/content-moderator/api-reference","timestamp":"1684732320.0","poster":"DDD6","upvote_count":"5","comment_id":"903722"}],"question_text":"You have a text-based chatbot.\n\nYou need to enable content moderation by using the Text Moderation API of Content Moderator.\n\nWhich two service responses should you use? Each correct answer presents part of the solution.\n\nNOTE: Each correct selection is worth one point."},{"id":"MzfIUXsxoAMUexLknZmK","discussion":[{"upvote_count":"30","timestamp":"1689579480.0","comment_id":"953922","content":"Should be NYN:\n\nhttps://learn.microsoft.com/en-us/dotnet/api/azure.ai.textanalytics.textanalyticsclient.recognizeentities?view=azure-dotnet\n\nDefinition:\nRuns a predictive model to identify a collection of named entities in the passed-in document, and categorize those entities into types such as person, location, or organization.\n\nThis method does not extract phrases.","poster":"StrateqEBS","comments":[{"timestamp":"1694515020.0","comment_id":"1005649","poster":"[Removed]","content":"The last one is clear \"Will output all key phrases on the console\" and we have on the example Console.WriteLine($\"\\t{entity.text}\") - With (\\t) tabs","upvote_count":"1"},{"timestamp":"1699195320.0","content":"Agree with you. Particularly for the last point we are using the RecognizeEntities method that is used for NER purposes. And the we loop in to the list of entities.\nhttps://github.com/Azure/azure-sdk-for-net/blob/main/sdk/textanalytics/Azure.AI.TextAnalytics/samples/Sample4_RecognizeEntities.md\n\nFor Key-Phrase extraction there is another method \"ExtractKeyPhrases\"\nhttps://github.com/Azure/azure-sdk-for-net/blob/main/sdk/textanalytics/Azure.AI.TextAnalytics/samples/Sample3_ExtractKeyPhrases.md\n\nfor key-phrases","poster":"rdemontis","comment_id":"1062995","upvote_count":"6"},{"upvote_count":"3","content":"Correct! Examples:\nOutput NER: trip, Seattle, last week\nhttps://learn.microsoft.com/en-us/azure/ai-services/language-service/named-entity-recognition/quickstart?tabs=ga-api&pivots=programming-language-csharp#output\n\nOutput Key phrase extraction: modern medical office, Dr. Smith, great staff\nhttps://learn.microsoft.com/en-us/azure/ai-services/language-service/key-phrase-extraction/quickstart?pivots=programming-language-csharp#output","comment_id":"996848","timestamp":"1693654440.0","poster":"M25"}]},{"upvote_count":"11","timestamp":"1688215860.0","content":"NYY is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/language-service/named-entity-recognition/overview\nNamed Entity Recognition (NER) is one of the features offered by Azure Cognitive Service for Language, a collection of machine learning and AI algorithms in the cloud for developing intelligent applications that involve written language. The NER feature can identify and categorize entities in unstructured text. For example: people, places, organizations, and quantities.","comments":[{"comment_id":"1169275","upvote_count":"7","content":"But entities are not the same as key phrases. A key phrase here could be 'Tour of Paris' which doesn't coincide with the entities. So I think the last one should be N.","comments":[{"comment_id":"1192497","poster":"ProfessorZ","timestamp":"1712696940.0","content":"https://learn.microsoft.com/en-us/azure/ai-services/language-service/named-entity-recognition/quickstart?tabs=ga-api&pivots=programming-language-csharp\nExample output shows \"last week\" as text output:\n\nNamed Entities:\n Text: trip, Category: Event, Sub-Category:\n Score: 0.74, Length: 4, Offset: 18\n\n Text: Seattle, Category: Location, Sub-Category: GPE\n Score: 1.00, Length: 7, Offset: 26\n\n Text: **last week**, Category: DateTime, Sub-Category: DateRange","upvote_count":"1"}],"poster":"Mehe323","timestamp":"1709960160.0"}],"comment_id":"939942","poster":"zellck"},{"comment_id":"1358527","poster":"syupwsh","content":"In order from top to bottom\n\nNo is CORRECT. The function recognize_entities is designed to check named entities but the words \"our\" and \"included\" are not named entities and hence will not be included in the output.\n\nYes is CORRECT. If we check what the function is doing it is designed to find the recognized entity and both “Paris” and “Eiffel Tower” are recognized entities. Hence this will be there in the response generated.\n\nNo is CORRECT because the function GetKeyWords utilizes the RecognizeEntities method from the Azure Text Analytics service. This method is specifically designed to identify named entities in the text, such as locations, organizations, and people. It does not extract key phrases, which would typically be broader and might include significant terms or concepts within the text.","timestamp":"1739926440.0","upvote_count":"1"},{"comments":[{"content":"On closer look at this trick (e.v.i.l) question, I will answer No for Eiffel and Tower as separate. \nUnder location there is : \nStructural - Manmade structures - en (supported language)\n\nSo, I assume the question creator read this and thought it can be used to trick people","timestamp":"1725909300.0","upvote_count":"1","poster":"famco","comment_id":"1281210"}],"upvote_count":"1","poster":"famco","comment_id":"1281206","timestamp":"1725908880.0","content":"I'm not sure if it is going to be Eiffel and Tower or just \"Eiffel Tower\""},{"poster":"JakeCallham","timestamp":"1725031620.0","upvote_count":"2","content":"I beleive NNN. Second is N because it will output two keys, not three.","comments":[{"upvote_count":"1","comments":[{"upvote_count":"1","content":"Why will they be split. Eiffel tower is identified as a man-made structure under location-structural.","timestamp":"1725909540.0","comment_id":"1281213","poster":"famco"}],"poster":"JakeCallham","timestamp":"1725031920.0","comment_id":"1275147","content":"i get back to it: You're correct. Based on the given C# code using TextAnalyticsClient and the provided input string, the output would indeed include the words \"Paris\", \"Eiffel\", and \"Tower\". Let's break this down:\n\nThe function getkeywords takes a TextAnalyticsClient and a string as input.\nIt uses the RecognizeEntities method (note: there's a typo in the original code; it should be RecognizeEntities, not RecognizeEntitites) to analyze the text.\nThe input string is: \"Our tour of Paris included a visit to the Eiffel Tower\"\nThe TextAnalyticsClient's entity recognition would identify named entities in this text.\n\"Paris\" is recognized as a location entity.\n\"Eiffel Tower\" is recognized as a landmark entity, which would be split into two separate entities: \"Eiffel\" and \"Tower\"."}],"comment_id":"1275145"},{"timestamp":"1723519200.0","poster":"anto69","content":"Must be N-Y-N, these are named entities","comment_id":"1264950","upvote_count":"1"},{"poster":"moonlightc","comment_id":"1261887","upvote_count":"4","timestamp":"1722992820.0","content":"It should be NNN\n\nAccording to ChatGPT\n\nKey words:\n Paris\n Eiffel Tower"},{"timestamp":"1716983160.0","comment_id":"1220880","content":"No\nYes\nNo","poster":"omankoman","upvote_count":"3"},{"content":"on exam, NYN. For the last one I selected N because the method looks like it's extracting entities, not key phrases.","timestamp":"1716543840.0","upvote_count":"4","poster":"funny_penguin","comment_id":"1217361"},{"timestamp":"1716386940.0","content":"NYN is right answer.","poster":"takaimomoGcup","comment_id":"1215790","upvote_count":"3"},{"timestamp":"1711826100.0","content":"The function will output all the key phrases from the input string to the console. No, the function will output the recognized entities, not all key phrases. Key phrases could include other important words or phrases in the text that are not necessarily entities. For key phrase extraction, a different method would be used.","comment_id":"1186324","poster":"Murtuza","upvote_count":"2"},{"upvote_count":"2","poster":"Murtuza","comment_id":"1177342","timestamp":"1710854040.0","content":"For the last choice that seems to be a topic of dicussion \nConsole Output:\nThe code prints the header “Key words:” to the console.\nIt then iterates through the response.Value (presumably a collection of categorized entites"},{"upvote_count":"3","content":"Agree NYN","poster":"lastget","timestamp":"1704716820.0","comment_id":"1116600"},{"poster":"katrang","upvote_count":"1","timestamp":"1697697660.0","comment_id":"1047623","content":"I think NYY. I could not see where all keywords would be output, but after checking the documentation they would also be identified as entities along with the Eiffel Tower (tour, paris and visit)"},{"poster":"973b658","upvote_count":"1","content":"It is true.","timestamp":"1686726300.0","comment_id":"922825","comments":[{"upvote_count":"2","comment_id":"1235110","poster":"anjanc","content":"not sure why this guy writes 'it is true' for all questions!!!","timestamp":"1719032460.0"}]}],"url":"https://www.examtopics.com/discussions/microsoft/view/112136-exam-ai-102-topic-3-question-48-discussion/","exam_id":40,"answers_community":[],"timestamp":"2023-06-14 09:05:00","unix_timestamp":1686726300,"answer_ET":"","isMC":false,"question_id":165,"topic":"3","question_text":"HOTSPOT -\n\nYou are developing a text processing solution.\n\nYou have the function shown below.\n\n//IMG//\n\n\nFor the second argument, you call the function and specify the following string.\n\nOur tour of Paris included a visit to the Eiffel Tower\n\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\n\n//IMG//","question_images":["https://img.examtopics.com/ai-102/image52.png","https://img.examtopics.com/ai-102/image53.png"],"answer_description":"","answer":"","answer_images":["https://img.examtopics.com/ai-102/image220.png"]}],"exam":{"name":"AI-102","isMCOnly":false,"numberOfQuestions":329,"provider":"Microsoft","isImplemented":true,"id":40,"isBeta":false,"lastUpdated":"12 Apr 2025"},"currentPage":33},"__N_SSP":true}