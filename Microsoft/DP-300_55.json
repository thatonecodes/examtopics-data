{"pageProps":{"questions":[{"id":"4H90x3ErT3oo2JKNpySB","isMC":true,"answer":"A","timestamp":"2021-11-10 19:29:00","answer_images":[],"answers_community":[],"question_images":[],"answer_description":"An Azure Data Factory can trigger a Databricks notebook.\nReference:\nhttps://docs.microsoft.com/en-us/azure/data-factory/transform-data-using-databricks-notebook","question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou have an Azure Data Lake Storage account that contains a staging zone.\nYou need to design a daily process to ingest incremental data from the staging zone, transform the data by executing an R script, and then insert the transformed data into a data warehouse in Azure Synapse Analytics.\nSolution: You use an Azure Data Factory schedule trigger to execute a pipeline that executes an Azure Databricks notebook, and then inserts the data into the data warehouse.\nDoes this meet the goal?","url":"https://www.examtopics.com/discussions/microsoft/view/65793-exam-dp-300-topic-5-question-8-discussion/","topic":"5","exam_id":68,"answer_ET":"A","unix_timestamp":1636568940,"choices":{"A":"Yes","B":"No"},"question_id":271,"discussion":[{"comment_id":"863979","poster":"U_C","content":"Yes, this solution meets the goal. By using an Azure Data Factory schedule trigger to execute a pipeline that executes an Azure Databricks notebook, you can transform the data from the staging zone in your Azure Data Lake Storage account. Then, by inserting the data into the data warehouse in Azure Synapse Analytics, you can complete the daily process of ingesting incremental data. So, the answer is A. Yes.","upvote_count":"2","timestamp":"1728311160.0"},{"poster":"Ciupaz","timestamp":"1713260340.0","content":"Not related to DP-300 exam.","comment_id":"696151","upvote_count":"1"},{"upvote_count":"1","comments":[{"comment_id":"658534","upvote_count":"1","content":"Sorry ignore my comment, it should be A. Yes.\nDatabricks can run R script Notebook. \nhttps://docs.databricks.com/spark/latest/sparkr/index.html","poster":"Icyb3r","timestamp":"1709487480.0"}],"content":"In the Question mentioned \"Execute R script\" not \"executes an Azure Databricks notebook\" \nThe correct answer should be - B (No)","timestamp":"1709480340.0","poster":"Icyb3r","comment_id":"658527"},{"timestamp":"1696164960.0","poster":"cusman","upvote_count":"2","comment_id":"579516","content":"DP-203"},{"poster":"o2091","timestamp":"1683736140.0","upvote_count":"2","comment_id":"475702","content":"looks correct"}]},{"id":"r9QjSvquzJLanCw3ek96","question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou have an Azure Data Lake Storage account that contains a staging zone.\nYou need to design a daily process to ingest incremental data from the staging zone, transform the data by executing an R script, and then insert the transformed data into a data warehouse in Azure Synapse Analytics.\nSolution: You use an Azure Data Factory schedule trigger to execute a pipeline that copies the data to a staging table in the data warehouse, and then uses a stored procedure to execute the R script.\nDoes this meet the goal?","answer_images":[],"isMC":true,"question_images":[],"choices":{"A":"Yes","B":"No"},"answer_description":"","discussion":[{"comment_id":"579517","poster":"cusman","content":"DP-203","timestamp":"1664628960.0","upvote_count":"8"},{"timestamp":"1720526760.0","content":"Selected Answer: B\nTransform Data using R Script: The solution suggests using a stored procedure to execute the R script. While stored procedures can be used for certain types of processing, executing an R script might be more efficiently done using tools that natively support R, such as Azure Machine Learning Services or Azure Databricks.","comment_id":"1117543","upvote_count":"2","poster":"dakku987"},{"timestamp":"1696689000.0","upvote_count":"2","content":"B. No.\n\nThe solution described does not fully meet the stated goal. While it includes a pipeline to copy data to a staging table in the data warehouse, it does not account for the incremental nature of the data. Additionally, using a stored procedure to execute the R script may not be the most efficient approach for transforming the data.","poster":"U_C","comment_id":"863985"},{"upvote_count":"1","content":"Selected Answer: A\nA. Yes.\n\nThis solution meets the goal of ingesting incremental data from the staging zone, transforming the data using an R script, and inserting the transformed data into a data warehouse in Azure Synapse Analytics. By using Azure Data Factory to copy the data to a staging table in the data warehouse, and then using a stored procedure to execute the R script, you can ensure that the data is transformed correctly before it is inserted into the data warehouse. Additionally, using a stored procedure can help simplify the pipeline and reduce maintenance efforts, since the R script can be updated in a single location","timestamp":"1693716120.0","poster":"KIET2131","comment_id":"827717"},{"poster":"Ciupaz","comment_id":"717436","timestamp":"1683991380.0","upvote_count":"3","content":"This question is not for DBA (DP-300 exam)."},{"upvote_count":"3","poster":"Icyb3r","content":"Selected Answer: B\nInsert to DWH comes after the Execution of R script, so the correct Answer should be (B. No)","timestamp":"1677860160.0","comment_id":"658562"},{"comment_id":"532333","content":"Selected Answer: A\nSeems right\nhttps://docs.microsoft.com/en-us/sql/machine-learning/tutorials/quickstart-r-create-script?view=sql-server-ver15\nBy default, sp_execute_external_script accepts a single dataset as input, which typically you supply in the form of a valid SQL query. It then returns a single R data frame as output.","timestamp":"1658766780.0","upvote_count":"1","poster":"CaptainJameson"},{"content":"looks correct","timestamp":"1652200140.0","poster":"o2091","comment_id":"475704","upvote_count":"1"}],"exam_id":68,"answer_ET":"B","timestamp":"2021-11-10 19:29:00","question_id":272,"answers_community":["B (71%)","A (29%)"],"url":"https://www.examtopics.com/discussions/microsoft/view/65795-exam-dp-300-topic-5-question-9-discussion/","unix_timestamp":1636568940,"answer":"B","topic":"5"},{"id":"pBtdj0BkhoHuPsaQFTxG","question_text":"You plan to move two 100-GB databases to Azure.\nYou need to dynamically scale resources consumption based on workloads. The solution must minimize downtime during scaling operations.\nWhat should you use?","question_id":273,"isMC":true,"answer_description":"","answer":"A","answers_community":["A (100%)"],"answer_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/34461-exam-dp-300-topic-6-question-1-discussion/","timestamp":"2020-10-14 14:40:00","question_images":[],"discussion":[{"upvote_count":"11","comment_id":"206583","content":"Option is correct because he is asking for Two Databases, and to reduce the resource the best is to use an elastic pool with a certain number of eDTUs that are shared among multiple databases in the pool\nNote:\nDynamic scalability is different from autoscale. Autoscale is when a service scales automatically based on criteria, whereas dynamic scalability allows for manual scaling with a minimal downtime.","timestamp":"1619461980.0","poster":"MustafaElmasry"},{"comment_id":"1199021","timestamp":"1729413540.0","poster":"sca88","content":"Selected Answer: A\nA should be correct. The two database can share resources of the elastic pool.","upvote_count":"1"},{"content":"If it had been \"Azure SQL Database serverless\" then I would pick it. But it is just \"Azure SQL Database\".\n\nSo go with A. \"Elastic pool\"","upvote_count":"1","poster":"voodoo_sh","timestamp":"1720090500.0","comment_id":"1113687"},{"upvote_count":"1","content":"A. An Azure SQL Database elastic pool","timestamp":"1692764700.0","poster":"KIET2131","comment_id":"818860"},{"poster":"louisaok","upvote_count":"1","comment_id":"792492","timestamp":"1690692540.0","content":"You should use Azure SQL Database elastic pools for the two 100-GB databases to dynamically scale resources consumption based on workloads and minimize downtime during scaling operations. Azure SQL Database elastic pools enable you to manage multiple databases as a single unit and share resources dynamically based on the workload of each database, reducing the administrative overhead of managing individual databases and minimizing downtime during scaling operations."},{"timestamp":"1688733480.0","content":"The elastic pool will dynamically scale each database based on the demand.\n\nhttps://mattou07.net/posts/reduce-your-azure-sql-server-costs-with-elastic-pools/","upvote_count":"1","poster":"OneplusOne","comment_id":"768636"},{"upvote_count":"1","content":"I'm not convinced we need Elastic Pool. Elastic Pool is good to use when we want two or more DBs to share resources (especially if they don't peak at the same time). Elastic Pool DOES NOT support Auto Scaling . I think we should use Azure SQL DBs (two DBs). it supports auto scaling and with minimal downtime. The correct Answer is D.\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/scale-resources?view=azuresql","poster":"TheDataGuy","timestamp":"1688059920.0","comment_id":"761415"},{"content":"Selected Answer: A\nCorrect answer A","upvote_count":"3","comment_id":"529370","timestamp":"1658429040.0","poster":"Chunchi"},{"poster":"learnazureportal","timestamp":"1644818640.0","content":"The correct Answer is A. not b/c we are planning to migrate TWO dbs. b/c \"dynamically scale resources consumption based on workloads.\" only works for option A.","upvote_count":"2","comment_id":"424616"},{"comment_id":"296923","poster":"Corbiz","comments":[{"content":"The solution must minimize downtime during scaling operations.","timestamp":"1654428060.0","upvote_count":"1","poster":"ramelas","comment_id":"494350"}],"content":"Answer: A, C and D are correct.\nAzure SQL Database and SQL Managed Instance enable you to dynamically add more resources to your database with minimal downtime.\nAzure SQL Database offers the ability to dynamically scale your databases:\n• With a single database, you can use either DTU or vCore models to define maximum amount of resources that will be assigned to each database.\n• Elastic pools enable you to define maximum resource limit per group of databases in the pool.\nAzure SQL Managed Instance allows you to scale as well:\n• SQL Managed Instance uses vCores mode and enables you to define maximum CPU cores and maximum of storage allocated to your instance. All databases within the managed instance will share the resources allocated to the instance\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/scale-resources","timestamp":"1629654420.0","upvote_count":"1"},{"poster":"bnc","timestamp":"1626973560.0","comment_id":"273943","upvote_count":"4","content":"I really dislike questions like this. You'd almost always choose Azure SQL over MI unless there's a compat reason. Putting 2 databases in an elastic pool is typically counterproductive cost-wise, but since the question is only about downtime, both A and D have similar latency in scaling. SQL MI can scale also, but not as fast as Azure SQL DB. Finally, Azure SQL DB using serverless (no elastic pool) can be considered since we don't know the workload. \n\nStaying within the same service level (standard to standard or gp to gp) will be the fastest for 100GB databases, as data is not copied and detached/attached. Moving between tiers is quite a bit slower (gp -> bc). Here, hyperscale offers the all around fastest rescale time, so even though you don't *need* hyperscale for size, the only thing being asked is, \"which scales fastest?\" Since hyperscale is a service tier of Azure SQL DB, I think D is correct as it offers the most options. \n\nRefer to latency chart:\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/elastic-pool-scale"},{"comment_id":"222593","poster":"Dhiva_","timestamp":"1621406100.0","upvote_count":"4","content":"For me it's A, since they stated two databases"},{"poster":"MustafaElmasry","content":"Azure SQL Managed Instance allows you to scale as well:\n\nSQL Managed Instance uses vCores mode and enables you to define maximum CPU cores and maximum of storage allocated to your instance. All databases within the managed instance will share the resources allocated to the instance","comment_id":"206585","timestamp":"1619462040.0","upvote_count":"1"},{"comment_id":"199781","poster":"Dexter13","upvote_count":"1","content":"I would say D since you need Hyperscale which is type of Azure SQL DB","timestamp":"1618404000.0","comments":[{"poster":"Frisco","content":"Two databases with a size of 100GB, not 100 TB. Hyperscale isn't needed.","comment_id":"206506","upvote_count":"11","timestamp":"1619455320.0"}]}],"answer_ET":"A","unix_timestamp":1602679200,"choices":{"C":"an Azure SQL Database managed instance","B":"SQL Server on Azure virtual machines","D":"Azure SQL databases","A":"An Azure SQL Database elastic pool"},"exam_id":68,"topic":"6"},{"id":"vq87X15LtiUqDCXUU2TS","timestamp":"2020-10-28 01:17:00","answer_ET":"A","discussion":[{"comment_id":"207354","content":"Answer seems true","timestamp":"1603844220.0","poster":"MediMedi","upvote_count":"13"},{"content":"Selected Answer: B\nNo - there is only one readable replica in Premium and Business Critical service tiers as per:\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/high-availability-sla-local-zone-redundancy?view=azuresql&tabs=azure-powershell#premium-and-business-critical-service-tier-zone-redundant-availability\n\"As an extra benefit, the local storage availability model includes the ability to redirect read-only Azure SQL connections to one of the secondary replicas.\"","upvote_count":"1","poster":"itops_dba","comment_id":"1313127","timestamp":"1731775380.0"},{"upvote_count":"2","poster":"Motanel","comment_id":"875344","timestamp":"1681973220.0","content":"Selected Answer: A\nBusiness Critical"},{"timestamp":"1672586760.0","upvote_count":"2","comment_id":"763236","poster":"TheDataGuy","content":"The answer is Yes according to this link:\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/high-availability-sla?view=azuresql&tabs=azure-powershell#premium-and-business-critical-service-tier-zone-redundant-availability"},{"comment_id":"568671","content":"Selected Answer: A\nYES\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/read-scale-out\nAs part of High Availability architecture, each single database, elastic pool database, and managed instance in the Premium and Business Critical service tier is automatically provisioned with a primary read-write replica and several secondary read-only replicas.","timestamp":"1647383820.0","upvote_count":"2","poster":"reachmymind"},{"timestamp":"1637763960.0","upvote_count":"1","comment_id":"486036","poster":"jerkyflexoff","content":"Answer I think YES.\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/high-availability-sla\nAs an extra benefit, the premium availability model includes the ability to redirect read-only Azure SQL connections to one of the secondary replicas. This feature is called Read Scale-Out. It provides 100% additional compute capacity at no extra charge to off-load read-only operations, such as analytical workloads, from the primary replica."},{"comment_id":"300566","comments":[{"upvote_count":"6","poster":"ETAN","timestamp":"1616120820.0","content":"your explaination is not right","comment_id":"314529"}],"content":"does not meet \"During normal operations, provide at least two readable copies of Sales.\"\nso NO","poster":"nkav","timestamp":"1614479760.0","upvote_count":"2"},{"poster":"themickou","comment_id":"287558","upvote_count":"4","content":"Ensure that Sales remains available if a datacenter fails. > true with availability zones because replicas are located in distant regions not the same datacenter","timestamp":"1612963560.0"}],"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou have an Azure SQL database named Sales.\nYou need to implement disaster recovery for Sales to meet the following requirements:\n✑ During normal operations, provide at least two readable copies of Sales.\n✑ Ensure that Sales remains available if a datacenter fails.\nSolution: You deploy an Azure SQL database that uses the Business Critical service tier and Availability Zones.\nDoes this meet the goal?","isMC":true,"question_images":[],"answers_community":["A (80%)","B (20%)"],"unix_timestamp":1603844220,"topic":"6","answer":"A","exam_id":68,"answer_description":"","answer_images":[],"choices":{"A":"Yes","B":"No"},"question_id":274,"url":"https://www.examtopics.com/discussions/microsoft/view/35328-exam-dp-300-topic-6-question-10-discussion/"},{"id":"2ogbqFtGfFHfImM4eeW8","choices":{"B":"No","A":"Yes"},"answer_description":"","answer_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/35329-exam-dp-300-topic-6-question-11-discussion/","exam_id":68,"discussion":[{"comments":[{"comment_id":"497550","content":"I agree with this answer, but the question is crappy. They don't suggest if still available is read only or read/write. To me available is, business as usual R/W a fail over would trigger read only availability.","upvote_count":"1","timestamp":"1686296580.0","poster":"jerkyflexoff"},{"comment_id":"332893","timestamp":"1665448260.0","content":"With auto-failover groups or geo-replication, you can use the replicas as read-only endpoint. Note that with General Purpose you only get one replica per failover group or geo-replica. With business critical, since there's also an AG involved, you can use the geo-replica's primary as well as the read only secondary, both as read only endpoints. \nAnswer is No.","comments":[{"content":"I am wrong. Answer is Yes.\nhttps://channel9.msdn.com/Series/Azure-SQL-for-Beginners/Geo-replication-and-Auto-failover-Groups-in-Azure-SQL-51-of-61","poster":"U_C","timestamp":"1666059660.0","comment_id":"337907","upvote_count":"1"}],"poster":"U_C","upvote_count":"1"}],"timestamp":"1660198560.0","content":"https://docs.microsoft.com/en-us/learn/modules/azure-sql-high-availability/7-higher-availablity-options you cannot have multiples replicas with auto failover and we need 2 here so NO","poster":"themickou","upvote_count":"11","comment_id":"288128"},{"content":"Answer is correct; though In the Premium and Business Critical service tiers, applications could have \"read-only replicas\" at no extra cost, but \"read-only replicas \" is disabled at cannot be enabled in Basic, Standard, or General Purpose service tiers ; https://docs.microsoft.com/en-us/azure/azure-sql/database/read-scale-out","poster":"ChengKuo","comment_id":"269156","upvote_count":"7","timestamp":"1658001600.0"},{"poster":"voodoo_sh","comment_id":"1366393","upvote_count":"1","timestamp":"1741390920.0","content":"Selected Answer: A\nI think the answer is Yes.\nFailover groups provide two readable copies of the database - one is primary, second is secondary.\n\np.s. Ofc question is open to interpretation - what they mean under two readable copies - is it 1 primary and two replicas of it, or it can be 2 servers (primary and secondary), both of which can be read from. Crappy question, bad work by whoever make it."},{"upvote_count":"1","comment_id":"1347482","poster":"voodoo_sh","timestamp":"1737998760.0","content":"Selected Answer: B\nIf by \"data center\" they mean just one zone in a region, not a whole region, then answer is No. \n\nFailover Groups replicate data to another region, and if primary region has an outage, database will not failover automatically 1 hour minimum. So database will be unavailable for some time. And requirements say Sales must remain available."},{"timestamp":"1729406820.0","comment_id":"875343","content":"Selected Answer: B\nB is correct","poster":"Motanel","upvote_count":"1"},{"comment_id":"568678","content":"Selected Answer: B\nNO as Fail-over Group provides only Primary & Secondary (only 1 read replica)\n\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/auto-failover-group-sql-db?tabs=azure-powershell","poster":"reachmymind","timestamp":"1694810580.0","upvote_count":"2"},{"comment_id":"333990","poster":"pm4certs","content":"Given answer is correct...though failover groups gives you secondary read copy of the data but in case of outage, your database won't be available as failover groups have a grace period of one hour so during that one hour, it might be down","comments":[{"upvote_count":"1","timestamp":"1675184760.0","content":"Because there are RW/RO listeners in failover group, the secondary replic is always available.","poster":"U_C","comment_id":"417922"}],"timestamp":"1665581640.0","upvote_count":"1"},{"content":"Answer: Yes\nReason: Auto-Failover group if created for a General Purpose service tier will create a replica in another region which will provide protection against datacenter disaster and Auto-failover group also supports read-scale so we get two read replica (primary replica which is read/write and Auto-failover replica in another region which is read-only replica).","upvote_count":"4","timestamp":"1659280740.0","comment_id":"280707","poster":"vicky007_87"},{"timestamp":"1658655960.0","comment_id":"275234","content":"I think the answer should be No. cause general purpose doesn't support HA with zone redundant. but we need to Ensure that Sales remains available if a datacenter fails. ref: https://docs.microsoft.com/en-us/azure/azure-sql/database/service-tiers-general-purpose-business-critical","poster":"ondemand","upvote_count":"1"},{"comment_id":"207355","poster":"MediMedi","upvote_count":"1","timestamp":"1651097880.0","comments":[{"upvote_count":"2","content":"Failover group wont. \"Auto-failover groups support replication of all databases in the group to only one secondary server or instance in a different region.\"\n\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/auto-failover-group-overview?tabs=azure-powershell","comments":[{"timestamp":"1658004540.0","upvote_count":"3","comment_id":"269163","comments":[{"content":"It will depends on what is the \"normal operations\" referring to; in case it includes the applications, the read replica is not supported ; but yes from Server instance perspective, with auto failover groups on there the secondary server db should be readable says from SSMS, it's hard to decide yes or not for this question","comment_id":"271752","upvote_count":"2","comments":[{"timestamp":"1658298600.0","content":"Did further search, general purpose tier can have 0 - 4 Read-only replicas using geo-replication which is auto configured by failover group, so the answer should be \"YES\"","poster":"ChengKuo","comment_id":"271829","upvote_count":"3"}],"poster":"ChengKuo","timestamp":"1658285940.0"}],"content":"Right, but the secondary is readable. So, the primary plus secondary would be two readable copies /during normal operations./","poster":"BobbyTables"}],"timestamp":"1653238620.0","poster":"adalfege","comment_id":"225155"}],"content":"Not clear if failover group would satisfy: at least two readable copies of Sales."}],"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou have an Azure SQL database named Sales.\nYou need to implement disaster recovery for Sales to meet the following requirements:\n✑ During normal operations, provide at least two readable copies of Sales.\n✑ Ensure that Sales remains available if a datacenter fails.\nSolution: You deploy an Azure SQL database that uses the General Purpose service tier and failover groups.\nDoes this meet the goal?","topic":"6","question_id":275,"timestamp":"2020-10-28 01:18:00","question_images":[],"answer":"B","answer_ET":"B","isMC":true,"unix_timestamp":1603844280,"answers_community":["B (80%)","A (20%)"]}],"exam":{"id":68,"isMCOnly":false,"isImplemented":true,"name":"DP-300","provider":"Microsoft","lastUpdated":"12 Apr 2025","numberOfQuestions":360,"isBeta":false},"currentPage":55},"__N_SSP":true}