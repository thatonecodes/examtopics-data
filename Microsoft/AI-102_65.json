{"pageProps":{"questions":[{"id":"JT8GGz0nm5SX8uXutZWq","timestamp":"2024-10-17 14:06:00","answer_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/149674-exam-ai-102-topic-8-question-3-discussion/","answer_ET":"CD","isMC":true,"question_id":321,"choices":{"D":"Azure AI Vision","E":"Azure AI Custom Vision","C":"Azure AI Content Safety","B":"Microsoft Defender for Cloud Apps","A":"Azure AI Document Intelligence"},"unix_timestamp":1729166760,"answer":"CD","topic":"8","answer_description":"","answers_community":["CD (83%)","C (17%)"],"exam_id":40,"question_images":[],"question_text":"You have an Azure subscription.\n\nYou are building a social media app that will enable users to share images.\n\nYou need to ensure that inappropriate content uploaded by the users is blocked. The solution must minimize development effort.\n\nWhat are two tools that you can use? Each correct answer presents a complete solution.\n\nNOTE: Each correct selection is worth one point.","discussion":[{"upvote_count":"5","content":"Selected Answer: CD\nThe question mentions \"must minimize development effort\". That means you should lean away from anything custom.\n\nAnswers are C and D.","poster":"3fbc31b","comment_id":"1314251","timestamp":"1731966780.0"},{"content":"Selected Answer: CD\nC&D are correct","upvote_count":"1","comment_id":"1400440","poster":"Mattt","timestamp":"1742375400.0"},{"content":"Selected Answer: CD\nAzure AI Content Safety is CORRECT because it is specifically designed to detect and filter out harmful or inappropriate content across various media types, including images. It provides built-in moderation capabilities that minimize the development effort needed to ensure compliance with safety guidelines, making it suitable for scenarios like social media apps where user-generated content needs to be monitored.\n\nAzure AI Vision is CORRECT because it includes capabilities for analyzing images, such as detecting objects, faces, and content features that may be inappropriate. It can be used to perform image analysis and integrate content moderation capabilities into applications with minimal custom development. While not a dedicated content safety tool, it can be configured to identify certain types of inappropriate content, such as explicit or offensive imagery.\n\nC and D are correct","upvote_count":"1","comment_id":"1354817","timestamp":"1739244360.0","poster":"syupwsh"},{"upvote_count":"1","timestamp":"1730175240.0","comment_id":"1304286","content":"A, D \nhttps://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-detecting-adult-content","comments":[{"poster":"tae893","timestamp":"1730175300.0","comment_id":"1304287","content":"Sorry C, D is correct","upvote_count":"2"}],"poster":"tae893"},{"timestamp":"1730158740.0","upvote_count":"2","comment_id":"1304223","content":"Selected Answer: CD\nCorrect answers are C and D, verified using CoPilot:\n\nThe two tools you can use to ensure inappropriate content is blocked while minimizing development effort are:\n\nC. Azure AI Content Safety and D. Azure AI Vision.\n\nAzure AI Content Safety provides advanced algorithms for processing images and text to detect and block harmful content. Azure AI Vision offers computer vision capabilities to analyze images and detect inappropriate content","poster":"a8da4af"},{"timestamp":"1730105940.0","content":"CD\nhttps://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-detecting-adult-content","comment_id":"1303891","upvote_count":"1","poster":"Fefnut"},{"poster":"e41f7aa","upvote_count":"1","content":"Selected Answer: CD\nAnswer is C & D","timestamp":"1730099400.0","comment_id":"1303856"},{"poster":"jafaca","comment_id":"1299194","upvote_count":"2","timestamp":"1729166760.0","content":"Selected Answer: C\nAzure AI Vision & Content Safety"}]},{"id":"mzc3MSEArUTAm82cYixA","isMC":false,"answer_ET":"","unix_timestamp":1729523940,"answer_images":["https://img.examtopics.com/ai-102/image194.png"],"exam_id":40,"discussion":[{"upvote_count":"1","poster":"syupwsh","content":"contentsafety/ is CORRECT because Azure AI Content Safety is specifically designed to analyze text for harmful or unsafe content, including hateful language. Using contentsafety/ in the endpoint ensures that the appropriate API is called to evaluate the user request against predefined safety categories, such as hate speech.\n\ntext:analyze is CORRECT because it is used to evaluate the input text against safety categories like hate speech, violence, and other harmful content. This endpoint enables detailed analysis of the input text, identifying whether it contains hateful language or violates safety standards.","timestamp":"1739431620.0","comment_id":"1355999"},{"comment_id":"1315849","timestamp":"1732196460.0","content":"Answer is correct to https://learn.microsoft.com/en-us/azure/ai-services/content-safety/how-to/use-blocklist?tabs=windows%2Crest Blocklist is used in the http body as blocklistnames","poster":"Turst","upvote_count":"4"},{"content":"text:analyze - > https://learn.microsoft.com/en-us/azure/ai-services/content-safety/quickstart-text?tabs=visual-studio%2Cwindows&pivots=programming-language-rest#analyze-text-content","poster":"mrwiti","timestamp":"1731853980.0","upvote_count":"3","comment_id":"1313571"},{"content":"I think it's correct, contentsafety and then text:analyze","poster":"a8da4af","comment_id":"1304723","timestamp":"1730238840.0","upvote_count":"4"},{"timestamp":"1730020440.0","upvote_count":"2","comments":[{"content":"No, you need the text analyze service.","comment_id":"1331739","upvote_count":"1","timestamp":"1735174560.0","poster":"pabsinaz"}],"content":"2nd shloud be text/blocklists : https://learn.microsoft.com/en-us/azure/ai-services/content-safety/how-to/use-blocklist?tabs=windows%2Crest","poster":"4670ccc","comment_id":"1303530"}],"answers_community":[],"url":"https://www.examtopics.com/discussions/microsoft/view/149966-exam-ai-102-topic-8-question-4-discussion/","topic":"8","timestamp":"2024-10-21 17:19:00","answer":"","question_text":"HOTSPOT\n-\n\nYou have an Azure subscription that contains an Azure AI Content Safety resource named CS1.\n\nYou need to call CS1 to identify whether a user request contains hateful language.\n\nHow should you complete the command? To answer, select the appropriate options in the answer area.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","question_images":["https://img.examtopics.com/ai-102/image193.png"],"answer_description":"","question_id":322},{"id":"2rI4Ikz80dALOWvMdPcR","timestamp":"2024-10-21 17:19:00","topic":"8","exam_id":40,"answers_community":["B (87%)","13%"],"answer_ET":"B","question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou have an Azure subscription that contains an Azure OpenAI resource named AI1 and an Azure AI Content Safety resource named CS1.\n\nYou build a chatbot that uses AI1 to provide generative answers to specific questions and CS1 to check input and output for objectionable content.\n\nYou need to optimize the content filter configurations by running tests on sample questions.\n\nSolution: From Content Safety Studio, you use the Protected material detection feature to run the tests.\n\nDoes this meet the requirement?","question_images":[],"unix_timestamp":1729523940,"answer_description":"","choices":{"A":"Yes","B":"No"},"answer":"B","question_id":323,"url":"https://www.examtopics.com/discussions/microsoft/view/149967-exam-ai-102-topic-8-question-5-discussion/","isMC":true,"discussion":[{"timestamp":"1739244660.0","content":"Selected Answer: B\nNo is CORRECT. Protected material detection is focused on identifying sensitive content such as personal identifiable information (PII), copyright violations, and other legally protected materials. However, the question specifically asks about optimizing content filter configurations for objectionable content, such as inappropriate or harmful text, which is better addressed by using features like Safety metaprompt or the Moderate content feature within Azure Content Safety Studio.","poster":"syupwsh","upvote_count":"1","comment_id":"1354822"},{"comment_id":"1335116","content":"Selected Answer: B\nNo, using the Protected material detection feature from Content Safety Studio does not meet the requirement. The Protected material detection feature is designed to identify and manage sensitive or protected material, but it is not specifically intended for optimizing content filter configurations for objectionable content in a chatbot.\n\nTo optimize the content filter configurations for objectionable content, you should use the Moderate text content feature in Content Safety Studio. This feature is specifically designed to help you run tests on sample questions and check for objectionable content, ensuring that your chatbot's input and output adhere to safety and quality standards.","poster":"pabsinaz","timestamp":"1735711140.0","upvote_count":"4"},{"comment_id":"1330063","poster":"Jegababu","timestamp":"1734790560.0","upvote_count":"2","content":"Selected Answer: B\nhttps://learn.microsoft.com/en-us/azure/ai-services/content-safety/concepts/protected-material?tabs=text#user-scenarios"},{"upvote_count":"3","timestamp":"1734113100.0","comment_id":"1326210","content":"Selected Answer: B\nBut if using the true definition of objectionable (unpleasant or offensive) then the choice is No as this would be the text analyze api. Protected material is meant to block copyrighted material from being used in responses","poster":"Andriki"},{"upvote_count":"3","poster":"chrillelundmark","content":"Selected Answer: B\nhttps://learn.microsoft.com/en-us/azure/ai-services/content-safety/overview#product-features","comment_id":"1323091","timestamp":"1733573640.0"},{"upvote_count":"1","content":"B is Correct , here's what chatGPT says:\n\nThe answer is B. No.\n\nHere’s why:\n\nThe Protected material detection feature in Content Safety Studio is typically designed to detect and monitor sensitive or protected content, but it may not directly apply to optimizing the filter configurations for a chatbot. To test content filtering settings specifically for objectionable or harmful content in AI-generated responses, you would likely use Content Safety’s standard filtering features directly on the input and output of the chatbot, rather than the Protected material detection feature.\n\nFor optimizing content filters, you would test using sample questions and responses in Content Safety Studio’s primary filtering and moderation tools, where you can review and adjust configurations.","poster":"a8da4af","comment_id":"1304728","timestamp":"1730239560.0"},{"timestamp":"1729966680.0","poster":"Slapp1n","content":"Selected Answer: A\nThe answer should be Yes: \n\nThe solution involves using the \"Protected material detection\" feature from Content Safety Studio to optimize content filter configurations by running tests on sample questions. This approach meets the requirement for testing and optimizing content safety configurations for generative AI output, ensuring that objectionable content is properly detected and managed.","comment_id":"1303377","upvote_count":"2"}],"answer_images":[]},{"id":"tEOMImYaPxAEXDebJATX","answer_description":"","unix_timestamp":1729523940,"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou have an Azure subscription that contains an Azure OpenAI resource named AI1 and an Azure AI Content Safety resource named CS1.\n\nYou build a chatbot that uses AI1 to provide generative answers to specific questions and CS1 to check input and output for objectionable content.\n\nYou need to optimize the content filter configurations by running tests on sample questions.\n\nSolution: From Content Safety Studio, you use the Moderate text content feature to run the tests.\n\nDoes this meet the requirement?","url":"https://www.examtopics.com/discussions/microsoft/view/149968-exam-ai-102-topic-8-question-6-discussion/","topic":"8","question_images":[],"answer":"A","question_id":324,"isMC":true,"discussion":[{"poster":"syupwsh","comment_id":"1354823","upvote_count":"1","timestamp":"1739244720.0","content":"Selected Answer: A\nYes is CORRECT because the Moderate text content feature in Content Safety Studio allows you to test and optimize the content filter configurations by evaluating sample text for objectionable content. This meets the requirement to run tests on sample questions and refine the configurations for the chatbot's content safety.\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/content-safety/overview#content-safety-studio-features"},{"comment_id":"1335115","content":"Selected Answer: A\nUsing the Moderate text content feature from Content Safety Studio to run tests on sample questions does meet the requirement. This approach allows you to analyze and optimize the content filter configurations effectively by ensuring that the input and output are checked for objectionable content. This helps in maintaining the quality and safety of the responses generated by the chatbot.","timestamp":"1735711020.0","upvote_count":"2","poster":"pabsinaz"},{"content":"The answer is A. Yes.\n\nExplanation:\n\nThe Moderate text content feature in Content Safety Studio is designed to detect objectionable or harmful content in text. By using this feature, you can effectively test and optimize content filtering configurations by running sample questions and analyzing the responses for inappropriate content. This approach meets the requirement of optimizing the content filter configurations for your chatbot's input and output.","timestamp":"1730239620.0","comment_id":"1304729","poster":"a8da4af","upvote_count":"4"}],"answer_ET":"A","answers_community":["A (100%)"],"answer_images":[],"timestamp":"2024-10-21 17:19:00","exam_id":40,"choices":{"B":"No","A":"Yes"}},{"id":"HvqiyXrVHQh9iTubV6sS","choices":{"A":"Yes","B":"No"},"answer":"B","answer_ET":"B","question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou have an Azure subscription that contains an Azure OpenAI resource named AI1 and an Azure AI Content Safety resource named CS1.\n\nYou build a chatbot that uses AI1 to provide generative answers to specific questions and CS1 to check input and output for objectionable content.\n\nYou need to optimize the content filter configurations by running tests on sample questions.\n\nSolution: From Content Safety Studio, you use the Monitor online activity feature to run the tests.\n\nDoes this meet the requirement?","discussion":[{"timestamp":"1739244780.0","content":"Selected Answer: B\nNo is CORRECT. The Monitor online activity feature in Content Safety Studio is used for real-time monitoring and analyzing live content streams but is not designed for running tests on sample questions to optimize content filter configurations. To meet the requirement, you should use the Test or Analyze features within Content Safety Studio, which are specifically designed for testing and adjusting content filter configurations on sample data.","upvote_count":"1","poster":"syupwsh","comment_id":"1354824"},{"timestamp":"1733573280.0","content":"Selected Answer: B\nhttps://learn.microsoft.com/en-us/azure/ai-services/content-safety/overview#content-safety-studio-features","comment_id":"1323089","poster":"chrillelundmark","upvote_count":"2"},{"comment_id":"1304730","upvote_count":"1","timestamp":"1730239680.0","content":"The answer is B. No.\n\nExplanation:\n\nThe Monitor online activity feature in Content Safety Studio is typically used for tracking and analyzing real-time online activities, which is not directly related to testing or optimizing content filtering configurations on sample questions. To optimize and test content filters for a chatbot, you would use features like Moderate text content that are specifically designed for detecting objectionable content in text inputs and outputs. Therefore, this solution does not meet the requirement.","poster":"a8da4af"}],"answer_description":"","topic":"8","timestamp":"2024-10-21 17:19:00","answers_community":["B (100%)"],"answer_images":[],"isMC":true,"exam_id":40,"question_id":325,"unix_timestamp":1729523940,"question_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/149969-exam-ai-102-topic-8-question-7-discussion/"}],"exam":{"isMCOnly":false,"isBeta":false,"lastUpdated":"12 Apr 2025","numberOfQuestions":329,"id":40,"provider":"Microsoft","isImplemented":true,"name":"AI-102"},"currentPage":65},"__N_SSP":true}