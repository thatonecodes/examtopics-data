{"pageProps":{"questions":[{"id":"HvmFlet0e2l75ZyDSwu6","isMC":true,"question_text":"You train a model and register it in your Azure Machine Learning workspace. You are ready to deploy the model as a real-time web service.\nYou deploy the model to an Azure Kubernetes Service (AKS) inference cluster, but the deployment fails because an error occurs when the service runs the entry script that is associated with the model deployment.\nYou need to debug the error by iteratively modifying the code and reloading the service, without requiring a re-deployment of the service for each code update.\nWhat should you do?","topic":"4","question_id":376,"answer_images":[],"discussion":[{"comments":[{"timestamp":"1731825480.0","upvote_count":"1","content":"will this violates the requirement \"without requiring a re-deployment of the service for each code update\"","comment_id":"1212697","poster":"Shariq"}],"upvote_count":"50","timestamp":"1612561260.0","poster":"Bizmaercq","comment_id":"151388","content":"The right answer is D.\n\nDeployment and runtime errors can be easier to diagnose by deploying the service as a container in a local Docker instance, like this:\nfrom azureml.core.webservice import LocalWebservice\n\ndeployment_config = LocalWebservice.deploy_configuration(port=8890)\nservice = Model.deploy(ws, 'test-svc', [model], inference_config, deployment_config)\n\nYou can then troubleshoot runtime issues by making changes to the scoring file that is referenced in the inference configuration, and reloading the service without redeploying it (something you can only do with a local service):\n\nservice.reload()\nprint(service.run(input_data = json_data))"},{"content":"D: If you encounter problems deploying a model to ACI or AKS, try deploying it as a local web service. Using a local web service makes it easier to troubleshoot problems. The Docker image containing the model is downloaded and started on your local system.\n\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-deployment","timestamp":"1614532080.0","upvote_count":"19","comment_id":"169330","poster":"111ssy"},{"content":"Selected Answer: D\nyou need to test and debug locally before deploying to prod. Check this link: https://learn.microsoft.com/en-us/azure/machine-learning/how-to-debug-managed-online-endpoints-visual-studio-code?view=azureml-api-2&tabs=cli","timestamp":"1732907280.0","upvote_count":"1","comment_id":"1221142","poster":"sl_mslconsulting"},{"comment_id":"987410","upvote_count":"2","poster":"Mal42","content":"On exam Aug 18 2023","timestamp":"1708609620.0"},{"poster":"phdykd","comment_id":"964230","upvote_count":"1","content":"D. D. Create a local web service deployment configuration and deploy the model to a local Docker container.\n\nThis option provides a flexible and quick environment for debugging and testing. Using a local Docker container, you can quickly change the code in your entry script and immediately see the effect of your changes without going through the entire deployment process on Azure Kubernetes Service (AKS) or Azure Container Instances (ACI). Once you've debugged your entry script locally, you can then deploy it to AKS.","timestamp":"1706320260.0"},{"content":"C. Add a breakpoint to the first line of the entry script and redeploy the service to AKS.\nAdding a breakpoint to the first line of the entry script and redeploying the service to AKS will allow you to iteratively modify and test the code without requiring a re-deployment of the service for each code update. This will enable you to identify and fix the error in the entry script, without having to repeatedly deploy the service, saving time and resources. You can use tools like Visual Studio Code or PyCharm to attach a debugger to the running service, set a breakpoint on the first line of the entry script, and then use the debugger to step through the code and identify the error. Once you have identified and fixed the error, you can update the code, remove the breakpoint, and redeploy the service to AKS.","comment_id":"818464","timestamp":"1692733140.0","poster":"phdykd","upvote_count":"1"},{"upvote_count":"1","timestamp":"1684440960.0","comment_id":"721602","content":"Selected Answer: D\nThe right answer is D.","poster":"PremPatrick"},{"timestamp":"1665531720.0","comment_id":"584445","upvote_count":"2","poster":"pancman","content":"Selected Answer: D\nIf you encounter problems deploying a model to ACI or AKS, try deploying it as a local web service."},{"poster":"ljljljlj","upvote_count":"4","comment_id":"403952","timestamp":"1641910740.0","content":"On exam 2021/7/10"},{"timestamp":"1628632800.0","poster":"ZeeshanNawaz","upvote_count":"3","comment_id":"287931","content":"Correct answer should be D"},{"content":"D, agreed. ACI is for production of low resource models. 1GB size and 48 GB ram or less","poster":"hachascloud","comment_id":"280667","upvote_count":"3","timestamp":"1627741560.0"}],"timestamp":"2020-08-05 21:41:00","answers_community":["D (100%)"],"answer_description":"","answer_ET":"D","choices":{"C":"Add a breakpoint to the first line of the entry script and redeploy the service to AKS.","E":"Register a new version of the model and update the entry script to load the new version of the model from its registered path.","D":"Create a local web service deployment configuration and deploy the model to a local Docker container.","A":"Modify the AKS service deployment configuration to enable application insights and re-deploy to AKS.","B":"Create an Azure Container Instances (ACI) web service deployment configuration and deploy the model on ACI."},"question_images":[],"answer":"D","url":"https://www.examtopics.com/discussions/microsoft/view/27447-exam-dp-100-topic-4-question-19-discussion/","unix_timestamp":1596656460,"exam_id":64},{"id":"f3T2xWieEMa82xjf6o22","unix_timestamp":1616845140,"answer":"B","discussion":[{"content":"Answer is correct. AKS -> GPU support","comment_id":"321797","poster":"ACSC","timestamp":"1616845140.0","upvote_count":"19"},{"poster":"D0ktor","comment_id":"1314949","timestamp":"1732053480.0","content":"Selected Answer: B\nAKS is the solution","upvote_count":"1"},{"upvote_count":"1","comment_id":"1022000","poster":"Ran2025","timestamp":"1696135140.0","content":"B is correct! AKS supports real-time GPU-based inferencing\nhttps://learn.microsoft.com/en-gb/azure/machine-learning/concept-compute-target?view=azureml-api-2"},{"comment_id":"964073","poster":"phdykd","content":"B. Azure Kubernetes Service\n\nAzure Kubernetes Service (AKS) provides an option to create a GPU-enabled node pool which would be suitable for real-time GPU-based inferencing. The other services listed do not provide the same level of GPU support necessary for such operations.\n\nKeep in mind that setting up and managing a Kubernetes cluster does require some additional skills and setup compared to other Azure services, but it provides a high level of control and scalability.","timestamp":"1690394220.0","upvote_count":"1"},{"content":"The compute type that should be used for real-time GPU-based inferencing of a deep learning model is:\nD. Machine Learning Compute\n\nExplanation:\nTo enable GPU-based inferencing on a deployed model, Machine Learning Compute (MLC) should be used. MLC is a managed service provided by Azure Machine Learning that can provision compute resources for training and inferencing machine learning models. The service can be configured to allocate resources based on the required processing power, which can include GPU and CPU-based clusters.\n\nAzure Container Instance (A) is a compute service that allows for running containerized applications without managing the underlying infrastructure, but it does not provide GPU resources. Azure Kubernetes Service (B) is a container orchestration service that can be used to manage containerized applications but requires additional configuration to enable GPU-based inferencing. Field Programmable Gate Array (C) is a hardware device that can be used to implement specific logic circuits but is not a cloud-based compute resource.","upvote_count":"3","poster":"phdykd","comment_id":"818054","timestamp":"1677084000.0"},{"comment_id":"552119","content":"On 20Feb2022","upvote_count":"2","timestamp":"1645381320.0","poster":"[Removed]"},{"upvote_count":"1","timestamp":"1642424520.0","comment_id":"525783","content":"Answer is correct.","poster":"austin06112000"},{"timestamp":"1628779140.0","poster":"dwight55","upvote_count":"1","content":"looking for somebody to share contrib access pdf file with Q&A & discussion\nm a i l to me at dwight (at) existiert.net\nofc does not have to be free","comment_id":"423681"},{"timestamp":"1624287720.0","comment_id":"387224","poster":"treadst0ne","content":"Answer is B.\nGPU for inference when deployed as a web service is supported only on AKS.\nhttps://docs.microsoft.com/en-gb/azure/machine-learning/concept-compute-target","upvote_count":"3"}],"isMC":true,"topic":"4","answer_images":[],"exam_id":64,"question_text":"You create a deep learning model for image recognition on Azure Machine Learning service using GPU-based training.\nYou must deploy the model to a context that allows for real-time GPU-based inferencing.\nYou need to configure compute resources for model inferencing.\nWhich compute type should you use?","answers_community":["B (100%)"],"timestamp":"2021-03-27 12:39:00","choices":{"A":"Azure Container Instance","D":"Machine Learning Compute","C":"Field Programmable Gate Array","B":"Azure Kubernetes Service"},"question_id":377,"url":"https://www.examtopics.com/discussions/microsoft/view/48292-exam-dp-100-topic-4-question-2-discussion/","answer_ET":"B","answer_description":"You can use Azure Machine Learning to deploy a GPU-enabled model as a web service. Deploying a model on Azure Kubernetes Service (AKS) is one option.\nThe AKS cluster provides a GPU resource that is used by the model for inference.\nInference, or model scoring, is the phase where the deployed model is used to make predictions. Using GPUs instead of CPUs offers performance advantages on highly parallelizable computation.\nReference:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-inferencing-gpus","question_images":[]},{"id":"v2NyJoONCcCVBT11inco","unix_timestamp":1604451600,"discussion":[{"poster":"dsyouness","comment_id":"212398","upvote_count":"54","content":"The answer should be B :\nasync : Create a batch inference pipeline from the training pipeline","timestamp":"1620082800.0"},{"timestamp":"1620607500.0","content":"Should be B. \n .... batch inferencing is used to apply a predictive model to multiple cases asynchronously - usually writing the results to a file or database.\nhttps://docs.microsoft.com/en-us/learn/modules/deploy-batch-inference-pipelines-with-azure-machine-learning/1-introduction","poster":"DickyC","upvote_count":"19","comment_id":"216332"},{"timestamp":"1733663340.0","poster":"evangelist","comment_id":"1226698","content":"Selected Answer: B\nasynchronously ==>batch","upvote_count":"1"},{"timestamp":"1732908960.0","poster":"sl_mslconsulting","comment_id":"1221160","upvote_count":"1","content":"Selected Answer: B\nuse this link to help you answer this question: https://learn.microsoft.com/en-us/azure/machine-learning/concept-endpoints-batch?view=azureml-api-2#pipeline-component-deployment"},{"upvote_count":"1","poster":"deyoz","timestamp":"1724112480.0","content":"Selected Answer: B\nReal time inference??? it is Batch inference.","comment_id":"1154420"},{"comment_id":"1024376","timestamp":"1712200140.0","upvote_count":"1","content":"I think that the answer is B","poster":"Ran2025"},{"timestamp":"1708172880.0","content":"Selected Answer: B\nAsync= B","comment_id":"983488","poster":"BR_CS","upvote_count":"1"},{"content":"B.B. Create a batch inference pipeline from the training pipeline.\n\nAsynchronous predictions are typically done with batch inferencing. Azure Machine Learning provides the batch inference pipeline, which is suited for large volumes of data where the results aren't needed in real-time. This differs from a real-time inference pipeline, which provides synchronous, real-time predictions. So, to generate predictions asynchronously for a dataset of input data values, you should create a batch inference pipeline from the training pipeline.","comment_id":"964233","poster":"phdykd","timestamp":"1706320440.0","upvote_count":"1"},{"content":"B and C.","timestamp":"1692795360.0","upvote_count":"1","comment_id":"819321","poster":"phdykd"},{"poster":"RamundiGR","content":"we are talking to get Asynch response so it should be Batch Inference","timestamp":"1691404800.0","upvote_count":"1","comment_id":"800882"},{"poster":"RamundiGR","comment_id":"785395","timestamp":"1690112520.0","content":"Another one wrong this should be B, please correct this answer I have paid for it to be sure the answers are correct.","upvote_count":"5"},{"comment_id":"694097","timestamp":"1681402980.0","poster":"Mckay_","content":"Examtopic should try to review all these wrong answer choices. It is obvious that the word to focus on in this question is \"\"asynchronous\". The answer is B - batch inferencing","upvote_count":"2"},{"content":"Selected Answer: B\nAsync = batch\nSync = realtime","comment_id":"614586","upvote_count":"4","timestamp":"1670690520.0","poster":"ning"},{"content":"Selected Answer: B\n\"asynchronously\" is the key word here. Asynchronous predictions means batch inferencing","comment_id":"584446","timestamp":"1665531840.0","poster":"pancman","upvote_count":"4"},{"timestamp":"1663030560.0","poster":"synapse","content":"Selected Answer: B\nB. Asynchronous predictions = Batch inferencing","comment_id":"566486","upvote_count":"4"},{"timestamp":"1662181020.0","comment_id":"559870","upvote_count":"2","content":"Similar question On Exam: 03 March 2022","poster":"AjoseO"},{"upvote_count":"3","timestamp":"1641910800.0","poster":"ljljljlj","content":"On exam 2021/7/10","comment_id":"403953"},{"content":"B, asynchromous predictions indicates batch inferencing","poster":"hachascloud","comment_id":"280664","timestamp":"1627741440.0","upvote_count":"7"},{"upvote_count":"11","comments":[{"poster":"prashantjoge","timestamp":"1638041640.0","upvote_count":"3","content":"no the catch phrase is \"for a dataset of input values\" If it was just asynchronous, real-time inference would be the correct answer. Tricky question","comment_id":"368183","comments":[{"comment_id":"368185","content":"In many production scenarios, long-running tasks that operate on large volumes of data are performed as batch operations. In machine learning, batch inferencing is used to apply a predictive model to multiple cases asynchronously - usually writing the results to a file or database.","upvote_count":"1","poster":"prashantjoge","timestamp":"1638041700.0"}]}],"poster":"DanielGP","content":"\"Asynchronously\" is the key to this question. Correct answer must be \"B\".","comment_id":"254682","timestamp":"1624955160.0"}],"answer":"B","isMC":true,"topic":"4","answer_images":[],"exam_id":64,"question_text":"You use Azure Machine Learning designer to create a training pipeline for a regression model.\nYou need to prepare the pipeline for deployment as an endpoint that generates predictions asynchronously for a dataset of input data values.\nWhat should you do?","answers_community":["B (100%)"],"timestamp":"2020-11-04 02:00:00","choices":{"A":"Clone the training pipeline.","D":"Replace the dataset in the training pipeline with an Enter Data Manually module.","C":"Create a real-time inference pipeline from the training pipeline.","B":"Create a batch inference pipeline from the training pipeline."},"question_id":378,"url":"https://www.examtopics.com/discussions/microsoft/view/35978-exam-dp-100-topic-4-question-20-discussion/","answer_ET":"B","answer_description":"","question_images":[]},{"id":"DKJzVCUnudAmci9blZLL","choices":{"D":"Delete the existing model and register the new one with the same name.","A":"Register a model with a different name from the existing model and a custom property named version with the value 2.","B":"Register the model with the same name as the existing model.","C":"Save the new model in the default datastore with the same name as the existing model. Do not register the new model."},"exam_id":64,"answer":"B","isMC":true,"discussion":[{"timestamp":"1627066800.0","upvote_count":"11","poster":"Abhinav_nasaiitkgp","content":"Answer is correct.\nModel version: A version of a registered model. When a new model is added to the Model Registry, it is added as Version 1. Each model registered to the same model name increments the version number.","comment_id":"274871"},{"comment_id":"403954","upvote_count":"7","content":"On exam 2021/7/10","poster":"ljljljlj","timestamp":"1641910800.0"},{"content":"Selected Answer: B\nregistering a model with the same name as an existing model will automatically create a new version of that model. Each time you register a model with the same name, the version number increments by one.","comment_id":"1226700","timestamp":"1733663400.0","poster":"evangelist","upvote_count":"1"},{"poster":"[Removed]","timestamp":"1661012640.0","upvote_count":"1","comment_id":"552128","content":"On 20Feb2022"}],"url":"https://www.examtopics.com/discussions/microsoft/view/43144-exam-dp-100-topic-4-question-21-discussion/","timestamp":"2021-01-23 22:00:00","unix_timestamp":1611435600,"question_text":"You retrain an existing model.\nYou need to register the new version of a model while keeping the current version of the model in the registry.\nWhat should you do?","answer_images":[],"answer_description":"Model version: A version of a registered model. When a new model is added to the Model Registry, it is added as Version 1. Each model registered to the same model name increments the version number.\nReference:\nhttps://docs.microsoft.com/en-us/azure/databricks/applications/mlflow/model-registry","answers_community":["B (100%)"],"question_images":[],"topic":"4","question_id":379,"answer_ET":"B"},{"id":"fFwBzfha36pyY2DToL2i","discussion":[{"content":"I agree, D and E","timestamp":"1632022680.0","upvote_count":"33","poster":"kty","comment_id":"314599"},{"content":"DE is correct","upvote_count":"15","comment_id":"215107","timestamp":"1620455640.0","poster":"pddddd"},{"content":"Selected Answer: DE\nD, E are both correct","upvote_count":"1","comment_id":"1226704","timestamp":"1733663640.0","poster":"evangelist"},{"upvote_count":"1","poster":"deyoz","comment_id":"1141469","timestamp":"1722883980.0","content":"model_framework is used to filter the result based on the framework used to train the model (such as pytorch or tensorflow). So, definitely, D and E are the answers."},{"timestamp":"1691405100.0","poster":"RamundiGR","upvote_count":"5","content":"I wonder why those question are not fixed. I paid for the subscription but it is not worth if solutions are not correct.","comment_id":"800886"},{"comment_id":"785402","poster":"RamundiGR","timestamp":"1690113000.0","content":"Another One to fix, Can wee please correct for the future customers?","upvote_count":"3"},{"content":"C'mon ExamTopic, the answers are obvious here! D and E are the answers.","timestamp":"1681403220.0","comment_id":"694103","poster":"Mckay_","upvote_count":"3"},{"timestamp":"1670767440.0","poster":"ning","upvote_count":"2","comment_id":"614963","content":"Selected Answer: DE\nIs C missing something, does not sounds like an answer"},{"timestamp":"1665487740.0","comment_id":"584167","content":"Selected Answer: DE\nDE are the only ones which take into account the accuracy value hence the correct answers.","poster":"David_Tadeu","upvote_count":"3"},{"comment_id":"559871","content":"On Exam: 03 March 2022","timestamp":"1662181020.0","poster":"AjoseO","upvote_count":"2"},{"comment_id":"501529","upvote_count":"3","poster":"dija123","content":"Selected Answer: DE\nI agree with DE","timestamp":"1655218860.0"},{"comment_id":"483496","upvote_count":"3","poster":"Peishi","timestamp":"1653146520.0","content":"agree on D&E"},{"upvote_count":"5","comment_id":"407712","timestamp":"1642328580.0","content":"I agree with D and E","poster":"slash_nyk"},{"comment_id":"219187","upvote_count":"11","poster":"Jolin130","timestamp":"1620999240.0","content":"I go for DE"}],"url":"https://www.examtopics.com/discussions/microsoft/view/36440-exam-dp-100-topic-4-question-22-discussion/","choices":{"E":"Specify a tag named accuracy with the accuracy metric as a value when registering the model, and only register subsequent models if their accuracy is higher than the accuracy tag value of the currently registered model.","D":"Specify a property named accuracy with the accuracy metric as a value when registering the model, and only register subsequent models if their accuracy is higher than the accuracy property value of the currently registered model.","A":"Specify a different name for the model each time you register it.","B":"Register the model with the same name each time regardless of accuracy, and always use the latest version of the model in the batch inferencing pipeline.","C":"Specify the model framework version when registering the model, and only register subsequent models if this value is higher."},"unix_timestamp":1604824440,"answers_community":["DE (100%)"],"answer_ET":"DE","isMC":true,"question_id":380,"timestamp":"2020-11-08 09:34:00","answer_description":"","question_images":[],"question_text":"You use the Azure Machine Learning SDK to run a training experiment that trains a classification model and calculates its accuracy metric.\nThe model will be retrained each month as new data is available.\nYou must register the model for use in a batch inference pipeline.\nYou need to register the model and ensure that the models created by subsequent retraining experiments are registered only if their accuracy is higher than the currently registered model.\nWhat are two possible ways to achieve this goal? Each correct answer presents a complete solution.\nNOTE: Each correct selection is worth one point.","answer_images":[],"topic":"4","exam_id":64,"answer":"DE"}],"exam":{"numberOfQuestions":512,"name":"DP-100","isBeta":false,"isMCOnly":false,"lastUpdated":"12 Apr 2025","id":64,"provider":"Microsoft","isImplemented":true},"currentPage":76},"__N_SSP":true}