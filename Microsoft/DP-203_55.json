{"pageProps":{"questions":[{"id":"yj51njtkY05wDnLVuats","answer":"A","unix_timestamp":1641460440,"answer_images":[],"topic":"3","isMC":true,"exam_id":67,"question_id":271,"answer_description":"","question_images":[],"answers_community":["A (100%)"],"question_text":"You are designing an Azure Synapse solution that will provide a query interface for the data stored in an Azure Storage account. The storage account is only accessible from a virtual network.\nYou need to recommend an authentication mechanism to ensure that the solution can access the source data.\nWhat should you recommend?","discussion":[{"content":"correct","poster":"PallaviPatel","timestamp":"1641460440.0","comment_id":"518102","upvote_count":"13"},{"content":"Whenever you see Vnet , answer is usually managed Identity","comments":[{"poster":"Sr18","upvote_count":"1","timestamp":"1719082440.0","content":"very true","comment_id":"1235561"}],"poster":"Jerrie86","upvote_count":"7","comment_id":"787128","timestamp":"1674607920.0"},{"content":"Selected Answer: A\ncorrect","poster":"kkk5566","comment_id":"994704","upvote_count":"2","timestamp":"1693451760.0"},{"content":"Selected Answer: A\nManaged Idendity = VNET","timestamp":"1687766520.0","poster":"auwia","upvote_count":"3","comment_id":"934189"},{"poster":"orionduo","comment_id":"932142","upvote_count":"1","content":"Selected Answer: A\ncorrect","timestamp":"1687579260.0"},{"poster":"vctrhugo","upvote_count":"2","timestamp":"1687213440.0","comment_id":"927989","content":"Selected Answer: A\nA. A managed identity: By assigning a managed identity to the Azure Synapse solution, you can enable it to authenticate and access the Azure Storage account securely. The managed identity acts as a service principal and provides a way to authenticate to Azure services without the need for explicit credentials. By granting the managed identity appropriate permissions on the Azure Storage account, the solution can access the data while ensuring security and avoiding the need for storing and managing explicit credentials.\n\nB. Anonymous public read access is not recommended in this scenario as it would expose the data publicly without any authentication, which can lead to unauthorized access.\n\nC. A shared key is not recommended in this scenario as it involves managing and distributing the storage account's access keys, which can be cumbersome, less secure, and not ideal for scenarios where the storage account is only accessible from a virtual network."},{"timestamp":"1662132180.0","upvote_count":"4","poster":"anks84","content":"Correct, Managed Identity authentication is required when your storage account is attached to a VNet.","comment_id":"657548"},{"timestamp":"1660237800.0","comment_id":"645564","content":"correct","poster":"Deeksha1234","upvote_count":"1"},{"poster":"ravi2931","content":"Correct","timestamp":"1649263320.0","upvote_count":"1","comment_id":"581930"},{"timestamp":"1647975000.0","poster":"alex1491","content":"the key here is virtual network. Correct!","upvote_count":"1","comment_id":"573161"},{"content":"Correct","timestamp":"1643040780.0","upvote_count":"3","poster":"ANath","comment_id":"531438"}],"choices":{"B":"anonymous public read access","C":"a shared key","A":"a managed identity"},"timestamp":"2022-01-06 10:14:00","answer_ET":"A","url":"https://www.examtopics.com/discussions/microsoft/view/69575-exam-dp-203-topic-3-question-20-discussion/"},{"id":"gtxa5clYpot5HFzUthEP","answer":"B","unix_timestamp":1640457900,"answer_images":[],"topic":"3","isMC":true,"question_id":272,"exam_id":67,"answer_description":"","question_images":[],"answers_community":["B (100%)"],"choices":{"B":"shared access signatures (SAS)","C":"Azure Active Directory (Azure AD) identities","D":"account keys","A":"role assignments"},"discussion":[{"poster":"bad_atitude","comment_id":"509231","timestamp":"1656175500.0","upvote_count":"18","content":"Agree with the answer => B"},{"timestamp":"1729193640.0","upvote_count":"1","content":"Selected Answer: B\nSAS for limited time","comment_id":"1197423","poster":"Alongi"},{"upvote_count":"1","content":"Selected Answer: B\ncorrect","comment_id":"994705","poster":"kkk5566","timestamp":"1709184000.0"},{"upvote_count":"1","poster":"auwia","content":"Selected Answer: B\nCorrect.","comment_id":"934191","timestamp":"1703584980.0"},{"poster":"vctrhugo","upvote_count":"2","comment_id":"927988","content":"Selected Answer: B\nYou are developing an application that uses Azure Data Lake Storage Gen2.\nYou need to recommend a solution to grant permissions to a specific application for a limited time period.\nWhat should you include in the recommendation?\nA. role assignments\nB. shared access signatures (SAS)\nC. Azure Active Directory (Azure AD) identities\nD. account keys","timestamp":"1703031720.0"},{"upvote_count":"2","poster":"Deeksha1234","content":"correct","comment_id":"645566","timestamp":"1676142780.0"},{"comment_id":"624741","timestamp":"1672334760.0","content":"the key here is \"limited time period\", so SAS.","upvote_count":"3","poster":"Remedios79"},{"timestamp":"1666714080.0","poster":"juanlu46","content":"Selected Answer: B\nCorrect!","comment_id":"591825","upvote_count":"4"}],"question_text":"You are developing an application that uses Azure Data Lake Storage Gen2.\nYou need to recommend a solution to grant permissions to a specific application for a limited time period.\nWhat should you include in the recommendation?","answer_ET":"B","timestamp":"2021-12-25 19:45:00","url":"https://www.examtopics.com/discussions/microsoft/view/68573-exam-dp-203-topic-3-question-21-discussion/"},{"id":"51lIZ3by8OvquKcGbgMd","answer":"","isMC":false,"question_images":["https://www.examtopics.com/assets/media/exam-media/04259/0031600001.png"],"question_text":"HOTSPOT -\nYou use Azure Data Lake Storage Gen2 to store data that data scientists and data engineers will query by using Azure Databricks interactive notebooks. Users will have access only to the Data Lake Storage folders that relate to the projects on which they work.\nYou need to recommend which authentication methods to use for Databricks and Data Lake Storage to provide the users with the appropriate access. The solution must minimize administrative effort and development effort.\nWhich authentication method should you recommend for each Azure service? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","answer_ET":"","answers_community":[],"exam_id":67,"answer_description":"Box 1: Personal access tokens -\nYou can use storage shared access signatures (SAS) to access an Azure Data Lake Storage Gen2 storage account directly. With SAS, you can restrict access to a storage account using temporary tokens with fine-grained access control.\nYou can add multiple storage accounts and configure respective SAS token providers in the same Spark session.\nBox 2: Azure Active Directory credential passthrough\nYou can authenticate automatically to Azure Data Lake Storage Gen1 (ADLS Gen1) and Azure Data Lake Storage Gen2 (ADLS Gen2) from Azure Databricks clusters using the same Azure Active Directory (Azure AD) identity that you use to log into Azure Databricks. When you enable your cluster for Azure Data Lake\nStorage credential passthrough, commands that you run on that cluster can read and write data in Azure Data Lake Storage without requiring you to configure service principal credentials for access to storage.\nAfter configuring Azure Data Lake Storage credential passthrough and creating storage containers, you can access data directly in Azure Data Lake Storage\nGen1 using an adl:// path and Azure Data Lake Storage Gen2 using an abfss:// path:\nReference:\nhttps://docs.microsoft.com/en-us/azure/databricks/data/data-sources/azure/adls-gen2/azure-datalake-gen2-sas-access https://docs.microsoft.com/en-us/azure/databricks/security/credential-passthrough/adls-passthrough","discussion":[{"upvote_count":"66","timestamp":"1639419360.0","content":"Accessing the ADLS via Databricks should be using Azure Active Directory with Passthrough. Accessing the files in ADLS should be SAS, based on the options provided.\n\nThe explanation provided for this question is incorrect.","comments":[{"content":"To be more clear, for box it shall be user delegation SAS which is secured with ADD credentials.","poster":"edba","comment_id":"525442","upvote_count":"2","timestamp":"1642390740.0"},{"upvote_count":"4","poster":"Billybob0604","content":"This is it. Correct","comment_id":"746413","timestamp":"1671129120.0"}],"poster":"ItHYMeRIsh","comment_id":"500804"},{"timestamp":"1641920880.0","poster":"vivekazure","comment_id":"521659","content":"1. Accessing the Databricks should be using Personal Tokens\n2. Accessing the ADLS should be using Shared Access Signatures. (Because of controlled access to project folders they work).","upvote_count":"15"},{"poster":"e56bb91","content":"ChatGPT 4o\nAzure Active Directory (Azure AD) passthrough for both","timestamp":"1720536300.0","comment_id":"1244961","upvote_count":"2"},{"upvote_count":"1","poster":"Souvik_79","comment_id":"1241299","timestamp":"1719998160.0","content":"The whole community is confused. Everyone has their own answers and explanations. No consensus whatsoever :("},{"comment_id":"1235325","poster":"ageorgieva","timestamp":"1719052200.0","content":"Personal Token\nShared Access Signatures","upvote_count":"1"},{"poster":"Alongi","comment_id":"1194835","upvote_count":"1","content":"1. Personal Token\n2. Passthrough","timestamp":"1713000720.0"},{"upvote_count":"1","content":"Personal access token\nCredential Pass through","comment_id":"1190591","poster":"Alongi","timestamp":"1712431800.0"},{"content":"box1 Azure Active Directory with Passthrough\nbox2 SAS","upvote_count":"5","poster":"kkk5566","timestamp":"1693452540.0","comment_id":"994712"},{"upvote_count":"4","poster":"[Removed]","timestamp":"1688625420.0","comment_id":"944383","content":"Box 1 - Pass through Databricks\nBox 2 - SAS - DL Gen 2"},{"upvote_count":"4","content":"Databricks: Azure Active Directory credential passthrough or personal access tokens.\nData Lake Storage: Azure Active Directory credential passthrough.\nPlease note that while shared access keys and shared access signatures are valid authentication methods for Data Lake Storage, they do not meet the requirement of minimizing administrative effort and providing granular access control based on projects in this scenario.","timestamp":"1687767240.0","poster":"auwia","comment_id":"934199"},{"comments":[{"poster":"JG1984","timestamp":"1687287780.0","comment_id":"928718","upvote_count":"1","content":"Personal Access Tokens are an alternative authentication method for Azure Databricks that can be used to authenticate to the Databricks REST API and to access Databricks resources. While PATs can provide a high level of security, they require more administrative effort to manage and maintain than Azure Active Directory Credential Passthrough."}],"upvote_count":"1","content":"I think the answers given are correct. The question is which authentication to use \"for\" Databricks and Gen2. So we look at authenticating for (or \"into\") either of them. The question then becomes which authentication can you use to access databricks and then through that which authentication can you use to authenticate for gen2?","timestamp":"1683295440.0","poster":"gogosgh","comment_id":"890086"},{"poster":"OldSchool","upvote_count":"1","comment_id":"735092","content":"As we need to access Databricks via ADLS use Azure Databricks access tokens or AAD tokens as explained here: https://learn.microsoft.com/en-us/azure/databricks/dev-tools/api/latest/aad/\nData Lake Storage with Passtrough","timestamp":"1670158320.0"},{"timestamp":"1669816440.0","upvote_count":"7","content":"Both should be Azure Active Directory with Passthrough\n1. Shared Key and SAS authorization grants access to a user (or application) without requiring them to have an identity in Azure Active Directory (Azure AD). With these two forms of authentication, Azure RBAC and ACLs have no effect.\nACLs let you grant \"fine-grained\" access, such as write access to a specific directory or file.\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-access-control-model\nAzure AD provides superior security and ease of use over Shared Key for authorizing requests to Blob storage. For more information, see Authorize access to data in Azure Storage.\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/security-recommendations\n\n2. Azure AD Passthrough will ensure a user can only access the data that they have previously been granted access to via Azure AD in ADLS Gen2.\nhttps://www.databricks.com/blog/2019/10/24/simplify-data-lake-access-with-azure-ad-credential-passthrough.html","comment_id":"731556","poster":"Pais"},{"content":"Databricks- Azure Active Directory with Passthrough\nhttps://learn.microsoft.com/en-us/azure/databricks/security/credential-passthrough/adls-passthrough\nData Lake Storage - SAS\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-access-control-model","timestamp":"1666195320.0","poster":"KR8055","upvote_count":"4","comment_id":"699177"},{"poster":"sunil_smile","comments":[{"comment_id":"792931","comments":[{"comment_id":"792954","timestamp":"1675091100.0","content":"Sorry but I missed completely one definition:\n-) personal acces token = Personal Access Tokens (PATs) can be used to authenticate to the Databricks REST API, allowing for programmatic access to your Databricks workspace\n\nSo by using a PAT, you can automate data movements between Databricks and Data Lake Storage Gen 2 and control user permission to appropriate access\n\nCorrect answer should be:\n1) how to authenticate the ADLS gen2 dataset using databricks? ---> personal acces token\n2) how to authenticate the ADLS gen2 dataset using Data Lake Storage? ---> SAS","poster":"vrodriguesp","upvote_count":"1"}],"content":"I agree with you, plus looking at the definitions here:\n\n-) SAS = A shared access signature provides secure delegated access to resources in your storage account. With a SAS, you have granular control over how a client can access your data\n-) Azure Active Directory with Passthrough = Credential passthrough allows you to authenticate automatically to Azure Data Lake Storage from Azure Databricks clusters using the identity that you use to log in to Azure Databricks.\n-) Shared Access Key = Access keys give you full rights to everything in your storage account\n\nThe more explicit question will be:\nWhich authentication method should you recommend for each Azure service to provide the users with the appropriate access? \n1) how to authenticate the ADLS gen2 dataset using databricks? ---> Credential Pass through\n2) how to authenticate the ADLS gen2 dataset using Data Lake Storage? ---> SAS","timestamp":"1675089720.0","poster":"vrodriguesp","upvote_count":"1"}],"upvote_count":"5","timestamp":"1663479660.0","comment_id":"672012","content":"the question is about how to authenticate the ADLS gen2 dataset both in Databricks and ADLSGen2... Its not about how you authenticate the Databricks.\n\n1) Credential Pass through\n2) SAS"},{"timestamp":"1660312200.0","upvote_count":"1","comment_id":"645918","content":"Given answer seems correct, agree with HaBroNounen's explanation","poster":"Deeksha1234"},{"poster":"vishal10","comment_id":"639299","upvote_count":"2","content":"Azure Data Lake Storage Gen2 also supports Shared Key and SAS methods for authentication.\nTo authenticate to and access Databricks REST APIs, you can use Azure Databricks personal access tokens or Azure Active Directory (Azure AD) tokens","timestamp":"1659108480.0"},{"content":"It is not mentioning REST API, so it is not personal tokens. I think a normal user will log in databricks using the Active directory. Also, databricks will use Active directory passthrough to use ADLS gen2. Of course, ACLs will be needed to restrict to the folder level which is compatible to the answer.","poster":"luis1220","upvote_count":"1","timestamp":"1658536920.0","comment_id":"635392"},{"upvote_count":"10","timestamp":"1641109140.0","comment_id":"514876","poster":"HaBroNounen","comments":[{"content":"Azure Databricks is different from Databricks:\nbased on this link: https://learn.microsoft.com/en-us/azure/databricks/security/auth-authz/ \n\nso the answer is Azure Active Directory","poster":"elahe","timestamp":"1703695320.0","comment_id":"1107001","upvote_count":"1"}],"content":"Access Databricks with personal access tokens:\nhttps://docs.databricks.com/dev-tools/api/latest/authentication.html\n\nAccess ADLS from Databricks with Credential Passthrough:\nhttps://databricks.com/de/blog/2019/10/24/simplify-data-lake-access-with-azure-ad-credential-passthrough.html"},{"upvote_count":"1","poster":"Canary_2021","content":"Question 1: I select B 'Azure Key Vault secrets'\nA: credential passthrough let you access ADLS Gen1 and Gen 2 using same login as Databricks.\nB: Key Vault secrets can create a shared login to Databricks. In this way, you don't need to create diff login for diff user any more. \nC. Personal access tocks is special for Databricks rest API call. For this question, data scientists and data engineers will query by using Azure Databricks interactive notebooks. So I don't select C.\n\nQuestion 2: I select A 'Azure Active Directory credential passthrough'. The answer is correct.","timestamp":"1640632200.0","comment_id":"510561","comments":[{"comment_id":"510563","upvote_count":"2","content":"Correct my answer. \nQuestion 1: A\nAccess ADLS Gen2 from Databricks by running query interactively from notebooks.\nQuestion 2: C 'Shared access signatures'\nUsers also need directly access to the Data Lake Storage for specific folders.","timestamp":"1640632500.0","poster":"Canary_2021"}]},{"timestamp":"1640312700.0","content":"The answer is correct. personal token is the default authentication method for databricks. https://docs.microsoft.com/en-us/azure/databricks/dev-tools/api/latest/authentication","poster":"tony4fit","comment_id":"508253","upvote_count":"3"}],"timestamp":"2021-12-13 19:16:00","url":"https://www.examtopics.com/discussions/microsoft/view/67845-exam-dp-203-topic-3-question-22-discussion/","question_id":273,"answer_images":["https://www.examtopics.com/assets/media/exam-media/04259/0031700001.png"],"topic":"3","unix_timestamp":1639419360},{"id":"Fc56p7U6Ge236h5lR0Vf","question_id":274,"isMC":true,"answer_ET":"E","topic":"3","answer_description":"","answers_community":["E (86%)","14%"],"question_text":"You have an Azure Synapse Analytics dedicated SQL pool that contains a table named Contacts. Contacts contains a column named Phone.\nYou need to ensure that users in a specific role only see the last four digits of a phone number when querying the Phone column.\nWhat should you include in the solution?","choices":{"D":"column encryption","A":"table partitions","B":"a default value","E":"dynamic data masking","C":"row-level security (RLS)"},"question_images":[],"timestamp":"2022-01-06 10:30:00","url":"https://www.examtopics.com/discussions/microsoft/view/69577-exam-dp-203-topic-3-question-23-discussion/","exam_id":67,"answer":"E","discussion":[{"content":"correct","comment_id":"518116","poster":"PallaviPatel","upvote_count":"14","timestamp":"1657092600.0"},{"comment_id":"531441","poster":"ANath","upvote_count":"5","content":"Correct","timestamp":"1658672220.0"},{"poster":"jsav1","content":"Selected Answer: E\nCorrect","upvote_count":"1","comment_id":"1123076","timestamp":"1721013780.0"},{"timestamp":"1710263940.0","content":"Selected Answer: C\nThe correct answer is row level security (\"to allow specific roles\")\n\nSee https://learn.microsoft.com/en-us/azure/data-explorer/kusto/management/rowlevelsecuritypolicy\n\nMore use cases\n\n A call center support person may identify callers by several digits of their social security number. This number shouldn't be fully exposed to the support person. An RLS policy can be applied on the table to mask all but the last four digits of the social security number in the result set of any query.","poster":"74gjd_37","upvote_count":"1","comment_id":"1005881"},{"content":"Selected Answer: E\ncorrect","poster":"kkk5566","comment_id":"994713","timestamp":"1709184600.0","upvote_count":"1"},{"poster":"borinot","upvote_count":"2","comment_id":"722962","comments":[{"comment_id":"806340","timestamp":"1691837940.0","poster":"vrodriguesp","content":"I think the key is \"when querying the Phone column\". Column encryption encrypts individual columns of database on db level, instead Dynamic data masking does not store masked data, only display it.","upvote_count":"3"}],"timestamp":"1684605600.0","content":"And Topic 3 question 24 is column-level encryption?"},{"timestamp":"1676217360.0","comment_id":"645922","content":"correct!","poster":"Deeksha1234","upvote_count":"2"},{"timestamp":"1666714380.0","content":"Selected Answer: E\nCorrect!","comment_id":"591827","upvote_count":"4","poster":"juanlu46"},{"upvote_count":"4","poster":"wwdba","timestamp":"1660761600.0","comment_id":"549704","content":"Correct"}],"unix_timestamp":1641461400,"answer_images":[]},{"id":"RQEYndLM1MWKkTbGQ66A","choices":{"C":"column-level encryption","D":"Azure Active Directory (Azure AD) pass-through authentication","B":"row-level security (RLS)","A":"Transparent Data Encryption (TDE)"},"answer":"C","answers_community":["C (100%)"],"answer_ET":"C","answer_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/74500-exam-dp-203-topic-3-question-24-discussion/","question_id":275,"unix_timestamp":1650903900,"answer_description":"","discussion":[{"content":"Selected Answer: C\nBy discard, is C, you can create a symetric key to encript a data, for example one column, and then use this data as feature of the model\nhttps://docs.microsoft.com/en-us/sql/relational-databases/security/encryption/encrypt-a-column-of-data?view=sql-server-ver15\nThe other options that not meet the requeriments:\n- TDE encript data, but decrypt when you query https://docs.microsoft.com/en-us/azure/azure-sql/database/transparent-data-encryption-tde-overview?tabs=azure-portal\n- RLS is for row restriction, not meet the requeriment\n- Azure AD pass-through is for authentication","timestamp":"1682439900.0","poster":"juanlu46","comment_id":"591834","upvote_count":"15"},{"poster":"kkk5566","comment_id":"994716","content":"Selected Answer: C\nC. Column-level encryption","timestamp":"1725075180.0","upvote_count":"1"},{"upvote_count":"3","content":"C. Column-level encryption\n\nExplanation:\nThe given requirement is to enable users to utilize credit card data for model features but to not have access to the actual credit card numbers. Column-level encryption serves this purpose best as it allows for specific columns (in this case, the credit card number column) to be encrypted, while still enabling operations on the data.\n\nA. Transparent Data Encryption (TDE): This encrypts the physical files of the database, but not specific columns. It doesn't fit the requirement here.\n\nB. Row-level security (RLS): This restricts data access at the row level based on certain filters. It doesn't offer column-specific security, and thus isn't the best choice here.\n\nD. Azure Active Directory (Azure AD) pass-through authentication: This is an authentication method, not an encryption method. It would not be applicable for protecting specific data within the database.","poster":"_Lukas_","comment_id":"958030","timestamp":"1721534100.0"},{"upvote_count":"2","poster":"yogiazaad","comment_id":"773952","content":"Looks like the column level encryption is still in preview.\nhttps://azure.microsoft.com/en-us/updates/columnlevel-encryption-for-azure-synapse-analytics/","timestamp":"1705102920.0"},{"comment_id":"773949","poster":"yogiazaad","content":"IS column level encryption supported on Dedicated SQL Pools? The question is relate to Dedicated Pool?","upvote_count":"1","timestamp":"1705102860.0"},{"upvote_count":"1","content":"correct","poster":"Deeksha1234","timestamp":"1691848920.0","comment_id":"645926"}],"exam_id":67,"isMC":true,"question_text":"You are designing database for an Azure Synapse Analytics dedicated SQL pool to support workloads for detecting ecommerce transaction fraud.\nData will be combined from multiple ecommerce sites and can include sensitive financial information such as credit card numbers.\nYou need to recommend a solution that meets the following requirements:\nUsers must be able to identify potentially fraudulent transactions.\n//IMG//\n\n✑ Users must be able to use credit cards as a potential feature in models.\n✑ Users must NOT be able to access the actual credit card numbers.\nWhat should you include in the recommendation?","question_images":["https://www.examtopics.com/assets/media/exam-media/04259/0031800001.png"],"timestamp":"2022-04-25 18:25:00","topic":"3"}],"exam":{"isBeta":false,"id":67,"isImplemented":true,"lastUpdated":"12 Apr 2025","name":"DP-203","provider":"Microsoft","isMCOnly":false,"numberOfQuestions":384},"currentPage":55},"__N_SSP":true}