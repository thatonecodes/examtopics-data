{"pageProps":{"questions":[{"id":"hvNnBiFQehudTCS7qaqV","exam_id":70,"answer_images":[],"answer":"A","question_images":[],"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this question, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou have a Power BI dataset named Dataset1.\nIn Dataset1, you currently have 50 measures that use the same time intelligence logic.\nYou need to reduce the number of measures, while maintaining the current functionality.\nSolution: From Tabular Editor, you create a calculation group.\nDoes this meet the goal?","isMC":true,"question_id":131,"choices":{"B":"No","A":"Yes"},"answer_ET":"A","discussion":[{"poster":"JasonVu","timestamp":"1670697960.0","upvote_count":"18","content":"Answer is Yes","comment_id":"741180"},{"content":"Selected Answer: A\nAnswer should be Yes","comment_id":"744175","timestamp":"1670943960.0","poster":"nbagchi","upvote_count":"10"},{"poster":"sheilawu","upvote_count":"1","comment_id":"1021150","content":"Selected Answer: A\nFor reduceing the measure , yes.\nFor reducing the speed, no.","timestamp":"1696033620.0"},{"comment_id":"915265","upvote_count":"1","content":"Selected Answer: A\nA is correct answer.","timestamp":"1685956680.0","poster":"Eltooth"},{"content":"Selected Answer: A\nCG reduce the number of measures","timestamp":"1679996820.0","comment_id":"853069","poster":"DarioReymago","upvote_count":"2"},{"timestamp":"1679902620.0","upvote_count":"2","comment_id":"851876","poster":"solref","content":"Selected Answer: A\nCalculation groups reduce the number of redundant measures"},{"poster":"Denis06","content":"Calculation group is needed. \nhttps://databear.com/calculation-groups-in-power-bi/","upvote_count":"4","comment_id":"776220","timestamp":"1673765820.0"},{"comment_id":"767434","poster":"louisaok","timestamp":"1672995120.0","upvote_count":"4","content":"Selected Answer: A\nCalculation groups can significantly reduce the number of redundant measures by grouping common measure expressions as calculation items."},{"content":"Selected Answer: A\nYes. Calculation Group is the way to reduce the number of measures.","timestamp":"1672396380.0","comment_id":"761845","poster":"cherious","upvote_count":"4"},{"content":"Selected Answer: A\nCalculation group is needed.","upvote_count":"4","timestamp":"1671621120.0","poster":"Az301301X","comment_id":"752200"}],"answer_description":"","unix_timestamp":1670697960,"timestamp":"2022-12-10 19:46:00","answers_community":["A (100%)"],"url":"https://www.examtopics.com/discussions/microsoft/view/90947-exam-dp-500-topic-1-question-51-discussion/","topic":"1"},{"id":"dxDE6yC4JuIx0dqTTS9G","choices":{"A":"Yes","B":"No"},"topic":"1","answers_community":["B (100%)"],"exam_id":70,"isMC":true,"timestamp":"2022-12-10 19:49:00","discussion":[{"comment_id":"744176","timestamp":"1670944020.0","upvote_count":"8","poster":"nbagchi","content":"Selected Answer: B\nAnswer is No"},{"comment_id":"741183","content":"Answer should be No","poster":"JasonVu","upvote_count":"5","timestamp":"1670698140.0"},{"comment_id":"968781","upvote_count":"2","timestamp":"1690871460.0","content":"Selected Answer: B\nUsing grouping sets in DAX Studio allows you to create groups of measures, but it does not reduce the number of measures in the dataset. Grouping sets are used to aggregate data across multiple dimensions in a query result, but they do not help in reducing the number of individual measures.","poster":"Alborz"},{"content":"Selected Answer: B\nB is correct answer. CG needed.","poster":"Eltooth","upvote_count":"1","comment_id":"915266","timestamp":"1685956740.0"},{"content":"Selected Answer: B\ndax studio has no grouping set and calculation groups neither","comment_id":"853098","timestamp":"1679998920.0","poster":"DarioReymago","upvote_count":"3"},{"timestamp":"1679902740.0","content":"Selected Answer: B\nGrouping set doesnt exist on DAX STUDIO\nhttps://community.powerbi.com/t5/Desktop/DAX-Grouping-Sets/m-p/2079648#M774276","poster":"solref","comment_id":"851879","upvote_count":"3"},{"timestamp":"1674494160.0","comment_id":"785652","upvote_count":"2","content":"DAX has no grouping set: https://community.powerbi.com/t5/Desktop/DAX-Grouping-Sets/td-p/2078121","poster":"Madiba_kaka"},{"content":"According to this: https://community.powerbi.com/t5/Desktop/DAX-Grouping-Sets/td-p/2078121, there is no such thing as a grouping set in DAX so the answer has to be no","upvote_count":"3","poster":"ivanb94","timestamp":"1672999920.0","comment_id":"767499"}],"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this question, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou have a Power BI dataset named Dataset1.\nIn Dataset1, you currently have 50 measures that use the same time intelligence logic.\nYou need to reduce the number of measures, while maintaining the current functionality.\nSolution: From DAX Studio, you write a query that uses grouping sets.\nDoes this meet the goal?","url":"https://www.examtopics.com/discussions/microsoft/view/90948-exam-dp-500-topic-1-question-52-discussion/","question_images":[],"answer_description":"","question_id":132,"unix_timestamp":1670698140,"answer":"B","answer_ET":"B","answer_images":[]},{"id":"t0MlyvFC7n5Qam37FXvx","answer_ET":"B","answer_description":"","discussion":[{"upvote_count":"10","poster":"Az301301X","comment_id":"746982","timestamp":"1671181020.0","content":"You are using an Azure Synapse Analytics serverless SQL pool to query a collection of Apache Parquet files by using automatic schema inference. So, a View would do the trick, not an Ext Table, hence my answer would be NO. The correct in my opinion is a View."},{"timestamp":"1705572600.0","poster":"Sri966","upvote_count":"1","content":"Selected Answer: B\nNO is the answer","comment_id":"1125712"},{"poster":"manolet","content":"I choose B (NO) in the best practices reference it only mentions to Use CETAS to enhance query performance and joins: https://learn.microsoft.com/en-us/azure/synapse-analytics/sql/best-practices-serverless-sql-pool","upvote_count":"1","comment_id":"970851","timestamp":"1691047140.0"},{"content":"Selected Answer: A\nDefining an external table for the Parquet files and updating the query to use the table can help reduce I/O reads and tempdb usage in Azure Synapse Analytics serverless SQL pool. By creating an external table, you are registering the Parquet files as a table in the database, which allows you to access the data directly without the need for OPENROWSET and schema inference. This can lead to improved query performance and reduced I/O and tempdb usage.\n\nUsing an external table can also simplify query development and improve data access efficiency. The table's metadata is maintained in the data catalog, which can help optimize query execution.","upvote_count":"2","timestamp":"1690872000.0","comment_id":"968790","poster":"Alborz","comments":[{"upvote_count":"1","timestamp":"1691047080.0","poster":"manolet","content":"I don't find your explanation in the best practice reference page for serverless sql pool: https://learn.microsoft.com/en-us/azure/synapse-analytics/sql/best-practices-serverless-sql-pool","comment_id":"970850"}]},{"upvote_count":"1","comment_id":"915269","poster":"Eltooth","content":"Selected Answer: B\nBis correct answer.","timestamp":"1685957160.0"},{"upvote_count":"1","content":"Correct answer is B","timestamp":"1685200800.0","comment_id":"908067","poster":"Sudhamisha"},{"upvote_count":"2","comment_id":"771020","content":"Selected Answer: B\nI think it's B","poster":"Saffar","timestamp":"1673320260.0"},{"content":"Selected Answer: A\nCan't recommend it definitely but I would go for the yes because it is considered optimal to always use external table in Serverless SQL pool.\n\nNative external tables that you can use to read and export data in various data formats such as CSV and Parquet. Native external tables are available in serverless SQL pools, and they are in public preview in dedicated SQL pools. Writing/exporting data using CETAS and the native external tables is available only in the serverless SQL pool, but not in the dedicated SQL pools.\n\nThe native external tables are the recommended solution in the pools where they are generally available. If you need to access external data, always use the native tables in serverless pools. In dedicated pools, you should switch to the native tables for reading Parquet files once they are in GA.\n\nSource: https://learn.microsoft.com/en-us/azure/synapse-analytics/sql/develop-tables-external-tables?tabs=hadoop","timestamp":"1672398960.0","comment_id":"761861","upvote_count":"2","poster":"cherious","comments":[{"upvote_count":"6","content":"I have change my mind. \n\nI have read that external tables are useful for smaller datasets such as reference data or dimensions. The answer would be no\nSource: https://www.serverlesssql.com/optimisation/external-tables-vs-views-which-to-use/","poster":"cherious","comment_id":"762141","timestamp":"1672417680.0"}]},{"content":"Selected Answer: B\nNo in my opinion.","poster":"Az301301X","upvote_count":"3","comment_id":"752202","timestamp":"1671621300.0"},{"timestamp":"1670944260.0","content":"Selected Answer: A\nWe can define the schema in an External Table\nCheck this: https://learn.microsoft.com/en-us/azure/synapse-analytics/sql/develop-tables-external-tables?tabs=hadoop#create-external-table","poster":"nbagchi","comment_id":"744181","upvote_count":"2"},{"comment_id":"740982","content":"Correct answer is A","poster":"AT96","upvote_count":"2","timestamp":"1670677260.0"}],"question_id":133,"timestamp":"2022-12-10 14:01:00","topic":"1","answers_community":["B (54%)","A (46%)"],"unix_timestamp":1670677260,"question_images":["https://img.examtopics.com/dp-500/image60.png"],"choices":{"B":"No","A":"Yes"},"url":"https://www.examtopics.com/discussions/microsoft/view/90926-exam-dp-500-topic-1-question-53-discussion/","answer":"B","answer_images":[],"isMC":true,"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this question, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou are using an Azure Synapse Analytics serverless SQL pool to query a collection of Apache Parquet files by using automatic schema inference. The files contain more than 40 million rows of UTF-8-encoded business names, survey names, and participant counts. The database is configured to use the default collation.\nThe queries use OPENROWSET and infer the schema shown in the following table.\n//IMG//\n\nYou need to recommend changes to the queries to reduce I/O reads and tempdb usage.\nSolution: You recommend defining an external table for the Parquet files and updating the query to use the table.\nDoes this meet the goal?","exam_id":70},{"id":"JTRxmZg14Z6RLStEyBiY","isMC":true,"exam_id":70,"question_id":134,"discussion":[{"content":"Selected Answer: A\nParquet files don't contain metadata about maximum character column length. So serverless SQL pool infers it as varchar(8000).\nYou can see an example like this question in the following link:\nhttps://learn.microsoft.com/en-us/azure/synapse-analytics/sql/best-practices-serverless-sql-pool#check-inferred-data-types","upvote_count":"9","timestamp":"1676276700.0","comment_id":"807191","poster":"Fer079","comments":[{"timestamp":"1679907420.0","upvote_count":"1","comment_id":"851941","poster":"solref","content":"It is exactly what I found! Thanks for sharing :)"}]},{"poster":"Alborz","upvote_count":"1","comment_id":"968795","timestamp":"1690872540.0","content":"Selected Answer: B\nUsing OPENROWSET WITH to explicitly specify the maximum length for businessName and surveyName does not meet the goal of reducing I/O reads and tempdb usage in Azure Synapse Analytics serverless SQL pool. Specifying the maximum length using OPENROWSET WITH will only enforce a length constraint on the columns but will not directly impact I/O reads or tempdb usage."},{"poster":"Samuel77","timestamp":"1688469840.0","upvote_count":"2","comment_id":"942682","content":"I will select B"},{"comment_id":"934673","timestamp":"1687800480.0","upvote_count":"1","content":"Selected Answer: A\non 40M rows reducing the default varchar(8000) to a smaller size will improve I/O and tempDb.","poster":"Plb2"},{"upvote_count":"2","content":"Selected Answer: B\nby defaut inferred data types show varchar(8000) with or without WITH clause","poster":"DarioReymago","timestamp":"1680440940.0","comment_id":"858859"},{"content":"Selected Answer: A\nParquet files don't contain metadata about maximum character column length. So serverless SQL pool infers it as varchar(8000).\n\nYou can optimize inferred data types, using WITH to specify max length\nhttps://learn.microsoft.com/en-us/azure/synapse-analytics/sql/best-practices-serverless-sql-pool#check-inferred-data-types","timestamp":"1680240180.0","upvote_count":"2","comments":[{"content":"Answer= NO . I correct myself: The Schema definition is a best practice, but it doesnt explain a reduction of IO.\n\nUse proper collation reduces the I/O\nData in a Parquet file is organized in row groups. Serverless SQL pool skips row groups based on the specified predicate in the WHERE clause, which reduces IO. The result is increased query performance.\nhttps://learn.microsoft.com/en-us/azure/synapse-analytics/sql/best-practices-serverless-sql-pool#check-inferred-data-types","upvote_count":"1","poster":"solref","timestamp":"1680241680.0","comment_id":"856643"}],"poster":"solref","comment_id":"856633"},{"comment_id":"760743","upvote_count":"4","comments":[{"content":"bc of the automatic schema that is even emphasized in the question scenario so I would definitely go with no as the correct answer.","upvote_count":"1","comment_id":"767505","timestamp":"1673000220.0","poster":"ivanb94"},{"content":"Check the Explicitly specify schema, I would vote A","timestamp":"1679729340.0","poster":"DS_newb","comment_id":"849874","upvote_count":"1"}],"content":"Selected Answer: B\nYou don't need to use OPENROWSET WITH when reading Parquet files. \nRef: https://learn.microsoft.com/en-us/azure/synapse-analytics/sql/query-parquet-files","timestamp":"1672299960.0","poster":"Maazi"},{"content":"Selected Answer: B\nCorrect","poster":"nbagchi","timestamp":"1670944380.0","comment_id":"744184","upvote_count":"1"}],"url":"https://www.examtopics.com/discussions/microsoft/view/91448-exam-dp-500-topic-1-question-54-discussion/","answer_ET":"A","timestamp":"2022-12-13 16:13:00","answer_images":[],"topic":"1","answer_description":"","unix_timestamp":1670944380,"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this question, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou are using an Azure Synapse Analytics serverless SQL pool to query a collection of Apache Parquet files by using automatic schema inference. The files contain more than 40 million rows of UTF-8-encoded business names, survey names, and participant counts. The database is configured to use the default collation.\nThe queries use OPENROWSET and infer the schema shown in the following table.\n//IMG//\n\nYou need to recommend changes to the queries to reduce I/O reads and tempdb usage.\nSolution: You recommend using OPENROWSET WITH to explicitly specify the maximum length for businessName and surveyName.\nDoes this meet the goal?","choices":{"A":"Yes","B":"No"},"answer":"A","question_images":["https://img.examtopics.com/dp-500/image60.png"],"answers_community":["A (60%)","B (40%)"]},{"id":"Y79aJNyMrA8ugKNwyeov","discussion":[{"upvote_count":"8","content":"Selected Answer: A\n\"views are generally faster and have more features such as OPENROWSET\"\n\"External tables require an explicit defined schema while views can use OPENROWSET to provide automatic schema inference allowing for more flexibility (but note that an explicitly defined schema can provide faster performance)\"\n\nSource: https://www.jamesserra.com/archive/2020/11/external-tables-vs-t-sql-views-on-files-in-a-data-lake/","timestamp":"1672487940.0","comment_id":"762622","poster":"cherious"},{"comment_id":"752209","content":"Selected Answer: A\nYes. Views is my answer for auto schema.","poster":"Az301301X","timestamp":"1671621360.0","upvote_count":"5"},{"comment_id":"968802","poster":"Alborz","timestamp":"1690872960.0","content":"Selected Answer: A\nWhen you define a data source and view for the Parquet files, you create metadata that specifies the schema of the data and its location. This eliminates the need for automatic schema inference during query execution, reducing I/O reads and improving performance.","upvote_count":"1"},{"timestamp":"1681552680.0","upvote_count":"1","content":"Selected Answer: A\nViews are recommended for large datasets because they can have partition pruning. External table don't and are recommended for smaller datasets","comment_id":"870819","poster":"AN_78"},{"timestamp":"1671978540.0","poster":"Chk88","comment_id":"755712","upvote_count":"1","content":"B correct"},{"comment_id":"744185","upvote_count":"1","poster":"nbagchi","content":"Selected Answer: B\nCorrect","timestamp":"1670944380.0"},{"comment_id":"743754","content":"this is the correct. \"External tables\" require an explicit defined schema while \"views\" can use OPENROWSET to provide \"automatic schema inference\" allowing for more flexibility.","poster":"Az301301X","timestamp":"1670920620.0","upvote_count":"3"}],"timestamp":"2022-12-13 09:37:00","topic":"1","exam_id":70,"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this question, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou are using an Azure Synapse Analytics serverless SQL pool to query a collection of Apache Parquet files by using automatic schema inference. The files contain more than 40 million rows of UTF-8-encoded business names, survey names, and participant counts. The database is configured to use the default collation.\nThe queries use OPENROWSET and infer the schema shown in the following table.\n//IMG//\n\nYou need to recommend changes to the queries to reduce I/O reads and tempdb usage.\nSolution: You recommend defining a data source and view for the Parquet files. You recommend updating the query to use the view.\nDoes this meet the goal?","answer":"A","unix_timestamp":1670920620,"answers_community":["A (94%)","6%"],"question_id":135,"question_images":["https://img.examtopics.com/dp-500/image60.png"],"answer_ET":"A","url":"https://www.examtopics.com/discussions/microsoft/view/91336-exam-dp-500-topic-1-question-55-discussion/","answer_images":[],"isMC":true,"choices":{"B":"No","A":"Yes"},"answer_description":""}],"exam":{"provider":"Microsoft","lastUpdated":"12 Apr 2025","isBeta":false,"isImplemented":true,"id":70,"isMCOnly":false,"name":"DP-500","numberOfQuestions":183},"currentPage":27},"__N_SSP":true}