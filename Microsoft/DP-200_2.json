{"pageProps":{"questions":[{"id":"kVqiH7oWkzOoZlU1kfxh","question_id":6,"answer_description":"A: Premium/business critical service tier model that is based on a cluster of database engine processes. This architectural model relies on a fact that there is always a quorum of available database engine nodes and has minimal performance impact on your workload even during maintenance activities.\nE: In the premium model, Azure SQL database integrates compute and storage on the single node. High availability in this architectural model is achieved by replication of compute (SQL Server Database Engine process) and storage (locally attached SSD) deployed in 4-node cluster, using technology similar to SQL\nServer Always On Availability Groups.\n\n\nF: Zone redundant configuration -\nBy default, the quorum-set replicas for the local storage configurations are created in the same datacenter. With the introduction of Azure Availability Zones, you have the ability to place the different replicas in the quorum-sets to different availability zones in the same region. To eliminate a single point of failure, the control ring is also duplicated across multiple zones as three gateway rings (GW).\nReferences:\nhttps://docs.microsoft.com/en-us/azure/sql-database/sql-database-high-availability","url":"https://www.examtopics.com/discussions/microsoft/view/16975-exam-dp-200-topic-1-question-14-discussion/","question_text":"A company plans to use Azure SQL Database to support a mission-critical application.\nThe application must be highly available without performance degradation during maintenance windows.\nYou need to implement the solution.\nWhich three technologies should you implement? Each correct answer presents part of the solution.\nNOTE: Each correct selection is worth one point.","question_images":[],"choices":{"B":"Virtual machine Scale Sets","D":"SQL Data Sync","F":"Zone-redundant configuration","A":"Premium service tier","C":"Basic service tier","E":"Always On availability groups"},"answers_community":[],"exam_id":65,"isMC":true,"answer_ET":"AEF","answer":"AEF","topic":"1","unix_timestamp":1584619800,"discussion":[{"poster":"bansal_vikrant","content":"Look at the Conclusion section in the below link. It clearly mentions Always on and thus the provided answer is correct [A,E,F]\nhttps://docs.microsoft.com/en-us/azure/sql-database/sql-database-high-availability","upvote_count":"19","comment_id":"115532","timestamp":"1592739900.0","comments":[{"content":"I think it is confusing because the Premium tier says \"similar to Always On\" but I agree with the answer because you can apply Always On AGs to the VMs that host the SQL Servers","timestamp":"1594128480.0","poster":"induna","upvote_count":"4","comment_id":"128996"},{"poster":"hello_there_","timestamp":"1624429380.0","content":"The question asks \"how should YOU configure\". The documentation states that \"High availability is implemented using a technology similar to SQL Server Always On availability groups\", but this is an implementation detail of the premium/business critical service tiers, not something you have to configure yourself. That said, the other answers make even less sense.","comment_id":"388547","upvote_count":"1"}]},{"upvote_count":"9","poster":"sidharthamanu","content":"The given answer[A,E,F] is correct. Same can be understood from given link - https://docs.microsoft.com/en-us/azure/sql-database/sql-database-high-availability","timestamp":"1589799120.0","comment_id":"91189"},{"content":"Correct answer is A & F; \"Always On availability groups\" are integral part of (already included in) Premium tier zone redundant availability:\n\"High availability is implemented using a technology similar to SQL Server Always On availability groups.\" \nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/high-availability-sla\nFor better understanding of the above once and for all, pls look at the illustrations too.","timestamp":"1615626240.0","upvote_count":"2","poster":"GeorgiP","comment_id":"309569"},{"poster":"syu31svc","content":"Between Premium and Basic, Premium would be the better choice\nData Sync is definitely irrelevant for this question\nVM Scale Sets is also wrong for sure\nSo answer is AEF","upvote_count":"4","comment_id":"225798","timestamp":"1606134300.0"},{"comment_id":"219302","timestamp":"1605381060.0","poster":"Egocentric","content":"https://docs.microsoft.com/en-us/azure/sql-database/sql-database-high-availability. here there describe it nicely. A<E<F is the answer","upvote_count":"1"},{"upvote_count":"1","timestamp":"1601198100.0","content":"Re premium- High availability requirement - As an extra benefit, the premium availability model includes the ability to redirect read-only Azure SQL connections to one of the secondary replicas.","comment_id":"188257","poster":"hart232"},{"poster":"LeandroAmore","content":"The correct answer is A and F, in here https://docs.microsoft.com/en-us/azure/azure-sql/database/high-availability-sla microsoft says:\nThe underlying database files (.mdf/.ldf) are placed on the attached SSD storage to provide very low latency IO to your workload. High availability is implemented using a technology similar to SQL Server Always On availability groups.\n\nbut it says SIMILAR and you don't implement always on, Microsoft does it for you.","upvote_count":"3","comments":[{"timestamp":"1599017340.0","upvote_count":"4","content":"But the question asked for three technologies。。","comment_id":"171693","poster":"zac874997967"}],"timestamp":"1594148520.0","comment_id":"129204"},{"content":"You can not implement Alway On Availability Group on Azure Database Premium or any SKU.\n\nhttps://docs.microsoft.com/en-au/sql/database-engine/availability-groups/windows/overview-of-always-on-availability-groups-sql-server?view=sql-server-ver15","comment_id":"65973","comments":[{"comment_id":"68475","content":"Right, \"Always On Available\" only applicable to on-prem \"SQL Server\".","timestamp":"1585276440.0","poster":"zenomas","upvote_count":"1","comments":[{"upvote_count":"7","comment_id":"78296","timestamp":"1587628560.0","comments":[{"poster":"abeworld","timestamp":"1587628680.0","comment_id":"78297","upvote_count":"2","content":"actually this is for Azure VM - so my answer is not correct."}],"poster":"abeworld","content":"Its on azure too : https://docs.microsoft.com/en-us/azure/virtual-machines/windows/sql/virtual-machines-windows-portal-sql-availability-group-overview\n\nanswer is correct"},{"timestamp":"1601034120.0","comment_id":"186946","poster":"M0e","upvote_count":"1","content":"For Azure SQL DB it is called \"Failover groups\" so the correct answer is: Premium service tier, Failover groups and Zone-redundant configuration."}]},{"comment_id":"87365","timestamp":"1589239980.0","content":"This is true, always on availability groups is for on premise. Answer should be Premium service tier, SQL Data Sync and Zone-redundant configuration.","poster":"soak","upvote_count":"1"}],"poster":"Huepig","upvote_count":"8","timestamp":"1584619800.0"}],"timestamp":"2020-03-19 13:10:00","answer_images":["https://www.examtopics.com/assets/media/exam-media/03872/0002200001.png"]},{"id":"OsYHjY5MpBUJbgIDm6U4","timestamp":"2020-10-03 19:20:00","unix_timestamp":1601745600,"discussion":[{"timestamp":"1611493440.0","content":"I agree with the answer we have a new feature \"Azure Storage Explorer\" which is explained in detail in the video \"https://www.youtube.com/watch?v=GJYAgi5eYYE\" which confirms the answer with proof","comment_id":"275275","poster":"Deepu1987","upvote_count":"7"},{"content":"i agree with the answer","timestamp":"1608585540.0","comment_id":"249688","upvote_count":"5","poster":"forrahul123"},{"poster":"Piiri565","content":"I DIDN'T AGREE, When the question is asking for file storage, how the answer is related to blob storage.","comment_id":"215904","comments":[{"content":"Anything can go into blob storage, including files. However, files cannot go into tables or queues. Since there is no choice for files, blobs can be the only choice. AZ Copy is an excellent way to get data into a storage blob as well","timestamp":"1605986940.0","poster":"mrsmjparker","comment_id":"224544","upvote_count":"15"}],"upvote_count":"2","timestamp":"1604923680.0"},{"comment_id":"215582","content":"I agree","upvote_count":"3","timestamp":"1604877120.0","poster":"MHZ"},{"timestamp":"1601745600.0","content":"I agree with the answer","comment_id":"192467","poster":"Sc2","upvote_count":"3"}],"exam_id":65,"answer_description":"Storage Logging logs request data in a set of blobs in a blob container named $logs in your storage account. This container does not show up if you list all the blob containers in your account but you can see its contents if you access it directly.\nTo view and analyze your log data, you should download the blobs that contain the log data you are interested in to a local machine. Many storage-browsing tools enable you to download blobs from your storage account; you can also use the Azure Storage team provided command-line Azure Copy Tool (AzCopy) to download your log data.\nReferences:\nhttps://docs.microsoft.com/en-us/rest/api/storageservices/enabling-storage-logging-and-accessing-log-data","answer":"AB","answers_community":[],"question_text":"A company plans to use Azure Storage for file storage purposes. Compliance rules require:\n✑ A single storage account to store all operations including reads, writes and deletes\n✑ Retention of an on-premises copy of historical operations\nYou need to configure the storage account.\nWhich two actions should you perform? Each correct answer presents part of the solution.\nNOTE: Each correct selection is worth one point.","answer_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/33531-exam-dp-200-topic-1-question-15-discussion/","topic":"1","answer_ET":"AB","isMC":true,"question_images":[],"question_id":7,"choices":{"B":"Use the AzCopy tool to download log data from $logs/blob","A":"Configure the storage account to log read, write and delete operations for service type Blob","D":"Use the storage client to download log data from $logs/table","E":"Configure the storage account to log read, write and delete operations for service type queue","C":"Configure the storage account to log read, write and delete operations for service-type table"}},{"id":"MrTtxNt90sWGh5V6S6DT","question_images":["https://www.examtopics.com/assets/media/exam-media/03872/0002400003.png"],"url":"https://www.examtopics.com/discussions/microsoft/view/15670-exam-dp-200-topic-1-question-16-discussion/","answer_ET":"","exam_id":65,"question_id":8,"topic":"1","discussion":[{"timestamp":"1592377620.0","poster":"SebK","upvote_count":"16","content":"In Data Lake Gen 2, encryption is enabled by default and can't be disabled. \nhttps://docs.microsoft.com/en-us/learn/modules/secure-azure-storage-account/2-storage-security-features","comment_id":"112233"},{"upvote_count":"13","comment_id":"75785","poster":"Miles19","content":"I think this question is obsolete as in the answer we can see that they are talking about Gen1. Microsoft recommends using Data Lake Gen2.","timestamp":"1587139320.0"},{"poster":"hart232","comment_id":"188268","upvote_count":"3","content":"Confusing question.","timestamp":"1601198760.0"},{"poster":"goodzilla","timestamp":"1583493840.0","comments":[{"comment_id":"74833","content":"No, Actually you can't. If you don't have a policy pre-configured, you won't be able to designate the secret.","poster":"Leonido","upvote_count":"5","timestamp":"1586950620.0"}],"content":"One of the things that are not clear for me in this kind of questions is the right order of some answers. \nIn this case, 3rd and 4th answers couldn't those be switched as keep the right order of answers of this exercise?","upvote_count":"3","comment_id":"59854"}],"answer_images":["https://www.examtopics.com/assets/media/exam-media/03872/0002500001.png"],"unix_timestamp":1583493840,"answer_description":"Create a new Azure Data Lake Storage account with Azure Data Lake managed encryption keys\nFor Azure services, Azure Key Vault is the recommended key storage solution and provides a common management experience across services. Keys are stored and managed in key vaults, and access to a key vault can be given to users or services. Azure Key Vault supports customer creation of keys or import of customer keys for use in customer-managed encryption key scenarios.\nNote: Data Lake Storage Gen1 account Encryption Settings. There are three options:\n✑ Do not enable encryption.\n✑ Use keys managed by Data Lake Storage Gen1, if you want Data Lake Storage Gen1 to manage your encryption keys.\n✑ Use keys from your own Key Vault. You can select an existing Azure Key Vault or create a new Key Vault. To use the keys from a Key Vault, you must assign permissions for the Data Lake Storage Gen1 account to access the Azure Key Vault.\nReferences:\nhttps://docs.microsoft.com/en-us/azure/security/fundamentals/encryption-atrest","answers_community":[],"timestamp":"2020-03-06 12:24:00","isMC":false,"answer":"","question_text":"DRAG DROP -\nYou are developing a solution to visualize multiple terabytes of geospatial data.\nThe solution has the following requirements:\n✑ Data must be encrypted.\n✑ Data must be accessible by multiple resources on Microsoft Azure.\nYou need to provision storage for the solution.\nWhich four actions should you perform in sequence? To answer, move the appropriate action from the list of actions to the answer area and arrange them in the correct order.\nSelect and Place:\n//IMG//"},{"id":"Lqcb2yhgSxiiCcnm7PhU","isMC":true,"question_id":9,"question_text":"You are developing a data engineering solution for a company. The solution will store a large set of key-value pair data by using Microsoft Azure Cosmos DB.\nThe solution has the following requirements:\n✑ Data must be partitioned into multiple containers.\n✑ Data containers must be configured separately.\n✑ Data must be accessible from applications hosted around the world.\n✑ The solution must minimize latency.\nYou need to provision Azure Cosmos DB.\nWhich three actions should you perform? Each correct answer presents part of the solution.\nNOTE: Each correct selection is worth one point.","unix_timestamp":1617583860,"answer_description":"Scale read and write throughput globally. You can enable every region to be writable and elastically scale reads and writes all around the world. The throughput that your application configures on an Azure Cosmos database or a container is guaranteed to be delivered across all regions associated with your Azure Cosmos account. The provisioned throughput is guaranteed up by financially backed SLAs.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/distribute-data-globally","answer_ET":"E","discussion":[{"content":"The answers are C, D and E. \n• C. Configure table-level throughput. Requirements state that containers must be configured separately.\n• D. Replicate the data globally by manually adding regions to the Azure Cosmos DB account. By adding extra regions our data is automatically copied to those regions reducing latency.\n• E. Provision an Azure Cosmos DB account with the Azure Table API. Enable multi-region writes. By enabling multi-region writes this also reduces latency since we don't have a single master database, but rather would be implementing a multi-master model.","comment_id":"329698","upvote_count":"37","poster":"JohnCrawford","timestamp":"1617718860.0"},{"comment_id":"351648","upvote_count":"8","content":"question doesn't mention the requirement for multi-region write, So as per my understanding answer should be B, C, D\nPlease suggest if my understanding is correct","timestamp":"1620363120.0","poster":"Maky2365"},{"content":"Cosmos db support multi region write so C-D-E","timestamp":"1637407500.0","comment_id":"482449","upvote_count":"1","poster":"massnonn"},{"timestamp":"1618408440.0","content":"Answer is CDE","comment_id":"335517","poster":"Wendy_DK","upvote_count":"1"},{"poster":"AnilKJ","timestamp":"1617779820.0","upvote_count":"2","comment_id":"330133","comments":[{"comment_id":"350321","upvote_count":"2","comments":[{"comment_id":"350702","content":"Propose solution is C, D and E.\nWhen we say Azure Cosmos containers we are pertaining to the \"CONTAINERS\" of what we chose in the creation of DB. The option C pertains to configuration in \"Cassandra API\" in which the name of the container is \"TABLE\" and there are also other containers such as Container for SQL API, Collection for Mongo DB, graph for Gremlin API and Table for Table API\n\nReference: https://azure.microsoft.com/en-us/blog/sharing-provisioned-throughput-across-multiple-containers-in-azure-cosmosdb/","poster":"cadio30","timestamp":"1620276480.0","upvote_count":"4"}],"poster":"VeeraSekhar","timestamp":"1620220560.0","content":"https://docs.microsoft.com/en-us/azure/cosmos-db/set-throughput\nFrom the above link CosmosDB allows throughput at two levels \nAzure Cosmos containers\nAzure Cosmos databases\nHence B,D,E is correct answer. Sometimes we have to choose answer from list of provided answers."}],"content":"B,D,E is the answer"},{"upvote_count":"1","comments":[{"content":"Answer is CDE","upvote_count":"1","poster":"Devendra00023","timestamp":"1617771300.0","comment_id":"330057"}],"content":"There must be 3 answers, any one knows what are those.","timestamp":"1617583860.0","poster":"princy18","comment_id":"328305"}],"choices":{"A":"Configure account-level throughput.","B":"Provision an Azure Cosmos DB account with the Azure Table API. Enable geo-redundancy.","E":"Provision an Azure Cosmos DB account with the Azure Table API. Enable multi-region writes.","C":"Configure table-level throughput.","D":"Replicate the data globally by manually adding regions to the Azure Cosmos DB account."},"timestamp":"2021-04-05 02:51:00","question_images":[],"answer":"E","topic":"1","answers_community":[],"exam_id":65,"url":"https://www.examtopics.com/discussions/microsoft/view/49112-exam-dp-200-topic-1-question-17-discussion/","answer_images":[]},{"id":"7OUq7k6z7x7NJQRn2UCn","choices":{"B":"number of databases","C":"eDTUs consumption","D":"number of read operations","A":"maximum data size","E":"number of transactions"},"url":"https://www.examtopics.com/discussions/microsoft/view/30725-exam-dp-200-topic-1-question-18-discussion/","answer":"AC","isMC":true,"unix_timestamp":1599421500,"answer_ET":"AC","question_id":10,"topic":"1","question_images":[],"answers_community":[],"answer_images":[],"question_text":"A company has a SaaS solution that uses Azure SQL Database with elastic pools. The solution will have a dedicated database for each customer organization.\nCustomer organizations have peak usage at different periods during the year.\nWhich two factors affect your costs when sizing the Azure SQL Database elastic pools? Each correct answer presents a complete solution.\nNOTE: Each correct selection is worth one point.","timestamp":"2020-09-06 21:45:00","exam_id":65,"answer_description":"A: With the vCore purchase model, in the General Purpose tier, you are charged for Premium blob storage that you provision for your database or elastic pool.\nStorage can be configured between 5 GB and 4 TB with 1 GB increments. Storage is priced at GB/month.\nC: In the DTU purchase model, elastic pools are available in basic, standard and premium service tiers. Each tier is distinguished primarily by its overall performance, which is measured in elastic Database Transaction Units (eDTUs).\nReferences:\nhttps://azure.microsoft.com/en-in/pricing/details/sql-database/elastic/","discussion":[{"comment_id":"236361","upvote_count":"17","timestamp":"1607251560.0","poster":"chaoxes","content":"Number of databases is not affecting pricing. \nWhat affects is:\nStorage: maximum data size\neDTU: elasitc database throughput unit - unit of measurement used to determine scale in elastic pool.\n\nThus correct answers: A & C"},{"poster":"syu31svc","content":"A & C 100%","timestamp":"1606135200.0","upvote_count":"5","comment_id":"225814"},{"poster":"EYIT","content":"out of scope post July 2020","comments":[{"content":"nope its not","upvote_count":"4","comment_id":"218922","poster":"azp","timestamp":"1605329280.0"}],"comment_id":"174771","upvote_count":"1","timestamp":"1599421500.0"}]}],"exam":{"isMCOnly":false,"isBeta":false,"name":"DP-200","id":65,"lastUpdated":"12 Apr 2025","provider":"Microsoft","numberOfQuestions":228,"isImplemented":true},"currentPage":2},"__N_SSP":true}