{"pageProps":{"questions":[{"id":"UziZCDAEqh0cxjCGJyw3","timestamp":"2025-03-29 19:10:00","answer_description":"","answer":"","unix_timestamp":1743271800,"exam_id":71,"answers_community":[],"answer_ET":"","question_id":91,"question_images":["https://img.examtopics.com/dp-600/image220.png","https://img.examtopics.com/dp-600/image221.png"],"question_text":"HOTSPOT\n-\n\nYou are creating a report and a semantic model in Microsoft Power BI Desktop.\n\nThe Value measure has the expression shown in the following exhibit.\n\n//IMG//\n\n\nUse the drop-down menus to select the answer choice that completes each statement based on the information presented in the graphic.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","url":"https://www.examtopics.com/discussions/microsoft/view/170143-exam-dp-600-topic-1-question-183-discussion/","isMC":false,"topic":"1","discussion":[{"upvote_count":"1","poster":"Rataxe","comment_id":"1411813","timestamp":"1743271800.0","content":"Calculation group: This is the correct choice. The measure is part of a calculation group that dynamically changes its output based on the context provided by the Metric column.\n\nPercentages or decimal number: This is the correct choice. The measure can return values formatted as percentages (e.g., %_of_Customers, %_of_Gross_Margin) or as decimal numbers, depending on the context and the underlying measures."}],"answer_images":["https://img.examtopics.com/dp-600/image222.png"]},{"id":"71mhai01AobXiF1qxnop","timestamp":"2024-02-11 14:15:00","answer":"A","discussion":[{"comment_id":"1147243","comments":[{"upvote_count":"3","content":"correct","poster":"wojciech_wie","comment_id":"1152644","timestamp":"1708183140.0"}],"poster":"nmosq","upvote_count":"31","content":"Selected Answer: A\nAnswer A.\n\nB - Not all the rows are profiled in the sample (only 1000 of 2000)\nC- From the column statistics, you don't have any missing values in the sample\nD- The values that occur only once are 871 (unique count)","timestamp":"1707657300.0"},{"timestamp":"1711570500.0","poster":"a_51","comment_id":"1184342","content":"Selected Answer: A\nA\nWe see a count of 1000 (which is the limit by default) we do not know all the data is read, but we can see of the 1000 distinct is less and so we have duplicate values.","upvote_count":"5"},{"timestamp":"1735120800.0","poster":"NRezgui","comment_id":"1331491","upvote_count":"1","content":"Selected Answer: A\nThe column has duplicate values."},{"content":"Selected Answer: A\nThe column has duplicate values","timestamp":"1731650400.0","poster":"Rakesh16","upvote_count":"1","comment_id":"1312434"},{"timestamp":"1731054300.0","poster":"Naqib","upvote_count":"2","content":"Answer A:\n\nDistinct Value: This refers to all different values present in a dataset. When you retrieve distinct values from a column, you eliminate duplicate values so that each value is shown once. For example, if a column contains the values [1, 2, 2, 3, 3, 3], the distinct values would be [1, 2, 3].\n\nUnique Value: This usually refers to values that appear only once in the dataset. Unlike distinct values, a unique value will only be considered if it has no duplicates at all. For example, if a column contains the values [1, 2, 2, 3, 3, 3], the unique values would be [1], since only 1 appears without repetition.","comment_id":"1308670"},{"poster":"b65ecca","upvote_count":"2","timestamp":"1719902880.0","content":"Selected Answer: A\nDifficult to say if BCD are correct since we only see 1000 rows and not all columns. One thing is for sure though, there are columns that have values that occur more than once.","comment_id":"1240601"},{"timestamp":"1717021980.0","comment_id":"1221291","content":"Answer is A\nDistinct mean : count all the values as 1, even if there was more than one.\nUnique mean : count only the value that are not repeated in the particular column","upvote_count":"3","poster":"gills"},{"comment_id":"1208098","content":"Selected Answer: A\nIMHO, it is A, well explained below","upvote_count":"2","poster":"stilferx","timestamp":"1715127180.0"},{"comment_id":"1183378","poster":"Nefirs","upvote_count":"2","timestamp":"1711462680.0","content":"Selected Answer: A\nA\nmy reasoning: every other answer option cannot be answered for sure since only 1000 values out of 2000 are profiled. -> B: only 1000 rows are profiled -> C: the column might have missings -> D: there might be more unique/distinct counts."},{"upvote_count":"1","poster":"a_51","comment_id":"1178213","timestamp":"1710935040.0","content":"Selected Answer: A\nA is Best choice based on the picture."},{"poster":"Momoanwar","upvote_count":"4","timestamp":"1708208220.0","comment_id":"1152877","content":"Selected Answer: A\nIts A\nOnly one column selected here\nNo informations about missing values\nDistinct count not mean exist only once"}],"exam_id":71,"url":"https://www.examtopics.com/discussions/microsoft/view/133523-exam-dp-600-topic-1-question-19-discussion/","answer_images":[],"topic":"1","question_id":92,"answers_community":["A (100%)"],"answer_description":"","isMC":true,"question_text":"You have a Fabric workspace named Workspace1 that contains a dataflow named Dataflow1. Dataflow1 has a query that returns 2,000 rows.\nYou view the query in Power Query as shown in the following exhibit.\n//IMG//\n\nWhat can you identify about the pickupLongitude column?","question_images":["https://img.examtopics.com/dp-600/image24.png"],"unix_timestamp":1707657300,"choices":{"A":"The column has duplicate values.","B":"All the table rows are profiled.","D":"There are 935 values that occur only once.","C":"The column has missing values."},"answer_ET":"A"},{"id":"UDLYWg9UiLpisDx35jny","exam_id":71,"answer_description":"","question_text":"HOTSPOT -\n\nCase study -\nThis is a case study. Case studies are not timed separately. You can use as much exam time as you would like to complete each case. However, there may be additional case studies and sections on this exam. You must manage your time to ensure that you are able to complete all questions included on this exam in the time provided.\nTo answer the questions included in a case study, you will need to reference information that is provided in the case study. Case studies might contain exhibits and other resources that provide more information about the scenario that is described in the case study. Each question is independent of the other questions in this case study.\nAt the end of this case study, a review screen will appear. This screen allows you to review your answers and to make changes before you move to the next section of the exam. After you begin a new section, you cannot return to this section.\n\nTo start the case study -\nTo display the first question in this case study, click the Next button. Use the buttons in the left pane to explore the content of the case study before you answer the questions. Clicking these buttons displays information such as business requirements, existing environment, and problem statements. If the case study has an All Information tab, note that the information displayed is identical to the information displayed on the subsequent tabs. When you are ready to answer a question, click the Question button to return to the question.\n\nOverview -\nContoso, Ltd. is a US-based health supplements company. Contoso has two divisions named Sales and Research. The Sales division contains two departments named Online Sales and Retail Sales. The Research division assigns internally developed product lines to individual teams of researchers and analysts.\n\nExisting Environment -\n\nIdentity Environment -\nContoso has a Microsoft Entra tenant named contoso.com. The tenant contains two groups named ResearchReviewersGroup1 and ResearchReviewersGroup2.\n\nData Environment -\nContoso has the following data environment:\nThe Sales division uses a Microsoft Power BI Premium capacity.\nThe semantic model of the Online Sales department includes a fact table named Orders that uses Import made. In the system of origin, the OrderID value represents the sequence in which orders are created.\nThe Research department uses an on-premises, third-party data warehousing product.\nFabric is enabled for contoso.com.\nAn Azure Data Lake Storage Gen2 storage account named storage1 contains Research division data for a product line named Productline1. The data is in the delta format.\nA Data Lake Storage Gen2 storage account named storage2 contains Research division data for a product line named Productline2. The data is in the CSV format.\n\nRequirements -\n\nPlanned Changes -\nContoso plans to make the following changes:\nEnable support for Fabric in the Power BI Premium capacity used by the Sales division.\nMake all the data for the Sales division and the Research division available in Fabric.\nFor the Research division, create two Fabric workspaces named Productline1ws and Productine2ws.\nIn Productline1ws, create a lakehouse named Lakehouse1.\nIn Lakehouse1, create a shortcut to storage1 named ResearchProduct.\n\nData Analytics Requirements -\nContoso identifies the following data analytics requirements:\nAll the workspaces for the Sales division and the Research division must support all Fabric experiences.\nThe Research division workspaces must use a dedicated, on-demand capacity that has per-minute billing.\nThe Research division workspaces must be grouped together logically to support OneLake data hub filtering based on the department name.\nFor the Research division workspaces, the members of ResearchReviewersGroup1 must be able to read lakehouse and warehouse data and shortcuts by using SQL endpoints.\nFor the Research division workspaces, the members of ResearchReviewersGroup2 must be able to read lakehouse data by using Lakehouse explorer.\nAll the semantic models and reports for the Research division must use version control that supports branching.\n\nData Preparation Requirements -\nContoso identifies the following data preparation requirements:\nThe Research division data for Productline1 must be retrieved from Lakehouse1 by using Fabric notebooks.\nAll the Research division data in the lakehouses must be presented as managed tables in Lakehouse explorer.\n\nSemantic Model Requirements -\nContoso identifies the following requirements for implementing and managing semantic models:\nThe number of rows added to the Orders table during refreshes must be minimized.\nThe semantic models in the Research division workspaces must use Direct Lake mode.\n\nGeneral Requirements -\nContoso identifies the following high-level requirements that must be considered for all solutions:\nFollow the principle of least privilege when applicable.\nMinimize implementation and maintenance effort when possible.\nYou need to recommend a solution to group the Research division workspaces.\nWhat should you include in the recommendation? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\n//IMG//","discussion":[{"content":"Domain\\Fabric Admin Portal","timestamp":"1708205040.0","upvote_count":"61","poster":"Momoanwar","comment_id":"1152830"},{"content":"https://learn.microsoft.com/en-us/fabric/governance/domains#create-a-domain\nFrom MS Learn\n1. \"In Fabric, a domain is a way to logically group together services in the organization\"\n2. You have to use Fabric Admin portal to do the groupings.","comment_id":"1163108","upvote_count":"16","timestamp":"1726778340.0","poster":"XiltroX"},{"content":"The right answer is Doamin \\ OneLake Data Hub. \nThe key wording is the Research Group will use 'Lakehouse Explorer'. This tool will connect to the Onelake Data Hub. \nFrom an admin perspective, you use the Fabric Admin portal to create the Domain Grouping. I think that is the confusion. Hope that helps someone.","comment_id":"1340470","upvote_count":"2","poster":"testtaker45","timestamp":"1736876400.0"},{"comment_id":"1312416","content":"Domain & The Fabric Admin portal.","upvote_count":"1","poster":"Rakesh16","timestamp":"1731649800.0"},{"upvote_count":"2","timestamp":"1729404600.0","content":"Domain is for grouping resources so Domain and Fabric Admin portal","comment_id":"1300301","poster":"Egocentric"},{"poster":"hjhjh123","upvote_count":"1","content":"its a capacity and fabric\n: Domain Purpose: Domains are typically used for organizing and managing resources in a broader context and for access control rather than directly impacting performance and resource allocation.\nNot Ideal for Resource Management: While domains can help with organizational structure, they do not offer the performance benefits and cost management that a dedicated capacity does.","timestamp":"1726178640.0","comment_id":"1282864"},{"timestamp":"1718844120.0","poster":"buhari","comments":[{"timestamp":"1743385440.0","poster":"Ozyoluebube","content":"Fabric Admin Portal allows Fabric Admins to create and manage domains.\n\nIn the Domains tab of the Fabric Admin Portal, admins can:\n\nCreate and edit domains.\n\nAssign domain admins and contributors.\n\nAssociate workspaces with domains.\n\nIncorrect Options:\nOneLake Data Hub – Used to view and filter data by domain, but not to create or manage domains.\n\nMicrosoft Entra Admin Portal – Manages user identity and permissions, not Fabric domains.","upvote_count":"1","comment_id":"1413886"},{"comment_id":"1237313","poster":"Omer38","content":"grouping is done via Data Hub not Fabric Admin Tool","timestamp":"1719389580.0","upvote_count":"3"}],"upvote_count":"2","comment_id":"1233389","content":"ans: Domain and Fabric Admin portal ( to create the domain.)\nOnelake hub is to view those domains and underlying artifacts."},{"comment_id":"1228450","timestamp":"1718109660.0","poster":"Refined","content":"The right answer is Domain/Fabric Admin Portal.\nYou can create group with Domain, and Domain is managed at the Fabric Admin Portal level.","upvote_count":"2"},{"poster":"2dc6125","content":"https://learn.microsoft.com/en-us/fabric/governance/domains#create-a-domain\n1- Domain is the way to logically group your resources.\n2- Domain is located in the Admin portal.","comment_id":"1208484","upvote_count":"1","timestamp":"1715187780.0"},{"content":"IMHO, \n** Domain / One Lake Data Hub **\n\nLink: https://learn.microsoft.com/en-us/fabric/governance/domains#create-a-domain\n1. Because of this: In Fabric, a domain is a way of logically grouping together all the data in an organization that is relevant to a particular area or field.\n\n2. Because of this:\nFor instance, in the OneLake data hub, users can filter content by domain in order find content that is relevant to them. In addition, some tenant-level settings for managing and governing data can be delegated to the domain level, thus allowing domain-specific configuration of those settings.","upvote_count":"3","comment_id":"1207930","poster":"stilferx","comments":[{"poster":"dev2dev","comment_id":"1212050","timestamp":"1715792520.0","content":"2nd is admin portal. You can explore/navigate domains and contents from the data hub.","upvote_count":"2"},{"comment_id":"1207932","timestamp":"1715097000.0","poster":"stilferx","content":"But, if the question is how to do this, than answer may be Fabric Admin Portal, because of that: To assign workspaces to a domain or subdomain in the admin portal, you must be a Fabric admin or a domain admin.\n\nSo, there is an ambiguity in a question","upvote_count":"3"}],"timestamp":"1715096700.0"},{"timestamp":"1714381560.0","upvote_count":"1","comment_id":"1203924","content":"Grouping Method: Domain. This method allows for logical grouping based on department names, which supports OneLake data hub filtering as required.\nTool: The Fabric Admin Portal provides the necessary tools for managing and organizing workspaces.","poster":"rmeng"},{"comment_id":"1159395","timestamp":"1708922640.0","upvote_count":"1","poster":"sraakesh95","content":"Tenant and MS Entra ID\nThe grouping method should likely be \"Tenant,\" as this would allow for the organization of workspaces within the same Power BI service tenant, adhering to the principle of least privilege by keeping all resources under the same administrative boundary and simplifying management.\nThe tool to manage this could be \"The Microsoft Entra admin center,\" formerly known as the Azure Active Directory admin center, which is used for managing various aspects of Microsoft services, including user and group management within a tenant. This would align with minimizing implementation and maintenance effort, as it is a centralized management tool."},{"poster":"SamuComqi","comment_id":"1153075","upvote_count":"3","content":"- Domain\n- The Fabric Admin Portal\n\nhttps://learn.microsoft.com/en-us/fabric/governance/domains#configure-domain-settings","timestamp":"1708240080.0"},{"upvote_count":"4","timestamp":"1708071600.0","comment_id":"1151823","poster":"David_Webb","comments":[{"content":"Thank you for the link. I stand corrected.","timestamp":"1708111260.0","comment_id":"1152200","upvote_count":"2","poster":"Bharat"}],"content":"Group method: Domain\nTool: The Fabric Admin Portal\nThe tool here should mean the tool to implement the grouping solution. Thus, the answer should be the Fabric admin portal instead.\nhttps://learn.microsoft.com/en-us/fabric/governance/domains#create-a-domain"},{"upvote_count":"2","content":"I think theseon is right\nOne Lake Data Hub is used to filter data based on domain, but It doesn't create the domain or group data\nWhen you want to make a domain, you should use Admin portal","comment_id":"1151656","poster":"praisekim","timestamp":"1708044420.0"},{"upvote_count":"1","poster":"Bharat","comment_id":"1150305","timestamp":"1707924420.0","content":"One Lake Data Hub is the right answer according to the documentation link that you have provided."},{"upvote_count":"1","comment_id":"1150263","content":"Domain: Group the Research division workspaces based on their departmental context.\nOne Lake Data Hub: Use One Lake Data Hub to filter and organize the Research division workspaces effectively.\nExplanation:\n\nDomain allows you to group workspaces based on their purpose or business context. In this case, grouping by department (Research division) aligns with the requirement.\nOne Lake Data Hub provides the necessary filtering capabilities for organizing workspaces based on department names.","timestamp":"1707919440.0","poster":"rmeng"},{"timestamp":"1707482460.0","poster":"theseon","upvote_count":"4","comment_id":"1145455","content":"Should the tool not be Fabric Admin Portal?\n\nhttps://learn.microsoft.com/en-us/fabric/governance/domains#configure-domain-settings","comments":[{"comment_id":"1318489","content":"The Fabric Admin Portal is a strong contender if the context involves governance and initial setup of the domain, whereas the OneLake Data Hub is better for day-to-day filtering and workspace organization for users. It’s essential to match the tool choice with the specific scope of the requirement.","poster":"Mphatso","upvote_count":"1","timestamp":"1732694880.0"}]}],"unix_timestamp":1707482460,"question_images":["https://img.examtopics.com/dp-600/image1.png"],"url":"https://www.examtopics.com/discussions/microsoft/view/133443-exam-dp-600-topic-1-question-2-discussion/","answer":"","isMC":false,"answer_ET":"","topic":"1","answers_community":[],"answer_images":["https://img.examtopics.com/dp-600/image223.png"],"question_id":93,"timestamp":"2024-02-09 13:41:00"},{"id":"DpoNbQMgi3fEQ5XIMB1o","answer_images":[],"answer_description":"","answer_ET":"C","topic":"1","answer":"C","unix_timestamp":1707936900,"question_images":[],"choices":{"C":"the C1 settings","D":"the Tenant1 settings","A":"the DS1 settings","B":"the WS1 settings"},"discussion":[{"upvote_count":"25","comment_id":"1178220","content":"Selected Answer: C\nAs XMLA is set to Read-Only first, you must go to the capacity settings to enable read-write.\nhttps://learn.microsoft.com/en-us/power-bi/enterprise/service-premium-connect-tools#enable-xmla-read-write","poster":"a_51","timestamp":"1710935640.0"},{"timestamp":"1711638180.0","poster":"STH","upvote_count":"11","content":"Selected Answer: C\nThe question concerns changing from read-only to read-write (in the Capacity settings), not about enabling XMLA endpoints (in the Tenant settings), which, as per the query, are already set up.","comment_id":"1184830"},{"poster":"NRezgui","comment_id":"1331492","upvote_count":"2","timestamp":"1735120980.0","content":"Selected Answer: C\nthe C1 settings"},{"content":"Selected Answer: C\nThe XMLA endpoint in Microsoft Fabric allows read-write operations for datasets. To enable read-write access, you must first configure the capacity settings (C1 in this case) to allow XMLA read-write connectivity","poster":"Charley92","upvote_count":"1","comment_id":"1320465","timestamp":"1733032860.0"},{"comment_id":"1312435","timestamp":"1731650400.0","poster":"Rakesh16","content":"Selected Answer: C\nthe C1 settings","upvote_count":"1"},{"poster":"jass007_k","content":"Correct answer is option C)\nR/W settings of XMLA endpoint is done under capacity settings by fabric admin. By default, read-only connectivity using the endpoint is enabled for the Semantic models.\nLink for reference: https://learn.microsoft.com/en-us/power-bi/enterprise/service-premium-connect-tools#enable-xmla-read-write","comment_id":"1303558","upvote_count":"2","timestamp":"1730028420.0"},{"comment_id":"1245171","upvote_count":"1","content":"Selected Answer: C\nCorrect answer is C\nhttps://learn.microsoft.com/en-us/power-bi/enterprise/service-premium-connect-tools#:~:text=To%20enable%20read,to%20the%20capacity.","timestamp":"1720562340.0","poster":"6d1de25"},{"poster":"momo1165","timestamp":"1718826300.0","upvote_count":"1","comment_id":"1233111","content":"Enable XMLA read-write:\nSelect Settings > Admin portal.\nIn the Admin portal, select Capacity settings > Power BI Premium > capacity name.\nExpand Workloads. In the XMLA Endpoint setting, select Read Write. The XMLA Endpoint setting applies to all workspaces and semantic models assigned to the capacity."},{"comment_id":"1232280","poster":"Rezako","timestamp":"1718691660.0","upvote_count":"1","content":"Selected Answer: C\nThe right answer is C,\nYou use tenant setting to Allow XMLA endpoints and Analyze in Excel with on-premises datasets. It is read only access but with Capacity settings you can choose between off, read only and read-write"},{"poster":"Jons123son","upvote_count":"3","content":"Selected Answer: D\nThe questions asked what should be modified FIRST. Therefore, I would go with D because C requires that D is activated. Although, I am not sure if D is not activated by default, thus making C the ONLY modification required.\nI hate it when MS exam questions leave room for interpretation. Why don't they ask for two answers...\n\nWeirdly enough Questions 21 covers basically the same topic and there people agree that Tenant settings are definitely required next to capacity settings.","timestamp":"1717222980.0","comment_id":"1222526","comments":[{"content":"Those are other 2 settings in the Tenant settings are enabled by default. If it explicitly said XMLA Read/Write then I'd want to go with the Capacity settings like others have said as it seems the most applicable. I do get what you mean though, I was having the same doubts.","upvote_count":"1","comment_id":"1273631","timestamp":"1724781900.0","poster":"user12345678"}]},{"comment_id":"1219707","upvote_count":"1","timestamp":"1716829200.0","content":"To ensure read-write access to a dataset (DS1) using the XMLA endpoint in your Fabric tenant, you need to modify the settings that control XMLA endpoint access. This typically involves enabling read-write capabilities for the XMLA endpoint at the capacity level. Therefore, you should modify:\n\nC. the C1 settings","poster":"282b85d"},{"upvote_count":"1","content":"Selected Answer: C\nIMHO, \n\nthe answer is C. As described here: https://learn.microsoft.com/en-us/power-bi/enterprise/service-premium-connect-tools#enable-xmla-read-write\n\nin the section \"To enable read-write for a Premium capacity\"","poster":"stilferx","comment_id":"1208103","timestamp":"1715128020.0"},{"comment_id":"1198640","upvote_count":"2","poster":"VAzureD","content":"Selected Answer: D\nwe need to first configure tenant settings:\nAllow XMLA endpoints and Analyze in Excel with on-premises semantic models:","timestamp":"1713534480.0","comments":[{"timestamp":"1714934400.0","comment_id":"1207020","poster":"manolet","content":"Yes, but the question refers to enabling read-write to the capacity.","upvote_count":"2"}]},{"content":"Selected Answer: B\nTo ensure read-write access to the dataset DS1 via the XMLA endpoint, you should modify the settings at the workspace level (WS1). Specifically, enable read-write operations for the XMLA endpoint within the workspace configuration.","upvote_count":"1","comment_id":"1194863","timestamp":"1713003720.0","poster":"emmanuelkech","comments":[{"comment_id":"1207017","upvote_count":"2","poster":"manolet","content":"No. You are wrong.","timestamp":"1714934160.0"}]},{"poster":"thuss","upvote_count":"4","timestamp":"1710238260.0","content":"Again, bad wording in the question. If it is specifically about read-write, it's C. If it's about having XMLA endpoints available in the first place, it's D. Judging by Microsoft's wordings and ways of referring to their own documentation, I guess they want us to go for C.","comment_id":"1171593"},{"upvote_count":"2","poster":"metiii","timestamp":"1710013380.0","comment_id":"1169758","content":"Selected Answer: D\nWe need to configure several settings but in terms of hierarchy we need to first configure tenant settings:\nAllow XMLA endpoints and Analyze in Excel with on-premises semantic models: Users in the organization can use Excel to view and interact with on-premises Power BI semantic models. This also allows connections to XMLA endpoints.\nhttps://learn.microsoft.com/en-us/fabric/admin/tenant-settings-index"},{"timestamp":"1708963500.0","content":"C is the right answer. The read/write permission is set in capacity settings in Admin Portal.","upvote_count":"1","poster":"XiltroX","comment_id":"1159908"},{"comment_id":"1152881","upvote_count":"1","timestamp":"1708208280.0","poster":"Momoanwar","content":"Selected Answer: C\nFirst check on capacity level"},{"poster":"wojciech_wie","upvote_count":"3","timestamp":"1708183620.0","content":"C1 \nhttps://learn.microsoft.com/en-us/power-bi/enterprise/service-premium-connect-tools","comment_id":"1152647"},{"upvote_count":"2","comment_id":"1150419","content":"C1 is Correct.","timestamp":"1707936900.0","poster":"Nerd_Remo"}],"exam_id":71,"isMC":true,"answers_community":["C (85%)","Other"],"question_text":"You have a Fabric tenant named Tenant1 that contains a workspace named WS1. WS1 uses a capacity named C1 and contains a dataset named DS1.\nYou need to ensure read-write access to DS1 is available by using XMLA endpoint.\nWhat should be modified first?","timestamp":"2024-02-14 19:55:00","question_id":94,"url":"https://www.examtopics.com/discussions/microsoft/view/133878-exam-dp-600-topic-1-question-20-discussion/"},{"id":"T05AB4DNv2I2NPwomcOL","url":"https://www.examtopics.com/discussions/microsoft/view/134090-exam-dp-600-topic-1-question-21-discussion/","exam_id":71,"answer_ET":"ADE","question_text":"You have a Fabric tenant that contains a workspace named Workspace1. Workspace1 is assigned to a Fabric capacity.\nYou need to recommend a solution to provide users with the ability to create and publish custom Direct Lake semantic models by using external tools. The solution must follow the principle of least privilege.\nWhich three actions in the Fabric Admin portal should you include in the recommendation? Each correct answer presents part of the solution.\nNOTE: Each correct answer is worth one point.","unix_timestamp":1708209060,"question_images":[],"choices":{"D":"From the Capacity settings, set XMLA Endpoint to Read Write.","F":"From the Tenant settings, enable Publish to Web.","A":"From the Tenant settings, set Allow XMLA Endpoints and Analyze in Excel with on-premises datasets to Enabled.","C":"From the Tenant settings, select Users can edit data model in the Power BI service.","E":"From the Tenant settings, set Users can create Fabric items to Enabled.","B":"From the Tenant settings, set Allow Azure Active Directory guest users to access Microsoft Fabric to Enabled."},"timestamp":"2024-02-17 23:31:00","isMC":true,"answer_images":[],"question_id":95,"topic":"1","answer":"ADE","answers_community":["ADE (86%)","8%"],"answer_description":"","discussion":[{"comment_id":"1160897","timestamp":"1709058660.0","content":"D - The XMLA endpoint needs to be enabled from the capacity settings as it is crucial for allowing external tools to only read, but also, publish and manage custom Direct Lake semantic models.\n\nA - Again from Tenant settings, we need to enable XMLA endpoints ; This is to ensure that external tools interact with the data models as and when necessary within the tenant's workspace ; The analyze in excel is just complimentary to this setting in Fabric and is irrelevant\n\nE - Sets appropriate permissions to users by allowing them to edit models and publish them as when required abiding by the principle of least privilege.\n\nB&C have concerns with the principle of least privilege and security concerns while publishing to the Web","poster":"sraakesh95","upvote_count":"30"},{"comment_id":"1225427","timestamp":"1717672080.0","upvote_count":"11","poster":"282b85d","content":"Selected Answer: ADE\nA. Enabling XMLA Endpoints is crucial because it allows external tools (like SQL Server Management Studio, Tabular Editor, or any other tool that can connect via XMLA) to connect to Power BI datasets. This is essential for users who need to create, modify, or manage semantic models using these external tools. \nD. Setting the XMLA Endpoint to Read Write allows users not only to read the data from the Power BI service but also to write back to it. This is necessary for users to create and publish custom Direct Lake semantic models. Without write access, users would be unable to publish or update their models, which is a critical part of managing semantic models.\nE. Enabling users to create Fabric items is essential because it allows users to create new Power BI datasets, dataflows, and other necessary components within the workspace."},{"upvote_count":"2","comment_id":"1331499","content":"Selected Answer: ADE\nD - The XMLA endpoint needs to be enabled from the capacity settings as it is crucial for allowing external tools to only read, but also, publish and manage custom Direct Lake semantic models.","poster":"NRezgui","timestamp":"1735121640.0"},{"content":"Selected Answer: ADE\nADE is the answer","timestamp":"1731650460.0","upvote_count":"2","poster":"Rakesh16","comment_id":"1312436"},{"upvote_count":"1","content":"A- From tenant settings, setting allow XMLA endpoints and Analyze in excel with on-premises datasets to enabled\nD- From capacity settings, set XMLA endpoint to ReadWrite\nE- From Tenant settings, setUsers can create fabric items within workspace","timestamp":"1730028900.0","poster":"jass007_k","comment_id":"1303562"},{"timestamp":"1723128360.0","upvote_count":"2","content":"Selected Answer: ADE\nC is not correct for those voting for it. Below is the (verbatim) description for the \"Users can edit data models in the Power BI service (preview)\" Tenant setting in the Admin portal. \n\n\"Turn on this setting to allow users to edit data models in the service. This setting DOESN'T apply to DirectLake semantic models or editing a semantic model through an API or XMLA endpoint.\"\n\nMore information on that Tenant setting from the link below ....\n\nhttps://learn.microsoft.com/en-us/power-bi/transform-model/service-edit-data-models#enabling-data-model-editing-in-the-admin-portal","poster":"nyoike","comment_id":"1262546"},{"comment_id":"1254090","content":"C is wrong for 2 reasons, this setting is not in the tenant, it is in workspace settings. The second reason is that this feature is still in preview till date of my comment.","upvote_count":"1","timestamp":"1721793540.0","poster":"Ahmadpbi"},{"content":"ADE\nOPTION C should not be consider as :\nUsers can edit data models in the Power BI service (preview)\nEnabled for the entire organization\nTurn on this setting to allow users to edit data models in the service. This setting doesn't apply to DirectLake semantic models or editing a semantic model through an API or XMLA endpoint.","poster":"Subhamssg13","timestamp":"1718531700.0","comment_id":"1231289","upvote_count":"2"},{"content":"ADE \nB. From the Tenant settings, set Allow Azure Active Directory guest users to access Microsoft Fabric to Enabled. This focuses on external user access, which might not be necessary for your scenario.\n\nC. From the Tenant settings, select Users can edit data model in the Power BI service. This primarily affects in-browser editing of Power BI models and is less relevant to creating custom models with external tools.\n\nF. From the Tenant settings, enable Publish to Web. This is unrelated to external tool development and is concerned with sharing Power BI reports publicly.","timestamp":"1715186040.0","comment_id":"1208473","poster":"rlo123","upvote_count":"2"},{"poster":"stilferx","timestamp":"1715130300.0","comment_id":"1208110","content":"Selected Answer: ADE\nA -> D -> E","upvote_count":"2"},{"comments":[{"comment_id":"1235653","content":"From the link you https://learn.microsoft.com/en-us/fabric/admin/service-admin-portal-data-model provided - It clearly says that \"This setting doesn't apply to DirectLake datasets or editing a dataset through an API or XMLA endpoint.\" so it is not C.","upvote_count":"2","poster":"Priyanka007","timestamp":"1719101700.0"}],"comment_id":"1201615","poster":"hello2tomoki","timestamp":"1713989100.0","upvote_count":"1","content":"Selected Answer: ACD\nA. From the Tenant settings, set Allow XMLA Endpoints and Analyze in Excel with on-premises datasets to Enabled (https://learn.microsoft.com/en-us/fabric/admin/service-admin-portal-integration) . C. From the Tenant settings, select Users can edit data model in the Power BI service (https://learn.microsoft.com/en-us/fabric/admin/service-admin-portal-data-model) . D. From the Capacity settings, set XMLA Endpoint to Read Write (https://learn.microsoft.com/en-us/power-bi/enterprise/service-premium-connect-tools) ."},{"timestamp":"1713968160.0","upvote_count":"2","poster":"PazaBIandData","comment_id":"1201441","content":"Selected Answer: ADE\nAD for sure\nhttps://learn.microsoft.com/en-us/power-bi/enterprise/service-premium-connect-tools#security"},{"upvote_count":"2","content":"A Allow XMLA Endpoints and Analyze in Excel with on-premises datasets:\n From the Tenant settings, set Allow XMLA Endpoints and Analyze in Excel with on-premises datasets to Enabled. This allows users to interact with the dataset via XMLA endpoints and analyze data using Excel.\nD. Set XMLA Endpoint to Read Write:\n In the Capacity settings, configure the XMLA Endpoint to Read Write. This ensures that users have the necessary permissions to create and modify semantic models through external tools.\nE Enable Users to Create Fabric Items:\n From the Tenant settings, set Users can create Fabric items to Enabled. This grants users the ability to create custom semantic models within the Fabric workspace.","poster":"a61d298","timestamp":"1713735840.0","comment_id":"1199835"},{"timestamp":"1713573420.0","comment_id":"1198881","upvote_count":"3","content":"Selected Answer: ADE\nsraakesh95 Highly Voted 1 month, 3 weeks ago\nD - The XMLA endpoint needs to be enabled from the capacity settings as it is crucial for allowing external tools to only read, but also, publish and manage custom Direct Lake semantic models.\n\nA - Again from Tenant settings, we need to enable XMLA endpoints ; This is to ensure that external tools interact with the data models as and when necessary within the tenant's workspace ; The analyze in excel is just complimentary to this setting in Fabric and is irrelevant\n\nE - Sets appropriate permissions to users by allowing them to edit models and publish them as when required abiding by the principle of least privilege.\n\nB&C have concerns with the principle of least privilege and security concerns while publishing to the Web\n upvoted 8 times\n\nJUST TO VOTE GUYS","poster":"kelvin3105"},{"poster":"PCCCCCC","upvote_count":"1","content":"Selected Answer: ADE\nNot C : https://learn.microsoft.com/en-us/power-bi/transform-model/service-edit-data-models#enabling-data-model-editing-in-the-admin-portal","comment_id":"1196765","timestamp":"1713294900.0"},{"upvote_count":"1","comment_id":"1178240","timestamp":"1710937380.0","content":"Selected Answer: ADE\nADE seems most appropriate","poster":"a_51"},{"poster":"azure_bimonster","content":"Selected Answer: ADE\nMost probably ADE, I put E because users have the necessary permissions to create custom Direct Lake semantic models within the Fabric workspace.","comment_id":"1177717","timestamp":"1710880500.0","upvote_count":"2"},{"content":"Selected Answer: ADF\nADF seems correct answer","timestamp":"1710026700.0","comment_id":"1169948","upvote_count":"3","poster":"azure_bimonster"},{"upvote_count":"3","comment_id":"1169755","timestamp":"1710013080.0","poster":"metiii","content":"Selected Answer: ADE\nIt's ADE\nfrom https://learn.microsoft.com/en-us/fabric/admin/tenant-settings-index\nA: We need this to connect to XMLA endpoint.\nD: Obviously this is required for Read Write access throufg XMLA endpoint.\nE: This is required to create a direct lake semantic model which is a fabrci item.\n\nC:from link above: \"This setting doesn't apply to DirectLake semantic models or editing a semantic model through an API or XMLA endpoint\"\nB: This setting allows guest users to access our tenant, it's Irrelevant.\nF: This is Irrelevant too, it allows us to publish a report to web."},{"timestamp":"1709119260.0","poster":"Felgas","comment_id":"1161553","upvote_count":"1","content":"Answer is ADF\nCan't be C because the portal says \"This setting doesn't apply to DirectLake semantic models or editing a semantic model through an API or XMLA endpoint\""},{"content":"Answer is ACD","poster":"TashaP","upvote_count":"2","timestamp":"1708876860.0","comment_id":"1158939"},{"upvote_count":"1","timestamp":"1708209060.0","poster":"Momoanwar","comment_id":"1152888","comments":[{"timestamp":"1708209060.0","poster":"Momoanwar","comment_id":"1152889","content":"I mean B and F","upvote_count":"1"}],"content":"Selected Answer: ACD\nCorrect ACD\nB an d for external users\nE to enable fabric"}]}],"exam":{"numberOfQuestions":179,"isBeta":false,"isImplemented":true,"provider":"Microsoft","id":71,"name":"DP-600","isMCOnly":false,"lastUpdated":"12 Apr 2025"},"currentPage":19},"__N_SSP":true}