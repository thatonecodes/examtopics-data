{"pageProps":{"questions":[{"id":"t8IgRDgUSzVpzW62OOgy","timestamp":"2021-04-03 04:07:00","question_id":21,"answer_images":["https://www.examtopics.com/assets/media/exam-media/03872/0004200002.png"],"question_text":"DRAG DROP -\nYou have a table named SalesFact in an enterprise data warehouse in Azure Synapse Analytics. SalesFact contains sales data from the past 36 months and has the following characteristics:\n✑ Is partitioned by month\n✑ Contains one billion rows\n✑ Has clustered columnstore indexes\nAt the beginning of each month, you need to remove data from SalesFact that is older than 36 months as quickly as possible.\nWhich three actions should you perform in sequence in a stored procedure? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\nSelect and Place:\n//IMG//","isMC":false,"question_images":["https://www.examtopics.com/assets/media/exam-media/03872/0004200001.png"],"answer_ET":"","discussion":[{"upvote_count":"19","timestamp":"1617415620.0","comment_id":"327098","content":"The answer is correct","poster":"LongBao"},{"content":"1.- Copy the data to a new table by using CTAS.\n2.- Switch partition...\n3.- Drop new table","upvote_count":"2","timestamp":"1626697140.0","comment_id":"409567","poster":"Kostali"},{"comments":[{"poster":"Mily94","upvote_count":"4","content":"are you sure? Why copy data?","timestamp":"1619342100.0","comments":[{"comment_id":"347352","content":"No need to copy data, when finally you have to drop the table, additionally, copying will take more time is not needed and is less efficient","poster":"rajneesharora","upvote_count":"5","timestamp":"1619921040.0"}],"comment_id":"342420"},{"upvote_count":"1","content":"No! you dont have to spend time for copying. to switch is more easy and take less time...","poster":"memo43","timestamp":"1621155060.0","comment_id":"358464"}],"comment_id":"339553","upvote_count":"2","content":"1.- Copy the data to a new table by using CTAS.\n2.- Switch partition...\n3.- Drop new table","timestamp":"1618921440.0","poster":"AngelRio"}],"answers_community":[],"url":"https://www.examtopics.com/discussions/microsoft/view/48877-exam-dp-200-topic-1-question-28-discussion/","unix_timestamp":1617415620,"exam_id":65,"answer_description":"Step 1: Create an empty table named SalesFact_work that has the same schema as SalesFact.\nStep 2: Switch the partition containing the stale data from SalesFact to SalesFact_Work.\nSQL Data Warehouse supports partition splitting, merging, and switching. To switch partitions between two tables, you must ensure that the partitions align on their respective boundaries and that the table definitions match.\nLoading data into partitions with partition switching is a convenient way stage new data in a table that is not visible to users the switch in the new data.\nStep 3: Drop the SalesFact_Work table.\nReference:\nhttps://docs.microsoft.com/en-us/azure/sql-data-warehouse/sql-data-warehouse-tables-partition","topic":"1","answer":""},{"id":"8W6XH527uBgyK4Nh30wE","timestamp":"2020-03-27 06:50:00","question_id":22,"answer_images":[],"question_text":"You plan to implement an Azure Cosmos DB database that will write 100,000,000 JSON records every 24 hours. The database will be replicated to three regions.\nOnly one region will be writable.\nYou need to select a consistency level for the database to meet the following requirements:\n✑ Guarantee monotonic reads and writes within a session.\n✑ Provide the fastest throughput.\n✑ Provide the lowest latency.\nWhich consistency level should you select?","isMC":true,"answer_ET":"D","question_images":[],"discussion":[{"content":"I guess Andrea25 could have got this question which i found in another dump where there are three answers but the question is slightly different\nYou plan to deploy an Azure Cosmos DB database that supports multi-master replication.\n\nYou need to select a consistency level for the database to meet the following requirements:\n\n– Provide a recovery point objective (RPO) of less than 15 minutes.\n\n– Provide a recovery time objective (RTO) of zero minutes.\n\nWhat are three possible consistency levels that you can select? Each correct answer presents a complete solution. NOTE: Each correct selection is worth one point.\nA . Strong\nB . Bounded Staleness\nC . Eventual\nD . Session\nE . Consistent Prefix","comments":[{"comment_id":"274948","timestamp":"1611453660.0","upvote_count":"2","content":"I saw this question in other dump too. CDE would be the three options. \nTo this question, Session is the only option. D is the answer.","poster":"mickeyisacat615"}],"comment_id":"74361","timestamp":"1586843040.0","poster":"ivanbtod","upvote_count":"34"},{"timestamp":"1586517660.0","poster":"Andrea25","upvote_count":"18","comments":[{"upvote_count":"1","timestamp":"1586678640.0","content":"Andrea25 Were all the questions on the exam from this dump?","poster":"ivanbtod","comment_id":"73584"},{"comment_id":"107087","timestamp":"1591814580.0","upvote_count":"12","poster":"llt","content":"No, the actual exam DOES NOT require to provide 3 answers, I know this question. The keyword is 'monotonic', so the correct answer is SESSION. https://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels"}],"content":"I had this question in my exam. The question ask to choice three of those:\n- Eventual;\n- Session;\n- Consistent Prefix","comment_id":"72940"},{"content":"The correct answer is D: Session ------>>> Session consistency is the most widely used consistency level for both single region as well as globally distributed applications. It provides write latencies, availability, and read throughput comparable to that of eventual consistency but also provides the consistency guarantees that suit the needs of applications written to operate in the context of a user","upvote_count":"3","timestamp":"1618421580.0","poster":"Qrm_1972","comment_id":"335708"},{"poster":"syu31svc","comment_id":"225836","content":"Link supports D as the answer","timestamp":"1606137180.0","upvote_count":"2"},{"comment_id":"68501","content":"Keyword here is \"Guarantee monotonic reads and writes within a session.\"","timestamp":"1585288200.0","poster":"zenomas","upvote_count":"14"}],"choices":{"A":"Strong","E":"Consistent Prefix","D":"Session","C":"Eventual","B":"Bounded Staleness"},"answers_community":[],"url":"https://www.examtopics.com/discussions/microsoft/view/17537-exam-dp-200-topic-1-question-29-discussion/","unix_timestamp":1585288200,"answer_description":"Session: Within a single client session reads are guaranteed to honor the consistent-prefix (assuming a single ג€writerג€ session), monotonic reads, monotonic writes, read-your-writes, and write-follows-reads guarantees. Clients outside of the session performing writes will see eventual consistency.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels","exam_id":65,"topic":"1","answer":"D"},{"id":"totlb0ZiTB5bxkmoYDup","answer_description":"You can create high availability clusters of On-premises data gateway installations, to ensure your organization can access on-premises data resources used in\nPower BI reports and dashboards. Such clusters allow gateway administrators to group gateways to avoid single points of failure in accessing on-premises data resources. The Power BI service always uses the primary gateway in the cluster, unless it's not available. In that case, the service switches to the next gateway in the cluster, and so on.\nReferences:\nhttps://docs.microsoft.com/en-us/power-bi/service-gateway-high-availability-clusters","answer":"D","url":"https://www.examtopics.com/discussions/microsoft/view/21645-exam-dp-200-topic-1-question-3-discussion/","question_images":[],"timestamp":"2020-05-31 09:52:00","answers_community":[],"answer_images":[],"answer_ET":"D","exam_id":65,"topic":"1","unix_timestamp":1590911520,"discussion":[{"comment_id":"99164","timestamp":"1590911520.0","poster":"Treadmill","content":"https://docs.microsoft.com/en-us/data-integration/gateway/service-gateway-high-availability-clusters","upvote_count":"9"},{"comment_id":"236313","upvote_count":"5","timestamp":"1607247780.0","content":"D. Clusters is correct. The answer is ok.","poster":"chaoxes"},{"content":"D is correct","poster":"syu31svc","comment_id":"225754","upvote_count":"2","timestamp":"1606131720.0"},{"content":"IGNORE MY EARLIER COMMENT, \nThe answer is spark because SPARK has the functionality of INTERACTIVE QUERIES AS WELL.\nSpark In-memory processing, interactive queries, micro-batch stream processing\nhttps://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-provision-linux-clusters","comment_id":"219250","poster":"uomer","timestamp":"1605375840.0","upvote_count":"1"}],"question_text":"You develop data engineering solutions for a company. The company has on-premises Microsoft SQL Server databases at multiple locations.\nThe company must integrate data with Microsoft Power BI and Microsoft Azure Logic Apps. The solution must avoid single points of failure during connection and transfer to the cloud. The solution must also minimize latency.\nYou need to secure the transfer of data between on-premises databases and Microsoft Azure.\nWhat should you do?","isMC":true,"question_id":23,"choices":{"A":"Install a standalone on-premises Azure data gateway at each location","C":"Install an Azure on-premises data gateway at the primary location","B":"Install an on-premises data gateway in personal mode at each location","D":"Install an Azure on-premises data gateway as a cluster at each location"}},{"id":"wuCdzBX7azKG0ithO6WQ","question_images":[],"answer_description":"We must use Custom Text data masking, which exposes the first and last characters and adds a custom padding string in the middle.\nReference:\nhttps://docs.microsoft.com/en-us/azure/sql-database/sql-database-dynamic-data-masking-get-started","choices":{"A":"Yes","B":"No"},"question_id":24,"answer_images":[],"answer":"A","exam_id":65,"unix_timestamp":1621155540,"answer_ET":"A","timestamp":"2021-05-16 10:59:00","discussion":[{"upvote_count":"3","content":"answer is CORRECT.\nyou should mask in custom... others are not appropriate","timestamp":"1621155540.0","comment_id":"358470","poster":"memo43"}],"url":"https://www.examtopics.com/discussions/microsoft/view/52859-exam-dp-200-topic-1-question-30-discussion/","answers_community":[],"isMC":true,"topic":"1","question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou have an Azure SQL database named DB1 that contains a table named Table1. Table1 has a field named Customer_ID that is varchar(22).\nYou need to implement masking for the Customer_ID field to meet the following requirements:\n✑ The first two prefix characters must be exposed.\n✑ The last four suffix characters must be exposed.\n✑ All other characters must be masked.\nSolution: You implement data masking and use a custom text mask.\nDoes this meet the goal?"},{"id":"49ligVMqHi0OZu9RMu0x","question_id":25,"isMC":true,"exam_id":65,"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou have an Azure Storage account that contains 100 GB of files. The files contain text and numerical values. 75% of the rows contain description data that has an average length of 1.1 MB.\nYou plan to copy the data from the storage account to an enterprise data warehouse in Azure Synapse Analytics.\nYou need to prepare the files to ensure that the data copies quickly.\nSolution: You modify the files to ensure that each row is less than 1 MB.\nDoes this meet the goal?","answer_images":[],"discussion":[{"comment_id":"331549","poster":"JohnCrawford","content":"The only thing I've found mentioning row size when doing the loads relates to loads using Polybase. Then the row size needs to less than 1 MB. https://docs.microsoft.com/en-us/azure/data-factory/connector-azure-sql-data-warehouse","upvote_count":"9","timestamp":"1617914340.0"},{"comment_id":"440378","timestamp":"1630937520.0","content":"REcommended approach as per this: https://docs.microsoft.com/en-us/azure/synapse-analytics/sql/data-loading-best-practices","upvote_count":"1","poster":"hsetin"},{"timestamp":"1630937280.0","comment_id":"440377","upvote_count":"1","content":"it is not just about the size, it is the approach. the recommended approach is about zipping the file.","poster":"hsetin"},{"comment_id":"381329","upvote_count":"4","comments":[{"upvote_count":"1","poster":"ricardoveedgee","comment_id":"390814","timestamp":"1624665240.0","content":"I concur. The correct answer is 'yes' since the no size limitation update (PolyBase) applies to only SQL Server 2019+. To date, Azure Synapse Analytics still has a cap at 1 MB."}],"timestamp":"1623618540.0","content":"Answer is Yes. File size should be less than 1 MB.","poster":"Simon2021"},{"upvote_count":"1","timestamp":"1623596340.0","comment_id":"381170","poster":"dumpi","content":"correct answer is B"},{"content":"\"Yes.\"","poster":"JaNieWiem","upvote_count":"4","timestamp":"1619019900.0","comment_id":"340414"},{"content":"Row size should be still maximum 1 MB. So answer is YES. Also according to latest updates https://docs.microsoft.com/en-us/sql/relational-databases/polybase/polybase-versioned-feature-summary?view=sql-server-ver15","comment_id":"334467","upvote_count":"2","poster":"Nevia","timestamp":"1618297860.0"},{"upvote_count":"4","content":"Earlier, the answer to this question was \"Yes\", but now it shows as \"No\". Can someone confirm what is the correct answer ?","comment_id":"330545","comments":[{"content":"so what is the correct answer","poster":"dlamine9","comments":[{"poster":"Anand_96","content":"Answer is \"yes\"","upvote_count":"1","timestamp":"1622628120.0","comment_id":"372569"}],"timestamp":"1621189440.0","comment_id":"358994","upvote_count":"1"}],"timestamp":"1617814260.0","poster":"MayankSh"}],"answers_community":[],"choices":{"B":"No","A":"Yes"},"answer_description":"Instead convert the files to compressed delimited text files.\nReference:\nhttps://docs.microsoft.com/en-us/azure/sql-data-warehouse/guidance-for-loading-data","answer_ET":"B","unix_timestamp":1617814260,"answer":"B","topic":"1","question_images":[],"timestamp":"2021-04-07 18:51:00","url":"https://www.examtopics.com/discussions/microsoft/view/49527-exam-dp-200-topic-1-question-31-discussion/"}],"exam":{"isImplemented":true,"id":65,"numberOfQuestions":228,"name":"DP-200","lastUpdated":"12 Apr 2025","provider":"Microsoft","isMCOnly":false,"isBeta":false},"currentPage":5},"__N_SSP":true}