{"pageProps":{"questions":[{"id":"EssTHPFM2G2veI34lUs7","isMC":true,"answer":"AB","answer_ET":"AB","question_images":[],"answer_images":[],"unix_timestamp":1585937160,"topic":"2","question_text":"You have a database that contains sales data.\nYou plan to process the sales data by using two data streams named Stream1 and Stream2. Stream1 will be used for purchase order data. Stream2 will be used for reference data.\nThe reference data is stored in CSV files.\nYou need to recommend an ingestion solution for each data stream.\nWhat two solutions should you recommend? Each correct answer is a complete solution.\nNOTE: Each correct selection is worth one point.","url":"https://www.examtopics.com/discussions/microsoft/view/17831-exam-ai-100-topic-2-question-21-discussion/","choices":{"C":"an Azure event hub for Stream1 and Stream2","B":"Azure Blob storage for Stream1 and Stream2","E":"Azure Cosmos DB for Stream1 and an Azure event hub for Stream2","A":"an Azure event hub for Stream1 and Azure Blob storage for Stream2","D":"Azure Blob storage for Stream1 and Azure Cosmos DB for Stream2"},"timestamp":"2020-04-03 20:06:00","discussion":[{"content":"For Stream1, you should use an Azure Event Hub. For Stream2, you should use Azure Blob storage.","comment_id":"927834","poster":"rveney","upvote_count":"1","timestamp":"1687202100.0"},{"poster":"Cornholioz","content":"I think the trick here is that Stream2 only has reference data which needs to be persisted. Not sure, but I think that's why Stream2 needs a storage solution and cannot be just Event Hubs.\nGoing with given answer.","timestamp":"1612900320.0","comment_id":"287101","upvote_count":"4"},{"upvote_count":"1","comment_id":"253159","timestamp":"1609054140.0","content":"A and C","poster":"valar_morghulis"},{"timestamp":"1602324600.0","upvote_count":"1","poster":"CeliaZhou","comment_id":"197239","content":"I think the answer could be A and C"},{"poster":"abdelbz12","timestamp":"1601316720.0","comments":[{"timestamp":"1607730360.0","upvote_count":"1","content":"but each correct answer represents a complete solution, and stream analytics is not mentioned","comment_id":"241274","poster":"AcetheTest"}],"content":"I think the answers are correct. blob data can be processed as a data stream by Stream Analytics. https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-define-inputs","comment_id":"189214","upvote_count":"1"},{"poster":"sayak17","comment_id":"177479","content":"Where is it said in the question that real time stream ingestion is required? The data already exists in a database right","upvote_count":"1","timestamp":"1599801960.0"},{"comment_id":"94346","timestamp":"1590238740.0","upvote_count":"1","poster":"carloshvp","comments":[{"timestamp":"1595889780.0","comment_id":"145317","poster":"Arinze","content":"Stream2 has to be by reference so that's why its Blob and event hub for ingestion for Stream1","upvote_count":"1"}],"content":"As shown in the link, ingestion is done either with IoT Hub, Event Hubs or Kafka/HDInsight. Therefore the answer should be C\nhttps://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/real-time-ingestion"},{"poster":"AulaitQM","comments":[{"timestamp":"1587129660.0","poster":"lchvce","comment_id":"75736","content":"Maybe using Hot Path?","upvote_count":"1"}],"timestamp":"1585937160.0","comment_id":"70809","content":"Why is Azure Blob Storage an answer for a question asking about an ingestion solution?","upvote_count":"3"}],"answer_description":"Stream1 - Azure Event -\n\nStream2 - Blob Storage -\nAzure Event Hubs is a highly scalable data streaming platform and event ingestion service, capable of receiving and processing millions of events per second.\nEvent Hubs can process and store events, data, or telemetry produced by distributed software and devices. Data sent to an event hub can be transformed and stored using any real-time analytics provider or batching/storage adapters. Event Hubs provides publish-subscribe capabilities with low latency at massive scale, which makes it appropriate for big data scenarios.\n\nStream1, Stream2 - Blob Storage -\nStream Analytics has first-class integration with Azure data streams as inputs from three kinds of resources:\n\nAzure Event Hubs -\n\nAzure IoT Hub -\n\nAzure Blob storage -\nThese input resources can live in the same Azure subscription as your Stream Analytics job or a different subscription.\nReferences:\nhttps://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/real-time-ingestion","answers_community":[],"question_id":61,"exam_id":39},{"id":"m19wzG7XKXf0ekfi8M4I","answer_ET":"B","answer_description":"Instead add an SSH key to the node, and then you create an SSH connection.\nReferences:\nhttps://docs.microsoft.com/en-us/azure/aks/ssh","answer_images":[],"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou are developing an application that uses an Azure Kubernetes Service (AKS) cluster.\nYou are troubleshooting a node issue.\nYou need to connect to an AKS node by using SSH.\nSolution: You create a managed identity for AKS, and then you create an SSH connection.\nDoes this meet the goal?","exam_id":39,"discussion":[{"content":"B. No\nthe given solution of creating a managed identity for AKS and then creating an SSH connection does not meet the goal of connecting to an AKS node using SSH.","upvote_count":"1","poster":"rveney","timestamp":"1687182060.0","comment_id":"927556"},{"poster":"dijaa","content":"all are wrong except for add SSH to the node then make SSH connection","comment_id":"429966","upvote_count":"1","timestamp":"1629723180.0"},{"poster":"shaark18","upvote_count":"1","comment_id":"383252","timestamp":"1623835860.0","content":"We need to add an SSH key to the node, and then create an SSH connection, so answer is NO"},{"comment_id":"310679","content":"I think answer is correct. As per link below with managed identity we can only Sign into Azure CLI or PowerShell with the identity. https://docs.microsoft.com/en-us/azure/container-registry/container-registry-authentication-managed-identity","upvote_count":"1","timestamp":"1615740240.0","poster":"Maunik"},{"timestamp":"1614210360.0","comment_id":"298627","content":"The reason why using SSH to AKS node is to check maintenance or troubleshoot. So here we want to generate SSH keys and added to the AKS cluster. And then create SSH connection to AKS node. So clearly what the question does is the first part, answer is B.","poster":"zzxl","upvote_count":"2"},{"content":"Is this correct?","comment_id":"171636","comments":[{"upvote_count":"2","comment_id":"186876","timestamp":"1601026980.0","poster":"XXXX","content":"Yes, one of the correct ways to achieve this is in the explanation provided"}],"upvote_count":"2","poster":"clownfishman","timestamp":"1599006780.0"}],"timestamp":"2020-09-02 02:33:00","question_id":62,"question_images":[],"answers_community":[],"isMC":true,"unix_timestamp":1599006780,"topic":"2","answer":"B","choices":{"A":"Yes","B":"No"},"url":"https://www.examtopics.com/discussions/microsoft/view/30300-exam-ai-100-topic-2-question-22-discussion/"},{"id":"kJSH4dXzj58ChgkmGmdv","unix_timestamp":1609224900,"answer":"B","answer_images":[],"answer_ET":"B","answer_description":"Instead add an SSH key to the node, and then you create an SSH connection.\nReferences:\nhttps://docs.microsoft.com/en-us/azure/aks/ssh","question_images":[],"choices":{"B":"No","A":"Yes"},"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou are developing an application that uses an Azure Kubernetes Service (AKS) cluster.\nYou are troubleshooting a node issue.\nYou need to connect to an AKS node by using SSH.\nSolution: You change the permissions of the AKS resource group, and then you create an SSH connection.\nDoes this meet the goal?","url":"https://www.examtopics.com/discussions/microsoft/view/40951-exam-ai-100-topic-2-question-23-discussion/","exam_id":39,"isMC":true,"question_id":63,"topic":"2","timestamp":"2020-12-29 07:55:00","discussion":[{"content":"B. No\n the given solution of changing the permissions of the AKS resource group and then creating an SSH connection does not meet the goal of connecting to an AKS node using SSH.","timestamp":"1687182060.0","comment_id":"927557","upvote_count":"1","poster":"rveney"},{"poster":"awron_durat","content":"The answer is correct.","timestamp":"1609224900.0","upvote_count":"1","comment_id":"254597"}],"answers_community":[]},{"id":"XVjzN6Yxwmgjf6Vcx7MS","answers_community":[],"choices":{"B":"No","A":"Yes"},"question_id":64,"timestamp":"2020-12-29 07:55:00","exam_id":39,"answer_ET":"A","discussion":[{"timestamp":"1687182180.0","content":"A. Yes\n\nAdding an SSH key to the AKS node and then creating an SSH connection can meet the goal of connecting to an AKS node using SSH. By adding the SSH key to the node, you establish the necessary credentials for SSH authentication. Once the key is added, you can use it to authenticate and establish an SSH connection to the AKS node.\n\nThis solution assumes that you have access to the AKS node and have the necessary privileges to add the SSH key. Additionally, make sure that the SSH key is correctly configured and that the SSH port (default: port 22) is accessible for the AKS node.\n\nConnecting to an AKS node using SSH can be useful for troubleshooting purposes, but it's important to follow security best practices and limit SSH access only to authorized users or when necessary.","upvote_count":"1","poster":"rveney","comment_id":"927560"},{"content":"This answer is correct.","comment_id":"254598","poster":"awron_durat","upvote_count":"2","timestamp":"1609224900.0"}],"answer_images":[],"answer_description":"By default, SSH keys are generated when you create an AKS cluster. If you did not specify your own SSH keys when you created your AKS cluster, add your public SSH keys to the AKS nodes.\nYou also need to create an SSH connection to the AKS node.\nReferences:\nhttps://docs.microsoft.com/en-us/azure/aks/ssh","topic":"2","isMC":true,"question_images":[],"unix_timestamp":1609224900,"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou are developing an application that uses an Azure Kubernetes Service (AKS) cluster.\nYou are troubleshooting a node issue.\nYou need to connect to an AKS node by using SSH.\nSolution: You add an SSH key to the node, and then you create an SSH connection.\nDoes this meet the goal?","url":"https://www.examtopics.com/discussions/microsoft/view/40952-exam-ai-100-topic-2-question-24-discussion/","answer":"A"},{"id":"cL1WXojXNuobW3RATXOG","unix_timestamp":1599937020,"answer":"C","answers_community":[],"isMC":true,"question_images":[],"answer_description":"With Azure Data Factory you can use workflows to orchestrate data integration and data transformation processes at scale.\nBuild data integration, and easily transform and integrate big data processing and machine learning with the visual interface.\nReferences:\nhttps://azure.microsoft.com/en-us/services/data-factory/","discussion":[{"upvote_count":"10","comment_id":"267926","timestamp":"1610715600.0","content":"The comment by Nova077 must not be approved untill it has some source or reference . Such comments creates confusions,,,,","poster":"UpsetUser"},{"poster":"rveney","timestamp":"1687202220.0","upvote_count":"1","comment_id":"927836","content":"To orchestrate the workflow, you should use Azure Data Factory"},{"upvote_count":"1","content":"Seems \"orchestrate' always end up with Azure Data Factory...","timestamp":"1627307040.0","poster":"YipingRuan","comment_id":"414728"},{"timestamp":"1624127880.0","poster":"PinkUnicorns","upvote_count":"1","content":"you can do copy activity but read through the docs\nhttps://docs.microsoft.com/en-us/azure/data-factory/copy-activity-overview","comment_id":"385701"},{"poster":"erosazi_5705","upvote_count":"1","comment_id":"318190","timestamp":"1616511480.0","content":"Why not azure pipeline?"},{"comments":[{"timestamp":"1600040760.0","comment_id":"178951","content":"You can.\n https://marlonribunal.com/copy-data-from-on-premise-sql-server-to-azure-database-using-azure-data-factory/","comments":[{"comment_id":"184976","timestamp":"1600832640.0","upvote_count":"2","content":"Yes. answer is correct. This link shows how it can be done https://docs.microsoft.com/en-us/azure/data-factory/tutorial-hybrid-copy-portal","poster":"sayak17"}],"poster":"fahimRPA","upvote_count":"4"},{"poster":"meswapnilspal","comment_id":"306855","content":"Yes it can be done, i use ADF on day-to-day basis. Please be careful with your comments. Community is dependent upon discussions, as they clarify lot of confusions.","upvote_count":"8","timestamp":"1615350180.0"}],"upvote_count":"1","content":"You can't use ADF to transfer on premise data though!","comment_id":"178381","poster":"Nova077","timestamp":"1599937020.0"}],"topic":"2","exam_id":39,"url":"https://www.examtopics.com/discussions/microsoft/view/31157-exam-ai-100-topic-2-question-25-discussion/","timestamp":"2020-09-12 20:57:00","question_id":65,"choices":{"B":"Azure Pipelines","D":"Azure Container Instances","C":"Azure Data Factory","A":"Azure Kubernetes Service (AKS)"},"answer_images":[],"question_text":"You are developing a Computer Vision application.\nYou plan to use a workflow that will load data from an on-premises database to Azure Blob storage, and then connect to an Azure Machine Learning service.\nWhat should you use to orchestrate the workflow?","answer_ET":"C"}],"exam":{"name":"AI-100","provider":"Microsoft","isMCOnly":false,"id":39,"lastUpdated":"12 Apr 2025","numberOfQuestions":206,"isImplemented":true,"isBeta":false},"currentPage":13},"__N_SSP":true}