{"pageProps":{"questions":[{"id":"NCAl9mYPvh0Pb60tk660","answer_images":["https://www.examtopics.com/assets/media/exam-media/04276/0014400002.jpg"],"question_text":"HOTSPOT -\nYou have an Azure Cosmos DB Core (SQL) API account named account1.\nIn account1, you run the following query in a container that contains 100GB of data.\n//IMG//\n\nYou view the following metrics while performing the query.\n//IMG//\n\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","isMC":false,"question_images":["https://www.examtopics.com/assets/media/exam-media/04276/0014300001.png","https://www.examtopics.com/assets/media/exam-media/04276/0014300002.png","https://www.examtopics.com/assets/media/exam-media/04276/0014400001.png"],"answers_community":[],"unix_timestamp":1683094320,"answer":"","url":"https://www.examtopics.com/discussions/microsoft/view/108365-exam-dp-420-topic-5-question-16-discussion/","answer_description":"Box 1: No -\nEach physical partition should have its own index, but since no index is used, the query is not cross-partition.\n\nBox 2: No -\nIndex utilization is 0% and Index Look up time is also zero.\n\nBox 3: Yes -\nA partition key index will be created, and the query will perform across the partitions.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/sql/how-to-query-container","discussion":[{"upvote_count":"7","comments":[{"poster":"[Removed]","content":"YNN < correction","comments":[{"comment_id":"1201900","content":"This is the correct answer","poster":"[Removed]","upvote_count":"2","timestamp":"1729851360.0"}],"comment_id":"997154","timestamp":"1709423820.0","upvote_count":"7"}],"comment_id":"991617","poster":"[Removed]","content":"YNY\n\"This query's filter uses the system function UPPER, which isn't served from the index.\"\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/nosql/query-metrics-performance#scan-queries-commonly-slow-and-expensive","timestamp":"1709066520.0"},{"content":"I would say YNY","comment_id":"1411006","poster":"matejka","upvote_count":"1","timestamp":"1743104340.0"},{"upvote_count":"1","comments":[{"comment_id":"1225294","poster":"8fe085a","upvote_count":"2","content":"The third question ask waht happens when the container is recreated with the customerid as partition key, so it is not currently the partition key, therfore the query is cross partition.","timestamp":"1733482320.0"}],"timestamp":"1715902260.0","content":"how do we know if it's cross partition query or not?","comment_id":"1072947","poster":"bcd_6"},{"timestamp":"1702308420.0","upvote_count":"1","comment_id":"920707","poster":"EvanG","content":"using a function like Lower on the left side of equality won't use the index in relational dbs. Not sure about Cosmosdb"},{"content":"To correctly answer the question one would have to know the partionkey https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-query-container","comment_id":"888209","poster":"TRUESON","upvote_count":"1","timestamp":"1698999120.0"}],"topic":"5","question_id":111,"answer_ET":"","timestamp":"2023-05-03 08:12:00","exam_id":69},{"id":"yTyggCLcm73fs68JGknY","isMC":true,"question_id":112,"choices":{"C":"In an Azure Synapse Analytics serverless SQL pool, create a view that uses OPENROWSET and the CosmosDB provider.","A":"In an Apache Spark pool in Azure Synapse, create a table that uses cosmos.olap as the data source.","B":"Create a private endpoint connection to the account.","D":"Enable Azure Synapse Link for the account and Analytical store on the container.","E":"In an Apache Spark pool in Azure Synapse, create a table that uses cosmos.oltp as the data source."},"exam_id":69,"discussion":[{"timestamp":"1735460520.0","content":"Selected Answer: AD\nanswer provided is correct","upvote_count":"1","poster":"3709334","comment_id":"1333401"},{"comment_id":"931846","timestamp":"1719165900.0","content":"Selected Answer: AD\nSelected Answer: AD","poster":"azuredemo2022three","upvote_count":"3"},{"content":"Answer A and D","upvote_count":"1","comment_id":"929853","timestamp":"1718998380.0","poster":"azuredemo2022three","comments":[{"timestamp":"1718998500.0","comment_id":"929858","content":"A. In an Apache Spark pool in Azure Synapse, create a table that uses cosmos.olap as the data source:\nBy creating a table in an Apache Spark pool in Azure Synapse that uses the cosmos.olap data source, you can efficiently access and analyze the data stored in your Azure Cosmos DB account. This approach leverages the optimized capabilities of Apache Spark and allows you to perform machine learning tasks on the data.\n\nD. Enable Azure Synapse Link for the account and Analytical store on the container:\nEnabling Azure Synapse Link for your Azure Cosmos DB account and enabling the Analytical store on the container provides seamless integration between Azure Cosmos DB and Azure Synapse Analytics. It allows you to load and analyze data from Azure Cosmos DB using Apache Spark in Azure Synapse Analytics without impacting the performance of your web apps.","upvote_count":"2","poster":"azuredemo2022three"}]},{"comment_id":"920658","poster":"imando","timestamp":"1718109120.0","content":"Why not E ?","upvote_count":"1"},{"timestamp":"1714563240.0","content":"Might be correct https://learn.microsoft.com/en-us/azure/synapse-analytics/synapse-link/how-to-query-analytical-store-spark","upvote_count":"1","comment_id":"886169","poster":"TRUESON"}],"topic":"5","answers_community":["AD (100%)"],"unix_timestamp":1682940840,"answer":"AD","answer_ET":"AD","answer_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/108111-exam-dp-420-topic-5-question-17-discussion/","timestamp":"2023-05-01 13:34:00","question_text":"You have an Azure Cosmos DB Core (SQL) API account that is used by 10 web apps.\nYou need to analyze the data stored in the account by using Apache Spark to create machine learning models. The solution must NOT affect the performance of the web apps.\nWhich two actions should you perform? Each correct answer presents part of the solution.\nNOTE: Each correct selection is worth one point.","answer_description":"","question_images":[]},{"id":"gKS9GXoHNGxt2BzcQyxz","answer":"","discussion":[{"comment_id":"680407","content":"RPO is 2 hours, correct, but this is not what is asked for, right!? If I set the interval to 12 hrs, then I have a RPO of 4 hours, but this is obviously a lower level of protection. Correct answer should be 12 hrs. My last backup will be deleted after 12 hours as per retention policy.","upvote_count":"13","timestamp":"1679894280.0","poster":"Internal_Koala"},{"content":"There is no information about the plan type.\n\nYou cannot call Azure support to restore data from automatic online backups in the case of the accidental deletion of a database or a container. You can create a support ticket with Microsoft Azure support or call Azure support to restore data from automatic online backups only if you have a Standard or Developer plan or any other plan higher than those. Since this use-case scenario mentions that you have a Basic Azure support plan, you cannot restore data from automatic online backups by calling or contacting Azure support. You need to upgrade from a Basic plan to at least a Standard or Developer plan to be able to leverage this feature.","timestamp":"1706193420.0","comment_id":"962716","upvote_count":"1","comments":[{"upvote_count":"1","timestamp":"1729155120.0","comment_id":"1197105","poster":"4415b99","content":"Where is it mentioned that you have a Basic Azure support plan?"}],"poster":"xofowi5140"},{"poster":"azuredemo2022three","comment_id":"939628","upvote_count":"4","timestamp":"1704095580.0","content":"12 hours\nCreate a support ticket"},{"timestamp":"1680670680.0","poster":"Lyarra","comment_id":"686576","content":"Wouldn't it provide protection for 6 hours? Backups retention is set for 12 hours, but Azure only keeps 2 backup copies by default.","upvote_count":"2","comments":[{"content":"The number of copies stored depends on the interval and the retention period.\nThe default retention backup intervall is 240 minutes (4h) and the retention period is 8h, thats why 2 copies are stored by default. The first 2 copies are free as well.\n\nIn this example, every 2h a copy is created and is kept for 12h. This means there can be up to 6 copies. 4 of the 6 copies are billed according to Azure blob storage pricing.\n\nThus, the correct answer is 12h.\n\nThis article explains that well: https://learn.microsoft.com/en-us/training/modules/implement-backup-restore-for-azure-cosmos-db-sql-api/2-evaluate-periodic-backup","timestamp":"1690271520.0","upvote_count":"1","poster":"Alex22022","comment_id":"787465"}]},{"comment_id":"682810","content":"I have 12 hours of backup, which is updated every 2 hours.","comments":[{"upvote_count":"2","comment_id":"682811","poster":"TimSss","timestamp":"1680104520.0","content":"so protection is 12h"}],"upvote_count":"1","poster":"TimSss","timestamp":"1680104460.0"}],"unix_timestamp":1664255880,"exam_id":69,"isMC":false,"answer_images":["https://www.examtopics.com/assets/media/exam-media/04276/0014800002.png"],"url":"https://www.examtopics.com/discussions/microsoft/view/83754-exam-dp-420-topic-5-question-18-discussion/","topic":"5","question_images":["https://www.examtopics.com/assets/media/exam-media/04276/0014700001.jpg","https://www.examtopics.com/assets/media/exam-media/04276/0014800001.png"],"answers_community":[],"answer_description":"Box 1: 2 hours -\nRPO is 2 hours.\nNote: Recovery Point Objective (RPO) is a measure of how frequently you take backups. If a disaster occurs between backups, can you afford to lose five minutes' worth of data updates? Or five hours? Or a full day? RPO represents how fresh recovered data will be. In practice, the RPO indicates the amount of data\n(updated or created) that will be lost or need to be reentered after an outage.\n\nBox 2: create a support ticket -\nRequest data restore from a backup\nIf you accidentally delete your database or a container, you can file a support ticket or call the Azure support to restore the data from automatic online backups.\nNote: With Azure Cosmos DB SQL API accounts, you can also maintain your own backups by using one of the following approaches:\nUse Azure Data Factory to move data periodically to a storage of your choice.\nUse Azure Cosmos DB change feed to read data periodically for full backups or for incremental changes, and store it in your own storage.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/configure-periodic-backup-restore","question_id":113,"timestamp":"2022-09-27 07:18:00","question_text":"HOTSPOT -\nYou configure a backup for an Azure Cosmos DB Core (SQL) API account as shown in the following exhibit.\n//IMG//\n\nUse the drop-down menus to select the answer choice that completes each statement based on the information presented in the graphic.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","answer_ET":""},{"id":"BiDjWUJqfGIcyT0FKrXq","url":"https://www.examtopics.com/discussions/microsoft/view/112860-exam-dp-420-topic-5-question-19-discussion/","isMC":true,"topic":"5","question_text":"You have an Azure Cosmos DB Core (SQL) API account that has multiple write regions.\nYou need to receive an alert when requests that target the database exceed the available request units per second (RU/s).\nWhich Azure Monitor signal should you use?","discussion":[{"upvote_count":"1","timestamp":"1722153300.0","content":"I don't think this the correct answer is Metadata Requests.\n\nhttps://www.examtopics.com/discussions/microsoft/view/86004-exam-dp-420-topic-5-question-2-discussion/","poster":"xofowi5140","comment_id":"965370"},{"comment_id":"931847","timestamp":"1719165960.0","poster":"azuredemo2022three","content":"Selected Answer: B\nSelected Answer: B","upvote_count":"2"},{"timestamp":"1718999100.0","poster":"azuredemo2022three","content":"B. Metadata Requests","comment_id":"929866","upvote_count":"1"}],"answer_description":"Metric Metadata Requests: Count of metadata requests. Azure Cosmos DB maintains system metadata container for each account, that allows you to enumerate collections, databases, etc., and their configurations, free of charge.\nUsed to monitor throttles due to metadata requests.\nIncorrect:\nNot A: Metric Data Usage: Total data usage reported at 5-minutes granularity per region. Used to monitor total data usage at container and region, minimum granularity should be 5 minutes.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/monitor-cosmos-db-reference#metrics","question_images":[],"exam_id":69,"answers_community":["B (100%)"],"choices":{"B":"Metadata Requests","C":"Region Removed","D":"Region Added","A":"Data Usage"},"timestamp":"2023-06-21 21:45:00","answer_ET":"B","unix_timestamp":1687376700,"answer_images":[],"answer":"B","question_id":114},{"id":"CnYtOtoSugE0sGmYzbG1","question_id":115,"answers_community":["C (59%)","B (41%)"],"exam_id":69,"discussion":[{"comment_id":"775415","poster":"mkahmann","upvote_count":"10","content":"Selected Answer: B\nI think B is the correct answer. The link provided by avocacao is about checking whether a certain amount of requests exceeded the rate limit.\n\nReading the text on this page, I think the answer should be B.\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/monitor-cosmos-db","comments":[{"upvote_count":"2","comment_id":"882667","poster":"[Removed]","timestamp":"1682601600.0","content":"I think you are right, the Provisioned Throughput metric measures the number of provisioned Request Units per second (RU/s) for a Cosmos DB account, and can be used to trigger an alert when the actual usage exceeds a threshold."},{"poster":"mkahmann","upvote_count":"1","comment_id":"775426","timestamp":"1673700900.0","content":"To be more specific:\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/monitor?tabs=azure-diagnostics#alerts"}],"timestamp":"1673700600.0"},{"poster":"andicoro","comment_id":"699728","timestamp":"1666257120.0","upvote_count":"8","content":"Selected Answer: C\nAnswer should be C for sure"},{"upvote_count":"1","timestamp":"1741635660.0","content":"Selected Answer: C\nThe correct answer is:\n\nC. Total Request Units\n\nExplanation:\nThe Total Request Units signal in Azure Monitor is used to track and monitor the consumption of Request Units per second (RU/s) in Azure Cosmos DB. By setting up an alert for this signal, you can be notified when the RU/s consumption exceeds the provisioned RU/s, which might indicate that the system is throttling requests or approaching its limit.\n\nWhy not the other options?\nA. Data Usage: This monitors the storage usage of your database and containers, not RU/s consumption.\n\nB. Provisioned Throughput: This indicates the amount of RU/s that has been provisioned, but it does not provide insight into whether your requests are exceeding this value.\n\nD. Document Count: This tracks the number of documents, not the RU/s consumption.","poster":"Tuopikson","comment_id":"1386485"},{"upvote_count":"1","comment_id":"1352009","timestamp":"1738778220.0","content":"Selected Answer: B\nBy setting up an alert for the \"Provisioned Throughput\" metric, you can monitor when the request units per second (RU/s) exceed the provisioned amount and receive notifications accordingly \nhttps://learn.microsoft.com/en-us/azure/cosmos-db/create-alerts","poster":"szkielet"},{"upvote_count":"1","comment_id":"1287988","content":"Selected Answer: B\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/monitor?tabs=azure-diagnostics#alerts\nRate limiting on request units (metric alert) -> Alerts if the container or a database has exceeded the provisioned throughput limit.","poster":"skynetbcn","timestamp":"1727068320.0"},{"content":"Selected Answer: C\nTotalRequestUnits (Total Request Units) \nUsed to monitor Total RU usage at a minute granularity. To get average RU consumed per second, use Sum aggregation at minute interval/level and divide by 60.\n\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/monitor-reference","timestamp":"1709799540.0","poster":"[Removed]","comment_id":"1167781","upvote_count":"3"},{"comment_id":"1019296","upvote_count":"1","poster":"Garyn","content":"Selected Answer: B\n\"Provisioned Throughput\" allows you to monitor the actual consumption of the provisioned RU/s against what you've provisioned for your Cosmos DB account. You can set up alerts based on this signal to notify you when your actual RU/s consumption approaches or exceeds the provisioned RU/s, helping you manage your capacity and avoid RU/s throttling.\n\n\"Total Request Units\" is more about monitoring the total number of request units consumed by queries and operations over a period of time. It's useful for understanding query performance and workload trends but may not directly alert you when RU/s consumption exceeds the provisioned amount.","timestamp":"1695860760.0"},{"timestamp":"1677828180.0","upvote_count":"4","poster":"basiltomato","comment_id":"827732","content":"Selected Answer: C\nCorrect answer: Total Request Units\n\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/create-alerts#create-an-alert-rule\n\"Now, you can define the logic for triggering an alert and use the chart to view trends of your Azure Cosmos DB account. The Total Request Units metric supports dimensions. These dimensions allow you to filter on the metric. For example, you can use dimensions to filter to a specific database or container you want to monitor. If you don't select any dimension, this value is ignored.\n\nChoose StatusCode as the Dimension name. Select Add custom value and set the status code to 429.\""},{"content":"Selected Answer: C\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/create-alerts","upvote_count":"3","poster":"avocacao","timestamp":"1671696660.0","comment_id":"753081"}],"answer_ET":"C","question_text":"You have an Azure Cosmos DB Core (SQL) API account that has multiple write regions.\nYou need to receive an alert when requests that target the database exceed the available request units per second (RU/s).\nWhich Azure Monitor signal should you use?","url":"https://www.examtopics.com/discussions/microsoft/view/86004-exam-dp-420-topic-5-question-2-discussion/","question_images":[],"answer_description":"","choices":{"C":"Total Request Units","D":"Document Count","B":"Provisioned Throughput","A":"Data Usage"},"answer_images":[],"answer":"C","timestamp":"2022-10-20 11:12:00","isMC":true,"topic":"5","unix_timestamp":1666257120}],"exam":{"isMCOnly":false,"lastUpdated":"12 Apr 2025","isImplemented":true,"provider":"Microsoft","numberOfQuestions":147,"isBeta":false,"name":"DP-420","id":69},"currentPage":23},"__N_SSP":true}