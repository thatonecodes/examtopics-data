{"pageProps":{"questions":[{"id":"7yJIIYwPYENuIBmLdESQ","topic":"2","isMC":false,"question_images":["https://www.examtopics.com/assets/media/exam-media/04274/0013700001.png","https://www.examtopics.com/assets/media/exam-media/04274/0013800001.png"],"answer":"","url":"https://www.examtopics.com/discussions/microsoft/view/87873-exam-dp-100-topic-2-question-60-discussion/","timestamp":"2022-11-18 08:52:00","answers_community":[],"unix_timestamp":1668757920,"exam_id":64,"answer_ET":"","question_id":136,"question_text":"HOTSPOT -\nYou create an Azure Machine Learning workspace named workspace1. You assign a custom role to a user of workspace1.\nThe custom role has the following JSON definition:\n//IMG//\n\nInstructions: For each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","answer_description":"Box 1: No -\nThe actions listed in NotActions are prohibited.\nIf the roles include Actions that have a wildcard (*), the effective permissions are computed by subtracting the NotActions from the allowed Actions.\n\nBox 2: No -\nDeleting compute resources in the workspace is in the NotActions list.\n\nBox 3: Yes -\nWriting metrics is not listed in NotActions.\nReference:\nhttps://docs.microsoft.com/en-us/azure/role-based-access-control/overview#how-azure-rbac-determines-if-a-user-has-access-to-a-resource","answer_images":["https://www.examtopics.com/assets/media/exam-media/04274/0013800002.png"],"discussion":[{"upvote_count":"5","poster":"ABosco","comment_id":"984146","timestamp":"1708233420.0","content":"No, No, Yes is correct. The last one is concerning the Roles not related to WS."},{"content":"Correct. No, No, Yes","poster":"PremPatrick","upvote_count":"5","comment_id":"721152","timestamp":"1684389120.0"},{"content":"No,No,NO \n\nWriting metrics specifically is not listed in the NotActions property of the provided role definition. However, the NotActions property does include \"Microsoft.MachineLearningServices/workspaces/write\", which would likely prevent the user from writing metrics to the workspace, as writing metrics would likely require write permissions on the workspace\n\nSaM","upvote_count":"3","timestamp":"1705139460.0","comment_id":"950457","poster":"PI_Team","comments":[{"upvote_count":"2","timestamp":"1708868820.0","comment_id":"990017","content":"\"Microsoft.MachineLearningServices/workspaces/write\", this line only means that It can't create or update the workspace\ni don't think that writing metrics is part of the \"updating workspace\"","poster":"Nadine_nm","comments":[{"poster":"PI_Team","timestamp":"1720020960.0","comment_id":"1112978","upvote_count":"4","content":"Yes, you are correct! My bad!"}]},{"poster":"phydev","timestamp":"1705611660.0","content":"You used \"likely\" twice. So does it or does it not?","upvote_count":"1","comment_id":"955801"}]},{"timestamp":"1689261420.0","content":"I think answer is correct\nReference: https://learn.microsoft.com/en-us/azure/machine-learning/how-to-assign-roles?tabs=labeler","comment_id":"774710","upvote_count":"3","poster":"[Removed]"}]},{"id":"6K1cDwr76UaSphA6aVA0","topic":"2","url":"https://www.examtopics.com/discussions/microsoft/view/89935-exam-dp-100-topic-2-question-61-discussion/","question_id":137,"timestamp":"2022-12-04 08:41:00","isMC":false,"answer_description":"Box 1: No -\nRunning user code in separate processes is not possible in Scala.\n\nBox 2: No -\nAutoscaling is enabled. Minimum 2 workers, Maximum 8 workers.\nReference:\nhttps://docs.databricks.com/clusters/configure.html","unix_timestamp":1670139660,"question_images":["https://www.examtopics.com/assets/media/exam-media/04274/0014000001.png","https://www.examtopics.com/assets/media/exam-media/04274/0014100001.png"],"discussion":[{"upvote_count":"12","content":"Correct answer:\n\nScala code will be executed inside the Spark JVM (per machine) that is shared between all users, so you can get access to everything that is inside JVM.\n\nhttps://learn.microsoft.com/en-us/answers/questions/924587/azure-databricks-scala-on-high-concurrency-cluster.html\n\nHigh Concurrency clusters can run workloads developed in SQL, Python, and R. The performance and security of High Concurrency clusters is provided by running user code in separate processes, which is not possible in Scala.\n\nhttps://learn.microsoft.com/en-us/azure/databricks/clusters/configure#--high-concurrency-clusters","poster":"michaelmorar","comment_id":"734920","timestamp":"1670139660.0"},{"upvote_count":"1","content":"this question is seem related to DP-203 data engineering exam more","poster":"hiyoww","comment_id":"1190803","timestamp":"1712472780.0"},{"comment_id":"1042732","comments":[{"comment_id":"1303921","content":"Pool = None\n- no parallel processes\n\nNumber of workers vary between 2 and 8 so not fixed","timestamp":"1730111640.0","poster":"jefimija","upvote_count":"1"}],"upvote_count":"1","content":"why not yes and yes>???","poster":"cyberfriends","timestamp":"1697205900.0"}],"question_text":"HOTSPOT -\nYou create a new Azure Databricks workspace.\nYou configure a new cluster for long-running tasks with mixed loads on the compute cluster as shown in the image below.\n//IMG//\n\nUse the drop-down menus to select the answer choice that completes each statement based on the information presented in the graphic.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","answer":"","answers_community":[],"exam_id":64,"answer_images":["https://www.examtopics.com/assets/media/exam-media/04274/0014100002.jpg"],"answer_ET":""},{"id":"VEpYUGpUWFV7sw8866rV","answer_ET":"","unix_timestamp":1680562200,"question_id":138,"exam_id":64,"timestamp":"2023-04-04 00:50:00","isMC":false,"answer_description":"","discussion":[{"content":"given answer is correct","comment_id":"1222390","upvote_count":"2","timestamp":"1733019360.0","poster":"evangelist"},{"upvote_count":"4","content":"Correct, the answer is: Dataset and Tabular.from_delimited_files\nTo make CSV files available for use in Azure ML experiments and data processing pipelines, and specifically for them to be loaded directly into pandas dataframes, the appropriate method from the Dataset class is Tabular.from_delimited_files.\n- Tabular.from_delimited_files is designed for structured files like CSVs and will load the data into a format that can be easily converted to pandas dataframes, which is exactly the requirement.\n\nWrong answers:\n- File.from_files is used when you are working with file datasets that are which a collection of references to the files directly without loading their contents into a structured format, rather than providing a dataset that represents the data in a tabular format like CSV.\n- Tabular.from_pandas_dataframe is used to create a tabular dataset from an existing pandas dataframe in memory, not from files in a datastore.","comment_id":"1108095","timestamp":"1719600060.0","poster":"Lion007"},{"content":"Sorry for the previous response. I've double-checked and updated the code. The answer is correct.\n\nfrom azureml.core import Workspace, Dataset\n\nws = Workspace.from_config()\nblob_ds = ws.get_default_datastore ()\ntarget_data = [(blob ds, 'data/files/archive/*.csv')]\ndata1 = Dataset.Tabular.from_delimited_files(path=target_data)\nregistered_datal datal.register(workspaws, name data1')","timestamp":"1718267760.0","upvote_count":"4","comment_id":"1095383","poster":"NullVoider_0"},{"upvote_count":"4","content":"The mentioned answer is partially correct. The actual code is given below.\n\nfrom azureml.core import Workspace, Dataset\n\nws = Workspace.from_config()\nblob_ds = ws.get_default_datastore ()\ntarget_data = [(blob ds, 'data/files/archive/*.csv')]\ndata1 = Dataset.Files.from_files(path=target_data)\nregistered_datal datal.register(workspaws, name datal')","timestamp":"1718267400.0","poster":"NullVoider_0","comment_id":"1095380"},{"poster":"orionduo","content":"It seems correct\nhttps://github.com/MicrosoftDocs/azure-docs/blob/main/articles/machine-learning/v1/how-to-create-register-datasets.md#create-a-tabulardataset","timestamp":"1709173260.0","upvote_count":"2","comment_id":"992679"},{"poster":"ajay0011","upvote_count":"2","comment_id":"860411","timestamp":"1696373400.0","content":"correct"}],"topic":"2","url":"https://www.examtopics.com/discussions/microsoft/view/105028-exam-dp-100-topic-2-question-62-discussion/","question_text":"HOTSPOT\n-\n\nYou use an Azure Machine Learning workspace. The default datastore contains comma-separated values (CSV) files.\n\nThe CSV files must be made available for use in experiments and data processing pipelines. The files must be loaded directly into pandas dataframes.\n\nHow should you complete the code? To answer, select the appropriate options in the answer area.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","question_images":["https://img.examtopics.com/dp-100/image377.png"],"answer_images":["https://img.examtopics.com/dp-100/image378.png"],"answers_community":[],"answer":""},{"id":"qFkNKnUys93lxqEIMYrj","timestamp":"2023-05-20 13:55:00","answer_description":"","topic":"2","url":"https://www.examtopics.com/discussions/microsoft/view/109787-exam-dp-100-topic-2-question-63-discussion/","exam_id":64,"discussion":[{"poster":"orionduo","upvote_count":"3","content":"correct\nhttps://learn.microsoft.com/en-us/python/api/azureml-core/azureml.core.conda_dependencies.condadependencies?view=azure-ml-py","comment_id":"992681","timestamp":"1724891160.0"},{"content":"The given answer is correct","comment_id":"902558","timestamp":"1716206100.0","upvote_count":"2","poster":"vish9"}],"question_text":"HOTSPOT\n-\n\nYou plan to use a curated environment to run Azure Machine Learning training experiments in a workspace.\n\nYou need to display all curated environments and their respective packages in the workspace.\n\nHow should you complete the code? To answer, select the appropriate options in the answer area.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","answer_ET":"","unix_timestamp":1684583700,"question_id":139,"answer_images":["https://img.examtopics.com/dp-100/image380.png"],"question_images":["https://img.examtopics.com/dp-100/image379.png"],"answer":"","isMC":false,"answers_community":[]},{"id":"zgCtyR1CARassudl7v3S","isMC":true,"choices":{"D":"Type","C":"Error count","B":"Std deviation","A":"Profile"},"question_id":140,"topic":"2","answer_ET":"C","discussion":[{"comment_id":"860414","content":"To detect columns with odd or missing values, you should analyze the Error count statistic.\n\nThe Error count statistic represents the number of missing or malformed values in each column of your dataset. Analyzing this statistic allows you to detect columns with missing values or with values that don't conform to the expected data type.\n\nThe Profile statistic provides a summary of the statistical properties of each column, such as the minimum, maximum, mean, median, and quartiles. The Std deviation statistic represents the variation of each column around its mean value. These statistics are useful to understand the distribution and variability of the data, but they don't provide information about missing or malformed values.\n\nThe Type statistic represents the data type of each column, such as integer, float, or string. While this statistic is useful to understand the structure of the dataset, it doesn't provide information about missing or malformed values.\n\nTherefore, the correct answer is option C: Error count.","upvote_count":"9","timestamp":"1680562560.0","poster":"ajay0011"},{"poster":"Sadhak","timestamp":"1731857040.0","content":"Selected Answer: C\nC. Error count","upvote_count":"1","comment_id":"1313610"},{"upvote_count":"2","timestamp":"1711384920.0","content":"on exam 3/25/2024","comment_id":"1182639","poster":"Karthikat"},{"poster":"Kanwal001","comment_id":"992464","content":"On exam 28 Aug 2023","upvote_count":"4","timestamp":"1693244040.0"},{"timestamp":"1689852120.0","comment_id":"957460","content":"On exam 20 July 2023.","upvote_count":"2","poster":"phydev"},{"poster":"Jin_22","timestamp":"1679486580.0","comment_id":"847024","content":"C. Error count\n\nTo detect columns with odd or missing values, you should analyze the \"Error count\" statistic. The Error count metric provides information on the number of missing or null values present in each column. By analyzing this metric, you can identify columns that have a high number of missing or null values, which may indicate issues with the data quality or the data collection process. Additionally, you can also identify columns with odd or unexpected values that do not fit the data distribution or that have a high number of outliers.","upvote_count":"3"}],"answer":"C","answers_community":["C (100%)"],"answer_description":"","question_text":"You are profiling data by using Azure Machine Learning studio.\n\nYou need to detect columns with odd or missing values.\n\nWhich statistic should you analyze?","question_images":[],"exam_id":64,"unix_timestamp":1679486580,"url":"https://www.examtopics.com/discussions/microsoft/view/103579-exam-dp-100-topic-2-question-64-discussion/","timestamp":"2023-03-22 13:03:00","answer_images":[]}],"exam":{"lastUpdated":"12 Apr 2025","name":"DP-100","provider":"Microsoft","isMCOnly":false,"id":64,"isImplemented":true,"numberOfQuestions":512,"isBeta":false},"currentPage":28},"__N_SSP":true}