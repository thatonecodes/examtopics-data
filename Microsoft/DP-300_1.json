{"pageProps":{"questions":[{"id":"kSnUz1Y9GlbFqn4ssFox","question_id":1,"url":"https://www.examtopics.com/discussions/microsoft/view/41948-exam-dp-300-topic-1-question-1-discussion/","answer_description":"","answer_ET":"ACE","exam_id":68,"choices":{"C":"number of concurrently peaking databases * peak CPU utilization per database","B":"geo-replication support","A":"total size of all the databases","E":"total number of databases * average CPU utilization per database","D":"maximum number of concurrent sessions for all the databases"},"answer":"ACE","discussion":[{"comment_id":"285185","poster":"Waltmas","timestamp":"1612662600.0","content":"answer is correct","upvote_count":"23"},{"content":"Selected Answer: ACE\nanswer is correct\nhttps://docs.google.com/document/d/1oNH9i2ssNi9gISG3JGuxUoUhmAA4xCaGahEKv2dRN6Y/edit?usp=sharing","upvote_count":"10","comment_id":"1401817","timestamp":"1742631180.0","poster":"Nityaanantha_Raman"},{"upvote_count":"1","comment_id":"1379940","content":"Selected Answer: ACE\nThe best size for a pool depends on the aggregate resources needed for all databases in the pool. You need to determine:\nMaximum storage bytes utilized by all databases in the pool - A\nFor the vCore-based purchasing model: https://ln.run/W3HEW\nMAX(<Total number of DBs × Average vCore utilization per DB>, <Number of concurrently peaking DBs × Peak vCore utilization per DB>) - C + E","timestamp":"1741602000.0","poster":"wayejiv"},{"timestamp":"1739779080.0","poster":"Jasmine121","comment_id":"1357648","content":"Selected Answer: ACE\nhttps://azure.microsoft.com/en-us/pricing/details/azure-sql-database/elastic/?msockid=145e6c06ec6f666823a47958ed7f67ab\nHere you can find pricing for elastic pools, and\n(A) Max Num of DBs Per Pool shoud be considered (e.g. 100/200/500)","upvote_count":"1"},{"poster":"TashaGirl","timestamp":"1731924000.0","comment_id":"1313931","content":"The best size for a pool depends on the aggregate resources needed for all databases in the pool. You need to determine:\nMaximum storage bytes utilized by all databases in the pool - A \nFor the vCore-based purchasing model:\nMAX(<Total number of DBs × Average vCore utilization per DB>, <Number of concurrently peaking DBs × Peak vCore utilization per DB>) - C + E","upvote_count":"1"},{"content":"For the vCore-based purchasing model:\nMAX(<Total number of DBs × Average vCore utilization per DB>, <Number of concurrently peaking DBs × Peak vCore utilization per DB>)","upvote_count":"1","comment_id":"1313930","poster":"TashaGirl","timestamp":"1731923880.0"},{"comment_id":"893180","content":"Selected Answer: ACE\nThe given answer is correct based on the Microsoft Learn documentation.\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/elastic-pool-overview?view=azuresql#how-do-i-choose-the-correct-pool-size","timestamp":"1727327520.0","poster":"MS_KoolaidMan","upvote_count":"2"},{"timestamp":"1702911240.0","upvote_count":"3","poster":"b0redj0rd","content":"Selected Answer: ACE\nACE is the correct response.","comment_id":"1099798"},{"poster":"Michael_Z","timestamp":"1694134500.0","comment_id":"1001989","content":"Selected Answer: ACE\nCorrect answer : ACE","upvote_count":"1"},{"content":"Selected Answer: ACE\nCorrect answer : ACE","timestamp":"1687792020.0","poster":"Pranava_GCP","comment_id":"934581","upvote_count":"1"},{"comment_id":"841434","poster":"kenn1234","content":"ACE same question in MS practice exam","upvote_count":"2","timestamp":"1679011080.0"},{"poster":"Adonor1","content":"ACE is the correct Answer","timestamp":"1645886280.0","comment_id":"556705","upvote_count":"2"},{"timestamp":"1643837760.0","content":"Given answer is correct. A,C and E\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/elastic-pool-overview\nSection: How do I choose the correct pool size.","upvote_count":"2","poster":"smaa","comment_id":"539208"},{"comment_id":"509497","content":"Answer: A, D, E","timestamp":"1640508480.0","comments":[{"poster":"pozdrotechno","content":"D is not correct. The database sessions are not mentioned anywhere in the documentation for elastic pool cost-effectiveness calculations.\n\nEach database counts as one. The number of sessions within the databases doesn't matter.","upvote_count":"2","timestamp":"1647079680.0","comment_id":"566045"}],"poster":"Chandra111","upvote_count":"1"},{"timestamp":"1630496040.0","poster":"Mladen_66","comment_id":"437094","upvote_count":"4","content":"ACE for the vCore - https://docs.microsoft.com/en-us/azure/azure-sql/database/elastic-pool-overview"},{"upvote_count":"1","poster":"learnazureportal","timestamp":"1628902320.0","comments":[{"timestamp":"1634521200.0","poster":"learnazureportal","comment_id":"463813","content":"I meant A,C.E","upvote_count":"3"}],"content":"The Correct Answer is A, D & E.","comment_id":"424565"}],"question_text":"You have 20 Azure SQL databases provisioned by using the vCore purchasing model.\nYou plan to create an Azure SQL Database elastic pool and add the 20 databases.\nWhich three metrics should you use to size the elastic pool to meet the demands of your workload? Each correct answer presents part of the solution.\nNOTE: Each correct selection is worth one point.","topic":"1","timestamp":"2021-01-10 06:58:00","isMC":true,"answers_community":["ACE (100%)"],"answer_images":[],"unix_timestamp":1610258280,"question_images":[]},{"id":"1BL7O6Nxie7nQb0DqDZK","unix_timestamp":1629713940,"url":"https://www.examtopics.com/discussions/microsoft/view/60366-exam-dp-300-topic-1-question-10-discussion/","topic":"1","answer":"D","exam_id":68,"discussion":[{"comment_id":"429874","upvote_count":"25","timestamp":"1629713940.0","poster":"HichemZe","content":"Question FOR DP-203 , Not For DBA (DP-300)"},{"comments":[{"timestamp":"1675056540.0","upvote_count":"1","comment_id":"792432","poster":"KingChuang","content":"Correct: D\n\nhttps://learn.microsoft.com/en-us/azure/event-hubs/event-hubs-quotas"}],"poster":"Oralinux","comment_id":"562827","timestamp":"1727327700.0","upvote_count":"5","content":"Selected Answer: D\nThe number of partitions is specified at creation and must be between 1 and 32. The partition count isn't changeable in all tiers except the dedicated tier, so you should consider long-term scale when setting partition count.\nhttps://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-faq"},{"content":"Selected Answer: D\nanswer D","timestamp":"1744303800.0","poster":"sincerebb","comment_id":"1559646","upvote_count":"1"},{"timestamp":"1633024080.0","comment_id":"455064","comments":[{"timestamp":"1637538420.0","upvote_count":"5","content":"The answer looks right","poster":"o2091","comment_id":"483735"}],"poster":"o2091","upvote_count":"1","content":"is the answer correct?"}],"timestamp":"2021-08-23 12:19:00","isMC":true,"answer_description":"","question_id":2,"choices":{"C":"Azure Data Factory","B":"Azure Stream Analytics","A":"Azure Event Hubs Standard","D":"Azure Event Hubs Dedicated"},"answer_ET":"D","answers_community":["D (100%)"],"question_text":"You are designing a streaming data solution that will ingest variable volumes of data.\nYou need to ensure that you can change the partition count after creation.\nWhich service should you use to ingest the data?","question_images":[],"answer_images":[]},{"id":"s5peWM5YRsXH873s1GYF","topic":"1","answer_description":"Box 1: CREATE EXTERNAL TABLE -\nAn external table points to data located in Hadoop, Azure Storage blob, or Azure Data Lake Storage. External tables are used to read data from files or write data to files in Azure Storage. With Synapse SQL, you can use external tables to read external data using dedicated SQL pool or serverless SQL pool.\nSyntax:\nCREATE EXTERNAL TABLE { database_name.schema_name.table_name | schema_name.table_name | table_name }\n( <column_definition> [ ,...n ] )\nWITH (\nLOCATION = 'folder_or_filepath',\nDATA_SOURCE = external_data_source_name,\nFILE_FORMAT = external_file_format_name\n\nBox 2. OPENROWSET -\nWhen using serverless SQL pool, CETAS is used to create an external table and export query results to Azure Storage Blob or Azure Data Lake Storage Gen2.\nExample:\n\nAS -\nSELECT decennialTime, stateName, SUM(population) AS population\n\nFROM -\nOPENROWSET(BULK 'https://azureopendatastorage.blob.core.windows.net/censusdatacontainer/release/us_population_county/year=*/*.parquet',\nFORMAT='PARQUET') AS [r]\nGROUP BY decennialTime, stateName\n\nGO -\nReference:\nhttps://docs.microsoft.com/en-us/azure/synapse-analytics/sql/develop-tables-external-tables","answers_community":[],"question_images":["https://www.examtopics.com/assets/media/exam-media/04275/0003900001.png","https://www.examtopics.com/assets/media/exam-media/04275/0004000001.png"],"exam_id":68,"unix_timestamp":1629714000,"answer":"","answer_ET":"","url":"https://www.examtopics.com/discussions/microsoft/view/60367-exam-dp-300-topic-1-question-11-discussion/","question_text":"HOTSPOT -\nYou are building a database in an Azure Synapse Analytics serverless SQL pool.\nYou have data stored in Parquet files in an Azure Data Lake Storage Gen2 container.\nRecords are structured as shown in the following sample.\n//IMG//\n\nThe records contain two applicants at most.\nYou need to build a table that includes only the address fields.\nHow should you complete the Transact-SQL statement? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","question_id":3,"discussion":[{"poster":"learnazureportal","comment_id":"463815","timestamp":"1726813260.0","content":"The Given answer is correct.","upvote_count":"8"},{"timestamp":"1744245240.0","poster":"sincerebb","comment_id":"1559426","upvote_count":"1","content":"The Given answer is correct"},{"content":"CREATE TABLE\nOPENROWSET","poster":"kkkiet","timestamp":"1675935300.0","upvote_count":"1","comment_id":"803038"},{"poster":"Ciupaz","timestamp":"1668273120.0","comment_id":"716825","upvote_count":"2","content":"Azure Synapse Analytics questions are not part of the DP-300 exam."}],"answer_images":["https://www.examtopics.com/assets/media/exam-media/04275/0004100001.png"],"isMC":false,"timestamp":"2021-08-23 12:20:00"},{"id":"ge4H2nxJzfOXJblitcKa","question_text":"You have an Azure Synapse Analytics Apache Spark pool named Pool1.\nYou plan to load JSON files from an Azure Data Lake Storage Gen2 container into the tables in Pool1. The structure and data types vary by file.\nYou need to load the files into the tables. The solution must maintain the source data types.\nWhat should you do?","question_id":4,"unix_timestamp":1629714000,"timestamp":"2021-08-23 12:20:00","exam_id":68,"discussion":[{"comments":[{"upvote_count":"6","content":"Thanks HichemZe! I was about to have a panic attack regarding several of these questions before seeing your very helpful response!","comment_id":"612934","poster":"GeoFlux121","timestamp":"1717794420.0"},{"content":"we get it ,you've made your point..... no need to have the same comment for every question .","comments":[{"comment_id":"471878","timestamp":"1698975240.0","upvote_count":"2","poster":"aprilson24","content":"ya right, why keeps on commenting for every question. lol"},{"poster":"Zonq","upvote_count":"9","content":"Maybe to indicate that this exact question is for other exam?","comment_id":"482500","comments":[{"content":"it is not from other exam. These questions are on dp-300...........","timestamp":"1701952620.0","poster":"ramelas","upvote_count":"3","comment_id":"495983"}],"timestamp":"1700482020.0"}],"poster":"Mphorish","comment_id":"437023","timestamp":"1693561320.0","upvote_count":"20"}],"timestamp":"1692786000.0","upvote_count":"32","content":"Question FOR DP-203 , Not For DBA (DP-300)","comment_id":"429876","poster":"HichemZe"},{"comment_id":"620929","upvote_count":"8","poster":"Backy","timestamp":"1719141600.0","content":"Answer is A\n\nIf you want to load into Spark pool then use Spark itself\nOPENROWSET is for the source, here the issue is the target meaning Spark"},{"timestamp":"1730221980.0","poster":"Ciupaz","content":"Azure Sinapse Analytics is out of scope of the DP-300 exam.","comment_id":"707271","upvote_count":"3"},{"comment_id":"452383","comments":[{"poster":"o2091","content":"Is the A correct? what do you think?","upvote_count":"1","comments":[{"content":"A is correct, when you create native parquet tables in spark they are automaticly available in serverless sql pools as tables","upvote_count":"3","comment_id":"502083","poster":"ramelas","timestamp":"1702639740.0"}],"comment_id":"483737","timestamp":"1700610900.0"}],"upvote_count":"3","poster":"captainpike","timestamp":"1695815100.0","content":"How using a serverless SQL pool can be the right answer if the question states to \"have an Azure Synapse Analytics Apache Spark pool named Pool1.\"? Yes, It can be copied from serverless to Apache Spark pool but that's a heck of speculation. I am going to stick with PySpark (https://docs.microsoft.com/en-us/azure/synapse-analytics/spark/apache-spark-development-using-notebooks?tabs=classical#set-a-primary-language)"}],"question_images":[],"answer_description":"Synapse notebooks support four Apache Spark languages:\nPySpark (Python)\nSpark (Scala)\n\nSpark SQL -\n.NET Spark (C#)\nNote: Bring data to a notebook.\nYou can load data from Azure Blob Storage, Azure Data Lake Store Gen 2, and SQL pool as shown in the code samples below.\nRead a CSV from Azure Data Lake Store Gen2 as a Spark DataFrame. from pyspark.sql import SparkSession from pyspark.sql.types import * account_name = \"Your account name\" container_name = \"Your container name\" relative_path = \"Your path\" adls_path = 'abfss://%s@%s.dfs.core.windows.net/%s' % (container_name, account_name, relative_path) df1 = spark.read.option('header', 'true') \\\n.option('delimiter', ',') \\\n.csv(adls_path + '/Testfile.csv')\nReference:\nhttps://docs.microsoft.com/en-us/azure/synapse-analytics/spark/apache-spark-development-using-notebooks","answer":"A","url":"https://www.examtopics.com/discussions/microsoft/view/60368-exam-dp-300-topic-1-question-12-discussion/","choices":{"B":"Load the data by using the OPENROWSET Transact-SQL command in an Azure Synapse Analytics serverless SQL pool.","D":"Use a Conditional Split transformation in an Azure Synapse data flow.","C":"Use a Get Metadata activity in Azure Data Factory.","A":"Load the data by using PySpark."},"answers_community":[],"isMC":true,"answer_ET":"A","topic":"1","answer_images":[]},{"id":"WmPLZNuQThbeDnpTPlRw","answers_community":["B (100%)"],"answer_images":[],"isMC":true,"answer":"B","answer_ET":"B","topic":"1","unix_timestamp":1629463080,"question_images":[],"question_id":5,"discussion":[{"comment_id":"428132","upvote_count":"41","poster":"HichemZe","timestamp":"1660999080.0","content":"It's a question for DP-203 !!","comments":[{"content":"Thanks for sharing that. ;)","upvote_count":"1","timestamp":"1692619680.0","comment_id":"649731","poster":"Icyb3r"},{"comment_id":"495410","poster":"mimi21212152","content":"okay we get it no need to say the same thing over and over","comments":[{"comment_id":"831779","timestamp":"1709808720.0","upvote_count":"10","content":"I think it's okay to tag the question as one from DP-203 - we don't have time to waste on questions that are not part of DP-300 objectives.","poster":"TheMCT"},{"poster":"ofzrgrz","comment_id":"993481","upvote_count":"9","content":"No, it's actually useful to confirm for each question that THIS ONE is not part of the actual DP-300 curriculum. My time is precious and I would rather not prepare for a different exam than the one I intend to take lol","timestamp":"1724962200.0"}],"timestamp":"1670359500.0","upvote_count":"6"}]},{"upvote_count":"6","content":"A replicated table has a full copy of the table available on every Compute node","poster":"gt002","timestamp":"1671476880.0","comment_id":"505041"},{"comment_id":"904431","timestamp":"1716422220.0","poster":"MS_KoolaidMan","content":"Selected Answer: B\nReplicate seems like the only logical answer.","upvote_count":"1"},{"content":"base on the following the Correct ANswer is ... ==> B.Replicate\n\nCheat sheet for dedicated SQL pool (formerly SQL DW) in Azure Synapse Analytics\n Use the following strategies, depending on the table properties:\n Type: Replicated\n Great fit for…: Small dimension tables in a star schema with less than 2 GB of storage after compression (~5x compression) \n\n\nhttps://learn.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/cheat-sheet#distributed-or-replicated-tables","timestamp":"1703340900.0","poster":"matiandal","comment_id":"754279","upvote_count":"1"},{"content":"HASH is correct, please fix!","poster":"giuseppepacilli85","comment_id":"704037","timestamp":"1698252300.0","upvote_count":"1"},{"upvote_count":"2","timestamp":"1697725620.0","comment_id":"699097","poster":"bad_atitude","content":"B. Replicated is correct"},{"comment_id":"698162","upvote_count":"3","content":"Never seen dimension tables or Synapse Analytics in MeasureUp test practice for the DP-300 exam.","poster":"Ciupaz","timestamp":"1697628000.0"},{"comment_id":"500033","content":"understand that these questions are going to be on dp 300, just stop saying that the website needs a fix. this is not a problem from website but from microsoft","upvote_count":"5","timestamp":"1670852880.0","poster":"ramelas"},{"poster":"matongax","upvote_count":"6","timestamp":"1666998120.0","comment_id":"469496","content":"minimize data movement = replicate"},{"comment_id":"468494","poster":"jerkyflexoff","timestamp":"1666866480.0","upvote_count":"1","content":"Please fix this......"},{"content":"They should fix this ASAP","timestamp":"1662077580.0","poster":"gabriel3600","comment_id":"437544","upvote_count":"3"},{"content":"They should fix this ASAP","timestamp":"1661864400.0","upvote_count":"3","comment_id":"435508","poster":"ovokpus"}],"question_text":"You are designing a date dimension table in an Azure Synapse Analytics dedicated SQL pool. The date dimension table will be used by all the fact tables.\nWhich distribution type should you recommend to minimize data movement?","answer_description":"A replicated table has a full copy of the table available on every Compute node. Queries run fast on replicated tables since joins on replicated tables don't require data movement. Replication requires extra storage, though, and isn't practical for large tables.\nIncorrect Answers:\nC: A round-robin distributed table distributes table rows evenly across all distributions. The assignment of rows to distributions is random. Unlike hash-distributed tables, rows with equal values are not guaranteed to be assigned to the same distribution.\nAs a result, the system sometimes needs to invoke a data movement operation to better organize your data before it can resolve a query.\nReference:\nhttps://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-distribute","url":"https://www.examtopics.com/discussions/microsoft/view/60055-exam-dp-300-topic-1-question-13-discussion/","timestamp":"2021-08-20 14:38:00","exam_id":68,"choices":{"A":"HASH","C":"ROUND_ROBIN","B":"REPLICATE"}}],"exam":{"isImplemented":true,"lastUpdated":"12 Apr 2025","name":"DP-300","id":68,"isBeta":false,"isMCOnly":false,"numberOfQuestions":360,"provider":"Microsoft"},"currentPage":1},"__N_SSP":true}