{"pageProps":{"questions":[{"id":"AL7VjFiB5FxQSz0KxD4Y","choices":{"B":"No","A":"Yes"},"exam_id":53,"topic":"3","discussion":[{"poster":"stieltjes","timestamp":"1617968580.0","content":"correct","upvote_count":"13","comment_id":"331919"},{"content":"Selected Answer: B\nCorrect","comment_id":"568151","poster":"Dawn7","timestamp":"1647322920.0","upvote_count":"2"},{"poster":"[Removed]","timestamp":"1647243060.0","upvote_count":"1","content":"Selected Answer: B\nCorrect","comment_id":"567486"},{"upvote_count":"1","timestamp":"1646478180.0","content":"Selected Answer: B\nCorrect answer given","comment_id":"561380","poster":"anupam77"},{"content":"Answer is No\n\nIt's the access tier you need to change","timestamp":"1633302960.0","poster":"syu31svc","upvote_count":"3","comment_id":"456788"},{"timestamp":"1632133440.0","comment_id":"448135","upvote_count":"3","content":"came in exam on 20-sep-21, I passed, i choose given answer","poster":"nkv"},{"poster":"bigngster","upvote_count":"1","content":"Correct. But this is not a good question.\n\nAs other have pointed out, Azure file share does NOT have an archive tier (https://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-create-file-share?tabs=azure-portal) . Only 3 tiers are available, Transaction optimized, Hot, Cool.\n\nPerhaps creating an Azure file share is the first step in rehydrating the data. Moving data to Cool / hot tier is rehydrating. However, the question stops short in just stating creating a file share, which does nothing to the original data.","timestamp":"1628882460.0","comment_id":"424519"},{"timestamp":"1627902840.0","content":"What a crap question, if it is intended to check the knowledge on the access tier should be NO, otherwise YES","poster":"El_Hechizo","comment_id":"418665","upvote_count":"1"},{"comment_id":"407062","upvote_count":"2","content":"archive tier, should be No?","poster":"kiwi123","timestamp":"1626351840.0"},{"comment_id":"403653","timestamp":"1625974320.0","upvote_count":"2","content":"If files stored in File Share are not accessible immediately, then how long will take when user access the file? \n\nAnswer is A","poster":"Linus0"},{"comment_id":"389708","upvote_count":"2","timestamp":"1624546800.0","poster":"ReginaldoBarreto","content":"question without foot or head....\nThis question is about the TIER, not the storage type."},{"timestamp":"1623148020.0","content":"I think the answer is A.\nFile share of Azure storage account provides immediate access.","comment_id":"377423","upvote_count":"2","comments":[{"upvote_count":"1","comments":[{"content":"slow and high reterival cost","poster":"Rajesh123","comment_id":"586813","upvote_count":"1","timestamp":"1650119100.0"}],"comment_id":"427875","poster":"pentium75","content":"Not if it's in the archive tier: \"Data in the archive tier can take several hours to retrieve depending on the specified rehydration priority.\"\n\nhttps://github.com/MicrosoftDocs/azure-docs/blob/master/articles/storage/blobs/storage-blob-storage-tiers.md","timestamp":"1629435060.0"}],"poster":"PhyMac"}],"answer_images":[],"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou have an Azure Storage account that contains two 1-GB data files named File1 and File2. The data files are set to use the archive access tier.\nYou need to ensure that File1 is accessible immediately when a retrieval request is initiated.\nSolution: You add a new file share to the storage account.\nDoes this meet the goal?","question_images":[],"answers_community":["B (100%)"],"answer_ET":"B","question_id":111,"unix_timestamp":1617968580,"url":"https://www.examtopics.com/discussions/microsoft/view/49709-exam-az-304-topic-3-question-25-discussion/","timestamp":"2021-04-09 13:43:00","isMC":true,"answer":"B","answer_description":""},{"id":"iKDat42d1w6hU5oDGccA","answer_ET":"B","isMC":true,"exam_id":53,"answer_images":["https://www.examtopics.com/assets/media/exam-media/04027/0016800001.png"],"topic":"3","answer_description":"Instead use the hot access tier.\nThe hot access tier has higher storage costs than cool and archive tiers, but the lowest access costs. Example usage scenarios for the hot access tier include:\nData that's in active use or expected to be accessed (read from and written to) frequently.\n\n✑ Data that's staged for processing and eventual migration to the cool access tier.\nReference:\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers","timestamp":"2021-04-10 16:08:00","answer":"B","discussion":[{"upvote_count":"20","timestamp":"1618063680.0","comment_id":"332597","poster":"maciezie","content":"Correct"},{"content":"https://docs.microsoft.com/en-us/azure/storage/blobs/archive-rehydrate-overview?tabs=azure-portal\n\nWhile a blob is in the archive access tier, it's considered to be offline and can't be read or modified. In order to read or modify data in an archived blob, you must first rehydrate the blob to an online tier, either the hot or cool tier. There are two options for rehydrating a blob that is stored in the archive tier:\n\nCopy an archived blob to an online tier: You can rehydrate an archived blob by copying it to a new blob in the hot or cool tier with the Copy Blob or Copy Blob from URL operation. Microsoft recommends this option for most scenarios.\n\nChange a blob's access tier to an online tier: You can rehydrate an archived blob to hot or cool by changing its tier using the Set Blob Tier operation.\n\nAnswer is No","upvote_count":"5","comment_id":"452396","timestamp":"1632744540.0","poster":"syu31svc"},{"timestamp":"1647322920.0","upvote_count":"1","content":"Selected Answer: B\nCorrect","comment_id":"568152","poster":"Dawn7"},{"comment_id":"567487","content":"Selected Answer: B\nCorrect","upvote_count":"1","poster":"[Removed]","timestamp":"1647243060.0"},{"comment_id":"562159","timestamp":"1646587260.0","poster":"azurelearner666","upvote_count":"1","content":"It's No. \n\nBut the comment \"Instead use the hot access tier\" is wrong. At least partially.\nAs the Hot & Cool access tiers will enable \"Immediate access\""}],"unix_timestamp":1618063680,"question_images":[],"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou have an Azure Storage account that contains two 1-GB data files named File1 and File2. The data files are set to use the archive access tier.\nYou need to ensure that File1 is accessible immediately when a retrieval request is initiated.\nSolution: You move File1 to a new storage account. For File1, you set Access tier to Archive.\nDoes this meet the goal?","answers_community":["B (100%)"],"url":"https://www.examtopics.com/discussions/microsoft/view/49808-exam-az-304-topic-3-question-26-discussion/","choices":{"B":"No","A":"Yes"},"question_id":112},{"id":"HHKdYug5syIqU0pS9QvF","answers_community":["A (53%)","B (47%)"],"answer":"A","question_id":113,"topic":"3","timestamp":"2020-12-02 08:17:00","answer_description":"","unix_timestamp":1606893420,"question_images":["https://www.examtopics.com/assets/media/exam-media/04027/0016900002.png"],"discussion":[{"timestamp":"1606893420.0","content":"B would be a more appropriate answer","upvote_count":"101","comments":[{"comment_id":"234276","poster":"mmmore","upvote_count":"12","content":"Agreed, I believe this question is looking us to recognise that messages need be able sent from different application components. A service bus will do this. The actual orchestration via Data Factory doesn't make a lot of sense. Something like Durable (Azure) Functions would be more suited for that.","timestamp":"1607022840.0"},{"comment_id":"233198","timestamp":"1606927260.0","content":"agreed","upvote_count":"4","poster":"andyR"},{"timestamp":"1621699620.0","upvote_count":"8","content":"\"An integration component will process the message, and then trigger either Function1 or Function2 depending on the type of order.\" to me this describes an Event Grid","comment_id":"363795","poster":"Moley"},{"comment_id":"350326","comments":[{"content":"Question states \"will process the message, and then trigger EITHER Function1 OR Function2\" (not both)","comment_id":"512378","timestamp":"1640794020.0","poster":"examineezer","upvote_count":"2"}],"upvote_count":"4","poster":"soren","content":"Agreed. There can be a generic trigger associated with the queue and within that trigger logic can determine the order type and execute the correct AZ function. The trigger can also do the logging. ADF could work but seems out of place for this task IMO.","timestamp":"1620221400.0"},{"comment_id":"1101419","content":"Correct, option B. Azure Service Bus bindings for Azure Functions - https://learn.microsoft.com/en-us/azure/azure-functions/functions-bindings-service-bus?tabs=isolated-process%2Cextensionv5%2Cextensionv3&pivots=programming-language-csharp","timestamp":"1703066400.0","poster":"trferreiraBR","upvote_count":"1"}],"poster":"MaxBlanche","comment_id":"232704"},{"content":"Look at the question carefully it states: \nAn integration component will **process** the message, and then trigger either Function1 or Function2 depending on the type of order.\nThe keyword is process the message neither Service Bus nor Event Grid provide those functionalities. \nThere is not mentioned where you would be storing the message but Azure Data Factory can integerate with various platforms and pick messages and based on that could fire either Function1 or Function2 based on order type.","comment_id":"237364","timestamp":"1607348220.0","poster":"uzairahm007","upvote_count":"74","comments":[{"timestamp":"1636212600.0","upvote_count":"2","comment_id":"473514","poster":"examineezer","content":"Event grid supports filtering. Message comes in. Filter the message based on type of order. SImples."},{"upvote_count":"4","timestamp":"1627690020.0","comment_id":"417642","poster":"PerfumoPeru","content":"Plus, this \"process\" should be audited, sending data to Azure Storage Acoount. So ADF is correct."},{"upvote_count":"14","content":"an ETL tool for managing a transaction... mmm smells strange.\n\nBUS has a FIFO option that is necessary for \"check availability\"","poster":"Oracleist","timestamp":"1618760160.0","comment_id":"338287"},{"comment_id":"250665","timestamp":"1608700260.0","poster":"arseyam","content":"Microsoft Azure Service Bus is a fully managed enterprise message broker with message queues and public-subscribe topics. Service Bus is used to decouple applications and services from each other, providing the following benefits:\nLoad-balancing work across competing workers\nSafely routing and transferring data and control across service and application boundaries\nCoordinating transactional work that requires a high-degree of reliability\nIn the question\nWhen the order is received, App1 will generate a message to check for product availability at vendor 1 and vendor 2.\n\nWith Topics the Publisher sends a message to a topic and one or more subscribers receive a copy of the message, depending on filter rules set on these subscriptions.\n\nhttps://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-queues-topics-subscriptions#topics-and-subscriptions","upvote_count":"12"}]},{"timestamp":"1735461480.0","comment_id":"1333410","content":"Selected Answer: B\nThinking as an architect:\n1. Order requests must be processed with ordering guarantees, otherwise you'll get a mess\n2. Although technically both ADF and ASB (with filtering) have required integration/processing capabilities, ADF doesn't provide ordering guarantees.\nAnswer is B: ASB","poster":"seaman33","upvote_count":"1"},{"poster":"rxlicon","upvote_count":"1","timestamp":"1693671960.0","comment_id":"996997","content":"the problem is that in the answers options you haven't a topic but only the queue service. So ASB can't process to different functions.\nLeaves only A, Azure Data factory"},{"upvote_count":"1","comment_id":"776970","timestamp":"1673809860.0","content":"Selected Answer: A\nThe requirement can be achieved with Service Bus topics/subscriptions by sending the message based on metadata to subscribers listening to a specific topic.\n\nBut since there is no such answer Factory is second best","poster":"manajerOfEmptyness"},{"content":"Selected Answer: B\nThis is what the Service Bus does.","timestamp":"1663789320.0","poster":"jellybiscuit","upvote_count":"1","comment_id":"675472"},{"upvote_count":"1","timestamp":"1661410680.0","comment_id":"651679","content":"Selected Answer: A\nAs @tteesstt said before, it's 1:M vs 1:1, it can't be SB.\nA) ADF pipeline","poster":"nidhogg"},{"content":"Selected Answer: A\nThe answer is correct. I got it wrong at first but after analysis, I have come to understand the question better. \n\nThe messaging, which is probably held using Service bus Topic, is done separately. This question is about the integration component, not the messaging service. ADF will do the processing of the messages, and the trigger F1 and/or F2.","poster":"AubinBakana","comment_id":"645460","upvote_count":"4","timestamp":"1660220580.0"},{"poster":"sapien45","comment_id":"616157","content":"Azure Service Bus\nFIFO\nDelivery guarantee : At-Most-Once \n It stores messages in a \"broker\" (for example, a queue) until the consuming party is ready to receive the messages. \nB","upvote_count":"3","timestamp":"1655204040.0"},{"content":"Where I work it's common to have the front end put messages in a service bus queue/topic to be processed by back end functions. This is critical to avoid the functions from being overwhelmed in busy times. So I'm going service bus.\n\nAlso, I don't know how the ADF which some people are proposing could be triggered to process the message from the web app, in my experience ADF is more for batch processes.","upvote_count":"1","poster":"AberdeenAngus","comment_id":"604244","timestamp":"1653024000.0"},{"content":"For people who chose B, you obviously didn’t setup and serverless environment with Azure before… without logging the data to storage you could do with Event Grid to determine the function app to call based on message type but when you need to manage the flow of data to storage account, you will ultimately need ADF or Logic App to handle the logic flow regardless whether you use ADF for ETL or not. \n\nAnswer is Azure Data Factory","upvote_count":"2","timestamp":"1649671260.0","poster":"Pupu86","comment_id":"584137"},{"upvote_count":"4","content":"Selected Answer: A\nThe question clearly asks “Which type of resource should you recommend for the integration component?”. The integration component will “process the message, and then trigger either Function1 or Function2 depending on the type of order.” This is not asking how to send the message; it’s asking how to process the message. I believe the answer is correct, ADF.","comment_id":"578525","timestamp":"1648670040.0","poster":"StevensDKLrg"},{"comment_id":"568153","poster":"Dawn7","upvote_count":"1","content":"Selected Answer: B\nI would go with B","timestamp":"1647322980.0"},{"poster":"arun","comment_id":"566262","timestamp":"1647102120.0","content":"Selected Answer: A\nAs per below link 'ADF pipeline' can consume message from Web Activity and it support transform as well so it can parse/validate the incoming message and call respective function (1 or 2)..\n\nhttps://docs.microsoft.com/en-us/azure/data-factory/concepts-pipelines-activities?tabs=data-factory#control-flow-activities\n\nI use ASB queue which cannot do message validation by itself to decide which function should be called further.\n\nHowever, ASB Topic can do the expected behavior but it's not mentioned in the answer so i think 'ADF pipeline' is best suitable from the given option.","upvote_count":"3"},{"upvote_count":"3","poster":"northgaterebel","comment_id":"548095","timestamp":"1644961860.0","content":"Selected Answer: B\nAnswer is Service Bus, no doubt. When to use: Order processing and financial transactions. \nhttps://docs.microsoft.com/en-us/azure/event-grid/compare-messaging-services#comparison-of-services"},{"poster":"ScottyKnows","upvote_count":"4","timestamp":"1644369660.0","comment_id":"543457","content":"Selected Answer: A\nMultiple sources confirm it to be Datafactory."},{"comment_id":"543202","poster":"carlos045","upvote_count":"1","timestamp":"1644339120.0","content":"i think is B"},{"timestamp":"1644266820.0","comment_id":"542661","upvote_count":"1","content":"Selected Answer: B\nQuestion asks for a resource. Pipeline is not a resource \"A data factory can have one or more pipelines. A pipeline is a logical grouping of activities that together perform a task.\"\nIf the ADF is correct, it would say A - Azure Data Factory, but it is a Pipeline that is not a resource.","poster":"Uglydotcom"},{"timestamp":"1643890740.0","poster":"Limburg2020","upvote_count":"1","comment_id":"539678","content":"Answer A\nA data factory can have one or more pipelines. A pipeline is a logical grouping of activities that together perform a task. The activities in a pipeline define actions to perform on your data. Data Factory has three groupings of activities: data movement activities, data transformation activities, and control activities. Azure Functions is now integrated with Azure Data Factory, allowing you to run an Azure function as a step in your data factory pipelines."},{"comment_id":"537433","content":"Seen today 31/1/2022 in my exam","poster":"bruncili","timestamp":"1643662020.0","upvote_count":"2"},{"content":"Service Bus:\n\"Filtering and actions\nSubscribers can define which messages they want to receive from a topic. These messages are specified in the form of one or more named subscription rules. For each matching rule condition, the subscription produces a copy of the message, which may be differently annotated for each matching rule.\"\nAnd the question asks to direct messages based on order type. So it is a perfect match.","comment_id":"529573","poster":"jmay","upvote_count":"1","timestamp":"1642822920.0"},{"comments":[{"poster":"yyuryyucicuryyforme","timestamp":"1642469880.0","content":"Well, in the link mentioned, it clearly says \"Azure Data Factory (ADF) is a managed data integration service\" and the requirement is for an integration component. A queue or a bus is also an integration component but these are more storage and communication not processing. I have no doubt A) is a solution and can orchestrate or even directly perform the necessary processing and control activities. I wonder if any architect would choose it as it seems overkill.","upvote_count":"3","comment_id":"526238"}],"poster":"FBFTopics","content":"Maybe it's A because of this link: https://azure.microsoft.com/es-es/blog/azure-functions-now-supported-as-a-step-in-azure-data-factory-pipelines/\n\"Azure Functions is now integrated with ADF, allowing you to run an Azure function as a step in your data factory pipelines\".\nThey're asking to trigger either Function1 or Function2.\nHowever, I'm not really sure, sorry.","upvote_count":"2","comment_id":"521337","timestamp":"1641884820.0"},{"poster":"tomatosis","upvote_count":"1","comment_id":"513435","timestamp":"1640873220.0","content":"I will go for B. There are many people leaning towards A which I could not understand. The key in this question is \"message\". From the link regarding Option A, I can't find anything related to message. How can it be the correct answer?"},{"comment_id":"512384","timestamp":"1640794260.0","content":"With service bus, on a single queue, you can have multiple subscriptions, each of which CAN include a filter. Ignore my other comments below - the answer is B","poster":"examineezer","upvote_count":"1"},{"content":"Selected Answer: B\nAnswer is B. \nADF pipeline is used for data processing. Azure service bus -> subscriber triggers the function requested. I would go this way.","timestamp":"1639822800.0","comment_id":"504149","poster":"[Removed]","upvote_count":"2"},{"poster":"ZodiaC","timestamp":"1639244100.0","upvote_count":"3","comment_id":"499568","content":"Selected Answer: B\nSURE! 100%"},{"content":"Selected Answer: B\nis 100% B because that more appropriate to this question","timestamp":"1638687900.0","comment_id":"494126","upvote_count":"3","poster":"ZodiaC"},{"timestamp":"1634336520.0","content":"People are saying B but Service Bus can't do the following: \"process the message, and then trigger either Function1 or Function2\". There is no such feature in Service Bus, it's either 1:1 queue or 1:M Topic. It cannot dynamically pick 1 function to execute on some predefined rule.\nA) ADF Pipeline","poster":"tteesstt","upvote_count":"9","comment_id":"462816"},{"poster":"JeremyRui","upvote_count":"1","timestamp":"1633789680.0","content":"From here https://docs.microsoft.com/en-us/azure/event-grid/compare-messaging-services it is clearly showing that SB is used for order processing","comment_id":"459672"},{"timestamp":"1633789020.0","content":"The question is asking about the 'Integration Component', which requirements are described in bullet point2. It's NOT asking about the system. So it's about message processing and B should be the right answer.","comment_id":"459668","upvote_count":"2","poster":"JeremyRui"},{"content":"I would go for B as the answer\n\nhttps://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messaging-overview\n\nMicrosoft Azure Service Bus is a fully managed enterprise message broker with message queues and publish-subscribe topics\nPost results of processing to one or more different queues.\n\nService Bus is one of the triggers for Azure functions\n\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-triggers-bindings?tabs=csharp","poster":"syu31svc","timestamp":"1633517220.0","upvote_count":"4","comment_id":"458188"},{"poster":"Spooky7","comment_id":"452631","upvote_count":"4","timestamp":"1632763440.0","content":"I would go for B:\n- Azure Service Bus with 1 topic and 2 subscriptions, each for different vendor\n- 2 Azure Functions with Azure Bus triggers pointing out to specific topic and subscription\n\nThere is a lot of confusion about \"process\" statement. It doesn't have to mean data transformation or custom logic. It may simply means putting message in right queue which ServiceBus topics are exactly doing underhood.\n\nA - is overkill, doesn't fit to given scenario. It is clearly a question related to message processing\nC - Event Grid domain is a meta-topic over multiple EventGrid topic, but we need here only 1 topic, so overkill again\nD - is used in different scenarios","comments":[{"poster":"rdemontis","content":"the problem is that in the answers options you haven't a topic but only the queue service. So it can't fit the bill","timestamp":"1637336400.0","upvote_count":"2","comment_id":"481891"}]},{"poster":"addam23","timestamp":"1629343320.0","content":"It is the weirdest-message solution I've ever met, but the answer is... A.\nThe message must be 'processed' and azure functions must be 'triggered by'. A mandess. \nBut it seems to be it. Each normal guy will just create 2 sb queries or topics...","comment_id":"427184","upvote_count":"2"},{"comment_id":"425040","content":"B is the most appropriate and most comment solution in this case.","poster":"teehex","upvote_count":"1","timestamp":"1629002460.0"},{"upvote_count":"1","content":"B without doubts","poster":"gssd4scoder","comment_id":"406124","timestamp":"1626255420.0"},{"poster":"riti5171","comment_id":"400865","timestamp":"1625660940.0","upvote_count":"3","content":"Here ADF is acting like an orchestration service where multiple actions are performed on the basis of outcomes. Very typical ADF scenario."},{"comment_id":"397049","poster":"Entarch","content":"Option B looks appropriate. ADF works better in other use cases wherein it can acquire data from a DB, transform and then store in Azure Data Lake.","upvote_count":"2","timestamp":"1625243400.0"},{"content":"Answer is B: Service Bus\n\nIt clear state all the time that will process a message, not an event, and there is a bid difference between the two.\nAlso it states that all steps should be saved to stored, if it is an event, there is not garantee that it will be picked. But if it is a message it will stay in a queue until picked and processed.\n\nREF: https://docs.microsoft.com/en-us/azure/event-grid/compare-messaging-services","upvote_count":"5","comment_id":"383448","timestamp":"1623851640.0","poster":"GetulioJr"},{"comment_id":"381755","upvote_count":"1","poster":"meghatulli","timestamp":"1623663840.0","content":"Service Bus. The integration component that 'processes' messages to decide which subscriber could be filters: \nhttps://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-filter-examples"},{"poster":"AZExamTaker2021","upvote_count":"1","comment_id":"380260","timestamp":"1623479160.0","content":"This scenario talks about the case where App1 send the information to the next processor to get the availability of the product. hence there is an expectation from the originator side. hence this is NOT a EVEN this is more message which MUST be processed. So Event Gris is not the right choice as this is not an Event. Now for Service bus - it work in PULL mode where Subscriber has to work to pull the data. Now it requires some one to invokes the Function App which can the pull the information from Service Bus (as subscriber needs to pull) which is NOT mentioned here. hence ADF could be the best possible choice. What do you say?"},{"content":"The answer should C 'Event Grid'.\nEvent Grid provides us the filter on topic and also enable us to implement pub/sub architecture. Queue is First In First Out therefore we won't be able to use for Function Subscription because Queue Trigger will also provide to One designated function. You can direct message to Function1 or Function 2.\n\nThe answer should be 'Event Grid'.","poster":"erickim007","timestamp":"1623384180.0","comment_id":"379443","upvote_count":"1"},{"content":"The answer should be C 'Event Grid Domain' which consists of different topic. With Event Grid Topic, you can filter topic and provide subscription to different Function.\nIn addition, Event Grid Topic can have storage account queue as subscriber, should we need to provide message queue received results back.","poster":"erickim007","upvote_count":"2","comment_id":"370514","timestamp":"1622417040.0"},{"content":"When a message needs to be processed (before calling Func A or Func B), then the only correct option is ADF. None of the other options can “ process” a message!\n\nSo, the given answer is correct:\nA. ADF","poster":"SriRamOne","timestamp":"1621986180.0","comment_id":"366736","upvote_count":"4"},{"poster":"outrageousorange","content":"Event Grid\n\n\"filter by a value in the data object\"\n\nhttps://docs.microsoft.com/en-us/azure/event-grid/how-to-filter-events#filter-by-operators-and-data","upvote_count":"1","comment_id":"359871","timestamp":"1621291320.0"},{"poster":"Harish55","upvote_count":"20","content":"Have got the same question in the exam. But service bus wasn't there as an option.","timestamp":"1620634740.0","comment_id":"353549"},{"timestamp":"1620056700.0","content":"When it comes to apps, messages and triggering functions the best model is to use service bus and both functions will subscribe to it. #AzureWellArchitectedFramework","comment_id":"348767","poster":"demonite","upvote_count":"1"},{"comment_id":"335914","timestamp":"1618452300.0","upvote_count":"8","content":"I think in B, but rechecking the requirement: \"An integration component will process the message, and then trigger either Function1 or Function2 depending on the type of order.\"\nIt say \"process\" and the \"trigger\", service bus Queue is a broker, is not capable to process the message, obviously when we say process it means transformation/enrichment or maybe format the message, so the answer should be A","poster":"claudio82"},{"poster":"mortezaadi","comment_id":"328838","content":"Azure Data factory is mostly used in bigdata and the pipeline is for transformation and consumption of data :\n\nhttps://docs.microsoft.com/en-us/azure/data-factory/introduction\n\nthough you can achieve the goal of this question by data factory, it is not the right product for this scenario, I'll go with service bus here","upvote_count":"3","timestamp":"1617638340.0"},{"poster":"ricky007","comment_id":"316268","content":"I would have said B as the answer. But the question says \"Processing\" before calling functions. Service Bus is broker but not processor. So going with ADF. Not clear though, pretty tricky.","upvote_count":"3","timestamp":"1616324460.0"},{"timestamp":"1615546260.0","upvote_count":"1","poster":"Unofficial","comment_id":"308778","content":"When handling high-value messages that cannot be lost or duplicated, use Azure Service Bus.\n\nhttps://docs.microsoft.com/en-us/azure/event-grid/compare-messaging-services"},{"upvote_count":"5","poster":"avii","timestamp":"1615213500.0","content":"It should be A.\nRead this point which says : An integration component will process the message\nNote: SB will not process message and trigger function app.","comment_id":"305764"},{"poster":"Deepbond","upvote_count":"4","content":"A is correct answer.\nThe catch here is \"process\". Component will process the message and trigger either F1 or F2 based on \"order type\".\nService bus can't handle business logic so it should be ADF.","timestamp":"1615160820.0","comment_id":"305423"},{"comment_id":"301747","timestamp":"1614653220.0","poster":"ElsaBBP","upvote_count":"2","content":"for message transfer, service bus is the option. for integration of the process, Data Factory Pipeline is the only option so the provided answer is correct."},{"poster":"hghemant","timestamp":"1614526200.0","upvote_count":"1","comment_id":"300860","content":"Azure Service Bus queue"},{"upvote_count":"4","content":"I think the best option is a logic apps or another function, but for the given answer, only DataFactory is able to process the message and send it to different target.","timestamp":"1613767560.0","poster":"S_d90","comment_id":"294593"},{"timestamp":"1613311140.0","content":"A data factory can have one or more pipelines. A pipeline is a logical grouping of activities that together perform a task. For example, a pipeline could contain a set of activities that ingest and clean log data, and then kick off a mapping data flow to analyze the log data. The pipeline allows you to manage the activities as a set instead of each one individually. You deploy and schedule the pipeline instead of the activities independently.\n\nThe activities in a pipeline define actions to perform on your data. For example, you may use a copy activity to copy data from SQL Server to an Azure Blob Storage. Then, use a data flow activity or a Databricks Notebook activity to process and transform data from the blob storage to an Azure Synapse Analytics pool on top of which business intelligence reporting solutions are built.\n\nData Factory has three groupings of activities: data movement activities, data transformation activities, and control activities. An activity can take zero or more input datasets and produce one or more output datasets. The following diagram shows the relationship between pipeline, activity, and dataset in Data Factory:\n\nRelationship between dataset, activity, and pipeline","poster":"expertaz","upvote_count":"2","comment_id":"290299"},{"upvote_count":"3","timestamp":"1612796820.0","content":"Answer is azure data factory as we could only either call function 1 or function 2 if use service bus queues not any of them as service bus queue is bind to single function only as function name is mentioned in annotation and there is no parameter or configuration which can change function name dynamically.\n@FunctionName(\"sbprocessor\")\n public void serviceBusProcess(\n @ServiceBusQueueTrigger(name = \"msg\",\n queueName = \"myqueuename\",\n connection = \"myconnvarname\") String message,\n final ExecutionContext context\n ) \nThe ServiceBusQueueTrigger annotation allows you to create a function that runs when a Service Bus queue message is created. Configuration options available include queue name and connection string name.\nThe ServiceBusTopicTrigger annotation allows you to designate a topic and subscription to target what data triggers the function.\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-service-bus-trigger?tabs=java#example","poster":"azurecert2021","comments":[{"poster":"Aghora","content":"can you not have 2 queues in a service bus ? the app would send the message to corresponding queue and that ques would then triggers the corresponding function . my understanding is that you can have many ques in a service bus and use each on for different function . please correct me if iam wrong . thank you","comment_id":"287637","timestamp":"1612970640.0","upvote_count":"1"}],"comment_id":"286271"},{"content":"Answer is A - Azure Data Factory pipeline (via Azure Function Activity)\n\nTranslated flow with services:\nApp1 > {message} > Service Bus > Data Factory > {triggers} > Func1/2 (vendor) ; \n\nClues: \nTransaction flow #2: App1 generates a message ... we can imply (implicitly) this goes into a queue which could be service bus (fifo or topics - pub/sub model) or storage queues (standard). \nTransaction flow #3: ***the crux of question***; we can infer the integration component \"processes the message and triggers func1/2\". This clearly rules out service bus queues (holds messages, does not process), event grid (triggers, does not process) and event hubs (stream capture, does not process). So we are left with Azure Data Factory where we can leverage \"Azure Function Activity which allows you to run Azure functions\" via a linked service connection >>>> https://docs.microsoft.com/en-us/azure/data-factory/control-flow-azure-function-activity","timestamp":"1612231500.0","upvote_count":"6","comments":[{"upvote_count":"1","poster":"xaccan","timestamp":"1612691700.0","content":"u re wrong, it is B. an Azure Service Bus queue","comment_id":"285424"}],"comment_id":"281550","poster":"JohnWick2020"},{"timestamp":"1611861960.0","content":"The provided answer (ADF pipeline) could be correct per below example.\nhttps://www.sqlservercentral.com/blogs/communication-in-azure-using-data-factory-to-send-messages-to-azure-service-bus","comment_id":"278778","upvote_count":"2","poster":"MichaelCWWong"},{"content":"B. an Azure Service Bus queue","timestamp":"1611536760.0","poster":"glam","upvote_count":"1","comment_id":"275592"},{"comment_id":"275555","upvote_count":"4","content":"A is correct, I had two other exams dumps and both has, actual test and exams boost!","timestamp":"1611531180.0","poster":"FK2974"},{"comment_id":"275502","timestamp":"1611522840.0","upvote_count":"1","content":"Option B - Service Bus is closest match","poster":"alphamode"},{"poster":"Haritosh","content":"ASBQ is the correct answer. Data Factory is for entirely different purpose.","timestamp":"1611378780.0","upvote_count":"1","comment_id":"274304"},{"upvote_count":"1","content":"ADF is ETL tool but Service Bus is used for Integration in application. I would choose Service bus as answer.","comment_id":"273243","timestamp":"1611264360.0","poster":"milind8451"},{"poster":"stylocool","timestamp":"1611132240.0","comments":[{"comment_id":"427894","content":"But can that trigger different functions depending of the message content?","upvote_count":"1","timestamp":"1629437340.0","poster":"pentium75"}],"comment_id":"271838","content":"B is correct because service bus can trigger functions\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-service-bus-trigger?tabs=csharp","upvote_count":"1"},{"timestamp":"1610590500.0","upvote_count":"1","poster":"nohaph","content":"Correct Answer is B --> Az Service Bus Queue because it is a secure message broker.\nReference --> https://docs.microsoft.com/en-us/azure/architecture/reference-architectures/enterprise-integration/queues-events","comment_id":"266670"},{"content":"it should be another Function (or App Service) + Service Bus with 1 incoming queue and optionally pub/sub for F1 anf F2\n\npretty weird wording in question and answers","upvote_count":"2","poster":"nexnexnex","comment_id":"266181","timestamp":"1610530620.0"},{"comment_id":"264906","poster":"Ziegler","timestamp":"1610385120.0","upvote_count":"1","content":"B is the correct answer\n\nhttps://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messaging-overview"},{"timestamp":"1610162940.0","comment_id":"262968","content":"It is \"B - Service Bus\". Microsoft Documentation says \"Transfer business data, such as sales or purchase orders, journals, or inventory movements.\"\nhttps://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messaging-overview","poster":"bipin24x7","upvote_count":"1"},{"content":"This also discussed here:\n https://www.examtopics.com/discussions/microsoft/view/30305-exam-az-304-topic-3-question-2-discussion/","comment_id":"261024","poster":"SyntaxError","timestamp":"1609938900.0","upvote_count":"1"},{"timestamp":"1609788180.0","content":"Service bus Queue: https://docs.microsoft.com/pl-pl/azure/event-grid/compare-messaging-services","upvote_count":"1","comment_id":"259651","poster":"kirsie"},{"content":"given answer is correct.","comment_id":"259081","poster":"sanketshah","upvote_count":"1","timestamp":"1609729140.0"},{"content":"Service Bus Queue is the right answer","timestamp":"1608994740.0","poster":"ihustle","comment_id":"252701","upvote_count":"3"},{"comment_id":"246515","poster":"shashu07","upvote_count":"3","timestamp":"1608209160.0","content":"SERVICE BUS\nSince vendor is involved, its a distributed platform, ideal for service bus.\nIntegrated component is Service bus as it can process the message and trigger to functions as well, according to below post\nUse the Service Bus trigger to respond to messages from a Service Bus queue or topic. Starting with extension version 3.1.0, you can trigger on a session-enabled queue or topic\nAzure Service Bus trigger for Azure Functions\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-service-bus-trigger?tabs=csharp"},{"poster":"bob2007","upvote_count":"3","content":"DF is more to copy data https://docs.microsoft.com/en-us/azure/data-factory/control-flow-azure-function-activity SB is for messaging https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-service-bus","timestamp":"1608182520.0","comment_id":"246209"},{"comments":[{"content":"look at the definition of Event Grid how would it help in this scenario?\nEvent Grid is an eventing backplane that enables event-driven, reactive programming. It uses a publish-subscribe model. Publishers emit events, but have no expectation about which events are handled. Subscribers decide which events they want to handle.","poster":"uzairahm007","upvote_count":"1","comment_id":"237362","timestamp":"1607347980.0"},{"poster":"GenXCoder","timestamp":"1607358240.0","upvote_count":"5","content":"There is no delay with Service Bus unless the receiving service is backed up. The question is about messages, not events -> both event hub and event grid are out.","comment_id":"237483"},{"comment_id":"284718","poster":"YellowSky002","timestamp":"1612609020.0","content":"\"✑ An integration component will process the message, and then trigger either Function1 or Function2 depending on the type of order.\"\nNo delay with Service Bus, there is a latency.\nService bus and Event Grid will NOT be able to process anything.\nFunc1 and Func2 will not be called together it is one or the other.","upvote_count":"1"}],"timestamp":"1607200800.0","content":"Service Bus is a brokered messaging system. It stores messages in a \"broker\" (for example, a queue) until the consuming party is ready to receive the messages. So, there could be a delay in getting the response which beats the purpose of this live user interaction session where the polling could delay the response. Because it will wait for the function to pick the message and both the functions should be picking the same message to check the availability with two different vendors. and once a message is consumed it is no longer available for others to consume. hence, even grid is the right solution.","upvote_count":"3","poster":"Abbas","comment_id":"236026"}],"answer_images":[],"choices":{"B":"an Azure Service Bus queue","A":"an Azure Data Factory pipeline","D":"an Azure Event Hubs capture","C":"an Azure Event Grid domain"},"url":"https://www.examtopics.com/discussions/microsoft/view/38412-exam-az-304-topic-3-question-27-discussion/","question_text":"You are designing an order processing system in Azure that will contain the Azure resources shown in the following table.\n//IMG//\n\nThe order processing system will have the following transaction flow:\n✑ A customer will place an order by using App1.\n✑ When the order is received, App1 will generate a message to check for product availability at vendor 1 and vendor 2.\n✑ An integration component will process the message, and then trigger either Function1 or Function2 depending on the type of order.\n✑ Once a vendor confirms the product availability, a status message for App1 will be generated by Function1 or Function2.\n✑ All the steps of the transaction will be logged to storage1.\nWhich type of resource should you recommend for the integration component?","answer_ET":"A","isMC":true,"exam_id":53},{"id":"YGBcs6dzZywITlz5GtW7","answer_ET":"","answer_images":["https://www.examtopics.com/assets/media/exam-media/04027/0017100001.png"],"question_text":"HOTSPOT -\nYou have an existing implementation of Microsoft SQL Server Integration Services (SSIS) packages stored in an SSISDB catalog on your on-premises network.\nThe on-premises network does not have hybrid connectivity to Azure by using Site-to-Site VPN or ExpressRoute.\nYou want to migrate the packages to Azure Data Factory.\nYou need to recommend a solution that facilitates the migration while minimizing changes to the existing packages. The solution must minimize costs.\nWhat should you recommend? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","unix_timestamp":1607348520,"answers_community":[],"timestamp":"2020-12-07 14:42:00","question_images":["https://www.examtopics.com/assets/media/exam-media/04027/0017000001.png"],"topic":"3","isMC":false,"exam_id":53,"url":"https://www.examtopics.com/discussions/microsoft/view/39126-exam-az-304-topic-3-question-28-discussion/","answer":"","answer_description":"Box 1: Azure SQL database -\nYou can't create the SSISDB Catalog database on Azure SQL Database at this time independently of creating the Azure-SSIS Integration Runtime in Azure Data\nFactory. The Azure-SSIS IR is the runtime environment that runs SSIS packages on Azure.\nBox 2: Azure-SQL Server Integration Service Integration Runtime and self-hosted integration runtime\nThe Integration Runtime (IR) is the compute infrastructure used by Azure Data Factory to provide data integration capabilities across different network environments. Azure-SSIS Integration Runtime (IR) in Azure Data Factory (ADF) supports running SSIS packages.\nSelf-hosted integration runtime can be used for data movement in this scenario.\nReference:\nhttps://docs.microsoft.com/en-us/azure/data-factory/create-azure-integration-runtime https://docs.microsoft.com/en-us/sql/integration-services/lift-shift/ssis-azure-connect-to-catalog-database","question_id":114,"discussion":[{"upvote_count":"51","content":"Box 1: Azure SQL database -\nBox 2: Azure-SQL Server Integration Service Integration Runtime and self-hosted integration runtime","comment_id":"275599","timestamp":"1611537540.0","poster":"glam"},{"timestamp":"1607348520.0","comment_id":"237369","upvote_count":"16","comments":[{"comments":[{"upvote_count":"1","comment_id":"529295","poster":"FinMessner","timestamp":"1642789320.0","content":"It's going to an Azure SQL DB first..."}],"timestamp":"1609085820.0","content":"because data coming from on-prem, you need self hosted","upvote_count":"5","poster":"jhoomtv","comment_id":"253430"},{"comment_id":"308611","poster":"sallymaher","upvote_count":"4","content":"in this case you are moving the package directly to ADF , so why you will use Asure SQL in the first box ??? As long as I'll use Azure SQL so Azure IR is enough .","timestamp":"1615531200.0"}],"poster":"uzairahm007","content":"Why Self hosted IR?\nThis article describes how to run SQL Server Integration Services (SSIS) packages on an Azure-SSIS Integration Runtime (Azure-SSIS IR) in Azure Data Factory with a self-hosted integration runtime (self-hosted IR) configured as a proxy.\n\nWith this feature, you can access data on-premises without having to join your Azure-SSIS IR to a virtual network. The feature is useful when your corporate network has a configuration too complex or a policy too restrictive for you to inject your Azure-SSIS IR into it.\nhttps://docs.microsoft.com/en-us/azure/data-factory/self-hosted-integration-runtime-proxy-ssis\nAs Azure cloud does not connectivity to on Premise network you would need to implement self Hosted-IR as well"},{"poster":"[Removed]","upvote_count":"2","comment_id":"567494","content":"Correct answer given","timestamp":"1647243960.0"},{"poster":"FinMessner","timestamp":"1642789260.0","upvote_count":"1","content":"Provision. Before you can deploy and run SSIS packages in Azure, you have to provision the SSIS Catalog (SSISDB) and the Azure-SSIS Integration Runtime.\n\nYou don't need a self-hosted integration runtime also because the catalog is now in an Azure SQL SSIS DB.","comment_id":"529291"},{"poster":"syu31svc","upvote_count":"4","content":"https://docs.microsoft.com/en-us/sql/integration-services/lift-shift/ssis-azure-lift-shift-ssis-packages-overview?view=sql-server-ver15\n\nYou can now move your SQL Server Integration Services (SSIS) projects, packages, and workloads to the Azure cloud. Deploy, run, and manage SSIS projects and packages in the SSIS Catalog (SSISDB) on Azure SQL Database or SQL Managed Instance with familiar tools such as SQL Server Management Studio (SSMS).\n\nhttps://docs.microsoft.com/en-us/azure/data-factory/self-hosted-integration-runtime-proxy-ssis\n\nWith this feature, you can access data and run tasks on premises without having to join your Azure-SSIS IR to a virtual network\n\nAnswer is correct","timestamp":"1633350060.0","comments":[{"poster":"sapien45","upvote_count":"1","timestamp":"1655205060.0","content":"Great answer","comment_id":"616167"}],"comment_id":"457112"},{"poster":"Gautam1985","upvote_count":"2","comment_id":"435108","timestamp":"1630301340.0","content":"Correct"},{"timestamp":"1627992660.0","content":"To run SSIS packages, you need \"Azure-SQL Server Integration services Integration runtime\" https://www.youtube.com/watch?v=weiHOeje-QA min 3:07. To connect without VPN or Express Route, you need to install a self-hosted integration runtime that acts as a proxy (as seen on video). Then the second Box is: \"Azure-SQL Server Integration services Integration runtime and self-hosted integration\". \nFor the first one, I guess Azure SQL Database.","upvote_count":"5","poster":"El_Hechizo","comment_id":"419205"},{"poster":"Jasper666","comment_id":"381017","upvote_count":"1","timestamp":"1623578820.0","comments":[{"poster":"Amit3","content":"Question says you need to facilitate migtration but doesn't say you have migrated already.","timestamp":"1623608280.0","upvote_count":"1","comment_id":"381264"}],"content":"Select the Set up Self-Hosted Integration Runtime as a proxy for your Azure-SSIS Integration Runtime check box to choose whether you want to configure a self-hosted IR as proxy for your Azure-SSIS IR. Since we migrated completely to azure this is not needed. Box 1 is azure sql database and Box 2 is azure SSIS IR only. (https://docs.microsoft.com/en-us/azure/data-factory/self-hosted-integration-runtime-proxy-ssis)"},{"timestamp":"1619370300.0","content":"Correct answer","upvote_count":"3","poster":"aspirin","comment_id":"342733"},{"content":"The installation of a self-hosted integration runtime needs an on-premises machine or a virtual machine inside a private network.\nI would select 2 for Box 2.","upvote_count":"1","timestamp":"1618664340.0","comment_id":"337594","poster":"Leon3020"},{"poster":"prashantjoge","timestamp":"1616400000.0","upvote_count":"4","content":"is this even in the syllabus... id ont see any mention of this in MS learn","comment_id":"316952"},{"comment_id":"301748","content":"the second answer would be C only if you have a stable Site to Site connectivity or ER. without this, an SSIS IR only is the correct answer. I know the question is so misleading :)","timestamp":"1614653820.0","poster":"ElsaBBP","upvote_count":"2"},{"content":"In my opinion the answer is correct, as per your reference @uzairahm007, \"This article describes how to run SQL Server Integration Services (SSIS) packages on an Azure-SSIS Integration Runtime (Azure-SSIS IR) in Azure Data Factory with a self-hosted integration runtime (self-hosted IR) configured as a proxy.\n\nWith this feature, you can access data on-premises without having to join your Azure-SSIS IR to a virtual network. The feature is useful when your corporate network has a configuration too complex or a policy too restrictive for you to inject your Azure-SSIS IR into it.\" So both self hosted and Azure SSIS IR are needed for this feature to work.","upvote_count":"6","timestamp":"1610831820.0","comment_id":"269119","poster":"rizabeer"},{"upvote_count":"2","comment_id":"266167","poster":"heany","content":"second one should be IR only. as self-hosting is running on on-prem network. but it also mentioned 'The on-premises network does not have hybrid connectivity to Azure by using Site-to-Site VPN or ExpressRoute'","timestamp":"1610529720.0"},{"poster":"Sasi27","content":"so whats the answer then ?","timestamp":"1610370060.0","upvote_count":"1","comment_id":"264731"}]},{"id":"ANK9exQpnD4zfsNDejlJ","question_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/30777-exam-az-304-topic-3-question-29-discussion/","unix_timestamp":1599475980,"answers_community":["C (100%)"],"question_id":115,"answer":"C","isMC":true,"answer_images":[],"timestamp":"2020-09-07 12:53:00","choices":{"D":"Azure Stack Hub","A":"Azure StorSimple","B":"Azure Batch","C":"Azure Data Box"},"answer_description":"Microsoft has engineered an extremely powerful solution that helps customers get their data to the Azure public cloud in a cost-effective, secure, and efficient manner with powerful Azure and machine learning at play. The solution is called Data Box.\nData Box and is in general availability status. It is a rugged device that allows organizations to have 100 TB of capacity on which to copy their data and then send it to be transferred to Azure.\nIncorrect Answers:\nA: StoreSimple would not be able to handle 70 TB of data.\nReference:\nhttps://www.vembu.com/blog/what-is-microsoft-azure-data-box-disk-edge-heavy-gateway-overview/","discussion":[{"timestamp":"1599475980.0","content":"https://docs.microsoft.com/en-us/azure/databox/data-box-overview\n80TB max for Databox","poster":"speedminer","comments":[{"upvote_count":"5","poster":"folkmusic99","content":"100-TB device has 80 TB or usable capacity after RAID 5 protection","comment_id":"375354","timestamp":"1622914260.0"}],"upvote_count":"23","comment_id":"175142"},{"upvote_count":"9","poster":"sumedh01","comment_id":"228495","timestamp":"1606411560.0","content":"Storage capacity 100 TB device has 80 TB usable capacity after RAID 5 protection"},{"timestamp":"1647323040.0","upvote_count":"1","content":"Selected Answer: C\nI think it is correct","poster":"Dawn7","comment_id":"568154"},{"poster":"Dpejic","upvote_count":"2","timestamp":"1640342520.0","content":"On exam 24.12.2021","comment_id":"508443"},{"timestamp":"1634632800.0","upvote_count":"5","content":"Azure Data box is correct\nchoose the same\ncleared with 900 on 17th October 2021","comment_id":"464560","poster":"sharepoint_Azure_pp"},{"upvote_count":"2","comment_id":"457519","poster":"syu31svc","timestamp":"1633413300.0","content":"The Microsoft Azure Data Box cloud solution lets you send terabytes of data into and out of Azure in a quick, inexpensive, and reliable way. The secure data transfer is accelerated by shipping you a proprietary Data Box storage device. Each storage device has a maximum usable storage capacity of 80 TB and is transported to your datacenter through a regional carrier.\n\nAnswer is C"},{"timestamp":"1630301340.0","upvote_count":"1","poster":"Gautam1985","comment_id":"435109","content":"correct"},{"poster":"tvs2021","content":"on exam (7-19-2021). cleared 304 exam.","timestamp":"1626692880.0","upvote_count":"6","comment_id":"409488"},{"content":"StorSimple would fit only 15 TB or up to 38 TB. So answer is correct.\n\nREF: https://docs.microsoft.com/en-us/azure/storsimple/storsimple-8000-technical-specifications-and-compliance","poster":"GetulioJr","timestamp":"1623857100.0","upvote_count":"1","comments":[{"upvote_count":"1","poster":"pentium75","content":"Could also use more than one device, but it would surely not 'minimize cost'.","timestamp":"1629630600.0","comment_id":"429220"}],"comment_id":"383515"},{"poster":"ShahEM","upvote_count":"2","content":"Correct","comment_id":"347062","timestamp":"1619880120.0"},{"content":"C. Azure Data Box","upvote_count":"4","timestamp":"1611537780.0","poster":"glam","comment_id":"275602"},{"upvote_count":"3","comment_id":"273255","content":"Right ans.","timestamp":"1611264660.0","poster":"milind8451"},{"upvote_count":"3","comment_id":"268789","poster":"Blaaa","content":"Correct","timestamp":"1610797680.0"},{"comment_id":"227196","upvote_count":"4","timestamp":"1606282800.0","content":"correct","poster":"Hanger_Man"}],"answer_ET":"C","exam_id":53,"question_text":"You have 70 TB of files on your on-premises file server.\nYou need to recommend solution for importing data to Azure. The solution must minimize cost.\nWhat Azure service should you recommend?","topic":"3"}],"exam":{"id":53,"provider":"Microsoft","isBeta":false,"isImplemented":true,"numberOfQuestions":237,"lastUpdated":"12 Apr 2025","isMCOnly":false,"name":"AZ-304"},"currentPage":23},"__N_SSP":true}