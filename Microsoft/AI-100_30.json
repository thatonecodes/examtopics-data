{"pageProps":{"questions":[{"id":"LSqALZVd4sNGGeDy6CmF","answer_ET":"","discussion":[{"timestamp":"1600354980.0","content":"1 Create image\n2 Register image\n3 Start container\n4 Ge endpoint\n\nThe model is supposed to be already created and an image is just a template yo need to instantiate by running the container and then get the endpoint","poster":"jadepe","comment_id":"181041","upvote_count":"24"},{"comment_id":"288837","content":"Any chance it could be Train > Register > Start > Endpoint (as per the image)? Is \"create\" required, or could that be included in the \"register\" process?","timestamp":"1613130300.0","poster":"KenCraw","comments":[{"upvote_count":"1","poster":"Cornholioz","comment_id":"293026","content":"Well, I think create and register are two steps. But I see where you are coming from. You are looking to fit in the required actions within the 4 steps they've asked for.\n\nIt doesn't say if the model was already trained. So, not sure if it is a required step. (But the image shows a \"Trained\" Model)\n\nThen again, Starting the Container is also required after the image is created & registered.\n\nGetting the endpoint is required because the question asks about deploying it as a webservice which means it is probably good to state this as a step in process.\nBut it asks for just 4 steps.\nPoorly framed question!","timestamp":"1613616180.0"}],"upvote_count":"1"},{"poster":"UpsetUser","timestamp":"1610893560.0","comments":[{"timestamp":"1613088540.0","upvote_count":"2","poster":"Cornholioz","content":"The practice test probably copied the answer from here or vice versa. If there is a correct answer as per documentation or an actual hands-on-keyboard, that will be acceptable.\n\nIs getting the endpoint a required step? I mean the objective is to run it as a webservice, so it is obvious that you will get it. I'm surprised it's even an explicit step here.\n\nAlso, Training the model is required because you only created the model but never trained it.\n\nStarting the container is probably more important than getting the endpoint.\n\nAnyway... thus far, it looks like there is no consensus on the answer.","comment_id":"288600","comments":[{"timestamp":"1613130240.0","poster":"KenCraw","upvote_count":"1","content":"Any chance it could. be Train > Register > Start > Endpoint (as per the image)?","comment_id":"288836"},{"poster":"allanm","content":"You definitely need the endpoint if you are going to deploy anything as a web service. I don't think you need to train the model as it's already been trained. I think the right answer is - Create image > register image > start container > get endpoint","upvote_count":"1","comment_id":"365861","timestamp":"1621886280.0"}]}],"comment_id":"269532","content":"Given answer is correct as per V__t__Se___ Practice tests","upvote_count":"1"}],"answer":"","answers_community":[],"isMC":false,"answer_description":"The following diagram illustrates the complete deployment workflow:\n\nThe deployment workflow includes the following steps:\n1. Register the model in a registry hosted in your Azure Machine Learning Service workspace\n2. Register an image that pairs a model with a scoring script and dependencies in a portable container\n3. Deploy the image as a web service in the cloud or to edge devices\n4. Monitor and collect data\n5. Update a deployment to use a new image.\nReferences:\nhttps://docs.microsoft.com/bs-latn-ba/azure/machine-learning/service/concept-model-management-and-deployment#step-3-deploy-image","unix_timestamp":1600354980,"question_text":"DRAG DROP -\nYou create an image classification model in Azure Machine Learning Studio.\nYou need to deploy the model as a containerized web service.\nWhich four actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\nSelect and Place:\n//IMG//","answer_images":["https://www.examtopics.com/assets/media/exam-media/03857/0018700001.png","https://www.examtopics.com/assets/media/exam-media/03857/0018800001.png"],"question_id":146,"timestamp":"2020-09-17 17:03:00","url":"https://www.examtopics.com/discussions/microsoft/view/31486-exam-ai-100-topic-4-question-25-discussion/","topic":"4","question_images":["https://www.examtopics.com/assets/media/exam-media/03857/0018600001.png"],"exam_id":39},{"id":"KbEpdTBHyPSvctzPI7If","url":"https://www.examtopics.com/discussions/microsoft/view/4407-exam-ai-100-topic-4-question-26-discussion/","answer_ET":"B","choices":{"D":"a network gateway","B":"a data gateway","C":"Azure Data Factory","A":"a site-to-site VPN"},"topic":"4","timestamp":"2019-08-31 05:59:00","answers_community":[],"answer_description":"From April 2017 onward we can use On-premises Data Gateway for Azure Analysis Services. This means you can connect your Tabular Models hosted in Azure\nAnalysis Services to your on-premises data sources through On-premises Data Gateway.\n\nReferences:\nhttps://biinsight.com/on-premises-data-gateway-for-azure-analysis-services/","question_images":[],"question_id":147,"question_text":"You are building an Azure Analysis Services cube for your AI deployment.\nThe source data for the cube is located in an on premises network in a Microsoft SQL Server database.\nYou need to ensure that the Azure Analysis Services service can access the source data.\nWhat should you deploy to your Azure subscription?","isMC":true,"answer":"B","unix_timestamp":1567223940,"answer_images":["https://www.examtopics.com/assets/media/exam-media/03857/0018900001.png"],"exam_id":39,"discussion":[{"upvote_count":"11","comments":[{"comment_id":"78678","poster":"princesskay","content":"I agree its is B.","upvote_count":"5","timestamp":"1587653280.0"}],"poster":"ari_ira","timestamp":"1576076940.0","comment_id":"28812","content":"I think B is correct \nhttps://docs.microsoft.com/en-us/azure/analysis-services/analysis-services-gateway"},{"comment_id":"929206","timestamp":"1687335900.0","content":"You should deploy an On-premises data gateway to your Azure subscription to ensure that the Azure Analysis Services service can access the source data. An On-premises data gateway is required when an Azure Analysis Services server in the cloud needs to connect to on-premises data sources. The gateway provides secure data transfer between on-premises data sources and your Azure Analysis Services servers in the cloud. You can install and configure an On-premises data gateway to connect to on-premises data sources from an Azure Analysis Services server. You can download and install the gateway on a computer in your organization, register the gateway with the Gateway Cloud Service, create a gateway resource in Azure, and connect the gateway resource to servers. You can configure the AlwaysUseGateway server property to specify the server resource to access all data sources through an On-premises data gateway. You can also configure the gateway to use a proxy server if necessary","poster":"rveney","upvote_count":"1"},{"poster":"AlfuryDB","content":"This one is quite straightforward. Let me explain:\nA) is it possible? yes of course but do we need it? 1 simple service, do you want to get into ExpressRoute or S2S VPNs configurations? there must be something simpler.\nC) The main reason of ADF is to orchestrate and offer a platform for integration purposes but are we talking about on-premises integration or with? https://docs.microsoft.com/en-us/azure/data-factory/#:~:text=Azure%20Data%20Factory%20is%20Azure's,with%20full%20compatibility%20in%20ADF.\nD) This solution alone does not do anything here without configuring the rest of the components. \n\nTherefore data gateway helps with this scenario. It's a simple way to connect an on-premises service with the cloud. Are there others? Yes, and with different flavours (e.g. azure relay from a different angle). However, the solution is more simplistic with data gateway.\nThis can be done in 4 steps: https://docs.microsoft.com/en-us/azure/analysis-services/analysis-services-gateway","comment_id":"316237","upvote_count":"1","timestamp":"1616321520.0"},{"upvote_count":"1","poster":"renuka1234","comment_id":"300733","timestamp":"1614510240.0","content":"https://docs.microsoft.com/en-us/data-integration/gateway/service-gateway-onprem"},{"timestamp":"1567223940.0","content":"it may be azure data factory","upvote_count":"2","comments":[{"timestamp":"1603962240.0","poster":"noonereallyknows","upvote_count":"6","content":"It can't be ADF because you don't want to import and store the data in the cloud, you want to access it directly from Analysis Services","comment_id":"208371","comments":[{"upvote_count":"1","timestamp":"1613616420.0","poster":"Cornholioz","comment_id":"293028","content":"Good answer"}]}],"comment_id":"9064","poster":"CodeAnant"}]},{"id":"3SGvb0KG8DRB1jgS51xj","answer_ET":"","url":"https://www.examtopics.com/discussions/microsoft/view/32809-exam-ai-100-topic-4-question-27-discussion/","question_text":"DRAG DROP -\nYou develop a custom application that uses a token to connect to Azure Cognitive Services resources.\nA new security policy requires that all access keys are changed every 30 days.\nYou need to recommend a solution to implement the security policy.\nWhich three actions should you recommend be performed every 30 days? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\nSelect and Place:\n//IMG//","answers_community":[],"answer_images":["https://www.examtopics.com/assets/media/exam-media/03857/0019000002.png","https://www.examtopics.com/assets/media/exam-media/03857/0019100001.png"],"answer_description":"Step 1: Generate new keys in the Cognitive Service resources\n\nStep 2: Retrieve a token from the Cognitive Services endpoint\nStep 3: Update the custom application to use the new authorization\nEach request to an Azure Cognitive Service must include an authentication header. This header passes along a subscription key or access token, which is used to validate your subscription for a service or group of services.\nReferences:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/authentication","discussion":[{"comment_id":"385825","timestamp":"1624145040.0","upvote_count":"1","comments":[{"content":"so is the answer provided correct?","poster":"herru","upvote_count":"1","comment_id":"392689","timestamp":"1624865880.0"}],"poster":"PinkUnicorns","content":"This question was in the exam, I got it wrong after looking at this response. This is correct."},{"comment_id":"291988","upvote_count":"3","timestamp":"1613499300.0","poster":"aceking","content":"correct answer, it's in the official Azure AI100 lab. https://www.youtube.com/watch?v=A0ELM3tcgnQ"},{"timestamp":"1601954340.0","content":"coz the question is about access keys which exist against the deployed cognitive service","poster":"lollo1234","upvote_count":"2","comment_id":"193911"},{"timestamp":"1601103240.0","content":"What not using key vault?","poster":"CeliaZhou","upvote_count":"1","comment_id":"187494"}],"question_id":148,"answer":"","unix_timestamp":1601103240,"topic":"4","question_images":["https://www.examtopics.com/assets/media/exam-media/03857/0019000001.png"],"timestamp":"2020-09-26 08:54:00","exam_id":39,"isMC":false},{"id":"vRK4xKVvQwHT3G46EbxJ","question_id":149,"unix_timestamp":1609261200,"answer":"","answer_images":["https://www.examtopics.com/assets/media/exam-media/03857/0019400001.png"],"question_images":["https://www.examtopics.com/assets/media/exam-media/03857/0019300001.png"],"answer_description":"Incorrect Answers:\nNot Keys as they are used for encryption only.\nReferences:\nhttps://docs.microsoft.com/en-us/azure/key-vault/key-vault-secure-your-key-vault","question_text":"DRAG DROP -\nYou use an Azure key vault to store credentials for several Azure Machine Learning applications.\nYou need to configure the key vault to meet the following requirements:\n✑ Ensure that the IT security team can add new passwords and periodically change the passwords.\n✑ Ensure that the applications can securely retrieve the passwords for the applications.\n✑ Use the principle of least privilege.\nWhich permissions should you grant? To answer, drag the appropriate permissions to the correct targets. Each permission may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.\nNOTE: Each correct selection is worth one point.\nSelect and Place:\n//IMG//","discussion":[{"comment_id":"254902","poster":"awron_durat","content":"The answer provided is correct.","timestamp":"1609261200.0","upvote_count":"5"}],"isMC":false,"answers_community":[],"exam_id":39,"answer_ET":"","topic":"4","timestamp":"2020-12-29 18:00:00","url":"https://www.examtopics.com/discussions/microsoft/view/40991-exam-ai-100-topic-4-question-28-discussion/"},{"id":"2fCLVnlp0pVGDfb9GMLk","answer_description":"The N-series is a family of Azure Virtual Machines with GPU capabilities. GPUs are ideal for compute and graphics-intensive workloads, helping customers to fuel innovation through scenarios like high-end remote visualisation, deep learning and predictive analytics.\nThe ND-series is focused on training and inference scenarios for deep learning. It uses the NVIDIA Tesla P40 GPUs. The latest version - NDv2 - features the\nNVIDIA Tesla V100 GPUs.\nReferences:\nhttps://azure.microsoft.com/en-in/pricing/details/virtual-machines/series/","answers_community":[],"answer_ET":"A","url":"https://www.examtopics.com/discussions/microsoft/view/40992-exam-ai-100-topic-4-question-29-discussion/","discussion":[{"timestamp":"1609261260.0","upvote_count":"5","poster":"awron_durat","comment_id":"254904","content":"The answer provided is correct."},{"poster":"rveney","timestamp":"1687336440.0","comment_id":"929212","content":"To ensure that the data analysis occurs as quickly as possible, you should recommend the ND virtual machine series to the data scientist. The ND virtual machine series is designed for high-performance computing and is optimized for deep learning workloads. It features NVIDIA GPUs and provides fast interconnects between nodes, which can improve the performance of data analysis. The ND virtual machine series is available in several sizes, ranging from ND6 to ND40, and can be used for a variety of deep learning workloads, including image and speech recognition, natural language processing, and reinforcement learning","upvote_count":"1"}],"question_images":[],"answer_images":[],"timestamp":"2020-12-29 18:01:00","question_id":150,"answer":"A","exam_id":39,"choices":{"D":"Ev3","C":"DC","A":"ND","B":"B"},"question_text":"A data scientist deploys a deep learning model on an Fsv2 virtual machine.\nData analysis is slow.\nYou need to recommend which virtual machine series the data scientist must use to ensure that data analysis occurs as quickly as possible.\nWhich series should you recommend?","isMC":true,"topic":"4","unix_timestamp":1609261260}],"exam":{"isBeta":false,"lastUpdated":"12 Apr 2025","isImplemented":true,"name":"AI-100","isMCOnly":false,"numberOfQuestions":206,"id":39,"provider":"Microsoft"},"currentPage":30},"__N_SSP":true}