{"pageProps":{"questions":[{"id":"67D1EXdEGAOgM6rt93Ej","isMC":false,"discussion":[{"timestamp":"1639672260.0","upvote_count":"42","content":"The answer provided is correct","comments":[{"content":"The provided sequence is correct per below link:\n\nhttps://docs.microsoft.com/en-us/azure/data-factory/continuous-integration-delivery","upvote_count":"10","poster":"SameerL","comment_id":"631816","timestamp":"1657894620.0"}],"poster":"ItHYMeRIsh","comment_id":"503065"},{"content":"Before creating a pull request, it is required to save our changes on a feature branch (publish our local changes). So the correct order is:\n1. Create a repository and a main branch\n2. Create a feature branch\n3. Publish changes\n4. Create a pull request\n5. Merge changes","comment_id":"507657","comments":[{"poster":"wwdba","timestamp":"1645556100.0","upvote_count":"1","content":"I agree. This was my order too. My understanding is: Publish changes = Push the changes to the remote repository","comment_id":"553934"},{"timestamp":"1640735520.0","comments":[{"timestamp":"1641799140.0","comment_id":"520699","upvote_count":"1","comments":[{"poster":"xeti","comment_id":"565908","upvote_count":"6","content":"No, the given answer is correct.\n\nPublish is done after the merge to collaboration (main) branch and is essentially a CI trigger to update the adf_publish branch.","timestamp":"1647053820.0"}],"poster":"NaiCob","content":"Before Pull Request you have to publish you local changes"}],"poster":"corebit","upvote_count":"3","comment_id":"511653","content":"@NaiCob I believe the given answer is correct. What changes are published before creating a PR?"},{"timestamp":"1643191860.0","content":"Nope. given answers are correct.","upvote_count":"2","comment_id":"532775","poster":"dev2dev"},{"upvote_count":"1","poster":"Lotusss","comment_id":"592834","content":"I agree! Reference: https://www.google.com/search?q=Create+branch+create+feature+branch+create+ull+request&ei=7uFoYr7tO4-VkgWOt6jYAQ&ved=0ahUKEwi-nOOLzrP3AhWPiqQKHY4bChsQ4dUDCA8&uact=5&oq=Create+branch+create+feature+branch+create+ull+request&gs_lcp=Cgdnd3Mtd2l6EAMyBwghEAoQoAE6BwgAEEcQsAM6BQghEKABOggIIRAWEB0QHjoECCEQFUoECEEYAEoECEYYAFCxA1i5KmDXLGgDcAF4AIABnAGIAZgPkgEEMTYuNZgBAKABAcgBCMABAQ&sclient=gws-wiz#kpvalbx=_DeJoYrujKovCkwWT-anIBg18","timestamp":"1651034220.0"},{"comment_id":"608204","upvote_count":"1","comments":[{"poster":"sdokmak","content":"3. Pull requests before making any changes, again to reduce conflict.","comment_id":"608207","timestamp":"1653689640.0","upvote_count":"1"}],"poster":"sdokmak","timestamp":"1653688500.0","content":"Pushing (publishing) always last otherwise:\n1. You will have conflicts.\n2. Your last 2 steps do nothing."},{"timestamp":"1670792640.0","comment_id":"742097","poster":"Igor85","upvote_count":"5","content":"no, publish you can only do from the main branch. to publish changes from main you first have to create a PR, get approval, merge to main."}],"timestamp":"1640244060.0","poster":"NaiCob","upvote_count":"23"},{"comment_id":"1311159","poster":"seranvijay","upvote_count":"1","content":"Answer is correct\nhttps://learn.microsoft.com/en-us/azure/data-factory/source-control#version-control","timestamp":"1731484320.0"},{"poster":"evangelist","upvote_count":"1","timestamp":"1721213580.0","comment_id":"1249540","content":"Create a repository and a main branch: This is the foundational step where you set up the repository that will contain your project.\nCreate a feature branch: This step allows developers to work on new features or fixes in isolation from the main branch.\nPublish changes: This step involves pushing local changes to the remote repository, making them available for review and collaboration.\nCreate a pull request: After publishing changes, you create a pull request to propose merging the feature branch into the main branch.\nMerge changes: This is the final step where changes from the feature branch are merged into the main branch after approval."},{"timestamp":"1698250140.0","comment_id":"1053864","content":"The given answer is correct. Please note that publish change is not same as commiting.","poster":"Adediwura","upvote_count":"2"},{"poster":"kkk5566","content":"correct","timestamp":"1693550100.0","upvote_count":"1","comment_id":"995762"},{"timestamp":"1674654960.0","content":"This case study was in my exam word to word. Thanks guys. passed at 970.\nJust dont do dumps but try to understand the logic via some youtube dp-203 tutorials. There is series by databag.ai. So please study to excel in exam as well in prof life.","upvote_count":"4","poster":"Jerrie86","comment_id":"787704"},{"content":"Given answer and sequence is absolutely correct !!","poster":"anks84","comment_id":"662687","timestamp":"1662567600.0","upvote_count":"2"},{"poster":"Deeksha1234","content":"given answer is correct","comment_id":"646337","timestamp":"1660396680.0","upvote_count":"2"},{"upvote_count":"3","content":"Given answer is correct:\n\n1. Create a repository and a main branch -You need a Git repository in Azure Pipelines, TFS, or GitHub with your app.\n2. Create a feature branch -\n3. Create a pull request - you propose that changes you've made on a head branch should be merged\n4. Merge changes -merge feature branches into the main/collaboration branch using pull requests.\n5. Publish changes -after you merged changes to the collaboration branch (main is default), click Publish to manually publish. \n\nhttps://docs.microsoft.com/en-us/azure/data-factory/source-control\nhttps://docs.github.com/en/pull-requests/collaborating-with-pull-requests/getting-started/about-collaborative-development-models\nhttps://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests","comment_id":"601967","timestamp":"1652601600.0","poster":"hbad"},{"content":"https://www.atlassian.com/git/tutorials/comparing-workflows/feature-branch-workflow","upvote_count":"1","poster":"Send2","timestamp":"1651467780.0","comment_id":"595882"},{"upvote_count":"2","comment_id":"555255","timestamp":"1645705620.0","poster":"Kondzio","content":"I think it's correct. Publish step is the last one, because there is no auto-publish on the master branch by default"},{"content":"I think answer is correct. Pls refer to https://docs.microsoft.com/en-us/azure/data-factory/source-control#version-control","poster":"edba","upvote_count":"4","comment_id":"512922","timestamp":"1640828040.0"},{"comment_id":"512794","poster":"Canary_2021","upvote_count":"2","timestamp":"1640815560.0","content":"The answers are correct.\nhttps://www.youtube.com/watch?v=cLf3nAiGG3Q"}],"question_images":["https://www.examtopics.com/assets/media/exam-media/04259/0014400004.jpg"],"exam_id":67,"answer_description":"Scenario: Identify a process to ensure that changes to the ingestion and transformation activities can be version-controlled and developed independently by multiple data engineers.\nStep 1: Create a repository and a main branch\nYou need a Git repository in Azure Pipelines, TFS, or GitHub with your app.\n\nStep 2: Create a feature branch -\n\nStep 3: Create a pull request -\n\nStep 4: Merge changes -\nMerge feature branches into the main branch using pull requests.\n\nStep 5: Publish changes -\nReference:\nhttps://docs.microsoft.com/en-us/azure/devops/pipelines/repos/pipeline-options-for-git","answer":"","url":"https://www.examtopics.com/discussions/microsoft/view/68137-exam-dp-203-topic-7-question-1-discussion/","question_id":381,"unix_timestamp":1639672260,"answer_ET":"","timestamp":"2021-12-16 17:31:00","question_text":"DRAG DROP -\nYou need to implement versioned changes to the integration pipelines. The solution must meet the data integration requirements.\nIn which order should you perform the actions? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\nSelect and Place:\n//IMG//","topic":"7","answer_images":["https://www.examtopics.com/assets/media/exam-media/04259/0014500001.jpg"],"answers_community":[]},{"id":"Y82ZF3g1lLBpeQiHhsmH","timestamp":"2022-04-27 06:45:00","answer":"","exam_id":67,"topic":"8","answer_images":["https://www.examtopics.com/assets/media/exam-media/04259/0028300001.png"],"discussion":[{"poster":"noobprogrammer","content":"Answer looks correct to me:\n1)Configure Event Hubs partition - The description says: \"Maximize the throughput of ingesting Twitter feeds from Event Hubs to Azure Storage without purchasing additional throughput or capacity units.\"\n\n2) An Azure Data Lake Storage Gen2 account.\nDatabricks cluster has nothing to do with storage, and a Data lake fits the needs","upvote_count":"16","timestamp":"1651160400.0","comment_id":"593913"},{"poster":"Deeksha1234","upvote_count":"8","comment_id":"646339","content":"correct!","timestamp":"1660397100.0"},{"timestamp":"1719409560.0","comment_id":"1237496","content":"For me the correct answer is: \n1. Azure Event Hubs Dedicated: In most streaming scenarios, data is lightweight, typically less than 1 MB, and requires high throughput. \nref: https://learn.microsoft.com/en-us/azure/event-hubs/event-hubs-dedicated-overview#supports-streaming-large-messages\n2. An Azure Data Lake Storage Gen2 account","poster":"Algasibiur","upvote_count":"2"},{"upvote_count":"1","content":"correct","timestamp":"1693550340.0","poster":"kkk5566","comment_id":"995764"},{"upvote_count":"1","timestamp":"1651034700.0","content":"Box one is Enable auto-inflate\nBox two Data Lake account","comment_id":"592839","comments":[{"poster":"NamitSehgal","comment_id":"624354","upvote_count":"4","timestamp":"1656464820.0","content":"Enable auto-inflate is for scale up Azure Event Hubs throughput units, so given answer by xamtopics are correct."}],"poster":"Lotusss"}],"question_text":"HOTSPOT -\nYou need to design a data ingestion and storage solution for the Twitter feeds. The solution must meet the customer sentiment analytics requirements.\nWhat should you include in the solution? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","question_id":382,"answer_ET":"","url":"https://www.examtopics.com/discussions/microsoft/view/74647-exam-dp-203-topic-8-question-1-discussion/","unix_timestamp":1651034700,"answers_community":[],"question_images":["https://www.examtopics.com/assets/media/exam-media/04259/0028200004.png"],"answer_description":"Box 1: Configure Evegent Hubs partitions\nScenario: Maximize the throughput of ingesting Twitter feeds from Event Hubs to Azure Storage without purchasing additional throughput or capacity units.\nEvent Hubs is designed to help with processing of large volumes of events. Event Hubs throughput is scaled by using partitions and throughput-unit allocations.\nIncorrect Answers:\n✑ Event Hubs Dedicated: Event Hubs clusters offer single-tenant deployments for customers with the most demanding streaming needs. This single-tenant offering has a guaranteed 99.99% SLA and is available only on our Dedicated pricing tier.\n✑ Auto-Inflate: The Auto-inflate feature of Event Hubs automatically scales up by increasing the number of TUs, to meet usage needs.\nEvent Hubs traffic is controlled by TUs (standard tier). Auto-inflate enables you to start small with the minimum required TUs you choose. The feature then scales automatically to the maximum limit of TUs you need, depending on the increase in your traffic.\nBox 2: An Azure Data Lake Storage Gen2 account\nScenario: Ensure that the data store supports Azure AD-based access control down to the object level.\nAzure Data Lake Storage Gen2 implements an access control model that supports both Azure role-based access control (Azure RBAC) and POSIX-like access control lists (ACLs).\nIncorrect Answers:\n✑ Azure Databricks: An Azure administrator with the proper permissions can configure Azure Active Directory conditional access to control where and when users are permitted to sign in to Azure Databricks.\n✑ Azure Storage supports using Azure Active Directory (Azure AD) to authorize requests to blob data.\nYou can scope access to Azure blob resources at the following levels, beginning with the narrowest scope:\n- An individual container. At this scope, a role assignment applies to all of the blobs in the container, as well as container properties and metadata.\n- The storage account. At this scope, a role assignment applies to all containers and their blobs.\n- The resource group. At this scope, a role assignment applies to all of the containers in all of the storage accounts in the resource group.\n- The subscription. At this scope, a role assignment applies to all of the containers in all of the storage accounts in all of the resource groups in the subscription.\n- A management group.\nReference:\nhttps://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-features https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-access-control","isMC":false},{"id":"vPRA7IDmgIECc5lrq77A","answer":"C","url":"https://www.examtopics.com/discussions/microsoft/view/62088-exam-dp-203-topic-9-question-1-discussion/","unix_timestamp":1631694720,"question_id":383,"answer_images":[],"answer_ET":"C","answer_description":"","question_images":[],"answers_community":["C (100%)"],"timestamp":"2021-09-15 10:32:00","discussion":[{"poster":"Kyle1","timestamp":"1647381240.0","comment_id":"445447","upvote_count":"35","content":"I think it should be C. The company doesn't want any virtual network stuff and server-level is more comprehensive, thus safer than just database-level rule."},{"poster":"Marcus1612","content":"The answer is C. Since there is no VPN between on-premises machines and Azure SQL server, communications use a public endpoint. You can limit the public access to databases through a Server Level IP Firewall rules. https://docs.microsoft.com/en-us/azure/azure-sql/database/network-access-controls-overview","timestamp":"1647559260.0","comment_id":"446801","upvote_count":"12"},{"timestamp":"1709282520.0","comment_id":"995766","upvote_count":"1","content":"Selected Answer: C\nis correct","poster":"kkk5566"},{"comment_id":"931085","content":"Selected Answer: C\nOption C, a server-level firewall IP rule, is the correct choice in this scenario. It provides a firewall rule at the server level, which means that any connections to the analytical data store will be filtered based on the specified IP addresses. By configuring the server-level firewall rule to only allow access from the IP addresses within the Litware on-premises network, you can effectively block access from users outside the network.\n\nOptions A and B, virtual network rules, are not the most appropriate choices in this case because they apply to the network level rather than the server or database level. Virtual network rules are used to control access to the Azure SQL server or database from specific virtual networks or subnets.","upvote_count":"2","poster":"vctrhugo","timestamp":"1703290260.0"},{"comment_id":"734855","content":"Selected Answer: C\nActually, my preferred option is \"database-level firewall IP rules for each and every database\", but that option is not there, so I will have to choose C (a server-level firewall IP rule). Option D (a database-level firewall IP rule) is not sufficient, since we will have at least two databases, including Master and the Data Store database, to protect. \n\n\"We recommend that you use database-level IP firewall rules whenever possible. This practice enhances security and makes your database more portable. Use server-level IP firewall rules for administrators. Also use them when you have many databases that have the same access requirements, and you don't want to configure each database individually.\"\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/firewall-configure?view=azuresql","upvote_count":"4","timestamp":"1685848860.0","poster":"AzureJobsTillRetire"},{"timestamp":"1676302260.0","comment_id":"646341","content":"Selected Answer: C\ncorrect","upvote_count":"1","poster":"Deeksha1234"},{"comment_id":"623702","content":"Selected Answer: C\nAnswer is correct","timestamp":"1672207620.0","poster":"StudentFromAus","upvote_count":"1"},{"timestamp":"1670091060.0","upvote_count":"1","poster":"MvanG","content":"Synapse Analytics has built in firewall. That combined with \"least privileged, answer should be D. a Database -level firewall IP rule.","comment_id":"611152"},{"upvote_count":"1","comments":[{"comment_id":"608213","upvote_count":"1","timestamp":"1669600260.0","poster":"sdokmak","content":"This is a tough one! Their on-prem data is in a private network, so in hindsite we should vNet peering to azure because server-level ip is not enough, yet... vNet is not enough for On-Prem either and would VPN/Express Routes involved. Best answer is C."}],"poster":"parx","timestamp":"1665791280.0","comment_id":"586065","content":"Option A seems correct. Virtual Network (VNET) not to be confused with VPN. When setting up a IP rule at VNET, any resource within this VNET will be accessible only to that IP address. In this case On-Premises IP."},{"comment_id":"532778","poster":"dev2dev","timestamp":"1658823240.0","upvote_count":"1","content":"Selected Answer: C\nread the last line \"Litware does not plan to implement Azure ExpressRoute or a VPN between the on-premises network and Azure.\" so C is correct instead of A"},{"timestamp":"1658726040.0","content":"Selected Answer: C\nC looks correct.","comment_id":"531925","poster":"PallaviPatel","upvote_count":"1"},{"content":"A server-level firewall IP rule is correct","comment_id":"514225","poster":"SabaJamal2010AtGmail","timestamp":"1656616620.0","upvote_count":"1"},{"comments":[{"upvote_count":"3","poster":"vanrell","comment_id":"571506","content":"Remember, the question is on how to PREVENT outside users to gain access, combined with no VPN, answer should be C.\nIf the question was about GRANTING access, then following principle of least privilege would be as you mentioned a database level IP Firewall.","timestamp":"1663657200.0"}],"comment_id":"512803","timestamp":"1656534600.0","content":"https://docs.microsoft.com/en-us/azure/azure-sql/database/firewall-configure\n• Server-level IP firewall rules: These rules enable clients to access your entire server, that is, all the databases managed by the server.\n• Database-level IP firewall rules: Database-level IP firewall rules enable clients to access certain (secure) databases. You create the rules for each database (including the master database), and they're stored in the individual database.\n• We recommend that you use database-level IP firewall rules whenever possible.\nSo if target analytical data store is SQL data base in Azure, it is better to use database-level IP firewall rules.\n\nFor this question, the target analytical data store is Power BI, Ingestion data store is Data Lake Gen2. Not sure if this is the reason to select C?","poster":"Canary_2021","upvote_count":"2"},{"poster":"alexleonvalencia","upvote_count":"1","timestamp":"1654998060.0","content":"Selected Answer: C\nCorrecta","comment_id":"499768"},{"timestamp":"1653497940.0","content":"Selected Answer: C\nAnswer is C because the company doesn't want to use any virtual network tools.","upvote_count":"3","comment_id":"486878","poster":"FredNo"},{"comments":[{"comments":[{"comment_id":"1113955","timestamp":"1720108860.0","poster":"MarkJoh","content":"sp_set_database_firewall_rule","upvote_count":"1"}],"content":"How to add rule at database level?","timestamp":"1650237660.0","comment_id":"463756","upvote_count":"1","poster":"YipingRuan"}],"content":"Answer should be D, I think.\n\"Litware does not plan to implement Azure ExpressRoute or a VPN between the on-premises network and Azure\"","poster":"jefvaen","comment_id":"445085","upvote_count":"3","timestamp":"1647340320.0"}],"isMC":true,"topic":"9","question_text":"What should you recommend to prevent users outside the Litware on-premises network from accessing the analytical data store?","choices":{"D":"a database-level firewall IP rule","A":"a server-level virtual network rule","C":"a server-level firewall IP rule","B":"a database-level virtual network rule"},"exam_id":67},{"id":"UnhjGTS8gBG5QaOrKzdO","question_id":384,"unix_timestamp":1629969240,"answer_images":[],"answer_ET":"C","choices":{"D":"data sensitivity labels","C":"column-level security","B":"row-level security","A":"Transparent Data Encryption (TDE)"},"question_text":"What should you recommend using to secure sensitive customer contact information?","url":"https://www.examtopics.com/discussions/microsoft/view/60710-exam-dp-203-topic-9-question-2-discussion/","question_images":[],"timestamp":"2021-08-26 11:14:00","answer":"C","exam_id":67,"discussion":[{"timestamp":"1661646780.0","upvote_count":"45","content":"Answer is C\nhttps://azure.microsoft.com/en-ca/updates/column-level-security-is-now-supported-in-azure-sql-data-warehouse/\nYou can use CLS to manage user access to specific columns in your tables in a simpler manner, without having to redesign your data warehouse. CLS eliminates the need to maintain access restriction logic away from the data in another application or introduce views for filtering out sensitive columns for a subset of users.","poster":"echerish","comment_id":"433416"},{"poster":"FredNo","upvote_count":"8","timestamp":"1669402800.0","comment_id":"486879","content":"Selected Answer: C\nAnswer is C"},{"content":"Selected Answer: C\nC. Azure SQL Data Warehouse now supports column-level security (CLS), an additional capability for managing sensitive data in the cloud.\n\nYou can use CLS to manage user access to specific columns in your tables in a simpler manner, without having to redesign your data warehouse. CLS eliminates the need to maintain access restriction logic away from the data in another application or introduce views for filtering out sensitive columns for a subset of users. \n\nTo help secure your data, simply define a security policy on your table columns with the standard GRANT T-SQL statement.","upvote_count":"1","poster":"imatheushenrique","comment_id":"1399856","timestamp":"1742247660.0"},{"upvote_count":"1","timestamp":"1725243060.0","comment_id":"995768","poster":"kkk5566","content":"Selected Answer: C\nis correct"},{"upvote_count":"3","timestamp":"1719094560.0","poster":"vctrhugo","content":"Selected Answer: C\nOption C, column-level security, allows you to control access to specific columns within a table based on user permissions. This means you can restrict access to sensitive customer contact information, such as phone numbers, only to authorized users or roles within the organization. By implementing column-level security, you can ensure that business analysts are limited in their access to customer contact information, preventing them from viewing or analyzing the phone numbers, which are not analytically relevant in this case.","comment_id":"931087"},{"comment_id":"735211","timestamp":"1701704940.0","poster":"XiltroX","upvote_count":"4","content":"Answer is 100% C. The only way you can prevent users from seeing sensitive information is either through partial masking (partially visible) or complete blocking by using column level security."},{"upvote_count":"3","poster":"anks84","content":"Selected Answer: C\nCorrect Answer is C i.e. Column-level security !!","comment_id":"662773","timestamp":"1694109480.0"},{"upvote_count":"2","timestamp":"1692951000.0","poster":"yyyhhh","content":"Selected Answer: D\nThe answer is D. \nBetween C and D, D can \"minimize the number of different Azure services needed to achieve the business goals.\" But C needs to distribute role to the user, that is more complicated to apply.","comment_id":"651702"},{"upvote_count":"2","comment_id":"646345","timestamp":"1691933820.0","content":"Selected Answer: C\nC - column level security is correct","poster":"Deeksha1234"},{"poster":"dmgArtyco","upvote_count":"2","timestamp":"1691609340.0","comment_id":"644648","content":"La verdad que no queda nada claro"},{"poster":"Remedios79","content":"Selected Answer: C\nIt's C because of this requirement : \"Limit the business analysts' access to customer contact information, such as phone numbers, because this type of data is not analytically relevant.\"","timestamp":"1688368920.0","comment_id":"626463","upvote_count":"3"},{"upvote_count":"1","content":"It's tricky, because it says \"secure\" and not \"not to access\"","poster":"Davico93","timestamp":"1687314600.0","comment_id":"619570"},{"poster":"Arunava05","timestamp":"1684932960.0","content":"Even in udemy also the answer is same as ' Data sensitivity labels'","upvote_count":"3","comment_id":"606718"},{"timestamp":"1680798360.0","comment_id":"581925","upvote_count":"4","poster":"AlCubeHead","content":"Selected Answer: C\nYou don't secure data with sensitivity labels. They can only be used to identify who has accessed sensitive data. So it has to be column level security. There should really have been a Data Masking option here instead of column level security."},{"timestamp":"1675162020.0","content":"It should be C, because only analysts are might not see those columns but others yes","comments":[{"upvote_count":"1","comment_id":"626461","timestamp":"1688368800.0","content":"I agree with you!","poster":"Remedios79"}],"upvote_count":"3","comment_id":"536845","poster":"coulio"},{"comment_id":"531927","upvote_count":"2","timestamp":"1674631020.0","poster":"PallaviPatel","content":"Selected Answer: C\ncolumn level security is correct answer"},{"timestamp":"1674189000.0","poster":"Raghu108","content":"Selected Answer: C\nI fee it's C as we can limit access via CLS.","comment_id":"528127","upvote_count":"1"},{"timestamp":"1671251460.0","poster":"datnguye","comments":[{"timestamp":"1671251580.0","poster":"datnguye","upvote_count":"2","content":"Oh I mean to choose D (can't edit the comment)","comment_id":"503359"}],"content":"\"Limit access\" confusing the selection between C and D.\nIn this case, I would choose C because it doesn't say to elimitate column(s) e.g. Phone from querying data","upvote_count":"2","comment_id":"503356"},{"upvote_count":"1","timestamp":"1670816520.0","poster":"alexleonvalencia","comment_id":"499769","content":"Correcta [C]"},{"timestamp":"1663450200.0","poster":"Marcus1612","comment_id":"446807","upvote_count":"3","content":"D is wrong because \"this type of data is not analytically relevant.\" Classification enable users to analyse sensitive data."},{"comment_id":"439142","poster":"GervasioMontaNelas","content":"I agree, it should be C","timestamp":"1662295800.0","upvote_count":"4"},{"poster":"petulda","comment_id":"432150","upvote_count":"3","timestamp":"1661507700.0","content":"Why not Column level security ?"},{"content":"Why does this win over column-level security?","comment_id":"432124","timestamp":"1661505240.0","poster":"[Removed]","upvote_count":"2"}],"answer_description":"","isMC":true,"answers_community":["C (93%)","7%"],"topic":"9"}],"exam":{"numberOfQuestions":384,"isMCOnly":false,"name":"DP-203","isBeta":false,"lastUpdated":"12 Apr 2025","provider":"Microsoft","id":67,"isImplemented":true},"currentPage":77},"__N_SSP":true}