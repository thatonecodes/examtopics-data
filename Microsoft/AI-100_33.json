{"pageProps":{"questions":[{"id":"dUyxeWQBav93DFbxgTWW","answer_ET":"C","answer":"C","choices":{"C":"Use Azure Data Factory (ADF) to upload the data.","A":"Use Azure API Apps to upload the data.","B":"Use Azure Bot Service to upload the data.","D":"Use Azure Machine Learning to upload the data."},"answers_community":[],"discussion":[{"timestamp":"1687459680.0","comment_id":"930926","upvote_count":"1","content":"C. Use Azure Data Factory (ADF) to upload the data.\n\nAzure Data Factory (ADF) is a cloud-based data integration service that allows you to create data-driven workflows for orchestrating and automating data movement and transformation. In this scenario, ADF can be used to schedule and automate the process of uploading the parsed image data to Azure Storage once a week.\n\nADF provides a cost-effective solution as it allows you to define data pipelines without the need for extensive infrastructure setup or management. It can handle large-scale data transfers efficiently and provides built-in connectors for Azure Storage, enabling seamless integration with the storage service.\n\nUsing Azure API Apps or Azure Bot Service would not be the most suitable options for uploading data to Azure Storage as they are primarily designed for building APIs or developing conversational agents, respectively. Azure Machine Learning is a platform for developing and deploying machine learning models, not specifically designed for data uploading tasks.","poster":"rveney"}],"url":"https://www.examtopics.com/discussions/microsoft/view/112978-exam-ai-100-topic-5-question-1-discussion/","answer_description":"The Azure Data Factory (ADF) is a service designed to allow developers to integrate disparate data sources. It is a platform somewhat like SSIS in the cloud to manage the data you have both on-premises and in the cloud.\nIt provides access to on-premises data in SQL Server and cloud data in Azure Storage (Blob and Tables) and Azure SQL Database.\nReference:\nhttps://docs.microsoft.com/en-us/azure/data-factory/introduction https://www.jamesserra.com/archive/2014/11/what-is-azure-data-factory/","question_images":[],"unix_timestamp":1687459680,"question_text":"You are designing a business application that will use Azure Cognitive Services to parse images of business forms. You have the following requirements:\nParsed image data must be uploaded to Azure Storage once a week.\nThe solution must minimize infrastructure costs.\nWhat should you do?","timestamp":"2023-06-22 20:48:00","topic":"5","isMC":true,"exam_id":39,"question_id":161,"answer_images":[]},{"id":"eDS5Nsjkuuvh4CsgNRWI","question_id":162,"answers_community":[],"exam_id":39,"answer_ET":"B","unix_timestamp":1687460580,"question_text":"You are developing an AI application that will use keys stored in an Azure Key Vault.\nYou want to configure the Azure Key Vault to ensure that a key that is deleted is retained in the key vault for 90 days.\nWhat should you do?\nRecently, a key used by the application was deleted accidentally and was unrecoverable.\nYou need to ensure that if a key is deleted, it is retained in the key vault for 90 days.\nWhat should you do?","isMC":true,"choices":{"B":"In the Azure Portal, configure Soft delete and Purge protection.","A":"In to Azure Management Console, set the expiration date on the keys.","D":"In the Azure Portal, configure Azure Monitor for Key Vault.","C":"In the Azure Portal, configure back up of the Azure Key Vault."},"discussion":[{"upvote_count":"1","content":"To ensure that a key that is deleted is retained in the key vault for 90 days, you should configure Soft delete and Purge protection on the Azure Key Vaul","poster":"rveney","timestamp":"1687460580.0","comment_id":"930942"}],"timestamp":"2023-06-22 21:03:00","question_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/112984-exam-ai-100-topic-5-question-10-discussion/","answer_description":"Reference:\nhttps://docs.microsoft.com/en-us/azure/key-vault/general/key-vault-recovery?tabs=azure-portal","answer_images":[],"topic":"5","answer":"B"},{"id":"pnzxBkRLzCY34N5MsPBv","answer_description":"Reference:\nhttps://docs.microsoft.com/en-us/azure/storage/common/storage-encryption-keys-portal https://docs.microsoft.com/en-us/azure/key-vault/key-vault-hsm-protected-keys","answer_images":[],"discussion":[{"comment_id":"930947","timestamp":"1687460880.0","content":"C. Generate an encryption key.\n\nTo encrypt the Azure Blob storage account with a key generated by the hardware security module (HSM) of your company, the first step is to generate an encryption key. This encryption key will be used to encrypt and decrypt the data in the storage account.","upvote_count":"1","poster":"rveney"}],"url":"https://www.examtopics.com/discussions/microsoft/view/112985-exam-ai-100-topic-5-question-11-discussion/","unix_timestamp":1687460880,"question_images":[],"answers_community":[],"answer":"D","exam_id":39,"question_text":"You are designing the infrastructure for an AI solution that will analyze data stored in Azure Blob storage.\nYou want to encrypt the storage account by using a key generated by the hardware security module (HSM) of your company.\nWhat should you do first?","answer_ET":"D","timestamp":"2023-06-22 21:08:00","isMC":true,"choices":{"A":"Enable encryption with customer-managed keys.","C":"Generate an encryption key.","D":"Configure a service endpoint for the storage account.","B":"Generate an access key."},"question_id":163,"topic":"5"},{"id":"OWxYgwlspCuiucvlu0Rd","question_text":"You have deployed 1,000 sensors for an AI application that you are developing. The sensors generate large amounts data that is ingested on an hourly basis.\nYou want your application to analyze the data generated by the sensors in real-time.\nWhich of the following actions should you take?","choices":{"A":"Make use of Azure Kubernetes Service (AKS)","B":"Make use of Azure Cosmos DB","C":"Make use of an Azure HDInsight Hadoop cluster","D":"Make use of Azure Data Factory"},"timestamp":"2023-06-22 21:09:00","answer_images":[],"topic":"5","question_id":164,"answer_ET":"C","exam_id":39,"answers_community":[],"discussion":[{"comment_id":"930948","content":"A. Make use of Azure Kubernetes Service (AKS)\n\nTo analyze the data generated by the sensors in real-time, you can make use of Azure Kubernetes Service (AKS). AKS is a container orchestration service that allows you to deploy, manage, and scale containerized applications. By deploying your AI application on AKS, you can process the data in real-time using containers and take advantage of the scalability and flexibility offered by AKS.","poster":"rveney","upvote_count":"1","timestamp":"1687460940.0"}],"isMC":true,"unix_timestamp":1687460940,"answer":"C","url":"https://www.examtopics.com/discussions/microsoft/view/112986-exam-ai-100-topic-5-question-12-discussion/","question_images":[],"answer_description":"Azure HDInsight makes it easy, fast, and cost-effective to process massive amounts of data.\nYou can use HDInsight to process streaming data that's received in real time from a variety of devices.\nReference:\nhttps://docs.microsoft.com/en-us/azure/hdinsight/hadoop/apache-hadoop-introduction"},{"id":"KWUbs4fUArikmXMIuTuS","answers_community":[],"exam_id":39,"choices":{"A":"Make use of Azure Blob storage","D":"Make use of Azure Table storage","C":"Make use of Azure Databricks","B":"Make use of Azure Cosmos DB"},"question_text":"You are developing an AI application for your company. The application that uses batch processing to analyze data in JSON and PDF documents.\nYou want to store the JSON and PDF documents in Azure. You want to ensure data persistence while keeping costs at a minimum.\nWhich of the following actions should you take?","question_id":165,"discussion":[{"upvote_count":"1","comment_id":"929450","timestamp":"1687348980.0","content":"A. Make use of Azure Blob storage.\n\nTo store JSON and PDF documents in Azure while ensuring data persistence and minimizing costs, Azure Blob storage is the most suitable choice.","poster":"rveney"},{"upvote_count":"1","content":"Low Cost => Bloa","comment_id":"415160","poster":"YipingRuan","timestamp":"1627362540.0"}],"timestamp":"2021-07-27 07:09:00","answer_images":[],"question_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/58756-exam-ai-100-topic-5-question-13-discussion/","answer_ET":"A","answer_description":"The following technologies are recommended choices for batch processing solutions in Azure.\nAzure Storage Blob Containers. Many existing Azure business processes already use Azure blob storage, making this a good choice for a big data store.\nAzure Data Lake Store. Azure Data Lake Store offers virtually unlimited storage for any size of file, and extensive security options, making it a good choice for extremely large-scale big data solutions that require a centralized store for data in heterogeneous formats.\nReference:\nhttps://docs.microsoft.com/en-us/azure/architecture/data-guide/big-data/batch-processing https://docs.microsoft.com/bs-latn-ba/azure/storage/blobs/storage-blobs-introduction","answer":"A","isMC":true,"unix_timestamp":1627362540,"topic":"5"}],"exam":{"isMCOnly":false,"isBeta":false,"lastUpdated":"12 Apr 2025","numberOfQuestions":206,"name":"AI-100","id":39,"isImplemented":true,"provider":"Microsoft"},"currentPage":33},"__N_SSP":true}