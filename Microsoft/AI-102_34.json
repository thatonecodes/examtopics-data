{"pageProps":{"questions":[{"id":"bwWWpOkpYUh7Wo3xepka","question_text":"HOTSPOT\n-\n\nYou are building an Azure web app named App1 that will translate text from English to Spanish.\n\nYou need to use the Text Translation REST API to perform the translation. The solution must ensure that you have data sovereignty in the United States.\n\nHow should you complete the URI? To answer, select the appropriate options in the answer area.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","question_images":["https://img.examtopics.com/ai-102/image55.png"],"topic":"3","answers_community":[],"unix_timestamp":1686726540,"question_id":166,"discussion":[{"comments":[{"timestamp":"1714913160.0","poster":"rdemontis","content":"thanks for your contribution","upvote_count":"2","comment_id":"1062999"},{"timestamp":"1715179320.0","poster":"mpit","comment_id":"1065775","upvote_count":"1","content":"Thank you for your valuable contribution."}],"comment_id":"939936","poster":"zellck","content":"1. api-nam.cognitive.microsofttranslator.com\n2. translate\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/Translator/reference/v3-0-reference#base-urls\nRequests to Translator are, in most cases, handled by the datacenter that is closest to where the request originated. If there's a datacenter failure when using the global endpoint, the request may be routed outside of the geography.\n\nTo force the request to be handled within a specific geography, use the desired geographical endpoint. All requests are processed among the datacenters within the geography.\n- United States\napi-nam.cognitive.microsofttranslator.com\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/translator/reference/rest-api-guide\n- translate\nTranslate specified source language text into the target language text.","upvote_count":"35","timestamp":"1704120480.0"},{"timestamp":"1741855620.0","poster":"Mattt","comment_id":"1388231","upvote_count":"1","content":"Repeated more than 5 times in the question bank."},{"poster":"NagaoShingo","upvote_count":"2","content":"1. api-nam.cognitive.microsofttranslator.com\n2. translate","timestamp":"1733496240.0","comment_id":"1225503"},{"poster":"takaimomoGcup","comment_id":"1215789","upvote_count":"3","content":"api-nam.cognitive.microsofttranslator.com\ntranslate","timestamp":"1732291680.0"},{"poster":"abelarda","content":"Why not api-nam.cognitiveservice.azure.com/translate?","timestamp":"1731580980.0","upvote_count":"1","comment_id":"1211305"},{"content":"nam=North America","poster":"evangelist","comment_id":"1139200","upvote_count":"3","timestamp":"1722679260.0"},{"upvote_count":"1","timestamp":"1716812640.0","comment_id":"1081641","content":"The response is correct\n1. api-nam.cognitive.microsofttranslator.com\n2. translate","poster":"sca88"},{"timestamp":"1702544940.0","comment_id":"922830","poster":"973b658","content":"It is true.","upvote_count":"2"}],"answer_ET":"","answer_description":"","isMC":false,"timestamp":"2023-06-14 09:09:00","url":"https://www.examtopics.com/discussions/microsoft/view/112137-exam-ai-102-topic-3-question-49-discussion/","exam_id":40,"answer_images":["https://img.examtopics.com/ai-102/image56.png"],"answer":""},{"id":"8eGvN1KoF8nLFHnCorX0","unix_timestamp":1625073060,"answer_description":"Box 1: {\"fr\", \"de\", \"es\"}\nA common task of speech translation is to specify target translation languages, at least one is required but multiples are supported. The following code snippet sets both French and German as translation language targets. static async Task TranslateSpeechAsync()\n{\nvar translationConfig =\nSpeechTranslationConfig.FromSubscription(SPEECH__SUBSCRIPTION__KEY, SPEECH__SERVICE__REGION); translationConfig.SpeechRecognitionLanguage = \"it-IT\";\n\n// Translate to languages. See, https://aka.ms/speech/sttt-languages translationConfig.AddTargetLanguage(\"fr\"); translationConfig.AddTargetLanguage(\"de\");\n}\n\nBox 2: TranslationRecognizer -\nAfter you've created a SpeechTranslationConfig, the next step is to initialize a TranslationRecognizer.\nExample code:\nstatic async Task TranslateSpeechAsync()\n{\nvar translationConfig =\nSpeechTranslationConfig.FromSubscription(SPEECH__SUBSCRIPTION__KEY, SPEECH__SERVICE__REGION); var fromLanguage = \"en-US\"; var toLanguages = new List<string> { \"it\", \"fr\", \"de\" }; translationConfig.SpeechRecognitionLanguage = fromLanguage; toLanguages.ForEach(translationConfig.AddTargetLanguage); using var recognizer = new TranslationRecognizer(translationConfig);\n}","question_text":"HOTSPOT -\nYou are developing a service that records lectures given in English (United Kingdom).\nYou have a method named AppendToTranscriptFile that takes translated text and a language identifier.\nYou need to develop code that will provide transcripts of the lectures to attendees in their respective language. The supported languages are English, French,\nSpanish, and German.\nHow should you complete the code? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","timestamp":"2021-06-30 19:11:00","topic":"3","answer_ET":"","url":"https://www.examtopics.com/discussions/microsoft/view/56455-exam-ai-102-topic-3-question-5-discussion/","question_images":["https://www.examtopics.com/assets/media/exam-media/04271/0013100001.png"],"question_id":167,"answer_images":["https://www.examtopics.com/assets/media/exam-media/04271/0013200001.png"],"exam_id":40,"answer":"","discussion":[{"timestamp":"1625073060.0","content":"Correct!","poster":"azurelearner666","comment_id":"394991","upvote_count":"19"},{"upvote_count":"8","comment_id":"398578","content":"Seems correct\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.cognitiveservices.speech.translation.translationrecognizer?view=azure-dotnet","timestamp":"1625422080.0","poster":"idrisfl"},{"upvote_count":"1","timestamp":"1739343540.0","poster":"syupwsh","comment_id":"1355498","content":"(['fr', 'de', 'es']) is CORRECT because this list represents the language codes for French, German, and Spanish. These are the target languages into which the lecture needs to be translated. The method add_target_language(language) requires language codes to configure the translation for the specified languages.\n\nTranslationRecognizer is CORRECT because it is specifically designed to recognize speech and translate it into the specified target languages. Given the requirement to provide transcripts in multiple languages, the TranslationRecognizer is the appropriate choice."},{"content":"So, they want to make it a trick by asking for english language as well, but it does not need to be passed. So, one point for the person who remembers it does not have to be passed? That knowledge proves they know Azure-AI?","timestamp":"1725625800.0","upvote_count":"3","comment_id":"1279551","poster":"famco"},{"timestamp":"1719034500.0","comment_id":"1235139","content":"was on exam 20.06.24","upvote_count":"3","poster":"LM12"},{"comment_id":"1158166","poster":"audlindr","timestamp":"1708809600.0","content":"correct\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-translate-speech?tabs=terminal&pivots=programming-language-csharp","upvote_count":"1"},{"poster":"rdemontis","comment_id":"1062171","content":"correct answer\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.cognitiveservices.speech.translation.translationrecognizer?view=azure-dotnet","upvote_count":"2","timestamp":"1699108740.0"},{"poster":"ManvaIT","timestamp":"1696409940.0","comment_id":"1024594","upvote_count":"5","content":"Correct,got this in Oct2023 exam"},{"comment_id":"633034","upvote_count":"7","poster":"Eltooth","content":"Answer is correct.\n\n(\"fr\", \"de\", \"es\")\nTranslationRecognizer","timestamp":"1658149740.0"}],"answers_community":[],"isMC":false},{"id":"CsTapV8XiL2z1jvWwK8d","url":"https://www.examtopics.com/discussions/microsoft/view/112140-exam-ai-102-topic-3-question-50-discussion/","answers_community":[],"question_id":168,"answer_ET":"","answer_description":"","answer":"","question_text":"DRAG DROP\n-\n\nYou have a Docker host named Host1 that contains a container base image.\n\nYou have an Azure subscription that contains a custom speech-to-text model named model1.\n\nYou need to run model1 on Host1.\n\nWhich three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\n\n//IMG//","discussion":[{"comment_id":"939932","comments":[{"timestamp":"1709961300.0","upvote_count":"4","content":"Okay, this link provides more information about the approval step, but approval is only necessary when you run the container in a disconnected environment. So if that is mentioned in a question, choosing this step will make more sense.\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-container-overview#request-approval-to-run-the-container","poster":"Mehe323","comment_id":"1169289"}],"content":"1. Request approval to run container\n2. Export model1 to Host1\n3. Run the container\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/speech-container-stt?tabs=container&pivots=programming-language-csharp","upvote_count":"35","timestamp":"1688215440.0","poster":"zellck"},{"comment_id":"922836","content":"No.\n1.Export model1 to Host1. \n2.Request approval to run the container. \n3.Run the container.","upvote_count":"8","timestamp":"1686726720.0","comments":[{"poster":"omankoman","upvote_count":"4","comments":[{"comment_id":"1285275","upvote_count":"3","timestamp":"1726582380.0","content":"yes you are yes to the no","poster":"mrg998"}],"content":"you are no.\n1. Request approval to run container\n2. Export model1 to Host1\n3. Run the container","timestamp":"1716982980.0","comment_id":"1220878"}],"poster":"973b658"},{"content":"1) Request approval to run the container: Before running certain Azure Cognitive Services models in containers, you need to obtain approval from Microsoft. This step is crucial to ensure compliance with usage policies and to enable containerized deployment.\n\n2) Export model1 to Host1: You need to export the custom speech-to-text model from Azure to your local Docker host (Host1). This step involves downloading the model so that it can be used within the Docker container on Host1.\n\n3) Run the container: Finally, you need to run the Docker container on Host1, specifying the exported model. This step will launch the container with the speech-to-text model, enabling it to process speech data.","comment_id":"1358531","timestamp":"1739926860.0","poster":"syupwsh","upvote_count":"1"},{"poster":"sukantadey","content":"Request approval to run container\nExport model1 to Host1\nRun the container","comment_id":"1356211","upvote_count":"1","timestamp":"1739466120.0"},{"comment_id":"1281217","content":"Maybe the question creator was in a hurry (they always are) and saw only the documentation that said there needs to be approval (but it was for disconnected and even though this is not disconnected). Or maybe the question from ET missed disconnected keyword.","upvote_count":"3","poster":"famco","timestamp":"1725909900.0"},{"poster":"krzkrzkra","content":"1. Request approval to run container\n2. Export model1 to Host1\n3. Run the container","comment_id":"1248508","upvote_count":"2","timestamp":"1721067060.0"},{"upvote_count":"4","timestamp":"1718393940.0","content":"this is the answer from Copilot:\n\nTo run the custom speech-to-text model on your Docker host, you should perform the following actions in sequence:\n\nExport model to Host1: You need to export the model from Azure to your Docker host. This typically involves downloading the model and moving it to the Docker host.\n\nRun the container: Once the model is on the Docker host, you can run the container that uses this model.\n\nConfigure disk logging: After the container is running, configure disk logging to keep track of the container's activities and to troubleshoot any issues that might arise.","poster":"etellez","comment_id":"1230635"},{"content":"Request\nExport\nRun","comment_id":"1215787","upvote_count":"1","poster":"takaimomoGcup","timestamp":"1716386520.0"},{"comment_id":"1063014","poster":"rdemontis","timestamp":"1699196160.0","upvote_count":"2","content":"Probably here we are requested to run the container in a disconnected environmnet so i think correct answer is :\n\nRequest approval to run container\nExport model1 to Host1\nRun the container\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/containers/disconnected-containers"},{"upvote_count":"3","poster":"sl_mslconsulting","content":"You only need to request approval if you plan to run the container in a completely disconnected environment. And you might not get approved at all as there are some requirements. The question does not indicate if we need to run the container in such a environment.","timestamp":"1697323080.0","comment_id":"1043741","comments":[{"content":"Based on what you can choose here I would say itâ€™s a disconnected environment. For a connected environment using docker run allows you to download the model at the same so there is no need to export the model manually and then copy it to the host. Zellck is right in the choices.","upvote_count":"2","timestamp":"1697323560.0","poster":"sl_mslconsulting","comment_id":"1043742"}]},{"comment_id":"996888","timestamp":"1693671540.0","poster":"M25","upvote_count":"1","content":"https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-container-cstt?tabs=custom-model%2Ccontainer&pivots=programming-language-csharp\nIn this article, you'll learn how to download [from Microsoft Container Registry (MCR)], install, and run a Custom speech to text container.\nGet the model ID (to use as the argument to the ModelId parameter of the docker run command): The custom model has to have been trained by using the Speech Studio.\nN/a so far, excluding A (Retrain the model).","comments":[{"comment_id":"996889","timestamp":"1693658460.0","upvote_count":"2","content":"Run the container with docker run:\nB (Request approval precedes),\nThe docker run command will start the container when all three of the following options are provided with valid values: ApiKey, Billing, EULA\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-container-howto#billing-arguments\n\nD (Run container), C (Get model)\nHere's an example docker run command with placeholder values. â€¦ This command:\nâ€¢ Runs a custom speech to text container from the container image.\nâ€¢ Allocates 4 CPU cores and 8 GB of memory.\nâ€¢ Loads the custom speech to text model from the volume input mount, for example, C:\\CustomSpeech.\nâ€¢ Exposes TCP port 5000 and allocates a pseudo-TTY for the container.\nâ€¢ Downloads the model given the ModelId (if not found on the volume mount).","poster":"M25"}]},{"poster":"Tin_Tin","comment_id":"934027","timestamp":"1687752960.0","upvote_count":"1","content":"Not sure.\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/speech-container-overview#request-approval-to-run-the-container"}],"unix_timestamp":1686726720,"topic":"3","timestamp":"2023-06-14 09:12:00","exam_id":40,"answer_images":["https://img.examtopics.com/ai-102/image58.png"],"isMC":false,"question_images":["https://img.examtopics.com/ai-102/image57.png"]},{"id":"fz3fww1MUnrii1z8LheP","answer_ET":"A","choices":{"A":"Yes","B":"No"},"question_id":169,"answers_community":["A (59%)","B (41%)"],"isMC":true,"url":"https://www.examtopics.com/discussions/microsoft/view/112141-exam-ai-102-topic-3-question-51-discussion/","timestamp":"2023-06-14 09:13:00","answer_description":"","discussion":[{"content":"Selected Answer: A\nA. Yes\n\nCreating a new utterance for each phrase in the FindContact intent is a correct approach to implement the phrase list in Conversational Language Understanding. This method trains the language model to recognize variations of how users might express the intent to find contacts in different locations, thereby improving the model's accuracy in identifying the FindContact intent.","comment_id":"1139220","poster":"evangelist","comments":[{"comment_id":"1139221","upvote_count":"1","poster":"evangelist","content":"Yes, creating a new utterance for each phrase in the FindContact intent aligns with the recommended practice for designing applications in Conversational Language Understanding, as detailed in the documentation. This approach helps in accurately capturing the intent by providing diverse examples of how users might express their request, thus enhancing the model's ability to understand and classify user queries correctly. For more detailed guidelines, refer to the section on creating example utterances for each intent in the documentation","timestamp":"1706963100.0"}],"upvote_count":"13","timestamp":"1706962980.0"},{"content":"Selected Answer: B\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/luis/concepts/application-design#create-example-utterances-for-each-intent\n\nNo is the answer","timestamp":"1740888240.0","upvote_count":"1","poster":"syupwsh","comment_id":"1363762"},{"poster":"pabsinaz","upvote_count":"1","comment_id":"1333351","content":"Selected Answer: A\nAbsolutely yes","timestamp":"1735451580.0"},{"poster":"kennynelcon","timestamp":"1734735960.0","content":"Selected Answer: B\nPhrase List","upvote_count":"1","comment_id":"1329738"},{"comment_id":"1246812","poster":"krzkrzkra","upvote_count":"2","content":"Selected Answer: B\nSelected Answer: B","timestamp":"1720793160.0"},{"timestamp":"1719132300.0","upvote_count":"2","poster":"HVardhini","content":"Selected Answer: A\nA is the correct answer","comment_id":"1235749"},{"content":"Selected Answer: B\nit is B","comment_id":"1235114","upvote_count":"1","poster":"anjanc","timestamp":"1719033360.0"},{"timestamp":"1718460120.0","upvote_count":"2","poster":"fuck_india","comment_id":"1230987","content":"This issue is not working because everyone's opinion is 50-50. I don't know the correct answer, so I will be staring at MS Learn when this question comes up on the real exam.Examtopic should scrutinize and post the correct answer."},{"comment_id":"1217579","poster":"nanaw770","content":"Selected Answer: A\nIt MUST be A.","timestamp":"1716560460.0","upvote_count":"2"},{"poster":"PCRamirez","content":"According to Windows Copilot: B. No\n\nCreating a new utterance for each phrase in the FindContact intent is not the most efficient approach. Instead, you can use phrase lists in Conversational Language Understanding (LUIS) to group similar phrases together. By defining a phrase list, you can handle variations of the same intent more effectively. In this case, you can create a phrase list containing the cities (London, Seattle, Ukraine) and use it within the FindContact intent. This way, LUIS will recognize any variation of these cities as part of the same intent without creating individual utterances for each location. ðŸ˜Š","timestamp":"1707327360.0","upvote_count":"3","comment_id":"1143587","comments":[{"poster":"demonite","comment_id":"1224128","content":"LUIS is deprecated, CLU will handle creating a new utterance for each phrase","timestamp":"1717503900.0","upvote_count":"2"}]},{"content":"Selected Answer: B\nAccording to ChatGPT:\nB. No\n\nExplanation: While creating a new utterance for each phrase in the FindContact intent is a step in the right direction, it may not be sufficient to fully meet the goal. To effectively implement the phrase list in Conversational Language Understanding, it's essential to consider variations in how users might express the same intent. The provided phrases cover different scenarios (finding contacts in different locations), but there may be additional variations and nuances to consider. Therefore, merely creating a new utterance for each provided phrase might not capture all possible ways users could express the intent to find contacts. A more comprehensive approach to training the language model might involve incorporating synonyms, alternative phrasings, and potential variations that users might use when searching for contacts.","timestamp":"1707164340.0","poster":"Tactable","upvote_count":"2","comment_id":"1141436"},{"timestamp":"1704566100.0","upvote_count":"2","comment_id":"1115378","content":"Selected Answer: A\nIt's \"Yes\" actually, not the more efficient way to do it, but it will work","poster":"dimsok"},{"comments":[{"content":"It won't be efficient but it will do the job, I would vote for \"Yes\"","upvote_count":"2","timestamp":"1704565980.0","poster":"dimsok","comment_id":"1115375"}],"content":"Selected Answer: B\nB. No\n\nCreating a new utterance for each phrase in the FindContact intent is not the most efficient approach for implementing the provided phrase list. Instead, you should use phrase list features or entities to capture variations of these phrases more effectively.\n\nIn Conversational Language Understanding, you can define a phrase list or entity that includes variations of location names like \"London,\" \"Seattle,\" and \"Ukraine.\" By doing this, you allow the model to recognize these location names as entities, making your intent more flexible and capable of handling variations. This approach is much more scalable and less labor-intensive than creating individual utterances for each location.\n\nThe goal should be met by using phrase lists or entities effectively to capture variations in the input data and improve the model's performance. (ChatGPT)","poster":"rdemontis","timestamp":"1699197120.0","comment_id":"1063043","upvote_count":"1"},{"comment_id":"1043747","comments":[{"upvote_count":"1","content":"The utterances provided are different enough. But if your picky and insist that you should have at least 15 utterances that you would pick B anyway.","comment_id":"1043751","poster":"sl_mslconsulting","timestamp":"1697324580.0"}],"upvote_count":"1","content":"Selected Answer: B\nI picked B because you need the entity to retrieve the location from the utterances for you app to be able to know which contacts to retrieve from the store.","timestamp":"1697324400.0","poster":"sl_mslconsulting"},{"comment_id":"937400","content":"Selected Answer: B\nB is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/luis/concepts/application-design#create-example-utterances-for-each-intent\nTo start, avoid creating too many utterances for each intent. Once you have determined the intents you need for your app, create 15 to 30 example utterances per intent. Each utterance should be different from the previously provided utterances. Include a variety of word counts, word choices, verb tenses, and punctuation.","upvote_count":"4","timestamp":"1688006400.0","poster":"zellck"},{"upvote_count":"1","comment_id":"922837","content":"Selected Answer: B\nB. Same question.","timestamp":"1686726780.0","poster":"973b658"}],"exam_id":40,"unix_timestamp":1686726780,"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou build a language model by using a Conversational Language Understanding. The language model is used to search for information on a contact list by using an intent named FindContact.\n\nA conversational expert provides you with the following list of phrases to use for training.\n\nâ€¢ Find contacts in London.\nâ€¢ Who do I know in Seattle?\nâ€¢ Search for contacts in Ukraine.\n\nYou need to implement the phrase list in Conversational Language Understanding.\n\nSolution: You create a new utterance for each phrase in the FindContact intent.\n\nDoes this meet the goal?","answer_images":[],"question_images":[],"answer":"A","topic":"3"},{"id":"n3fop6UgeJJoOhMCZ4MY","exam_id":40,"timestamp":"2023-06-14 09:18:00","answer_description":"","isMC":false,"question_images":["https://img.examtopics.com/ai-102/image59.png"],"answer":"","url":"https://www.examtopics.com/discussions/microsoft/view/112143-exam-ai-102-topic-3-question-52-discussion/","discussion":[{"content":"1. From original instance, export existing project.\n2. From new instance, import the project file.\n3. From new instance, train and publish model.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/language-service/question-answering/how-to/migrate-knowledge-base","timestamp":"1688215260.0","poster":"zellck","upvote_count":"31","comment_id":"939927"},{"poster":"syupwsh","timestamp":"1739927040.0","content":"1) From the original Language service instance, export the existing project: Exporting the project from the original instance creates a project file that contains all the necessary configurations and data. This file is needed to import the project into the new instance.\n\n2) From the new Language service instance, import the project file: Importing the project file into the new instance sets up the project in the new region with the same configurations and data as the original.\n\n3) From the new Language service instance, train and publish the project: After importing the project, you need to train and publish it in the new instance to ensure it is fully functional and available for use.","upvote_count":"1","comment_id":"1358532"},{"content":"options are wrong last one should be train and publish model instead train and publish the project . Fix that.","comment_id":"1303512","timestamp":"1730015580.0","upvote_count":"2","poster":"Christian_garcia_martin"},{"comment_id":"1248512","poster":"krzkrzkra","timestamp":"1721067120.0","content":"1. From original instance, export existing project.\n2. From new instance, import the project file.\n3. From new instance, train and publish model.","upvote_count":"1"},{"comment_id":"1236636","poster":"JacobZ","upvote_count":"3","content":"Got this in the exam, Jun 2024.","timestamp":"1719270420.0"},{"comment_id":"1220867","content":"1. From original instance, export existing project.\n2. From new instance, import the project file.\n3. From new instance, train and publish model.","timestamp":"1716982560.0","poster":"omankoman","upvote_count":"3"},{"timestamp":"1716386220.0","poster":"takaimomoGcup","upvote_count":"2","comment_id":"1215784","content":"original, export existing project.\nnew, import the project file.\nnew, train and publish model."},{"upvote_count":"1","comment_id":"1139222","content":"Answer is correct\nfirst from the source instance, export the source project;\nat the new instance, import the exported source project;\nto deploy, one has to train and publish the model from imported project, the training is needed before the model can work in new project from different Azure region","timestamp":"1706963220.0","poster":"evangelist"},{"upvote_count":"3","poster":"rdemontis","timestamp":"1699197600.0","content":"the answer seems correct:\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/language-service/question-answering/how-to/migrate-knowledge-base\nhttps://learn.microsoft.com/en-us/azure/ai-services/qnamaker/quickstarts/create-publish-knowledge-base#publish-the-knowledge-base","comment_id":"1063048"},{"poster":"973b658","comment_id":"922842","content":"It is true.","timestamp":"1686727080.0","upvote_count":"2"}],"question_id":170,"answer_ET":"","answer_images":["https://img.examtopics.com/ai-102/image60.png"],"question_text":"DRAG DROP\n-\n\nYou have a question answering project in Azure Cognitive Service for Language.\n\nYou need to move the project to a Language service instance in a different Azure region.\n\nWhich three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\n\n//IMG//","answers_community":[],"unix_timestamp":1686727080,"topic":"3"}],"exam":{"isMCOnly":false,"name":"AI-102","id":40,"numberOfQuestions":329,"lastUpdated":"12 Apr 2025","isBeta":false,"provider":"Microsoft","isImplemented":true},"currentPage":34},"__N_SSP":true}