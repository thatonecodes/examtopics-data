{"pageProps":{"questions":[{"id":"gjIfQfDBj6zGfJZamun4","isMC":false,"answer":"","timestamp":"2021-09-18 14:21:00","answer_images":["https://www.examtopics.com/assets/media/exam-media/04271/0024200001.png"],"url":"https://www.examtopics.com/discussions/microsoft/view/62325-exam-ai-102-topic-5-question-12-discussion/","question_text":"HOTSPOT -\nYou are building a bot and that will use Language Understanding.\nYou have a LUDown file that contains the following content.\n//IMG//\n\nUse the drop-down menus to select the answer choice that completes each statement based on the information presented in the graphic.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","question_images":["https://www.examtopics.com/assets/media/exam-media/04271/0024000001.png","https://www.examtopics.com/assets/media/exam-media/04271/0024100001.png"],"answer_description":"Reference:\nhttps://github.com/solliancenet/tech-immersion-data-ai/blob/master/ai-exp1/README.md","question_id":241,"exam_id":40,"unix_timestamp":1631967660,"answers_community":[],"topic":"5","discussion":[{"upvote_count":"23","poster":"Zoul","content":"Answer is correct. From the link provided:\nSelectItem is the intent, and each item below it are example utterances that capture ways users can express this intent. Entities in .lu files are denoted using {<entityName>=<labeled value>} notation. Taking from our sample code once again, you can find the bottom left entity within the following utterance: choose the {DirectionalReference=bottom left}.","comment_id":"463294","timestamp":"1634420340.0"},{"timestamp":"1688290980.0","comment_id":"940718","content":"1. intent\n2. utterance\n\nhttps://learn.microsoft.com/en-us/azure/bot-service/file-format/bot-builder-lu-file-format?view=azure-bot-service-4.0#defining-intents-using-sample-utterances\nIntents with their sample utterances are declared in the following way:\n# <intent-name>\n - <utterance1>\n - <utterance2>\n# <intent-name> describes a new intent definition section. Each line after the intent definition are example utterances that describe that intent using the - <utterance> format.","upvote_count":"18","poster":"zellck"},{"poster":"syupwsh","comment_id":"1355922","timestamp":"1739410380.0","content":"SelectItem is an intent because in the context of Language Understanding (LUIS), intents represent actions that users want to perform. The phrases under \"SelectItem\" (e.g., \"choose last\", \"choose the {DirectionalReference=bottom left}\") are examples of user utterances that map to the action of selecting an item, indicating that \"SelectItem\" is the intent.\n\nChoose {@DirectionalReference=top right} is an utterance because it is a specific example of what a user might say to invoke the \"SelectItem\" intent. In Language Understanding (LUIS), utterances are the individual phrases that users might say, which are then mapped to a corresponding intent for processing.","upvote_count":"1"},{"content":"1. intent\n2. utterance","comment_id":"1247924","upvote_count":"3","timestamp":"1720981140.0","poster":"krzkrzkra"},{"content":"correct answer and explanation. The provided reference demonstrates it","poster":"rdemontis","comment_id":"1065028","timestamp":"1699378020.0","upvote_count":"2"},{"upvote_count":"1","content":"Answer is correct. \nThe LUIS model begins with categories of user intentions called intents. Each intent needs examples of user utterances (something a user should say). Each utterance can provide a variety of data that needs to be extracted with entities.","poster":"ParkXD","comment_id":"637908","timestamp":"1658908260.0"},{"comment_id":"633609","content":"Intent\nUtterance.","timestamp":"1658238780.0","poster":"Eltooth","upvote_count":"2"},{"upvote_count":"2","poster":"sdokmak","comment_id":"620250","timestamp":"1655887740.0","content":"a trick stolen from previous questions\n(U) (S) A, Utterance Statement\n(E)(n)gland, Entity Noun\n(I)(v)ory Coast, Intent Verb"},{"upvote_count":"1","timestamp":"1652154060.0","content":"Answer is correct","poster":"PHD_CHENG","comment_id":"599392"},{"poster":"Ravnit","comment_id":"488678","content":"Was on exam 27/11/2021","upvote_count":"1","timestamp":"1638063120.0"},{"content":"Based on the reference, it should be entity for the second question","timestamp":"1631967660.0","poster":"Diem","comment_id":"447066","upvote_count":"7"}],"answer_ET":""},{"id":"temJP5Y9l1JojFO1UqeW","answer":"","question_text":"HOTSPOT -\nYou are designing a conversation flow to be used in a chatbot.\nYou need to test the conversation flow by using the Microsoft Bot Framework Emulator.\nHow should you complete the .chat file? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","exam_id":40,"answers_community":[],"question_id":242,"answer_ET":"","unix_timestamp":1631867340,"answer_description":"Reference:\nhttps://docs.microsoft.com/en-us/azure/bot-service/bot-builder-howto-add-media-attachments?view=azure-bot-service-4.0&tabs=csharp","timestamp":"2021-09-17 10:29:00","url":"https://www.examtopics.com/discussions/microsoft/view/62268-exam-ai-102-topic-5-question-13-discussion/","answer_images":["https://www.examtopics.com/assets/media/exam-media/04271/0024400001.png"],"topic":"5","question_images":["https://www.examtopics.com/assets/media/exam-media/04271/0024300001.png"],"discussion":[{"poster":"Diem","upvote_count":"13","comment_id":"451675","timestamp":"1664170560.0","content":"The given answer is correct. Second box is Carousel which includes multiple attachments."},{"timestamp":"1719913080.0","poster":"zellck","comment_id":"940715","content":"1. Typing\n2. carousel\n3. adaptivecard\n\nhttps://learn.microsoft.com/en-us/azure/bot-service/bot-service-design-user-experience?view=azure-bot-service-4.0#cards\n- CardCarousel\nA horizontally scrollable collection of cards that allows your user to easily view a series of possible user choices.\n- AdaptiveCard\nAn open card exchange format rendered as a JSON object. Typically used for cross-channel deployment of cards. Cards adapt to the look and feel of each host channel.","upvote_count":"11"},{"upvote_count":"1","timestamp":"1739410560.0","poster":"syupwsh","comment_id":"1355923","content":"Typing is CORRECT because it simulates the typing indicator shown to users, making the interaction more natural by indicating that the bot is processing the user's request and preparing a response.\n\ncarousel is CORRECT because it is used to display multiple attachments in a horizontal layout, allowing users to scroll through options. This is appropriate for displaying multiple watch images.\n\nadaptivecard is CORRECT because it is used to display richly formatted content, which is appropriate for presenting detailed information about the selected watch, such as in a watch profile card."},{"comment_id":"1065031","content":"the answer seems correct\n\nhttps://docs.microsoft.com/en-us/azure/bot-service/bot-builder-howto-send-messages?view=azure-bot-service-4.0&tabs=csharp\n\n\nhttps://learn.microsoft.com/en-us/azure/bot-service/bot-service-design-user-experience?view=azure-bot-service-4.0#cards","poster":"rdemontis","timestamp":"1731000720.0","upvote_count":"3"},{"comment_id":"920334","timestamp":"1718065380.0","poster":"ziggy1117","content":"answer is correct:\n\nIn the context of Azure Bot Service, a carousel refers to a visual component that displays a set of cards or items in a horizontally scrollable format. It is commonly used to present multiple options or pieces of information to the user in a visually appealing manner.\n\nA carousel typically consists of multiple cards, where each card represents a specific item, option, or piece of content. Each card within the carousel can contain text, images, buttons, or other interactive elements. Users can scroll through the carousel horizontally to view and interact with different cards.","upvote_count":"1"},{"content":"Was on exam 27/11/2021","poster":"Ravnit","comment_id":"488679","timestamp":"1669599120.0","upvote_count":"2"},{"content":"Second box should be thumbnail","comment_id":"446480","timestamp":"1663404600.0","poster":"GMKanon","upvote_count":"2"},{"poster":"SnowCheetah","comments":[{"upvote_count":"1","poster":"timmayy54","content":"Fully Agree, for 2. having 2 attachments makes Carousel more right than Adaptive, plus Adaptive is last answer and double using the same one is quite rare.","timestamp":"1674866160.0","comment_id":"534224"}],"content":"I am not sure on the second answer is correct or not\n\n1. Typing is correct ( it's answer indicate on [delay] ) https://docs.microsoft.com/en-us/azure/bot-service/bot-builder-howto-send-messages?view=azure-bot-service-4.0&tabs=csharp\n\n2. Since attachment is attach with 2 images ==> it cannot be thumbnail, which can only a simple card as a proper response. however I am not sure adaptive card can be selected as well for this choice.\n\n3. Adaptive card is correct ( in context after user send selection, bot is sending detail of selected item ) https://docs.microsoft.com/en-us/azure/bot-service/bot-builder-howto-add-media-attachments?view=azure-bot-service-4.0&tabs=csharp","upvote_count":"3","timestamp":"1663403340.0","comment_id":"446466"}],"isMC":false},{"id":"w6j5wnsNOpRiUQOqSbRr","answer":"A","question_text":"You are building a chatbot by using the Microsoft Bot Framework Composer as shown in the exhibit. (Click the Exhibit tab.)\n//IMG//\n\nThe chatbot contains a dialog named GetUserDetails. GetUserDetails contains a TextInput control that prompts users for their name.\nThe user input will be stored in a property named name.\nYou need to ensure that you can dispose of the property when the last active dialog ends.\nWhich scope should you assign to name?","exam_id":40,"answers_community":["A (100%)"],"question_id":243,"unix_timestamp":1652596560,"answer_ET":"A","timestamp":"2022-05-15 08:36:00","answer_description":"","url":"https://www.examtopics.com/discussions/microsoft/view/75647-exam-ai-102-topic-5-question-14-discussion/","answer_images":[],"topic":"5","question_images":["https://www.examtopics.com/assets/media/exam-media/04271/0024500001.png"],"choices":{"A":"dialog","B":"user","C":"turn","D":"conversation"},"discussion":[{"comment_id":"940703","poster":"zellck","timestamp":"1688290200.0","content":"Selected Answer: A\nA is the answer.\n\nhttps://learn.microsoft.com/en-us/composer/ref-memory-variables?tabs=v2x#the-scopes\n- Dialog\nProperties associated with the active dialog. Properties in the dialog scope are kept until the dialog ends.","upvote_count":"8"},{"poster":"syupwsh","timestamp":"1739751840.0","comment_id":"1357502","upvote_count":"1","content":"Selected Answer: A\nCredit to zellck for the link provided\n\nAnswer is A"},{"content":"Selected Answer: A\nA is answer.","comment_id":"1229900","poster":"reigenchimpo","upvote_count":"1","timestamp":"1718290920.0"},{"timestamp":"1717251240.0","content":"Selected Answer: A\nA is right answer.","comment_id":"1222689","poster":"nanaw770","upvote_count":"1"},{"content":"Selected Answer: A\nhttps://learn.microsoft.com/en-us/composer/concept-memory?tabs=v1x","poster":"rdemontis","upvote_count":"2","timestamp":"1699378920.0","comment_id":"1065041"},{"comments":[{"content":"True, when it says \"when the dialog ends\", one could say that it means \"after the dialog ends\", or \"until\". Why are you so sure?","poster":"abelarda","comment_id":"1211554","upvote_count":"1","timestamp":"1715703540.0"},{"poster":"Moody_L","timestamp":"1654158900.0","upvote_count":"4","content":"Dialog scope are retained until the \"last active dialog ends\". That's what the question asked for.\nRef: Under \"Composer v1.x\" tab, https://docs.microsoft.com/en-us/composer/concept-memory?tabs=v2x","comment_id":"610503","comments":[{"upvote_count":"2","timestamp":"1660755960.0","poster":"ninjia","content":"Agreed. A. dialog","comment_id":"648165"}]}],"comment_id":"601934","poster":"Isidro","upvote_count":"1","content":"Shouldn't it be USER? If Dialog is selected, one the last dialog is concluded, the information will be lost.","timestamp":"1652596560.0"}],"isMC":true},{"id":"zwQBjm9u1hnxtKdieK3F","isMC":false,"exam_id":40,"answer_ET":"","answer_description":"Step 1: For the knowledge base, select Show active learning suggestions.\nIn order to see the suggested questions, on the Edit knowledge base page, select View Options, then select Show active learning suggestions.\nStep 2: Approve and reject suggestions.\nEach QnA pair suggests the new question alternatives with a check mark, , to accept the question or an x to reject the suggestions. Select the check mark to\nג\"\nadd the question.\nStep 3: Save and train the knowledge base.\nSelect Save and Train to save the changes to the knowledge base.\nStep 4: Publish the knowledge base.\nSelect Publish to allow the changes to be available from the GenerateAnswer API.\nWhen 5 or more similar queries are clustered, every 30 minutes, QnA Maker suggests the alternate questions for you to accept or reject.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/qnamaker/how-to/improve-knowledge-base","question_text":"DRAG DROP -\nYou have a chatbot that uses a QnA Maker application.\nYou enable active learning for the knowledge base used by the QnA Maker application.\nYou need to integrate user input into the model.\nWhich four actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\nSelect and Place:\n//IMG//","discussion":[{"timestamp":"1688286360.0","comments":[{"content":"agree. thanks for explanation and references","poster":"rdemontis","comment_id":"1070660","timestamp":"1699980480.0","upvote_count":"5"}],"upvote_count":"22","content":"1. From knowledge base, select show active learning suggestions.\n2. Approve and reject the suggestions.\n3. Save and train knowledge base.\n4. Publish knowledge base.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/qnamaker/how-to/improve-knowledge-base#view-suggested-questions\n- In order to see the suggested questions, on the Edit knowledge base page, select View Options, then select Show active learning suggestions. This option will be disabled if there are no suggestions present for any of the question and answer pairs.\n- Each QnA pair suggests the new question alternatives with a check mark, ✔ , to accept the question or an x to reject the suggestions. Select the check mark to add the question.\n- Select Save and Train to save the changes to the knowledge base.\n- Select Publish to allow the changes to be available from the GenerateAnswer API.","comment_id":"940652","poster":"zellck"},{"comment_id":"633983","timestamp":"1658313360.0","content":"Answer provided is correct.\n\n(Turn on active learning) - Done\n1. Show active learning suggestions\n2. Accept the question or reject the suggestions\n3. Save and Train\n4. Publish\n\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/qnamaker/how-to/improve-knowledge-base#view-suggested-questions","poster":"Eltooth","comments":[{"timestamp":"1717250940.0","poster":"nanaw770","upvote_count":"1","comment_id":"1222684","content":"Your spelling mistake confuses the whole thing. The correct answer is this.\n\n1. For the knowledge base, select Show active learning suggestions.\n2. Approve and reject the suggestions.\n3. Save and train knowledge base.\n4. Publish knowledge base."},{"upvote_count":"1","timestamp":"1660756140.0","comment_id":"648166","poster":"ninjia","content":"Agreed."}],"upvote_count":"13"},{"upvote_count":"1","poster":"syupwsh","comment_id":"1355925","content":"1) For the knowledge base, select Show active learning suggestions is CORRECT because enabling this option allows you to see the suggestions generated by active learning, which are based on user interactions and feedback.\n\n2) Approve and reject suggestions is CORRECT because reviewing the suggestions and approving or rejecting them helps improve the knowledge base by incorporating relevant user input and feedback.\n\n3) Save and train the knowledge base is CORRECT because after approving and rejecting suggestions, you need to save these changes and train the knowledge base to update the model with the new information.\n\n4) Publish the knowledge base is CORRECT because publishing the knowledge base makes the updated model available to the chatbot, ensuring that it can use the improved responses based on the integrated user input.","timestamp":"1739411220.0"},{"upvote_count":"2","poster":"anto69","comment_id":"1266169","content":"1. From knowledge base, select show active learning suggestions.\n2. Approve and reject the suggestions.\n3. Save and train knowledge base.\n4. Publish knowledge base.","timestamp":"1723692960.0"},{"poster":"evangelist","content":"1. Show active learning suggestions\n2. Accept the question or reject the suggestions\n3. Save and Train\n4. Publish","upvote_count":"1","comment_id":"1139893","timestamp":"1707033960.0"}],"question_id":244,"answer_images":["https://www.examtopics.com/assets/media/exam-media/04271/0024800001.png"],"url":"https://www.examtopics.com/discussions/microsoft/view/77633-exam-ai-102-topic-5-question-15-discussion/","answer":"","answers_community":[],"topic":"5","unix_timestamp":1658313360,"timestamp":"2022-07-20 12:36:00","question_images":["https://www.examtopics.com/assets/media/exam-media/04271/0024700001.png"]},{"id":"ajyl3KWbwbjvBiQP9UGz","question_id":245,"answer_images":[],"discussion":[{"upvote_count":"13","content":"Selected Answer: ABC\nA, B and C are correct answers in order shown below.\n\nB. Create a Speech service \nhttps://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/tutorial-voice-enable-your-bot-speech-sdk#create-a-speech-service-resource\n\nA. Enable WebSockets for the chatbot app \nhttps://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/tutorial-voice-enable-your-bot-speech-sdk#enable-web-sockets\n\nC. Register a Direct Line Speech channel \nhttps://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/tutorial-voice-enable-your-bot-speech-sdk#register-the-direct-line-speech-channel","comment_id":"633987","timestamp":"1658314020.0","poster":"Eltooth"},{"upvote_count":"1","poster":"syupwsh","comment_id":"1354739","content":"Selected Answer: ABC\nEnable WebSockets for the chatbot app is CORRECT because WebSockets are required to establish a real-time, bidirectional communication channel between the client and the server, which is essential for handling speech input and output effectively.\n\nCreate a Speech service is CORRECT because the Speech service provides the necessary capabilities to convert speech to text, text to speech, and handle other speech-related functionalities required for enabling speech in the chatbot.\n\nRegister a Direct Line Speech channel is CORRECT because the Direct Line Speech channel allows the bot to integrate with the Speech service and handle voice interactions. This channel is specifically designed for enabling speech capabilities in a chatbot.\n\nABC it is","timestamp":"1739235600.0"},{"timestamp":"1721079600.0","comment_id":"1248583","poster":"SAMBIT","upvote_count":"1","content":"Do create some to really get to the answer. A is not a choice. CORS is a must."},{"upvote_count":"2","poster":"reigenchimpo","content":"Selected Answer: ABC\nABC is answer. difficult.","comment_id":"1229898","timestamp":"1718290860.0"},{"poster":"nanaw770","timestamp":"1717250760.0","comment_id":"1222682","content":"Selected Answer: ABC\nABC is justice! Sunshine Ikezaki!","upvote_count":"1"},{"content":"Selected Answer: ABC\nPlease do not choose BCE, \n\nTo enable speech capabilities for a chatbot, the correct actions include:\n\nA. Enable WebSockets for the chatbot app: Necessary for the bot to communicate with the Direct Line Speech channel using web sockets.\nB. Create a Speech service: Required to provide speech-to-text and text-to-speech capabilities for the chatbot.\nC. Register a Direct Line Speech channel: Essential for connecting the chatbot with the Speech service to enable speech interactions.\nFor detailed steps, you can refer to the official Azure documentation: Tutorial: Voice-enable your bot.\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/tutorial-voice-enable-your-bot-speech-sdk#enable-web-sockets","poster":"evangelist","upvote_count":"1","timestamp":"1707034200.0","comment_id":"1139894"},{"poster":"rdemontis","comment_id":"1065057","timestamp":"1699379820.0","upvote_count":"2","content":"Selected Answer: ABC\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/tutorial-voice-enable-your-bot-speech-sdk"},{"poster":"zellck","upvote_count":"4","timestamp":"1688047740.0","content":"Selected Answer: ABC\nABC is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/tutorial-voice-enable-your-bot-speech-sdk#create-a-speech-service-resource\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/tutorial-voice-enable-your-bot-speech-sdk#enable-web-sockets\nYou need to make a small configuration change so that your bot can communicate with the Direct Line Speech channel by using web sockets. \n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/tutorial-voice-enable-your-bot-speech-sdk#register-the-direct-line-speech-channel\nThis channel creates a connection between your bot and a client app compiled with the Speech SDK.","comment_id":"938226"},{"content":"Selected Answer: ABC\nsaid ChatGPT","timestamp":"1682344440.0","comment_id":"879400","upvote_count":"3","poster":"Pffffff"},{"comment_id":"840817","upvote_count":"1","content":"Selected Answer: BCE\nAccording to ChapGPT, the correct answers are BCE : \nThe three actions that need to be performed to enable speech capabilities for an Azure chatbot are:\n\nB. Create a Speech service: A Speech service is needed to process the audio input and output of the chatbot. Azure provides the Speech service that can be created from the Azure portal.\n\nC. Register a Direct Line Speech channel: A Direct Line Speech channel needs to be registered in the Azure portal for the chatbot app. The Direct Line Speech channel enables the chatbot to receive audio input and provide audio output to the user.\n\nE. Enable CORS for the chatbot app: Cross-Origin Resource Sharing (CORS) needs to be enabled for the chatbot app to allow the browser to access resources from a different domain. This is required when using the Direct Line Speech channel.\n\nTherefore, the correct actions are B, C, and E.","timestamp":"1678963020.0","poster":"marti_tremblay000"},{"comment_id":"766960","poster":"Pyguy","timestamp":"1672945020.0","upvote_count":"2","comments":[{"content":"Can you please share your reference?\n\nEltooth has provided link as below.\nEnable web sockets\nYou need to make a small configuration change so that your bot can communicate with the Direct Line Speech channel by using web sockets. \nhttps://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/tutorial-voice-enable-your-bot-speech-sdk#enable-web-sockets","comment_id":"816078","poster":"AzureJobsTillRetire","timestamp":"1676941980.0","upvote_count":"1"}],"content":"Selected Answer: BCE\ninstead of WebSockets you should enable CORS . Cross-Origin Resource Sharing , will allow your bot app to communicate with the Speech service.. Nothing to do websockets here.."}],"choices":{"E":"Enable CORS for the chatbot app.","F":"Create a Language Understanding service.","D":"Register a Cortana channel.","B":"Create a Speech service.","C":"Register a Direct Line Speech channel.","A":"Enable WebSockets for the chatbot app."},"isMC":true,"topic":"5","question_images":[],"unix_timestamp":1658314020,"question_text":"You need to enable speech capabilities for a chatbot.\nWhich three actions should you perform? Each correct answer presents part of the solution.\nNOTE: Each correct selection is worth one point.","answer_description":"","answer_ET":"ABC","url":"https://www.examtopics.com/discussions/microsoft/view/77634-exam-ai-102-topic-5-question-16-discussion/","answers_community":["ABC (90%)","10%"],"timestamp":"2022-07-20 12:47:00","exam_id":40,"answer":"ABC"}],"exam":{"numberOfQuestions":329,"provider":"Microsoft","isMCOnly":false,"isImplemented":true,"name":"AI-102","id":40,"isBeta":false,"lastUpdated":"12 Apr 2025"},"currentPage":49},"__N_SSP":true}