{"pageProps":{"questions":[{"id":"4a19LFgWji01gTQ9yuhZ","topic":"6","exam_id":51,"url":"https://www.examtopics.com/discussions/microsoft/view/18753-exam-az-301-topic-6-question-27-discussion/","answer_ET":"","question_text":"HOTSPOT -\nYou are designing an Azure web app.\nYou plan to deploy the web app to the North Europe Azure region and the West Europe Azure region.\nYou need to recommend a solution for the web app. The solution must meet the following requirements:\n✑ Users must always access the web app from the North Europe region, unless the region fails.\n✑ The web app must be available to users if an Azure region is unavailable.\n✑ Deployment costs must be minimized.\nWhat should you include in the recommendation? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","discussion":[{"poster":"Protonenpaule","timestamp":"1587371880.0","content":"https://docs.microsoft.com/en-us/azure/traffic-manager/traffic-manager-routing-methods#priority-traffic-routing-method","comment_id":"76847","upvote_count":"11"},{"comments":[{"upvote_count":"1","timestamp":"1632633960.0","poster":"lawry","content":"Azure App Service application itself doesn't support muti-regions. We need a Load balancer.\nhttps://docs.microsoft.com/en-us/azure/architecture/reference-architectures/app-service-web-app/multi-region\nHowever, for the fixed default region and failover, we choose to use Traffic Manager.","comment_id":"451671"}],"poster":"amsun10","upvote_count":"1","timestamp":"1629350220.0","comment_id":"427229","content":"Why not select Application Gateway in Box1"},{"content":"given answer is correct.","upvote_count":"1","comment_id":"306464","timestamp":"1615301280.0","poster":"glam"},{"timestamp":"1609634460.0","upvote_count":"1","content":"given answer is correct.","poster":"sanketshah","comment_id":"258037"},{"timestamp":"1599229980.0","upvote_count":"4","content":"Answers are correct. Ironically this same scenario, this same questions were asked in AWS Solutions Architect exam with Route 66 (instead of Traffic Manager) and Priority routing (same as priority routing)","comments":[{"comments":[{"content":"There is in AWS","timestamp":"1656097800.0","comments":[{"comment_id":"621839","poster":"JayBee65","content":"Actually its Route 53, close :)","timestamp":"1656097860.0","upvote_count":"1"}],"poster":"JayBee65","upvote_count":"1","comment_id":"621838"}],"timestamp":"1603522440.0","comment_id":"204969","upvote_count":"2","content":"there's no such thing as Route 66","poster":"certmonster"}],"poster":"exams0123456","comment_id":"173462"},{"poster":"RiteshAg","comment_id":"110176","upvote_count":"1","comments":[{"poster":"FloJoe","timestamp":"1592564760.0","upvote_count":"5","comment_id":"113881","content":"Because of the requirement \"sers must always access the web app from the North Europe region, unless the region fails.\" \n\nAnd geographic routing would route users to the service which is closest to their location based on DNS info."}],"content":"why not geographic routing method?","timestamp":"1592143920.0"},{"upvote_count":"3","comment_id":"88693","content":"given ans is correct","timestamp":"1589429460.0","poster":"pandeya442"}],"question_id":196,"isMC":false,"answer":"","answers_community":[],"answer_images":["https://www.examtopics.com/assets/media/exam-media/02744/0019200001.jpg"],"timestamp":"2020-04-20 10:38:00","question_images":["https://www.examtopics.com/assets/media/exam-media/02744/0019100004.jpg"],"answer_description":"","unix_timestamp":1587371880},{"id":"qavp9GTyktEVspopPq8S","question_text":"DRAG DROP -\nYou need to design an architecture to capture the creation of users and the assignment of roles. The captured data must be stored in Azure Cosmos DB.\nWhich Azure services should you include in the design? To answer, drag the appropriate services to the correct targets. Each service may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.\nNOTE: Each correct selection is worth one point.\nSelect and Place:\n//IMG//","answers_community":[],"exam_id":51,"topic":"6","timestamp":"2019-09-05 10:34:00","question_images":["https://www.examtopics.com/assets/media/exam-media/02744/0019400001.jpg"],"answer_ET":"","unix_timestamp":1567672440,"answer_description":"","question_id":197,"discussion":[{"comment_id":"10554","timestamp":"1568176500.0","content":"My Answer for this question is Event Grid and Azure Functions, it clearly articulated in this URL: https://docs.microsoft.com/en-us/learn/modules/choose-a-messaging-model-in-azure-to-connect-your-services/4-choose-event-grid","upvote_count":"51","poster":"Shankar","comments":[{"content":"No, because for event grid, source can't be active directory log.","timestamp":"1578079680.0","poster":"onlyfunmails","comment_id":"35045","upvote_count":"9"},{"timestamp":"1593680940.0","upvote_count":"7","content":"Sorry, you are wrong. Follow this tutorial how you can achevie this exactly https://docs.microsoft.com/en-us/azure/active-directory/reports-monitoring/tutorial-azure-monitor-stream-logs-to-event-hub","comment_id":"124835","poster":"dev2dev"},{"poster":"qr","timestamp":"1598685060.0","upvote_count":"3","content":"Upvoted Shankar mistakenly as answer is actually correct as per dev2dev link.","comment_id":"168997"},{"upvote_count":"1","comment_id":"673130","poster":"sKaiNL","timestamp":"1663579800.0","content":"No, the page you gave states that it gets data from multiple sources and Event Hub is one of them. The event structure for Event Grid is something different than the AAD audit events. Check the page again. So nothing relevant is clearly articulated.\nBy the way it is clearly mentioned in the link below that \"You can route AAD logs to your Azure Storage account, Event Hub, Azure Monitor Logs or a custom solution\"\nhttps://learn.microsoft.com/en-us/azure/active-directory/reports-monitoring/concept-activity-logs-azure-monitor"}]},{"content":"https://docs.microsoft.com/en-us/azure/active-directory/reports-monitoring/concept-activity-logs-azure-monitor . Azure Event Hub can read data from Azure AD audit log and then use function along with cosmos DB change feed to store in Cosmos DB","poster":"pradjhun","upvote_count":"21","comment_id":"27305","timestamp":"1575654720.0"},{"timestamp":"1645411680.0","comment_id":"552467","poster":"joehoesofat","upvote_count":"1","content":"this one is correct https://www.examtopics.com/discussions/microsoft/view/62786-exam-az-304-topic-5-question-60-discussion/"},{"timestamp":"1616840580.0","poster":"j888","comment_id":"321757","upvote_count":"1","content":"Difficult question. It definitely needs to involve pushing the Event Hub -> Event Grid -> function-> cosmo db. Will just take the given answer as the correct answer"},{"content":"Answer is correct , Azure active directory - monitoring-audit logs -add Diagnostic settings- you will have 3 options ( log analytics workspace - storage account - event hub ) no option for even grid , please comment how you will send the audit log for event grid directly from Azure AD ? as per the graph !!!","timestamp":"1616684460.0","upvote_count":"2","poster":"sallymaher","comment_id":"320300"},{"timestamp":"1616439720.0","poster":"AKumar","upvote_count":"1","content":"May be this link help you to choose the best option..\n\nhttps://docs.microsoft.com/en-us/azure/event-grid/event-grid-event-hubs-integration","comment_id":"317456"},{"timestamp":"1615378440.0","poster":"slafcemafce","comment_id":"307140","content":"Event Hub (because Event Grid doesn't contain the actual item that has to be stored)\nAzure Function","upvote_count":"1"},{"content":"event hub\nazure function","timestamp":"1615301400.0","upvote_count":"1","poster":"glam","comment_id":"306467"},{"poster":"eulerzzzz","timestamp":"1611472500.0","comment_id":"275071","upvote_count":"2","content":"Grid - Function. \"Azure Event Grid is ideal for reactive scenarios, like when an item has been shipped or an item has been added or updated on storage. We have to take into account also its native integrations with Functions, Logic Apps and Webhooks. Moreover, Event Grid is cheaper than Event Hubs and more suitable when we don’t have to deal with big data\" , https://www.cognizantsoftvision.com/blog/azure-event-grid-vs-event-hubs/"},{"poster":"sanketshah","comment_id":"258039","content":"Event Grid\nAzure function \ncorrect answer.","timestamp":"1609634640.0","upvote_count":"2"},{"upvote_count":"1","comments":[{"upvote_count":"1","comment_id":"254037","timestamp":"1609157760.0","content":"Can't edit my previous post,\nwas trying to say, Answer is incorrect.\n\nIt should be Event Grid and Azure Function.","poster":"PrashantGupta1616"}],"timestamp":"1608900600.0","poster":"PrashantGupta1616","content":"Correct answer.\nAs per MS documents;\n\nEvent grid meant for event capturing purpose and easily integrated with Azure services\nand event hub use for big data app/pipeline.\nhttps://docs.microsoft.com/en-us/azure/event-grid/compare-messaging-services","comment_id":"252051"},{"content":"A good answer to this question is explained here: https://www.cognizantsoftvision.com/blog/azure-event-grid-vs-event-hubs/#:~:text=The%20noticeable%20difference%20between%20them,can%20trigger%20an%20Azure%20Function.\nAnswer should be Event Grid and Azure Function","upvote_count":"1","timestamp":"1601465760.0","poster":"NDubey","comment_id":"190307"},{"content":"the answer is clear here, event hub & azure function:\nhttps://docs.microsoft.com/en-us/azure/active-directory/reports-monitoring/tutorial-azure-monitor-stream-logs-to-event-hub","comment_id":"176710","upvote_count":"3","timestamp":"1599681600.0","poster":"Edhotp"},{"content":"the only options for exporting audit logs (diagnostic settings under monitoring) are to log analytics, storage account or event hub.\nSo event hub answer is correct and function app can be used together with event hub as a trigger.","poster":"azureexaminer","comment_id":"160482","timestamp":"1597717800.0","upvote_count":"3"},{"upvote_count":"2","poster":"James0208","timestamp":"1596837660.0","content":"I think the main reason for choosing Event Hubs than Event Grid is Event Grid isn't a data pipeline, and doesn't deliver the actual object that was updated. https://docs.microsoft.com/en-us/azure/event-grid/compare-messaging-services Given the question implies to store the user data into db, Event Hubs is correct.","comment_id":"152749"},{"poster":"Neetiniti","comment_id":"133383","upvote_count":"5","timestamp":"1594602480.0","content":"Answer-Box-1- Event Hub-https://docs.microsoft.com/en-us/azure/active-directory/reports-monitoring/tutorial-azure-monitor-stream-logs-to-event-hub \nBox-2-Azure Functions-https://docs.microsoft.com/en-us/azure/azure-functions/functions-event-hub-cosmos-db"},{"poster":"juri","content":"answer is correct, event grid do not support AAD as a source:\nhttps://docs.microsoft.com/en-us/azure/event-grid/overview#event-sources","comment_id":"124193","timestamp":"1593602160.0","upvote_count":"2"},{"poster":"Prash85","comment_id":"124094","content":"Event Hub & Azure Function...","upvote_count":"1","timestamp":"1593592740.0"},{"content":"B1:Azure Event Grid\nB2:Azure Function","upvote_count":"1","poster":"DeveshSolanki","comment_id":"120238","timestamp":"1593152640.0","comments":[{"timestamp":"1595859600.0","poster":"sourabh7257","content":"Azure Event Hub is correct","comment_id":"145040","upvote_count":"1"}]},{"poster":"philva","content":"https://docs.microsoft.com/en-us/azure/active-directory/reports-monitoring/concept-activity-logs-azure-monitor\nhttps://docs.microsoft.com/en-us/azure/azure-monitor/platform/platform-logs-overview\nSeems like eventhub is correct","timestamp":"1592792700.0","comment_id":"115976","upvote_count":"1"},{"comment_id":"103724","timestamp":"1591442160.0","upvote_count":"7","poster":"anagar","content":"Event Hub & Azure Function.\nEvent hub can be used to stream Active directory logs\n\nSign in to the Azure portal.\nSelect Azure Active Directory > Monitoring > Audit logs.\nSelect Export Settings.\nIn the Diagnostics settings pane, do either of the following: ... \nSelect the Stream to an event hub check box, and then select Event Hub/Configure."},{"poster":"Exam_Topic1","timestamp":"1589717340.0","upvote_count":"2","comment_id":"90532","content":"https://docs.microsoft.com/en-us/azure/active-directory/reports-monitoring/concept-activity-logs-azure-monitor link should assure anyone doubting the answer. Also has a video walking through the process. I was originally confused because I thought Log Analytics would need to be a part of the solution, but this issue is also clarified. The tool is now called Azure Monitor logs to prevent confusion.\n\"Integrate Azure AD activity logs with your own custom log solutions by streaming them to an event hub.\""},{"poster":"pandeya442","content":"Azure Event Grid\nAzure Function","upvote_count":"2","timestamp":"1589429520.0","comment_id":"88695"},{"timestamp":"1588271760.0","upvote_count":"2","poster":"Gorha","comment_id":"81813","content":"Answer is correct!"},{"poster":"Rajuuu","timestamp":"1588043880.0","comment_id":"80597","content":"Event Grid and Function app.","upvote_count":"2","comments":[{"upvote_count":"2","poster":"[Removed]","comment_id":"99866","content":"You mean, Event HUB and Azure Function.","timestamp":"1591004100.0"}]},{"upvote_count":"2","timestamp":"1587382620.0","content":"Answer is correct.\n\nhttps://docs.microsoft.com/en-us/azure/active-directory/reports-monitoring/tutorial-azure-monitor-stream-logs-to-event-hub","comment_id":"76935","poster":"azureh"},{"content":"Correct answers. See also https://docs.microsoft.com/en-us/azure/azure-functions/functions-event-hub-cosmos-db","poster":"Protonenpaule","comments":[{"content":"Thi is very dangerous, please verify that active directory can connect to event hub?","timestamp":"1589170140.0","poster":"JakeCallham","comment_id":"86934","upvote_count":"2"}],"upvote_count":"4","comment_id":"76860","timestamp":"1587373500.0"},{"poster":"pinchocr","content":"1. Log Analytics\n2. Evant Hubs","timestamp":"1586266680.0","comment_id":"72124","upvote_count":"3"},{"poster":"onlyfunmails","timestamp":"1578079560.0","comment_id":"35042","upvote_count":"10","content":"https://docs.microsoft.com/en-us/azure/azure-monitor/platform/platform-logs-overview\nActive directory logs can redirected to Storage account, log analytics or event hub only.\nSo, Event hub which can call a function on an event."},{"poster":"AzureGC","comment_id":"24450","content":"See the overview for event hubs, appears the answers should be: \nAzure Event Hubs; Azure Functions; \n\n\"Azure Event Hubs also integrates with Azure Functions for a serverless architecture.\" from: \nhttps://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-about","timestamp":"1574729280.0","upvote_count":"2","comments":[{"comment_id":"80594","upvote_count":"3","content":"Event Hubs are meant for huge amount of Streaming , OIT or Telemetery data .Azure Active directory does not provide that volume.","poster":"Rajuuu","timestamp":"1588043280.0"}]},{"content":"the battle is EventGrid vs EventHub. the question mentions data must be stored in 'cosmos DB'. this is the clue. EventGrid is the only one that saves in serverless, nosql and low cost. \nhttps://docs.microsoft.com/en-us/azure/event-grid/compare-messaging-services","upvote_count":"1","timestamp":"1573229340.0","poster":"powertechnet","comments":[{"upvote_count":"10","content":"No, as we have function to do job of saving data to Cosmos DB. As Source is active directory log, which can only to sent to a storage account or log workspace or an event hub.","poster":"onlyfunmails","comment_id":"35046","timestamp":"1578079800.0"}],"comment_id":"19965"},{"upvote_count":"5","timestamp":"1572682080.0","content":"Event Grid is a simple but versatile event distribution system. Use it to deliver discrete events to subscribers, which will receive those events reliably and quickly. We have one more messaging model to examine - what if we want to deliver a large stream of events? In this scenario, Event Grid isn't a great solution because it's designed for one-event-at-a-time delivery. Instead, we need to turn to another Azure service: Event Hubs.","poster":"kondapaturi","comment_id":"18786"},{"content":"https://docs.microsoft.com/en-us/azure/active-directory/reports-monitoring/tutorial-azure-monitor-stream-logs-to-event-hub","upvote_count":"4","timestamp":"1569971940.0","poster":"TK01","comment_id":"13500"},{"poster":"GB_SYD","content":"@shankar: Event Grid isn't a great solution because it's designed for one-event-at-a-time delivery. Instead, we need to turn to another Azure service: Event Hubs. The last statement of the page you referred. Events Hub is the right one.","upvote_count":"5","timestamp":"1569783540.0","comment_id":"13184"},{"poster":"RAIHAN","timestamp":"1567672440.0","comment_id":"9711","content":"wrong answer !","comments":[{"poster":"tartar","upvote_count":"7","content":"event hub\nazure function","comment_id":"182617","timestamp":"1600570440.0"}],"upvote_count":"1"}],"answer":"","answer_images":["https://www.examtopics.com/assets/media/exam-media/02744/0019600001.jpg"],"url":"https://www.examtopics.com/discussions/microsoft/view/4740-exam-az-301-topic-6-question-28-discussion/","isMC":false},{"id":"UH6tIewCsTUNf0fqmB1h","answer_images":[],"question_text":"You are developing a web application that provides streaming video to users. You configure the application to use continuous integration and deployment.\nThe app must be highly available and provide a continuous streaming experience for users.\nYou need to recommend a solution that allows the application to store data in a geographical location that is closest to the user.\nWhat should you recommend?","answers_community":[],"exam_id":51,"answer":"D","unix_timestamp":1589429580,"isMC":true,"timestamp":"2020-05-14 06:13:00","topic":"6","answer_description":"Azure Content Delivery Network (CDN) is a global CDN solution for delivering high-bandwidth content. It can be hosted in Azure or any other location. With Azure\nCDN, you can cache static objects loaded from Azure Blob storage, a web application, or any publicly accessible web server, by using the closest point of presence (POP) server. Azure CDN can also accelerate dynamic content, which cannot be cached, by leveraging various network and routing optimizations.\nReferences:\nhttps://docs.microsoft.com/en-in/azure/cdn/","answer_ET":"D","url":"https://www.examtopics.com/discussions/microsoft/view/20538-exam-az-301-topic-6-question-29-discussion/","choices":{"C":"Azure Redis Cache","D":"Azure Content Delivery Network (CDN)","B":"Azure App Service Isolated","A":"Azure App Service Web Apps"},"question_images":[],"question_id":198,"discussion":[{"upvote_count":"2","comment_id":"485571","content":"D. Azure Content Delivery Network (CDN)","timestamp":"1637723160.0","poster":"vepsa"},{"comments":[{"poster":"Ario","timestamp":"1632824340.0","upvote_count":"1","comment_id":"453277","content":"Sorry guys disregard my comment was a typo"}],"timestamp":"1632223560.0","upvote_count":"1","comment_id":"448863","poster":"Ario","content":"Correct answer is Azure Redis Cache"},{"poster":"glam","comment_id":"306470","content":"D. Azure Content Delivery Network (CDN)","upvote_count":"2","timestamp":"1615301460.0"},{"upvote_count":"1","content":"given answer is correct.","poster":"sanketshah","timestamp":"1609634700.0","comment_id":"258040"},{"content":"That's correct CDN.","poster":"sidbarker","upvote_count":"1","timestamp":"1601447700.0","comment_id":"190123"},{"upvote_count":"3","comments":[{"upvote_count":"9","comment_id":"116896","timestamp":"1592867940.0","poster":"SIDNEY1","content":"So smart!"}],"timestamp":"1589429580.0","poster":"pandeya442","comment_id":"88696","content":"given ans is correct"}]},{"id":"YwjgD9vSdivK3kuZSwXa","topic":"6","isMC":true,"discussion":[{"timestamp":"1567406700.0","comment_id":"9251","poster":"gabriion","content":"Why not GRS, which is B? They don't need to read from the secondary endpoint and RA-GRS is more expensive.","comments":[{"comments":[{"comments":[{"comments":[{"content":"B is ok","poster":"tartar","upvote_count":"5","comment_id":"182563","timestamp":"1600561560.0"}],"timestamp":"1592898780.0","poster":"FloJoe","upvote_count":"24","comment_id":"117195","content":"You are so wrong mate. 2nd replica can be \n- your data replicated in the same data center\n- your data replicated in another data center in the same region\n- your data replicated in another data center in another region\n\nThese are then the different levels which you need for your disaster strategy. If a region fails, the first two options are not helpful. \n\nGRS and RA-GRS both mean the third option. However, in GRS you would only be able to read from the fall back location once the disaster occured and first data source becomes unavailble. \n\nThe RA-GRS however, gives you a way to read from the 2nd location already which is useful in same cases but more expensive than simply GRS. \n\nHere, we do not have a requirement to read data from the 2nd location while the first is still actively working. Hence B is the cheaper option."}],"upvote_count":"2","content":"Disagree with you. Whenever a 2nd replica means always read only access","timestamp":"1590443520.0","comment_id":"95679","poster":"satgo"}],"timestamp":"1578996660.0","upvote_count":"6","comment_id":"38861","poster":"Ekramy_Elnaggar","content":"Agreee"},{"timestamp":"1586367000.0","comment_id":"72437","upvote_count":"3","poster":"Daren","content":"True. B is correct"},{"content":"true, RA-GRS is more expensive and there is no specific reason to choose it here.","timestamp":"1590892920.0","comment_id":"99102","poster":"gops84","upvote_count":"4"}],"upvote_count":"59"},{"comment_id":"38858","content":"- Ensures that application can access the data by using a REST connection >> this eliminates the SQL option .\n\n- Minimize costs >> this eliminates the RA-GRS\n\nso the correct answer is : B","timestamp":"1578996540.0","comments":[{"upvote_count":"1","content":"Why does it eliminates SQL option ?\nhttps://docs.microsoft.com/en-us/rest/api/sql/","comment_id":"88926","timestamp":"1589460480.0","poster":"Pierrick","comments":[{"content":"To my understanding, with that REST API you manage the databases (like remove a db or pause a db, etc.) But you cannot access the data of the DB instances. Hence the apps cannot access data by using REST.","comment_id":"113786","upvote_count":"2","poster":"FloJoe","timestamp":"1592556180.0"},{"content":"he built-in REST API is supported for server and database management. This means you can only perform CRUD at server or database level (e.g. creating a new database, updating some settings). You can use OData as it is supported in Azure SQL Database query.","timestamp":"1598687700.0","comment_id":"169020","upvote_count":"1","poster":"Abhiatms02"}]}],"poster":"Ekramy_Elnaggar","upvote_count":"41"},{"upvote_count":"1","comment_id":"317355","timestamp":"1616432280.0","poster":"AKumar","content":"Found no such requirement which will justify the given answer. Instead question considered to minimize the cost, thus correct and best option to choose is - \nB- tables in an Azure Storage account that uses geo-redundant storage (GRS)"},{"timestamp":"1612936920.0","upvote_count":"1","poster":"glam","comment_id":"287352","content":"B. tables in an Azure Storage account that uses geo-redundant storage (GRS)"},{"poster":"sanketshah","comment_id":"257693","upvote_count":"1","timestamp":"1609606980.0","content":"B is correct answer"},{"timestamp":"1601122620.0","poster":"solgae","upvote_count":"3","comment_id":"187646","content":"B is NOT the correct answer. GRS does NOT provide automatic failover capability - it needs to be MANUALLY triggered when region failure occurs! (There’s a reason why GRS is cheaper than RA-GRS) Because one of the requirements listed on the question asks to “ensure” application can be accessed by REST, it CANNOT have a period where the data is not accessible. Only RA-GRS can guarantee availability in that level. (If you argue the question is worded vaguely, then you would be right, but take “ensure” as “always available as much as possible”)\n\nThere are too many comments that gets hung up about “no requirement for secondary read-only copy” and the “minimize cost requirement”. Do not get tunnel visioned to a single requirement and consider ALL requirements. If the solution only meets partial requirements, it is NOT a valid solution. Consider ALL requirements, and not just a single one.\n\nThe given answer C is correct.","comments":[{"content":"There is no requirement for automatic failover, you should notice the cost factor as well. B is correct.","upvote_count":"1","comment_id":"278817","timestamp":"1611866820.0","poster":"milind8451"}]},{"upvote_count":"1","poster":"Rooh","content":"The correct answer is B","comment_id":"177451","timestamp":"1599797700.0"},{"comment_id":"153606","timestamp":"1596976860.0","content":"I believe the answer is correct. Sometimes questions add çost minimization clause to confuse and distract from the main requirement. We need to maintain that first priority is always to meet the requirement and the cheapest option given may not be correct.","upvote_count":"2","poster":"manu202020"},{"content":"given answer is correct as there is requirement for the application to access the data.","upvote_count":"1","comment_id":"151144","poster":"mackc13","timestamp":"1596627960.0"},{"comment_id":"139935","upvote_count":"2","poster":"tanito83","timestamp":"1595292000.0","content":"The correct answer is B. Please, modify it."},{"content":"We cannot read data from secondary GRS unless it fails over, so i believe RA-GRS is the correct answer\nhttps://www.skylinesacademy.com/blog/2019/7/31/azure-storage-replication","upvote_count":"3","poster":"AZViewer","timestamp":"1593378300.0","comments":[{"timestamp":"1596036960.0","content":"The specification doesn't ask for that. GRS is cheaper.","comment_id":"146617","poster":"Yannor","upvote_count":"1"}],"comment_id":"122222"},{"poster":"RBa001","upvote_count":"1","content":"The question says \"Ensure Application is able to access\" thus Option C is the correct option","timestamp":"1589469420.0","comment_id":"89011","comments":[{"poster":"yemma","content":"The application is able to access the data using the primary replica.\nThe data is replicated to the secondary and can be accessed using failover.\nGRS is cheaper then RA-GRS so the answer is GRS.","upvote_count":"4","comment_id":"92353","timestamp":"1589915880.0"}]},{"poster":"ara321","comment_id":"80429","content":"ANswer is C\nhttps://docs.microsoft.com/bs-latn-ba/azure/sql-database/sql-database-automated-backups?tabs=single-database","timestamp":"1588014300.0","upvote_count":"2"},{"poster":"Rajuuu","comments":[{"poster":"mon_k","comment_id":"85388","timestamp":"1588891740.0","upvote_count":"1","content":"Where did you see RA-GRS is cheaper than GRS??"},{"timestamp":"1591732920.0","upvote_count":"2","content":"GRS is cheaper than RA-GRS.","comment_id":"106240","poster":"TYT"}],"timestamp":"1587989340.0","upvote_count":"1","comment_id":"80293","content":"C is the correct answer. RA-GRS is the cheapest option."},{"upvote_count":"6","poster":"CipherK","timestamp":"1586129580.0","comment_id":"71627","content":"Both B and C fulfill the requirement of replicate data. But also require the minimum cost. Since GRS is cheaper than RA-GRS. Should choose B.","comments":[{"content":"It doesn't say it needs data from the second region only during failure. so the answer is right i'd assume","timestamp":"1587512160.0","comment_id":"77643","poster":"[Removed]","upvote_count":"1"}]},{"content":"Tried the pricing calculator for Un-manged Page Blobs, RA-GRS is expensive than GRS. So I think correct answer is B.","comment_id":"71612","poster":"Prabby","upvote_count":"4","timestamp":"1586126280.0"},{"comment_id":"71457","content":"Super obvious that the answer is B.","timestamp":"1586097060.0","upvote_count":"2","poster":"Daren"},{"upvote_count":"4","content":"The answer seems to be correct. Check out this\n\nWith GRS or GZRS, the data in the secondary location isn't available for read or write access unless there is a failover to the secondary region. For read access to the secondary location, configure your storage account to use read-access geo-redundant storage (RA-GRS) or read-access geo-zone-redundant storage (RA-GZRS).\n\nhttps://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy#redundancy-in-a-secondary-region","comment_id":"65710","comments":[{"content":"The question doesn't ask for read access to the secondary.","comment_id":"146619","timestamp":"1596037080.0","upvote_count":"1","poster":"Yannor"}],"poster":"blackalbum","timestamp":"1584551400.0"},{"upvote_count":"5","poster":"niki88","comment_id":"51768","timestamp":"1581961980.0","content":"C is correct \ndata is available to be read only if the customer or Microsoft initiates a failover from the primary to secondary region\nhttps://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy","comments":[{"timestamp":"1582250880.0","content":"The requirements aren't that the data be available (immediately) - just that it'd be replicated...","upvote_count":"4","comment_id":"53240","poster":"cyga75"}]},{"timestamp":"1579539240.0","content":"for me B is correct answer. \nhttps://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy-grs","comment_id":"41044","poster":"marco1","upvote_count":"1"},{"poster":"AzureGC","comments":[{"upvote_count":"10","poster":"mpknz","timestamp":"1581638520.0","content":"There is no mention of any requirement to have immediate access to the data in event of a failover and we do not know if the application would benefit from read only access to the data thus given the stated need to minimize costs I believe GRS is the better answer","comment_id":"50313"}],"timestamp":"1575322260.0","content":"RA-GRS is because of the REST API requirement, which is available all the time; GRS is only available during failover; Elastic pool is more expensive than RA-GRS","comment_id":"26089","upvote_count":"5"},{"content":"Why not \"Azure SQL elastic pool\"?\nhttps://docs.microsoft.com/en-us/azure/sql-database/sql-database-elastic-pool\nSQL Database elastic pools are a simple, cost-effective solution for managing and scaling multiple databases that have varying and unpredictable usage demands.","comment_id":"13839","upvote_count":"2","comments":[{"comment_id":"38859","upvote_count":"6","poster":"Ekramy_Elnaggar","content":"you cannot access Azure SQL DB by using REST connection , instead normal SQL connection. but you can do this with the Storage account","timestamp":"1578996600.0"}],"poster":"sparkf1","timestamp":"1570199040.0"}],"answers_community":[],"question_id":199,"answer_description":"","choices":{"A":"an Azure SQL Database elastic database pool that uses active geo-replication","C":"tables in an Azure Storage account that use read-access geo-redundant storage (RA-GR)","B":"tables in an Azure Storage account that uses geo-redundant storage (GRS)","D":"an Azure SQL database that uses active geo-replication"},"answer":"C","question_text":"You need to recommend a data storage solution that meets the following requirements:\n✑ Ensures that application can access the data by using a REST connection\nHosts 20 independent tables of varying sizes and usage patterns\n//IMG//\n\n✑ Automatically replicates the data to a second Azure region\n✑ Minimizes costs\nWhat should you recommend?","url":"https://www.examtopics.com/discussions/microsoft/view/4519-exam-az-301-topic-6-question-3-discussion/","exam_id":51,"timestamp":"2019-09-02 08:45:00","unix_timestamp":1567406700,"question_images":["https://www.examtopics.com/assets/media/exam-media/02744/0016800003.png"],"answer_ET":"C","answer_images":[]},{"id":"GcyQ7krzO6Yp3lfV71KI","question_images":["https://www.examtopics.com/assets/media/exam-media/02744/0019800001.jpg"],"question_id":200,"topic":"6","question_text":"HOTSPOT -\nYour company deploys an Azure App Service Web App.\nDuring testing the application fails under load. The application cannot handle more than 100 concurrent user sessions. You enable the Always On feature. You also configure auto-scaling to increase counts from two to 10 based on HTTP queue length.\nYou need to improve the performance of the application.\nWhich solution should you use for each application scenario? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","isMC":false,"answer_images":["https://www.examtopics.com/assets/media/exam-media/02744/0019900001.jpg"],"discussion":[{"poster":"profileexto","upvote_count":"10","content":"Given answers are correct","comment_id":"138702","timestamp":"1595165460.0"},{"upvote_count":"1","comment_id":"306472","poster":"glam","timestamp":"1615301520.0","content":"given answer are correct."},{"timestamp":"1609634700.0","poster":"sanketshah","comment_id":"258041","upvote_count":"1","content":"given answer are correct."},{"comments":[{"upvote_count":"2","comment_id":"204972","content":"for caching of frequently access data","timestamp":"1603522860.0","poster":"certmonster"}],"comment_id":"194333","content":"Why redis cache?","timestamp":"1601991060.0","poster":"David_986969","upvote_count":"1"},{"upvote_count":"1","timestamp":"1601449740.0","comment_id":"190152","poster":"sidbarker","content":"This is very good answer."}],"url":"https://www.examtopics.com/discussions/microsoft/view/26142-exam-az-301-topic-6-question-30-discussion/","answers_community":[],"unix_timestamp":1595165460,"answer_ET":"","answer":"","exam_id":51,"timestamp":"2020-07-19 15:31:00","answer_description":"Box 1: Content Delivery Network -\nA content delivery network (CDN) is a distributed network of servers that can efficiently deliver web content to users. CDNs store cached content on edge servers in point-of-presence (POP) locations that are close to end users, to minimize latency.\nAzure Content Delivery Network (CDN) offers developers a global solution for rapidly delivering high-bandwidth content to users by caching their content at strategically placed physical nodes across the world. Azure CDN can also accelerate dynamic content, which cannot be cached, by leveraging various network optimizations using CDN POPs. For example, route optimization to bypass Border Gateway Protocol (BGP).\n\nBox 2: Azure Redis Cache -\nAzure Cache for Redis is based on the popular software Redis. It is typically used as a cache to improve the performance and scalability of systems that rely heavily on backend data-stores. Performance is improved by temporarily copying frequently accessed data to fast storage located close to the application. With\nAzure Cache for Redis, this fast storage is located in-memory with Azure Cache for Redis instead of being loaded from disk by a database.\nReferences:\nhttps://docs.microsoft.com/en-us/azure/azure-cache-for-redis/cache-overview"}],"exam":{"isBeta":false,"lastUpdated":"12 Apr 2025","isImplemented":true,"provider":"Microsoft","numberOfQuestions":232,"name":"AZ-301","isMCOnly":false,"id":51},"currentPage":40},"__N_SSP":true}