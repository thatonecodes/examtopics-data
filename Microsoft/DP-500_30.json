{"pageProps":{"questions":[{"id":"ycYMmzbHFsNzyBbQzIpg","answer_images":["https://img.examtopics.com/dp-500/image79.png"],"unix_timestamp":1672823220,"question_id":146,"answer_ET":"","url":"https://www.examtopics.com/discussions/microsoft/view/93807-exam-dp-500-topic-1-question-65-discussion/","question_text":"HOTSPOT -\nYou use Advanced Editor in Power Query Editor to edit a query that references two tables named Sales and Commission.\nA sample of the data in the Sales table is shown in the following table.\n//IMG//\n\nA sample of the data in the Commission table is shown in the following table.\n//IMG//\n\nYou need to merge the tables by using Power Query Editor without losing any rows in the Sales table.\nHow should you complete the query? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\n//IMG//","answers_community":[],"topic":"1","answer_description":"","answer":"","isMC":false,"timestamp":"2023-01-04 10:07:00","question_images":["https://img.examtopics.com/dp-500/image76.png","https://img.examtopics.com/dp-500/image77.png","https://img.examtopics.com/dp-500/image78.png"],"exam_id":70,"discussion":[{"poster":"SamuComqi","upvote_count":"3","comment_id":"984976","timestamp":"1692422100.0","content":"I took the exam a few days ago (14/8/2023) and I passed the exam with a score of 915.\nMy answer was:\n- Join\n- LeftOuter"},{"timestamp":"1687777080.0","comment_id":"934320","content":"Join\nLeftOuter","upvote_count":"1","poster":"Eltooth"},{"upvote_count":"1","comment_id":"859745","timestamp":"1680513780.0","content":"in Power Q is joinNested and leftouter \nhttps://learn.microsoft.com/en-us/power-query/merge-queries-left-anti\nhttps://learn.microsoft.com/en-us/power-query/merge-queries-left-outer","poster":"DarioReymago"},{"timestamp":"1674464760.0","content":"Considering that Left.Outer per definition keeps all the rows in the \"left\" table, here Sales, the answer is definetly correct","poster":"stfglv","upvote_count":"2","comment_id":"785159"},{"timestamp":"1673370060.0","comment_id":"771633","content":"Just created two tables same data and combine them in Power BI, join and leftouter is correct.","upvote_count":"3","poster":"moreinva43"},{"upvote_count":"3","comment_id":"765416","timestamp":"1672823220.0","poster":"AshwinN1992","content":"Is this correct"}]},{"id":"6UmfINRCEgpRawrONvjN","discussion":[{"comment_id":"984977","content":"I took the exam a few days ago (14/8/2023) and I passed the exam with a score of 915.\nMy answer was:\n- Denormalize the tables in DB1","upvote_count":"1","timestamp":"1692422100.0","poster":"SamuComqi"},{"comment_id":"934721","upvote_count":"3","timestamp":"1687805280.0","content":"Selected Answer: D\nD(enormalize)","poster":"Plb2"},{"content":"Selected Answer: D\nI think D is correct","timestamp":"1680515100.0","poster":"DarioReymago","comment_id":"859768","upvote_count":"2"},{"upvote_count":"1","timestamp":"1674084300.0","comment_id":"780524","poster":"cookiemonster42","comments":[{"comment_id":"792600","upvote_count":"1","timestamp":"1675070820.0","poster":"stfglv","content":"no because \"DB1 is a transactional database in the third normal form\" --> the last part of the sentence means that it is already normalized."},{"poster":"per_ing","content":"Denormalized tables are quicker to read than normalized, so I believe this is correct https://medium.com/@innerbit/when-and-how-you-should-denormalize-a-relational-database-75047344ebac","comment_id":"783147","timestamp":"1674294420.0","upvote_count":"4"},{"poster":"salvalcaraz","upvote_count":"1","timestamp":"1702815480.0","content":"A query performs faster in a big denormalized table.\nNormalized databases requires more joins, which are expensive query processes.","comment_id":"1098879"}],"content":"shouldn't it be B, because long tables are taking longer to process?"}],"answer_description":"","choices":{"D":"Denormalize the tables in DB1.","B":"Normalize the tables in DB1.","C":"Create calculated columns in Dataset1.","A":"Remove the relationships from Dataset1."},"answers_community":["D (100%)"],"question_text":"You have a Power BI dataset named Dataset1 that uses DirectQuery against an Azure SQL database named DB1.\nDB1 is a transactional database in the third normal form.\nYou need to recommend a solution to minimize how long it takes to execute the query. The solution must maintain the current functionality.\nWhat should you include in the recommendation?","question_id":147,"answer_images":[],"topic":"1","timestamp":"2023-01-19 00:25:00","exam_id":70,"question_images":[],"isMC":true,"unix_timestamp":1674084300,"answer":"D","answer_ET":"D","url":"https://www.examtopics.com/discussions/microsoft/view/95911-exam-dp-500-topic-1-question-66-discussion/"},{"id":"iVbCtDkk9zlGlSCLeKBQ","exam_id":70,"answer_images":[],"answer_description":"","question_images":[],"answer":"A","question_text":"You have a file named File1.txt that has the following characteristics:\n\nA header row -\n\nTab delimited values -\n\nUNIX-style line endings -\nYou need to read File1.txt by using an Azure Synapse Analytics serverless SQL pool.\nWhich query should you execute?","answer_ET":"A","discussion":[{"timestamp":"1672309380.0","comment_id":"760873","upvote_count":"6","content":"Selected Answer: A\nRef: https://learn.microsoft.com/en-us/azure/synapse-analytics/sql/query-single-csv-file","poster":"Maazi"},{"content":"Selected Answer: A\na is correct","timestamp":"1680515340.0","comment_id":"859774","poster":"DarioReymago","upvote_count":"1"},{"comments":[{"upvote_count":"1","timestamp":"1680588480.0","poster":"solref","comment_id":"860697","content":"CHAT GPT :\nBased on the characteristics of the File1.txt, the correct query to read the file using an Azure Synapse Analytics serverless SQL pool is: D\n\nExplanation:\nThe file has a header row, so it's important to specify that the first row is not a header row in the query by setting FIRSTROW=1.\nThe file is tab-delimited, so FIELDTERMINATOR should be set to '\\t'.\nThe file has UNIX-style line endings, so ROWTERMINATOR should be set to '0x0a'.\nThe FORMAT option should be set to 'CSV', even though it is not strictly a CSV file because it is tab-delimited. This is because CSV format can handle tab-delimited files as well.\nOptions A, B, and C are not correct because they have incorrect field terminators or row terminators, or they do not specify that the first row is a header row."}],"upvote_count":"2","content":"Selected Answer: A\nChat GPT:\nBased on the characteristics of the File1.txt, the correct query to execute in Azure Synapse Analytics serverless SQL pool is option A.\nThis query uses the OPENROWSET function to read a CSV file, which is specified by the BULK option. The FIELDTERMINATOR is set to a tab character (\\t), and the ROWTERMINATOR is set to the UNIX-style line ending (0x0a). The FIRSTROW option is set to 2 to skip the header row. Option B uses a comma as the field terminator, which does not match the tab-delimited format of the file. Option C uses a comma as the field terminator and the UNIX-style line ending as the row terminator, which does not match the characteristics of the file. Option D sets the FIRSTROW option to 1, which would include the header row in the result set.\nSo, A.","comment_id":"856580","poster":"Az301301X","timestamp":"1680235260.0"},{"upvote_count":"1","comment_id":"795672","content":"It's C, open AI confirmed it :)","poster":"cookiemonster42","timestamp":"1675302060.0"},{"timestamp":"1674466380.0","content":"This part of the A solution is the key and makes all other solutions incorrect (t for tab): FIELDTERMINATOR = ‘\\t'","comments":[{"content":"....and FIRSTROW= 2, because the Headers.","upvote_count":"2","comment_id":"786235","timestamp":"1674543420.0","poster":"Az301301X"},{"comment_id":"852171","timestamp":"1679925180.0","upvote_count":"1","content":"You are right \nTerminating character Tab = '\\t'\nNewline character = '\\n'\n\n\nhttps://learn.microsoft.com/en-us/sql/relational-databases/import-export/specify-field-and-row-terminators-sql-server?view=sql-server-ver16","poster":"solref"},{"content":"Option D contains FIELDTERMINATOR = ‘\\t' as well FYI.","timestamp":"1682503620.0","poster":"sgodd_0298","comment_id":"881421","upvote_count":"1"}],"comment_id":"785181","upvote_count":"4","poster":"stfglv"},{"poster":"moreinva43","comment_id":"766932","timestamp":"1672943160.0","upvote_count":"1","content":"that website makes it look like the answer is c with the same field terminator and row terminator."}],"url":"https://www.examtopics.com/discussions/microsoft/view/93148-exam-dp-500-topic-1-question-67-discussion/","topic":"1","answers_community":["A (100%)"],"unix_timestamp":1672309380,"timestamp":"2022-12-29 11:23:00","isMC":true,"question_id":148,"choices":{"A":"SELECT*\nFROM OPENROWSET(\nBULK ‘file1.txt’,\nDATA_SOURCE = ‘Sql1’,\nFORMAT = ‘CSV’, PARSER_VERSION = ‘2.0’,\nFIELDTERMINATOR = ‘\\t’,\nROWTERMINATOR = ‘0x0a’,\n\nFIRSTROW= 2 -\n)","D":"SELECT*\nFROM OPENROWSET(\nBULK ‘file1.txt’,\nDATA_SOURCE = ‘Sql1’,\nFORMAT = ‘CSV’, PARSER_VERSION = ‘2.0’,\nFIELDTERMINATOR = ‘\\t’,\nROWTERMINATOR = ‘0x0a’,\n\nFIRSTROW= 1 -\n)","C":"SELECT*\nFROM OPENROWSET(\nBULK ‘file1.txt’,\nDATA_SOURCE = ‘Sql1’,\nFORMAT = ‘CSV’, PARSER_VERSION = ‘2.0’,\nFIELDTERMINATOR = ‘,’,\nROWTERMINATOR = ‘0x0a’,\n\nFIRSTROW= 2 -\n)","B":"SELECT*\nFROM OPENROWSET(\nBULK ‘file1.txt’,\nDATA_SOURCE = ‘Sql1’,\nFORMAT = ‘CSV’, PARSER_VERSION = ‘2.0’,\nFIELDTERMINATOR = ‘,’,\nROWTERMINATOR = ‘\\n’,\n\nFIRSTROW= 2 -\n)"}},{"id":"LqGK0vegURhoqSQqYqf1","answers_community":[],"unix_timestamp":1670768580,"answer_description":"","answer_ET":"","isMC":false,"topic":"1","answer_images":["https://img.examtopics.com/dp-500/image83.png"],"question_id":149,"answer":"","timestamp":"2022-12-11 15:23:00","exam_id":70,"question_text":"HOTSPOT -\nYou have a Power BI dataset that has the query dependencies shown in the following exhibit.\n//IMG//\n\nUse the drop-down menus to select the answer choice that completes each statement based on the information presented in the graphic.\nNOTE: Each correct selection is worth one point.\n//IMG//","url":"https://www.examtopics.com/discussions/microsoft/view/91018-exam-dp-500-topic-1-question-68-discussion/","discussion":[{"poster":"Arnaudvdc1981","timestamp":"1670919960.0","content":"Orders query is executed 3 times but creating a dataflow will reduce data refresh times, not the table.buffer\nhttps://learn.microsoft.com/en-us/power-bi/guidance/power-query-referenced-queries","comment_id":"743746","upvote_count":"18"},{"timestamp":"1671644280.0","poster":"6688Wj","upvote_count":"10","content":"3 and Dataflow","comment_id":"752611"},{"content":"I took the exam a few days ago (14/8/2023) and I passed the exam with a score of 915.\nMy answer was:\n- 3\n- Replacing the Orders query with a dataflow","upvote_count":"4","comment_id":"984979","poster":"SamuComqi","timestamp":"1692422160.0"},{"poster":"Eltooth","comment_id":"934644","content":"3\nDataflow","timestamp":"1687798140.0","upvote_count":"2"},{"upvote_count":"7","comment_id":"763571","timestamp":"1672644120.0","content":"3 and Dataflow.\n\nWhen the data model is refreshed, it's often assumed that Power Query retrieves the Query1 result, and that it's reused by referenced queries. This thinking is incorrect. In fact, Power Query executes Query2, Query3, and Query4 separately. Query1 is executed three times. The multiple executions can result in slow data refresh, and negatively impact on the data source.\n\nThe use of the Table.Buffer function in Query1 won't eliminate the additional data retrieval. We recommend you create a dataflow instead. Using a dataflow can improve data refresh time, and reduce impact on your data sources.\n\nSource: https://learn.microsoft.com/en-us/power-bi/guidance/power-query-referenced-queries","poster":"cherious"},{"timestamp":"1670768580.0","upvote_count":"2","content":"should be 0","comment_id":"741780","comments":[{"poster":"JasonVu","timestamp":"1670768820.0","content":"*3*. Did not see the reference query","comment_id":"741782","upvote_count":"4"}],"poster":"JasonVu"}],"question_images":["https://img.examtopics.com/dp-500/image81.png","https://img.examtopics.com/dp-500/image82.png"]},{"id":"4nI1sGCTXVPKksHNubdE","question_id":150,"question_images":[],"timestamp":"2023-01-06 21:09:00","exam_id":70,"unix_timestamp":1673035740,"answer_description":"","choices":{"D":"Apache Parquet","B":"Delta","A":"CSV","C":"JSON"},"url":"https://www.examtopics.com/discussions/microsoft/view/94226-exam-dp-500-topic-1-question-69-discussion/","answer_images":[],"discussion":[{"poster":"Qordata","upvote_count":"1","comment_id":"1023615","timestamp":"1696309620.0","content":"D is correct \nReference: https://learn.microsoft.com/en-us/azure/synapse-analytics/sql/best-practices-serverless-sql-pool#prepare-files-for-querying"},{"upvote_count":"1","poster":"SamuComqi","content":"Selected Answer: D\nI took the exam a few days ago (14/8/2023) and I passed the exam with a score of 915.\nMy answer was:\n Apache Parquet","timestamp":"1692422160.0","comment_id":"984981"},{"timestamp":"1681631340.0","comment_id":"871571","content":"From Chatgpt:\nBy using Apache Parquet format for the external table, you can minimize the query execution time for serverless SQL pools in Azure Synapse Analytics because:\n\nColumnar storage: Apache Parquet stores data in a columnar format, which allows for highly efficient and fast data access. This means that queries against the external table can be executed faster because only the relevant columns are read.\n\nCompression: Apache Parquet uses a highly efficient compression algorithm, which reduces the size of the data on disk. Smaller data size means less data to transfer, which results in faster query execution time.\n\nPartitioning: Apache Parquet supports partitioning, which allows you to subdivide the external table into smaller, more manageable files. When querying the table, only the relevant partitions are scanned, which makes query execution faster.\n\nOverall, by using Apache Parquet for the external table, you can significantly reduce the amount of time it takes for a serverless SQL pool to execute a query against the table, making it a more performant solution for analyzing large datasets.","upvote_count":"1","poster":"Albeeliu"},{"comment_id":"832802","timestamp":"1678270320.0","upvote_count":"2","content":"Selected Answer: D\nWell, this link doesn't give the answer directly, but MS indirectly states that you should use Apache Parquet files for your SQL serverless pool.\n\nhttps://learn.microsoft.com/en-us/azure/synapse-analytics/get-started-analyze-sql-on-demand","poster":"Hongzu13"},{"comment_id":"768050","content":"Selected Answer: D\nD is correct","timestamp":"1673035740.0","poster":"louisaok","upvote_count":"3"}],"topic":"1","answer":"D","answers_community":["D (100%)"],"question_text":"You are creating an external table by using an Apache Spark pool in Azure Synapse Analytics. The table will contain more than 20 million rows partitioned by date. The table will be shared with the SQL engines.\nYou need to minimize how long it takes for a serverless SQL pool to execute a query data against the table.\nIn which file format should you recommend storing the table data?","isMC":true,"answer_ET":"D"}],"exam":{"lastUpdated":"12 Apr 2025","isImplemented":true,"provider":"Microsoft","isMCOnly":false,"id":70,"numberOfQuestions":183,"isBeta":false,"name":"DP-500"},"currentPage":30},"__N_SSP":true}