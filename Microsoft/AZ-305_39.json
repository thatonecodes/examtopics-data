{"pageProps":{"questions":[{"id":"XeQ1nR8lsVj0itQ56ZBS","url":"https://www.examtopics.com/discussions/microsoft/view/81586-exam-az-305-topic-4-question-27-discussion/","answer_description":"Box 1: Install a self-hosted integration runtime.\nIf your data store is located inside an on-premises network, an Azure virtual network, or Amazon Virtual Private Cloud, you need to configure a self-hosted integration runtime to connect to it.\nThe Integration Runtime to be used to connect to the data store. You can use Azure Integration Runtime or Self-hosted Integration Runtime (if your data store is located in private network). If not specified, it uses the default Azure Integration Runtime.\nBox 2: Create a pipeline.\nYou perform the Copy activity with a pipeline.\nReference:\nhttps://docs.microsoft.com/en-us/azure/data-factory/connector-file-system","topic":"4","answer_ET":"","unix_timestamp":1662841740,"answer_images":["https://www.examtopics.com/assets/media/exam-media/04224/0021100002.png"],"discussion":[{"comment_id":"673797","timestamp":"1663649400.0","upvote_count":"19","content":"Correct\nhttps://learn.microsoft.com/en-us/azure/data-factory/connector-file-system?tabs=data-factory","poster":"jellybiscuit"},{"upvote_count":"11","comment_id":"867452","content":"Correct. \n\no copy the data from Server1 to Azure Storage using Azure Data Factory, you should do the following next:\n\n1. From Server1: b. Install a self-hosted integration runtime\nA self-hosted integration runtime needs to be installed on Server1 to enable secure communication between the on-premises network and Azure Data Factory. This runtime allows Data Factory to access and copy data from the on-premises file server to Azure Storage.\n\n2. From the data factory: a. Create a pipeline\nIn the Azure Data Factory, create a pipeline that specifies the source (on-premises file server) and destination (Azure Storage). The pipeline will use the self-hosted integration runtime to establish a connection to the on-premises file server and transfer the data to Azure Storage.","timestamp":"1681227060.0","poster":"NotMeAnyWay"},{"timestamp":"1731507960.0","poster":"[Removed]","content":"CORRECT","upvote_count":"1","comment_id":"1311358"},{"timestamp":"1713488040.0","upvote_count":"1","poster":"Lazylinux","content":"Given answer is correct as per \nhttps://learn.microsoft.com/en-us/azure/data-factory/connector-file-system?tabs=data-factory","comment_id":"1198251"},{"poster":"OPT_001122","timestamp":"1675170060.0","comment_id":"794177","upvote_count":"4","content":"Box 1: Install a self-hosted integration runtime.\nBox 2: Create a pipeline."},{"poster":"FabrityDev","content":"As described in link below, you have to install self hosted integration runtime on the Server and create a Pipeline in Data Factory.\n\nhttps://www.sqlshack.com/copy-data-from-on-premises-data-store-to-an-azure-data-store-using-azure-data-factory/","upvote_count":"1","comment_id":"777904","timestamp":"1673884860.0"},{"poster":"GarryK","timestamp":"1662841740.0","content":"https://docs.microsoft.com/en-us/azure/data-factory/data-migration-guidance-hdfs-azure-storage\nou must install the Data Factory self-hosted integration runtime on a Windows VM in your Azure virtual network.\nhttps://docs.microsoft.com/en-us/azure/data-factory/concepts-pipelines-activities?tabs=data-factory\nA Data Factory or Synapse Workspace can have one or more pipelines. A pipeline is a logical grouping of activities that together perform a task. For example, a pipeline could contain a set of activities that ingest and clean log data, and then kick off a mapping data flow to analyze the log data.","comment_id":"665665","upvote_count":"6"}],"question_text":"HOTSPOT -\nYour on-premises network contains a file server named Server1 that stores 500 GB of data.\nYou need to use Azure Data Factory to copy the data from Server1 to Azure Storage.\nYou add a new data factory.\nWhat should you do next? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","answer":"","answers_community":[],"timestamp":"2022-09-10 22:29:00","isMC":false,"question_id":191,"question_images":["https://www.examtopics.com/assets/media/exam-media/04224/0021100001.png"],"exam_id":54},{"id":"qTOl7dNGqLemMY09xqrM","answer_description":"","timestamp":"2022-09-12 08:04:00","choices":{"B":"cluster autoscaler","D":"Virtual Kubelet","C":"virtual nodes","A":"horizontal pod autoscaler"},"isMC":true,"answer_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/81749-exam-az-305-topic-4-question-28-discussion/","question_images":[],"answer":"C","unix_timestamp":1662962640,"exam_id":54,"question_id":192,"discussion":[{"poster":"OPT_001122","upvote_count":"72","comments":[{"upvote_count":"6","timestamp":"1693403700.0","comment_id":"994181","poster":"TinoTen","content":"Thank you OPT_001122 Sensei"}],"comment_id":"801169","timestamp":"1675790100.0","content":"Selected Answer: C\ncluster autoscaler for windows\nVirtual Nodes for Linux"},{"poster":"NotMeAnyWay","content":"Selected Answer: C\nC. virtual nodes\n\nTo meet the requirements of minimizing the time it takes to provision compute resources during scale-out operations, supporting autoscaling of Linux containers, and minimizing administrative effort, you should recommend virtual nodes for the Azure Kubernetes Service (AKS) solution with Linux nodes.\n\nVirtual nodes allow you to scale your AKS cluster quickly by offloading the additional compute resources to Azure Container Instances (ACI). This reduces the time it takes to provision resources during scale-out operations, as the resources can be provisioned instantly without having to wait for a new node to be created. Additionally, virtual nodes support autoscaling of Linux containers and require minimal administrative effort compared to other scaling options.","upvote_count":"6","comment_id":"867454","timestamp":"1681227300.0"},{"comment_id":"1311361","upvote_count":"2","content":"Selected Answer: C\nC is correct","poster":"[Removed]","timestamp":"1731508140.0"},{"content":"Selected Answer: C\nGiven answer C is correct as per \no rapidly scale application workloads in an AKS cluster, you can use virtual nodes. With virtual nodes, you have quick provisioning of pods, and only pay per second for their execution time. You don't need to wait for Kubernetes cluster autoscaler to deploy VM compute nodes to run more pods. Virtual nodes are only supported with Linux pods and nodes.\nhttps://learn.microsoft.com/en-us/azure/aks/virtual-nodes","timestamp":"1713488760.0","poster":"Lazylinux","upvote_count":"3","comment_id":"1198258"},{"comment_id":"796744","poster":"VBK8579","timestamp":"1675400520.0","upvote_count":"1","content":"Selected Answer: C\nTo minimize the time it takes to provision compute resources during scale-out operations in an AKS cluster with Linux nodes, the recommended scaling option would be Virtual Nodes. Virtual Nodes allow the AKS cluster to use Azure Container Instances (ACI) as worker nodes, which can be quickly and easily provisioned, enabling faster scaling compared to traditional AKS worker nodes."},{"timestamp":"1675170180.0","poster":"OPT_001122","upvote_count":"2","comment_id":"794181","content":"Selected Answer: C\nTo rapidly scale application workloads in an AKS cluster, you can use virtual nodes."},{"timestamp":"1673186460.0","upvote_count":"1","poster":"[Removed]","comment_id":"769489","content":"Selected Answer: C\nVirtual Nodes"},{"content":"Selected Answer: C\nhttps://learn.microsoft.com/en-us/azure/aks/virtual-nodes\nThe virtual nodes add-on for AKS, is based on the open source project Virtual Kubelet.\n\nSo if you need to scale out faster than AKS let you, you need to burst to ACI.","timestamp":"1666283100.0","upvote_count":"1","poster":"simonseztech","comment_id":"700119"},{"comment_id":"673806","upvote_count":"3","content":"Selected Answer: C\nC - because \"virtual node\" is the name of the Microsoft \"product\". \nIn short, it connects kubernetes management to ACI containers.\nThat said... it uses Virtual Kubelet technology, and probably horizontal pod autoscaler to scale.","timestamp":"1663650240.0","poster":"jellybiscuit"},{"poster":"S_883","comment_id":"671929","timestamp":"1663465620.0","upvote_count":"3","content":"Selected Answer: C\nhttps://docs.microsoft.com/en-us/azure/aks/virtual-nodes\nit should be C then?"},{"content":"I believe Kay000001 meant C, virtual nodes\n\nTo rapidly scale application workloads in an AKS cluster, you can use virtual nodes. With virtual nodes, you have quick provisioning of pods, and only pay per second for their execution time. You don't need to wait for Kubernetes cluster autoscaler to deploy VM compute nodes to run the additional pods. Virtual nodes are only supported with Linux pods and nodes.","upvote_count":"4","poster":"scottims","comment_id":"667275","timestamp":"1663003320.0"},{"timestamp":"1662962640.0","content":"Selected Answer: B\nB.\nhttps://docs.microsoft.com/en-us/azure/aks/virtual-nodes","upvote_count":"3","poster":"kay000001","comment_id":"666632"}],"answers_community":["C (97%)","3%"],"question_text":"You have an Azure subscription.\nYou need to recommend an Azure Kubernetes Service (AKS) solution that will use Linux nodes. The solution must meet the following requirements:\n✑ Minimize the time it takes to provision compute resources during scale-out operations.\n✑ Support autoscaling of Linux containers.\n✑ Minimize administrative effort.\nWhich scaling option should you recommend?","answer_ET":"C","topic":"4"},{"id":"0yLZwy1qORjNXaVCFUKj","question_images":["https://www.examtopics.com/assets/media/exam-media/04224/0021300001.png"],"topic":"4","answer_ET":"B","question_id":193,"answer_description":"","answers_community":["B (58%)","A (40%)","3%"],"unix_timestamp":1662513780,"isMC":true,"choices":{"D":"an Azure Event Hubs capture","B":"an Azure Data Factory pipeline","A":"an Azure Service Bus queue","C":"an Azure Event Grid domain"},"exam_id":54,"discussion":[{"comment_id":"696746","timestamp":"1665973800.0","content":"Selected Answer: B\nThe given answer is correct.\nADF pipeline can process the message and trigger the appropriate condition. On ADF, you can add a diagnostic setting to send logs to a storage account. \nOther possible options would be Event grid subscription & Service bus topic.\n\nService bus TOPIC can be used with filtering rules on each subscription but not queue. \nhttps://learn.microsoft.com/en-us/azure/service-bus-messaging/service-bus-queues-topics-subscriptions#rules-and-actions","poster":"Samko635","upvote_count":"46"},{"upvote_count":"35","comments":[{"poster":"Snownoodles","content":"Sorry, after reading the following link, I think the correct answer should be B\nPlease note the question is asking to implement \"An integration component will process the message\". Service Bus definitely is unable to process the message, it's just a message queue.\nADF has a \"control activity\" which is like IF---Then flow\nhttps://learn.microsoft.com/en-us/azure/data-factory/control-flow-if-condition-activity","comment_id":"702522","upvote_count":"47","timestamp":"1666566600.0"}],"content":"Selected Answer: A\nOption A looks correct to me: an Azure Service Bus queue\nADF pipeline is for data ETL/movement only","timestamp":"1662513780.0","poster":"Snownoodles","comment_id":"661812"},{"upvote_count":"1","content":"Selected Answer: A\nRegardless of how easily ADF pipelines can handle a single use case, from arch perspective, it cannot be a solution. ETL / data transformation pipelines are designed for batch processing with large amounts of data rather than high numbers of messages. A successful ordering app could easily exceed its concurrency max capacity... On the other hand, it will be much pricier. \nOn the other hand, this is a classical use case for event driven architectures, service bus is designed for these use cases.","poster":"ahhatem","comment_id":"1410793","timestamp":"1743064980.0"},{"comment_id":"1400362","content":"Selected Answer: A\nService Bus is a fully managed enterprise message broker with message queues and publish-subscribe topics. The service is intended for enterprise applications that require transactions, ordering, duplicate detection, and instantaneous consistency.\n\nhttps://learn.microsoft.com/en-us/azure/service-bus-messaging/compare-messaging-services","poster":"424ede1","upvote_count":"1","timestamp":"1742348640.0"},{"content":"Selected Answer: A\nData Factory is an ETL/ELT tool, not a messaging system. Hence, “an Azure Service Bus queue” is the most appropriate. - o1","comment_id":"1364447","upvote_count":"3","poster":"lelima","timestamp":"1741013340.0"},{"upvote_count":"2","content":"Selected Answer: A\nService Bus Queue makes the most sense given the scenario.","timestamp":"1740431820.0","poster":"RickJamez","comment_id":"1361186"},{"upvote_count":"2","comment_id":"1351078","poster":"7f3f6bd","content":"Selected Answer: A\n\"Message processing and triggering functions (Function1 or Function2)\"\n\nEvent-driven workflow → Service Bus queues are built for message-based integrations.\nEnsures reliable message delivery, including retries, ordering, and dead-lettering.\n\"Checking product availability at vendor 1 and vendor 2\"\n\nRequires request-response messaging, best handled by Azure Service Bus (queue or topic).\nService Bus ensures that each message is processed once and reliably.\n\"Transaction steps are logged to storage\"\n\nService Bus supports transactional processing, ensuring all steps are logged correctly.","timestamp":"1738604760.0"},{"content":"Selected Answer: A\nService Bus Queue is build to hand this use case. It is a message handling service. You need to have a guarantee and low latency for order processing systems. Data Factory use case is ETL.","upvote_count":"1","comment_id":"1329675","poster":"jbnkb","timestamp":"1734725880.0"},{"upvote_count":"2","timestamp":"1731508320.0","content":"Selected Answer: B\nB is correct","comment_id":"1311363","poster":"[Removed]"},{"timestamp":"1729356180.0","content":"I go for service bus queue, since ADF is typically used for batch processing and scheduled workflows, not for handling individual messages or event-driven architectures.","comment_id":"1300089","poster":"cosmicT73","upvote_count":"2"},{"comment_id":"1260529","poster":"cr0bar","content":"The key bit for me on this one is “An integration component will process the message, and then trigger either Function1 or Function2 depending on the type of order.”.\n\nWe’re being asked to name the integration component. Since service bus will only queue the data and not trigger functions, it has to be Azure Data Factory.","upvote_count":"2","timestamp":"1722750000.0"},{"comment_id":"1180847","content":"The answer should be C\nhttps://learn.microsoft.com/en-us/azure/event-grid/overview#receive-events-from-your-applications","poster":"BlackJackVll","timestamp":"1711196640.0","upvote_count":"2"},{"upvote_count":"1","timestamp":"1710612240.0","comment_id":"1175175","poster":"rishisoft1","content":"The question is just asking about Integration component, so ADF is integration that calls function1 & 2."},{"content":"Selected Answer: A\nAzure Service Bus Queue is specifically designed for asynchronous communication and queuing messages.on the other hand, are better suited for orchestration tasks involving data movement and transformation at scale. They are not designed for real-time message processing like the one required in this scenario.","timestamp":"1710346200.0","comment_id":"1172713","upvote_count":"2","poster":"Frank_2022"},{"poster":"Sriramps","comment_id":"1131667","content":"Azure service bus queue - decoupling components \nAzure data factory pipeline - integrating components....\nSo answer is B","timestamp":"1706186520.0","upvote_count":"4"},{"timestamp":"1703202360.0","comment_id":"1103041","upvote_count":"1","poster":"azim1","content":"Selected Answer: A\nBoth service bus and adf pipeline can be used, however, service bus seems to be more optimized for this workflow."},{"comment_id":"1074467","content":"key word was integration service.","poster":"PMPft17","comments":[{"upvote_count":"3","poster":"xRiot007","content":"Anything can be an integration service, so I wouldn't say it's a keyword","timestamp":"1708433340.0","comment_id":"1154711"}],"upvote_count":"1","timestamp":"1700373120.0"},{"upvote_count":"3","poster":"husam421","content":"Selected Answer: B\nhttps://learn.microsoft.com/en-us/azure/service-bus-messaging/service-bus-queues-topics-subscriptions#rules-and-actions","comment_id":"1018757","timestamp":"1695814440.0"},{"timestamp":"1695648000.0","comment_id":"1016818","poster":"joesatriani","content":"Selected Answer: B\nB is right answer.","upvote_count":"3"},{"comment_id":"1005704","timestamp":"1694519580.0","content":"Selected Answer: C\nCannot be service bus queue since it is required to trigger a function based on the message generated. Azure service bus topics would make sense.\nEvent grid offers pub/sub with the domains.\nADF it's a mistery for me","poster":"Red0101","upvote_count":"2"},{"poster":"jojorabbit2021","timestamp":"1692151980.0","content":"Selected Answer: B\nB is correct","upvote_count":"3","comment_id":"982120"},{"content":"I believe it is Event Grid because it matches all criteria and is simple that ADF for this scenario","comment_id":"981068","timestamp":"1692042300.0","poster":"Raj70","upvote_count":"1"},{"content":"Selected Answer: A\nA. An Azure Service Bus queue is the recommended resource for the integration component in this transaction flow. An Azure Service Bus queue provides reliable message delivery between different parts of a distributed system. In this transaction flow, the integration component can use an Azure Service Bus queue to receive messages from App1 and trigger either Function1 or Function2 depending on the type of order. Once a vendor confirms the product availability, a status message can be generated and sent to App1 via the same queue. Additionally, all the steps of the transaction can be logged to storage1 using a separate process.","comment_id":"887099","poster":"lombri","timestamp":"1683011880.0","upvote_count":"3"},{"poster":"NotMeAnyWay","comments":[{"comments":[{"comment_id":"995309","content":"To add: An e-commerce site can use Azure Service Bus to process an order, Azure Event Hubs to capture site telemetry, and Azure Event Grid to respond to events like an item being shipped. Thus, Azure Data Factory is the best solution to coordinate all the requested activities.","poster":"memo454","upvote_count":"2","timestamp":"1693501080.0"}],"comment_id":"988261","upvote_count":"1","content":"Azure Data Factory is used to orchestrate and coordinate activities, including invoking functions based on conditions and the workflow described needs to decide which function to invoke based on the type of order so adf is a betther solution. The answer is b","timestamp":"1692791640.0","poster":"sieira"}],"comment_id":"867467","upvote_count":"5","content":"Selected Answer: A\nA. an Azure Service Bus queue\n\nIn this scenario, the integration component should be an Azure Service Bus queue. Service Bus queues are a suitable choice for processing messages between App1 and the Azure Functions (Function1 and Function2) in a reliable and efficient manner. They enable communication in a decoupled manner, allowing for better scalability and resilience. Additionally, Service Bus queues support message ordering, duplicate detection, and can handle multiple consumers, making it a good fit for the described order processing system.\n\nAzure Data Factory is primarily designed for data integration, orchestration, and movement scenarios, such as ETL (Extract, Transform, Load) processes, rather than for real-time message processing and triggering functions based on message content.","timestamp":"1681228920.0"},{"poster":"AzureMasterChamp","timestamp":"1679753100.0","comments":[{"poster":"obllew","comment_id":"961822","upvote_count":"1","timestamp":"1690216740.0","content":"One Event Grid domain can contain 2 topics, and so have separate bindings to Function1 and Function2, so maybe"},{"content":"https://learn.microsoft.com/en-us/azure/event-grid/event-domains","poster":"AzureMasterChamp","comment_id":"850183","upvote_count":"1","timestamp":"1679753220.0"}],"upvote_count":"3","content":"We need pub-sub here, I think correct answer should be Azure Event Grid Domain. \nAzure service Bus Queue will not help, for pub-sub we need Azure Service Bus Topic.","comment_id":"850179"},{"comment_id":"845855","upvote_count":"5","comments":[{"comment_id":"1103979","timestamp":"1703327820.0","upvote_count":"1","content":"You're wrong. https://learn.microsoft.com/en-us/azure/azure-functions/functions-bindings-service-bus?tabs=isolated-process%2Cextensionv5%2Cextensionv3&pivots=programming-language-csharp","poster":"trferreiraBR"}],"poster":"steel72","timestamp":"1679398140.0","content":"Selected Answer: B\nCorrect answer is \"Azure Data Factory\".\nService Bus Queues do not support one-to-many, only Service Bus Topics do."},{"comment_id":"845374","upvote_count":"4","content":"Selected Answer: B\n\"messages\" so not C or D. \n\"will process the message\" so not A. \nB.","timestamp":"1679357160.0","poster":"curtmcgirt"},{"content":"Selected Answer: B\nSelected answer: B","poster":"equipowindows","comment_id":"821719","upvote_count":"2","timestamp":"1677348300.0"},{"content":"Selected answer: B\nAll the steps of the transaction will be logged to storage1. So ADF could create a data pipeline out of messages in storage account, then trigger Function1 and Function2.","comment_id":"813436","poster":"Rams_84zO6n","upvote_count":"1","timestamp":"1676748180.0"},{"comment_id":"809260","comments":[{"comment_id":"809262","upvote_count":"4","poster":"_fvt","content":"As we are talking of messages, I would choose Azure Service Bus, the real world answer should be this, but ASB with queue which is specified only allows one consumer, we need use Azure Service Bus topics instead... so not sure it's the right choice (https://learn.microsoft.com/en-us/azure/service-bus-messaging/service-bus-queues-topics-subscriptions).\n\nWithin event grid domain (answer C) we can define topic to trigger our functions but getting the event with the orderType content of the app service message is not easily feasible as event grid purpose is not to deal with messages data (same for Event hub, so discarding answer D also).\nhttps://learn.microsoft.com/en-us/azure/event-grid/includes/media/event-grid-domain-example-use-case/contoso-construction-example.png#lightbox\nhttps://learn.microsoft.com/en-us/azure/event-grid/event-domains\n\nSo I don't have an answer for this question actually, but I would probably choose B, because it seems the only one where we are free to do a hack which could \"work\".","timestamp":"1676447520.0"}],"upvote_count":"3","poster":"_fvt","timestamp":"1676447520.0","content":"I'm still trying to understand how an ADF pipeline could be a choice. \nHow you will easily interface the App message with the ADF pipeline ? using ADF Rest API call / logic app / function ? then you should just directly call the right function from the web app. Or maybe schedule the pipeline every minute to process the message in the logs from the storage and then call the right function ? But even, then you may need to send back the answer from the function to the web app as it generates a message for it. And pipeline / integration runtime would take time to start before running the pipeline for each call, if not being already busy by a previous run so the new run would be canceled, and so on... \nWould be an over-engineered mess to implement."},{"poster":"jecawi9630","upvote_count":"2","comment_id":"808789","content":"Selected Answer: B\nhttps://learn.microsoft.com/en-us/azure/data-factory/concepts-pipelines-activities","timestamp":"1676405400.0"},{"poster":"Anzus","timestamp":"1675899060.0","comment_id":"802653","upvote_count":"2","content":"Selected Answer: A\nBoth Service Bus and Data Factory pipeline can be applied to this scenario. Don't forget that functions can also integrate with the queue and process whatever is needed. In this case, I vote A since the app1 says it will send a message, not that it is going to trigger a pipeline."},{"comments":[{"comment_id":"800328","poster":"GarryK","content":"sorry misread the answer, its service bus TOPIC that we need for the filtering by order type, so answer is B.","upvote_count":"4","timestamp":"1675720500.0"}],"timestamp":"1675719300.0","upvote_count":"1","comment_id":"800311","poster":"GarryK","content":"Selected Answer: A\nCorrect answer is A\nhttps://learn.microsoft.com/en-us/azure/service-bus-messaging/service-bus-transactions\nIts exactly for this type of scenario.\nMessaging service, support filter with Topics, integrate with Azure functions (via triggers), and can log to azure monitor log\nhttps://learn.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messaging-overview\nhttps://learn.microsoft.com/en-us/azure/service-bus-messaging/service-bus-queues-topics-subscriptions\nhttps://learn.microsoft.com/en-us/azure/service-bus-messaging/monitor-service-bus"},{"upvote_count":"1","comment_id":"798897","content":"Selected Answer: A\nThere are a lot of possibilities. A, B, C are possible, really. However, we need to understand the \"purpose\".\n\nLooking at \"B\", don't you think is too much for this scenario? B is meant for something more complicated and therefore not for real-time basis.\n\nLeaving A and C which is message vs event. We are dealing with a ordering system thus we need a response and FIFO, we can't have two vendors on the same order. A is the only thing that fit the requirement.","timestamp":"1675607700.0","poster":"Lu5ck"},{"timestamp":"1675170300.0","content":"Selected Answer: B\nAzure Data Factory is the platform is the cloud-based ETL and data integration service that allows you to create data-driven workflows for orchestrating data movement and transforming data at scale. Using Azure Data Factory, you can create and schedule data-driven workflows (called pipelines) that can ingest data from disparate data stores.","comment_id":"794183","poster":"OPT_001122","upvote_count":"2"},{"timestamp":"1674809760.0","poster":"albertoramos","comment_id":"789447","content":"Selected Answer: A\nA. an Azure Service Bus queue is the most appropriate resource for the integration component in this scenario. The integration component will need to process messages and trigger different functions based on the type of order, which aligns with the functionality of an Azure Service Bus queue. It allows for the processing of messages in a reliable, scalable, and decoupled manner, making it a good fit for this order processing system.","upvote_count":"1"},{"comment_id":"781074","content":"Selected Answer: A\nyep, here's processing","poster":"user58","upvote_count":"1","timestamp":"1674129300.0"},{"poster":"FabrityDev","content":"I don't really understand why an ETL solution such as Data Factory would be used in such scenario. Therefore I refuse to believe that it's B. Service Bus makes a lot of sense, but it's stated that it's specifically a queue which has only one sender and one receiver so it cannot be A as we have two Functions. I think i should be C and created different topics for receivers. Logging to storage is also possible, check the documentation:\n\nhttps://learn.microsoft.com/en-us/azure/event-grid/event-domains\nhttps://learn.microsoft.com/en-us/azure/event-grid/diagnostic-logs","timestamp":"1673889180.0","comments":[{"comment_id":"1288054","content":"why not creating two service bus queues one for vendor 1, the other for vendor 2, and it is the app which selects which bus to drop the message in. the question is asking about the technology to be used not how to use it..so i think it is more conveneint to chose A","timestamp":"1727084580.0","upvote_count":"1","poster":"cosmicT73"},{"timestamp":"1675438200.0","poster":"RandomNickname","content":"Yup. It's an irritating question.\nService Bus doesn't make sense to me.\nData Factory would typically be for integration.\nHowever Event Grid ticks all the box's also.\n\nI'm tied between either B or C","upvote_count":"1","comment_id":"797154"}],"comment_id":"777978","upvote_count":"1"},{"comment_id":"776914","timestamp":"1673806620.0","upvote_count":"2","content":"Selected Answer: A\nService Bus is used for messaging","poster":"MadSysadmin"},{"timestamp":"1673544540.0","poster":"ArvindS","upvote_count":"2","comment_id":"773752","content":"Selected Answer: B\nhttps://learn.microsoft.com/en-us/azure/data-factory/control-flow-if-condition-activity"},{"comment_id":"772882","content":"Selected Answer: C\nInteresting nobody suggests EventGrid domain where you just send message to the topic {orderType} and thus call Function accordingly to order type","upvote_count":"3","poster":"gramotei","timestamp":"1673470140.0","comments":[{"comment_id":"808353","content":"I agree - I would go Event Grid as the least effort solution here as will do all of the required integration","poster":"np2021","timestamp":"1676376840.0","upvote_count":"1"}]},{"content":"Selected Answer: A\nTo me Service Bus is the right answer","poster":"Mo22","comment_id":"770559","timestamp":"1673277240.0","upvote_count":"1"},{"comment_id":"760926","timestamp":"1672312680.0","poster":"mVic","upvote_count":"2","content":"Selected Answer: B\nADF pipeline can process the message and trigger the appropriate condition. On ADF, you can add a diagnostic setting to send logs to a storage account."},{"comment_id":"757667","upvote_count":"4","timestamp":"1672074000.0","content":"Selected Answer: B\n\"Integration\" is the key here.","poster":"Singii"},{"timestamp":"1670551500.0","comment_id":"739671","content":"Selected Answer: B\nkey word integration","poster":"Born_Again","upvote_count":"3"},{"comment_id":"738396","poster":"CineZorro824","upvote_count":"2","content":"Has to be A, Service Bus.\nService Bus can trigger functions https://learn.microsoft.com/en-us/azure/azure-functions/functions-bindings-service-bus-trigger?tabs=in-process%2Cextensionv5&pivots=programming-language-csharp\nIt is also an integration component (coupling systems through messaging).\nI think ADF is more for data integration and transformation, and that's not what is happening in this use case. The text literally says we are responding to a *message*, which is exactly what Service Bus is for.","timestamp":"1670448720.0"},{"poster":"A_GEE","timestamp":"1669955280.0","upvote_count":"2","content":"Selected Answer: B\nAfter reading the requirement: \"An integration component\" will process the message\nThe solution is for this integration component and must be able to process the message. Service bus queue cannot process the message. So I will vote for ADF","comment_id":"733442"},{"content":"Service Bus, service bus allows you to define topics which routes messages to subscribers based on message elements. Azure Function can subscribe to topics. Data Factory is used for ETL processing and this is definitely not it.","timestamp":"1668858720.0","comment_id":"721969","upvote_count":"1","poster":"tomt"},{"comment_id":"721002","upvote_count":"4","timestamp":"1668734160.0","content":"Selected Answer: B\nB is correct","poster":"pitIOuStou"},{"upvote_count":"3","comment_id":"719547","poster":"pitIOuStou","timestamp":"1668594600.0","content":"Selected Answer: B\nAnswer is B"},{"poster":"diego_alejandro","timestamp":"1668173760.0","comment_id":"716081","upvote_count":"2","content":"the answer it's B"},{"poster":"diego_alejandro","upvote_count":"2","timestamp":"1668085080.0","comment_id":"715238","content":"Answer it's B...just a pipeline can process the message..."},{"content":"ADF pipeline can invoke function app, but how web app is going to trigger Data Factory? ADF can be triggered by schedule, file or event grid. SO you would have to deploy something to mediate web app and adf. Wouldn;t it be better to user Service Bus?","poster":"mtc9","comment_id":"714553","upvote_count":"1","timestamp":"1667996340.0"},{"timestamp":"1667478960.0","poster":"diego_alejandro","upvote_count":"1","content":"option A","comment_id":"710482"},{"poster":"Tanminator","upvote_count":"3","content":"Selected Answer: B\nAn Azure Data Factory pipeline is required for the integration.","comment_id":"706902","timestamp":"1667012280.0"},{"poster":"Snownoodles","comment_id":"702519","timestamp":"1666566540.0","content":"Selected Answer: B\nThe correct answer should be B \nPlease note the question is asking to implement \"An integration component will process the message\". Service Bus definitely is unable to process the message, it's just a message queue.\nADF has a \"control activity\" which is like IF---Then flow:\nhttps://learn.microsoft.com/en-us/azure/data-factory/control-flow-if-condition-activity\nThis should be the right choice of \"integration component\"","upvote_count":"5"},{"timestamp":"1666529880.0","comment_id":"702181","upvote_count":"3","content":"Selected Answer: B\nservice bus queue allows the processing of a message by a single consumer. For this case, the the message is send to both vendors.\nhttps://learn.microsoft.com/en-us/azure/service-bus-messaging/service-bus-queues-topics-subscriptions","poster":"CLToh"},{"upvote_count":"1","content":"Selected Answer: A\nService Bus queue","comment_id":"673812","poster":"jellybiscuit","timestamp":"1663650720.0"},{"poster":"lemoniazure","timestamp":"1663555500.0","content":"Should be service bus topic or ADF pipeline.","upvote_count":"4","comment_id":"672863"},{"comment_id":"671924","content":"Selected Answer: A\nThe correct is A:\n...App1 will generate a MESSAGE to check...\n...component will process the MESSAGE...\n...a status MESSAGE for App1 will be generated by Function..\n\nhttps://learn.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messaging-overview?source=recommendations","timestamp":"1663464960.0","upvote_count":"3","poster":"Elton_Bicalho"},{"content":"A data factory is like an ETL solution. I think it can choose which function to call based on a parameter. The anser A is queue, not a topic. Queue only can have one consumer. Any ideas?","comment_id":"667566","poster":"Dinima","timestamp":"1663031400.0","upvote_count":"4"},{"content":"Selected Answer: A\nAzure Service Bus supports a set of cloud-based, message-oriented middleware technologies including reliable message queuing and durable publish/subscribe messaging\nhttps://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-queues-topics-subscriptions","timestamp":"1662842160.0","comment_id":"665667","upvote_count":"2","poster":"GarryK"}],"timestamp":"2022-09-07 03:23:00","url":"https://www.examtopics.com/discussions/microsoft/view/80775-exam-az-305-topic-4-question-29-discussion/","answer":"B","question_text":"You are designing an order processing system in Azure that will contain the Azure resources shown in the following table.\n//IMG//\n\nThe order processing system will have the following transaction flow:\n✑ A customer will place an order by using App1.\n✑ When the order is received, App1 will generate a message to check for product availability at vendor 1 and vendor 2.\n✑ An integration component will process the message, and then trigger either Function1 or Function2 depending on the type of order.\n✑ Once a vendor confirms the product availability, a status message for App1 will be generated by Function1 or Function2.\n✑ All the steps of the transaction will be logged to storage1.\nWhich type of resource should you recommend for the integration component?","answer_images":[]},{"id":"QPlwqzbUQeBEXqljrVVF","answer_images":[],"question_text":"Your company has the infrastructure shown in the following table.\n//IMG//\n\nThe on-premises Active Directory domain syncs with Azure Active Directory (Azure AD).\nServer1 runs an application named App1 that uses LDAP queries to verify user identities in the on-premises Active Directory domain.\nYou plan to migrate Server1 to a virtual machine in Subscription1.\nA company security policy states that the virtual machines and services deployed to Subscription1 must be prevented from accessing the on-premises network.\nYou need to recommend a solution to ensure that App1 continues to function after the migration. The solution must meet the security policy.\nWhat should you include in the recommendation?","question_images":["https://www.examtopics.com/assets/media/exam-media/04224/0018000001.png"],"answer_description":"","answers_community":["D (97%)","3%"],"choices":{"B":"the Active Directory Domain Services role on a virtual machine","A":"Azure AD Application Proxy","D":"Azure AD Domain Services (Azure AD DS)","C":"an Azure VPN gateway"},"exam_id":54,"isMC":true,"answer_ET":"D","question_id":194,"url":"https://www.examtopics.com/discussions/microsoft/view/67592-exam-az-305-topic-4-question-3-discussion/","discussion":[{"upvote_count":"32","timestamp":"1639165560.0","content":"Selected Answer: D\nD seems to be correct. You can use Azure AD DS and sync identities needed from Azure AD to Azure AD DS to use legacy protocols like LDAP. Kerberos and NTLM","poster":"bkrich","comment_id":"498920"},{"comments":[{"timestamp":"1648425480.0","content":"If you have AD DS in an Azure VM, you wouldn't need to access the internal network as the on-prem AD DS is already synced to Azure AD.\n\nWhy would you do that tho? It's one extra VM to maintain, coz Server1 is a Linux VM that can't host AD DS, so you would need an extra Win VM just for that.","poster":"FrancisFerreira","comment_id":"576495","upvote_count":"8"}],"upvote_count":"10","timestamp":"1639422420.0","content":"Selected Answer: D\nAD DS in azure on a VM would be easiest option however policy restricts access. \nCorrect answer - D","comment_id":"500834","poster":"Eltooth"},{"timestamp":"1732974420.0","comment_id":"1320222","content":"Selected Answer: D\nMicrosoft Entra Domain Services","upvote_count":"1","poster":"Thanveer"},{"comment_id":"1310807","content":"Selected Answer: D\nD is correct","upvote_count":"1","timestamp":"1731435480.0","poster":"[Removed]"},{"comment_id":"1236465","poster":"23169fd","upvote_count":"1","timestamp":"1719246540.0","content":"Selected Answer: D\nD. Azure AD Domain Services (Azure AD DS)\n\nJustification:\nAzure AD DS: Offers LDAP, Kerberos, and NTLM authentication without requiring a direct connection to on-premises AD, ensuring compliance with the security policy.\nFunctionality: Allows App1 to perform LDAP queries to verify user identities using the synchronized data from Azure AD.\nSecurity: Prevents virtual machines in Subscription1 from accessing the on-premises network directly."},{"timestamp":"1683070800.0","upvote_count":"2","poster":"betterthanlife","content":"D is correct, App Proxy would not work & both the VPN gateway or DC in Azure IaaS would violate the requirement that virtual machines and services deployed to Subscription1 must be prevented from accessing the on-premises network.","comment_id":"888020"},{"content":"Selected Answer: D\nD. Azure AD Domain Services (Azure AD DS)\n\nAzure AD Domain Services (Azure AD DS) provides managed domain services such as domain join, group policy, LDAP, and Kerberos/NTLM authentication. It integrates with your existing Azure AD tenant, allowing you to continue using LDAP queries to verify user identities after migrating Server1 to a virtual machine in Subscription1.\n\nBy using Azure AD DS, you can ensure that App1 continues to function after migration while adhering to the company security policy that prevents virtual machines and services deployed to Subscription1 from accessing the on-premises network.","comment_id":"859057","timestamp":"1680452940.0","upvote_count":"6","poster":"NotMeAnyWay"},{"comment_id":"791012","content":"Selected Answer: D\nD. Azure AD Domain Services (Azure AD DS)","timestamp":"1674934500.0","upvote_count":"1","poster":"OPT_001122"},{"content":"Selected Answer: D\nExample here: https://docs.microsoft.com/en-us/azure/active-directory-domain-services/scenarios#azure-ad-ds-for-hybrid-organizations\n\nAzure AD Already exists and is synced with on premises AD.","comment_id":"663956","timestamp":"1662664620.0","poster":"Gowind2","upvote_count":"3"},{"timestamp":"1659756240.0","poster":"lemoniazure","upvote_count":"4","comment_id":"643171","content":"D,\nReason:\nAn Azure AD DS managed domain lets you run legacy applications in the cloud that can't use modern authentication methods, or where you don't want directory lookups to always go back to an on-premises AD DS environment. You can lift and shift those legacy applications from your on-premises environment into a managed domain, without needing to manage the AD DS environment in the cloud.\n\nAzure AD DS integrates with your existing Azure AD tenant. This integration lets users sign in to services and applications connected to the managed domain using their existing credentials. You can also use existing groups and user accounts to secure access to resources. These features provide a smoother lift-and-shift of on-premises resources to Azure."},{"poster":"shaojunni","timestamp":"1658933700.0","comment_id":"638154","upvote_count":"1","content":"D is correct. B is incorrect, since AAD is already in place and synced with AD on-premise."},{"poster":"AubinBakana","timestamp":"1658779020.0","upvote_count":"1","comment_id":"636931","content":"Selected Answer: D\nThis is the best answer. Azure AD DS was designed exactly for this type of scenario."},{"comment_id":"631728","upvote_count":"1","comments":[{"timestamp":"1658778900.0","poster":"AubinBakana","content":"Yes, but we are not talking about users here. This is an application feature. App Proxy is a jump box that allows users to connect to services on-prem without poking a whole in the Firewall. Totally different situation here.","comment_id":"636930","upvote_count":"3"}],"timestamp":"1657886460.0","content":"Selected Answer: A\nApplication Proxy is a feature of Azure AD that enables users to access on-premises web applications from a remote client.","poster":"codingdown"},{"comment_id":"631727","timestamp":"1657886400.0","comments":[{"timestamp":"1711455060.0","poster":"rishisoft1","comment_id":"1183289","content":"Application proxy helps to sync on-premise and Azure AD, actual authentication occurs through ADDS","upvote_count":"1"}],"poster":"codingdown","upvote_count":"1","content":"Selected Answer: A\nApplication Proxy is a feature of Azure AD that enables users to access on-premises web applications from a remote client."},{"poster":"tunmise_ay","content":"was in exam 1 June 2022","timestamp":"1654124040.0","upvote_count":"6","comments":[{"upvote_count":"1","timestamp":"1654625340.0","content":"did any other questions from this come. I am doing my exam on the 22nd","comment_id":"612859","poster":"al608"}],"comment_id":"610357"},{"content":"Selected Answer: D\nCorrect answer - D\nhttps://docs.microsoft.com/en-us/azure/active-directory-domain-services/faqs#can-i-add-domain-controllers-to-an-azure-ad-domain-services-managed-domain-","timestamp":"1653400500.0","poster":"Gor","upvote_count":"2","comment_id":"606750"},{"timestamp":"1653333660.0","content":"App1 requires to use LDAP queries to verify identities. I suppose the App will not modify (question doesn't refer to any changes in the App), no LDAP in AZ AD, so the only possibility is deploy an AD DS in Azure. VPN is in place. B seems to be correct, a Domain Controller in Azure","comment_id":"606293","poster":"winframe","upvote_count":"2"},{"upvote_count":"5","timestamp":"1652033880.0","poster":"datafypk","content":"was in exam 8 May 22","comment_id":"598651"},{"comment_id":"592829","upvote_count":"1","content":"Selected Answer: D\nCorrect answer - D\nhttps://docs.microsoft.com/en-us/azure/active-directory-domain-services/faqs#can-i-add-domain-controllers-to-an-azure-ad-domain-services-managed-domain-","poster":"Teringzooi","timestamp":"1651033920.0"},{"content":"in my exam on 31 Mar 22","timestamp":"1648780020.0","poster":"esther823","upvote_count":"3","comment_id":"579245"},{"comment_id":"579066","upvote_count":"4","content":"on exam 03-31-2022","timestamp":"1648746060.0","poster":"akkrishna22"},{"content":"Reading the topology and infrastructure, the company had deployed a Windows Server Active Directory, so the need sync that domain to a DC in the cloud to keep inside azure the server 1 authentication, by the way, Azure active directory domain services do not support join to a running AD, the had a managed services where the DC´s are managed by azure, so the answer should be B, a VM running a DC from on premise AD. (of course, the also need a VPN to sync the dc´s).\n\nhttps://docs.microsoft.com/en-us/azure/active-directory-domain-services/faqs#can-i-add-domain-controllers-to-an-azure-ad-domain-services-managed-domain-","comment_id":"572607","poster":"jorgenoguerah","upvote_count":"2","timestamp":"1647909060.0"},{"timestamp":"1645636500.0","upvote_count":"6","content":"On the AZ-305 2/22/22","comment_id":"554694","poster":"HGD545"}],"answer":"D","topic":"4","unix_timestamp":1639165560,"timestamp":"2021-12-10 20:46:00"},{"id":"14H9HP1mhN7qUuLIuu5k","discussion":[{"poster":"NotMeAnyWay","comment_id":"867468","upvote_count":"14","content":"Selected Answer: B\nCorrect:\n\nB. Azure Data Factory\n\nYou should include Azure Data Factory in the recommendation to create Azure-SQL Server Integration Services (SSIS) packages. Azure Data Factory supports running SSIS packages in the cloud using Azure-SSIS Integration Runtime, which allows you to target Azure SQL Database instances as the destinations for your SSIS packages. This enables you to continue using your existing SSIS packages while migrating your on-premises databases to Azure SQL Database.","timestamp":"1681228980.0"},{"content":"Selected Answer: B\nhttps://docs.microsoft.com/en-us/azure/data-factory/tutorial-deploy-ssis-packages-azure","poster":"GarryK","comment_id":"665668","timestamp":"1662842220.0","upvote_count":"7"},{"timestamp":"1731508500.0","comment_id":"1311366","upvote_count":"1","poster":"[Removed]","content":"Selected Answer: B\nB is correct"},{"content":"Selected Answer: B\nGiven Answer B is correct,\nOnce you understand the meaning of SSIS it becomes clear answer is Azure Data factory \nhttps://learn.microsoft.com/en-us/sql/integration-services/sql-server-integration-services?view=sql-server-ver16\nhttps://learn.microsoft.com/en-us/azure/data-factory/tutorial-deploy-ssis-packages-azure","poster":"Lazylinux","timestamp":"1713491220.0","comment_id":"1198265","upvote_count":"1"},{"comment_id":"796746","content":"Selected Answer: B\nAzure Data Factory provides a cloud-based platform for the orchestration and management of data transformation and movement. Azure Data Factory supports connecting to and migrating data from on-premises databases, including SQL Server, to Azure SQL Database. Azure Data Factory also supports integrating with SSIS packages, making it possible to continue using your existing SSIS packages while utilizing Azure SQL Database as the target database.","poster":"VBK8579","upvote_count":"5","timestamp":"1675400700.0"},{"content":"Selected Answer: B\nB. Azure Data Factory","poster":"OPT_001122","comment_id":"794185","timestamp":"1675170360.0","upvote_count":"1"},{"upvote_count":"2","poster":"Snownoodles","timestamp":"1663620060.0","comment_id":"673620","content":"I wonder if there is a typo in this question:\n\"You need to recommend a solution to CREATE Azure-SQL Server Integration Services (SSIS) packages\" \nShould \"CREATE\" be \"REPLACE\"?","comments":[{"content":"Apparently yes","poster":"sKaiNL","timestamp":"1663754880.0","comment_id":"674994","upvote_count":"2"}]},{"poster":"kay000001","comment_id":"666637","timestamp":"1662962820.0","content":"Selected Answer: B\nB.\nhttps://docs.microsoft.com/en-us/azure/data-factory/how-to-migrate-ssis-job-ssms","upvote_count":"4"}],"timestamp":"2022-09-10 22:37:00","answer":"B","question_images":[],"question_id":195,"answers_community":["B (100%)"],"choices":{"D":"SQL Server Migration Assistant (SSMA)","B":"Azure Data Factory","A":"Data Migration Assistant (DMA)","C":"Azure Data Catalog"},"exam_id":54,"answer_description":"","question_text":"You have 100 Microsoft SQL Server Integration Services (SSIS) packages that are configured to use 10 on-premises SQL Server databases as their destinations.\nYou plan to migrate the 10 on-premises databases to Azure SQL Database.\nYou need to recommend a solution to create Azure-SQL Server Integration Services (SSIS) packages. The solution must ensure that the packages can target the\nSQL Database instances as their destinations.\nWhat should you include in the recommendation?","topic":"4","answer_images":[],"answer_ET":"B","url":"https://www.examtopics.com/discussions/microsoft/view/81587-exam-az-305-topic-4-question-30-discussion/","isMC":true,"unix_timestamp":1662842220}],"exam":{"isBeta":false,"id":54,"provider":"Microsoft","numberOfQuestions":286,"name":"AZ-305","isMCOnly":false,"lastUpdated":"12 Apr 2025","isImplemented":true},"currentPage":39},"__N_SSP":true}