{"pageProps":{"questions":[{"id":"qn8ycYsAE3ryJ2nPFiSq","answer":"","timestamp":"2024-01-05 17:28:00","answer_ET":"","topic":"4","discussion":[{"comment_id":"1202664","poster":"Alongi","timestamp":"1729954080.0","content":"Correct","upvote_count":"3"},{"content":"Correct","timestamp":"1724855520.0","poster":"ArdiShah","comment_id":"1161795","upvote_count":"3"},{"upvote_count":"4","timestamp":"1720849200.0","content":"-- Create schema\nCREATE SCHEMA Security;\nGO\n\n-- Create function\nCREATE FUNCTION Security.tv_securitypredicate (@SalesRep AS nvarchar(50))\nRETURNS TABLE\nWITH SCHEMABINDING\nAS\nRETURN\n SELECT 1 AS tv_securitypredicate_result\n WHERE @SalesRep = USER_NAME();\nGO\n\n-- Create security policy\nCREATE SECURITY POLICY SalesFilter\nADD FILTER PREDICATE Security.tv_securitypredicate(SalesRep)\nON Sales.Orders\nWITH (STATE = ON);","comment_id":"1121384","poster":"Happynewyear1001"},{"timestamp":"1720189680.0","comment_id":"1114648","upvote_count":"4","content":"Correct.","poster":"jongert"}],"exam_id":67,"question_images":["https://img.examtopics.com/dp-203/image377.png"],"answer_description":"","url":"https://www.examtopics.com/discussions/microsoft/view/130413-exam-dp-203-topic-4-question-59-discussion/","isMC":false,"answers_community":[],"question_id":356,"unix_timestamp":1704472080,"question_text":"HOTSPOT\n-\n\nYou have an Azure Synapse Analytics dedicated SQL pool that contains a table named Sales.Orders. Sales.Orders contains a column named SalesRep.\n\nYou plan to implement row-level security (RLS) for Sales.Orders.\n\nYou need to create the security policy that will be used to implement RLS. The solution must ensure that sales representatives only see rows for which the value of the SalesRep column matches their username.\n\nHow should you complete the code? To answer, select the appropriate options in the answer area.\n\n//IMG//","answer_images":["https://img.examtopics.com/dp-203/image378.png"]},{"id":"PZBCMa7t4IkaJxY4vBGX","question_images":[],"question_text":"You are designing an Azure Databricks interactive cluster. The cluster will be used infrequently and will be configured for auto-termination.\nYou need to ensure that the cluster configuration is retained indefinitely after the cluster is terminated. The solution must minimize costs.\nWhat should you do?","topic":"4","answer":"A","url":"https://www.examtopics.com/discussions/microsoft/view/62056-exam-dp-203-topic-4-question-6-discussion/","answers_community":["A (93%)","7%"],"choices":{"D":"Clone the cluster after it is terminated.","C":"Terminate the cluster manually when processing completes.","B":"Create an Azure runbook that starts the cluster every 90 days.","A":"Pin the cluster."},"isMC":true,"answer_description":"","answer_ET":"A","answer_images":[],"timestamp":"2021-09-14 21:49:00","question_id":357,"exam_id":67,"discussion":[{"upvote_count":"11","timestamp":"1694350440.0","content":"To ensure that the cluster configuration is retained indefinitely after the cluster is terminated while minimizing costs, you should pin the cluster.\n\nPinning a cluster in Azure Databricks prevents it from being terminated by the auto-termination feature. This means that the cluster configuration and installed libraries will be retained even if the cluster is not being used. This is the most efficient and cost-effective way to ensure that the cluster configuration is retained indefinitely after the cluster is terminated.\n\nCreating an Azure runbook to start the cluster every 90 days would require additional resources and would not be a cost-effective solution. Terminating the cluster manually when processing completes would not retain the cluster configuration. Cloning the cluster after it is terminated would create a new cluster with the same configuration, but this would also result in additional costs. Should be A","poster":"markpumc","comment_id":"835129"},{"poster":"FredNo","upvote_count":"11","timestamp":"1652966940.0","content":"Selected Answer: A\nCorrect","comment_id":"481880"},{"content":"Selected Answer: A\nA. Pin the cluster\nPinning prevents automatic termination, keeping the cluster running longer than needed, increasing costs.\nSince the requirement is to use it infrequently, pinning is not a cost-effective solution.","timestamp":"1742252880.0","comment_id":"1399881","poster":"imatheushenrique","upvote_count":"1"},{"upvote_count":"1","timestamp":"1730138580.0","poster":"umever","comment_id":"1203651","content":"Azure Databricks retains cluster configuration information for up to 200 all-purpose clusters terminated in the last 30 days and up to 30 job clusters recently terminated by the job scheduler. To keep an all-purpose cluster configuration even after it has been terminated for more than 30 days, an administrator can pin a cluster to the cluster list.\nRef : https://docs.databricks.com/api/azure/workspace/clusters"},{"comment_id":"1126440","timestamp":"1721358480.0","content":"Selected Answer: A\nhttps://learn.microsoft.com/en-us/azure/databricks/compute/clusters-manage","upvote_count":"1","poster":"galiph"},{"upvote_count":"1","content":"Selected Answer: D\nCloning the cluster after it is terminated is the best option in this case because it will allow the cluster configuration to be retained indefinitely without requiring any ongoing maintenance or incurring unnecessary costs.\n\nHere are some of the benefits of cloning the cluster after it is terminated:\n\nThe cluster configuration will be retained indefinitely.\nThere will be no ongoing maintenance or costs associated with the cluster.\nThe cluster can be easily restarted when it is needed.","poster":"Azure_2023","timestamp":"1720960920.0","comment_id":"1122606"},{"timestamp":"1709198400.0","poster":"kkk5566","content":"Selected Answer: A\nis correct","comment_id":"994883","upvote_count":"1"},{"comment_id":"942193","timestamp":"1704319500.0","poster":"akk_1289","upvote_count":"2","content":"got this question for my exam"},{"timestamp":"1676231580.0","upvote_count":"3","poster":"Deeksha1234","content":"correct","comment_id":"645997"},{"poster":"Podavenna","content":"Correct answer!","timestamp":"1647294540.0","upvote_count":"6","comment_id":"444784"}],"unix_timestamp":1631648940},{"id":"bopkPwhwV68TjSRr7V0f","answers_community":["A (57%)","B (37%)","7%"],"unix_timestamp":1704745140,"answer_ET":"A","topic":"4","answer_description":"","timestamp":"2024-01-08 21:19:00","isMC":true,"url":"https://www.examtopics.com/discussions/microsoft/view/130651-exam-dp-203-topic-4-question-60-discussion/","question_id":358,"question_text":"You have an Azure data factory named DF1. DF1 contains a single pipeline that is executed by using a schedule trigger.\n\nFrom Diagnostics settings, you configure pipeline runs to be sent to a resource-specific destination table in a Log Analytics workspace.\n\nYou need to run KQL queries against the table.\n\nWhich table should you query?","answer":"A","choices":{"A":"ADFPipelineRun","C":"ADFActivityRun","D":"AzureDiagnostics","B":"ADFTriggerRun"},"exam_id":67,"answer_images":[],"question_images":[],"discussion":[{"timestamp":"1706208000.0","comment_id":"1131953","content":"Selected Answer: B\nThe answer is not D because the workspace was set to Resource-specific. See doc below.\nI'm torn between A (PipelineRun) vs B (TriggerRun) because the wording is so generic. However, since they mentioned the scheduling of the pipeline, I would lean on B.\nhttps://learn.microsoft.com/en-us/azure/azure-monitor/essentials/resource-logs#send-to-log-analytics-workspace","comments":[{"timestamp":"1709224680.0","content":"I would say it's A, because in the ADFTriggerRun it would only contain information on when was the pipeline executed and which pipeline, the question asks for \"pipeline runs\", but yes it's very generic, because by pipeline runs you can also think that it's about when it was executed, but since it doesn't implicitely say so, I'd go with A","upvote_count":"4","poster":"mav2000","comment_id":"1162802"}],"poster":"Bill_Walker","upvote_count":"7"},{"poster":"Mausar","comment_id":"1158146","timestamp":"1708807200.0","upvote_count":"6","content":"Selected Answer: A\nRemember that you are setting \"pipeline runs\" logs from diagnostics settings to be sent to a Log Analytics workspace, not the \"trigger runs\" or \"activity runs\" logs.\n\nAzure Diagnostics stores resource logs for Azure services that use Azure Diagnostics mode. Resource logs describe the internal operation of Azure resources. \nAzure services that use resource-specific mode store data in a table specific to that service and do not use the AzureDiagnostics table\n\nhttps://learn.microsoft.com/en-us/azure/azure-monitor/reference/tables/azurediagnostics"},{"content":"Selected Answer: A\nDiagnostic Settings and Log Routing:\n\nWhen configuring diagnostic settings for ADF to send logs to a Log Analytics workspace, you have two modes:\n\n Azure-Diagnostics Mode:\n In this mode, all diagnostic logs are sent to a consolidated table named AzureDiagnostics.\n This table aggregates various logs, and you can filter the data based on specific services or log types.\n\n Resource-Specific Mode:\n This mode routes logs into distinct tables specific to ADF activities.\n The relevant tables include:\n ADFPipelineRun: Contains records of pipeline executions.\n ADFActivityRun: Details individual activities within pipelines.\n ADFTriggerRun: Logs trigger executions.\n\n\nhttps://learn.microsoft.com/en-us/azure/data-factory/monitor-configure-diagnostics","timestamp":"1734043920.0","comment_id":"1325897","upvote_count":"1","poster":"KauK"},{"timestamp":"1725571800.0","upvote_count":"1","comment_id":"1279187","content":"Selected Answer: A\nhttps://learn.microsoft.com/en-us/azure/azure-monitor/essentials/resource-logs#resource-specific","poster":"raymoral"},{"comment_id":"1257749","poster":"f2a9aa5","content":"Selected Answer: A\nA. ADFPipelineRun\n\nHere’s why:\n\nADFPipelineRun: This table contains detailed information about the execution of your ADF pipelines, including start and end times, status, and other relevant metrics. It’s the go-to table for querying pipeline run details1.","timestamp":"1722297660.0","upvote_count":"3"},{"timestamp":"1721128440.0","upvote_count":"3","poster":"evangelist","content":"Selected Answer: A\nA is correct","comment_id":"1248843"},{"comment_id":"1243104","content":"Selected Answer: A\nhttps://learn.microsoft.com/en-us/azure/azure-monitor/reference/tables/adfpipelinerun","upvote_count":"3","timestamp":"1720226160.0","poster":"e56bb91"},{"poster":"mghf61","content":"Chat GPT answer: \n\nTo run KQL queries against the pipeline runs sent to a Log Analytics workspace, you should query the table that corresponds to the pipeline runs. Since you configured pipeline runs to be sent to a resource-specific destination table in the Log Analytics workspace, you should query the table corresponding to pipeline runs.\n\nTherefore, the correct table to query is:\n\nA. ADFPipelineRun","timestamp":"1708080720.0","upvote_count":"3","comment_id":"1151914"},{"comment_id":"1127405","poster":"Azure_2023","upvote_count":"4","timestamp":"1705769760.0","content":"Selected Answer: B\nADFTriggerRun\n\nThe ADFTriggerRun table stores logs related to trigger runs, which are the events that initiate pipeline executions. This table includes the trigger name, pipeline name, run ID, start time, end time, status, and a message about the trigger run. This table is useful for understanding how triggers are firing and how pipelines are being executed."},{"content":"Selected Answer: D\nShould be D.","poster":"vernillen","upvote_count":"1","comment_id":"1127193","timestamp":"1705746180.0"},{"upvote_count":"1","comment_id":"1123300","content":"Selected Answer: D\nPer the other two comments, answer should be D. Adding a voting comment so it can show on \"show answer\"","timestamp":"1705319100.0","poster":"Filda123"},{"content":"When you configure pipeline runs to be sent to a Log Analytics workspace in Azure Data Factory, the data is typically stored in the \"AzureDiagnostics\" table. Therefore, you should query the \"AzureDiagnostics\" table to retrieve information about pipeline runs.\n\nSo, the correct answer is:\n\nD. AzureDiagnostics","timestamp":"1705131840.0","upvote_count":"2","poster":"Happynewyear1001","comment_id":"1121387","comments":[{"upvote_count":"1","poster":"j888","timestamp":"1707603840.0","comments":[{"comment_id":"1146866","timestamp":"1707604440.0","upvote_count":"1","content":"I would choose Activity Run as a preference as it would show detailed activities of the run.\nHowever, I believe this question may seem to concern with the trigger rather than the pipeline.\n\n https://learn.microsoft.com/en-us/azure/data-factory/monitor-schema-logs-eventsactivities.","poster":"j888"}],"content":"It has already been stated that the destination table is sent to 'resource specific', not azure diagnostic","comment_id":"1146862"}]},{"content":"Answer is D\nhttps://learn.microsoft.com/en-us/azure/azure-monitor/essentials/resource-logs\nall data from any diagnostic setting is collected in the AzureDiagnostics table","comment_id":"1120309","poster":"Tapaskaro","timestamp":"1705019640.0","upvote_count":"1"},{"comment_id":"1116980","content":"IMHO activity run should show all the details","upvote_count":"1","timestamp":"1704745140.0","poster":"Oleh777"}]},{"id":"P7HD3vIgCkYj0mZuJeME","answer_images":["https://img.examtopics.com/dp-203/image380.png"],"exam_id":67,"answer":"","isMC":false,"question_images":["https://img.examtopics.com/dp-203/image379.png"],"timestamp":"2024-01-05 17:41:00","url":"https://www.examtopics.com/discussions/microsoft/view/130418-exam-dp-203-topic-4-question-61-discussion/","question_id":359,"question_text":"HOTSPOT\n-\n\nYou have an Azure Synapse Analytics dedicated SQL pool named sqlpool1 that contains a table named Sales1.\n\nEach row in the Sales table contains regional sales data and a field that lists the username of a sales analyst.\n\nYou need to configure row-level security (RLS) to ensure that the analysts can view only the rows containing their respective data.\n\nWhat should you do? To answer, select the appropriate options in the answer area.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","topic":"4","answer_description":"","discussion":[{"upvote_count":"1","comment_id":"1204177","content":"Correct answer","poster":"Alongi","timestamp":"1730235480.0"},{"upvote_count":"2","timestamp":"1720765800.0","comment_id":"1120557","poster":"[Removed]","content":"Correct"},{"comment_id":"1114658","upvote_count":"4","poster":"jongert","content":"Correct\n\nhttps://learn.microsoft.com/en-us/sql/relational-databases/security/row-level-security?view=sql-server-ver16","timestamp":"1720190460.0"}],"answers_community":[],"answer_ET":"","unix_timestamp":1704472860},{"id":"mSgv4KLcb1tVKP3G8vou","question_id":360,"question_text":"You have an Azure subscription that contains an Azure Synapse workspace named WS1 and an Azure Monitor action group named Group1. WS1 has a dedicated SQL pool.\n\nYou plan to archive monitoring data for integration activity runs.\n\nYou need to ensure that you can configure custom alerts based on the archived data that will execute Group1. The solution must minimize administrative effort.\n\nWhich diagnostic setting should you select?","timestamp":"2024-01-05 17:45:00","answers_community":["A (100%)"],"answer_description":"","exam_id":67,"unix_timestamp":1704473100,"answer_ET":"A","choices":{"A":"Send to Log Analytics workspace","B":"Archive to a storage account","D":"Send to a partner solution","C":"Stream to an event hub"},"topic":"4","isMC":true,"answer":"A","question_images":[],"discussion":[{"timestamp":"1721211780.0","comment_id":"1249525","poster":"evangelist","upvote_count":"1","content":"Selected Answer: A\nno doubt A"},{"content":"Selected Answer: A\nSend to Log Analytics workspace","upvote_count":"1","poster":"weyiyaw474","timestamp":"1714382400.0","comment_id":"1203931"},{"poster":"Lewiasskick","comment_id":"1137965","timestamp":"1706826000.0","upvote_count":"1","content":"https://learn.microsoft.com/en-us/azure/sentinel/detect-threats-custom"},{"poster":"jongert","upvote_count":"2","content":"Correct","timestamp":"1704473100.0","comment_id":"1114663"}],"url":"https://www.examtopics.com/discussions/microsoft/view/130419-exam-dp-203-topic-4-question-62-discussion/","answer_images":[]}],"exam":{"isImplemented":true,"id":67,"isMCOnly":false,"numberOfQuestions":384,"name":"DP-203","provider":"Microsoft","lastUpdated":"12 Apr 2025","isBeta":false},"currentPage":72},"__N_SSP":true}