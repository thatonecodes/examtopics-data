{"pageProps":{"questions":[{"id":"KMC2v20OPJT9rJPm3NJc","url":"https://www.examtopics.com/discussions/microsoft/view/112437-exam-dp-420-topic-3-question-5-discussion/","question_id":81,"discussion":[{"upvote_count":"1","timestamp":"1741116240.0","poster":"matejka","comment_id":"1365076","content":"Selected Answer: B\nTo make the contents of container1 available as reference data for an Azure Stream Analytics job, you should directly connect Azure Stream Analytics to Azure Cosmos DB as a reference data source. Utilizing Azure functions and Azure event hubs adds unnecessary complexity for this specific requirement. Directly connecting Azure Stream Analytics to Azure Cosmos DB ensures real-time data integration without the need for intermediate steps."},{"content":"This is a series of questions with multiple scenarios. Correct options are:\n1. You create an Azure Synapse pipeline that uses Azure Cosmos DB Core (SQL) API as the input and Azure Blob Storage as the output.\n2. You create an Azure Data Factory pipeline that uses Azure Cosmos DB Core (SQL) API as the input and Azure Blob Storage as the output.\nAll other options are incorrect.","upvote_count":"2","timestamp":"1730971980.0","poster":"[Removed]","comment_id":"1207769"},{"timestamp":"1726307280.0","comment_id":"1173359","content":"Selected Answer: A\nhttps://learn.microsoft.com/en-us/azure/stream-analytics/stream-analytics-use-reference-data#example\nStream Analytics supports Azure Blob Storage, Azure Data Lake Storage Gen2, and Azure SQL Database as the storage layer for reference data.\nI think the solution of outputting to Azure Blob Storage is yes, and the rest is no.","poster":"3a0b61c","upvote_count":"3"},{"comments":[{"upvote_count":"2","content":"Probably not as I do not see CosmosDB as an input for stream analytics job\n\nhttps://learn.microsoft.com/en-us/azure/stream-analytics/stream-analytics-add-inputs","comment_id":"1069961","poster":"SwePha","timestamp":"1715652360.0"}],"timestamp":"1704281700.0","poster":"XiangRongChang","content":"According to https://learn.microsoft.com/en-us/azure/stream-analytics/stream-analytics-quick-create-portal, can the answer be YES.","upvote_count":"2","comment_id":"941669"},{"timestamp":"1702815840.0","upvote_count":"4","content":"Given answer is correct","comment_id":"925902","poster":"azuredemo2022three"}],"answer_images":[],"answers_community":["A (75%)","B (25%)"],"question_images":[],"unix_timestamp":1686997440,"answer":"A","timestamp":"2023-06-17 12:24:00","topic":"3","answer_ET":"A","choices":{"A":"Yes","B":"No"},"answer_description":"","question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou have a container named container1 in an Azure Cosmos DB Core (SQL) API account.\nYou need to make the contents of container1 available as reference data for an Azure Stream Analytics job.\nSolution: You create an Azure Synapse pipeline that uses Azure Cosmos DB Core (SQL) API as the input and Azure Blob Storage as the output.\nDoes this meet the goal?","isMC":true,"exam_id":69},{"id":"fAHL8yczeIOnpcMDwlNS","question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou have a container named container1 in an Azure Cosmos DB Core (SQL) API account.\nYou need to make the contents of container1 available as reference data for an Azure Stream Analytics job.\nSolution: You create an Azure Data Factory pipeline that uses Azure Cosmos DB Core (SQL) API as the input and Azure Blob Storage as the output.\nDoes this meet the goal?","question_images":[],"question_id":82,"answer_ET":"A","timestamp":"2023-11-14 05:10:00","exam_id":69,"answer_description":"","url":"https://www.examtopics.com/discussions/microsoft/view/126023-exam-dp-420-topic-3-question-6-discussion/","answers_community":["A (100%)"],"unix_timestamp":1699935000,"isMC":true,"answer_images":[],"topic":"3","discussion":[{"upvote_count":"1","content":"This is a series of questions with multiple scenarios. Correct options are:\n1. You create an Azure Synapse pipeline that uses Azure Cosmos DB Core (SQL) API as the input and Azure Blob Storage as the output.\n2. You create an Azure Data Factory pipeline that uses Azure Cosmos DB Core (SQL) API as the input and Azure Blob Storage as the output.\nAll other options are incorrect.","comment_id":"1207770","timestamp":"1730971980.0","poster":"[Removed]"},{"timestamp":"1726307220.0","upvote_count":"1","comment_id":"1173357","content":"Selected Answer: A\nhttps://learn.microsoft.com/en-us/azure/stream-analytics/stream-analytics-use-reference-data#example\nStream Analytics supports Azure Blob Storage, Azure Data Lake Storage Gen2, and Azure SQL Database as the storage layer for reference data.\nI think the solution of outputting to Azure Blob Storage is yes, and the rest is no.","poster":"3a0b61c"},{"timestamp":"1715652600.0","comment_id":"1069971","poster":"SwePha","upvote_count":"4","content":"Selected Answer: A\nhttps://learn.microsoft.com/en-us/azure/data-factory/concepts-pipelines-activities?tabs=data-factory#data-movement-activities\n\nAzure Data Factory supports CosmosDB as a source and Blob storage as the sink."}],"choices":{"A":"Yes","B":"No"},"answer":"A"},{"id":"3hil4pXesex0BSkHGog3","answer_ET":"A","url":"https://www.examtopics.com/discussions/microsoft/view/84080-exam-dp-420-topic-3-question-7-discussion/","answers_community":["B (100%)"],"timestamp":"2022-09-30 07:27:00","exam_id":69,"unix_timestamp":1664515620,"isMC":true,"answer":"B","answer_images":["https://www.examtopics.com/assets/media/exam-media/04276/0008100001.jpg"],"answer_description":"The Azure Cosmos DB change feed is a mechanism to get a continuous and incremental feed of records from an Azure Cosmos container as those records are being created or modified. Change feed support works by listening to container for any changes. It then outputs the sorted list of documents that were changed in the order in which they were modified.\nThe following diagram represents the data flow and components involved in the solution:\n\nReference:\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/sql/changefeed-ecommerce-solution","question_id":83,"question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou have a container named container1 in an Azure Cosmos DB Core (SQL) API account.\nYou need to make the contents of container1 available as reference data for an Azure Stream Analytics job.\nSolution: You create an Azure function that uses Azure Cosmos DB Core (SQL) API change feed as a trigger and Azure event hub as the output.\nDoes this meet the goal?","question_images":[],"choices":{"A":"Yes","B":"No"},"topic":"3","discussion":[{"timestamp":"1680154020.0","comment_id":"683240","comments":[{"content":"So, why question #6 is no? The question before this one.","upvote_count":"1","comments":[{"upvote_count":"2","timestamp":"1720006980.0","content":"Question #6 is wrong. For real-time data, you use an Event Hub. For reference data, you use Data Factory","poster":"xRiot007","comment_id":"1112797"}],"poster":"XiangRongChang","comment_id":"941660","timestamp":"1704281220.0"}],"poster":"Flammkuchen","content":"I don't thing that Y is correct. While event hub would be a great input source for Stream Analytics *Streaming* Data, it is not supported as input for Stream Analytics *Reference* Data. https://learn.microsoft.com/en-us/azure/stream-analytics/stream-analytics-add-inputs. \n\nUsing Data Factory is the recommended solution for reference data in the Microsoft docs: https://learn.microsoft.com/en-us/azure/stream-analytics/stream-analytics-use-reference-data","upvote_count":"8"},{"upvote_count":"1","content":"Selected Answer: B\nAnswer","timestamp":"1704144780.0","comment_id":"940290","poster":"azuredemo2022three"}]},{"id":"JZ2SEZ2SfffzRxSlmmsZ","topic":"3","exam_id":69,"question_images":[],"answers_community":["D (100%)"],"answer_ET":"D","isMC":true,"question_id":84,"answer_images":[],"answer":"D","choices":{"D":"all the properties of the updated items","B":"only the partition key and the changed properties of the updated items","C":"all the properties of the original items and the updated items","A":"only the changed properties and the system-defined properties of the updated items"},"unix_timestamp":1663436820,"url":"https://www.examtopics.com/discussions/microsoft/view/82559-exam-dp-420-topic-3-question-8-discussion/","discussion":[{"content":"Answer is D as all properties are sent to the change feed. This is testable by creating an Azure Function with CosmosDB input trigger.","upvote_count":"6","comment_id":"671719","timestamp":"1679082420.0","poster":"DudeWheresMyCar"},{"upvote_count":"1","content":"When you create an Azure function with a trigger on the change feed of an Azure Cosmos DB Core (SQL) API container, the Azure function receives the following:\n\nB. only the partition key and the changed properties of the updated items.\n\nThe change feed provides information about changes made to the items in the container. Specifically, it includes the partition key and the properties of the updated items. This allows the Azure function to process the changes, including the partition key and the specific properties that were modified, without needing to retrieve all properties of the original items.\n\nThis selective information is beneficial for efficiently processing changes and reacting to updates in real-time without the need to access the entire original item, which can help minimize processing overhead and improve performance.","poster":"Garyn","comments":[{"content":"Answer is D - all properties are retrieved using the change feed\n\nChange feed in Azure Cosmos DB is a persistent record of changes to a container in the order they occur. Change feed support in Azure Cosmos DB works by listening to an Azure Cosmos DB container for any changes. It then outputs the sorted list of documents that were changed in the order in which they were modified. \n\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/change-feed","poster":"xRiot007","upvote_count":"1","timestamp":"1720007880.0","comment_id":"1112813"}],"timestamp":"1711574400.0","comment_id":"1019186"},{"upvote_count":"2","poster":"Feanorich","comment_id":"985530","content":"Selected Answer: D\nIt is D","timestamp":"1708406280.0"},{"poster":"akash211","upvote_count":"1","comment_id":"966572","timestamp":"1706559720.0","content":"Selected Answer: D\nIt should be D only."},{"poster":"arnabdt","content":"Selected Answer: D\nD is correct","comment_id":"855938","timestamp":"1696089780.0","upvote_count":"1"},{"timestamp":"1687343280.0","content":"Selected Answer: D\nD is the correct answer","comment_id":"752275","poster":"roxsauromech","upvote_count":"3"},{"timestamp":"1680179520.0","upvote_count":"4","comment_id":"683553","content":"Selected Answer: D\nIt should be D","poster":"khushbu123"},{"upvote_count":"4","poster":"TimSss","content":"Selected Answer: D\nWrong. D is correct, entire doc is passed","comment_id":"682888","timestamp":"1680109500.0"}],"question_text":"You have an Azure Cosmos DB Core (SQL) API account.\nThe change feed is enabled on a container named invoice.\nYou create an Azure function that has a trigger on the change feed.\nWhat is received by the Azure function?","answer_description":"","timestamp":"2022-09-17 19:47:00"},{"id":"9HYgmO069pyPI1LxVrOK","answer_ET":"","answers_community":[],"url":"https://www.examtopics.com/discussions/microsoft/view/113273-exam-dp-420-topic-3-question-9-discussion/","timestamp":"2023-06-25 20:53:00","exam_id":69,"unix_timestamp":1687719180,"isMC":false,"answer":"","answer_images":["https://www.examtopics.com/assets/media/exam-media/04276/0008200005.jpg"],"answer_description":"Step 1: Create an Azure Cosmos DB core (SQL) API account\nStep 2: Enable Azure Synapse Link\nSynapse Link creates a tight seamless integration between Azure Cosmos DB and Azure Synapse Analytics.\nServerless SQL pool allows you to query and analyze data in your Azure Cosmos DB containers that are enabled with Azure Synapse Link. You can analyze data in near real-time without impacting the performance of your transactional workloads.\nStep 3: Create a database and a container that has Analytical store enabled\nCreate an analytical store enabled container\nReference:\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/configure-synapse-link","question_id":85,"question_text":"DRAG DROP -\nYou have an Azure Synapse Analytics workspace named workspace1 that contains a serverless SQL pool.\nYou have an Azure Table Storage account that stores operational data.\nYou need to replace the Table storage account with Azure Cosmos DB Core (SQL) API. The solution must meet the following requirements:\n✑ Support queries from the serverless SQL pool.\n✑ Only pay for analytical compute when running queries.\n✑ Ensure that analytical processes do NOT affect operational processes.\nWhich three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\nSelect and Place:\n//IMG//","question_images":["https://www.examtopics.com/assets/media/exam-media/04276/0008200004.jpg"],"topic":"3","discussion":[{"upvote_count":"5","poster":"azuredemo2022three","content":"Therefore, the correct sequence of actions is as follows:\n\n1. Create an Azure Cosmos DB Core (SQL) API account.\n2. Enable Azure Synapse Link.\n3. Create a database and a container that has Analytical store enabled.","timestamp":"1719341580.0","comment_id":"933826"}]}],"exam":{"isImplemented":true,"numberOfQuestions":147,"provider":"Microsoft","isBeta":false,"lastUpdated":"12 Apr 2025","name":"DP-420","id":69,"isMCOnly":false},"currentPage":17},"__N_SSP":true}