{"pageProps":{"questions":[{"id":"Ly4qdtMgYgnSthl1vmCA","url":"https://www.examtopics.com/discussions/microsoft/view/141754-exam-dp-203-topic-1-question-112-discussion/","question_id":16,"exam_id":67,"timestamp":"2024-06-02 16:31:00","question_text":"You have an Azure subscription that contains the resources shown in the following table.\n\n//IMG//\n\n\nYou need to implement Azure Synapse Link for Azure SQL Database.\n\nWhich two actions should you perform on sql1? Each correct answer presents a part of the solution.\n\nNOTE: Each correct selection is worth one point.","answer_ET":"AB","unix_timestamp":1717338660,"answer_images":[],"discussion":[{"upvote_count":"10","poster":"9b71f40","comment_id":"1223179","timestamp":"1717338660.0","content":"I think the given answers are correct, Please refer the below link\nhttps://learn.microsoft.com/en-us/azure/synapse-analytics/synapse-link/connect-synapse-link-sql-database","comments":[{"upvote_count":"4","poster":"Sr18","timestamp":"1718566020.0","content":"Indeed it will be AB.","comment_id":"1231513"}]},{"timestamp":"1733333640.0","poster":"17lan","comment_id":"1322035","upvote_count":"2","content":"Selected Answer: AB\nAgreed"},{"upvote_count":"3","content":"Selected Answer: AB\nAB ARE correct. for reference \nplease check \nhttps://learn.microsoft.com/en-us/azure/synapse-analytics/synapse-link/connect-synapse-link-sql-database","comment_id":"1302935","poster":"ff5037f","timestamp":"1729874460.0"},{"content":"To implement Azure Synapse Link for Azure SQL Database, you'll need to take the following actions on sql1:\n\nA. Update the firewall rules to allow Azure services to access sql1.\nThis is necessary because Azure Synapse Link requires the Azure Synapse workspace to be able to connect to the Azure SQL Database. Updating the firewall rules ensures that Azure services can access sql1.\n\nB. Enable the system-assigned managed identity.\nThis is important for security and authentication. The system-assigned managed identity allows Azure Synapse to authenticate to Azure SQL Database securely without needing to store credentials.\n\nSo, the correct actions are A and B.","poster":"babaksalarvand","timestamp":"1726389480.0","comment_id":"1283994","upvote_count":"1"},{"timestamp":"1725422400.0","comment_id":"1277939","upvote_count":"1","content":"Selected Answer: AC\nTo implement Azure Synapse Link for Azure SQL Database, you need to perform the following actions on sql1:\n\nUpdate the firewall rules to allow Azure services to access sql1.\nAssign the Contributor role to the system-assigned managed identity of workspace1 from the Access control (IAM) settings.","poster":"a85becd"},{"timestamp":"1723614840.0","comment_id":"1265520","upvote_count":"1","content":"Selected Answer: AC\ni think the answer is :\n A. Update the firewall rules to allow Azure services to access sql1.\nC. From the Access control (IAM) settings, assign the Contributor role to the system-assigned managed identity of workspace1.","poster":"NAWRESS96"}],"isMC":true,"answer":"AB","choices":{"B":"Enable the system-assigned managed identity.","D":"Disable Transparent Data Encryption (TDE).","A":"Update the firewall rules to allow Azure services to access sql1.","C":"From the Access control (IAM) settings, assign the Contributor role to the system-assigned managed identity of workspace1."},"topic":"1","answers_community":["AB (71%)","AC (29%)"],"answer_description":"","question_images":["https://img.examtopics.com/dp-203/image382.png"]},{"id":"2E0bhg3OYTZ5d9MXsF8S","answers_community":["C (100%)"],"answer":"C","choices":{"C":"3","B":"2","A":"1","D":"4"},"url":"https://www.examtopics.com/discussions/microsoft/view/141793-exam-dp-203-topic-1-question-113-discussion/","timestamp":"2024-06-03 07:47:00","answer_ET":"C","answer_images":[],"question_id":17,"isMC":true,"question_text":"You have an Azure subscription that contains an Azure Cosmos DB database. Azure Synapse Link is implemented on the database.\n\nYou configure a full fidelity schema for the analytical store.\n\nYou perform the following actions:\n\n• Insert {\"customerID\": 12, \"customer\": “Tailspin Toys\"} as the first document in the container.\n• Insert {\"customerID\": \"14\", \"customer\": \"Contoso\"} as the second document in the container.\n\nHow many columns will the analytical store contain?","topic":"1","exam_id":67,"unix_timestamp":1717393620,"question_images":[],"answer_description":"","discussion":[{"poster":"JamieMcD","comments":[{"timestamp":"1718566320.0","content":"Answer C","poster":"Sr18","comment_id":"1231514","upvote_count":"1"},{"timestamp":"1717655280.0","poster":"Sleuth","comment_id":"1225181","content":"The above explained is correct answer must be C. 3.\n12 and \"14\" being different datatypes will have separate columns in full fidelity schema.","upvote_count":"3"}],"comment_id":"1223439","timestamp":"1717393620.0","upvote_count":"10","content":"C - With a full fidelity schema, the analytical store will track both the data and their types accurately. This means different types for the same field will be stored in separate columns. Specifically:\n\nThere will be one column for customerID as an integer.\nThere will be another column for customerID as a string.\nThere will be one column for customer as a string."},{"timestamp":"1733339940.0","upvote_count":"1","comment_id":"1322057","content":"Selected Answer: C\nTotal Columns:\ncustomerID_Number: For the Integer type in the first document.\ncustomerID_String: For the String type in the second document.\ncustomer_String: For the consistent String type.\nTotal columns = 3","poster":"shinypriti23"},{"poster":"Okea","content":"Spark will manage each datatype as a column when loading into a DataFrame\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/analytical-store-introduction","timestamp":"1731569880.0","comment_id":"1311783","upvote_count":"1"},{"content":"Whats the actual answer? I thought B as two columns will be there, CustomerID and Customer. But I guess that C could be right as a third column is added for the Text \"14\" ??","upvote_count":"1","poster":"17c5d1e","comment_id":"1305005","timestamp":"1730294220.0"},{"upvote_count":"1","poster":"NAWRESS96","content":"Selected Answer: C\nBecause the customerID field appears with different data types (integer in the first and string in the second, the analytical store will treat these as separate columns to maintain the schema's fidelity.","timestamp":"1723624200.0","comment_id":"1265572"},{"poster":"Danweo","upvote_count":"1","timestamp":"1720884240.0","comment_id":"1247364","content":"Selected Answer: C\nC, a third column will be added for the change in datatype."}]},{"id":"JHuF6R73XLshrwT1LavQ","discussion":[{"upvote_count":"5","content":"Answer is correct see below link for more details on filepath() function\nhttps://learn.microsoft.com/en-us/azure/synapse-analytics/sql/query-specific-files#filepath","poster":"Sleuth","comment_id":"1225197","timestamp":"1717656060.0"},{"content":"SELECT\n r.filepath() AS filepath\n ,r.filepath(1) AS [year]\n ,r.filepath(2) AS [month]\n ,COUNT_BIG(*) AS [rows]\nFROM OPENROWSET(\n BULK 'csv/taxi/yellow_tripdata_*-*.csv',\n DATA_SOURCE = 'SqlOnDemandDemo',\n FORMAT = 'CSV',\n PARSER_VERSION = '2.0', \n FIRSTROW = 2\n )\nWITH (\n vendor_id INT\n) AS [r]\nWHERE\n r.filepath(1) IN ('2017')\n AND r.filepath(2) IN ('10', '11', '12')\nGROUP BY\n r.filepath()\n ,r.filepath(1)\n ,r.filepath(2)\nORDER BY\n filepath;","timestamp":"1719425880.0","poster":"CezarioAbrantesPP","comment_id":"1237688","upvote_count":"2"}],"answer_images":["https://img.examtopics.com/dp-203/image384.png"],"question_text":"HOTSPOT\n-\n\nYou have an Azure Data Lake Storage account that contains CSV files. The CSV files contain sales order data and are partitioned by using the following format.\n\n/data/salesorders/year=xxxx/month=y\n\nYou need to retrieve only the sales orders from January 2023 and February 2023.\n\nHow should you complete the query? To answer, select the appropriate options in the answer area.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","url":"https://www.examtopics.com/discussions/microsoft/view/141999-exam-dp-203-topic-1-question-114-discussion/","timestamp":"2024-06-06 08:41:00","answer":"","isMC":false,"question_images":["https://img.examtopics.com/dp-203/image383.png"],"question_id":18,"answer_description":"","answer_ET":"","exam_id":67,"unix_timestamp":1717656060,"answers_community":[],"topic":"1"},{"id":"8Er8cbsYGIkpdpWVoN0v","answer_ET":"","isMC":false,"topic":"1","answers_community":[],"answer_description":"","url":"https://www.examtopics.com/discussions/microsoft/view/156414-exam-dp-203-topic-1-question-115-discussion/","exam_id":67,"question_id":19,"discussion":[{"comment_id":"1365580","upvote_count":"1","timestamp":"1741206840.0","poster":"Rohit_0","content":"adl:// is the old protocol used by the Azure Data Lake Store (ADLS) Gen1. It was primarily used for accessing Azure Data Lake Store Gen1.\nSo it should be abfss://"},{"upvote_count":"2","content":"should be abfss:// ---> (Azure Blob File System Secure)","poster":"Pey1nkh","timestamp":"1739903520.0","comment_id":"1358407"},{"poster":"phant0mw0lf","content":"abfss ist correct due to the fact that it is a gen2 storage account and .dfs.core.windows.net is used as the location","comment_id":"1355791","timestamp":"1739392440.0","upvote_count":"1"}],"question_text":"HOTSPOT\n-\n\nYou have an Azure subscription that contains an Azure Data Lake Storage Gen2 account named adlsv2. adlsv2 contains a container named logs and an Azure Synapse Analytics dedicated SQL pool named Sqlpool.\n\nYou plan to use PolyBase to load external data into Sqlpool.\n\nYou need to define the external data source.\n\nHow should you complete the script? To answer, select the appropriate options in the answer area.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","question_images":["https://img.examtopics.com/dp-203/image392.png"],"answer_images":["https://img.examtopics.com/dp-203/image393.png"],"unix_timestamp":1739392440,"timestamp":"2025-02-12 21:34:00","answer":""},{"id":"4D6NBt9tPQpj9pvXm2wa","answer_ET":"B","isMC":true,"question_text":"You are developing a solution that will stream to Azure Stream Analytics. The solution will have both streaming data and reference data.\n\nWhich input type should you use for the reference data?","discussion":[{"comment_id":"1410196","poster":"HA29","upvote_count":"1","timestamp":"1742944620.0","content":"Selected Answer: B\nBlob storage and SQL Database are valid reference types"},{"upvote_count":"2","comment_id":"1358408","poster":"Pey1nkh","timestamp":"1739903640.0","content":"Selected Answer: B\nAzure Stream Analytics supports reference data from Azure Blob Storage, and the reference data is typically stored in CSV, JSON, or Parquet format."}],"timestamp":"2025-01-25 13:33:00","question_images":[],"answer_images":[],"answers_community":["B (100%)"],"choices":{"A":"Azure Service Bus","D":"Azure Event Hubs","B":"Azure Blob storage","C":"Azure IoT Hub"},"exam_id":67,"answer":"B","topic":"1","url":"https://www.examtopics.com/discussions/microsoft/view/155373-exam-dp-203-topic-1-question-116-discussion/","unix_timestamp":1737808380,"question_id":20,"answer_description":""}],"exam":{"provider":"Microsoft","isBeta":false,"id":67,"name":"DP-203","lastUpdated":"12 Apr 2025","isImplemented":true,"numberOfQuestions":384,"isMCOnly":false},"currentPage":4},"__N_SSP":true}