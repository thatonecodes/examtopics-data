{"pageProps":{"questions":[{"id":"A9mprNOO29mTfRmJGwsw","question_images":[],"answer_description":"","isMC":true,"answers_community":["CD (100%)"],"question_text":"You have an Azure Stream Analytics job.\nYou need to ensure that the job has enough streaming units provisioned.\nYou configure monitoring of the SU % Utilization metric.\nWhich two additional metrics should you monitor? Each correct answer presents part of the solution.\nNOTE: Each correct selection is worth one point.","topic":"3","answer_ET":"CD","exam_id":68,"unix_timestamp":1636839120,"discussion":[{"timestamp":"1669911900.0","poster":"stdevops","comment_id":"491799","content":"Selected Answer: CD\nwatermark and the number of backlogged events\nhttps://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-monitoring\nhttps://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-time-handling","upvote_count":"9"},{"comment_id":"1002819","poster":"ofzrgrz","content":"DP-203 question, you can skip.","upvote_count":"2","timestamp":"1725846180.0"},{"comment_id":"711737","upvote_count":"1","content":"Azure Stream Analytics is outside the scope of the DP-300 exam.","poster":"Ciupaz","timestamp":"1699186800.0"},{"poster":"cusman","upvote_count":"4","content":"DP-203","timestamp":"1680347040.0","comment_id":"579437"},{"timestamp":"1668375120.0","comment_id":"477769","upvote_count":"2","content":"its ok?","poster":"o2091"}],"question_id":156,"answer_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/65973-exam-dp-300-topic-3-question-14-discussion/","timestamp":"2021-11-13 22:32:00","answer":"CD","choices":{"A":"Late Input Events","D":"Watermark Delay","C":"Backlogged Input Events","E":"Function Events","B":"Out of order Events"}},{"id":"UgBlfIuLy0DvVpUmzCxR","choices":{"D":"SSH","C":"DBFS","E":"workspace","B":"jobs","A":"clusters"},"answer_ET":"A","answer_description":"","discussion":[{"poster":"ofzrgrz","timestamp":"1725846180.0","comment_id":"1002820","upvote_count":"1","content":"DP-203 question, you can skip."},{"content":"Selected Answer: A\nTo log actions that relate to changes in compute for an Azure Databricks resource, you should log the clusters service.","poster":"KIET2131","comment_id":"827616","timestamp":"1709434740.0","upvote_count":"3"},{"upvote_count":"2","content":"DataBricks are outside the scope of the DP-300 exam.","comment_id":"697228","timestamp":"1697534940.0","poster":"Ciupaz"},{"upvote_count":"3","timestamp":"1680347040.0","comment_id":"579438","poster":"cusman","content":"DP-203"},{"timestamp":"1668375180.0","upvote_count":"2","comment_id":"477770","poster":"o2091","content":"Answer looks correct"}],"topic":"3","question_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/65974-exam-dp-300-topic-3-question-15-discussion/","answer_images":[],"answers_community":["A (100%)"],"question_text":"You have an Azure Databricks resource.\nYou need to log actions that relate to changes in compute for the Databricks resource.\nWhich Databricks services should you log?","exam_id":68,"unix_timestamp":1636839180,"isMC":true,"question_id":157,"answer":"A","timestamp":"2021-11-13 22:33:00"},{"id":"GlQN74ZnWaY1HMO5Euy5","question_text":"Your company uses Azure Stream Analytics to monitor devices.\nThe company plans to double the number of devices that are monitored.\nYou need to monitor a Stream Analytics job to ensure that there are enough processing resources to handle the additional load.\nWhich metric should you monitor?","url":"https://www.examtopics.com/discussions/microsoft/view/65975-exam-dp-300-topic-3-question-16-discussion/","unix_timestamp":1636839180,"answer_description":"The Watermark delay metric is computed as the wall clock time of the processing node minus the largest watermark it has seen so far.\nThe watermark delay metric can rise due to:\n1. Not enough processing resources in Stream Analytics to handle the volume of input events.\n2. Not enough throughput within the input event brokers, so they are throttled.\n3. Output sinks are not provisioned with enough capacity, so they are throttled.\nReference:\nhttps://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-time-handling","answer":"D","timestamp":"2021-11-13 22:33:00","answers_community":[],"topic":"3","exam_id":68,"isMC":true,"discussion":[{"content":"DP-203 question, you can skip.","upvote_count":"1","poster":"ofzrgrz","timestamp":"1725846180.0","comment_id":"1002821"},{"poster":"Ciupaz","timestamp":"1697535000.0","comment_id":"697230","upvote_count":"1","content":"Stream Analytics is not part of the DP-300 exam."},{"content":"DP-203","comment_id":"579439","timestamp":"1680347040.0","upvote_count":"3","poster":"cusman"},{"comment_id":"477771","poster":"o2091","upvote_count":"1","content":"looks correct","timestamp":"1668375180.0"}],"answer_ET":"D","answer_images":[],"question_images":[],"choices":{"D":"Watermark delay","C":"Early Input Events","B":"Late Input Events","A":"Input Deserialization Errors"},"question_id":158},{"id":"Cn6MvIkvTz60dfDdhNq3","choices":{"B":"DWU percentage","D":"Cache hit percentage","A":"Local tempdb percentage","C":"Data Warehouse Units (DWU) used"},"answers_community":["D (100%)"],"question_text":"You manage an enterprise data warehouse in Azure Synapse Analytics.\nUsers report slow performance when they run commonly used queries. Users do not report performance changes for infrequently used queries.\nYou need to monitor resource utilization to determine the source of the performance issues.\nWhich metric should you monitor?","question_id":159,"unix_timestamp":1636638720,"answer_ET":"D","topic":"3","isMC":true,"discussion":[{"upvote_count":"2","comment_id":"1002822","content":"DP-203 question, you can skip.","poster":"ofzrgrz","timestamp":"1725846180.0"},{"content":"Answer: D\n\n\n// slow for frequent vs infrequent suggests issues with cache, so answer is D\n// tempdb does not care about frequent vs infrequent","timestamp":"1687528140.0","comment_id":"621027","poster":"Backy","upvote_count":"2"},{"comment_id":"579440","timestamp":"1680347100.0","poster":"cusman","upvote_count":"3","comments":[{"timestamp":"1694946720.0","content":"Yes, this question is for DP-203 exam.","upvote_count":"2","poster":"Ciupaz","comment_id":"671426"}],"content":"DP-203"},{"poster":"CaptainJameson","upvote_count":"4","comment_id":"566658","content":"Selected Answer: D\nCould be low cache hit ratio, because infrequent queries were already slower, so they don't notice any difference, but regular queries do now.\nCould also be tempdb as suggested, but then infrequent queries would also be affected depending on the query.\nOut of the options and unknowns, I would choose cache hit ratio.","timestamp":"1678699800.0"},{"comment_id":"477772","upvote_count":"2","timestamp":"1668375180.0","poster":"o2091","content":"Is D correct?"},{"poster":"ss1516","upvote_count":"4","timestamp":"1668174720.0","comments":[{"poster":"kutty09","content":"Frequent queries performance is also slow so D is wrong I think.","timestamp":"1678797780.0","comment_id":"567637","upvote_count":"1"},{"content":"If the cache hit ratio is low, it means that new or infrequent queries last a short time in the cache and their performance would be bad, but these types of queries have no problems. Therefore answer D is not correct","comment_id":"495689","timestamp":"1670395680.0","comments":[{"comment_id":"645937","upvote_count":"2","poster":"Backy","content":"The question does not say that \"infrequent queries\" are good or fast. It says that infrequent queries are unchanged. The issue is that the frequent queries are slower than before, meaning there are more infrequent queries now or they are more bunched together than before and fill up the cache before the frequent queries have a chance to run. Low cache hit would show it. The solution is a bigger cache or change the run patterns","timestamp":"1691850000.0"}],"poster":"quermi","upvote_count":"3"}],"comment_id":"476243","content":"D is correct.\nhttps://docs.microsoft.com/da-dk/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-how-to-monitor-cache"}],"timestamp":"2021-11-11 14:52:00","exam_id":68,"answer_images":[],"question_images":[],"answer":"D","url":"https://www.examtopics.com/discussions/microsoft/view/65835-exam-dp-300-topic-3-question-17-discussion/","answer_description":""},{"id":"VFgl5Veqy0m3rWi3fEG1","question_text":"You have an Azure Synapse Analytics dedicated SQL pool named Pool1 and a database named DB1. DB1 contains a fact table named Table.\nYou need to identify the extent of the data skew in Table1.\nWhat should you do in Synapse Studio?","url":"https://www.examtopics.com/discussions/microsoft/view/62200-exam-dp-300-topic-3-question-18-discussion/","unix_timestamp":1631796240,"answer_description":"","answer":"A","timestamp":"2021-09-16 14:44:00","answers_community":["A (100%)"],"topic":"3","isMC":true,"exam_id":68,"discussion":[{"upvote_count":"8","comments":[{"poster":"Dasist","upvote_count":"4","timestamp":"1663869600.0","content":"It is A.","comment_id":"449665"}],"poster":"Silus","content":"I think the correct answer is A, not D. Don't we have to connect to the dedicated pool to query the stats. DB1 is in a dedicated pool","timestamp":"1663332240.0","comment_id":"445932"},{"comment_id":"520465","upvote_count":"6","content":"Selected Answer: A\nA is the correct answer.","poster":"Lucky_me","timestamp":"1673298120.0"},{"content":"DP-203 question, you can skip.","poster":"ofzrgrz","upvote_count":"3","comment_id":"1002823","timestamp":"1725846180.0"},{"comment_id":"718730","timestamp":"1700053560.0","upvote_count":"1","content":"DP-203 question.","poster":"Ciupaz"},{"content":"This question is not part of DP-300 exam.","poster":"Ciupaz","upvote_count":"1","comment_id":"711886","timestamp":"1699202520.0"},{"timestamp":"1682864160.0","upvote_count":"2","content":"Selected Answer: A\nUse sys.dm_pdw_nodes_db_partition_stats to analyze any skewness in the data.","poster":"eric0718","comment_id":"595070"},{"poster":"cusman","content":"DP-203","upvote_count":"3","comment_id":"579441","timestamp":"1680347100.0"},{"comment_id":"554005","content":"Selected Answer: A\nThe table is in Pool1 not the serverless pool","timestamp":"1677099420.0","poster":"AlCubeHead","upvote_count":"2"},{"content":"Selected Answer: A\nOption A","upvote_count":"4","poster":"VinayakBudapanahalli","timestamp":"1674453720.0","comment_id":"530285"},{"content":"The answer is ok. tou runt the dmv over the database, no in the SQL Pool.\nTo call this from Azure Synapse Analytics or Analytics Platform System (PDW), use the name sys.dm_pdw_nodes_db_partition_stats. The partition_id in sys.dm_pdw_nodes_db_partition_stats differs from the partition_id in the sys.partitions catalog view for Azure Synapse Analytics. This syntax is not supported by serverless SQL pool in Azure Synapse\nhttps://docs.microsoft.com/en-us/sql/relational-databases/system-dynamic-management-views/sys-dm-db-partition-stats-transact-sql?view=sql-server-ver15","comment_id":"478003","timestamp":"1668413820.0","poster":"quermi","upvote_count":"2"}],"answer_ET":"A","answer_images":[],"question_images":[],"choices":{"D":"Connect to the built-in pool and query sys.dm_pdw_nodes_db_partition_stats.","A":"Connect to Pool1 and query sys.dm_pdw_nodes_db_partition_stats.","C":"Connect to Pool1 and run DBCC CHECKALLOC.","B":"Connect to the built-in pool and run DBCC CHECKALLOC."},"question_id":160}],"exam":{"name":"DP-300","isImplemented":true,"lastUpdated":"12 Apr 2025","numberOfQuestions":360,"isMCOnly":false,"isBeta":false,"id":68,"provider":"Microsoft"},"currentPage":32},"__N_SSP":true}