{"pageProps":{"questions":[{"id":"1l9pgQ9MhfcEoh3aVDJT","exam_id":39,"answer_description":"Box 1: Azure Cognitive Services -\nAzure Cognitive Services include image-processing algorithms to smartly identify, caption, index, and moderate your pictures and videos.\nNot: Azure Linguistic Analytics API, which provides advanced natural language processing over raw text.\n\nBox 2: Azure Data Factory -\nThe Azure Data Factory (ADF) is a service designed to allow developers to integrate disparate data sources. It is a platform somewhat like SSIS in the cloud to manage the data you have both on-prem and in the cloud.\nIt provides access to on-premises data in SQL Server and cloud data in Azure Storage (Blob and Tables) and Azure SQL Database.\nReference:\nhttps://azure.microsoft.com/en-us/services/cognitive-services/ https://www.jamesserra.com/archive/2014/11/what-is-azure-data-factory/","answers_community":[],"discussion":[{"comments":[{"poster":"Y2Data","comment_id":"355181","upvote_count":"2","content":"Same, why would you not use Data Factory?","timestamp":"1620786600.0"},{"content":"why not Data Factory?","upvote_count":"1","poster":"DonGeo","timestamp":"1620589080.0","comment_id":"353239"},{"timestamp":"1621936140.0","comments":[{"comment_id":"389229","content":"Beceause it says: \"Upload the data to the database\" and not \"The database to store the image in\". Soooo... what would you probably use to \"upload\" the data. I think Wesley0312 is right.","upvote_count":"1","timestamp":"1624511340.0","poster":"dynamicJames"}],"comment_id":"366297","upvote_count":"2","content":"You cannot use azure functions to store data in. It's not a database, rather it's serverless code to help applications running.\n\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-overview","poster":"allanm"}],"timestamp":"1619932080.0","upvote_count":"5","content":"Azure Cognitive Service and Azure Functions","poster":"Wesley0312","comment_id":"347414"},{"upvote_count":"1","poster":"dev2dev","timestamp":"1673789400.0","content":"The criteria is to reduce infrastructure costs. So functions app would be the choice.","comment_id":"776591"},{"comment_id":"362041","upvote_count":"2","poster":"fhqhfhqh","content":"This question was in the exam.","timestamp":"1621506120.0"}],"url":"https://www.examtopics.com/discussions/microsoft/view/51486-exam-ai-100-topic-1-question-1-discussion/","topic":"1","unix_timestamp":1619932080,"isMC":false,"answer_ET":"","answer":"","question_text":"HOTSPOT -\nYou are designing an application to parse images of business forms and upload the data to a database. The upload process will occur once a week.\nYou need to recommend which services to use for the application. The solution must minimize infrastructure costs.\nWhich services should you recommend? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","question_id":1,"question_images":["https://www.examtopics.com/assets/media/exam-media/03857/0000200001.jpg"],"answer_images":["https://www.examtopics.com/assets/media/exam-media/03857/0000300001.jpg"],"timestamp":"2021-05-02 07:08:00"},{"id":"xpgbK655NerVE3QFsXkd","answer":"ABC","topic":"1","url":"https://www.examtopics.com/discussions/microsoft/view/22547-exam-ai-100-topic-1-question-10-discussion/","question_text":"You deploy an infrastructure for a big data workload.\nYou need to run Azure HDInsight and Microsoft Machine Learning Server. You plan to set the RevoScaleR compute contexts to run rx function calls in parallel.\nWhat are three compute contexts that you can use for Machine Learning Server? Each correct answer presents a complete solution.\nNOTE: Each correct selection is worth one point.","isMC":true,"answer_ET":"ABC","exam_id":39,"answers_community":[],"answer_images":[],"discussion":[{"content":"I think A,B,C is correct. In this link https://docs.microsoft.com/en-us/machine-learning-server/r/concept-what-is-compute-context , it is indicated which RevoSvaleR compute context are available, which are local, spark, sqlserver, localpar, dopar. If you are going to run R script from an Edge, the possible values of the context are: local sequential, local parallel, Map Reduce and Spark. https://docs.microsoft.com/en-us/azure/hdinsight/r-server/r-server-compute-contexts.","comment_id":"110659","upvote_count":"7","poster":"damirbek369","timestamp":"1592208900.0","comments":[{"upvote_count":"2","comment_id":"248417","timestamp":"1608446400.0","content":"if based on your last link given https://docs.microsoft.com/en-us/azure/hdinsight/r-server/r-server-compute-contexts , the correct option should be Spark, Local Parallel & Local Sequential . Answer should be B, C, E right?","poster":"robotcop"}]},{"content":"the three compute contexts you can use for Machine Learning Server to run rx function calls in parallel are B. Spark, C. local parallel, and E. local sequential.","timestamp":"1687182900.0","upvote_count":"1","comment_id":"927570","poster":"rveney"},{"comment_id":"430743","poster":"gameoflove","content":"The correct one is B,C and E because he is processing BIg data on HD insight. https://docs.microsoft.com/en-us/azure/hdinsight/r-server/r-server-compute-contexts","timestamp":"1629807960.0","upvote_count":"1"},{"comments":[{"comment_id":"267523","timestamp":"1610669520.0","content":"That's because the documentation for compute context for an edge node says Local sequential does parallelized execution. However, I found this: https://docs.microsoft.com/en-us/machine-learning-server/r-reference/revoscaler/revoscaler#7-compute-context-functions\n\nNo one posted this link but I think it is the right one to refer here for RevoScaleR.\n\nIt does list Spark and Parallel clearly. But doesn't say Parallel execution for SQL and LocalSeq. Since LocalSeq does say \"sequential computations\" so I'm going with given answer:\nSQL, Local parallel and Spark.\nA, B, C","upvote_count":"4","poster":"Cornholioz"}],"poster":"aitruthseeker","timestamp":"1609996680.0","upvote_count":"2","content":"\"You plan to set the RevoScaleR compute contexts to run rx function calls in PARALLEL.\"\nYet people Say E instead of A","comment_id":"261549"},{"comment_id":"257983","upvote_count":"2","timestamp":"1609627080.0","content":"The Answer is wrong. The correct one is B,C and E because he is processing BIg data on HD insight. https://docs.microsoft.com/en-us/azure/hdinsight/r-server/r-server-compute-contexts\nBut if he was working on small data then the answer will be A, B, and C( although I am not sure about C in the small data case)\nhttps://docs.microsoft.com/en-us/machine-learning-server/r/tutorial-rxexecby","poster":"nohaph"},{"upvote_count":"1","content":"ABC is correct","poster":"Anirudh2020","timestamp":"1605175020.0","comment_id":"217819"},{"content":"correct answer is ABC","comment_id":"133312","upvote_count":"3","timestamp":"1594594920.0","poster":"ammarkareem"},{"content":"B,C,E seems right","poster":"jikku","upvote_count":"1","comment_id":"105024","timestamp":"1591589820.0"}],"question_id":2,"answer_description":"Remote computing is available for specific data sources on selected platforms. The following tables document the supported combinations.\n✑ RxInSqlServer, sqlserver: Remote compute context. Target server is a single database node (SQL Server 2016 R Services or SQL Server 2017 Machine\nLearning Services). Computation is parallel, but not distributed.\n✑ RxSpark, spark: Remote compute context. Target is a Spark cluster on Hadoop.\n✑ RxLocalParallel, localpar: Compute context is often used to enable controlled, distributed computations relying on instructions you provide rather than a built-in scheduler on Hadoop. You can use compute context for manual distributed computing.\nReferences:\nhttps://docs.microsoft.com/en-us/machine-learning-server/r/concept-what-is-compute-context","question_images":[],"timestamp":"2020-06-08 06:17:00","choices":{"E":"local sequential","B":"Spark","C":"local parallel","A":"SQL","D":"HBase"},"unix_timestamp":1591589820},{"id":"rpw3RH8ReW7Ag6m11QLT","isMC":true,"exam_id":39,"choices":{"E":"Azure Policy","B":"Azure service principals","C":"Azure managed identities","A":"Azure Key Vault","D":"Azure Security Center"},"question_text":"Your company has 1,000 AI developers who are responsible for provisioning environments in Azure.\nYou need to control the type, size, and location of the resources that the developers can provision.\nWhat should you use?","url":"https://www.examtopics.com/discussions/microsoft/view/3345-exam-ai-100-topic-1-question-11-discussion/","answer_ET":"B","answer_description":"When an application needs access to deploy or configure resources through Azure Resource Manager in Azure Stack, you create a service principal, which is a credential for your application. You can then delegate only the necessary permissions to that service principal.\nReferences:\nhttps://docs.microsoft.com/en-us/azure/azure-stack/azure-stack-create-service-principals","unix_timestamp":1565203980,"topic":"1","answers_community":["E (100%)"],"question_images":[],"question_id":3,"timestamp":"2019-08-07 20:53:00","discussion":[{"content":"Should be policy. This is what allows you to restrict resources that are created in groups.","comment_id":"6271","timestamp":"1565203980.0","upvote_count":"51","poster":"exam_taker5","comments":[{"upvote_count":"4","content":"Correct","timestamp":"1567220220.0","comment_id":"9059","poster":"CodeAnant"}]},{"upvote_count":"5","comments":[{"comment_id":"270514","upvote_count":"1","content":"Eh no, location etc can also be controlled by Azure Policy.","poster":"danflr","timestamp":"1610995020.0"}],"timestamp":"1593969000.0","poster":"mhmad9992","content":"It is a tricky question !! I think the answer is service Principle WHY? Because the question says to control location and size ..ETC. so first you need to create a service account for developers then you hse azure policy to apply rules on this account.","comment_id":"127044"},{"poster":"rveney","timestamp":"1687182960.0","content":"To control the type, size, and location of the resources that AI developers can provision in Azure, you should use E. Azure Policy.","upvote_count":"1","comment_id":"927571"},{"timestamp":"1654694880.0","content":"Selected Answer: E\nazure policy","poster":"ajiejeng","upvote_count":"1","comment_id":"613289"},{"timestamp":"1616720160.0","comment_id":"320655","poster":"Jeb","content":"The correct answer is E in terms of \"control\"","upvote_count":"1"},{"comment_id":"294548","content":"A service principal must be created in each tenant where the application is used, enabling it to establish an identity for sign-in a... You need to provision resources to a large number- Azure Policy is the best answer","timestamp":"1613761020.0","poster":"DANIEL","upvote_count":"1"},{"timestamp":"1611119940.0","comment_id":"271757","content":"This must be Azure Policy. Overview of Azure Policy clearly talks about all three:\nhttps://docs.microsoft.com/en-us/azure/governance/policy/overview","poster":"San_S","upvote_count":"1"},{"timestamp":"1610670420.0","upvote_count":"1","content":"The question is clear and it speaks about provisioning the infra and not about the access related to infra. \"You need to control the type, size, and location of the resources that the developers can provision.\" It speaks about controlling the type, size and location of the resources that developers can provision. Azure policies can control the type size and location for an infra that will be provisioned. This can be provisioned by any user, but what control the infra attributes are the policies. The service principles are only for authentication purpose and they don't enforce such policies. Hence the answer is Azure Policy.","comment_id":"267529","poster":"srinathparam"},{"comment_id":"266779","poster":"UpsetUser","content":"This is tricky,, Def Policy comes in mind at first, But hold on,,,, \n For specific only 1000 AI deveoplers ,, since all of them will be having same set of permissions.,,, \n\nSo all of those who are saying policy,,,, where are you going to attach that policy (JSON )..???\n\nSo, Therefore the best way is to create Azure service principal to which role is assigned using which every AI developer has to login...and on that Role,, policy can be attached. \n\nSo correct answer is B.","timestamp":"1610606940.0","upvote_count":"1"},{"timestamp":"1609997220.0","poster":"aitruthseeker","upvote_count":"1","comment_id":"261554","content":"Azure Policy seems to be the correct answer here. The answer solution doesn't seem to be aligned with the question. \n\nIn Azure Policy, we offer several built-in policies that are available by default. For example:\n\nAllowed Storage Account SKUs (Deny): Determines if a storage account being deployed is within a set of SKU sizes. Its effect is to deny all storage accounts that don't adhere to the set of defined SKU sizes.\n\"Allowed Resource Type (Deny): Defines the resource types that you can deploy. Its effect is to deny all resources that aren't part of this defined list.\nAllowed Locations (Deny): Restricts the available locations for new resources. Its effect is used to enforce your geo-compliance requirements.\nAllowed Virtual Machine SKUs (Deny): Specifies a set of virtual machine SKUs that you can deploy.\nAdd a tag to resources (Modify): Applies a required tag and its default value if it's not specified by the deploy request.\"\nCheck this link and watch the 23 min video on Azure Policy: \nhttps://docs.microsoft.com/en-us/azure/governance/policy/overview"},{"timestamp":"1609997100.0","upvote_count":"1","content":"Azure Policy seems to be the correct answer here. The answer solution doesn't seem to be aligned with the question. \nCheck this link and watch the 23 min video on Azure Policy: https://docs.microsoft.com/en-us/azure/governance/policy/overview","comment_id":"261552","poster":"aitruthseeker"},{"timestamp":"1608822720.0","poster":"valar_morghulis","upvote_count":"2","comment_id":"251629","content":"AZURE POLICY is the correct answer."},{"upvote_count":"1","comment_id":"217820","content":"Should be policy","poster":"Anirudh2020","timestamp":"1605175260.0"},{"poster":"combinatronix","timestamp":"1604820900.0","content":"It seems that Azure service principals has such capabilities.\n\nWhy are people saying it should only be policy if based here (https://docs.microsoft.com/en-us/azure-stack/operator/azure-stack-create-service-principals?view=azs-2005&pivots=state-disconnected):\n\n\" Just as a user is represented by a security principal called a user principal, an app is represented by a service principal. The service principal provides an identity for your app, allowing you to delegate only the necessary permissions to the app.\n\nAs an example, you may have a configuration management app that uses Azure Resource Manager to inventory Azure resources. In this scenario, you can create a service principal, grant the \"reader\" role to that service principal, and limit the configuration management app to read-only access.\"","upvote_count":"2","comment_id":"215087"},{"comment_id":"184225","content":"Azure Policy https://docs.microsoft.com/en-us/azure/governance/policy/overview#policy-definition","timestamp":"1600754580.0","poster":"sayak17","upvote_count":"1"},{"poster":"Nova077","upvote_count":"1","timestamp":"1599396600.0","content":"This should be policy.","comment_id":"174556"},{"timestamp":"1592897400.0","comment_id":"117173","content":"No doubt. It is Azure Policy.","poster":"fred777","upvote_count":"1"},{"comment_id":"110661","upvote_count":"4","comments":[{"comment_id":"267532","content":"Because everyone here only THINKS they know the correct answer. You and I are no exceptions. You \"think\" Azure Policy is the answer and I \"think\" it could be Azure Service Principal because you cannot attach a policy so easily but you can apply the Principal to the 1000 developers and then apply the policy on that Principal.","timestamp":"1610671020.0","poster":"Cornholioz","upvote_count":"1"}],"content":"I also think it is Azure Policy. The question to Moderators: Why don't they correct the wrong answers, once they are pointed out in the discussions?","timestamp":"1592209080.0","poster":"damirbek369"},{"upvote_count":"3","content":"Azure Policy is the only choice here","comment_id":"77350","timestamp":"1587456960.0","poster":"Atanu"},{"content":"The correct answer is Azure Policy as it's asking for controlling the location, size and type of resources.\nFrom Microsoft Docs: \n'Azure Policy controls properties such as the types or locations of resources. Unlike RBAC, Azure Policy is a default allow and explicit deny system.'\n\nReference: \nhttps://docs.microsoft.com/en-us/azure/governance/policy/overview","upvote_count":"4","comment_id":"75238","poster":"Mfweuydg","timestamp":"1587029160.0"},{"timestamp":"1586272980.0","upvote_count":"1","comment_id":"72162","content":"The answer to this question may be either to assign a policy or to use service principals.","poster":"Miles19"},{"comment_id":"46135","timestamp":"1580730660.0","content":"It is Azure Policy... as mentioned by exam_Taker5\nhttps://docs.microsoft.com/en-us/azure/governance/policy/overview","upvote_count":"4","poster":"K7P"},{"poster":"ab6664","timestamp":"1576504260.0","content":"No, it should be on environment-service-. hence service principal","upvote_count":"1","comment_id":"30083"},{"timestamp":"1576211640.0","comments":[{"upvote_count":"1","content":"Even on environments? Re: below comment.","poster":"Exposer","timestamp":"1577871120.0","comment_id":"34174"}],"content":"It has to be Azure policy: https://docs.microsoft.com/en-us/azure/governance/policy/overview","upvote_count":"1","comment_id":"29217","poster":"Ubaid"},{"upvote_count":"4","content":"Agreed with exam_taker5","timestamp":"1566928620.0","comment_id":"8610","poster":"Bharat"}],"answer":"E","answer_images":[]},{"id":"pK1EE7JWwNWBOSrnb1eX","timestamp":"2020-03-10 15:28:00","discussion":[{"upvote_count":"6","content":"FPGAs is correct because of the following line from the docs Piraat linked:\n\n\"FPGAs make it possible to achieve low latency for real-time inference (or model scoring) requests. Asynchronous requests (batching) aren't needed. Batching can cause latency, because more data needs to be processed. Implementations of neural processing units don't require batching; therefore the latency can be many times lower, compared to CPU and GPU processors.\"","timestamp":"1593703380.0","comment_id":"125138","poster":"samok"},{"poster":"Piraat","content":"relevant: https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-fpga-web-service","comment_id":"61743","timestamp":"1583850480.0","upvote_count":"5"},{"poster":"rveney","timestamp":"1687183020.0","comment_id":"927573","upvote_count":"1","content":"To ensure the ability to update the logic over time, while maintaining low latency for inferencing without the need for batching in an image classification AI solution, the compute target you should identify is C. central processing units (CPUs)."},{"comment_id":"174565","content":"https://www.aldec.com/en/company/blog/167--fpgas-vs-gpus-for-machine-learning-applications-which-one-is-better#:~:text=Efficiency%20and%20Power%3A%20FPGAs%20are,times%20better%20in%20power%20consumption.&text=This%20feature%20allows%20GPUs%20to%20be%20more%20power%20efficient%20than%20CPUs.\n\nThis document suggests that FPGAs are mostly used where functional safety plays a very important role such as automation, avionics and defense. \nGPUs are originally designed for graphics and high-performance computing systems where safety is not a necessity. GPU is also made for Graphics. It's true that FPGAs are a bit more powerful than GPU, since its graphics and image classification, I wonder if the answer will be GPU","upvote_count":"1","poster":"Nova077","timestamp":"1599397020.0"}],"exam_id":39,"topic":"1","question_text":"You are designing an AI solution in Azure that will perform image classification.\nYou need to identify which processing platform will provide you with the ability to update the logic over time. The solution must have the lowest latency for inferencing without having to batch.\nWhich compute target should you identify?","answer_description":"FPGAs, such as those available on Azure, provide performance close to ASICs. They are also flexible and reconfigurable over time, to implement new logic.\nIncorrect Answers:\nD: ASICs are custom circuits, such as Google's TensorFlow Processor Units (TPU), provide the highest efficiency. They can't be reconfigured as your needs change.\nReferences:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/service/concept-accelerate-with-fpgas","unix_timestamp":1583850480,"url":"https://www.examtopics.com/discussions/microsoft/view/16113-exam-ai-100-topic-1-question-12-discussion/","isMC":true,"question_images":[],"answer":"B","choices":{"A":"graphics processing units (GPUs)","D":"application-specific integrated circuits (ASICs)","B":"field-programmable gate arrays (FPGAs)","C":"central processing units (CPUs)"},"question_id":4,"answers_community":[],"answer_ET":"B","answer_images":[]},{"id":"PGkSVVQ4Q5Usb4QQBaVu","discussion":[{"upvote_count":"9","poster":"SamSmith","comment_id":"75062","timestamp":"1586985060.0","content":"A seems to be correct. See here - https://github.com/Azure/AKS/issues/52"},{"content":"To maintain the cluster configuration and avoid incurring compute costs when the Azure Kubernetes Service (AKS) cluster is not in use, the recommended solution would be to B. \nDownscale the cluster to zero nodes.\n\nBy downscaling the cluster to zero nodes, you effectively stop all the virtual machines (VMs) in the cluster. This allows you to maintain the cluster configuration and associated resources (such as networking, storage, and security settings) without incurring any compute costs.\n\nWhen the cluster is not in use, scaling it down to zero nodes ensures that no resources are actively consuming compute capacity, which helps optimize costs. This approach allows you to easily bring the cluster back online when needed without the need to recreate or reconfigure it.","poster":"rveney","comment_id":"927576","upvote_count":"1","timestamp":"1687183140.0"},{"comment_id":"386052","upvote_count":"1","poster":"dr_rabbit","content":"System pools must contain at least one node, and user node pools may contain zero or more nodes. See https://docs.microsoft.com/en-us/azure/aks/use-multiple-node-pools","timestamp":"1624174860.0"},{"upvote_count":"1","comment_id":"273490","timestamp":"1611294960.0","content":"Correct hai","poster":"Hotjo"},{"upvote_count":"1","poster":"aitruthseeker","content":"Azure Batch AI is retired. \nhttps://docs.microsoft.com/en-us/previous-versions/azure/batch-ai/overview-what-happened-batch-ai\n\nAs for the answer, Downscaling to 0 would probably remove the node configuration, whereas we have to keep the node configuration.","comment_id":"261558","timestamp":"1609997640.0"},{"upvote_count":"2","content":"Azure Batch AI is retired since early 2019, I doubt this question still applies","timestamp":"1604608920.0","poster":"noonereallyknows","comment_id":"213692"},{"timestamp":"1599712860.0","comments":[{"content":"steps to do it https://docs.microsoft.com/en-us/azure/aks/scale-cluster#scale-user-node-pools-to-0","timestamp":"1603678920.0","poster":"sayak17","comment_id":"205968","upvote_count":"1"}],"upvote_count":"3","content":"downscaling(not autoscaling) to 0 nodes is now supported in aks. See this: https://github.com/Azure/AKS/issues/52#issuecomment-660897690","poster":"sayak17","comment_id":"176890"},{"poster":"AllenBorder","upvote_count":"1","content":"Currently AKS supports at least 1 system node and 0 or more user nodes. So, what should be the correct answer?","timestamp":"1598616960.0","comment_id":"168415"},{"comment_id":"62294","upvote_count":"2","poster":"Piraat","content":"With the source provided, shouldn't it be 0 nodes? Or is the controle plane counted as a node?","timestamp":"1583909700.0"},{"timestamp":"1581311160.0","content":"Seems to be correct","comment_id":"48586","poster":"Monika","upvote_count":"3"}],"isMC":true,"question_images":[],"question_id":5,"url":"https://www.examtopics.com/discussions/microsoft/view/13711-exam-ai-100-topic-1-question-13-discussion/","topic":"1","unix_timestamp":1581311160,"answer_images":[],"answer_ET":"A","answer":"A","answers_community":[],"timestamp":"2020-02-10 06:06:00","exam_id":39,"choices":{"C":"Delete the cluster","B":"Downscale the cluster to zero nodes","A":"Downscale the cluster to one node"},"answer_description":"An AKS cluster has one or more nodes.\nReferences:\nhttps://docs.microsoft.com/en-us/azure/aks/concepts-clusters-workloads","question_text":"You have a solution that runs on a five-node Azure Kubernetes Service (AKS) cluster. The cluster uses an N-series virtual machine.\nAn Azure Batch AI process runs once a day and rarely on demand.\nYou need to recommend a solution to maintain the cluster configuration when the cluster is not in use. The solution must not incur any compute costs.\nWhat should you include in the recommendation?"}],"exam":{"isBeta":false,"name":"AI-100","id":39,"lastUpdated":"12 Apr 2025","numberOfQuestions":206,"provider":"Microsoft","isImplemented":true,"isMCOnly":false},"currentPage":1},"__N_SSP":true}