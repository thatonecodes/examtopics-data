{"pageProps":{"questions":[{"id":"BGndDDffZvK9bNVU2oBN","answer_description":"","timestamp":"2023-05-24 10:39:00","answer_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/110101-exam-ai-102-topic-3-question-39-discussion/","answers_community":["AC (91%)","9%"],"answer":"AC","isMC":true,"question_images":[],"answer_ET":"AC","exam_id":40,"unix_timestamp":1684917540,"choices":{"A":"From the language authoring REST endpoint, retrieve the model evaluation summary.","B":"From Language Studio, enable Active Learning, and then validate the utterances logged for review.","C":"From Language Studio, select Model performance.","D":"From the Azure portal, enable log collection in Log Analytics, and then analyze the logs."},"discussion":[{"timestamp":"1686439320.0","comment_id":"920308","content":"Selected Answer: AC\nagree with SmallFire:\nActive Learning cannot be initiated prior to the deployment of the model. The primary purpose of the 'Active Learning' feature is to leverage actual user interaction data to enhance the model's understanding capabilities. This is a continuous learning and optimization process that takes place after the model has been deployed and put into actual use.\nso the answer is AC.","poster":"ziggy1117","upvote_count":"13"},{"content":"Selected Answer: AC\nFrom the Azure AI language authoring REST endpoint, retrieve the model evaluation summary is CORRECT because this method allows you to programmatically access the evaluation metrics and performance summary of your trained Conversational Language Understanding model.\n\nFrom Language Studio, select Model performance is CORRECT because this option provides a graphical interface within Language Studio to review and assess the performance metrics of your model, such as accuracy, precision, recall, and F1 score.\n\nA and C","poster":"syupwsh","upvote_count":"1","timestamp":"1739181840.0","comment_id":"1354397"},{"poster":"anto69","upvote_count":"1","timestamp":"1723644300.0","content":"Selected Answer: AC\nA-C\nChatGPT still think that B is better than A, but this time I'm not agree","comment_id":"1265814"},{"timestamp":"1719052620.0","poster":"reiwanotora","upvote_count":"2","content":"Selected Answer: AC\nREST endpoint\nselect Model performance","comment_id":"1235328"},{"upvote_count":"1","timestamp":"1719037500.0","poster":"HaraTadahisa","comment_id":"1235195","content":"Selected Answer: AC\nI say this answer is A and C."},{"timestamp":"1718201760.0","upvote_count":"1","poster":"reigenchimpo","content":"Selected Answer: AC\nAC is answer.","comment_id":"1229223"},{"poster":"takaimomoGcup","upvote_count":"2","timestamp":"1716387360.0","comment_id":"1215796","content":"Selected Answer: AC\nREST and model performance."},{"timestamp":"1706340900.0","poster":"evangelist","comment_id":"1133134","upvote_count":"3","content":"Selected Answer: AC\nA. From the language authoring REST endpoint, retrieve the model evaluation summary.\nThis summary typically includes metrics like precision, recall, and accuracy, which are crucial for evaluating the effectiveness of a language understanding model.\nC. From Language Studio, select Model performance.\nIn Language Studio, the Model performance section typically provides detailed analytics about the model's performance, including various metrics and possibly confusion matrices."},{"timestamp":"1699184460.0","upvote_count":"3","comment_id":"1062828","content":"Selected Answer: AC\nIMHO correct answers are:\nA. --> https://learn.microsoft.com/en-us/rest/api/language/conversational-analysis-authoring/get-model-evaluation-summary?view=rest-language-2023-04-01&tabs=HTTP\n\nC. --> https://learn.microsoft.com/en-us/azure/ai-services/language-service/conversational-language-understanding/how-to/view-model-evaluation?tabs=Language-studio%2Cmodel-performance","poster":"rdemontis"},{"comment_id":"1043622","timestamp":"1697302320.0","content":"Selected Answer: AC\nIf you look closely, you can see that the Model performance feature in Language Studio is about evaluating the performance of the model using test data as opposed to active learning which is using the real data from users’ interactions, which you couldn’t do prior to the deployment. My only pet peeve is that rest endpoint never works for me - always giving me the 404 no matter what.","upvote_count":"1","poster":"sl_mslconsulting"},{"comment_id":"1006120","upvote_count":"2","timestamp":"1694568300.0","poster":"jangotango","content":"AC are correct - https://learn.microsoft.com/en-us/rest/api/language/2022-10-01-preview/text-analysis-authoring/get-model-evaluation-summary?tabs=HTTP"},{"timestamp":"1688010900.0","content":"Selected Answer: AC\nAC is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/language-service/conversational-language-understanding/how-to/view-model-evaluation?tabs=Language-studio%2Cmodel-performance","upvote_count":"4","poster":"zellck","comment_id":"937455"},{"poster":"EliteAllen","content":"Selected Answer: BC\nB. Active Learning in Language Studio is a feature that helps improve the performance of your model by suggesting utterances for you to review and label. This can help you evaluate the accuracy of your model by seeing how it performs on these suggested utterances.\n\nC. The Model performance feature in Language Studio provides a detailed report on the performance of your model, including precision, recall, and F1 score. This can give you a good indication of the accuracy of your model.\n\nOption A is incorrect because the language authoring REST endpoint does not provide a model evaluation summary.","upvote_count":"2","timestamp":"1686752760.0","comment_id":"923293","comments":[{"timestamp":"1692606540.0","comment_id":"986323","upvote_count":"2","poster":"hawkzey","content":"B is not correct as you cant not do active learning on a model that is not yet deployed"}]},{"upvote_count":"4","comment_id":"910814","content":"Active Learning cannot be initiated prior to the deployment of the model. The primary purpose of the 'Active Learning' feature is to leverage actual user interaction data to enhance the model's understanding capabilities. This is a continuous learning and optimization process that takes place after the model has been deployed and put into actual use.\nso the answer is AC.","poster":"SmallFire","timestamp":"1685509920.0"},{"comment_id":"905651","content":"Selected Answer: BC\nGoogle Bard Answer : Sure, here are two methods you can use to evaluate the accuracy of a Conversational Language Understanding model before deploying it:\n\nFrom Language Studio, select Model performance. This will show you a summary of the model's performance, including the F1 score, precision, and recall.\nFrom Language Studio, enable Active Learning, and then validate the utterances logged for review. This will allow you to manually review utterances that the model has misclassified, and then retrain the model with the corrected data.\nHere are the correct answers to your question:\n\nC. From Language Studio, select Model performance.\nB. From Language Studio, enable Active Learning, and then validate the utterances logged for review.","upvote_count":"1","timestamp":"1684917540.0","poster":"sheldon73"}],"question_id":156,"topic":"3","question_text":"You train a Conversational Language Understanding model to understand the natural language input of users.\n\nYou need to evaluate the accuracy of the model before deploying it.\n\nWhat are two methods you can use? Each correct answer presents a complete solution.\n\nNOTE: Each correct selection is worth one point."},{"id":"D76miQugR8VC8r7pHszD","choices":{"B":"No","A":"Yes"},"question_images":[],"answer":"B","exam_id":40,"answers_community":["B (100%)"],"unix_timestamp":1625072940,"topic":"3","answer_ET":"B","url":"https://www.examtopics.com/discussions/microsoft/view/56454-exam-ai-102-topic-3-question-4-discussion/","discussion":[{"timestamp":"1740806940.0","content":"Selected Answer: B\nNo need to create a new model when there is already one; just retrain\n\nAnswer is No","poster":"syupwsh","comment_id":"1363403","upvote_count":"1"},{"comment_id":"1222755","timestamp":"1733074560.0","poster":"omankoman","upvote_count":"4","content":"To pass this exam, you will need to separate and memorise each of the following categories: ‘Yes/No questions that are presented in sequence and cannot be reversed once a decision has been made’, ‘Yes/No three-choice questions’, ‘Drag and Drop drop drop-down selection questions’ and ‘Drag and Drop sorting questions’. Do your best. I did that, memorized all the questions and passed."},{"poster":"rdemontis","upvote_count":"2","content":"Selected Answer: B\nCorrect. Instead you need to add the new images and labels to the existing model. You retrain the model, and then publish the model","timestamp":"1714825980.0","comment_id":"1062168"},{"comments":[{"comment_id":"1040054","timestamp":"1712800140.0","content":"Oops I meant to answer the question 2 above this one.","upvote_count":"1","poster":"sl_mslconsulting"}],"upvote_count":"1","comment_id":"1040053","poster":"sl_mslconsulting","timestamp":"1712800020.0","content":"Selected Answer: B\nThe answer is B is because the limitations of the smart labeler: You should only request suggested tags for images whose tags have already been trained on once. Don't get suggestions for a new tag that you're just beginning to train. You are given new images of species that have not been seen by the model how can you expect it to suggest what they are? Also you can train the model right in the smart labeler: check the workflow and the limitations in the doc. https://learn.microsoft.com/en-us/azure/ai-services/custom-vision-service/suggested-tags"},{"comment_id":"984560","timestamp":"1708272240.0","upvote_count":"1","content":"Selected Answer: B\nNeed training. Correct answer: No","poster":"james2033"},{"poster":"Eltooth","content":"Selected Answer: B\nB is correct answer : No.\n\nThe model needs to be extended and retrained. (Udemy answer)\n\nNote: Use Smart Labeler to generate suggested tags for images. This lets you label a large number of images more quickly when training a Custom Vision model.","timestamp":"1674054120.0","upvote_count":"1","comment_id":"633031"},{"upvote_count":"4","content":"Answer is correct, no need to create a new model, the existing one should be extended and retrained","poster":"htolajide","comment_id":"449361","timestamp":"1647943500.0"},{"comments":[{"poster":"Messatsu","comments":[{"timestamp":"1643279040.0","content":"If must, Create and upload the new model, not upload the image..","upvote_count":"1","comment_id":"415295","poster":"YipingRuan"}],"comment_id":"412441","timestamp":"1642939800.0","upvote_count":"6","content":"No. If \"You create a new model, and then upload the new images and labels.\" your model lacks previous images of other flowers. So the answer is correct."}],"poster":"Rdninja","comment_id":"398463","content":"You don't need to retrain because you created a brand new model","upvote_count":"1","timestamp":"1641316260.0"},{"upvote_count":"3","comment_id":"394990","poster":"azurelearner666","timestamp":"1640891340.0","content":"correct!\nresponse lacks the model retraining..."}],"answer_description":"","question_text":"Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\nYou develop an application to identify species of flowers by training a Custom Vision model.\nYou receive images of new flower species.\nYou need to add the new images to the classifier.\nSolution: You create a new model, and then upload the new images and labels.\nDoes this meet the goal?","timestamp":"2021-06-30 19:09:00","question_id":157,"isMC":true,"answer_images":[]},{"id":"rimX5dDUEyCAFpz5iHo2","url":"https://www.examtopics.com/discussions/microsoft/view/108982-exam-ai-102-topic-3-question-40-discussion/","answer_description":"","isMC":false,"timestamp":"2023-05-11 17:58:00","question_id":158,"answer":"","answer_images":["https://img.examtopics.com/ai-102/image219.png"],"topic":"3","discussion":[{"timestamp":"1684219440.0","comment_id":"898933","poster":"MaliSanFuu","content":"Agreeing with @WinzigWeich\n\nAnswer should be:\n\n1) SpeechRecognitionLanguage\n2) AddTargetLanguage","upvote_count":"31"},{"content":"1) SpeechRecognitionLanguage\n2) AddTargetLanguage\n\nin the exercise of AI-102 online learning","upvote_count":"13","comment_id":"916032","poster":"ziggy1117","timestamp":"1686038280.0"},{"upvote_count":"2","comment_id":"1358516","content":"1) SpeechRecognitionLanguage is CORRECT because this property sets the language for speech recognition. In this case, you need to configure the app to recognize English speech, so you set the speech recognition language to \"en-US\".\n\n2) AddTargetLanguage is CORRECT because this property is used to add a target language for translation. In this case, you need to configure the app to translate the recognized English speech to German, so you use addTargetLanguage(\"de\").","poster":"syupwsh","timestamp":"1739925060.0"},{"timestamp":"1739465880.0","content":"1) SpeechRecognitionLanguage\n2) AddTargetLanguage","poster":"sukantadey","upvote_count":"2","comment_id":"1356206"},{"poster":"jkkkkkaaaaa","content":"https://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-translate-speech?tabs=terminal&pivots=programming-language-csharp","timestamp":"1732520460.0","upvote_count":"1","comment_id":"1317368"},{"comment_id":"1295729","poster":"Skyhawks","upvote_count":"1","content":"In this scenario, addTargetLanguage is not the best choice because you are configuring speech-to-speech translation with Azure Speech Translation API, and you need to set both the speech recognition language (input) and the speech synthesis language (output). If we were working with text translation, addTargetLanguage would be relevant. Because of this the correct answers are: speechRecognitionLanguage to \"en-US\" and speechSynthesisLanguage to \"de\"","timestamp":"1728590880.0"},{"comment_id":"1279785","content":"Wait a minute, Microsoft did it again. They made the first one an assignment and the second one a method call and gave the SpeechSynthesizer as an option. That's e v i l. I would just not notice that trick. How else can you explain that. Just to make the person who knows what SpeechSynthesis and with a time pressure fail.","poster":"famco","upvote_count":"1","timestamp":"1725653160.0"},{"upvote_count":"1","timestamp":"1720978860.0","content":"1. SpeechRecognitionLanguage\n2. AddTargetLanguage","poster":"krzkrzkra","comment_id":"1247881"},{"content":"1. speech_recognition_language\n2. add_target_language","upvote_count":"1","timestamp":"1718981940.0","comment_id":"1234519","poster":"HaraTadahisa"},{"poster":"omankoman","comment_id":"1220890","timestamp":"1716983700.0","content":"1. SpeechRecognitionLanguage\n2. AddTargetLanguage","upvote_count":"1"},{"poster":"takaimomoGcup","timestamp":"1716387420.0","content":"SpeechRecognitionLanguage\nAddTargetLanguage","comment_id":"1215798","upvote_count":"2"},{"timestamp":"1701082620.0","comment_id":"1081438","upvote_count":"1","poster":"sca88","content":"1) SpeechRecognitionLanguage\n2) AddTargetLanguage\n\nhttps://learn.microsoft.com/en-us/dotnet/api/microsoft.cognitiveservices.speech.speechtranslationconfig?view=azure-dotnet"},{"timestamp":"1688224200.0","comment_id":"940097","upvote_count":"8","comments":[{"timestamp":"1699184640.0","content":"thanks for explanation and the provided relevant documentation","poster":"rdemontis","comment_id":"1062829","upvote_count":"2"}],"content":"1. SpeechRecognitionLanguage\n2. AddTargetLanguage\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/how-to-translate-speech?tabs=terminal&pivots=programming-language-csharp#change-the-source-language\nOne common task of speech translation is specifying the input (or source) language. In your code, interact with the SpeechTranslationConfig instance by assigning it to the SpeechRecognitionLanguage property:\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/how-to-translate-speech?tabs=terminal&pivots=programming-language-csharp#add-a-translation-language\nAnother common task of speech translation is to specify target translation languages. At least one is required, but multiples are supported. With every call to AddTargetLanguage, a new target translation language is specified. In other words, when speech is recognized from the source language, each target translation is available as part of the resulting translation operation.","poster":"zellck"},{"poster":"WinzigWeich","timestamp":"1683820680.0","comment_id":"895201","upvote_count":"6","content":"https://microsoftlearning.github.io/AI-102-AIEngineer.de-de/Instructions/08-translate-speech.html\nC# Part \ntranslationConfig.SpeechRecognitionLanguage\ntranslationConfig.AddTargetLanguage"}],"question_images":["https://img.examtopics.com/ai-102/image33.png"],"exam_id":40,"answers_community":[],"answer_ET":"","question_text":"DRAG DROP -\n\nYou develop an app in C# named App1 that performs speech-to-speech translation.\n\nYou need to configure App1 to translate English to German.\n\nHow should you complete the SpeechTranslationConfig object? To answer, drag the appropriate values to the correct targets. Each value may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","unix_timestamp":1683820680},{"id":"UmzikKIYg708CGlhsBLy","url":"https://www.examtopics.com/discussions/microsoft/view/111850-exam-ai-102-topic-3-question-41-discussion/","isMC":true,"answer_description":"","timestamp":"2023-06-11 01:08:00","question_id":159,"answer_images":[],"answer":"B","topic":"3","discussion":[{"content":"Selected Answer: B\nIt is B.","comment_id":"920303","upvote_count":"9","timestamp":"1686438480.0","poster":"973b658"},{"content":"Selected Answer: B\nThe blade contains the necessary information to access the REST interface, including the endpoint URL and the keys required for authentication.\n\nB is the answer","timestamp":"1739181900.0","comment_id":"1354398","upvote_count":"1","poster":"syupwsh"},{"content":"Selected Answer: B\nI say this answer is B.","timestamp":"1719037440.0","poster":"HaraTadahisa","comment_id":"1235194","upvote_count":"1"},{"timestamp":"1718201760.0","content":"Selected Answer: B\nB is answer.","upvote_count":"1","comment_id":"1229221","poster":"reigenchimpo"},{"upvote_count":"1","content":"Selected Answer: B\nB is right answer.","timestamp":"1716387060.0","comment_id":"1215792","poster":"takaimomoGcup"},{"timestamp":"1706953080.0","poster":"evangelist","comment_id":"1139138","content":"Selected Answer: B\nB. Keys and Endpoint blade in the Azure portal.\n\nThis blade provides the endpoint URL needed to access the Cognitive Services API, along with the keys required for authentication. The endpoint URL is essential for making API calls to the service, including those for Language features such as sentiment analysis, key phrase extraction, named entity recognition, and more.","upvote_count":"3"},{"content":"Selected Answer: B\ncorrect","timestamp":"1699189860.0","poster":"rdemontis","comment_id":"1062907","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: B\nans correct","poster":"chenglim","timestamp":"1698367260.0","comment_id":"1055010"}],"question_images":[],"exam_id":40,"answers_community":["B (100%)"],"answer_ET":"B","question_text":"You have an Azure subscription that contains an Azure Cognitive Service for Language resource.\n\nYou need to identify the URL of the REST interface for the Language service.\n\nWhich blade should you use in the Azure portal?","choices":{"B":"Keys and Endpoint","C":"Networking","D":"Properties","A":"Identity"},"unix_timestamp":1686438480},{"id":"eX3GiXn72tAVapys4i82","unix_timestamp":1686438900,"question_text":"DRAG DROP\n-\n\nYou are building a transcription service for technical podcasts.\n\nTesting reveals that the service fails to transcribe technical terms accurately.\n\nYou need to improve the accuracy of the service.\n\nWhich five actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\n\n//IMG//","answer":"","answer_description":"","topic":"3","exam_id":40,"answer_images":["https://img.examtopics.com/ai-102/image36.png"],"timestamp":"2023-06-11 01:15:00","isMC":false,"question_images":["https://img.examtopics.com/ai-102/image35.png"],"url":"https://www.examtopics.com/discussions/microsoft/view/111851-exam-ai-102-topic-3-question-42-discussion/","answer_ET":"","question_id":160,"answers_community":[],"discussion":[{"upvote_count":"31","content":"1. Create Custom Speech project\n2. Create speech-to-text model\n3. Upload training datasets\n4. Train model\n5. Deploy model","comments":[{"comments":[{"upvote_count":"3","poster":"rdemontis","timestamp":"1699190160.0","comment_id":"1062913","content":"thanks for the provided references"}],"content":"https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/custom-speech-overview#how-does-it-work\nWith Custom Speech, you can upload your own data, test and train a custom model, compare accuracy between models, and deploy a model to a custom endpoint.\n- Create a project and choose a model. Use a Speech resource that you create in the Azure portal. If you will train a custom model with audio data, choose a Speech resource region with dedicated hardware for training audio data.\n- Upload test data. Upload test data to evaluate the speech to text offering for your applications, tools, and products.\n- Train a model. Provide written transcripts and related text, along with the corresponding audio data. Testing a model before and after training is optional but recommended.\n- Deploy a model. Once you're satisfied with the test results, deploy the model to a custom endpoint. With the exception of batch transcription, you must deploy a custom endpoint to use a Custom Speech model.","timestamp":"1688223960.0","comment_id":"940093","poster":"zellck","upvote_count":"8"}],"poster":"zellck","timestamp":"1688223960.0","comment_id":"940092"},{"poster":"syupwsh","comments":[{"poster":"syupwsh","content":"model how to accurately recognize and transcribe technical terms. These datasets provide the raw data that the model learns from. Uploading training data comes after creating the model because you need to associate the data with a specific model. You cannot train a model without first creating it and then supplying the necessary training data.\n\n4) Train the model: Training the model involves using the uploaded datasets to adjust and optimize the model's parameters. This process improves the model's accuracy in recognizing and transcribing the types of speech found in your training data, particularly the technical terms. Training must occur after you have both the model and the training data in place. The model needs the datasets to learn from, and you can't train a model without data.","comments":[{"content":"5) Deploy the model: Deploying the model makes it available for use by your transcription service. This step involves setting up a custom endpoint where the trained model can be accessed and utilized for transcription tasks. Deployment is the final step because the model must be fully trained and optimized before it can be used in a live environment. Deploying an untrained model would not yield accurate results.","poster":"syupwsh","comment_id":"1358519","timestamp":"1739925360.0","upvote_count":"1"}],"upvote_count":"1","comment_id":"1358518","timestamp":"1739925300.0"}],"content":"1) Create a Custom Speech project: A Custom Speech project is the starting point where you define the scope and settings for your custom model. This project serves as a container for all the resources and configurations related to your custom speech-to-text model. This is the first step because you need a project framework in place before you can create and manage models or datasets.\n\n2) Create a speech-to-text model: Within the Custom Speech project, you need to create a specific speech-to-text model that will be trained using your data. This model will be tailored to recognize and accurately transcribe the technical terms specific to your needs. This step follows the creation of the project because the model must reside within the project you set up. You need a target model to which you can upload and apply your training data.","upvote_count":"1","timestamp":"1739925300.0","comment_id":"1358517"},{"comment_id":"1266142","upvote_count":"2","content":"Given answer is correct","timestamp":"1723689240.0","poster":"anto69"},{"timestamp":"1721066880.0","comment_id":"1248506","poster":"krzkrzkra","content":"1. Create Custom Speech project\n2. Create speech-to-text model\n3. Upload training datasets\n4. Train model\n5. Deploy model","upvote_count":"1"},{"poster":"omankoman","content":"1. Create Custom Speech project\n2. Create speech-to-text model\n3. Upload training datasets\n4. Train model\n5. Deploy model","timestamp":"1716983280.0","upvote_count":"2","comment_id":"1220882"},{"comment_id":"1185104","upvote_count":"2","poster":"f2c587e","timestamp":"1711671000.0","content":"1. Create a Custom Voice Project\n2. Create a speech-to-text model\n3. Upload Training Datasets\n4. Training Model\n5. Implementation model"},{"poster":"f2c587e","comment_id":"1185103","content":"According to the answer, then data should not be uploaded to train the model? Seriously? So how do you plan to train yourself if they're supposed to be technical words. I agree with zellck","timestamp":"1711670880.0","upvote_count":"1"},{"poster":"rdemontis","comment_id":"1062912","upvote_count":"1","timestamp":"1699190100.0","content":"correct answer"},{"poster":"973b658","timestamp":"1686438900.0","comment_id":"920306","content":"It is true.","upvote_count":"3"}]}],"exam":{"isBeta":false,"isImplemented":true,"numberOfQuestions":329,"name":"AI-102","provider":"Microsoft","id":40,"lastUpdated":"12 Apr 2025","isMCOnly":false},"currentPage":32},"__N_SSP":true}