{"pageProps":{"questions":[{"id":"hjde8avpzvzn0608281F","isMC":false,"answer":"","question_images":["https://www.examtopics.com/assets/media/exam-media/04273/0024900005.png","https://www.examtopics.com/assets/media/exam-media/04273/0025000001.png","https://www.examtopics.com/assets/media/exam-media/04273/0025000002.png","https://www.examtopics.com/assets/media/exam-media/04273/0025000003.jpg","https://www.examtopics.com/assets/media/exam-media/04273/0025100001.png"],"exam_id":48,"topic":"3","discussion":[{"content":"given answer is correct.","timestamp":"1688908980.0","comments":[{"upvote_count":"4","comment_id":"950487","content":"Incorrect. First one is \"No\"","timestamp":"1705143360.0","poster":"[Removed]"},{"comment_id":"780986","poster":"Esward","upvote_count":"3","timestamp":"1689753360.0","content":"yes, you are correct! given answers are correct"}],"upvote_count":"16","comment_id":"770567","poster":"yukkki"},{"upvote_count":"8","content":"the given answer seems correct","poster":"OPT_001122","comment_id":"708550","timestamp":"1682863080.0"},{"comment_id":"1144234","upvote_count":"2","poster":"Woksi","timestamp":"1723096980.0","content":"Is the implementation of the PlayerScore viewable in the exam? Wouldn't questions about partition/row key would be settled there?"},{"upvote_count":"3","content":"See: https://learn.microsoft.com/en-us/dotnet/api/overview/azure/data.tables-readme?view=azure-dotnet","comment_id":"1128467","timestamp":"1721632740.0","poster":"raymond_abcd"},{"timestamp":"1721632500.0","upvote_count":"3","poster":"raymond_abcd","comment_id":"1128462","content":"CloudStorageClient is deprecated for CosmosDb it is now changed to TableServiceClient and then you have TableClient to store the data. So probably this question wil be different in the upcoming exam"},{"upvote_count":"1","content":"Yes, SaveScore will work with CosmosDb.\nThis is an example of Azure Cosmos DB for Table.\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/table/quickstart-dotnet?tabs=azure-cli%2Cwindows","comment_id":"1016457","poster":"Azr0112","timestamp":"1711350840.0"},{"upvote_count":"3","content":"No, No, No, Yes","comment_id":"950486","poster":"[Removed]","timestamp":"1705143240.0"},{"timestamp":"1689198120.0","upvote_count":"3","poster":"[Removed]","content":"Inserting will fail, this would require InsertOrReplace to work","comment_id":"773950"},{"poster":"bbq598","timestamp":"1687820460.0","content":"For box 2 there will be an exception if the same partition key and row key already exist.","upvote_count":"2","comments":[{"content":"So you need to answer box 3 first ;)","poster":"warchoon","comment_id":"821697","timestamp":"1692976920.0","upvote_count":"1"}],"comment_id":"757994"},{"content":"It seems that in the code no partition key for scoreTable is specified, which means that here we are using a single-partition collection. I would say in this case 3rd option is No, so no automatical partitioning will happen.","timestamp":"1685010540.0","comment_id":"726738","poster":"Yumi21","upvote_count":"2"},{"comment_id":"702788","poster":"TheExamMaster2020","timestamp":"1682321220.0","upvote_count":"1","content":"Y,N,Y,Y"},{"comment_id":"688595","upvote_count":"4","content":"What code should be there if doing automatic partitioning (C) remains a total secret to me. Should be somewhere on the table level...","timestamp":"1680869520.0","poster":"coffecold"},{"upvote_count":"2","comment_id":"669387","poster":"DivyaRajkumar","timestamp":"1678843380.0","content":"The given answer looks right to me,\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.cosmos.table?view=azure-dotnet"},{"comment_id":"664369","content":"CloudTableClient is for Table storage - CosmosClient is for Cosmos DB I don't think it will work with Cosmos","timestamp":"1678358160.0","poster":"azurepaul","comments":[{"content":"A = No\nSaveScore() method uses a storage account connectionString:\n CloudStorageAccount storageAccount = CloudStorageAccount.Parse(connectionString);\nand uses storageAccount to create CloudTableClient.\n\nThis is not a CosmosDB connection string, CosmosDB requires a Uri + credential (not given in given code!) So given code wil not work 100% to connect to CosmosDB even though it uses a compatible API.","timestamp":"1703235780.0","poster":"PrepX","upvote_count":"3","comment_id":"930233"},{"content":"Please do a simple bing search and you'll see it is Cosmos Db\nhttps://learn.microsoft.com/en-us/dotnet/api/microsoft.azure.cosmos.table.cloudtableclient?view=azure-dotnet","upvote_count":"1","poster":"Enigma___","timestamp":"1679318640.0","comment_id":"674082"},{"upvote_count":"2","timestamp":"1679314920.0","comment_id":"674028","poster":"ArturKon","content":"Cosmos DB offers Table API, you can use CosmosClient to connect to this."},{"timestamp":"1679315040.0","comment_id":"674030","content":"https://learn.microsoft.com/en-us/dotnet/api/microsoft.azure.cosmos.table.cloudtableclient?view=azure-dotnet","upvote_count":"1","poster":"ArturKon"}],"upvote_count":"6"},{"upvote_count":"2","content":"Correct 100%!","poster":"finnishr","comment_id":"660981","timestamp":"1678098000.0"},{"upvote_count":"3","comment_id":"592201","timestamp":"1666770840.0","poster":"BogdanG","content":"Answer is Correct."}],"answer_ET":"","question_id":176,"question_text":"HOTSPOT -\nA company develops a series of mobile games. All games use a single leaderboard service.\nYou have the following requirements:\n✑ Code must be scalable and allow for growth.\n✑ Each record must consist of a playerId, gameId, score, and time played.\n✑ When users reach a new high score, the system will save the new score using the SaveScore function below.\nEach game is assigned an Id based on the series title.\n//IMG//\n\nYou plan to store customer information in Azure Cosmos DB. The following data already exists in the database:\n//IMG//\n\nYou develop the following code to save scores in the data store. (Line numbers are included for reference only.)\n//IMG//\n\nYou develop the following code to query the database. (Line numbers are included for reference only.)\n//IMG//\n\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","answer_description":"Box 1: Yes -\nCreate a table.\nA CloudTableClient object lets you get reference objects for tables and entities. The following code creates a CloudTableClient object and uses it to create a new\nCloudTable object, which represents a table\n// Retrieve storage account from connection-string.\nCloudStorageAccount storageAccount =\nCloudStorageAccount.parse(storageConnectionString);\n// Create the table client.\nCloudTableClient tableClient = storageAccount.createCloudTableClient();\n// Create the table if it doesn't exist.\nString tableName = \"people\";\nCloudTable cloudTable = tableClient.getTableReference(tableName); cloudTable.createIfNotExists();\n\nBox 2: No -\nNew records are inserted with TableOperation.insert. Old records are not updated.\nTo update old records TableOperation.insertOrReplace should be used instead.\n\nBox 3: No -\n\nBox 4: Yes -\nReference:\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/table-storage-how-to-use-java","unix_timestamp":1650959640,"timestamp":"2022-04-26 09:54:00","url":"https://www.examtopics.com/discussions/microsoft/view/74568-exam-az-204-topic-3-question-22-discussion/","answer_images":["https://www.examtopics.com/assets/media/exam-media/04273/0025100002.png"],"answers_community":[]},{"id":"r2bmaHupgJ2Q3XYeAHii","isMC":true,"choices":{"F":"Create a new subscription in the current region","A":"Export the Azure Storage account Azure Resource Manager template","C":"Configure object replication for all blobs","D":"Use the AzCopy command line tool","E":"Create a new Azure Storage account in the current region","B":"Initiate a storage account failover"},"discussion":[{"timestamp":"1698388980.0","upvote_count":"13","poster":"[Removed]","comment_id":"592917","content":"Selected Answer: A\nWe can create a new Storage account in the new region, using the existing storage account ARM template. All we need to do is change the region name after exporting the ARM of existing account..","comments":[{"comment_id":"686656","timestamp":"1712299500.0","upvote_count":"4","content":"And the name of the storage account which needs to be unique. I think all these questions are about some sentence in some azure documentation.","poster":"gmishra88"}]},{"poster":"Nhiendo","comment_id":"762661","timestamp":"1719746460.0","upvote_count":"10","content":"Step One is always \"Export\""},{"comment_id":"722397","poster":"OPT_001122","timestamp":"1716173940.0","upvote_count":"3","content":"Selected Answer: A\nA. Export the Azure Storage account Azure Resource Manager template"},{"poster":"TheExamMaster2020","comment_id":"718777","content":"Did my exam on 15th November 2022. This question was on it.","timestamp":"1715773740.0","upvote_count":"6"},{"timestamp":"1698306960.0","content":"Answer is correct.","comment_id":"592202","upvote_count":"10","poster":"BogdanG"}],"url":"https://www.examtopics.com/discussions/microsoft/view/74569-exam-az-204-topic-3-question-23-discussion/","question_images":[],"question_id":177,"timestamp":"2022-04-26 09:56:00","answers_community":["A (100%)"],"answer_description":"","exam_id":48,"answer":"A","unix_timestamp":1650959760,"question_text":"You develop and deploy a web application to Azure App Service. The application accesses data stored in an Azure Storage account. The account contains several containers with several blobs with large amounts of data. You deploy all Azure resources to a single region.\nYou need to move the Azure Storage account to the new region. You must copy all data to the new region.\nWhat should you do first?","topic":"3","answer_ET":"A","answer_images":[]},{"id":"npsh2yu3i40UWXTsgKSx","discussion":[{"content":"Without knowing the functionality or the usage pattern or what it is for. Good lord, Microsoft","poster":"[Removed]","timestamp":"1664470620.0","upvote_count":"43","comment_id":"682879"},{"upvote_count":"24","poster":"serpevi","content":"Got this in 09/22 , went with SQL and Item Id, score 927.","timestamp":"1662877560.0","comment_id":"665859"},{"timestamp":"1704197160.0","comment_id":"1111843","comments":[{"poster":"Gauravbio","timestamp":"1715578740.0","upvote_count":"1","content":"Core sql api removed now, it should be no sql api","comment_id":"1210724"}],"poster":"130nk3r5","upvote_count":"7","content":"Got this today.\nWent with answer here.\nScore 927"},{"timestamp":"1694428020.0","content":"On my exam 2023sept","poster":"Tarajee","comment_id":"1004627","upvote_count":"8"},{"poster":"NightshadeRC","content":"Had this question in today's exam: 2023-07-26","timestamp":"1690339320.0","comment_id":"963274","upvote_count":"5"},{"upvote_count":"7","comment_id":"950499","content":"Answer seems correct, but the question is very bad. It doesn't even tell about the usage, so it could be Table API as well","poster":"[Removed]","timestamp":"1689239760.0"},{"comments":[{"poster":"MarcoStewart","comments":[{"comments":[{"content":"did contributor access is needed to pass the exam?","timestamp":"1708977300.0","comments":[{"content":"yes it is","poster":"Christian_garcia_martin","comment_id":"1266850","timestamp":"1723788480.0","upvote_count":"1"}],"comment_id":"1160036","upvote_count":"1","poster":"Puja079888"}],"comment_id":"1082737","upvote_count":"1","timestamp":"1701189480.0","poster":"CarlosTheBoldest","content":"Page 32 and above"}],"comment_id":"918524","timestamp":"1686245640.0","upvote_count":"3","content":"where can one find these case studies?"}],"comment_id":"844182","poster":"sarmaria","timestamp":"1679256300.0","content":"Got this question in the exam on 16/03/2023. Went with SQL and Item Id . Make sure to prepare for case studies. I got city and lights case study.","upvote_count":"5"},{"upvote_count":"12","content":"They changed names again. \"Core (SQL)\" is \"Api for NoSQL\" now. Its wonderful to choose \"SQL\" for \"NoSQL\". \nhttps://www.c-sharpcorner.com/article/road-to-az-2044/#:~:text=Core%20SQL%20API%2C%20default%20API%20for%20using%20Azure%20Cosmos%20DB%20enables%20querying%20your%20data%20with%20a%20language%20very%20close%20to%20SQL%3B\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/choose-api#coresql-api:~:text=API%20for%20NoSQL%20is%20native%20to%20Azure%20Cosmos%20DB.","poster":"warchoon","timestamp":"1677391200.0","comment_id":"822092"},{"timestamp":"1674122880.0","upvote_count":"2","poster":"Esward","content":"given answers are correct","comment_id":"780999"},{"timestamp":"1668921360.0","upvote_count":"2","poster":"OPT_001122","comment_id":"722400","content":"SQL and Item Id"},{"upvote_count":"2","content":"correct","comment_id":"704102","timestamp":"1666723200.0","poster":"rol204"},{"content":"Answer is correct:\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/choose-api","upvote_count":"4","timestamp":"1662914700.0","comment_id":"666286","poster":"kampatra"},{"comments":[{"content":"Table API is for manage tables, SQL is for queries","timestamp":"1701189540.0","comment_id":"1082738","poster":"CarlosTheBoldest","upvote_count":"1"}],"poster":"dtctx","comment_id":"594550","content":"Received this in test on 4/29 and passed the test. \n\nWent with Table API and Item ID. I do not know if Table API is correct, but I am confident that Item ID is.","upvote_count":"4","timestamp":"1651246080.0"},{"timestamp":"1651155900.0","poster":"sghaha","upvote_count":"1","content":"https://docs.microsoft.com/ko-kr/azure/cosmos-db/choose-api","comment_id":"593869"}],"question_id":178,"question_images":["https://www.examtopics.com/assets/media/exam-media/04273/0025400001.png"],"answer":"","answer_ET":"","exam_id":48,"answer_description":"Box 1: Core (SQL)\nCore(SQL) API stores data in document format. It offers the best end-to-end experience as we have full control over the interface, service, and the SDK client libraries. SQL API supports analytics and offers performance isolation between operational and analytical workloads.\n\nBox 2: item id -\nitem id is a unique identifier and is suitable for the partition key.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/choose-api\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/partitioning-overview","answer_images":["https://www.examtopics.com/assets/media/exam-media/04273/0025500001.png"],"unix_timestamp":1651155900,"answers_community":[],"topic":"3","isMC":false,"timestamp":"2022-04-28 16:25:00","question_text":"HOTSPOT -\nYou are developing an application to collect the following telemetry data for delivery drivers: first name, last name, package count, item id, and current location coordinates. The app will store the data in Azure Cosmos DB.\nYou need to configure Azure Cosmos DB to query the data.\nWhich values should you use? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","url":"https://www.examtopics.com/discussions/microsoft/view/74783-exam-az-204-topic-3-question-24-discussion/"},{"id":"Ep3YW6psuGRz1qEqjMHS","url":"https://www.examtopics.com/discussions/microsoft/view/79410-exam-az-204-topic-3-question-25-discussion/","answer_images":["https://www.examtopics.com/assets/media/exam-media/04273/0025700001.jpg"],"topic":"3","discussion":[{"timestamp":"1662122580.0","poster":"finnishr","comment_id":"657429","content":"The answer is correct.","comments":[{"content":"1. Monitor the progress of the change feed processor\nFeature: Lease container\nReason: The Lease container is responsible for tracking the progress of the change feed processor. It maintains state information, ensuring that the change feed processor knows where it left off and can resume from the correct point in the feed. This allows the system to monitor the progress and distribute the workload across multiple instances if needed.\n\n2. Prevent the change feed processor from retrying the entire batch when one document cannot be read\nFeature: Dead-letter queue\nReason: The Dead-letter queue allows you to handle documents that cannot be processed. If a document cannot be read or processed, instead of failing the entire batch, the problematic document is moved to a dead-letter queue, allowing the change feed processor to continue processing the rest of the batch without retrying the failed document.","poster":"ns4098","upvote_count":"1","comment_id":"1287836","timestamp":"1727021220.0"}],"upvote_count":"18"},{"upvote_count":"13","comment_id":"844186","timestamp":"1679256420.0","poster":"sarmaria","content":"Got this on 16/03/23. Went with proposed solution. Make sure to prepare for case study. I got city and lights case study. No Kubernetes, Search, Logic Apps questions for me."},{"timestamp":"1702952280.0","comment_id":"1100210","poster":"Stann07","upvote_count":"3","content":"On my exam Dec 18. went with the given answer. scored 842"},{"content":"On exam 3-Nov-2023. Went with proposed anwer - 932/1000.\n1) Change feed estimator\n2) Dead letter queue","comment_id":"1061504","upvote_count":"4","poster":"AndySmith","timestamp":"1699022820.0"},{"timestamp":"1695180300.0","comment_id":"1011874","comments":[{"timestamp":"1695341700.0","comment_id":"1013468","poster":"Nitin23","upvote_count":"2","content":"this is a bad site"}],"poster":"dddddd111","content":"I got this same question. Provided answers are correct. (Note: I failed the exam 20/9/23. I only scored 644 and I felt bad. I think because many questions here in Examtopics are not accurate. I suggest following the most voted answers and don't just not rely on Examtopics answers. At the beginning of the exam, you will be asked which programming languages you want to use. C#/Python. I chose C#. Also, I just want to add that some questions here are really in the actual exams, but the choices are written and formatted differently. Please be aware of that. Goodluck. I feel bad for failing it, but I want to retake next month. I will try Python. T_T","upvote_count":"10"},{"upvote_count":"1","poster":"kayvg","timestamp":"1692005160.0","content":"The answer is correct\n\nA change feed estimator is used to monitor teh progress of your change feed processor instances as they read the change feed\n\nA dead-letter queue is holding a queue for messages that cannot bbe delivered to their destination\n\n\n\nA deployment unit is to provide a container for an application or service, which is not relevant\n\nThe lease container is used to coordinate processing the change feed, which is not relevant aswell","comment_id":"980644"},{"poster":"kvtborad","timestamp":"1691494200.0","comment_id":"975581","upvote_count":"2","content":"I got this question on 6th August 2023. chose highly voted. passed with 904. I got Case study: city and Lights. All questions are from ExamTopics."},{"content":"Got this on 6/28/2023 and passed with 850. Went with answer.","timestamp":"1688042400.0","poster":"JH81","comment_id":"938094","upvote_count":"2"},{"upvote_count":"2","comment_id":"896136","timestamp":"1683915000.0","content":"Got this 2023-05-12.\n\nMy case:\ncase: You need to configure authorization.\ncase: You need to ensure the app does not time out and processes the blob data\ncase study: VanArsdel Inc Canada","poster":"aragones"},{"timestamp":"1674936420.0","poster":"narenazure","upvote_count":"1","comment_id":"791040","content":"The answer is correct.\nTo prevent your change feed processor from getting \"stuck\" continuously retrying the same batch of changes, you should add logic in your delegate code to write documents, upon exception, to an errored-message queue. This design ensures that you can keep track of unprocessed changes while still being able to continue to process future changes. The errored-message queue might be another Azure Cosmos DB container. The exact data store does not matter, simply that the unprocessed changes are persisted.\nError handling section - https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/change-feed-processor?tabs=dotnet"},{"content":"Given answers are correct!","comments":[{"comment_id":"781024","poster":"Esward","upvote_count":"2","content":"To prevent your change feed processor from getting \"stuck\" continuously retrying the same batch of changes, you should add logic in your delegate code to write documents, upon exception, to an errored-message queue. This design ensures that you can keep track of unprocessed changes while still being able to continue to process future changes. The errored-message queue might be another Azure Cosmos DB container. The exact data store does not matter, simply that the unprocessed changes are persisted.\n\nIn addition, you can use the change feed estimator to monitor the progress of your change feed processor instances as they read the change feed or use the life cycle notifications to detect underlying failures.","timestamp":"1674124800.0"}],"timestamp":"1674124440.0","upvote_count":"1","comment_id":"781018","poster":"Esward"},{"upvote_count":"3","content":"got in 11/11/2022","timestamp":"1668525900.0","comment_id":"718909","poster":"Sreedharc"},{"comment_id":"701011","comments":[{"content":"thanks for mentioning the date","comment_id":"708557","poster":"OPT_001122","upvote_count":"1","timestamp":"1667232300.0"}],"content":"Got this on 10/21/2022","upvote_count":"3","timestamp":"1666364460.0","poster":"vcfvct"},{"poster":"gmishra88","upvote_count":"1","content":"Sure, this is also taken from a certification. But where does a dead letter queue come in change feed processor. If this comes, yes, this is the correct answer. But it all doesn't make any sense","comments":[{"upvote_count":"3","comments":[{"poster":"Pentagon","upvote_count":"1","timestamp":"1667400420.0","content":"If just for saving the last position, I think it should be lease container.\n\"When the delegate finishes processing the changes successfully, update the lease store with the latest processed point in time and go to #1\"\nDead-letter queue seems to be prevent re-trying too much instead of resuming at the last done position.","comment_id":"709879"}],"content":"It is do-it-your self stuff:\n\"To prevent your change feed processor from getting \"stuck\" continuously retrying the same batch of changes, you should add logic in your delegate code to write documents, upon exception, to a dead-letter queue \"\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/sql/change-feed-processor?tabs=dotnet","timestamp":"1665149460.0","comment_id":"688661","poster":"coffecold"}],"timestamp":"1664952840.0","comment_id":"686660"}],"unix_timestamp":1662122580,"answer":"","answers_community":[],"exam_id":48,"question_images":["https://www.examtopics.com/assets/media/exam-media/04273/0025600001.jpg"],"question_id":179,"isMC":false,"question_text":"DRAG DROP -\nYou are implementing an Azure solution that uses Azure Cosmos DB and the latest Azure Cosmos DB SDK. You add a change feed processor to a new container instance.\nYou attempt to read a batch of 100 documents. The process fails when reading one of the documents. The solution must monitor the progress of the change feed processor instance on the new container as the change feed is read. You must prevent the change feed processor from retrying the entire batch when one document cannot be read.\nYou need to implement the change feed processor to read the documents.\nWhich features should you use? To answer, drag the appropriate features to the cored requirements. Each feature may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.\nNOTE: Each cored selection is worth one point.\nSelect and Place:\n//IMG//","answer_description":"Box 1: Change feed estimator -\nYou can use the change feed estimator to monitor the progress of your change feed processor instances as they read the change feed or use the life cycle notifications to detect underlying failures.\n\nBox 2: Dead-letter queue -\nTo prevent your change feed processor from getting \"stuck\" continuously retrying the same batch of changes, you should add logic in your delegate code to write documents, upon exception, to a dead-letter queue. This design ensures that you can keep track of unprocessed changes while still being able to continue to process future changes. The dead-letter queue might be another Cosmos container. The exact data store does not matter, simply that the unprocessed changes are persisted.\nReference:\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/sql/change-feed-processor","answer_ET":"","timestamp":"2022-09-02 14:43:00"},{"id":"tszHa95m7ABT7KGsIdAz","question_id":180,"discussion":[{"poster":"baroo1","timestamp":"1676383920.0","content":"No - Not modified, created.\nNo - Not accessed, created.\nYes - Rules are matching the statement. The prefix \"transactions\" can be applicable for containers as well. \"container\" / \"container/blob\" or \"blob\" can be used under this context.\nSource: https://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview#archive-data-after-ingest\nNo - \"enableAutoTierToHotFromCool\": \"true\" should be enabled.","upvote_count":"28","comment_id":"808448"},{"comments":[{"comment_id":"665605","upvote_count":"63","timestamp":"1662834900.0","comments":[{"comments":[{"comment_id":"674058","content":"Looks like 3rd is NO, according to filter's guide:\n\n\"Filter blobs by name or first letters. To find items in a specific container, enter the name of the container followed by a forward slash, then the blob name or first letters. For example, to show all blobs starting with \"a\", type: \"mycontainer/a\".\"\n\nSo it looks like we are searching blobs with \"transactions\" prefix in all containers in 3rd.","timestamp":"1663671360.0","upvote_count":"1","poster":"ArturKon"},{"comment_id":"673964","upvote_count":"5","timestamp":"1663664760.0","content":"But name \"transactions\" satisfies rule `name must start from \"transactions\"`, why it doesn't fit?","poster":"cwn53066"}],"comment_id":"669750","upvote_count":"2","poster":"ChiragShah4885","content":"Container name \"transactions\" is in prefixMatch means its name must start from \"transactions\". Its name is not \"transactions\". Dani_ac7's answer looks correct","timestamp":"1663233420.0"}],"content":"I guess, third statement (The policy rule tiers..) result is Yes.\nContainer name \"transactions\" is in prefixMatch.\n\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview#archive-data-after-ingest\n\nSolution is:\n- No\n- No\n- Yes\n- No","poster":"Tenk14"},{"timestamp":"1674128220.0","comment_id":"781055","poster":"Esward","content":"Correct: if you want to match the blobs within a specific container, you should mention the conatiner name/blob name\n\n{\n \"rules\": [\n {\n \"name\": \"agingRule\",\n \"enabled\": true,\n \"type\": \"Lifecycle\",\n \"definition\": {\n \"filters\": {\n \"blobTypes\": [ \"blockBlob\" ],\n \"prefixMatch\": [ \"sample-container/blob1\", \"container2/blob2\" ]\n },\n \"actions\": {\n \"baseBlob\": {\n \"tierToCool\": { \"daysAfterModificationGreaterThan\": 30 },\n \"tierToArchive\": { \"daysAfterModificationGreaterThan\": 90 }\n }\n }\n }\n }\n ]\n}","upvote_count":"1"},{"poster":"Hendrikdb","upvote_count":"1","content":"wrong:\nAn array of strings for prefixes to be matched. Each rule can define up to 10 case-sensitive prefixes. A prefix string must start with a container name. For example, if you want to match all blobs under https://myaccount.blob.core.windows.net/sample-container/blob1/... for a rule, the prefixMatch is sample-container/blob1","comment_id":"1153293","timestamp":"1708263540.0"}],"upvote_count":"26","poster":"Dani_ac7","comment_id":"656583","timestamp":"1662058800.0","content":"With this image, all answers are NO:\n\n- Container named transaction is not in code\n- is no present line \"enableAutoTierToHotFromCool\": true"},{"content":"The solution is \n-No\n-No\n-Yes\n-No","timestamp":"1738288620.0","comment_id":"1349353","poster":"DamuKeesh","upvote_count":"1"},{"upvote_count":"1","timestamp":"1724322660.0","content":"Block blobs prefixed with “transactions” will transition blobs that have not been modified in over 60 days to cool storage, and delete blobs not modified in 365 days.\nYes. This is correct based on the rule provided.\nBlobs are moved to cool storage if they have not been accessed for 60 days.\nNo. The rule is based on the creation date, not access date.\nThe policy rule tiers previous versions within a container named “transactions” that are 60 days or older to the cool tier and deletes previous versions that are 365 days or older.\nNo. The rule applies to block blobs with the prefix “transactions,” not specifically to previous versions within a container.\nBlobs will automatically be tiered from cool back to hot if accessed again after being tiered to cool.\nNo. As you correctly pointed out, the rule does not specify “enableAutoTierToHotFromCool” as true.\nSo, the correct answers should be: Yes, No, No, No.","poster":"4bd3116","comment_id":"1270630"},{"content":"NO , NO ,YES ,NO . Last one is NO becouse you don't see \"enableAutoTierToHotFromColl\" : true","comment_id":"1266853","poster":"Christian_garcia_martin","upvote_count":"3","timestamp":"1723788960.0"},{"timestamp":"1711115760.0","upvote_count":"4","poster":"jobolesonihal","content":"policy doesn't mention baseblob.\nSolution is:\n- No\n- No\n- Yes\n- No","comment_id":"1180087"},{"timestamp":"1707959100.0","comment_id":"1150671","upvote_count":"6","poster":"SSR999","content":"Premium Block Blobs wont support access tiers and Lifecycle management policies (tiering)\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/storage-feature-support-in-storage-accounts#premium-block-blob-accounts"},{"poster":"NPE_","content":"3rd is YES, check the reference: \nhttps://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview\n\nOn the page it says: \"A prefix string must start with a container name. For example, if you want to match all blobs under https://myaccount.blob.core.windows.net/sample-container/blob1/... for a rule, the prefixMatch is sample-container/blob1.\" This means that the container name is \"transactions\"\n\nSo the only one that make me confusing is the 4th. According to the discussion, you have to manually enable \"enableAutoTierToHotFromCool\". And it is also mentioned above in the link that \"The enableAutoTierToHotFromCool action is available only when used with the daysAfterLastAccessTimeGreaterThan run condition. \" As in our case, the prerequisite for the auto tier to hot from cool is not even fulfilled, so it is not possible to expect an \"AutoTierToHotFromCool\" effect.\n\n I would go with a NO for the 4th.","comment_id":"1058566","timestamp":"1698739620.0","upvote_count":"3"},{"comments":[{"comment_id":"1017991","poster":"nikipediaa","upvote_count":"1","timestamp":"1695745860.0","content":"sorry, not this one, but similar with containers and numbers :)"}],"comment_id":"1017989","timestamp":"1695745740.0","poster":"nikipediaa","content":"Question was on exam 2023-09-26","upvote_count":"1"},{"poster":"aragones","timestamp":"1684007280.0","comment_id":"897038","upvote_count":"2","content":"Got this 2023-05-12.\nWithout 4th question.\n\nmy cases also:\ncase: You need to configure authorization.\ncase: You need to ensure the app does not time out and processes the blob data\ncase study: VanArsdel Inc Canada"},{"timestamp":"1683915060.0","poster":"aragones","upvote_count":"1","comment_id":"896138","content":"Got this 2023-05-12.\n\nMy case:\ncase: You need to configure authorization.\ncase: You need to ensure the app does not time out and processes the blob data\ncase study: VanArsdel Inc Canada"},{"comment_id":"872556","poster":"surprise0011","upvote_count":"8","timestamp":"1681724580.0","content":"received 2023-04-17 went N,N,Y, score 926\nlast box was not there only first three"},{"poster":"surprise0011","upvote_count":"4","comment_id":"861316","timestamp":"1680627660.0","content":"premium block blob storage does not support access tiers. This is confusing"},{"content":"Question was in Exam 2023-03-30","comment_id":"855383","timestamp":"1680161880.0","poster":"Saluk_DE","upvote_count":"1"},{"comment_id":"844191","upvote_count":"4","poster":"sarmaria","timestamp":"1679256480.0","content":"Got this on 16/03/23. Make sure to prepare for case study. I got city and lights case study. No Kubernetes, Search, Logic Apps questions for me."},{"poster":"rasojol523","upvote_count":"2","timestamp":"1678536480.0","content":"Box 3: No ?\n'DayAfterCreationGraterThan 60' does not include 'just 60 days'. Therefore, if something has been made for 60 days, it would not be included in '60 days or later', so box 3 would be NO ?","comment_id":"835951"},{"comment_id":"823766","upvote_count":"3","content":"Was on the exam 27.02.2023\nWent with NNYN.\nScore 870","poster":"Ayman99","timestamp":"1677506400.0"},{"content":"Box 1, 2: No - this is about past versions, not about blobs \nBox 3: Yes - exactly policy description\nBox 4: No - first this is about past version not blob, second even blob moving back needs enableAutoTierToHotFromCool","upvote_count":"2","timestamp":"1677395340.0","comment_id":"822128","poster":"warchoon"},{"poster":"Adiu","comment_id":"816310","timestamp":"1676963100.0","content":"One important thing - the rule is for version and according to MS:\nThe baseBlob element in a lifecycle management policy refers to the current version of a blob. The version element refers to a previous version.","upvote_count":"2"},{"poster":"Michael2023","content":"Dani_ac7 is right I guess, but I think because we have here an Premium Block Blob Account/Storage which doesnt support Access Tier (Hot, Cool, Archive)... Access Tier is only supported in Standard general-purpose v2 Accounts\n\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/storage-feature-support-in-storage-accounts#premium-block-blob-accounts","comment_id":"789618","timestamp":"1674825120.0","upvote_count":"4"},{"comment_id":"775043","comments":[{"comment_id":"787273","timestamp":"1674621780.0","upvote_count":"2","content":"yes you need.","poster":"Jhilphis"}],"timestamp":"1673663640.0","content":"Do I need to buy the contributor access to pass this exam?","poster":"adilkhan","upvote_count":"1"},{"upvote_count":"4","comment_id":"746326","content":"Answer is:\nNo\nNo\nYes\nNo\n\nThe third is Yes due to PrefixMatch being used to specifying containers.\n\nDocumentation where this question appears as example and as explanation of what it does:\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview#manage-previous-versions\n\nThe fourth is No, due to no present line \"enableAutoTierToHotFromCool\": true","timestamp":"1671122880.0","poster":"dgcc97"},{"upvote_count":"5","poster":"Trimack93","comment_id":"734660","content":"It is worth mentioning that we have an application that uses a premium block blob storage account and as of now, tiering is not supported for these (see https://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview#rule-actions). So it looks like 3rd answer (moving blobs to cold tier) should also be NO.","timestamp":"1670097660.0"},{"content":"Box4 is No\n\nIn the following example, blobs are moved to cool storage if they haven't been accessed for 30 days. The enableAutoTierToHotFromCool property is a Boolean value that indicates whether a blob should automatically be tiered from cool back to hot if it's accessed again after being tiered to cool.\n\n{\n \"enabled\": true,\n \"name\": \"last-accessed-thirty-days-ago\",\n \"type\": \"Lifecycle\",\n \"definition\": {\n \"actions\": {\n \"baseBlob\": {\n \"enableAutoTierToHotFromCool\": true,\n \"tierToCool\": {\n \"daysAfterLastAccessTimeGreaterThan\": 30\n }\n }\n },\n \"filters\": {\n \"blobTypes\": [\n \"blockBlob\"\n ],\n \"prefixMatch\": [\n \"mylifecyclecontainer/log\"\n ]\n }\n }\n}","upvote_count":"2","comment_id":"722435","poster":"OPT_001122","timestamp":"1668926520.0"},{"comment_id":"716392","poster":"micro9000","content":"N,N,Y,N\nYou should add enableAutoTierToHotFromCool and set to true\n\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview#move-data-based-on-last-accessed-time\n\nIn the following example, blobs are moved to cool storage if they haven't been accessed for 30 days. The enableAutoTierToHotFromCool property is a Boolean value that indicates whether a blob should automatically be tiered from cool back to hot if it's accessed again after being tiered to cool.","timestamp":"1668212760.0","upvote_count":"1"},{"content":"Got this on 10/21/2022.","poster":"vcfvct","comments":[{"upvote_count":"1","comment_id":"708559","poster":"OPT_001122","content":"Thanks for mentioning the date","timestamp":"1667232480.0"}],"upvote_count":"4","timestamp":"1666364460.0","comment_id":"701012"},{"poster":"OPT_001122","content":"what is the correct answer, there are different answers in the discusison","comment_id":"685921","upvote_count":"2","timestamp":"1664857320.0"},{"timestamp":"1663756560.0","content":"what is the correct answer now ? so many different answers","upvote_count":"1","poster":"Neco38","comments":[{"upvote_count":"2","comment_id":"689200","timestamp":"1665226380.0","poster":"coffecold","content":"NO,NO,YES,NO"}],"comment_id":"675019"},{"upvote_count":"2","content":"ANSWER IS:\nNO\nNO\nYES\nYES\nAs for the last question on tiering back to hot from cool:\n\"enableAutoTierToHotFromCool\": true, is NOT stated so data is not tiered back from cool to hot automatically. Besides that. The option \"enableAutoTierToHotFromCool\": true is not supported for previous versions.\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview#archive-data-after-ingest","timestamp":"1663674300.0","comments":[{"comment_id":"674103","content":"Sorry... my bad:\nNO\nNO\nYES\nNO","upvote_count":"9","timestamp":"1663674360.0","poster":"Enigma___"},{"upvote_count":"3","content":"You are right. The property is not there and it is also not supported for versions. Important to remember, enableAutoTierToHotFromCool is only with \"daysAfterLastAccessTimeGreaterThan\" type of rules that uses the access times. They are not available for versions or snapshots (or for append blobs as whole because access specific rules are not supported for append blobs). All this is cool but I wonder how much I can remember from all these irrelevant data I can easily lookup with a search","poster":"[Removed]","comment_id":"683257","timestamp":"1664517780.0"}],"comment_id":"674100","poster":"Enigma___"}],"unix_timestamp":1662058800,"answer_images":["https://img.examtopics.com/az-204/image595.png"],"answer":"","answer_description":"","answer_ET":"","exam_id":48,"url":"https://www.examtopics.com/discussions/microsoft/view/79151-exam-az-204-topic-3-question-26-discussion/","answers_community":[],"question_images":["https://www.examtopics.com/assets/media/exam-media/04273/0025800001.png","https://www.examtopics.com/assets/media/exam-media/04273/0025900001.png"],"topic":"3","timestamp":"2022-09-01 21:00:00","isMC":false,"question_text":"HOTSPOT -\nYou are developing an application that uses a premium block blob storage account. The application will process a large volume of transactions daily. You enable\nBlob storage versioning.\nYou are optimizing costs by automating Azure Blob Storage access tiers. You apply the following policy rules to the storage account. (Line numbers are included for reference only.)\n//IMG//\n\nFor each of the following statements, select Yes if the statement is true. Otherwise, select No.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//"}],"exam":{"lastUpdated":"12 Apr 2025","numberOfQuestions":452,"name":"AZ-204","isBeta":false,"provider":"Microsoft","isImplemented":true,"id":48,"isMCOnly":false},"currentPage":36},"__N_SSP":true}