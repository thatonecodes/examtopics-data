{"pageProps":{"questions":[{"id":"Q8GWB5TV2rnGGoTVGaH5","question_images":["https://www.examtopics.com/assets/media/exam-media/04275/0023200003.png"],"discussion":[{"comment_id":"709105","upvote_count":"5","timestamp":"1698841200.0","content":"This question is for DP-203 exam (Data Engineer).","poster":"Ciupaz"},{"upvote_count":"1","poster":"Kostali","comment_id":"993063","timestamp":"1724934120.0","content":"P1 : PolyBase\nP2 : Bulk Insert"},{"comment_id":"821410","upvote_count":"2","poster":"KIET2131","content":"For P1:\n\nSet the Copy method to PolyBase\nFor P2:\n\nSet the Copy method to Bulk insert","timestamp":"1708859700.0"},{"timestamp":"1680353580.0","upvote_count":"3","content":"DP-203","poster":"cusman","comment_id":"579499"},{"comment_id":"530060","upvote_count":"3","content":"Looks correct","timestamp":"1674418020.0","poster":"CaptainJameson"},{"upvote_count":"1","comment_id":"475723","poster":"o2091","content":"its ok?","timestamp":"1668106500.0"}],"answer":"","answer_description":"P1: Set the Partition option to Dynamic Range.\nThe SQL Server connector in copy activity provides built-in data partitioning to copy data in parallel.\nP2: Set the Copy method to PolyBase\nPolybase is the most efficient way to move data into Azure Synapse Analytics. Use the staging blob feature to achieve high load speeds from all types of data stores, including Azure Blob storage and Data Lake Store. (Polybase supports Azure Blob storage and Azure Data Lake Store by default.)\nReference:\nhttps://docs.microsoft.com/en-us/azure/data-factory/connector-azure-sql-data-warehouse https://docs.microsoft.com/en-us/azure/data-factory/load-azure-sql-data-warehouse","topic":"5","isMC":false,"answers_community":[],"url":"https://www.examtopics.com/discussions/microsoft/view/65801-exam-dp-300-topic-5-question-1-discussion/","unix_timestamp":1636570500,"answer_images":["https://www.examtopics.com/assets/media/exam-media/04275/0023300001.png"],"question_text":"HOTSPOT -\nYou have an Azure Data Factory instance named ADF1 and two Azure Synapse Analytics workspaces named WS1 and WS2.\nADF1 contains the following pipelines:\n✑ P1: Uses a copy activity to copy data from a nonpartitioned table in a dedicated SQL pool of WS1 to an Azure Data Lake Storage Gen2 account\n✑ P2: Uses a copy activity to copy data from text-delimited files in an Azure Data Lake Storage Gen2 account to a nonpartitioned table in a dedicated SQL pool of WS2\nYou need to configure P1 and P2 to maximize parallelism and performance.\nWhich dataset settings should you configure for the copy activity of each pipeline? To answer, select the appropriate options in the answer area.\nHot Area:\n//IMG//","question_id":241,"timestamp":"2021-11-10 19:55:00","exam_id":68,"answer_ET":""},{"id":"tnu4PwyQxFO3nyqKs8Os","question_images":["https://www.examtopics.com/assets/media/exam-media/04275/0024200001.jpg"],"discussion":[{"poster":"[Removed]","timestamp":"1729516740.0","upvote_count":"1","comment_id":"1199668","content":"It's correct."},{"timestamp":"1698310260.0","upvote_count":"2","comment_id":"881331","content":"Correct.\nhttps://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/job-automation-managed-instance?view=azuresql","poster":"OBIJUAN88"},{"poster":"lukelin08","timestamp":"1679207160.0","comments":[{"content":"NOTE: More than one order of answer choices is correct.","upvote_count":"4","timestamp":"1683893700.0","comment_id":"716735","poster":"wyindualizer"}],"comment_id":"672917","content":"Not a fair question. An operator can be created before Database Mail is enabled or after, it doesnt matter which way around. As long as the Database Mail is enabled and an Operator created before adding a failure notification to a job.","upvote_count":"2"},{"comment_id":"529363","upvote_count":"1","timestamp":"1658428200.0","content":"Answer is correct","poster":"Chunchi"},{"timestamp":"1652200140.0","comment_id":"475703","poster":"o2091","content":"looks correct","upvote_count":"2"}],"answer":"","answer_description":"Step 1: Enable Database Mail -\nIf it isn't already enabled, first you would need to configure the Database Mail feature on SQL Managed Instance.\nBox 2: Create an operator.\nYou can notify the operator that something happened with your SQL Agent jobs. An operator defines contact information for an individual responsible for the maintenance of one or more instances in SQL Managed Instance.\nBox 3: Add a failure notification to the job,\nYou can then modify any SQL Agent job and assign operators that will be notified via email if the job completes, fails, or succeeds using SSMS or the following T-\nSQL script:\nEXEC msdb.dbo.sp_update_job @job_name=N'Load data using SSIS',\n@notify_level_email=3, -- Options are: 1 on succeed, 2 on failure, 3 on complete\n@notify_email_operator_name=N'AzureSQLTeam';\nReference:\nhttps://docs.microsoft.com/en-us/azure/azure-sql/managed-instance/job-automation-managed-instance","topic":"5","isMC":false,"answers_community":[],"url":"https://www.examtopics.com/discussions/microsoft/view/65794-exam-dp-300-topic-5-question-10-discussion/","unix_timestamp":1636568940,"answer_images":["https://www.examtopics.com/assets/media/exam-media/04275/0024200002.jpg"],"question_text":"DRAG DROP -\nYou have an Azure subscription that contains an Azure SQL managed instance named SQLMi1 and a SQL Agent job named Backupdb. Backupdb performs a daily backup of the databases hosted on SQLMi1.\nYou need to be notified by email if the job fails.\nWhich three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\nNOTE: More than one order of answer choices is correct. You will receive credit for any of the correct orders you select.\nSelect and Place:\n//IMG//","question_id":242,"timestamp":"2021-11-10 19:29:00","exam_id":68,"answer_ET":""},{"id":"AeXTDru2dX5REuGsh7WP","question_id":243,"isMC":false,"answers_community":[],"discussion":[{"poster":"TheDataGuy","content":"Condition-->Policy->Evaluate.\nhttps://learn.microsoft.com/en-us/sql/relational-databases/policy-based-management/administer-servers-by-using-policy-based-management?view=sql-server-ver16","upvote_count":"1","timestamp":"1688056380.0","comment_id":"761365"},{"comments":[{"content":"Thanks man. Good way to remember.","upvote_count":"1","poster":"TheSwedishGuy","timestamp":"1731761760.0","comment_id":"1212387"}],"timestamp":"1682330640.0","comment_id":"702902","upvote_count":"3","content":"Remember CP: firts the Condition, then the Policy.","poster":"Ciupaz"},{"upvote_count":"3","comment_id":"568338","content":"Correct Answer\n\n-> Create a custom condition based on a built-in facet\n-> Create a custom policy based on a condition\n-> Run a policy evaluation\n\nhttps://www.mssqltips.com/sqlservertip/2298/enforce-sql-server-database-naming-conventions-using-policy-based-management/","poster":"reachmymind","timestamp":"1663235280.0"},{"comment_id":"536619","poster":"smaa","content":"https://docs.microsoft.com/en-us/sql/relational-databases/policy-based-management/administer-servers-by-using-policy-based-management?view=sql-server-ver15\n\nLooks like given answer is correct.","timestamp":"1659226440.0","upvote_count":"1"},{"content":"Existing answer is correct. We should create a condition before creating policy.","upvote_count":"1","comment_id":"517920","timestamp":"1657068240.0","poster":"Anandk291996"},{"timestamp":"1649552220.0","comments":[{"poster":"maxtohmilz","content":"you should create the condition before the policy\nhttps://www.red-gate.com/simple-talk/blogs/sql-server-policy-based-management-creating-a-custom-condition/","upvote_count":"4","timestamp":"1652856660.0","comment_id":"480539"},{"content":"Yes, The correct answer is BCF.","timestamp":"1649717400.0","comment_id":"460827","upvote_count":"1","poster":"learnazureportal"}],"content":"I think the correct answer is: B-C-F","upvote_count":"3","poster":"U_C","comment_id":"459826"}],"question_images":["https://www.examtopics.com/assets/media/exam-media/04275/0024400001.jpg"],"question_text":"DRAG DROP -\nYou have SQL Server on an Azure virtual machine.\nYou need to use Policy-Based Management in Microsoft SQL Server to identify stored procedures that do not comply with your naming conventions.\nWhich three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\nSelect and Place:\n//IMG//","url":"https://www.examtopics.com/discussions/microsoft/view/63878-exam-dp-300-topic-5-question-11-discussion/","answer":"","timestamp":"2021-10-10 02:57:00","unix_timestamp":1633827420,"answer_images":["https://www.examtopics.com/assets/media/exam-media/04275/0024400002.jpg"],"exam_id":68,"answer_ET":"","answer_description":"First create a condition, then a custom policy based on the condition, finally run a policy evaluation.\nReference:\nhttps://www.mssqltips.com/sqlservertip/2298/enforce-sql-server-database-naming-conventions-using-policy-based-management/","topic":"5"},{"id":"qUAuctwbAfS4vQ6X8n0n","isMC":true,"question_text":"You have an Azure SQL managed instance named SQLMI1 that hosts 10 databases.\nYou need to implement alerts by using Azure Monitor. The solution must meet the following requirements:\n✑ Minimize costs.\n✑ Aggregate Intelligent Insights telemetry from each database.\nWhat should you do?","choices":{"D":"From the Diagnostic settings of SQLMI1, select Stream to an event hub.","A":"From the Diagnostic settings of each database, select Send to Log Analytics.","B":"From the Diagnostic settings of each database, select Stream to an event hub.","C":"From the Diagnostic settings of SQLMI1, select Send to Log Analytics."},"url":"https://www.examtopics.com/discussions/microsoft/view/62637-exam-dp-300-topic-5-question-12-discussion/","answer":"A","discussion":[{"comment_id":"863994","upvote_count":"5","comments":[{"timestamp":"1706717520.0","upvote_count":"6","comments":[{"comment_id":"1239323","timestamp":"1719670620.0","content":"He has pasted most of the generative AI, Chat GPT etc content only.","poster":"Sr18","upvote_count":"1"}],"content":"Everyone should be careful about U_C, he always provides wrong answers randomly.","poster":"stevenwong","comment_id":"1136950"},{"comment_id":"881367","poster":"OBIJUAN88","timestamp":"1682500980.0","content":"Yes, but: \nTo configure streaming of diagnostic telemetry for managed instance and instance databases, you will need to separately configure each:\n\nEnable streaming of diagnostic telemetry for managed instance\nEnable streaming of diagnostic telemetry for each instance database\nThe managed instance container has its own telemetry separate from each instance database's telemetry.\n\nSo, we need to do both. In that case for me the best answer is A as is needed.\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/metrics-diagnostic-telemetry-logging-streaming-export-configure?tabs=azure-portal&view=azuresql#configure-the-streaming-export-of-diagnostic-telemetry","upvote_count":"5"}],"content":"The answer is C.\n\nC. From the Diagnostic settings of SQLMI1, select Send to Log Analytics.\n\nTo implement alerts by using Azure Monitor, the best approach is to send diagnostic data from the Azure SQL managed instance to Log Analytics. This approach meets both requirements, as it aggregates telemetry data from each database and minimizes costs. With Log Analytics, you can centralize and analyze diagnostic data from different sources, including Azure SQL Managed Instances, and set up alerts based on specific conditions.\n\nOption A would require setting up diagnostic settings for each database individually, which can be time-consuming and difficult to manage. Option B would require creating an event hub for each database, which could result in increased costs and complexity.","poster":"U_C","timestamp":"1680879120.0"},{"comment_id":"1302530","poster":"MVFGrant","content":"when you said \" Aggregate Intelligent Insights\", with this you eliminate event hub, because you need a database for further analytics (eliminated option B and D)... so Log Analytics is a better option, and to compile all information , A is better than C","upvote_count":"1","timestamp":"1729787400.0"},{"content":"Selected Answer: A\nI think the answer actually within the question \n\"Aggregate Intelligent Insights telemetry from EACH database\"\nIn addition I do agree with OBIJUAN88 comment.","upvote_count":"1","timestamp":"1726876500.0","comment_id":"1287076","poster":"Vitos25"},{"comment_id":"1007971","upvote_count":"1","content":"You can use the Diagnostics settings menu in the Azure portal to enable and configure streaming of diagnostic telemetry. \n\nAdditionally, you can use PowerShell, the Azure CLI, the REST API, and Resource Manager templates to configure streaming of diagnostic telemetry. \n\nYou can set the following destinations to stream the diagnostic telemetry: Azure Storage, Azure Event Hubs, and Azure Monitor logs.\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/metrics-diagnostic-telemetry-logging-streaming-export-configure?view=azuresql&tabs=azure-portal#configure-the-streaming-export-of-diagnostic-telemetry","timestamp":"1694734260.0","poster":"igorclapa"},{"timestamp":"1693296900.0","poster":"testdumps2017","comment_id":"992912","content":"https://learn.microsoft.com/en-us/azure/azure-sql/database/metrics-diagnostic-telemetry-logging-streaming-export-configure?tabs=azure-portal&view=azuresql#configure-the-streaming-export-of-diagnostic-telemetry\n\"To configure streaming of diagnostic telemetry for managed instance and instance databases, you need to separately configure each:\n\nEnable streaming of diagnostic telemetry for managed instance\nEnable streaming of diagnostic telemetry for each instance database\nThe managed instance container has its own telemetry separate from each instance database's telemetry.\" - so the provided answer is correct, we need to do it for each database.","upvote_count":"2"},{"poster":"HSQL","upvote_count":"1","content":"To configure streaming of diagnostic telemetry for managed instance and instance databases, you will need to separately configure each:\n\nEnable streaming of diagnostic telemetry for managed instance\nEnable streaming of diagnostic telemetry for each instance database\nThe managed instance container has its own telemetry separate from each instance database's telemetry.","timestamp":"1677677520.0","comment_id":"825889"},{"timestamp":"1632432960.0","content":"https://docs.microsoft.com/en-us/azure/azure-sql/database/metrics-diagnostic-telemetry-logging-streaming-export-configure?tabs=azure-portal#configure-the-streaming-export-of-diagnostic-telemetry","comment_id":"450532","upvote_count":"3","poster":"Aggie0702"}],"answer_images":[],"answers_community":["A (100%)"],"exam_id":68,"topic":"5","timestamp":"2021-09-23 23:36:00","answer_ET":"A","question_images":[],"answer_description":"Databases in Azure SQL Managed Instance\nYou can set up an instance database resource to collect the following diagnostic telemetry:\nTo enable streaming of diagnostic telemetry for an instance database, follow these steps:\n1. Go to instance database resource within managed instance.\n2. Select Diagnostics settings.\n3. Select Turn on diagnostics if no previous settings exist, or select Edit setting to edit a previous setting.\n4. Etc.\n5. Repeat the above steps for each instance database you want to monitor.\nReference:\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/metrics-diagnostic-telemetry-logging-streaming-export-configure?tabs=azure-portal#configure-the- streaming-export-of-diagnostic-telemetry","unix_timestamp":1632432960,"question_id":244},{"id":"DzpzcjSwEHToB1BsSjyS","isMC":true,"answer_ET":"D","timestamp":"2021-11-10 19:27:00","topic":"5","question_images":[],"answer_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/65791-exam-dp-300-topic-5-question-13-discussion/","answers_community":[],"question_id":245,"question_text":"You have an Azure SQL managed instance that hosts multiple databases.\nYou need to configure alerts for each database based on the diagnostics telemetry of the database.\nWhat should you use?","exam_id":68,"choices":{"D":"Azure SQL Analytics alerts based on diagnostics logs","A":"Azure SQL Analytics alerts based on metrics","C":"SQL Health Check alerts based on metrics","B":"SQL Health Check alerts based on diagnostics logs"},"unix_timestamp":1636568820,"answer_description":"You can use Azure SQL Analytics for monitoring and alerting.\nYou can easily create alerts with the data coming from Azure SQL Database resources. Here are some useful log queries that you can use with a log alert:\nExample, HIGH CPU:\n\nAzureMetrics -\n| where ResourceProvider==\"MICROSOFT.SQL\"\n| where ResourceId contains \"/DATABASES/\"\n| where MetricName==\"cpu_percent\"\n| summarize AggregatedValue = max(Maximum) by bin(TimeGenerated, 5m)\n| render timechart\nNote: Azure Monitor Logs is based on Azure Data Explorer, and log queries are written using the same Kusto query language (KQL).\nReference:\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/metrics-diagnostic-telemetry-logging-streaming-export-configure?tabs=azure-portal#configure-the- streaming-export-of-diagnostic-telemetry","answer":"D","discussion":[{"comment_id":"818997","timestamp":"1724396400.0","upvote_count":"3","content":"D. Azure SQL Analytics alerts based on diagnostics logs","poster":"KIET2131"},{"timestamp":"1720355220.0","content":"For the standard, event-based monitoring experience, select the following check boxes for database diagnostics log telemetry: SQLInsights, AutomaticTuning, QueryStoreRuntimeStatistics, QueryStoreWaitStatistics, Errors, DatabaseWaitStatistics, Timeouts, Blocks, and Deadlocks.\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/metrics-diagnostic-telemetry-logging-streaming-export-configure?view=azuresql&tabs=azure-portal","comment_id":"768622","poster":"OneplusOne","upvote_count":"1"},{"upvote_count":"3","comment_id":"475699","poster":"o2091","timestamp":"1683736020.0","content":"looks good, what do you think?"}]}],"exam":{"isBeta":false,"isMCOnly":false,"id":68,"isImplemented":true,"provider":"Microsoft","numberOfQuestions":360,"lastUpdated":"12 Apr 2025","name":"DP-300"},"currentPage":49},"__N_SSP":true}