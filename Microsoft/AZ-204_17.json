{"pageProps":{"questions":[{"id":"MYvfHakLTAioRZ0a07wi","isMC":true,"url":"https://www.examtopics.com/discussions/microsoft/view/26836-exam-az-204-topic-2-question-20-discussion/","choices":{"C":"Process all Azure Storage Analytics logs for successful blob events.","A":"Process all Azure Blob storage events by using Azure Event Grid with a subscriber Azure Function app.","B":"Enable the change feed on the storage account and process all changes for available events.","D":"Use the Azure Monitor HTTP Data Collector API and scan the request body for successful blob events."},"answers_community":["B (100%)"],"question_text":"You are developing an application that uses Azure Blob storage.\nThe application must read the transaction logs of all the changes that occur to the blobs and the blob metadata in the storage account for auditing purposes. The changes must be in the order in which they occurred, include only create, update, delete, and copy operations and be retained for compliance reasons.\nYou need to process the transaction logs asynchronously.\nWhat should you do?","answer_description":"","question_images":[],"answer_ET":"B","topic":"2","question_id":81,"answer":"B","discussion":[{"timestamp":"1595925480.0","upvote_count":"79","comments":[{"content":"Right!","timestamp":"1624118640.0","comment_id":"385605","poster":"azurelearner666","upvote_count":"3"}],"comment_id":"145571","poster":"Ummara","content":"B: the change feed provides transaction logs of all the changes that occur to the blobs and the blob metadata in your storage account. The change feed provides ordered, guaranteed, a durable, immutable, read-only log of these changes. You can process these logs asynchronously, incrementally or in-full."},{"timestamp":"1622369520.0","upvote_count":"20","content":"Correct Answer: B\n\nThe purpose of the change feed is to provide transaction logs of all the changes that occur to the blobs and the blob metadata in your storage account. The change feed provides ordered, guaranteed, durable, immutable, read-only log of these changes. Client applications can read these logs at any time, either in streaming or in batch mode. The change feed enables you to build efficient and scalable solutions that process change events that occur in your Blob Storage account at a low cost.\n\n\nReference:\n\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-change-feed","poster":"mlantonis","comment_id":"370058"},{"content":"Selected Answer: B\nb","timestamp":"1728963780.0","upvote_count":"1","poster":"CESBCN","comment_id":"1297936"},{"comment_id":"1260035","content":"I think B is correct now, but I see copy operation and guessed that's not a change.","upvote_count":"1","timestamp":"1722631980.0","poster":"darcimf"},{"upvote_count":"2","comment_id":"1208791","content":"Ans --> A\n\nEnabling the change feed on the storage account) might not be the ideal choice for asynchronously processing transaction logs of blob changes for auditing purposes, compared to using Azure Event Grid:\n\nChange Feed vs. Azure Event Grid:\n Enabling the change feed on the storage account provides a log of blob changes, but it's designed more for data replication and integration scenarios rather than real-time event processing.\n Azure Event Grid, on the other hand, is specifically tailored for event-driven architectures and can deliver near real-time notifications about blob operations, which is crucial for auditing purposes where timeliness and reliability of events matter.","poster":"Sanjeev5131","timestamp":"1715248740.0"},{"comment_id":"1135581","upvote_count":"2","poster":"Jak007","content":"Selected Answer: B\nB) As stated by Exam topics.\nThey also provide the link to the Learn resource. Highly recommend reading it. One of the best Learn articles I've come across! \nhttps://learn.microsoft.com/en-us/azure/storage/blobs/storage-blob-change-feed?tabs=template","timestamp":"1706599680.0"},{"timestamp":"1684669560.0","content":"Selected Answer: B\nas is correct","comment_id":"903155","poster":"deathRac3","upvote_count":"2"},{"comment_id":"855362","upvote_count":"4","content":"Question was in Exam 2023-03-30","poster":"Saluk_DE","timestamp":"1680161040.0"},{"content":"Selected Answer: B\nExactly what Change Feed offers","upvote_count":"1","poster":"NombreFalso","timestamp":"1676766780.0","comment_id":"813602"},{"upvote_count":"1","comment_id":"785587","content":"Selected Answer: B\nB. Enable the change feed on the storage account and process all changes for available events.\nAzure Blob storage change feed provides a log of all the create, update, delete, and copy operations that occur on blobs and blob metadata in the storage account. It allows you to track the changes to the blobs in the order in which they occurred, which is what you need for auditing purposes. By enabling the change feed, your application can asynchronously process the changes and retain them for compliance reasons. You can also use Azure Event Grid to route the change feed events to a subscriber Azure Function app for further processing, this way you can keep the logs for the compliance reasons.","timestamp":"1674490560.0","poster":"alexein74"},{"poster":"carlosghosn","comment_id":"726586","content":"Got this in the exam today ! Nov 25, 2022","timestamp":"1669369380.0","upvote_count":"2"},{"poster":"AZAdam22","content":"Selected Answer: B\nB - Because change feed contains an ordered list of operations that have been made in a storage account.","timestamp":"1658073240.0","upvote_count":"1","comment_id":"632607"},{"comment_id":"613922","timestamp":"1654772340.0","content":"Selected Answer: B\nB is correct answer.","poster":"Eltooth","upvote_count":"1"},{"poster":"hamzabts","content":"B : The purpose of the change feed is to provide transaction logs of all the changes that occur to the blobs and the blob metadata in your storage account.","comment_id":"596424","upvote_count":"1","timestamp":"1651589760.0"},{"comment_id":"553678","timestamp":"1645534500.0","poster":"Freidrich","content":"Selected Answer: B\nCorrect.","upvote_count":"1"},{"poster":"HimanshuNankani","comment_id":"460940","timestamp":"1634021700.0","comments":[{"poster":"santoshsidnal","comment_id":"616501","content":"That’s a valid question!! I think we should use event grid approach i.e A","timestamp":"1655258040.0","upvote_count":"1","comments":[{"poster":"[Removed]","upvote_count":"1","comment_id":"682496","content":"BlobDeleted is supported eventType and even if it is not supported still the requirement that it should be ordered cannot be satisfier with the blob-storage-events through event-grid. Change feed supports ordering","timestamp":"1664443380.0"}]}],"upvote_count":"6","content":"What about the delete operations that are not logged by the change feed?"},{"content":"enabled change feed to get information and for auditing or compliance purpose","timestamp":"1627846500.0","upvote_count":"1","poster":"ozbonny","comment_id":"418396"},{"poster":"UnknowMan","content":"Correct B","comment_id":"361992","timestamp":"1621501980.0","upvote_count":"3"},{"upvote_count":"1","timestamp":"1620880080.0","comment_id":"355988","content":"B. Enable the change feed on the storage account and process all changes for available events.","poster":"glam"},{"timestamp":"1619616540.0","comment_id":"344674","poster":"siddharth","upvote_count":"1","content":"B is correct"},{"comment_id":"304914","poster":"jokergester","content":"For those who are confused with Azure Storage Analytics logging, read below. It also contains information about \"Change Feed\"\n\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-change-feed?tabs=azure-portal#what-is-the-difference-between-change-feed-and-storage-analytics-logging","timestamp":"1615086000.0","upvote_count":"8"},{"content":"correct","comment_id":"292810","upvote_count":"2","timestamp":"1613589300.0","poster":"dancsita"},{"poster":"Dilipk84","content":"correct","timestamp":"1610726220.0","comment_id":"268038","upvote_count":"2"},{"content":"Correct","timestamp":"1610173800.0","upvote_count":"2","poster":"khoant","comment_id":"263031"},{"content":"yes B is correct","upvote_count":"3","poster":"dineshkm06tnj","comment_id":"214850","timestamp":"1604782620.0"}],"timestamp":"2020-07-28 10:38:00","unix_timestamp":1595925480,"exam_id":48,"answer_images":[]},{"id":"tlFC9LEKodUOnzo0PZ1T","answer_images":["https://img.examtopics.com/az-204/image582.png"],"answer":"","discussion":[{"poster":"agueda","timestamp":"1615593720.0","comment_id":"309286","upvote_count":"303","content":"It should be:\n- FROM\n- WORKDIR\n- COPY\n- RUN\n- CMD\n\nSame question on:\nhttps://www.examtopics.com/discussions/microsoft/view/13131-exam-az-300-topic-3-question-4-discussion/\n\nAnd:\nhttps://www.examtopics.com/discussions/microsoft/view/11045-exam-az-203-topic-1-question-7-discussion/","comments":[{"timestamp":"1734082800.0","upvote_count":"1","comment_id":"1326071","poster":"PereCastor37","content":"Agree with you :\nDockerfile example by chatgpt 4o without give him the sentence : \nFROM\nWORKDIR\nCOPY\nRUN\nCMD"},{"upvote_count":"5","timestamp":"1642490580.0","poster":"Den1354","comment_id":"526369","content":"- FROM\n- COPY\n- WORKDIR\n- RUN\n- CMD\n\nOtherwise we are going to set for work directory path which doesn't exist yet","comments":[{"upvote_count":"4","content":"True \nFROM microsoft/aspnetcore:latest\nThis command specifies the base image for your container.\n\nWORKDIR /apps/ContosoApp\nThis command sets the working directory for the container. \n\nCOPY ./ .\nThis command copies all files and folders from the current directory (where the Dockerfile resides) to the working directory (/apps/ContosoApp) inside the container. \n\nRUN powershell ./setupScript.ps1\nThis command runs the setupScript.ps1 script using PowerShell within the container during the build process. \n\nCMD [\"dotnet\", \"ContosoApp.dll\"]\nThis command defines the default command that will be executed when the container starts.","poster":"zolani","comment_id":"1194214","timestamp":"1712906100.0"}]},{"comment_id":"309710","timestamp":"1615641540.0","comments":[{"upvote_count":"3","timestamp":"1615793820.0","comment_id":"311229","comments":[{"poster":"ranjitklive","comment_id":"415512","upvote_count":"3","content":"ENTRYPOINT instruction works very similarly to CMD in that it is used to specify the command executed when the container is started.","timestamp":"1627393680.0"},{"content":"which udemy course you guys are talking about?","timestamp":"1634877840.0","upvote_count":"2","poster":"solidrock","comment_id":"465996"},{"comment_id":"324931","comments":[{"upvote_count":"3","comments":[{"comment_id":"559538","poster":"Adediwura","timestamp":"1646236260.0","upvote_count":"1","content":"Very well said. The ENTRYPOIINT command overrides the CMD command asides that there is no difference. Both are use to create executables that will handle any arguments given to docker run"}],"content":"Actually the correct answers are here. Because, on Udemy, you are provided with CMD and ENTRYPOINT options for the script and the dll. None of these are build-time commands. Both of them are executed when you run the container.\nActually, here, on ExamTopics the RUN command runs the script at build time (which is correct) and the CMD runs the dll (given there is no other command specific at command line when the container is run. Otherwise the CMD command will be overwritten. This is the main difference between CMD and ENTRYPOINT). Sorry for the detailed explanation between CMD and ENTRYPOINT","comment_id":"382112","poster":"nychollas","timestamp":"1623700380.0"}],"timestamp":"1617183060.0","poster":"kwaazaar","content":"cmd is for runtime, not build-time.","upvote_count":"1"}],"content":"as per Udemy, the last steps would be CMD powershell ./script.ps1 and then ENTRYPOINT (dotnet, xx.dll) which I believe is the correct answer. But unfortunately the options are not there in Examtopic","poster":"Basu525"}],"upvote_count":"29","poster":"Dinima","content":"You are correct. This has been discussed in Udemy course as well as follows, \nThe first statement in the Dockefile must be the FROM statement to specify the image to use as the base image.\n\nThen specify the Image working directory\n\nThen copy all of the application contents using the COPY command\n\nAnd then use the CMD command to run the PowerShell command and the ENTRYPOINT statement to run the dotnet application."},{"timestamp":"1647768180.0","poster":"balis","upvote_count":"14","content":"This is correct answer\nIt should be:\n- FROM\n- WORKDIR\n- COPY\n- RUN\n- CMD\nbecause WORKDIR will create directory if it doesn't exist https://docs.docker.com/engine/reference/builder/#workdir","comment_id":"571516"},{"upvote_count":"3","poster":"ReyPirata","comment_id":"986708","content":"This was on the exam (08/20/2023). Scored 925\n\n- FROM\n- WORKDIR\n- COPY\n- RUN\n- CMD","timestamp":"1692635640.0"}]},{"content":"Just wondering who put the answers for the questions in this site? most of them are not correct.","comments":[{"timestamp":"1624620660.0","comment_id":"390389","content":"VCE exams have same issues \nProbably this are some braindumps of people who were not well prepared to take test or they too test just to scrap exam questions but they have no matter knowledge","upvote_count":"4","poster":"SlavMar"}],"upvote_count":"25","timestamp":"1623497160.0","poster":"TakumaK","comment_id":"380415"},{"timestamp":"1731181800.0","content":"FROM mcr.microsoft.com/dotnet/aspnet:latest\nWORKDIR /apps/ContosoApp\nCOPY ./ .\nRUN powershell ./setupScript.ps1\nCMD [\"dotnet\", \"ContosoApp.dll\"]","poster":"heptadecane","upvote_count":"3","comment_id":"1309192"},{"upvote_count":"1","timestamp":"1724208960.0","poster":"4bd3116","comment_id":"1269797","content":"FROM microsoft/aspnetcore:latest\nCOPY . /apps/ContosoApp\nWORKDIR /apps/ContosoApp\nRUN powershell ./setupScript.ps1\nCMD [\"dotnet\", \"ContosoApp.dll\"]"},{"timestamp":"1723668840.0","poster":"ciamp","upvote_count":"1","comment_id":"1265971","content":"FROM ubuntu:latest\nWORKDIR /app\nCOPY . /app\nRUN apt-get update && apt-get install -y <dependencies>\nCMD [\"executable\", \"param1\", \"param2\"]"},{"upvote_count":"3","content":"Got it in the exam 13.03.2024. Score: 910. Went with \n- FROM\n- WORKDIR\n- COPY\n- RUN\n- CMD","timestamp":"1710362640.0","comment_id":"1172897","poster":"onlyforheros"},{"upvote_count":"3","comment_id":"1136777","content":"Answer is \n-FROM\n-RUN\n-WORKDIR\n- COPY\n- CMD\ncheck this link\nhttps://learn.microsoft.com/en-us/training/modules/intro-to-docker-containers/3-how-docker-images-work","timestamp":"1706707620.0","poster":"AhmedAbdelAziz"},{"timestamp":"1704467340.0","comment_id":"1114585","content":"Here are the five commands you can use in the Dockerfile:\n\nFROM: Specify the base image.\n\nDockerfile\nCopy code\nFROM mcr.microsoft.com/dotnet/core/aspnet:3.1\nCOPY: Copy the application files to the container.\n\nDockerfile\nCopy code\nCOPY . /app\nWORKDIR: Set the working directory to the application folder.\n\nDockerfile\nCopy code\nWORKDIR /app\nRUN: Execute the setup script during the image build process.\n\nDockerfile\nCopy code\nRUN ./setupScript.ps1\nCMD: Specify the command to run when the container starts.\n\nDockerfile\nCopy code\nCMD [\"dotnet\", \"ContosoApp.dll\"]\nMake sure to adjust the paths and filenames according to your actual file structure.","poster":"manopeydakon","upvote_count":"2"},{"timestamp":"1702539780.0","content":"Got it in the exam 14/12/23. All questions are from ExamTopics. Case study - VanArsdel, Ltd (11 questions)","upvote_count":"1","poster":"arunkuml","comment_id":"1096154"},{"comment_id":"1020171","poster":"p2006","upvote_count":"3","timestamp":"1695927360.0","content":"Got on 9/25/2023\nFrom\nWorkdir\nCopy\nRun powershell\nCmd ContosoApp.dll"},{"poster":"RuffBoii","content":"Had this on my exam today.","upvote_count":"1","comment_id":"1013891","timestamp":"1695373500.0"},{"upvote_count":"1","comment_id":"993823","timestamp":"1693382580.0","poster":"mihailos","content":"Got it in exam 28/08/23. Scored 912. Went with the following:\n- FROM\n- WORKDIR\n- COPY\n- RUN\n- CMD","comments":[{"upvote_count":"1","poster":"TechyNetty","timestamp":"1693745520.0","comment_id":"997624","content":"Im yet to appear for exam soon. Since you attempted recently, were most of the questions from this site? Please respond, it will be helpful. thanks"}]},{"poster":"longnguyendh","comment_id":"966425","content":"■ FROM …\n■ WORKDIR …\n■ COPY …\n■ RUN …\n■ CMD …","timestamp":"1690636680.0","upvote_count":"1"},{"content":"Question was there for me on 29th May 2023","upvote_count":"1","timestamp":"1685698500.0","comment_id":"912692","poster":"deathRac3"},{"timestamp":"1676887680.0","content":"Got this in exam today..20/02/23\nscore: 817","poster":"70PineApple","comment_id":"815080","upvote_count":"1"},{"comment_id":"814996","content":"Got this question today on 20-02-2023 exam.","upvote_count":"1","poster":"Priya0703","timestamp":"1676881080.0"},{"poster":"HafizSalmanMalik","timestamp":"1673878800.0","content":"It should be:\n- FROM\n- WORKDIR\n- COPY\n- RUN\n- CMD","upvote_count":"3","comment_id":"777760"},{"content":"Got this in the exam today ! Nov 25, 2022","upvote_count":"3","comment_id":"726587","poster":"carlosghosn","timestamp":"1669369380.0"},{"timestamp":"1661575080.0","comment_id":"652456","content":"Answer seems to be wrongly documented, it should be like this.\n- FROM\n- WORKDIR\n- COPY\n- RUN\n- CMD","upvote_count":"3","poster":"ghuna"},{"upvote_count":"3","content":"For any doubt between RUN and CMD:\nThe requirement is something like this as per the question:\n✑ Call setupScripts.ps1 when the container is built. ( so definitely RUN comes first)\n✑ Run ContosoApp.dll when the container starts. (Therefore CMD comes next)\nRest of the above are quite clear for most of the users:\nFROM\nWORKDIR\nCOPY\nRUN\nCMD","poster":"samraw83","timestamp":"1658561100.0","comment_id":"635471"},{"poster":"angrybird2007","timestamp":"1657253700.0","upvote_count":"3","comment_id":"628607","content":"https://docs.docker.com/samples/dotnetcore/\n\n# syntax=docker/dockerfile:1\nFROM mcr.microsoft.com/dotnet/sdk:6.0 AS build-env\nWORKDIR /app\n\n# Copy csproj and restore as distinct layers\nCOPY *.csproj ./\nRUN dotnet restore\n\n# Copy everything else and build\nCOPY ../engine/examples ./\nRUN dotnet publish -c Release -o out\n\n# Build runtime image\nFROM mcr.microsoft.com/dotnet/aspnet:6.0\nWORKDIR /app\nCOPY --from=build-env /app/out .\nENTRYPOINT [\"dotnet\", \"aspnetapp.dll\"]"},{"content":"do they deliberately give you the wrong answers at this website to prompt discussion?","upvote_count":"4","timestamp":"1656638040.0","poster":"Pize","comment_id":"625509"},{"comment_id":"623914","poster":"prachi190892","content":"The Dockerfile will have below series of commands:\nFROM\nWORKDIR\nCOPY\nRUN: command that runs while the images builds\nCMD: command that runs when the container is created","timestamp":"1656413820.0","upvote_count":"2"},{"timestamp":"1654772820.0","upvote_count":"1","comment_id":"613941","poster":"Eltooth","content":"- FROM\n- WORKDIR\n- COPY\n- RUN\n- CMD"},{"upvote_count":"3","comment_id":"584301","content":"Got this on 04/05/22 (selected FROM - WORKDIR - COPY - RUN - CMD)","poster":"AZ204Cert","timestamp":"1649693460.0"},{"timestamp":"1649273280.0","content":"New to the site - it's disturbing how many answers that I see that conflict with top rated discussion comments. Anyone know how answers listed are determined? Is it scored automatically somehow?","comment_id":"582003","upvote_count":"1","poster":"Evo_Morales"},{"timestamp":"1646859240.0","content":"Got it in exam 03/22","poster":"petitbilly","upvote_count":"2","comment_id":"564327"},{"timestamp":"1646656680.0","comment_id":"562612","content":"Got this in the exam 03/22","upvote_count":"1","poster":"Baskman"},{"timestamp":"1646453640.0","content":"Got this in the real exam on 03/22, cleared it - Went with FROM / WORKDIR/COPY/RUN/CMD","upvote_count":"5","poster":"Alasmindas","comment_id":"561167"},{"timestamp":"1645701360.0","comment_id":"555207","upvote_count":"4","content":"According to docker: \n\nhttps://docs.docker.com/samples/rails/\n\nFROM\nWORKDIR\nCOPY\nRUN\nCMD","poster":"DonOnur"},{"comment_id":"542284","poster":"oescm","content":"Got this one 02/2022. Went with highly voted answer.","timestamp":"1644230400.0","upvote_count":"3"},{"content":"Got this in the exam 01/22","upvote_count":"2","comment_id":"529067","poster":"Mev4953","timestamp":"1642759080.0"},{"comment_id":"527578","content":"Got this one 01/2022. Wen with most voted (to avoid writing answers again)","timestamp":"1642602480.0","upvote_count":"2","poster":"lugospod"},{"content":"It should be:\n- FROM\n- WORKDIR\n- COPY\n- RUN\n- CMD\nCMD cannot be before FROM\nReference: https://docs.docker.com/engine/reference/builder/","upvote_count":"2","poster":"Arnab101","timestamp":"1642103760.0","comment_id":"523051"},{"upvote_count":"2","timestamp":"1640978040.0","content":"FROM\nWORKDIR\nCOPY\nRUN\nCMD","poster":"AidenYoukhana","comment_id":"514195"},{"content":"FROM \nWORKDIR\nCOPY\nRUN\nCMD","comment_id":"468059","upvote_count":"1","timestamp":"1635253980.0","poster":"Gautam47"},{"poster":"Drummer","content":"In this other old exam has the same question\nhttps://www.examtopics.com/discussions/microsoft/view/13131-exam-az-300-topic-3-question-4-discussion/\n\nAnaswer is\n1: FROM \n2: WORKDIR \n3: COPY \n4: RUN \n5: CMD","timestamp":"1630782900.0","comment_id":"439330","upvote_count":"5"},{"comments":[{"timestamp":"1635029460.0","poster":"jvyas","upvote_count":"3","comment_id":"466767","content":"I think they do it on purpose, so that they don't get removed or something."}],"content":"Seems that the person who posted this answer wants people to fail the exam.","timestamp":"1630711200.0","comment_id":"438763","poster":"ewertonews","upvote_count":"4"},{"timestamp":"1630487460.0","poster":"drw85","upvote_count":"3","content":"Not only is the answer completely wrong, the explanation is absolute garbage aswell.\nCMD is the docker entrypoint, it's what docker runs when the container is started.\nHas nothing to do with cmd.exe or anthing like that...","comment_id":"436997"},{"upvote_count":"5","poster":"Lukaz","comment_id":"431745","timestamp":"1629923520.0","content":"Answer should be:\nFROM microsoft/aspnetcore-build:latest\nWORKDIR /apps/ContosoApp\n COPY ./ .\nRUN powershell ./setupScript.ps1\nCMD [\"dotnet\", \"aspnetapp.dll\"]"},{"content":"all examples that I found was like \nFROM node:latest\nWORKDIR /usr/src/app\nCOPY package.json .\nRUN npm install\nCOPY . ./\nEXPOSE 3000\nCMD [ “npm”, “start” ] \nso I will go by for what I found","upvote_count":"3","timestamp":"1627846740.0","poster":"ozbonny","comment_id":"418398"},{"poster":"Nekerobert","comment_id":"397826","upvote_count":"4","timestamp":"1625341620.0","content":"The answer doesn't look correct at all. The command to build a Dockerfile is...\n1: FROM\n2: WORKDIR\n3: COPY\n4: RUN\n5: CMD"},{"timestamp":"1624852680.0","poster":"DParekh","comment_id":"392566","content":"wrong answer","upvote_count":"2"},{"comment_id":"381973","poster":"if54uran","timestamp":"1623684900.0","content":"Where do these answers even come from?","upvote_count":"4"},{"timestamp":"1622369580.0","upvote_count":"7","content":"Step 1: FROM\nStep 2: WORKDIR\nStep 3: COPY\nStep 4: RUN\nStep 5: CMD\n\nThe WORKDIR instruction sets the working directory for any RUN, CMD, ENTRYPOINT, COPY and ADD instructions that follow it in the Dockerfile. If the WORKDIR doesn’t exist, it will be created even if it’s not used in any subsequent Dockerfile instruction.\n\nReference:\nhttps://docs.docker.com/develop/develop-images/dockerfile_best-practices","poster":"mlantonis","comment_id":"370059"},{"poster":"mlantonis","comment_id":"362980","content":"1: FROM\n2: WORKDIR\n3: COPY\n4: RUN\n5: CMD\n\nThe WORKDIR instruction sets the working directory for any RUN, CMD, ENTRYPOINT, COPY and ADD instructions that follow it in the Dockerfile. If the WORKDIR doesn’t exist, it will be created even if it’s not used in any subsequent Dockerfile instruction.\n\nReference:\n\nhttps://docs.docker.com/develop/develop-images/dockerfile_best-practices \n\nhttps://stackoverflow.com/a/51066379/10412018","upvote_count":"6","timestamp":"1621598220.0"},{"comment_id":"355991","upvote_count":"3","timestamp":"1620880380.0","content":"It should be:\n- FROM\n- WORKDIR\n- COPY\n- RUN\n- CMD","poster":"glam"},{"poster":"TakumaK","upvote_count":"4","timestamp":"1620216360.0","content":"How even did this site find the answer totally wrong? One tip I need to keep in mind with ExamTopics is to check the comments first (even get more confused tho).\n\nFor this question, refer to the link below.\nhttps://docs.docker.com/develop/develop-images/dockerfile_best-practices/","comment_id":"350271"},{"content":"FROM\n- WORKDIR\n- COPY\n- RUN\n- CMD\nis correct order","comment_id":"348869","poster":"hems4all","timestamp":"1620063780.0","upvote_count":"3"},{"poster":"shocks","upvote_count":"1","comment_id":"346167","content":"You won't be able to execute Contoso.dll in an empty container.","timestamp":"1619785740.0"},{"content":"An answer that advocates having CMD before FROM in a Dockerfile... what a joke.","comment_id":"331275","upvote_count":"4","timestamp":"1617891840.0","poster":"Deputy_Cartman"},{"upvote_count":"4","poster":"Whirly","timestamp":"1616958060.0","content":"From MS website\n\n# https://hub.docker.com/_/microsoft-dotnet\nFROM mcr.microsoft.com/dotnet/sdk:5.0 AS build\nWORKDIR /source\n\n# copy csproj and restore as distinct layers\nCOPY *.sln .\nCOPY aspnetapp/*.csproj ./aspnetapp/\nRUN dotnet restore\n\n# copy everything else and build app\nCOPY aspnetapp/. ./aspnetapp/\nWORKDIR /source/aspnetapp\nRUN dotnet publish -c release -o /app --no-restore\n\n# final stage/image\nFROM mcr.microsoft.com/dotnet/aspnet:5.0\nWORKDIR /app\nCOPY --from=build /app ./\nENTRYPOINT [\"dotnet\", \"aspnetapp.dll\"]","comment_id":"322856"},{"upvote_count":"4","content":"It should be in :\n- FROM\n- WORKDIR\n- COPY\n- RUN\n- CMD","comment_id":"315095","poster":"Rorrs","timestamp":"1616181360.0"}],"answer_ET":"","unix_timestamp":1615593720,"url":"https://www.examtopics.com/discussions/microsoft/view/46808-exam-az-204-topic-2-question-21-discussion/","answer_description":"","exam_id":48,"question_text":"DRAG DROP -\nYou plan to create a Docker image that runs an ASP.NET Core application named ContosoApp. You have a setup script named setupScript.ps1 and a series of application files including ContosoApp.dll.\nYou need to create a Dockerfile document that meets the following requirements:\n✑ Call setupScripts.ps1 when the container is built.\n✑ Run ContosoApp.dll when the container starts.\nThe Dockerfile document must be created in the same folder where ContosoApp.dll and setupScript.ps1 are stored.\nWhich five commands should you use to develop the solution? To answer, move the appropriate commands from the list of commands to the answer area and arrange them in the correct order.\nSelect and Place:\n//IMG//","question_id":82,"timestamp":"2021-03-13 01:02:00","answers_community":[],"topic":"2","question_images":["https://www.examtopics.com/assets/media/exam-media/04273/0012100001.png"],"isMC":false},{"id":"H4SvuHgnqbUIqTiQnwiT","answer_images":[],"choices":{"A":"Use an App Service plan. Configure the Function App to use an Azure Blob Storage input trigger.","D":"Use an App Service plan. Configure the Function App to use an Azure Blob Storage trigger.","B":"Use a Consumption plan. Configure the Function App to use an Azure Blob Storage trigger.","E":"Use a Consumption plan. Configure the Function App to use an Azure Blob Storage input trigger.","C":"Use a Consumption plan. Configure the Function App to use a Timer trigger."},"topic":"2","question_id":83,"answer_description":"","answers_community":["D (92%)","8%"],"isMC":true,"timestamp":"2021-02-08 15:30:00","question_images":[],"exam_id":48,"answer":"D","url":"https://www.examtopics.com/discussions/microsoft/view/44278-exam-az-204-topic-2-question-22-discussion/","unix_timestamp":1612794600,"question_text":"You are developing an Azure Function App that processes images that are uploaded to an Azure Blob container.\nImages must be processed as quickly as possible after they are uploaded, and the solution must minimize latency. You create code to process images when the\nFunction App is triggered.\nYou need to configure the Function App.\nWhat should you do?","discussion":[{"comments":[{"upvote_count":"4","comments":[{"upvote_count":"34","content":"Seemingly there is no such thing as \"input trigger\" it is \"input binding\"\nSee: https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-blob-input?tabs=csharp","timestamp":"1626511740.0","comment_id":"408349","poster":"zzt"},{"comment_id":"390400","content":"I ment A","timestamp":"1624621020.0","upvote_count":"1","poster":"SlavMar"}],"content":"Why not B then. \nUsing input for function apps seems to make more sense","poster":"SlavMar","comment_id":"390398","timestamp":"1624620960.0"},{"comment_id":"1191710","timestamp":"1712596740.0","upvote_count":"1","poster":"nosby","content":"Agree. https://learn.microsoft.com/en-us/azure/azure-functions/functions-scale#cold-start-behavior"},{"upvote_count":"2","poster":"samraw83","content":"App service plan is best for the long running scenarios where you cannot use durable functions.","timestamp":"1656545040.0","comment_id":"624938"},{"poster":"OscarL","upvote_count":"1","timestamp":"1688185740.0","comment_id":"939581","content":"totally agree"},{"poster":"Dinima","timestamp":"1615641960.0","comment_id":"309719","content":"True, D, We have to use an Azure Blob storage trigger. In order to ensure the function is invoked immediately , m","upvote_count":"8"}],"poster":"Kitkit","comment_id":"287124","timestamp":"1612902360.0","upvote_count":"205","content":"The answer is D. Use an App Service plan. Configure the Function App to use an Azure Blob Storage trigger. \nConsumption plan can cause a 10-min delay in processing new blobs if a function app has gone idle. To avoid this latency, you can switch to an App Service plan with Always On enabled. \nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-blob-trigger?tabs=csharp"},{"upvote_count":"24","timestamp":"1612807140.0","comments":[{"content":"Agree with your point, all triggers are input..!!","comments":[{"upvote_count":"3","poster":"ewertonews","timestamp":"1630711560.0","comment_id":"438767","content":"But that nomenclature is not used by MS. \nA function can have a trigger and a input binding (HTTP trigger with a Storage Queue as input binding for example)."}],"comment_id":"415513","timestamp":"1627394280.0","upvote_count":"3","poster":"ranjitklive"},{"comments":[{"timestamp":"1681554240.0","upvote_count":"1","comment_id":"870836","content":"exactly my friend. I was trying to find info about it and as I was thinking, there is no such thing","poster":"surprise0011"}],"upvote_count":"13","timestamp":"1630711440.0","content":"It cannot be A. There is no such thing as a input trigger. it's either a (Blob Storage) trigger or an input binding. They are different things.","comment_id":"438766","poster":"ewertonews"}],"content":"A or D, never B.\nWith Consumption plan, you could have cold start, and the question say \"must be processed as quickly as possible\" so you need an App Service Plan.\nBetween A and D ... All triggers are Input, so i don´t undertand the difference.","poster":"danielcr","comment_id":"286360"},{"comment_id":"1363014","content":"Selected Answer: D\nInput binding not input trigger, it doesn't exist","upvote_count":"1","timestamp":"1740748200.0","poster":"Iaminall"},{"content":"Selected Answer: D\nResponse of copilot:\nTo minimize both latency and cost for uploading media to Azure Blob Storage, the Premium Plan would be the best choice. Here's why:\n\nLatency: The Premium Plan eliminates cold starts by keeping instances warm, which means your function will respond faster when triggered.\n\nCost: While the Premium Plan has a higher base cost compared to the Consumption Plan, it offers more predictable pricing and can be more cost-effective if your function runs continuously or frequently.\n\nThe Consumption Plan is cost-effective for sporadic workloads but may suffer from cold starts, leading to higher latency. The Service Plan provides more control and can be kept \"Always On,\" but it might be more expensive for infrequent use.\n\nSo the answer is D","timestamp":"1737010980.0","comment_id":"1341505","poster":"bouda19","upvote_count":"1"},{"poster":"DD7826","content":"Selected Answer: B\nTo process images as quickly as possible after they are uploaded to an Azure Blob container and minimize latency, you should:\n\nB. Use a Consumption plan. Configure the Function App to use an Azure Blob Storage trigger.\n\nThis configuration ensures that your Function App is triggered immediately when a new image is uploaded to the Blob container, leveraging the serverless nature of the Consumption plan to scale automatically and handle the processing efficiently","timestamp":"1736068620.0","upvote_count":"1","comment_id":"1336691"},{"content":"B. Use a Consumption plan. Configure the Function App to use an Azure Blob Storage trigger.\n\nHere's why:\n\nConsumption Plan: This plan is optimized for event-driven tasks like image processing, and it automatically scales based on the number of incoming requests, ensuring that images are processed as quickly as possible. The Function App will scale to handle multiple images without pre-allocating resources.\nAzure Blob Storage Trigger: This trigger is designed to respond to new blobs (images) in a storage container. It will fire the function as soon as a new blob is uploaded, which minimizes latency and ensures images are processed immediately.\nOther options:\n\nApp Service Plan: Not the best choice for minimizing latency and cost. It requires pre-allocated resources, which might lead to higher costs and unnecessary resource allocation, especially if your function is event-driven and sporadic.\nTimer Trigger: This would introduce delays, as the function would be triggered on a schedule, not immediately after a new image is uploaded.","upvote_count":"1","timestamp":"1727671260.0","poster":"ns4098","comment_id":"1291398"},{"timestamp":"1726852560.0","upvote_count":"1","comment_id":"1286994","poster":"Faolba","content":"Selected Answer: B\nB- Using a Consumption plan with an Azure Blob Storage trigger is the most effective way to ensure that images are processed as quickly as possible after they are uploaded. The Blob Storage trigger automatically invokes the Function App in response to blob uploads, minimizing latency and handling scaling automatically based on demand.\n\nWhile option D is technically correct, using an App Service plan may not be the most efficient choice for this scenario if your goal is to minimize latency and optimize costs.\n\nA Consumption plan is typically more suitable for event-driven scenarios like this, as it automatically scales and charges based on usage. An App Service plan might provide more predictable performance but could be more costly if the function is not in constant use. Therefore, option B remains the more optimal choice for processing images immediately upon upload."},{"content":"Whenever you see Function App, then answer should contain the word \"consumption plan\"","timestamp":"1718467560.0","upvote_count":"1","comment_id":"1231047","poster":"macfuk"},{"poster":"Stel0Papad4","upvote_count":"3","timestamp":"1716800040.0","content":"Selected Answer: D\nAfter a short discussion with Copilot AI , it gave me this answer:\n(Answer)\nIf performance and no latency are top priorities, go with Option D (App Service plan).\nIf cost efficiency and event-driven scalability matter more, choose Option B (Consumption plan).","comment_id":"1219413"},{"upvote_count":"1","comment_id":"1156396","timestamp":"1708609680.0","poster":"Isoldhe","comments":[{"poster":"TheFivePips","content":"AI has a hard time with details some of the time. If you remind it that consumption plans may take up to 10 minutes to warm up then it will correct itself","upvote_count":"1","comment_id":"1270045","timestamp":"1724238600.0"}],"content":"Selected Answer: B\nCopilot AI also says the answer is B"},{"comment_id":"1114598","poster":"manopeydakon","timestamp":"1704468480.0","upvote_count":"3","content":"Got this answer from ChatGPT:\nI understand the concern for minimizing latency and processing images as quickly as possible. However, the Azure Functions Consumption plan is designed to scale automatically based on demand, providing a cost-effective and efficient solution for scenarios where latency is a critical factor.\n\nWhen you configure your Azure Function App with an Azure Blob Storage trigger in a Consumption plan, it enables the function to respond quickly to new blob uploads. The Consumption plan is optimized for event-driven workloads, making it suitable for scenarios where you need fast response times.\n\nTherefore, option B (Use a Consumption plan. Configure the Function App to use an Azure Blob Storage trigger) remains a suitable and efficient choice for your requirements."},{"poster":"RuffBoii","comment_id":"1013892","comments":[{"poster":"CSLK","comment_id":"1166184","content":"What the answer you gave","upvote_count":"2","timestamp":"1709607600.0"}],"content":"Had this on my exam today.","timestamp":"1695373560.0","upvote_count":"3"},{"comment_id":"1012877","content":"What is the difference between \"storage trigger\" and \"storage input trigger\"? In the end, isn't the second one just a reinforcement to indicate that the moment a file is placed, precisely as input, in the hypothetical folder, then it is picked up and processed by the trigger. Thank you in advance for your answers","upvote_count":"1","timestamp":"1695280380.0","poster":"Guurr40__"},{"content":"Answer is B. \nWhen using a Consumption plan, Azure automatically scales out instances of the function as needed to handle incoming requests, and you only pay for the actual number of executions of the function. This ensures that the function is always available to process images without any delays caused by having to scale up or down manually.","comment_id":"844425","timestamp":"1679277240.0","poster":"sachinrikhe","upvote_count":"5","comments":[{"comment_id":"982205","upvote_count":"2","content":"You can't use Consumption Plan. Consumption Plan can take up to 10 mins to warm up which doesn't fit the requirement.","poster":"macobuzi","timestamp":"1692163260.0"}]},{"timestamp":"1679157780.0","comment_id":"842953","content":"Selected Answer: D\nD is correct \"For this scenario where images must be processed as quickly as possible and latency must be minimized, it is recommended to use the App Service plan instead of the Consumption plan.\n\nThe App Service plan provides dedicated resources to the function app, which can help improve performance and minimize the risk of cold start delays. Additionally, the App Service plan allows you to scale out the function app to multiple instances, which can help handle high traffic loads and further improve performance.\n\nOn the other hand, the Consumption plan is a serverless hosting option that scales automatically based on demand, but may result in cold start delays and limited resources during high traffic periods.\n\nTherefore, it is recommended to use the App Service plan for this scenario.\"","upvote_count":"3","poster":"nedlo"},{"comment_id":"820663","timestamp":"1677252420.0","content":"Selected Answer: D\nUse an App Service plan. Configure the Function App to use an Azure Blob Storage trigger.\nConsumption plan can cause a 10-min delay in processing new blobs if a function app has gone idle. To avoid this latency, you can switch to an App Service plan with Always On enabled.\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-blob-trigger?tabs=csharp","poster":"vguimars","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: D\nD. Use an App Service plan. Configure the Function App to use an Azure Blob Storage trigger.","poster":"OPT_001122","comment_id":"737132","timestamp":"1670352240.0"},{"poster":"madhubanti0007","content":"Selected Answer: D\nConsumption plan can cause a 10-min delay in processing new blobs if a function app has gone idle. To avoid this latency, you can switch to an App Service plan with Always On enabled.","comment_id":"711977","upvote_count":"2","timestamp":"1667676840.0"},{"upvote_count":"5","timestamp":"1667204700.0","content":"Got this question on 30-Oct-2022 exam.\nAnswer is D. Passed with 870 score","poster":"ms_master","comment_id":"708291","comments":[{"timestamp":"1670352300.0","content":"thanks for mentioning the date","upvote_count":"3","poster":"OPT_001122","comment_id":"737133"}]},{"upvote_count":"2","timestamp":"1662366600.0","comment_id":"659925","poster":"Ameet9","content":"Selected Answer: D\nAs quickly as possible then ofcourse it is App service plan"},{"timestamp":"1661575260.0","comment_id":"652459","poster":"ghuna","content":"Selected Answer: D\nif you want to be fast, then you need to avoid cold starts, which are part of consumption plan","upvote_count":"1"},{"timestamp":"1660725600.0","content":"Selected Answer: D\nD is correct as consumption plan will not process the data immediately.","comment_id":"647990","upvote_count":"1","poster":"rohitpatil113"},{"content":"Another wrong answer on this site","comment_id":"625510","poster":"Pize","upvote_count":"2","timestamp":"1656638220.0"},{"comment_id":"620787","timestamp":"1655962680.0","upvote_count":"2","content":"Solution is D : App service plan with Blob storage. \nAnswers with Consumption plan do not satisfy the requirement to minimize latency. \nAlso, there is no such thing as an input trigger.","poster":"xRiot007"},{"poster":"Hornwood509","comment_id":"595929","timestamp":"1651474980.0","upvote_count":"2","content":"Selected Answer: D\nFrom the URL: Minimizing latency: If your function app is on the Consumption plan, there can be up to a 10-minute delay in processing new blobs if a function app has gone idle. To avoid this latency, you can switch to an App Service plan with Always On enabled"},{"upvote_count":"1","comment_id":"580189","content":"Selected Answer: D\nConsumption plan can have up to 10 minutes of cold start, and the 'input trigger' does not exist, there are triggers and input bindings.","timestamp":"1648978620.0","poster":"noobpinkfloyd"},{"comments":[{"content":"It will be funny if Microsoft actually asks question to test that nuance.","comment_id":"682506","poster":"[Removed]","timestamp":"1664443980.0","upvote_count":"1"}],"upvote_count":"2","comment_id":"576936","poster":"systherm","timestamp":"1648481220.0","content":"Selected Answer: D\nWe have triggers, input bindings and output bindings. 'Input trigger' - it is redundant."},{"timestamp":"1647415380.0","content":"Selected Answer: D\nD correct, input binding not input trigger","upvote_count":"1","poster":"Nyalo","comment_id":"568833"},{"timestamp":"1645939500.0","upvote_count":"1","comment_id":"557152","poster":"vinarah","content":"I think the correct answer is D since we have a requirement to minimize latency."},{"timestamp":"1645538280.0","comment_id":"553724","content":"Selected Answer: D\nThe correct answer is D.","poster":"Freidrich","upvote_count":"1"},{"content":"Selected Answer: D\nThe correct answer is D.","comment_id":"544640","upvote_count":"1","timestamp":"1644505380.0","poster":"DiegoManinetti"},{"timestamp":"1643568420.0","comment_id":"536398","poster":"MFahd","upvote_count":"1","content":"The correct answer is D:"},{"comment_id":"535065","upvote_count":"1","timestamp":"1643419260.0","poster":"rkumar307","content":"Selected Answer: D\ncorrect answer is D. Use an App service plan. Configure the function app to use an azure blob storage trigger."},{"timestamp":"1642944780.0","upvote_count":"1","content":"Answer d\n1- Definitely not any consumption plan option, because they might be idle\n2- Nothing called \"input trigger\"","poster":"mabusalma","comment_id":"530556"},{"content":"Selected Answer: D\nconsumption plan can cause a delay so D is the appropriate answer","upvote_count":"1","poster":"LeoAlioth","timestamp":"1641815880.0","comment_id":"520819"},{"poster":"leonidn","comment_id":"516446","content":"Selected Answer: D\nConsumption plan may cause up to 10 minutes delay.","upvote_count":"1","timestamp":"1641290940.0"},{"content":"Selected Answer: D\nAnswer is D","upvote_count":"2","comment_id":"515092","timestamp":"1641143340.0","poster":"Lucario95"},{"poster":"AidenYoukhana","upvote_count":"1","content":"Selected Answer: D\nCORRECT ANSWER.","comment_id":"514201","timestamp":"1640979900.0"},{"comment_id":"510619","timestamp":"1640640780.0","upvote_count":"1","poster":"iamdamzy","content":"Correct Answer is D - Use an App Service plan. Configure the Function App to use an Azure Blob Storage trigger."},{"upvote_count":"1","poster":"Ojash","comment_id":"510450","content":"The Answer must be D.","timestamp":"1640622180.0"},{"comment_id":"510112","upvote_count":"2","content":"Selected Answer: D\nThe answer is D","timestamp":"1640592360.0","poster":"GhostJoe"},{"timestamp":"1640334600.0","poster":"0Haseeb","content":"Selected Answer: D\nThe answer is D","comment_id":"508390","upvote_count":"1"},{"upvote_count":"3","comment_id":"495748","timestamp":"1638863160.0","poster":"nkphuc700","content":"Selected Answer: D\nConsumption plan can cause a 10-min delay in processing new blobs if a function app has gone idle. To avoid this latency, you can switch to an App Service plan with Always On enabled."},{"timestamp":"1638271620.0","poster":"Mev4953","content":"Consumtion plan and App service plan. There is no budget issue. Read the text from this link: https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-blob-trigger?tabs=csharp\n\nMinimizing latency: If your function app is on the Consumption plan, there can be up to a 10-minute delay in processing new blobs if a function app has gone idle. To avoid this latency, you can switch to an App Service plan with Always On enabled. You can also use an Event Grid trigger with your Blob storage account. For an example, see the Event Grid tutorial.","upvote_count":"3","comment_id":"490635"},{"content":"As mentioned below, Consumption plan can have latency upto 10 minutes. So App Service plan is best choice here. So answer should be D.\n\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-blob-trigger","comment_id":"482708","timestamp":"1637426760.0","poster":"altafpatel1984","upvote_count":"2"},{"upvote_count":"3","content":"Whenever I see latency lurking in I will opt for anything but Consumption Plan. As for the Triggers and Bindings it's clear that we can only have input bindings and not input triggers as others have already said. Hence the answer is a clear D","comment_id":"481089","timestamp":"1637272080.0","poster":"Bedet"},{"poster":"borhen","timestamp":"1634065320.0","comment_id":"461231","content":"after the given answer, I will only check the discussion section","upvote_count":"2"},{"poster":"ozbonny","upvote_count":"3","content":"I'll use D because consumption plan has the cool delay, \napp service give quick response, and also include the correct declarative trigger for Azure Blob storage","comment_id":"418399","timestamp":"1627846980.0"},{"timestamp":"1626810000.0","poster":"cool_tool","comment_id":"410508","upvote_count":"4","comments":[{"content":"Correct answer is \" D \"","poster":"cool_tool","upvote_count":"2","timestamp":"1626810120.0","comment_id":"410510"}],"content":"MS: \"Minimizing latency: If your function app is on the Consumption plan, there can be up to a 10-minute delay in processing new blobs if a function app has gone idle. To avoid this latency, you can switch to an App Service plan with Always On enabled. You can also use an Event Grid trigger with your Blob storage account. For an example, see the Event Grid tutorial.\""},{"timestamp":"1626003120.0","upvote_count":"2","content":"Minimizing latency: If your function app is on the Consumption plan, there can be up to a 10-minute delay in processing new blobs if a function app has gone idle. To avoid this latency, you can switch to an App Service plan with Always On enabled.","comment_id":"403874","poster":"somenkr"},{"timestamp":"1624362660.0","upvote_count":"7","content":"I've got this question this morning. The right answer is D.","comment_id":"387914","poster":"PierrGo"},{"comment_id":"376113","content":"got this in the exam :)","poster":"francis6170","timestamp":"1622991000.0","upvote_count":"7"},{"upvote_count":"15","content":"Correct Answer: D\n\nWe definitely need an Azure Blob Storage trigger. There is not Azure Blob Storage input trigger. Input bindings allow you to read blob storage data as input to an Azure Function, not trigger.\n\nWith Consumption plan, you could have cold start, and the question say \"must be processed as quickly as possible\". If your Function App is on the Consumption plan, there can be up to a 10-minute delay in processing new blobs if a function app has gone idle. So, we need an App Service Plan.\n\n\nReference:\n\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-blob-trigger?tabs=csharp\n\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-blob-input?tabs=csharp\n\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-scale#overview-of-plans","comment_id":"370062","poster":"mlantonis","timestamp":"1622369640.0"},{"timestamp":"1621912620.0","upvote_count":"3","comment_id":"366063","content":"Ans - D is correct (wish we had a Premium ( warm up) option in place of Consumption and App Service plan.","poster":"prabhjot"},{"timestamp":"1621597740.0","comment_id":"362971","poster":"mlantonis","content":"We definitely need an Azure Blob Storage trigger. There is not Azure Blob Storage input trigger. Input bindings allow you to read blob storage data as input to an Azure Function, not trigger.\n\nWith Consumption plan, you could have cold start, and the question say \"must be processed as quickly as possible\". If your Function App is on the Consumption plan, there can be up to a 10-minute delay in processing new blobs if a function app has gone idle. So, we need an App Service Plan.\n\n\nReference:\n\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-blob-trigger?tabs=csharp\n\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-blob-input?tabs=csharp\n\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-scale#overview-of-plans","comments":[{"content":"Correct Answer: D","comment_id":"362972","poster":"mlantonis","timestamp":"1621597800.0","upvote_count":"1"}],"upvote_count":"3"},{"comment_id":"362179","content":"I think that is D","poster":"cblazquez","timestamp":"1621516260.0","upvote_count":"1"},{"content":"D. Use an App Service plan. Configure the Function App to use an Azure Blob Storage trigger.","comment_id":"355994","timestamp":"1620880560.0","poster":"glam","upvote_count":"1"},{"timestamp":"1618520940.0","content":"Surely it is not consumption plan, but between A and D it is A. The difference between the BlobTrigger and tne blob input trigger is the access: the BlobTrigger could only be used to read the blob, while the blob binding could be used for every function. Since the blob input trigger is an input binding, the answer is A. Similiar diskussion: https://stackoverflow.com/questions/58364329/what-is-the-difference-between-blobattribute-vs-blobtriggerattribute\n\" the main difference is the blob contents are provided as input with BlobTrigger\"","comment_id":"336597","comments":[{"timestamp":"1618646640.0","upvote_count":"3","comment_id":"337417","content":"The [Blob] attribute (= Blob input binding) does not trigger the function app. A blob input trigger does not exists. The correct answer is D.","poster":"alexffx"}],"poster":"kapetan","upvote_count":"1"},{"content":"Is NOT a consumption plan!\n\"If your function app is on the Consumption plan, there can be up to a 10-minute delay in processing new blobs if a function app has gone idle. To avoid this latency, you can switch to an App Service plan with Always On enabled. You can also use an Event Grid trigger with your Blob storage account\"\n\nper: https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-blob-trigger?tabs=csharp","poster":"PoundingCode","comment_id":"323640","upvote_count":"3","timestamp":"1617037380.0"},{"timestamp":"1616927520.0","comment_id":"322550","content":"D.\nMinimizing latency: If your function app is on the Consumption plan, there can be up to a 10-minute delay in processing new blobs if a function app has gone idle. To avoid this latency, you can switch to an App Service plan with Always On enabled.\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-blob-trigger?tabs=csharp","poster":"raiijana","upvote_count":"3"},{"content":"I agree, the correct answer is D. You use App Service Plan to minimize latency. And Blob Storage trigger.","poster":"sumaiyap86","comments":[{"comment_id":"305376","upvote_count":"1","timestamp":"1615154220.0","poster":"Kuna_Lambo","comments":[{"timestamp":"1616267100.0","upvote_count":"2","content":"In consumption plan it is not possible to turn on \"Always on\" so you might encounter cold start. In App service plan you can turn on \"Always on\" so there will not be cold start. That said the correct answer is D for me","comment_id":"315814","poster":"Krzysztof1543"}],"content":"In App service plan Always on is turn off."}],"comment_id":"302634","timestamp":"1614777780.0","upvote_count":"5"},{"upvote_count":"6","content":"Not sure what the difference is between storage trigger and storage input trigger. But I do know it needs to be app service plan instead of a consumer plan, since we want to minimize start-up time, which is an issue with consumer plan, source: https://docs.microsoft.com/en-us/azure/azure-functions/functions-scale \n\nrelevant quote from source above: Consumption plan Apps may scale to zero when idle, meaning some requests may have additional latency at startup. The consumption plan does have some optimizations to help decrease cold start time, including pulling from pre-warmed placeholder functions that already have the function host and language processes running.","timestamp":"1612794600.0","comments":[{"content":"I think no storage input trigger, only has storage input binding.\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-blob-input","upvote_count":"4","poster":"Bruce8300323","comment_id":"305017","timestamp":"1615107060.0"}],"poster":"pac1311","comment_id":"286249"}],"answer_ET":"D"},{"id":"iKagBJJzb57nPlQsvH6R","url":"https://www.examtopics.com/discussions/microsoft/view/46645-exam-az-204-topic-2-question-23-discussion/","discussion":[{"comment_id":"308658","upvote_count":"80","timestamp":"1615536000.0","content":"Answer: copyIndex, copy, Dependson. Check this link https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/define-resource-dependency.","poster":"cloudlabadm","comments":[{"comment_id":"789366","poster":"Esward","upvote_count":"3","timestamp":"1674800940.0","content":"Agreed"},{"comment_id":"1111835","poster":"130nk3r5","timestamp":"1704196920.0","content":"Got this today.\nWent with answer here.\nScore 927","upvote_count":"5"}]},{"poster":"mlantonis","timestamp":"1621599660.0","content":"Box 1: copyIndex\nNotice that the name of each resource includes the copyIndex() function, which returns the current iteration in the loop. copyIndex() is zero-based.\n\nBox 2: copy\nBy adding copy loop to the resources section of your template, you can dynamically set the number of resources to deploy. You also avoid having to repeat template syntax.\n\nBox 3: dependsOn\nWithin your Azure Resource Manager template (ARM template), the dependsOn element enables you to define one resource as a dependent on one or more resources.\n\nReference:\nhttps://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/copy-resources\nhttps://docs.microsoft.com/en-us/azure/virtual-machine-scale-sets/quick-create-template-windows\nhttps://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/define-resource-dependency","upvote_count":"57","comment_id":"362995"},{"timestamp":"1725533220.0","comment_id":"1278842","poster":"ben_thedevguy","upvote_count":"1","content":"Arm template is no longer in the AZ-204 exam according to this answer:\nhttps://trainingsupport.microsoft.com/en-us/mcp/forum/all/is-azure-resource-manager-arm-in-the-az-204-exam/bcdfdec6-2d40-470a-ba24-e3e6de9fdfaa\nAlthough I have not yet taken the exam since the answer is from a Microsoft Moderator which I think is reliable."},{"comment_id":"1104233","timestamp":"1703360760.0","poster":"bgbgvfvf","content":"I think answer is Correct!","upvote_count":"1"},{"comment_id":"1054436","timestamp":"1698314100.0","upvote_count":"1","content":"For the second part: \"Copy\"\nWhat is the point of adding the same property with the same name 3 times?","poster":"MrAzz"},{"poster":"deathRac3","comment_id":"912693","content":"Question was there for me on 29th May 2023","timestamp":"1685698500.0","upvote_count":"3"},{"poster":"CODE_STS","upvote_count":"3","comment_id":"824615","timestamp":"1677579360.0","content":"Got this in the exam today! Feb 28, 2023"},{"poster":"uffuchsi","upvote_count":"10","comment_id":"817260","content":"Received this in my exam today (22/02/2023). Selected copyIndex, copy, and dependsOn. Score 927.","timestamp":"1677020340.0"},{"content":"Got this on exam 12/30/2022","poster":"saravanasanthosh","comment_id":"762119","upvote_count":"2","timestamp":"1672417020.0"},{"poster":"OPT_001122","comment_id":"737135","upvote_count":"2","content":"Thanks to all who have mentioned the exam date","timestamp":"1670352360.0"},{"comment_id":"682548","content":"Do I need to remember these functions? The options are made in a way to confuse you and make a mistake. These are things developers just lookup in documentation. Not writing an ARM template every day","poster":"[Removed]","upvote_count":"8","timestamp":"1664447520.0"},{"comment_id":"588505","upvote_count":"5","timestamp":"1650442860.0","poster":"Rini100","content":"Got this on 20 Apr 2022.. (copyIndex, copy, dependsOn)"},{"comment_id":"584302","timestamp":"1649693520.0","upvote_count":"4","content":"Got this on 04/05/22 (selected copyIndex, copy, dependsOn)","poster":"AZ204Cert"},{"upvote_count":"3","content":"Got it in exam 03/22","timestamp":"1646859240.0","poster":"petitbilly","comment_id":"564328"},{"upvote_count":"2","content":"CORRECT ANSWER.","comment_id":"514203","timestamp":"1640980200.0","poster":"AidenYoukhana"},{"poster":"Rev1201","content":"Answer is Correct!","comment_id":"440172","timestamp":"1630912680.0","upvote_count":"3"},{"poster":"glam","content":"Answer: copyIndex, copy, Dependson","timestamp":"1620880860.0","comment_id":"355997","upvote_count":"3"},{"poster":"[Removed]","comment_id":"318481","content":"https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/template-tutorial-create-multiple-instances?tabs=CLI%2Cazure-cli","timestamp":"1616532780.0","upvote_count":"5"},{"poster":"agueda","comment_id":"309294","timestamp":"1615594980.0","upvote_count":"9","content":"Agree with the answer"}],"exam_id":48,"question_text":"HOTSPOT -\nYou are configuring a new development environment for a Java application.\nThe environment requires a Virtual Machine Scale Set (VMSS), several storage accounts, and networking components.\nThe VMSS must not be created until the storage accounts have been successfully created and an associated load balancer and virtual network is configured.\nHow should you complete the Azure Resource Manager template? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","timestamp":"2021-03-12 09:00:00","answer_images":["https://www.examtopics.com/assets/media/exam-media/04273/0012500001.png"],"answer_description":"Box 1: copyIndex -\nNotice that the name of each resource includes the copyIndex() function, which returns the current iteration in the loop. copyIndex() is zero-based.\n\nBox 2: copy -\nBy adding the copy element to the resources section of your template, you can dynamically set the number of resources to deploy.\n\nBox 3: dependsOn -\nExample:\n\"type\": \"Microsoft.Compute/virtualMachineScaleSets\",\n\"apiVersion\": \"2020-06-01\",\n\"name\": \"[variables('namingInfix')]\",\n\"location\": \"[parameters('location')]\",\n\"sku\": {\n\"name\": \"[parameters('vmSku')]\",\n\"tier\": \"Standard\",\n\"capacity\": \"[parameters('instanceCount')]\"\n},\n\"dependsOn\": [\n\"[resourceId('Microsoft.Network/loadBalancers', variables('loadBalancerName'))]\",\n\"[resourceId('Microsoft.Network/virtualNetworks', variables('virtualNetworkName'))]\"\n],\nReference:\nhttps://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/copy-resources https://docs.microsoft.com/en-us/azure/virtual-machine-scale-sets/quick-create-template-windows","answers_community":[],"answer_ET":"","answer":"","isMC":false,"question_id":84,"unix_timestamp":1615536000,"topic":"2","question_images":["https://www.examtopics.com/assets/media/exam-media/04273/0012400001.png"]},{"id":"8r88XZ8p4Zdz8PnLJgio","discussion":[{"comments":[{"content":"very good and helpful explanation","upvote_count":"3","poster":"OPT_001122","timestamp":"1668697620.0","comment_id":"720563"},{"poster":"NombreFalso","upvote_count":"8","timestamp":"1676759820.0","content":"Egg salad I mean excellent","comment_id":"813539"}],"comment_id":"370066","upvote_count":"144","content":"Box 1: No\nIt logs the following:\n- ExpirationTime - The time that the message expires.\n- InsertionTime - The time that the message was added to the queue.\n\nBox 2: Yes\nmaxDequeueCount: The number of times to try processing a message before moving it to the poison queue. Default value is 5.\n\nBox 3: Yes\nWhen there are multiple queue messages waiting, the queue trigger retrieves a batch of messages and invokes function instances concurrently to process them. By default, the batch size is 16. When the number being processed gets down to 8, the runtime gets another batch and starts processing those messages. So the maximum number of concurrent messages being processed per function on one virtual machine (VM) is 24.\n\nBox 4: Yes \n[Table(\"Orders\")]ICollector<Order> table bindings\nAnd in the code it adds the order:\ntableBindings.Add(JsonConvert.DeserializeObject<Object>(myQueueItem.AsString));","timestamp":"1622369760.0","poster":"mlantonis"},{"upvote_count":"50","timestamp":"1664448420.0","poster":"[Removed]","comments":[{"timestamp":"1730588400.0","poster":"mr_wilkrafal","comment_id":"1306354","upvote_count":"1","content":"Like, if not your comment, was gonna ask if we that image was updated or something..."}],"content":"Microsoft thinks that a good developer should remember the default value for the dequeCount (and not forget that in a stress exam situation that there is that property, which is not shown in the code, very convenient).","comment_id":"682568"},{"comment_id":"1104238","poster":"bgbgvfvf","timestamp":"1703361120.0","content":"I think the answer is correct","upvote_count":"1"},{"timestamp":"1640385960.0","upvote_count":"1","content":"correct","poster":"Anvsoc","comment_id":"508882"},{"poster":"tis_truth","comment_id":"498077","timestamp":"1639087260.0","comments":[{"content":"maxDequeueCount; deafult =5 \nhttps://docs.microsoft.com/fr-fr/azure/azure-functions/functions-bindings-storage-queue#hostjson-settings","upvote_count":"3","poster":"coffecold","timestamp":"1664439120.0","comment_id":"682466"},{"comment_id":"682562","content":"It is not in the function but in the host.json. Microsoft is testing whether you forgot about that. I really do not know why they try to trick people but then it is Microsoft","upvote_count":"6","poster":"[Removed]","timestamp":"1664448120.0"}],"content":"Would love to answer this correctly but the full code isn't showing. The maxDequeueCount value isn't showing in the question codeset provided. Does anyone have the full codeset?","upvote_count":"9"},{"comments":[{"poster":"j888","content":"Same.. obviously something is missing","timestamp":"1625552700.0","comment_id":"399701","upvote_count":"2"}],"upvote_count":"8","comment_id":"362307","timestamp":"1621524000.0","content":"Image isn't showing a full code? Please send me full code","poster":"still6dark"},{"upvote_count":"1","timestamp":"1620881100.0","poster":"glam","comment_id":"356002","content":"Correct."},{"timestamp":"1618521660.0","content":"The last statement is true: take a look at the input parameters:\n...[Table(\"Orders\")]ICollector<Order> table bindings...\nand in the code it adds the order:\ntableBindings.Add(JsonConvert.DeserializeObject<Object>(myQueueItem.AsString));","comment_id":"336603","upvote_count":"2","poster":"kapetan"},{"comment_id":"310857","content":"Seems correct\nhttps://docs.microsoft.com/fr-fr/azure/azure-functions/functions-bindings-storage-queue#hostjson-settings","timestamp":"1615753980.0","upvote_count":"22","poster":"idrisfl"},{"poster":"Marusyk","timestamp":"1615672680.0","content":"Answer is correct","upvote_count":"3","comment_id":"310020"},{"comment_id":"308264","poster":"Kuna_Lambo","timestamp":"1615490160.0","content":"AZ-203 Topic 1 Q#9","upvote_count":"2"}],"answer_ET":"","unix_timestamp":1615490160,"answer":"","question_id":85,"isMC":false,"topic":"2","timestamp":"2021-03-11 20:16:00","url":"https://www.examtopics.com/discussions/microsoft/view/46556-exam-az-204-topic-2-question-24-discussion/","exam_id":48,"question_text":"HOTSPOT -\nYou are developing an Azure Function App by using Visual Studio. The app will process orders input by an Azure Web App. The web app places the order information into Azure Queue Storage.\nYou need to review the Azure Function App code shown below.\n//IMG//\n\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","answers_community":[],"question_images":["https://www.examtopics.com/assets/media/exam-media/04273/0012700001.png","https://www.examtopics.com/assets/media/exam-media/04273/0012700002.png"],"answer_description":"Box 1: No -\nExpirationTime - The time that the message expires.\nInsertionTime - The time that the message was added to the queue.\n\nBox 2: Yes -\nmaxDequeueCount - The number of times to try processing a message before moving it to the poison queue. Default value is 5.\n\nBox 3: Yes -\nWhen there are multiple queue messages waiting, the queue trigger retrieves a batch of messages and invokes function instances concurrently to process them.\nBy default, the batch size is 16. When the number being processed gets down to 8, the runtime gets another batch and starts processing those messages. So the maximum number of concurrent messages being processed per function on one virtual machine (VM) is 24.\n\nBox 4: Yes -\nReference:\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-queue","answer_images":["https://www.examtopics.com/assets/media/exam-media/04273/0012800001.png"]}],"exam":{"name":"AZ-204","numberOfQuestions":452,"isImplemented":true,"isMCOnly":false,"provider":"Microsoft","id":48,"isBeta":false,"lastUpdated":"12 Apr 2025"},"currentPage":17},"__N_SSP":true}