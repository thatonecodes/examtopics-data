{"pageProps":{"questions":[{"id":"2lckRS7h4FgfA8YxNO05","timestamp":"2021-07-05 08:53:00","answer_ET":"D","question_id":31,"answers_community":["D (68%)","C (32%)"],"choices":{"B":"You should consider making use of the Measured grid sweep mode.","D":"You should consider making use of the Random grid sweep mode.","C":"You should consider making use of the Entire grid sweep mode.","A":"You should consider making use of the Selective grid sweep mode."},"exam_id":64,"url":"https://www.examtopics.com/discussions/microsoft/view/57147-exam-dp-100-topic-1-question-37-discussion/","answer_description":"","answer_images":[],"answer":"D","question_text":"You make use of Azure Machine Learning Studio to create a binary classification model.\nYou are preparing to carry out a parameter sweep of the model to tune hyperparameters. You have to make sure that the sweep allows for every possible combination of hyperparameters to be iterated. Also, the computing resources needed to carry out the sweep must be reduced.\nWhich of the following actions should you take?","unix_timestamp":1625467980,"isMC":true,"question_images":[],"topic":"1","discussion":[{"comments":[{"comment_id":"1134836","timestamp":"1706525040.0","poster":"prabhjot","upvote_count":"1","content":"For ensuring every possible combination of hyperparameters is explored, the \"Entire grid sweep mode\" is the appropriate choice."}],"upvote_count":"18","comment_id":"773415","timestamp":"1673525100.0","content":"I feel like like the two requirements are conflicting: every possible combination implies Entire grid while lower computational resources implies Random grid. \n\"Entire grid: When you select this option, the component loops over a grid predefined by the system, to try different combinations and identify the best learner. This option is useful when you don't know what the best parameter settings might be and want to try all possible combinations of values.\"\n\n\"Random sweep: When you select this option, the component will randomly select parameter values over a system-defined range. You must specify the maximum number of runs that you want the component to execute. This option is useful when you want to increase model performance by using the metrics of your choice but still conserve computing resources.\"","poster":"[Removed]"},{"timestamp":"1669239060.0","upvote_count":"8","comment_id":"725400","poster":"lookaaaa","content":"Selected Answer: D\nAll combination + Reduce computing resource , because \"Research has shown that this method (Random Grid Sweep) yields the same results, but is more efficient computationally.\" I think D would be the best choice"},{"upvote_count":"3","poster":"sim39","comment_id":"1317155","content":"Selected Answer: D\n_ALLOWS_ for every possible combination doesn't mean it has to iterate through all. The requirement to reduce compute resources obviously points us away from a full grid search.","timestamp":"1732471680.0"},{"content":"Selected Answer: C\nVote for Entire Grid Sweep Mode since one requirement is every possible combination of hyperparameters to be iterated. Other options reduce computational resources yet do not satisfy this requirement.","upvote_count":"1","comment_id":"1257971","poster":"Xsesi","timestamp":"1722324900.0"},{"comment_id":"1178955","content":"Selected Answer: D\n\"Maximum number of runs on random grid: This option also controls the number of iterations over a random sampling of parameter values, but the values are not generated randomly from the specified range; instead, a matrix is created of all possible combinations of parameter values and a random sampling is taken over the matrix. This method is more efficient and less prone to regional oversampling or undersampling.\"","upvote_count":"1","timestamp":"1710992760.0","poster":"Braxus"},{"timestamp":"1688754960.0","poster":"MarinaMijailovic","content":"The answer is D.\n\nRandom seed ALLOWS every possible combination. It won't go through every possible combination but any random combination is possible.","upvote_count":"2","comment_id":"945933"},{"comment_id":"918633","poster":"endeesa","timestamp":"1686253380.0","upvote_count":"2","content":"Selected Answer: C\nQuestion says \"You have to make sure that the sweep allows for every possible combination of hyperparameters to be iterated\". There is no way to guarantee Random sweep will get all possible combinations, answer is C"},{"upvote_count":"1","poster":"phdykd","timestamp":"1675282920.0","comment_id":"795494","content":"D. You should consider making use of the Random grid sweep mode.\n\nThe Random grid sweep mode randomly selects combinations of hyperparameters to test, reducing the number of total combinations and the computing resources needed to carry out the sweep. This method can still provide a good understanding of the relationship between hyperparameters and model performance, but may require multiple runs to converge on the optimal hyperparameters."},{"content":"If we want every possible combi9nation we need entire grid, so C is correct.","upvote_count":"3","comment_id":"771915","timestamp":"1673396460.0","poster":"meysa"},{"timestamp":"1672849740.0","comment_id":"765894","content":"Selected Answer: C\nC is correct..","upvote_count":"4","poster":"Sibajene"},{"poster":"Edriv","timestamp":"1670759580.0","content":"Keyword -> \"sweep allows for every possible combination\" so, option B https://learn.microsoft.com/en-us/azure/machine-learning/component-reference/tune-model-hyperparameters","upvote_count":"1","comment_id":"741644","comments":[{"comment_id":"741647","timestamp":"1670759700.0","poster":"Edriv","upvote_count":"3","content":"I mean, option C"}]},{"poster":"ning","comment_id":"617629","timestamp":"1655455380.0","content":"Entire grid is the only one can try all combinations,\nbut random sweep is low computational cost","upvote_count":"3"},{"content":"Selected Answer: D\nRelated with this question\n\nhttps://www.examtopics.com/discussions/microsoft/view/43145-exam-dp-100-topic-2-question-80-discussion/","upvote_count":"2","poster":"David_Tadeu","comment_id":"586279","timestamp":"1650018240.0"},{"upvote_count":"1","timestamp":"1646993880.0","content":"Answer D. there are two reqs... entire grid and low computational cost","comment_id":"565385","poster":"synapse"},{"content":"Selected Answer: D\nRandom grid","poster":"dija123","timestamp":"1639555500.0","comment_id":"501970","upvote_count":"1"},{"poster":"RyanTsai","timestamp":"1632039000.0","upvote_count":"4","content":"ans: C","comment_id":"447481"},{"poster":"Cacek","upvote_count":"2","timestamp":"1629453660.0","content":"\"every possible combination\", hence Entire grid sweep mode","comment_id":"428019","comments":[{"comment_id":"440794","poster":"sim39","upvote_count":"12","timestamp":"1631002200.0","content":"Because Random Grid ALLOW for every possible combination: this is the sample space for the algorithm. The \"entire grid\" option has a high computational cost"}]},{"upvote_count":"1","comment_id":"398937","comments":[{"comment_id":"405030","content":"\"the computing resources needed to carry out the sweep must be reduced\" ?","poster":"YipingRuan","upvote_count":"4","timestamp":"1626138960.0"}],"timestamp":"1625467980.0","poster":"gaint","content":"Why not C?"}]},{"id":"Vg5Clp3PqiGyfy40pjzL","question_text":"You are in the process of constructing a deep convolutional neural network (CNN). The CNN will be used for image classification.\nYou notice that the CNN model you constructed displays hints of overfitting.\nYou want to make sure that overfitting is minimized, and that the model is converged to an optimal fit.\nWhich of the following is TRUE with regards to achieving your goal?","isMC":true,"url":"https://www.examtopics.com/discussions/microsoft/view/57154-exam-dp-100-topic-1-question-38-discussion/","answer_ET":"D","choices":{"D":"You have to add L1/L2 regularization, and make use of training data augmentation.","B":"You have to add L1/L2 regularization, and reduce the amount of training data.","C":"You have to reduce the amount of training data and make use of training data augmentation.","E":"You have to add an additional dense layer with 512 input units, and add L1/L2 regularization.","A":"You have to add an additional dense layer with 512 input units, and reduce the amount of training data."},"question_id":32,"unix_timestamp":1625475600,"answer_images":[],"discussion":[{"upvote_count":"50","comments":[{"content":"\"data augmentation simply means increasing size of the data that is increasing the number of images present in the dataset.. using data augmentation a lot of similar images can be generated. This helps in increasing the dataset size and thus reduce overfitting.\"\n\nhttps://www.kdnuggets.com/2019/12/5-techniques-prevent-overfitting-neural-networks.html","timestamp":"1659263640.0","comment_id":"417812","poster":"Moshekwa","upvote_count":"14"},{"poster":"Nghia1","content":"agree, option B reduce amount of training data will lead to overfitting.","timestamp":"1717104540.0","upvote_count":"1","comment_id":"910602"}],"timestamp":"1657011600.0","poster":"exam_monkey1234","comment_id":"399022","content":"I would say answer D"},{"content":"Moderator, you should correct the answers, not me!\nD. You have to add L1/L2 regularization and make use of training data augmentation.\nOverfitting occurs when a model is too complex for data it is being trained on and memorizes the training data instead of generalizing to new data. To reduce overfitting, you can use regularization techniques such as L1 or L2 regularization, which add a penalty term to the loss function to discourage the model from learning overly complex representations. Additionally, increasing the amount of training data can also help reduce overfitting by giving the model more information to learn from. One common way to increase the amount of training data is to use data augmentation, which involves transforming the existing data in ways that preserve the labels to generate additional training examples.","comment_id":"795501","upvote_count":"9","timestamp":"1706819220.0","poster":"phdykd"},{"comment_id":"1088259","timestamp":"1733385660.0","content":"Selected Answer: D\nD is the correct ans","poster":"dporwal04","upvote_count":"2"},{"timestamp":"1727421960.0","content":"Selected Answer: D\nThe answer is D. Data augmentation really helps to reduce overfitting and L1L2 are most used regularization in Neural networks..\nDear moderator , please provide the correct answers. Many of them given here is misleading which can make chaos while attending exam","comment_id":"1018573","poster":"rakeshmk","upvote_count":"1"},{"upvote_count":"1","poster":"endeesa","comment_id":"918638","timestamp":"1717875960.0","content":"Selected Answer: D\nThe only option that makes sense to me is D. Adding regularisation will reduce overfitting, similarly adding more data adds more diversity to the training set allowing it to generalise better. So answer is D"},{"poster":"bvkr","timestamp":"1711643640.0","upvote_count":"2","comment_id":"853348","content":"ChatGPT answer: Option D: You have to add L1/L2 regularization, and make use of training data augmentation.\n\nWhen a deep CNN model displays hints of overfitting, it means that the model is too complex and has learned to fit the training data too closely. One way to minimize overfitting is to add regularization to the model, which adds a penalty term to the loss function, encouraging the model to choose simpler solutions.\n\nL1/L2 regularization adds a penalty term to the loss function that discourages the model from using large weights in the network. This has the effect of reducing the complexity of the model and can help prevent overfitting.\n\nData augmentation is another effective technique to minimize overfitting. It involves applying random transformations to the training data, such as random rotations or translations, to create new training examples that are similar to the original ones. This helps the model to generalize better to unseen data."},{"comment_id":"801027","upvote_count":"1","timestamp":"1707318060.0","content":"Selected Answer: D\nAnswer is D","poster":"Yoshizn"},{"upvote_count":"2","content":"Steps for reducing overfitting:\n\nAdd more data.\nUse data augmentation.\nUse architectures that generalize well.\nAdd regularization (mostly dropout, L1/L2 regularization are also possible)\nReduce architecture complexity.","timestamp":"1706200440.0","poster":"MansoorDataScientist","comment_id":"787899"},{"timestamp":"1705377540.0","upvote_count":"1","content":"Selected Answer: D\nD is definitely the answer.","comment_id":"777298","poster":"Peeking"},{"content":"Why don't C?","comment_id":"741672","upvote_count":"1","poster":"Edriv","timestamp":"1702297320.0"},{"timestamp":"1700775180.0","comment_id":"725402","upvote_count":"2","content":"Selected Answer: D\nincrese amount of data, simplify the model (decrese layers or NN unit, etc)","poster":"lookaaaa"},{"poster":"zweic","comment_id":"686899","content":"Selected Answer: D\nI would say D","timestamp":"1696510980.0","upvote_count":"2"},{"comments":[{"upvote_count":"1","content":"Source\nhttps://towardsdatascience.com/deep-learning-3-more-on-cnns-handling-overfitting-2bd5d99abe5d","timestamp":"1694416140.0","poster":"jlopezfelizzola","comment_id":"665781"}],"upvote_count":"2","comment_id":"665780","content":"Selected Answer: D\nMy vote is for D. A & E discarded because that is increasing the complexity of the architecture. B, C are suggesting reducing the amount of data. D will generate more data for the CNN to be able to generalize more.","poster":"jlopezfelizzola","timestamp":"1694400720.0"},{"content":"Selected Answer: D\nDefinitely D","upvote_count":"1","poster":"synapse","timestamp":"1678529640.0","comment_id":"565381"},{"comment_id":"497657","timestamp":"1670584080.0","content":"Selected Answer: D\nI vote for D","poster":"dija123","upvote_count":"1"},{"comment_id":"447301","content":"Answer is D :)","timestamp":"1663541160.0","upvote_count":"4","poster":"jed_elhak"},{"content":"Answer is D","comment_id":"424142","timestamp":"1660378080.0","poster":"Maryam89","upvote_count":"4"},{"timestamp":"1660113420.0","comment_id":"422518","content":"Data Augmentation should be added","upvote_count":"4","poster":"BenAji"}],"timestamp":"2021-07-05 11:00:00","answers_community":["D (100%)"],"exam_id":64,"answer_description":"","topic":"1","question_images":[],"answer":"D"},{"id":"cr4cJttR7fGYJeRadfbP","answer_description":"","isMC":true,"answer_ET":"B","url":"https://www.examtopics.com/discussions/microsoft/view/61020-exam-dp-100-topic-1-question-39-discussion/","choices":{"B":"No","A":"Yes"},"question_images":[],"question_text":"This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.\nYou are planning to make use of Azure Machine Learning designer to train models.\nYou need choose a suitable compute type.\nRecommendation: You choose Attached compute.\nWill the requirements be satisfied?","answers_community":["B (64%)","A (36%)"],"timestamp":"2021-08-30 10:12:00","unix_timestamp":1630311120,"question_id":33,"discussion":[{"poster":"dushmantha","content":"Should be True. Because we can use databricks or vm as attached compute for training purposes","comment_id":"435265","timestamp":"1630311120.0","upvote_count":"13","comments":[{"content":"Agree, Yes is the correct answer","poster":"beny","comment_id":"440482","timestamp":"1630948320.0","upvote_count":"5","comments":[{"comments":[{"content":"I agree","timestamp":"1660912200.0","upvote_count":"3","comment_id":"648963","poster":"Gabonia"}],"content":"No, unforunately only AML Compute cluster or AML compute instance can be used in designer according to :\n\nhttps://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target","poster":"[Removed]","upvote_count":"10","comment_id":"595456","timestamp":"1651385340.0"}]},{"comment_id":"617631","timestamp":"1655455440.0","upvote_count":"5","content":"Designer! Only computer instance or computer cluster","poster":"ning"}]},{"content":"Azure Machine Learning designer to train models. its the key so answer is compute cluster.","timestamp":"1635422580.0","comment_id":"469237","upvote_count":"8","poster":"azayra"},{"comment_id":"1312089","upvote_count":"1","poster":"testgm","content":"Attached compute is already supported by Azure Machine Learning Designer","timestamp":"1731596940.0"},{"comment_id":"1226193","timestamp":"1717770480.0","upvote_count":"2","content":"Selected Answer: A\nThere are now 5 tabs in compute, and \"Attached computes\" is one of them. When you configure & submit a pipeline job, you can choose attached compute.","poster":"sl_mslconsulting"},{"comment_id":"968627","poster":"phdykd","upvote_count":"1","content":"A-Yes is answer","timestamp":"1690849500.0"},{"upvote_count":"5","comment_id":"835179","poster":"SunilB","content":"We can use attached compute. Just tried it","timestamp":"1678463220.0"},{"timestamp":"1678022460.0","upvote_count":"5","comment_id":"829930","content":"Correct Answer: B\nSee the blue box in the link below which says 'Attached compute is not supported, use compute instances or clusters instead.'\nhttps://learn.microsoft.com/en-us/azure/machine-learning/tutorial-designer-automobile-price-train-score","poster":"SunilB"},{"content":"It is not possible to determine whether the requirements will be satisfied based on the information provided. The recommendation to choose Attached compute is a specific solution, but the requirements are not stated. It is important to have a clear understanding of the requirements and constraints before making a decision on which compute type to use in Azure Machine Learning Designer.","poster":"phdykd","upvote_count":"1","comment_id":"795508","timestamp":"1675283580.0"},{"content":"Selected Answer: A\nChatGPT says A","upvote_count":"1","comment_id":"786680","poster":"Starlite","timestamp":"1674576420.0"},{"comment_id":"741803","poster":"Edriv","content":"https://learn.microsoft.com/en-us/azure/machine-learning/concept-designer#compute","timestamp":"1670770440.0","upvote_count":"1"},{"poster":"lookaaaa","content":"Selected Answer: B\nAs is shown in the links below, Designer only supports Azure Machine Learning Compute (AML Compute cluster or AML compute instance) for training.\n\n1. https://learn.microsoft.com/en-us/azure/machine-learning/concept-designer#compute\n2. https://learn.microsoft.com/en-us/azure/machine-learning/concept-compute-target#training-compute-targets","timestamp":"1669246680.0","upvote_count":"4","comment_id":"725438"},{"upvote_count":"2","poster":"fvil","content":"Selected Answer: B\nCannot use Attached Compute Cluster in designer:\nhttps://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target\nSame context but slightly different question on exam 07/11/2022","timestamp":"1667831460.0","comment_id":"713103"},{"comment_id":"693321","content":"Selected Answer: A\nAnswer is A","poster":"amokrane_mancer","upvote_count":"1","timestamp":"1665599220.0"},{"timestamp":"1665465900.0","content":"Selected Answer: B\nNo is the correct answer.\nhttps://learn.microsoft.com/en-us/azure/machine-learning/concept-compute-target\nML Designer support 3 target:\n1.Azure Machine Learning compute cluste\n2.Azure Machine Learning compute instance\n3.Azure Machine Learning Kubernetes","poster":"JTWang","comments":[{"poster":"hiyoww","comment_id":"1190369","upvote_count":"1","content":"plus 4. Azure Machine Learning serverless compute","timestamp":"1712404200.0"}],"comment_id":"691767","upvote_count":"2"},{"upvote_count":"6","comment_id":"656935","poster":"Steven2022","content":"i just tried in AML designer, can choose attached compute now","timestamp":"1662091380.0"},{"timestamp":"1652968080.0","upvote_count":"1","poster":"WeiD","comment_id":"603946","content":"can attach Kubernetes service for training and inferencing (preview)\nAzure Machine Learning provides you with the following options to attach your own Kubernetes clusters for training and inferencing:\n\nAzure Kubernetes Service. Azure Kubernetes Service provides a managed cluster in Azure.\nAzure Arc Kubernetes. Use Azure Arc-enabled Kubernetes clusters if your cluster is hosted outside of Azure.\nThose 2 also listed in the https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target"},{"poster":"pancman","upvote_count":"1","comment_id":"585331","content":"Selected Answer: A\nThe correct answer should have been A","timestamp":"1649871000.0"},{"poster":"synapse","comments":[{"content":"Yes you can! https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-attach-compute-studio","comments":[{"content":"Yes, there is an option to attach compute in Azure ML studio, but that does not mean you can use it for Azure Machine Learning designer. As I explained before, Azure Machine Learning designer requires either a compute instance or a compute cluster as the compute type12. Attached compute is a compute resource that you already have and can connect to your Azure Machine Learning workspace3. It can be a remote VM, an Azure Databricks cluster, an Azure HDInsight cluster, or an Azure Data Lake Analytics account3. However, these compute types are not compatible with Azure Machine Learning designer, which runs in a containerized environment and packages your model dependencies in a Docker container2. Therefore, you should create or use a compute instance or a compute cluster instead of attaching compute in Azure ML studio.","poster":"deyoz","upvote_count":"1","comment_id":"1160159","timestamp":"1708993680.0"}],"timestamp":"1649870940.0","comment_id":"585330","poster":"pancman","upvote_count":"1"}],"comment_id":"565387","upvote_count":"1","content":"Selected Answer: B\nCant use attached when using designer","timestamp":"1646994060.0"},{"timestamp":"1639652580.0","comment_id":"502864","upvote_count":"5","content":"Training on attached compute is not possible when using designer according to this: https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target","poster":"chchufzx"},{"comment_id":"462415","content":"To use compute targets created outside the Azure Machine Learning workspace, you must attach them. Attaching a compute target makes it available to your workspace. Use Attached compute to attach a compute target for training. Use Inference clusters to attach an AKS cluster for inferencing.","timestamp":"1634273160.0","upvote_count":"2","poster":"skrjha20"}],"exam_id":64,"topic":"1","answer_images":[],"answer":"B"},{"id":"h8Pc0OsuThIkZ0i7VM8g","question_text":"This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.\nYou have been tasked with employing a machine learning model, which makes use of a PostgreSQL database and needs GPU processing, to forecast prices.\nYou are preparing to create a virtual machine that has the necessary tools built into it.\nYou need to make use of the correct virtual machine type.\nRecommendation: You make use of a Geo AI Data Science Virtual Machine (Geo-DSVM) Windows edition.\nWill the requirements be satisfied?","answer_description":"","answer_ET":"B","question_images":[],"discussion":[{"upvote_count":"10","timestamp":"1650047400.0","poster":"nick234987","content":"Because a Data Science Virtual Machine (DSVM) Windows edition also has GPU and you do not need Geo capabilities","comment_id":"462763"},{"timestamp":"1723869180.0","upvote_count":"1","content":"Geo AI Data Science Virtual Machine (Geo-DSVM) has nothing to do with the answer. WRONG","poster":"evangelist","comment_id":"1152399"},{"comment_id":"1070196","poster":"Matt2000","upvote_count":"2","timestamp":"1715672700.0","content":"Is Azure Geo AI Data Science VM (Geo-DSVM) currently available on Azure? I only find old references. That is usually an indicator that a service has been deprecated."},{"content":"Geo capabilites why would that be used in price prediction unless we know its a real estate prices !!","comment_id":"1067651","timestamp":"1715392020.0","poster":"Vikyyy","upvote_count":"1"},{"comment_id":"1041295","timestamp":"1712888820.0","content":"Selected Answer: B\nYou have been tasked with employing a machine learning model, which make use of \n+ a PostgreSQL database\n+ GPU processing\nto forecast prices. You are preparing to create a virtual machine that has the NECESSARY TOOLS built into it. --> Should not use Geo AI Data Science VM (Geo-DSVM) Windows edition. --> Choose answer B - No.","upvote_count":"1","poster":"james2033"},{"poster":"PopeyeDS","comment_id":"951246","timestamp":"1705216860.0","upvote_count":"1","content":"Selected Answer: B\nA more appropriate recommendation would be to use a Data Science Virtual Machine (DSVM) with GPU support. This would ensure that the virtual machine has the necessary tools for machine learning, including PostgreSQL for database management, and also provides GPU capabilities for accelerated processing required by the model."},{"content":"Correct answer. no PostgreSQL on the window edition","poster":"aaodiall1","upvote_count":"1","comment_id":"912136","timestamp":"1701443820.0"},{"content":"Selected Answer: B\nNo is right","poster":"orionduo","timestamp":"1692076440.0","comment_id":"809231","upvote_count":"1"},{"timestamp":"1690778220.0","comment_id":"793731","poster":"emmanuelodenyire","content":"Selected Answer: B\nB. No.\n\nWhile a Geo AI Data Science Virtual Machine (Geo-DSVM) Windows edition might be a good choice for geographic data processing and analysis, it does not necessarily meet the requirement for GPU processing for the machine learning model and a PostgreSQL database. A different virtual machine type with GPU support and PostgreSQL capabilities might be a better choice for this specific use case. It's recommended to check the specific virtual machine offerings and their specifications to ensure that the necessary hardware and software resources are available for the task at hand.","upvote_count":"2"},{"upvote_count":"1","comment_id":"750767","content":"no is the answer","poster":"sameerpixel","timestamp":"1687250700.0"},{"comment_id":"739952","content":"No","upvote_count":"1","poster":"Edriv","timestamp":"1686295080.0"},{"content":"isn't YES??","timestamp":"1678744380.0","upvote_count":"1","comment_id":"668379","poster":"claps92"},{"upvote_count":"2","content":"correct. no need for geo","timestamp":"1658770860.0","poster":"ranjsi01","comment_id":"532368"},{"upvote_count":"1","timestamp":"1649593680.0","poster":"Zhubajie","comment_id":"460054","content":"Any idea?"}],"isMC":true,"url":"https://www.examtopics.com/discussions/microsoft/view/63900-exam-dp-100-topic-1-question-4-discussion/","timestamp":"2021-10-10 14:28:00","answer":"B","choices":{"A":"Yes","B":"No"},"unix_timestamp":1633868880,"topic":"1","exam_id":64,"question_id":34,"answers_community":["B (100%)"],"answer_images":[]},{"id":"nA8MgClucXB7ucTnrWr5","question_id":35,"answer_ET":"B","answer_description":"","answer":"B","exam_id":64,"discussion":[{"poster":"Moshekwa","upvote_count":"11","comment_id":"417813","timestamp":"1675168560.0","content":"inference cluster is to deploy not train hence B"},{"comment_id":"909117","upvote_count":"1","content":"Selected Answer: B\nIts compute cluster","timestamp":"1732871640.0","poster":"krishna1818"},{"content":"Selected Answer: B\nTraining non on inference cluster","comment_id":"565389","timestamp":"1694420520.0","poster":"synapse","upvote_count":"2"}],"answers_community":["B (100%)"],"choices":{"A":"Yes","B":"No"},"question_images":[],"question_text":"This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.\nYou are planning to make use of Azure Machine Learning designer to train models.\nYou need choose a suitable compute type.\nRecommendation: You choose Inference cluster.\nWill the requirements be satisfied?","answer_images":[],"timestamp":"2021-07-31 12:36:00","isMC":true,"unix_timestamp":1627727760,"url":"https://www.examtopics.com/discussions/microsoft/view/59016-exam-dp-100-topic-1-question-40-discussion/","topic":"1"}],"exam":{"lastUpdated":"12 Apr 2025","isBeta":false,"isMCOnly":false,"provider":"Microsoft","numberOfQuestions":512,"name":"DP-100","id":64,"isImplemented":true},"currentPage":7},"__N_SSP":true}