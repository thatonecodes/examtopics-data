{"pageProps":{"questions":[{"id":"2A82rdKYavEIDof5SqZz","answer_ET":"C","isMC":true,"choices":{"B":"Azure Analysis Services using Microsoft Visual Studio","C":"Azure Stream Analytics cloud job using Azure PowerShell","A":"Azure Data Factory instance using Azure PowerShell","D":"Azure Data Factory instance using Microsoft Visual Studio"},"discussion":[{"comment_id":"119671","content":"I agree with answer C. But shoudn't be Azure Stream Analytics edge job ?","timestamp":"1593107040.0","comments":[{"timestamp":"1614599340.0","poster":"watata","comment_id":"301314","content":"yes, it should be this option","upvote_count":"4"}],"poster":"SebK","upvote_count":"21"},{"timestamp":"1603522500.0","comment_id":"204971","poster":"tyler4kn","upvote_count":"16","content":"In the exam, the answer is \"Azure Stream Analytics with Azure Portal\", not PowerShell. That is the correct answer."},{"poster":"realtp9","upvote_count":"1","comment_id":"436483","content":"on 31st August, it was Azure Stream Analytics Edge Application using Microsoft Visual Studio","timestamp":"1630424940.0"},{"comment_id":"237085","poster":"syu31svc","content":"It can only be stream analytics","upvote_count":"4","timestamp":"1607328240.0"},{"poster":"Arsa","upvote_count":"6","timestamp":"1598012460.0","comment_id":"162942","content":"correct"}],"answer_description":"Stream Analytics is a cost-effective event processing engine that helps uncover real-time insights from devices, sensors, infrastructure, applications and data quickly and easily.\nMonitor and manage Stream Analytics resources with Azure PowerShell cmdlets and powershell scripting that execute basic Stream Analytics tasks.\nNote: Visual Studio 2019 and Visual Studio 2017 also support Stream Analytics Tools.\nReference:\nhttps://cloudblogs.microsoft.com/sqlserver/2014/10/29/microsoft-adds-iot-streaming-analytics-data-production-and-workflow-services-to-azure/","answer":"C","exam_id":66,"answer_images":[],"unix_timestamp":1593107040,"url":"https://www.examtopics.com/discussions/microsoft/view/24057-exam-dp-201-topic-2-question-7-discussion/","topic":"2","question_id":121,"answers_community":[],"question_text":"A company purchases IoT devices to monitor manufacturing machinery. The company uses an IoT appliance to communicate with the IoT devices.\nThe company must be able to monitor the devices in real-time.\nYou need to design the solution.\nWhat should you recommend?","question_images":[],"timestamp":"2020-06-25 19:44:00"},{"id":"Qj7vLuyLYidOVcLdjynz","timestamp":"2020-04-01 18:58:00","question_images":["https://www.examtopics.com/assets/media/exam-media/03774/0015400001.png"],"answers_community":[],"discussion":[{"upvote_count":"60","timestamp":"1588061700.0","poster":"AaronZ","content":"Just finished my test, there is no second drop box for input source, only Input Type and Function. Maybe Event Hub and IoT hub both are correct now, so they removed the question.","comment_id":"80711","comments":[{"poster":"ChinChin","timestamp":"1589543520.0","upvote_count":"2","comment_id":"89468","content":"Correct"}]},{"upvote_count":"14","poster":"jsad","comment_id":"75379","timestamp":"1587054840.0","content":"It says that the app needs to alert users"},{"upvote_count":"2","comment_id":"330425","comments":[{"content":"stream","timestamp":"1618744320.0","upvote_count":"3","poster":"anamaster","comment_id":"338138"}],"timestamp":"1617804360.0","content":"How about box 1? Is the input a stream or a reference?","poster":"aksoumi"},{"poster":"nehab0101","timestamp":"1598083200.0","upvote_count":"3","content":"yes both are correct event hub and Iot Hub","comment_id":"163430"},{"timestamp":"1598012580.0","upvote_count":"3","comment_id":"162945","content":"correct answers","poster":"Arsa"},{"upvote_count":"7","comment_id":"119686","timestamp":"1593108120.0","poster":"AhmedReda","comments":[{"upvote_count":"1","timestamp":"1621844460.0","poster":"cadio30","content":"good reference","comment_id":"365415"}],"content":"I thinks Answer = IoT, as per that link of Geospatial function\nhttps://docs.microsoft.com/en-us/azure/stream-analytics/geospatial-scenarios"},{"upvote_count":"2","poster":"Abhilvs","content":"I guess it is IoT hub because IoT has the ability to integrate with Edge devices","timestamp":"1592736720.0","comment_id":"115479"},{"poster":"MLCL","content":"I think bothe Event Hub and IoT hub work in this scenario.","comment_id":"76843","upvote_count":"2","timestamp":"1587371520.0"},{"poster":"mclawson1966","comment_id":"70188","upvote_count":"4","content":"Why IoT Hub? I don't see a requirement for bi-directional...","timestamp":"1585760280.0"}],"answer_ET":"","url":"https://www.examtopics.com/discussions/microsoft/view/17771-exam-dp-201-topic-2-question-8-discussion/","answer_images":["https://www.examtopics.com/assets/media/exam-media/03774/0015500001.png"],"question_id":122,"unix_timestamp":1585760280,"answer":"","topic":"2","question_text":"HOTSPOT -\nYou plan to create a real-time monitoring app that alerts users when a device travels more than 200 meters away from a designated location.\nYou need to design an Azure Stream Analytics job to process the data for the planned app. The solution must minimize the amount of code developed and the number of technologies used.\nWhat should you include in the Stream Analytics job? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","answer_description":"Input type: Stream -\nYou can process real-time IoT data streams with Azure Stream Analytics.\n\nInput source: Azure IoT Hub -\nIn a real-world scenario, you could have hundreds of these sensors generating events as a stream. Ideally, a gateway device would run code to push these events to Azure Event Hubs or Azure IoT Hubs.\n\nFunction: Geospatial -\nWith built-in geospatial functions, you can use Azure Stream Analytics to build applications for scenarios such as fleet management, ride sharing, connected cars, and asset tracking.\nReference:\nhttps://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-get-started-with-azure-stream-analytics-to-process-data-from-iot-devices https://docs.microsoft.com/en-us/azure/stream-analytics/geospatial-scenarios","exam_id":66,"isMC":false},{"id":"7aLz2FGRCneEXwG4yvme","answer_description":"Azure Stream Analytics (ASA) on IoT Edge empowers developers to deploy near-real-time analytical intelligence closer to IoT devices so that they can unlock the full value of device-generated data.\nReference:\nhttps://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-edge","choices":{"A":"Azure Data Factory instance using the Azure portal","C":"Azure Stream Analytics Edge application using Microsoft Visual Studio","D":"Azure Analysis Services using the Azure portal","B":"Azure Analysis Services using Microsoft Visual Studio"},"answer_ET":"C","timestamp":"2021-03-24 10:18:00","isMC":true,"exam_id":66,"answer":"C","question_text":"A company purchases IoT devices to monitor manufacturing machinery. The company uses an IoT appliance to communicate with the IoT devices.\nThe company must be able to monitor the devices in real-time.\nYou need to design the solution.\nWhat should you recommend?","question_images":[],"answers_community":[],"discussion":[{"upvote_count":"8","poster":"Nik71","timestamp":"1616577480.0","content":"https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-tools-for-visual-studio-edge-jobs","comment_id":"318979"}],"topic":"2","url":"https://www.examtopics.com/discussions/microsoft/view/48067-exam-dp-201-topic-2-question-9-discussion/","question_id":123,"unix_timestamp":1616577480,"answer_images":[]},{"id":"Qus2YBM1atYrSSBuS6A7","answer_description":"Azure Synapse Analytics is a cloud-based enterprise data warehouse that leverages massively parallel processing (MPP) to quickly run complex queries across petabytes of data. Use SQL Data Warehouse as a key component of a big data solution.\nYou can access Azure Synapse Analytics (SQL DW) from Databricks using the SQL Data Warehouse connector (referred to as the SQL DW connector), a data source implementation for Apache Spark that uses Azure Blob Storage, and PolyBase in SQL DW to transfer large volumes of data efficiently between a\nDatabricks cluster and a SQL DW instance.\nScenario: ADatum identifies the following requirements for the Health Insights application:\nâœ‘ The new Health Insights application must be built on a massively parallel processing (MPP) architecture that will support the high performance of joins on large fact tables\nReference:\nhttps://docs.databricks.com/data/data-sources/azure/sql-data-warehouse.html","choices":{"D":"Azure Databricks","A":"Azure Cosmos DB that uses the Gremlin API","B":"Azure Data Factory","C":"Azure Cosmos DB that uses the SQL API"},"answer_ET":"D","timestamp":"2020-05-13 16:02:00","answer":"D","isMC":true,"exam_id":66,"question_text":"You need to design a solution that meets the business requirements of Health Insights.\nWhat should you include in the recommendation?","question_images":[],"answers_community":[],"discussion":[{"content":"It should be azure data warehouse (or actually synapse analytics now)","timestamp":"1589378520.0","upvote_count":"12","comments":[{"comment_id":"90394","poster":"vistran","upvote_count":"5","timestamp":"1589700360.0","content":"True\nSince that option is not available, next best option would be Azure Databricks which can access Azure Synapse Anlytics through Azure Synapse Connector I guess"},{"poster":"DaemonMahara","content":"I think question is asking for design solution for storing the data .. so Databricks should be fine i guess ...","timestamp":"1607107140.0","comment_id":"235136","upvote_count":"1"}],"poster":"[Removed]","comment_id":"88310"},{"poster":"SidN","upvote_count":"10","timestamp":"1592442660.0","comment_id":"112827","content":"isn't the answer B - ADF can be used to make data available into SQLDW as per requirement\"The data from Health Interface and Health Review must be available in Health Insights within 15 minutes of being committed.\""},{"upvote_count":"5","poster":"ThijsN","comment_id":"269011","content":"I pick databricks over ADF because it need to grab both streaming (the interface data) and batch data.","timestamp":"1610818740.0"},{"poster":"XoN","upvote_count":"2","comment_id":"267000","timestamp":"1610626800.0","content":"I had this question in my exam. I believe Databricks is the best answer."},{"upvote_count":"1","timestamp":"1608683340.0","content":"\"Minimize the number of services required to perform data processing, development, scheduling, monitoring, and the operationalizing of pipelines\" - ADF best fits this requirement so my answer is B","comments":[{"poster":"Johnnien","comment_id":"253030","content":"Can I use ADF only for solution of both Health Insights and Health Interface?","timestamp":"1609035720.0","upvote_count":"1"},{"comment_id":"269009","upvote_count":"2","poster":"ThijsN","content":"databricks fits that description as well.","timestamp":"1610818680.0"}],"poster":"saponazureguy","comment_id":"250548"},{"comment_id":"238117","timestamp":"1607422020.0","upvote_count":"2","poster":"syu31svc","content":"From https://docs.databricks.com/data/data-sources/azure/synapse-analytics.html:\n\"You can access Azure Synapse from Databricks using the Azure Synapse connector\"\nDatabricks it is then"},{"poster":"M0e","timestamp":"1603795320.0","comment_id":"206973","content":"Still not convinced why ADF is not the answer instead of ADB? I think both can be used as part of the solution. -- Data is ingested from Health Interface which should support scalable batch processing (ADB) and the data should be transferred to the Insight in 15 minutes intervals (ADF). So either both answers are correct or question is faulty and has been changed by now.","upvote_count":"2"},{"upvote_count":"3","timestamp":"1598129820.0","poster":"Bob123456","comment_id":"163923","content":"How about Cosmos with Sql Api option C ??","comments":[{"poster":"suhas16c","comment_id":"188875","timestamp":"1601278800.0","content":"Cosmos DB supports only self joins. But health insight app shold support joins on fact tables. Hence cosmos db is ruled out","upvote_count":"4"}]},{"poster":"extraego","comment_id":"158527","content":"From \"The data from Health Interface and Health Review must be available in Health Insights within 15 minutes of being committed.\" we have two options: Azure Data Factory and Azure Databricks. \nThen we need to be able to analyze events, so Azure Databricks is the answer.","upvote_count":"1","timestamp":"1597478340.0"},{"timestamp":"1596362700.0","content":"Answer B? \n\nAs described by Health Insights Requirements: the solution shall provide a data warehouse and the ingestion into the data warehouse. ADF might be the solution for the ingestion past.","comment_id":"149036","upvote_count":"1","poster":"dcpavelescu","comments":[{"poster":"Johnnien","content":"I cannot see the requirement of ingestion into the data warehouse.","comment_id":"253027","timestamp":"1609035300.0","upvote_count":"1"}]},{"content":"where is the option for synapse? the answer should be synapse","upvote_count":"2","poster":"pravinDataSpecialist","comment_id":"115752","timestamp":"1592760780.0"},{"poster":"thukza","timestamp":"1591386300.0","content":"massively parallel processing (MPP) architecture -> SQL DW but its not part of the answer options here","upvote_count":"1","comment_id":"103377"}],"topic":"20","url":"https://www.examtopics.com/discussions/microsoft/view/20482-exam-dp-201-topic-20-question-1-discussion/","question_id":124,"unix_timestamp":1589378520,"answer_images":[]},{"id":"rr1P8tr1yZ1A98pFKNWI","discussion":[{"poster":"dbdev","upvote_count":"12","content":"Do not read other comments(save time), the answer is correct.","comment_id":"374956","timestamp":"1622885040.0"},{"content":"It should be cosmosdb for health review as well because of encyption at rest and transit","comment_id":"309712","comments":[{"content":"oltp synaps .?","poster":"H_S","timestamp":"1616512500.0","comment_id":"318197","upvote_count":"1"},{"timestamp":"1618314420.0","comment_id":"334630","content":"Nah, always encrypted will do the trick","upvote_count":"1","poster":"maciejt"},{"poster":"Devendra00023","comment_id":"339491","content":"No, refer - https://docs.microsoft.com/en-us/azure/security/fundamentals/encryption-atrest#:~:text=Azure%20SQL%20Database%20currently%20supports,feature%20called%20Transparent%20Data%20Encryption.","timestamp":"1618915200.0","upvote_count":"3"},{"comment_id":"353091","comments":[{"poster":"Ous01","content":"Well, Azure SQL is also encrypted in transit without using Always Encrypted.","comment_id":"369100","upvote_count":"1","timestamp":"1622252100.0"}],"poster":"Mily94","upvote_count":"2","timestamp":"1620569220.0","content":"you can enable always encrypted on SQL DB."},{"content":"SQL database \"Transparent Data Encryption\" is \"encryption at rest\"","comment_id":"361882","timestamp":"1621493100.0","upvote_count":"2","poster":"alain2"}],"poster":"akram786","timestamp":"1615641660.0","upvote_count":"4"}],"exam_id":66,"timestamp":"2021-03-13 14:21:00","topic":"20","question_text":"HOTSPOT -\nWhich Azure data storage solution should you recommend for each application? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","question_id":125,"url":"https://www.examtopics.com/discussions/microsoft/view/46877-exam-dp-201-topic-20-question-2-discussion/","answers_community":[],"question_images":["https://www.examtopics.com/assets/media/exam-media/03774/0002900001.jpg"],"answer":"","answer_images":["https://www.examtopics.com/assets/media/exam-media/03774/0003000001.jpg","https://www.examtopics.com/assets/media/exam-media/03774/0003000002.png"],"isMC":false,"answer_ET":"","answer_description":"Health Review: Azure SQL Database\nScenario: ADatum identifies the following requirements for the Health Review application:\nEnsure that sensitive health data is encrypted at rest and in transit.\n\nâœ‘ Tag all the sensitive health data in Health Review. The data will be used for auditing.\nHealth Interface: Azure Cosmos DB\nADatum identifies the following requirements for the Health Interface application:\nâœ‘ Upgrade to a data storage solution that will provide flexible schemas and increased throughput for writing data. Data must be regionally located close to each hospital, and reads must display be the most recent committed version of an item.\nâœ‘ Reduce the amount of time it takes to add data from new hospitals to Health Interface.\nâœ‘ Support a more scalable batch processing solution in Azure.\nâœ‘ Reduce the amount of development effort to rewrite existing SQL queries.\nHealth Insights: Azure Synapse Analytics\nAzure Synapse Analytics is a cloud-based enterprise data warehouse that leverages massively parallel processing (MPP) to quickly run complex queries across petabytes of data. Use SQL Data Warehouse as a key component of a big data solution.\nYou can access Azure Synapse Analytics (SQL DW) from Databricks using the SQL Data Warehouse connector (referred to as the SQL DW connector), a data source implementation for Apache Spark that uses Azure Blob Storage, and PolyBase in SQL DW to transfer large volumes of data efficiently between a\nDatabricks cluster and a SQL DW instance.\nScenario: ADatum identifies the following requirements for the Health Insights application:\nâœ‘ The new Health Insights application must be built on a massively parallel processing (MPP) architecture that will support the high performance of joins on large fact tables\nReference:\nhttps://docs.databricks.com/data/data-sources/azure/sql-data-warehouse.html","unix_timestamp":1615641660}],"exam":{"isImplemented":true,"isMCOnly":false,"lastUpdated":"12 Apr 2025","numberOfQuestions":206,"isBeta":false,"id":66,"name":"DP-201","provider":"Microsoft"},"currentPage":25},"__N_SSP":true}