{"pageProps":{"questions":[{"id":"AFNYFfgS4YwsiIiHuMIe","answer_ET":"","topic":"5","discussion":[{"content":"Migrate\nUpdate\n40000\n\nThe question is probably incorrect. Usually `--throughput` parameter is used to configure throughput for manual mode. And `--max-throughput` is used for autoscale mode. But here `--throughput` is used for autoscale, so it is not clear how it will work, probably it will be ignored or the script will fail. \n\nhttps://microsoftlearning.github.io/dp-420-cosmos-db-dev/instructions/30-adjust-throughput-cli-script.html \n\nI think the question is incorrect. If the order of commands is correct, then we have to use `--max-throughput` 40000 instead of `--throughput ...`. If the order is incorrect, then we should call `-- throughput 40000` and after that we should change mode to autoscale. \n\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/autoscale-faq?tabs=azure-powerShell#how-does-the-migration-between-autoscale-and-standard--manual--provisioned-throughput-work-","upvote_count":"1","poster":"RosaHutor","comment_id":"1365332","comments":[{"timestamp":"1741167480.0","upvote_count":"1","content":"Anyway, answer for 3rd option is 40000, and not 4000","poster":"RosaHutor","comment_id":"1365333"}],"timestamp":"1741167300.0"},{"upvote_count":"3","content":"Migrate\nUpdate\n4000\n\nThe selected answer is correct.","comment_id":"1200699","timestamp":"1729683480.0","poster":"[Removed]"},{"comment_id":"1066361","comments":[{"poster":"xRiot007","upvote_count":"1","comment_id":"1113936","timestamp":"1720107360.0","content":"You can only refer to the script on the screen, not add *possible* commands before it. Given this, I think that script is incorrect. When updating it should also provide a max throughput prop set to 40.000. This question seems incomplete to me."}],"timestamp":"1715245080.0","upvote_count":"2","content":"This is very tricky question. They didn't specified the order of command in the question.\nThe thing is, you should use \"--max-throughput\" attribute to set it (to 40000), cause \"--throughput\" is ignored in this case.\nThus, the correct sequence of commands are reversed:\n// first, set default (max) provisioned mode (that will converted to max throughput when migration to autoscale)\naz cosmosdb sql database throughput update -a \"account1\" -g \"cosmosdbrg\" -n \"db1\" --max-throughput 40000\n\n// then migrate to autoscale keeping the current provisioned throughput as max\naz cosmosdb sql database throughput migrate -a \"account1\" -g \"cosmosdbrg\" -n \"db1\" --throughput-type autoscale\n\nBecause in autoscale mode you would still pay 1/10 of specified max throughput, you matches requirements specified in the question.","poster":"Norvegec"},{"upvote_count":"2","poster":"b890yc","content":"Answer: migrate, update & 4000\n\naz cosmosdb sql database throughput migrate -a \"account1\" -g \"cosmosdbrg\" -n \"db1\" --throughput-type autoscale\n\naz cosmosdb sql database throughput update -a \"account1\" -g \"cosmosdbrg\" -n \"db1\" ---throughput 4000\n\nTo set max throughput, use the following command.\naz cosmosdb sql database throughput update -a \"account1\" -g \"cosmosdbrg\" -n \"db1\" --max-throughput 40000","timestamp":"1711614000.0","comment_id":"1019480","comments":[]},{"upvote_count":"3","content":"Answer is \n\nMigrate / Migrate / 40000","comments":[{"poster":"azuredemo2022three","upvote_count":"2","content":"Correct Script\n\naz cosmosdb sql database throughput migrate -a \"account1\" -g \"cosmosdbrg\" -n \"db1\" --throughput-type autoscale\n\naz cosmosdb sql database throughput update -a \"account1\" -g \"cosmosdbrg\" -n \"db1\" --max-throughput 40000","timestamp":"1703186160.0","comment_id":"929763"}],"timestamp":"1703185020.0","poster":"azuredemo2022three","comment_id":"929749"},{"content":"For the second don‘t confuse throughput & max-throughput","comment_id":"885995","timestamp":"1698834480.0","poster":"TRUESON","upvote_count":"1"},{"content":"correct \nhttps://learn.microsoft.com/en-us/azure/cosmos-db/nosql/manage-with-cli?source=recommendations#migrate-a-database-to-autoscale-throughput","timestamp":"1685393400.0","upvote_count":"3","poster":"Juba1711","comment_id":"730912"}],"url":"https://www.examtopics.com/discussions/microsoft/view/89316-exam-dp-420-topic-5-question-3-discussion/","timestamp":"2022-11-29 23:50:00","question_text":"HOTSPOT -\nYou have a database named db1 in an Azure Cosmos DR Core (SQL) API account named account1. The db1 database has a manual throughput of 4,000 request units per second (RU/s).\nYou need to move db1 from manual throughput to autoscale throughput by using the Azure CLI. The solution must provide a minimum of 4,000 RU/s and a maximum of 40,000 RU/s.\nHow should you complete the CLI statements? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","answers_community":[],"answer":"","unix_timestamp":1669762200,"isMC":false,"question_id":126,"answer_description":"Box 1: migrate -\nThe az cosmosdb sql database throughput migrate command migrates the throughput of the SQL database between autoscale and manually provisioned.\nSyntax: az cosmosdb sql database throughput migrate\n--account-name\n--name\n--resource-group\n--throughput-type {autoscale, manual}\n\nBox 2: update -\nThe az cosmosdb sql database throughput update command updates the throughput of the SQL database under an Azure Cosmos DB account.\nSyntax: az cosmosdb sql database throughput update\n--account-name\n--name\n--resource-group\n[--max-throughput]\n[--throughput]\n\nBox 3: 4000 -\nSpecify the throughput.\n\nParameter --throughput -\nThe throughput of SQL database (RU/s).\nNote: Example migration from standard (manual) provisioned throughput to autoscale: Suppose you have a container with 10,000 RU/s manual provisioned throughput, and 25 GB of storage. When you enable autoscale, the initial autoscale max RU/s will be: 10,000 RU/s, which will scale between 1000 - 10,000 RU/s.\nNote 2: Parameter --max-throughput\nThe maximum throughput resource can scale to (RU/s). Provided when the resource is autoscale enabled. The minimum value can be 4000 (RU/s).\nReference:\nhttps://docs.microsoft.com/en-us/cli/azure/cosmosdb/sql/database/throughput","question_images":["https://www.examtopics.com/assets/media/exam-media/04276/0012200001.jpg"],"answer_images":["https://www.examtopics.com/assets/media/exam-media/04276/0012300001.jpg"],"exam_id":69},{"id":"i8YnFfPXzjWlgSNJuX1M","question_images":["https://img.examtopics.com/dp-420/image171.png"],"question_id":127,"topic":"5","discussion":[{"content":"Selected Answer: B\nB is correct","poster":"matejka","upvote_count":"1","comment_id":"1411009","timestamp":"1743104760.0"}],"unix_timestamp":1735122900,"timestamp":"2024-12-25 11:35:00","question_text":"You have an Azure subscription that contains the resources shown in the following table.\n\n//IMG//\n\n\nYou need to store the account key of account1 in KV1.\n\nWhat should you use?","answer_description":"","choices":{"C":"a certificate","B":"a secret","A":"a key"},"answer_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/153435-exam-dp-420-topic-5-question-30-discussion/","answers_community":["B (100%)"],"isMC":true,"exam_id":69,"answer":"B","answer_ET":"B"},{"id":"rv04oHIMOIyA3QFNUEq2","answer_images":[],"url":"https://www.examtopics.com/discussions/microsoft/view/135997-exam-dp-420-topic-5-question-32-discussion/","answers_community":["C (100%)"],"question_images":[],"question_id":128,"timestamp":"2024-03-14 08:01:00","exam_id":69,"discussion":[{"content":"Selected Answer: C\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/periodic-backup-restore-introduction#understanding-the-cost-of-backups\nTwo backups are provided free and extra backups are charged according to the region-based pricing for backup storage described in backup storage pricing.\n24hours/2hours*4days-2=46","comment_id":"1173192","timestamp":"1726290060.0","poster":"3a0b61c","upvote_count":"6"}],"unix_timestamp":1710399660,"answer":"C","question_text":"You have an Azure subscription that contains an Azure Cosmos DB for NoSQL account named account1.\n\nBackups for account1 have the following configurations:\n\n• Interval: 2 hours\n• Retention period: 4 days\n\nYou need to estimate the charges associated with the retention of the backups.\n\nHow many copies of the backups will incur additional charges?","topic":"5","answer_ET":"C","isMC":true,"choices":{"D":"48","C":"46","B":"12","A":"8"},"answer_description":""},{"id":"rN7C2JPAM0CEMrnfLomU","topic":"5","question_text":"HOTSPOT\n-\n\nYou have an on-premises network.\n\nYou have an Azure subscription that contains an Azure Cosmos DB account named account1 and an Azure virtual network named VNet1. VNet1 contains two virtual machines named VM1 and VM2. VNet1 is connected to the on-premises network by using a Site-to-Site (S2S) VPN.\n\nYou need to meet the following requirements:\n\n• Block access to the public endpoint of account1.\n• Allow only VM1 to access account1.\n\nWhat should you include in the solution? To answer, select the appropriate options in the answer area.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","answer_ET":"","unix_timestamp":1715076780,"url":"https://www.examtopics.com/discussions/microsoft/view/140129-exam-dp-420-topic-5-question-33-discussion/","exam_id":69,"answer_description":"","answers_community":[],"answer_images":["https://img.examtopics.com/dp-420/image180.png"],"discussion":[{"comment_id":"1207825","poster":"[Removed]","timestamp":"1730981580.0","upvote_count":"6","content":"To provide network connectivity to account1, use a: Private endpoint\nA private endpoint in Azure is a network interface that connects you privately and securely to a service powered by Azure Private Link. The private endpoint uses a private IP address from your VNet, effectively bringing the service into your VNet. This will block access to the public endpoint of account1.\nTo allow only VM1 to access account1, use: Network security group (NSG) inbound rules\nNetwork Security Group (NSG) provides a list of allowed and denied traffic rules. These rules can be associated with a subnet or a specific network interface. In this case, you can set up NSG inbound rules to allow only VM1 to access account1."}],"isMC":false,"answer":"","question_images":["https://img.examtopics.com/dp-420/image179.png"],"question_id":129,"timestamp":"2024-05-07 12:13:00"},{"id":"qETmBHsifheczaeeERtz","answer":"","question_text":"HOTSPOT\n-\n\nYou have an Azure subscription that contains an Azure Cosmos DB for NoSQL database named DB1. The shared throughput provisioned for DB1 is 10,000 DTU/s. DB1 contains the containers shown in the following table.\n\n//IMG//\n\n\nYou need to modify the throughput for the containers. The solution must meet the following requirements:\n\n• The maximum throughput for Container1 must be 4,000 DTU/s.\n• The throughput for Container2 must be shared across the containers.\n• Administrative effort must be minimized.\n\nWhat should you do? To answer, select the appropriate options in the answer area.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","url":"https://www.examtopics.com/discussions/microsoft/view/140130-exam-dp-420-topic-5-question-34-discussion/","answer_images":["https://img.examtopics.com/dp-420/image183.png"],"question_images":["https://img.examtopics.com/dp-420/image181.png","https://img.examtopics.com/dp-420/image182.png"],"topic":"5","unix_timestamp":1715077380,"answer_ET":"","exam_id":69,"isMC":false,"answers_community":[],"discussion":[{"poster":"matejka","upvote_count":"1","comment_id":"1372995","content":"Suggested Actions:\nContainer1: Modify the settings of Container1 to provision a throughput of 4,000 DTU/s.\n\nContainer2: Modify the settings of Container2 to use shared throughput from DB1.\n\nDB1: Ensure DB1's shared throughput can accommodate the changes.\n\nBy making these changes, you can achieve the specified throughput requirements while minimizing administrative effort.","timestamp":"1741538280.0"},{"comment_id":"1220871","content":"For Both you need to migrate the data to new containers\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/set-throughput\n\n\"A container with provisioned throughput cannot be converted to shared database container. Conversely a shared database container cannot be converted to have a dedicated throughput. You will need to move the data to a container with the desired throughput setting. (Container copy jobs for NoSQL, MongoDB and Cassandra APIs help with this process.)\"","timestamp":"1732887540.0","upvote_count":"2","poster":"8fe085a"},{"poster":"[Removed]","content":"For Container1: You should Modify the settings of Container1 to set its maximum throughput to 4000 DTU/s.\nFor Container2: You should Modify the settings of DB1 to share the throughput across containers.","upvote_count":"2","comment_id":"1207832","timestamp":"1730982180.0"}],"question_id":130,"timestamp":"2024-05-07 12:23:00","answer_description":""}],"exam":{"id":69,"numberOfQuestions":147,"isMCOnly":false,"name":"DP-420","provider":"Microsoft","lastUpdated":"12 Apr 2025","isBeta":false,"isImplemented":true},"currentPage":26},"__N_SSP":true}