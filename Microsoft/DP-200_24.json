{"pageProps":{"questions":[{"id":"JasFbtLUxxc5w0fPlyk8","exam_id":65,"answer_images":["https://www.examtopics.com/assets/media/exam-media/03872/0023500001.jpg"],"topic":"2","discussion":[{"comment_id":"182471","comments":[{"upvote_count":"1","poster":"dinesh_tng","comment_id":"393509","timestamp":"1624942980.0","content":"Actually, with the given options, answer is correct. Ans - C"}],"timestamp":"1600545420.0","poster":"09012020","upvote_count":"20","content":"I think answer is correct. TUMBLING WINDOW as event muse be counted once.\n\nTumbling window\nTumbling window functions are used to segment a data stream into distinct time segments and perform a function against them, such as the example below. The key differentiators of a Tumbling window are that they repeat, do not overlap, and an event cannot belong to more than one tumbling window\n\nTumbling window\nTumbling window functions are used to segment a data stream into distinct time segments and perform a function against them, such as the example below. The key differentiators of a Tumbling window are that they repeat, do not overlap, and an event cannot belong to more than one tumbling window"},{"comment_id":"364311","content":"Every tween must be counted only once - tumbling window, unlike hopping, guarantees the windows will not overlap","poster":"maciejt","upvote_count":"3","timestamp":"1621759560.0"},{"comment_id":"333074","timestamp":"1618124940.0","upvote_count":"2","content":"I think C is the correct answer. Definition of tumbling window: \"fixed size window with advance interval equals to the window size\". \nAnswer D is clearly wrong: \"a five-minute Hopping window that has a one-minute hop\" doesnt fit \"five minutes every five minutes\" requirement.","poster":"tucho"},{"content":"A hoping window can act as tumbling window, if time unit and window size is same.","timestamp":"1593911760.0","poster":"Rahul111","upvote_count":"2","comment_id":"126476","comments":[{"comment_id":"129249","content":"D. a five-minute Hopping window that has one-minute hop \n\nOne minute hop Rahul, 1 min hop.","poster":"MLCL","timestamp":"1594151760.0","upvote_count":"4"}]},{"poster":"oku","comment_id":"120571","upvote_count":"1","comments":[{"content":"It would be if the hop is 5 minutes as well as the window, BUT the answer \"D\" says this: \n\"D. a five-minute Hopping window that has one-minute hop\"\nwhich means overlap will occur. \nSo, the answer is \"C\" and that's correct.","poster":"Ikrom","upvote_count":"9","timestamp":"1593357900.0","comment_id":"121979"}],"content":"It must be Hopping Window -To make a Hopping window the same as a Tumbling window, specify the hop size to be the same as the window size. So Answer is D","timestamp":"1593178080.0"},{"upvote_count":"1","comments":[{"content":"Hopping Window has overlapped and an item can be counted more than once","poster":"z8zhong","timestamp":"1583944380.0","upvote_count":"9","comment_id":"62546"}],"poster":"avestabrzn","content":"I would say just Hopping Window.","comment_id":"60680","timestamp":"1583674680.0"}],"url":"https://www.examtopics.com/discussions/microsoft/view/15847-exam-dp-200-topic-2-question-45-discussion/","question_text":"You use Azure Stream Analytics to receive Twitter data from Azure Event Hubs and to output the data to an Azure Blob storage account.\nYou need to output the count of tweets during the last five minutes every five minutes. Each tweet must only be counted once.\nWhich windowing function should you use?","question_id":116,"answer_ET":"C","timestamp":"2020-03-08 14:38:00","answers_community":[],"question_images":[],"choices":{"C":"a five-minute Tumbling window","A":"a five-minute Sliding window","B":"a five-minute Session window","D":"a five-minute Hopping window that has a one-minute hop"},"answer_description":"Tumbling window functions are used to segment a data stream into distinct time segments and perform a function against them, such as the example below. The key differentiators of a Tumbling window are that they repeat, do not overlap, and an event cannot belong to more than one tumbling window.\n\nIncorrect Answers:\nD: Hopping window functions hop forward in time by a fixed period. It may be easy to think of them as Tumbling windows that can overlap, so events can belong to more than one Hopping window result set. To make a Hopping window the same as a Tumbling window, specify the hop size to be the same as the window size.\nReference:\nhttps://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-window-functions","unix_timestamp":1583674680,"answer":"C","isMC":true},{"id":"C65DjiUo3DRjn6XQcLsq","question_text":"You are developing a solution that will stream to Azure Stream Analytics. The solution will have both streaming data and reference data.\nWhich input type should you use for the reference data?","question_images":[],"timestamp":"2020-07-27 12:58:00","unix_timestamp":1595847480,"answer_description":"Stream Analytics supports Azure Blob storage and Azure SQL Database as the storage layer for Reference Data.\nReference:\nhttps://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-use-reference-data","answer_images":[],"exam_id":65,"choices":{"B":"Azure Event Hubs","A":"Azure Cosmos DB","C":"Azure Blob storage","D":"Azure IoT Hub"},"discussion":[{"upvote_count":"12","timestamp":"1595847480.0","poster":"Yaswant","comment_id":"144880","content":"For reference data Azure SQL database and Blob storage are supported."},{"poster":"syu31svc","comment_id":"227560","content":"Link provided supports C as the answer","upvote_count":"2","timestamp":"1606307760.0"},{"upvote_count":"2","content":"That is true, but it SQL DB is not in options","timestamp":"1605900060.0","poster":"sunil_kalra","comment_id":"223914"}],"answer_ET":"C","answers_community":[],"answer":"C","url":"https://www.examtopics.com/discussions/microsoft/view/26768-exam-dp-200-topic-2-question-46-discussion/","question_id":117,"isMC":true,"topic":"2"},{"id":"4UERCXf9QgdgSagUZNOY","answer":"","unix_timestamp":1621368960,"answer_description":"Box 1: Tumbling -\nTumbling window functions are used to segment a data stream into distinct time segments and perform a function against them, such as the example below. The key differentiators of a Tumbling window are that they repeat, do not overlap, and an event cannot belong to more than one tumbling window.\n\n\nBox 2: Hopping -\nHopping window functions hop forward in time by a fixed period. It may be easy to think of them as Tumbling windows that can overlap, so events can belong to more than one Hopping window result set. To make a Hopping window the same as a Tumbling window, specify the hop size to be the same as the window size.\n\n\nBox 3: Sliding -\nSliding window functions, unlike Tumbling or Hopping windows, produce an output only when an event occurs. Every window will have at least one event and the window continuously moves forward by an ג‚¬ (epsilon). Like hopping windows, events can belong to more than one sliding window.\n\nReference:\nhttps://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-window-functions","answer_ET":"","url":"https://www.examtopics.com/discussions/microsoft/view/53060-exam-dp-200-topic-2-question-47-discussion/","question_id":118,"answer_images":["https://www.examtopics.com/assets/media/exam-media/03872/0023800001.png","https://www.examtopics.com/assets/media/exam-media/03872/0023900001.png","https://www.examtopics.com/assets/media/exam-media/03872/0024000001.jpg","https://www.examtopics.com/assets/media/exam-media/03872/0024000002.jpg"],"question_text":"HOTSPOT -\nYou are implementing Azure Stream Analytics windowing functions.\nWhich windowing function should you use for each requirement? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","isMC":false,"timestamp":"2021-05-18 22:16:00","topic":"2","discussion":[{"upvote_count":"6","poster":"memo43","comment_id":"360821","timestamp":"1621368960.0","content":"answer is CORRECT"}],"exam_id":65,"answers_community":[],"question_images":["https://www.examtopics.com/assets/media/exam-media/03872/0023700001.png"]},{"id":"pblDxewkzH1vpB2E5meF","answer":"","exam_id":65,"question_id":119,"answer_images":["https://www.examtopics.com/assets/media/exam-media/03872/0024200001.png"],"url":"https://www.examtopics.com/discussions/microsoft/view/49229-exam-dp-200-topic-2-question-48-discussion/","question_text":"DRAG DROP -\nYou have an Azure Data Lake Storage Gen2 account that contains JSON files for customers. The files contain two attributes named FirstName and LastName.\nYou need to copy the data from the JSON files to an Azure Synapse Analytics table by using Azure Databricks. A new column must be created that concatenates the FirstName and LastName values.\nYou create the following components:\n✑ A destination table in Azure Synapse\n✑ An Azure Blob storage container\n✑ A service principal\nWhich five actions should you perform in sequence next in a Databricks notebook? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\nSelect and Place:\n//IMG//","timestamp":"2021-04-05 17:57:00","answer_ET":"","discussion":[{"upvote_count":"15","poster":"cadio30","comments":[{"content":"Can you explain what is \"FHEAB\"?","poster":"niwe","comments":[{"comments":[{"upvote_count":"1","timestamp":"1623638760.0","content":"Thanks!","comment_id":"381483","poster":"niwe"}],"poster":"maciejt","upvote_count":"2","comment_id":"364321","timestamp":"1621760160.0","content":"letter-numbers of steps to choose"}],"comment_id":"363071","timestamp":"1621605000.0","upvote_count":"1"}],"timestamp":"1620020820.0","content":"It requires to mount the ALDS gen 2 thus the sequence is right \"FHEAB\".","comment_id":"348297"},{"upvote_count":"10","poster":"hoangton","content":"Correct answer should be:\nStep 1: Mount the Data Lake Storage onto DBFS\nStep 2: Read the file into a data frame.\nStep 3: Perform transformations on the data frame.\nStep 4: Specify a temporary folder to stage the data\nStep 5: Write the results to a table in Azure Synapse.","timestamp":"1623509400.0","comment_id":"380527"},{"content":"The Answer is Perfect. \nMounting is not Required.\nDrop Data Frame should be there.\n\nThe question never mentioned that you have to use Service Principle. Had it be 6 steps I would have added Mounting Steps. But Considering only 5 steps, the below 5 steps have more priority then Mounting (not an essential).","upvote_count":"1","comment_id":"421107","comments":[{"timestamp":"1632720840.0","upvote_count":"1","poster":"satyamkishoresingh","content":"why drop dataframe ?cleanup the resource is about cluster not the DF .","comment_id":"452186"}],"timestamp":"1628324400.0","poster":"Bhagya123456"},{"content":"Mount Data Lake Storage onto DBFS (Service Principal)\nRead the file into data frame\nPerform Transformation on the data frame\nSpecify the temp folder to stage data\nwrite results to synapse table\nhttps://docs.microsoft.com/en-us/azure/databricks/scenarios/databricks-extract-load-sql-data-warehouse","poster":"vrmei","upvote_count":"4","comments":[{"timestamp":"1623000300.0","poster":"vrmei","upvote_count":"1","content":"small correction: I don't see the mount option in ADLS account configuration in the given URL. \nI feel the given answer might correct. The last one should be Drop the data frame which will do cleanup ...","comment_id":"376245"}],"timestamp":"1622999760.0","comment_id":"376238"},{"comment_id":"367573","upvote_count":"1","content":"Do we really need to stage the data? We could directly write the dataframe to Synapse.\nhttps://docs.microsoft.com/en-us/azure/databricks/data/data-sources/azure/synapse-analytics","timestamp":"1622082840.0","poster":"unidigm","comments":[{"content":"Yes, we do. tempDir (that stages data) MUST be specified for Synapse write method.","poster":"Rob77","timestamp":"1622131020.0","comment_id":"368102","upvote_count":"2"}]},{"poster":"Aragorn_2021","comments":[{"content":"Agree.\n\nService Principal (which is given in the task) is used for mounting.\n\nMount an Azure Data Lake Gen 2 to DBFS (Databricks File System) using a Service Principal:\nhttps://kyleake.medium.com/mount-an-adls-gen-2-to-databricks-file-system-using-a-service-principal-and-oauth-2-0-ep-5-73172dd0ddeb","timestamp":"1620981300.0","comment_id":"357032","poster":"111222333","upvote_count":"2"}],"timestamp":"1618938480.0","content":"I would go for FHEAB. Mount the storage -> Read the file to a dataframe ->transform it further -> write the data to temporary folder in storage -> and load to DWH","upvote_count":"5","comment_id":"339752"},{"comment_id":"333250","timestamp":"1618141200.0","content":"I agree with HEAB. But I don' know which is the missing one. I think there is no need to \"drop the DF\" or to \"mount the DL storage\"... :-( Does anybody know the right full answer?","poster":"tucho","upvote_count":"1"},{"upvote_count":"2","comment_id":"328836","content":"wrong, should be F,H,E,A,B. The DataLake storage has to be mounted onto DBFS before red the file","comments":[{"timestamp":"1617784980.0","upvote_count":"2","poster":"DongDuong","content":"Based on the provided link, I think the keyword here is \"mounted\". Datalake storage is not mounted onto DBFS, instead, it is called by Databricks via API. So the given answer is correct","comments":[{"upvote_count":"2","poster":"DongDuong","content":"After revising, I think FHEAB makes more sense","timestamp":"1617927960.0","comment_id":"331625"}],"comment_id":"330190"}],"poster":"alf99","timestamp":"1617638220.0"}],"answers_community":[],"topic":"2","answer_description":"Step 1: Read the file into a data frame.\nYou can load the json files as a data frame in Azure Databricks.\nStep 2: Perform transformations on the data frame.\nStep 3:Specify a temporary folder to stage the data\nSpecify a temporary folder to use while moving data between Azure Databricks and Azure Synapse.\nStep 4: Write the results to a table in Azure Synapse.\nYou upload the transformed data frame into Azure Synapse. You use the Azure Synapse connector for Azure Databricks to directly upload a dataframe as a table in a Azure Synapse.\n\nStep 5: Drop the data frame -\nClean up resources. You can terminate the cluster. From the Azure Databricks workspace, select Clusters on the left. For the cluster to terminate, under Actions, point to the ellipsis (...) and select the Terminate icon.\nReference:\nhttps://docs.microsoft.com/en-us/azure/azure-databricks/databricks-extract-load-sql-data-warehouse","unix_timestamp":1617638220,"question_images":["https://www.examtopics.com/assets/media/exam-media/03872/0024100004.png"],"isMC":false},{"id":"zMxPifO3eojpSmCM24Dl","answer_ET":"A","choices":{"B":"Self-hosted integration runtime","A":"Azure integration runtime","C":"Azure-SSIS integration runtime"},"question_text":"You have an Azure Storage account and a data warehouse in Azure Synapse Analytics in the UK South region.\nYou need to copy blob data from the storage account to the data warehouse by using Azure Data Factory.\nThe solution must meet the following requirements:\n✑ Ensure that the data remains in the UK South region at all times.\n✑ Minimize administrative effort.\nWhich type of integration runtime should you use?","answer_images":["https://www.examtopics.com/assets/media/exam-media/03872/0024400001.png"],"unix_timestamp":1620946740,"answer":"A","url":"https://www.examtopics.com/discussions/microsoft/view/52651-exam-dp-200-topic-2-question-49-discussion/","question_id":120,"discussion":[{"poster":"Chiranjib","timestamp":"1620946740.0","content":"I would go for A. ADF allows to create Azure IR for a specific region & \"UK South\" is listed as a region.\n\nhttps://docs.microsoft.com/en-us/azure/data-factory/create-azure-integration-runtime#create-azure-ir","upvote_count":"7","comment_id":"356702"}],"timestamp":"2021-05-14 00:59:00","topic":"2","answer_description":"Incorrect Answers:\nB: Self-hosted integration runtime is to be used On-premises.\nReference:\nhttps://docs.microsoft.com/en-us/azure/data-factory/concepts-integration-runtime","question_images":[],"answers_community":[],"exam_id":65,"isMC":true}],"exam":{"lastUpdated":"12 Apr 2025","isImplemented":true,"isBeta":false,"id":65,"isMCOnly":false,"name":"DP-200","provider":"Microsoft","numberOfQuestions":228},"currentPage":24},"__N_SSP":true}