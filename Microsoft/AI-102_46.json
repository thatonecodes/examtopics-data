{"pageProps":{"questions":[{"id":"V53zHQhO3vu97NWJ9D7T","question_images":["https://img.examtopics.com/ai-102/image179.png"],"isMC":true,"question_id":226,"answer_ET":"C","timestamp":"2024-10-19 11:16:00","answers_community":["C (71%)","D (17%)","13%"],"choices":{"B":"File2.jpg only","C":"File3.tiff only","D":"File2.jpg and File3.tiff only","A":"File 1.pdf only","E":"File1.pdf, File2.jpg, and File3.tiff"},"exam_id":40,"unix_timestamp":1729329360,"answer_description":"","topic":"4","answer":"C","discussion":[{"comment_id":"1312281","upvote_count":"6","content":"Selected Answer: C\nFile1 > 500 Mb so NO\nFile 2 <50x50 pixels so NO\nFile 3 YES","timestamp":"1731611520.0","poster":"Alan_CA"},{"comment_id":"1322771","content":"Selected Answer: C\nHave a look on any of the prebuilt models and you will see File3.tiff is the only one that fits.\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/prebuilt/contract?view=doc-intel-4.0.0#input-requirements","poster":"chrillelundmark","upvote_count":"5","timestamp":"1733493300.0"},{"content":"Selected Answer: C\nThe correct answer is:\n\nC. File3.tiffonly\n\nHere's why:\n\nFile1.pdf(800 MB): The Standard S0 pricing tier for Azure AI Document Intelligence has file size limits, and 800 MB exceeds the allowable limit for file analysis.\n\nFile2.jpg(1 KB, 25 x 25 pixels): This file is too small (both in terms of size and resolution) to be analyzed effectively. The minimum recommended resolution for analysis is typically higher, as such a low resolution might not provide enough data for meaningful results.\n\nFile3.tiff(5 MB, 5000 x 5000 pixels): This file is within the size and resolution limits for the Standard S0 tier. The system is capable of analyzing high-resolution images like this.","poster":"gyaansastra","upvote_count":"1","timestamp":"1741185780.0","comment_id":"1365436"},{"poster":"syupwsh","comment_id":"1354730","timestamp":"1739234520.0","content":"Selected Answer: C\nFile3.tiff meets all the requirements for processing by the Azure AI Document Intelligence resource:\n\nThe file size is 5 MB, which is within the 500 MB limit for the Standard S0 tier. Its dimensions are 5000 x 5000 pixels, which are within the acceptable range of 50 x 50 pixels to 10,000 x 10,000 pixels.\n\nC for correct","upvote_count":"1"},{"poster":"kennynelcon","comment_id":"1330559","content":"Selected Answer: D\nIn the Standard (S0) tier of Azure AI Document Intelligence, the key constraints you usually run into are:\n\nFile‐size limits of roughly 200 MB for PDFs and up to 420 MB for images (JPG/PNG/TIFF).\nImage dimension limits of up to around 10,000 × 10,000 pixels.\n\nFile1.pdf (800 MB) exceeds the typical 200 MB PDF limit, so it cannot be analyzed.\nFile2.jpg (1 KB, 25×25) is well below both the size and dimension limits for images, so it can be analyzed.\nFile3.tiff (5 MB, 5000×5000) is below the ~420 MB limit and within the 10,000×10,000 pixel limit, so it can be analyzed.\nTherefore, the files you can analyze in DI1 (S0 tier) are File2.jpg and File3.tiff.","upvote_count":"3","comments":[{"comment_id":"1340672","upvote_count":"2","content":"File1.pdf (exceeds) the limit of 500MB not 200....","timestamp":"1736915160.0","poster":"Architect_CTO"},{"timestamp":"1735366020.0","content":"Image dimensions must be between 50 pixels x 50 pixels and 10,000 pixels x 10,000 pixels. So the file2.jpg don't fit","poster":"PK234","comment_id":"1332815","upvote_count":"2"}],"timestamp":"1734899700.0"},{"poster":"nastolgia","comment_id":"1319307","content":"Selected Answer: C\nFile 3 only","timestamp":"1732807260.0","upvote_count":"2"},{"timestamp":"1730657220.0","comment_id":"1306593","poster":"Homi","content":"Selected Answer: C\nhttps://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/prebuilt/read?view=doc-intel-4.0.0&tabs=sample-code","upvote_count":"2"},{"comment_id":"1304830","upvote_count":"1","timestamp":"1730258820.0","content":"Selected Answer: D\nBetween 50 x 50 pixels and 10,000 pixels x 10,000 pixels. So D","poster":"e41f7aa","comments":[{"comment_id":"1322773","upvote_count":"1","timestamp":"1733493660.0","poster":"chrillelundmark","content":"What about the file size limitations? Are you sure that 25x25 is between 50x50 and 10,000x10,000? That's beyond my understanding."}]},{"poster":"cheetah313","comments":[{"poster":"e41f7aa","comment_id":"1304319","upvote_count":"1","timestamp":"1730185620.0","comments":[{"poster":"e41f7aa","upvote_count":"1","timestamp":"1730185620.0","comment_id":"1304320","content":"So D is the answer"}],"content":"Between 50 x 50 pixels and 10,000 pixels x 10,000 pixels. So E"}],"comment_id":"1299963","content":"Selected Answer: B\nAccording to ChatGPT the max size for PDFs is 200 MB and for images 50 MB. so File 1 is ruled out. But then it also says that the max resolution for image files \"should\" not exceed 4200 x 4200 pixels. \n\nTherefore I would say answer B: \"File2.jpg only\" is correct.","timestamp":"1729329360.0","upvote_count":"3"}],"answer_images":[],"question_text":"You have an Azure subscription that contains an Azure AI Document Intelligence resource named DI1. DI1 uses the Standard S0 pricing tier.\n\nYou have the files shown in the following table.\n\n//IMG//\n\n\nWhich files can you analyze by using DI1?","url":"https://www.examtopics.com/discussions/microsoft/view/149782-exam-ai-102-topic-4-question-29-discussion/"},{"id":"xyXJ5vbNduBnstJp4X1o","url":"https://www.examtopics.com/discussions/microsoft/view/56501-exam-ai-102-topic-4-question-3-discussion/","discussion":[{"poster":"syupwsh","timestamp":"1739679540.0","comment_id":"1357136","content":"Selected Answer: D\nhttps://learn.microsoft.com/en-us/azure/search/search-how-to-large-index#run-indexers-in-parallel\n\nIf your data source is an Azure Blob Storage container or Azure Data Lake Storage Gen 2, enumerating a large number of blobs can take a long time (even hours) until this operation is completed. As a result, your indexer's documents succeeded count doesn't appear to increase during that time and it might seem it's not making any progress, when it is. If you would like document processing to go faster for a large number of blobs, consider partitioning your data into multiple containers and create parallel indexers pointing to a single index.\n\nD for sure","upvote_count":"1"},{"poster":"krzkrzkra","upvote_count":"2","content":"Selected Answer: D\nSelected Answer: D","comment_id":"1247900","timestamp":"1720979940.0"},{"poster":"reigenchimpo","upvote_count":"2","content":"Selected Answer: D\nIn my opinion, D is correct on this question.","comment_id":"1229851","timestamp":"1718285940.0"},{"timestamp":"1717847280.0","content":"Selected Answer: D\nD makes sense. \"virtual folders\".","upvote_count":"2","comment_id":"1226716","poster":"anto69"},{"poster":"reiwanotora","comment_id":"1218710","timestamp":"1716694020.0","content":"Selected Answer: D\nFOCUS \"virtual folders\" word.","upvote_count":"3"},{"poster":"Murtuza","timestamp":"1711892700.0","content":"Tricky question think of virtual folder AS blob containers and the answer will be obvious","upvote_count":"2","comment_id":"1186829"},{"comments":[{"poster":"famco","upvote_count":"2","timestamp":"1726388400.0","comment_id":"1283976","content":"how is that different from separate containers?"}],"timestamp":"1707015060.0","upvote_count":"2","content":"Selected Answer: D\ne, option D is the best choice because it leverages the scalability and parallel processing capabilities of Azure Cognitive Search to efficiently index a large volume of documents. By organizing documents into virtual folders and creating an indexer for each folder, you can maximize the throughput of the indexing process. Increasing search units further supports this by allocating more resources to the task, thereby minimizing the time required to make the scanned documents searchable.","comment_id":"1139734","poster":"evangelist"},{"upvote_count":"3","comment_id":"1063522","content":"Selected Answer: D\nI think correct answer is D\n\nhttps://learn.microsoft.com/en-us/azure/search/search-howto-large-index#run-indexers-in-parallel","timestamp":"1699248000.0","poster":"rdemontis"},{"upvote_count":"1","poster":"sl_mslconsulting","content":"Selected Answer: D\n\"One search unit in your service can run one indexer at any given time. Creating multiple indexers is only useful if they can run in parallel\" so A and C are out. B is out as you are not running the indexers in parallel. Besides it's hard to image that with millions of scanned you don't have virtual folders in place to split the data already.","timestamp":"1698439260.0","comment_id":"1055831"},{"comment_id":"938071","upvote_count":"2","comments":[{"upvote_count":"4","poster":"zellck","comment_id":"938073","content":"If your data source is an Azure Blob Storage container or Azure Data Lake Storage Gen 2, enumerating a large number of blobs can take a long time (even hours) until this operation is completed. This will cause that your indexer's documents succeeded count isn't increased during that time and it may seem it's not making any progress, when it is. If you would like document processing to go faster for a large number of blobs, consider partitioning your data into multiple containers and create parallel indexers pointing to a single index.","timestamp":"1688041080.0"}],"poster":"zellck","content":"Selected Answer: D\nD is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/search/search-howto-large-index#run-indexers-in-parallel\nIf you partition your data, you can create multiple indexer-data-source combinations that pull from each data source and write to the same search index. Because each indexer is distinct, you can run them at the same time, populating a search index more quickly than if you ran them sequentially.\n\nMake sure you have sufficient capacity. One search unit in your service can run one indexer at any given time. Creating multiple indexers is only useful if they can run in parallel.","timestamp":"1688041080.0"},{"content":"Selected Answer: D\nD is correct answer. \n\nAlso marked correct on Udemy course practice test.","timestamp":"1658213580.0","upvote_count":"4","poster":"Eltooth","comment_id":"633410"},{"poster":"PHD_CHENG","timestamp":"1654601400.0","upvote_count":"2","content":"Was on exam 7 Jun 2022","comment_id":"612720"},{"content":"correct ans","poster":"prabhjot","upvote_count":"1","comment_id":"535856","timestamp":"1643504820.0"},{"upvote_count":"3","comment_id":"395078","timestamp":"1625076420.0","poster":"azurelearner666","content":"how to do this is defined here:\n\nhttps://docs.microsoft.com/en-us/azure/search/search-howto-indexing-azure-blob-storage#index-large-datasets\nThe response is missing the data source creation for each virtual folder or blob container.\nD is not correct, but the less wrong of a response…\nSo I give it a \"pass\", nowadays it is misleading and not fully correct..."},{"poster":"azurelearner666","comment_id":"395068","content":"seems to be correct","upvote_count":"2","timestamp":"1625076000.0"}],"isMC":true,"exam_id":40,"question_text":"You have an existing Azure Cognitive Search service.\nYou have an Azure Blob storage account that contains millions of scanned documents stored as images and PDFs.\nYou need to make the scanned documents available to search as quickly as possible.\nWhat should you do?","timestamp":"2021-06-30 20:00:00","topic":"4","answer_images":[],"question_images":[],"choices":{"B":"Split the data into multiple blob containers. Create an indexer for each container. Increase the search units. Within each indexer definition, schedule a sequential execution pattern.","D":"Split the data into multiple virtual folders. Create an indexer for each folder. Increase the search units. Within each indexer definition, schedule the same runtime execution pattern.","A":"Split the data into multiple blob containers. Create a Cognitive Search service for each container. Within each indexer definition, schedule the same runtime execution pattern.","C":"Create a Cognitive Search service for each type of document."},"answer_description":"","answer":"D","question_id":227,"answer_ET":"D","unix_timestamp":1625076000,"answers_community":["D (100%)"]},{"id":"9FyXH8exsY5DWDAUUD9t","question_images":["https://img.examtopics.com/ai-102/image180.png"],"url":"https://www.examtopics.com/discussions/microsoft/view/149783-exam-ai-102-topic-4-question-30-discussion/","answer_description":"","answer_images":["https://img.examtopics.com/ai-102/image228.png"],"question_id":228,"discussion":[{"comments":[{"content":"it's the same question that question 18 of topic 4 , but this time is in pyton instead C# , answers are the same : \nprebuilt-document\n0.75","poster":"Christian_garcia_martin","timestamp":"1730178540.0","upvote_count":"4","comment_id":"1304296"}],"upvote_count":"14","content":"I Think field one should be \"prebuilt-read\" as this is a model suitable for OCR with handwritten documents according to ChatGPT.","comment_id":"1299966","timestamp":"1729329780.0","poster":"cheetah313"},{"timestamp":"1730657460.0","poster":"Homi","comment_id":"1306595","content":"Prebuilt-read\nhttps://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/prebuilt/read?view=doc-intel-4.0.0&tabs=sample-code","upvote_count":"8"},{"content":"repeat qn\n\nPrebuilt-read\n0.75","comment_id":"1355912","upvote_count":"1","poster":"syupwsh","timestamp":"1739408100.0"},{"upvote_count":"2","poster":"jolimon","content":"Prebuilt-read\n0.75","comment_id":"1308492","timestamp":"1731001080.0"}],"topic":"4","question_text":"HOTSPOT -\n\nYou have an Azure subscription that contains an Azure AI Document Intelligence resource named DI1.\n\nYou build an app named App1 that analyzes PDF files for handwritten content by using DI1.\n\nYou need to ensure that App1 will recognize the handwritten content.\n\nHow should you complete the code? To answer, select the appropriate options in the answer area.\n\nNOTE: Each correct selection is worth one point.\n\n//IMG//","answers_community":[],"timestamp":"2024-10-19 11:23:00","answer_ET":"","isMC":false,"unix_timestamp":1729329780,"answer":"","exam_id":40},{"id":"cpForodyaZTfmVSs3DZ5","url":"https://www.examtopics.com/discussions/microsoft/view/149767-exam-ai-102-topic-4-question-31-discussion/","discussion":[{"comments":[{"upvote_count":"2","poster":"cheetah313","content":"Since the upload of the documents is done to the storage account, which is already present before we create the custom model project, I think the order in the original answer given is correct.","timestamp":"1729330260.0","comments":[{"poster":"chrillelundmark","timestamp":"1733494560.0","upvote_count":"3","content":"What you think isn't relevant compared to documentation. Read the documentation and find out Gadez is correct.\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/quickstarts/try-document-intelligence-studio?view=doc-intel-4.0.0","comment_id":"1322781"}],"comment_id":"1299967"}],"poster":"gadez1234","timestamp":"1729286820.0","comment_id":"1299808","upvote_count":"9","content":"I think the answer is as follows.\n\nCreate a custom model project and link the project to sa1\nUpload five sample documents.\nApply labels to the sample documents.\nTrain and test the model."},{"content":"Given answer seems correct since documents would be uploaded in SA already. https://learn.microsoft.com/en-us/training/modules/work-form-recognizer/9-form-recognizer-studio","upvote_count":"1","timestamp":"1742958180.0","poster":"sooss","comment_id":"1410237"},{"poster":"syupwsh","comment_id":"1355914","timestamp":"1739408520.0","content":"1) Create a custom model project and link the project to sa1: This step initializes the custom model project in Document Intelligence Studio and links it to the storage account (sa1) to access the necessary training data.\n\n2) Upload five sample documents: Uploading a minimum of five documents is sufficient to train a basic custom model. This reduces development effort while meeting the minimum requirements for training.\n\n3) Apply labels to the sample documents: Label the uploaded documents to define the specific fields or data points that the custom model needs to extract. This step is essential for supervised learning.\n\n4) Train and test the model: Once labeling is complete, train the model to recognize patterns in the labeled data and test its performance to ensure it meets accuracy requirements.","upvote_count":"1"},{"timestamp":"1730178720.0","comment_id":"1304297","content":"If you did not create custom model project , where do you upload images ? so for me:\nCreate a custom model project and link the project to sa1\nUpload five sample documents.\nApply labels to the sample documents.\nTrain and test the model.","upvote_count":"4","poster":"Christian_garcia_martin"}],"answer_images":["https://img.examtopics.com/ai-102/image183.png"],"exam_id":40,"isMC":false,"topic":"4","question_id":229,"timestamp":"2024-10-18 23:27:00","question_images":["https://img.examtopics.com/ai-102/image182.png"],"answer_ET":"","question_text":"DRAG DROP\n-\n\nYou have an Azure subscription that contains a storage account named sa1 and an Azure AI Document Intelligence resource named DI1.\n\nYou need to create and train a custom model in DI1 by using Document Intelligence Studio. The solution must minimize development effort.\n\nWhich four actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\n\n//IMG//","answer":"","answer_description":"","answers_community":[],"unix_timestamp":1729286820},{"id":"nX2cFe3YbUPnmwhQJhek","url":"https://www.examtopics.com/discussions/microsoft/view/150444-exam-ai-102-topic-4-question-32-discussion/","answer_images":["https://img.examtopics.com/ai-102/image185.png"],"question_text":"DRAG DROP\n-\n\nYou have an Azure subscription that contains an Azure AI Document Intelligence resource named DI1 and a storage account named sa1. The sa1 account contains a blob container named blob1 and an Azure Files share named share1.\n\nYou plan to build a custom model named Model1 in DI1.\n\nYou create sample forms and JSON files for Model1.\n\nYou need to train Model1 and retrieve the ID of the model.\n\nWhich four actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\n\nNOTE: More than one order of answer choices is correct. You will receive credit for any of the correct orders you select.\n\n//IMG//","answer_description":"","exam_id":40,"unix_timestamp":1730179020,"question_images":["https://img.examtopics.com/ai-102/image184.png"],"answer_ET":"","topic":"4","answer":"","question_id":230,"isMC":false,"answers_community":[],"timestamp":"2024-10-29 06:17:00","discussion":[{"content":"Microsoft copilot:\n\nUpload the forms and JSON files to blob1: Ensure that your sample forms and JSON files are uploaded to the blob container named blob1 in the storage account sa1.\n\nCreate a shared access signature (SAS) URL for blob1: Generate a SAS URL for the blob container to provide secure access to the files.\n\nCall the Build model REST API function: Use the SAS URL to call the Build model REST API function in DI1 to start the training process.\n\nCall the Get model REST API function: After the training is complete, call the Get model REST API function to retrieve the ID of Model1.","poster":"Christian_garcia_martin","comment_id":"1304298","timestamp":"1730179020.0","upvote_count":"12","comments":[{"poster":"Alan_CA","comment_id":"1312295","upvote_count":"3","timestamp":"1731612360.0","content":"Looks like you're right :\nhttps://learn.microsoft.com/en-us/rest/api/aiservices/document-models/build-model?view=rest-aiservices-v4.0%20(2024-07-31-preview)&tabs=HTTP#tabpanel_1_HTTP"}]},{"poster":"syupwsh","upvote_count":"2","timestamp":"1739842620.0","comment_id":"1358077","content":"Christian_garcia_martin's answers are correct"},{"comment_id":"1317105","upvote_count":"1","content":"We can connect to Azure Blob Storage using either an access key or a SAS token.","timestamp":"1732462920.0","poster":"nastolgia"}]}],"exam":{"lastUpdated":"12 Apr 2025","isBeta":false,"isImplemented":true,"provider":"Microsoft","name":"AI-102","id":40,"numberOfQuestions":329,"isMCOnly":false},"currentPage":46},"__N_SSP":true}