{"pageProps":{"questions":[{"id":"bReCYYmWWIyfNhy9qHCD","question_text":"HOTSPOT -\nYou are building an Azure Stream Analytics job to retrieve game data.\nYou need to ensure that the job returns the highest scoring record for each five-minute time interval of each game.\nHow should you complete the Stream Analytics query? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","answer_ET":"","unix_timestamp":1631449980,"timestamp":"2021-09-12 14:33:00","exam_id":68,"answer_description":"Box 1: TopOne() OVER(PARTITION BY Game ORDER BY Score Desc)\nTopOne returns the top-rank record, where rank defines the ranking position of the event in the window according to the specified ordering. Ordering/ranking is based on event columns and can be specified in ORDER BY clause.\nAnalytic Function Syntax:\nTopOne() OVER ([<PARTITION BY clause>] ORDER BY (<column name> [ASC |DESC])+ <LIMIT DURATION clause> [<WHEN clause>])\nBox 2: Tumbling(minute 5)\nTumbling window functions are used to segment a data stream into distinct time segments and perform a function against them, such as the example below. The key differentiators of a Tumbling window are that they repeat, do not overlap, and an event cannot belong to more than one tumbling window.\n\nReference:\nhttps://docs.microsoft.com/en-us/stream-analytics-query/topone-azure-stream-analytics https://github.com/MicrosoftDocs/azure-docs/blob/master/articles/stream-analytics/stream-analytics-window-functions.md","answers_community":[],"answer_images":["https://www.examtopics.com/assets/media/exam-media/04275/0015500001.png","https://www.examtopics.com/assets/media/exam-media/04275/0015600001.jpg"],"question_id":211,"answer":"","discussion":[{"content":"I got a similar question while taking a DP-203 exam. Don't think this is 100% question for DP-300","poster":"Bedet","upvote_count":"16","timestamp":"1678631580.0","comment_id":"443459","comments":[{"timestamp":"1696157880.0","upvote_count":"3","comment_id":"579430","content":"I believe this question is outside the scope of DP-300 and for DP-203.","poster":"cusman"}]},{"comment_id":"751364","timestamp":"1718903040.0","content":"Answer is correct but it is from dp-203","upvote_count":"3","poster":"lobr"},{"poster":"Ciupaz","comment_id":"697211","timestamp":"1713345120.0","upvote_count":"1","content":"Stream Analytics is not part of the DP-300 exam."},{"comment_id":"482886","poster":"o2091","upvote_count":"4","comments":[{"timestamp":"1706631480.0","content":"That looks like your answer to most questions!","upvote_count":"6","poster":"SabSep","comment_id":"639713"}],"content":"The answer looks right","timestamp":"1684617060.0"}],"isMC":false,"question_images":["https://www.examtopics.com/assets/media/exam-media/04275/0015400001.png"],"topic":"3","url":"https://www.examtopics.com/discussions/microsoft/view/61893-exam-dp-300-topic-3-question-9-discussion/"},{"id":"vXorrzu84m4f4yvwmLIp","question_images":[],"discussion":[{"poster":"voodoo_sh","upvote_count":"1","comment_id":"1341251","content":"Selected Answer: BC\nuse DB1\nalter database scoped configuration set LIGHTWEIGHT_QUERY_PROFILING = on\nalter database scoped configuration set LAST_QUERY_PLAN_STATS = on","timestamp":"1736973900.0"},{"upvote_count":"1","poster":"2f5c7cd","content":"Selected Answer: BC\nbc","timestamp":"1729410000.0","comment_id":"1300331"},{"content":"AC - Why B (Lightweight Query Profiling) is not the correct option:\nLightweight Query Profiling (LWP) provides a way to monitor query execution with minimal overhead, but it does not specifically capture the parameter values used in the last executed query. It is designed for gathering general execution statistics, such as CPU time, execution steps, etc., but not the actual parameter values used during the last execution.","poster":"bingomutant","timestamp":"1728625800.0","comment_id":"1295849","upvote_count":"1"},{"timestamp":"1724756820.0","comment_id":"1273388","upvote_count":"1","poster":"dorwai","content":"Selected Answer: AC\nLightweight Query Profiling (LWP) is used to monitor query execution in a lightweight manner, but it doesn't specifically capture the last executed query's parameters."},{"content":"Selected Answer: BE\nChat says B, E:\n\nthe correct answers are B (Enable Lightweight_Query_Profiling in DB1) and E (Enable PARAMETER_SNIFFING in DB1). These actions will help you capture and analyze parameter values for your sales report queries.","comment_id":"1216175","timestamp":"1716433020.0","poster":"pjfunner","upvote_count":"1"},{"poster":"KingChuang","content":"Selected Answer: BC\nI think answer given is correct.\n\nRef:\nhttps://learn.microsoft.com/en-us/sql/relational-databases/performance/query-profiling-infrastructure?view=sql-server-ver16","timestamp":"1676442840.0","comment_id":"809204","comments":[{"poster":"Sr18","upvote_count":"1","timestamp":"1719609780.0","comment_id":"1238934","content":"It is correct, B is obviously first choice but Query Plan can be used for same \nIn the query plan XML (from the query_plan column), look for the ParameterCompiledValue node to find the compiled parameter value"}],"upvote_count":"3"},{"comment_id":"768924","timestamp":"1673125800.0","upvote_count":"1","poster":"mmat","content":"Not sure if \"C. Enable Last_Query_Plan_Stats in DB1\" would capture anything related to parameters."},{"comment_id":"741132","upvote_count":"1","timestamp":"1670692440.0","poster":"lobr","content":"Is it ok?"}],"answer_description":"","question_text":"You have SQL Server on an Azure virtual machine that contains a database named DB1.\nYou have an application that queries DB1 to generate a sales report.\nYou need to see the parameter values from the last time the query was executed.\nWhich two actions should you perform? Each correct answer presents part of the solution.\nNOTE: Each correct selection is worth one point.","exam_id":68,"choices":{"D":"Enable Lightweight_Query_Profiling in the master database","A":"Enable Last_Query_Plan_Stats in the master database","B":"Enable Lightweight_Query_Profiling in DB1","E":"Enable PARAMETER_SNIFFING in DB1","C":"Enable Last_Query_Plan_Stats in DB1"},"question_id":212,"answer":"BC","answers_community":["BC (71%)","14%","14%"],"answer_images":[],"answer_ET":"BC","url":"https://www.examtopics.com/discussions/microsoft/view/90938-exam-dp-300-topic-4-question-1-discussion/","unix_timestamp":1670692440,"isMC":true,"timestamp":"2022-12-10 18:14:00","topic":"4"},{"id":"T9RaDse7VUVWg3vYgMRM","isMC":true,"exam_id":68,"answer_description":"Dedicated SQL pool supports many, but not all, of the table features offered by other databases.\nSurrogate keys are not supported. Implement it with an Identity column.\nReference:\nhttps://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-overview","answer":"A","answers_community":[],"discussion":[{"comment_id":"692029","timestamp":"1728645540.0","content":"This question is more related to the DP-203 exam. I've never seen a topic like this in MeasureUp practice test.","upvote_count":"4","poster":"Ciupaz"},{"comment_id":"500657","timestamp":"1702477860.0","upvote_count":"4","poster":"Fedor","content":"https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-identity\nSurrogate Keys. Implement with Identity - it is meant that Identity is OK"},{"content":"i don't know. The only one correct is B\n\nDedicated SQL pool supports many, but not all, of the table features offered by other databases. The following list shows some of the table features that aren't supported in dedicated SQL pool:\n- Foreign key, Check Table Constraints\n- Computed Columns\n- Indexed Views\n- Sequence (OPTION C)\n- Sparse Columns\n- Surrogate Keys. Implement with Identity (OPTION A).\n- Synonyms\n- Triggers\n- Unique Indexes\n- User-Defined Types\nhttps://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-overview#unsupported-table-features","poster":"quermi","timestamp":"1701959340.0","comment_id":"496090","upvote_count":"3"},{"content":"Another DB-203 Question...","comments":[{"content":"this is a 100% dp-300 questoin","comments":[{"upvote_count":"3","comment_id":"597934","content":"no it is not, Synaps is not part of 300","poster":"freemun05","timestamp":"1715046180.0"}],"poster":"gerard","comment_id":"501173","timestamp":"1702539420.0","upvote_count":"4"}],"upvote_count":"3","timestamp":"1699632060.0","comment_id":"475622","poster":"jerkyflexoff"},{"content":"Identity is correct, it is a dedicated SQL pool","poster":"joelabc1234","timestamp":"1698566400.0","upvote_count":"3","comment_id":"469600"},{"comment_id":"451779","timestamp":"1695723420.0","comments":[{"poster":"aakben","timestamp":"1696260840.0","upvote_count":"2","content":"But link for data factory and azure synapse pipelines not for azure synapse dedicated pool. \nReview your answer again","comment_id":"456141"}],"upvote_count":"1","poster":"aakben","content":"It should be sequence. Sequence is faster then identity value generation.\nhttps://docs.microsoft.com/en-us/azure/data-factory/data-flow-surrogate-key"}],"question_images":[],"answer_images":[],"timestamp":"2021-09-26 12:17:00","question_text":"You are designing a dimension table in an Azure Synapse Analytics dedicated SQL pool.\nYou need to create a surrogate key for the table. The solution must provide the fastest query performance.\nWhat should you use for the surrogate key?","question_id":213,"topic":"4","answer_ET":"A","unix_timestamp":1632651420,"url":"https://www.examtopics.com/discussions/microsoft/view/62734-exam-dp-300-topic-4-question-10-discussion/","choices":{"A":"an IDENTITY column","B":"a GUID column","C":"a sequence object"}},{"id":"CWGgRk78GIq6ukye6N4Z","question_text":"You are designing a star schema for a dataset that contains records of online orders. Each record includes an order date, an order due date, and an order ship date.\nYou need to ensure that the design provides the fastest query times of the records when querying for arbitrary date ranges and aggregating by fiscal calendar attributes.\nWhich two actions should you perform? Each correct answer presents part of the solution.\nNOTE: Each correct selection is worth one point.","timestamp":"2022-10-20 13:24:00","exam_id":68,"unix_timestamp":1666265040,"isMC":true,"choices":{"E":"Use DateTime columns for the date fields.","D":"Use integer columns for the date fields.","A":"Create a date dimension table that has a DateTime key.","C":"Use built-in SQL functions to extract date attributes.","B":"Create a date dimension table that has an integer key in the format of YYYYMMDD."},"answer_description":"Why use a Date Dimension Table in a Data Warehouse.\nThe Date dimension is one of these dimension tables related to the Fact. Here is a simple Data Diagram for a Data Mart of Internet Sales information for the\nAdventure Works DW database which can be obtained for free from CodePlex or other online sources.\n\nThe relationship is created by the surrogate keys columns (integer data type) rather than the date data type.\nThe query users have to write against a Data Mart are much simpler than against a transaction database. There are less joins because of the one to many relationships between the fact dimension table(s). The dimension tables are confusing to someone who has been normalizing databases as a career. The dimension is a flattened or de-normalized table. This creates cases of duplicate data, but the simplistic query overrides the duplicate data in a dimensional model.\nReference:\nhttps://www.mssqltips.com/sqlservertip/3117/defining-role-playing-dimensions-for-sql-server-analysis-services/ https://community.idera.com/database-tools/blog/b/community_blog/posts/why-use-a-date-dimension-table-in-a-data-warehouse","discussion":[{"comments":[{"timestamp":"1724238720.0","comment_id":"816605","poster":"CloudTech@2023","upvote_count":"2","content":"Why DP203?","comments":[{"upvote_count":"1","comment_id":"880474","timestamp":"1729866060.0","poster":"OBIJUAN88","content":"It talks about Data Warehouse, is out of scope"}]}],"timestamp":"1713612240.0","comment_id":"699840","content":"This is for DP-203 exam.","poster":"Ciupaz","upvote_count":"5"},{"upvote_count":"1","comment_id":"824596","content":"This is for DP-203 exam","poster":"HSQL","timestamp":"1724831640.0"}],"url":"https://www.examtopics.com/discussions/microsoft/view/86023-exam-dp-300-topic-4-question-11-discussion/","answers_community":[],"topic":"4","question_id":214,"answer_ET":"BD","question_images":[],"answer":"BD","answer_images":["https://www.examtopics.com/assets/media/exam-media/04275/0020100001.png"]},{"id":"KSYolEElTn3dUcVAaUdh","question_id":215,"timestamp":"2021-11-11 21:48:00","answer_description":"Box 1: Hash -\nConsider using a hash-distributed table when:\nThe table size on disk is more than 2 GB.\nThe table has frequent insert, update, and delete operations.\n\nBox 2: Clustered columnstore -\nClustered columnstore tables offer both the highest level of data compression and the best overall query performance.\nReference:\nhttps://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-distribute https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-index","question_images":["https://www.examtopics.com/assets/media/exam-media/04275/0020200001.jpg"],"exam_id":68,"answer_images":["https://www.examtopics.com/assets/media/exam-media/04275/0020300001.jpg"],"discussion":[{"upvote_count":"7","content":"looks correct","comment_id":"476512","timestamp":"1683830880.0","poster":"o2091"},{"content":"This is for DP-203 exam","upvote_count":"1","poster":"HSQL","comment_id":"824597","timestamp":"1724831700.0"},{"timestamp":"1712156760.0","poster":"Ciupaz","upvote_count":"4","comment_id":"685619","content":"This question is related to the DP-203 exam: Data Engineering on Microsoft Azure."},{"comment_id":"579473","timestamp":"1696163100.0","upvote_count":"3","content":"DP-203","poster":"cusman"},{"comment_id":"558529","upvote_count":"1","timestamp":"1693529820.0","poster":"kimalto452","content":"do203 question"}],"topic":"4","answer":"","isMC":false,"unix_timestamp":1636663680,"answer_ET":"","url":"https://www.examtopics.com/discussions/microsoft/view/65856-exam-dp-300-topic-4-question-12-discussion/","question_text":"HOTSPOT -\nYou are designing an enterprise data warehouse in Azure Synapse Analytics that will store website traffic analytics in a star schema.\nYou plan to have a fact table for website visits. The table will be approximately 5 GB.\nYou need to recommend which distribution type and index type to use for the table. The solution must provide the fastest query performance.\nWhat should you recommend? To answer, select the appropriate options in the answer area.\nNOTE: Each correct selection is worth one point.\nHot Area:\n//IMG//","answers_community":[]}],"exam":{"provider":"Microsoft","name":"DP-300","isMCOnly":false,"numberOfQuestions":360,"lastUpdated":"12 Apr 2025","isBeta":false,"id":68,"isImplemented":true},"currentPage":43},"__N_SSP":true}