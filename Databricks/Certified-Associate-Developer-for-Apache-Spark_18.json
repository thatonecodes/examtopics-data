{"pageProps":{"questions":[{"id":"dFfYMFuhlFkKODMlxtSH","isMC":true,"exam_id":161,"answer_ET":"C","answers_community":["C (67%)","B (33%)"],"unix_timestamp":1724226360,"question_images":[],"topic":"1","answer_images":[],"question_id":86,"url":"https://www.examtopics.com/discussions/databricks/view/146221-exam-certified-associate-developer-for-apache-spark-topic-1/","discussion":[{"poster":"bp_a_user","upvote_count":"1","comment_id":"1342954","timestamp":"1737282600.0","content":"Selected Answer: C\nagree, c is incorrect"},{"upvote_count":"1","poster":"Oks_An","timestamp":"1726745340.0","comment_id":"1286292","content":"Selected Answer: C\nWe need to identify INCORRECT statement, so C is the answer"},{"poster":"EmmanuelRams","content":"is telling you what is the incorrect statement, so C is incorrect","upvote_count":"1","comment_id":"1277893","timestamp":"1725411480.0"},{"poster":"6546a53","content":"Selected Answer: B\nI think it's B","upvote_count":"1","comment_id":"1269947","timestamp":"1724226360.0"}],"choices":{"B":"Transformations do not trigger execution while actions do trigger execution.","A":"There are wide and narrow transformations but there are not wide and narrow actions.","D":"Some actions can be used to return data objects in a format native to the programming language being used to access the Spark API while transformations do not provide this ability.","E":"Transformations are typically logic operations while actions are typically focused on returning results.","C":"Transformations work on DataFrames/Datasets while actions are reserved for native language objects."},"question_text":"Which of the following statements describing a difference between transformations and actions is incorrect?","answer_description":"","answer":"C","timestamp":"2024-08-21 09:46:00"},{"id":"0CWtwvSBA1hPIgT5gH9O","answer_ET":"C","topic":"1","unix_timestamp":1720547460,"answer_images":[],"question_images":[],"answer_description":"","timestamp":"2024-07-09 19:51:00","isMC":true,"answers_community":["C (100%)"],"answer":"C","choices":{"B":"Spark jobs will fail or run slowly if inaccurate data is not collected and removed from the Spark job.","A":"Logical results will be incorrect if inaccurate data is not collected and removed from the Spark job.","C":"Spark jobs will fail or run slowly if memory is not available for new objects to be created.","D":"Spark jobs will produce inaccurate results if there are too many different transformations called before a single action.","E":"Spark jobs will produce inaccurate results if memory is not available for new tasks to run and complete."},"exam_id":161,"question_id":87,"question_text":"Which of the following describes why garbage collection in Spark is important?","discussion":[{"timestamp":"1720547460.0","poster":"f728f7f","upvote_count":"1","content":"Selected Answer: C\nC is correct. Garbage in JVM is about releasing memory of objects that are no longer used so that new objects can be created","comment_id":"1245022"}],"url":"https://www.examtopics.com/discussions/databricks/view/143645-exam-certified-associate-developer-for-apache-spark-topic-1/"},{"id":"39EmxSantTfKTRetT7I4","unix_timestamp":1682490420,"timestamp":"2023-04-26 08:27:00","answer_ET":"B","question_id":88,"discussion":[{"upvote_count":"6","timestamp":"1682490420.0","content":"Selected Answer: B\nThe operation that can be used to create a DataFrame with a subset of columns from DataFrame storesDF that are specified by name is storesDF.select().\n\nThe select() operation allows you to specify the columns you want to keep in the resulting DataFrame by passing in the column names as arguments. For example, to create a new DataFrame that contains only the columns store_id and store_name from the storesDF \n\nDataFrame, you can use the following code:\n\nnewDF = storesDF.select(\"store_id\", \"store_name\")","comment_id":"881177","poster":"4be8126"},{"timestamp":"1721699160.0","upvote_count":"1","poster":"YoSpark","comment_id":"1253366","content":"E.storesDF.drop() is also correct. It is just opposite of select. If you have a large number of columns you need to select but a few to drop to meet your requirements, then drop is easier than select."},{"timestamp":"1687014360.0","poster":"TmData","content":"Selected Answer: B\nThe select() operation in Spark DataFrame allows you to specify the columns you want to include in the resulting DataFrame. You can provide column names as arguments to the select() operation to create a new DataFrame with only the specified columns.","upvote_count":"2","comment_id":"926072"}],"url":"https://www.examtopics.com/discussions/databricks/view/107534-exam-certified-associate-developer-for-apache-spark-topic-1/","exam_id":161,"answer_images":[],"question_images":[],"choices":{"D":"storesDF.filter()","B":"storesDF.select()","A":"storesDF.subset()","C":"storesDF.selectColumn()","E":"storesDF.drop()"},"answer_description":"","isMC":true,"question_text":"Which of the following operations can be used to create a DataFrame with a subset of columns from DataFrame storesDF that are specified by name?","topic":"1","answer":"B","answers_community":["B (100%)"]},{"id":"ksGCj3G4e25xHXnhbqrb","answer_description":"","answers_community":["D (100%)"],"answer":"D","question_images":[],"isMC":true,"topic":"1","question_text":"Which of the following code blocks returns a DataFrame where rows in DataFrame storesDF containing missing values in every column have been dropped?","answer_ET":"D","answer_images":[],"exam_id":161,"discussion":[{"content":"Selected Answer: D\nThe correct answer is:\n\nD. storesDF.na.drop(\"all\")\n\nExplanation:\nna.drop() is used to drop rows with missing values in a DataFrame.\nThe \"all\" argument specifies that rows will only be dropped if all columns in that row contain missing values.\nIf \"all\" is not specified, the default behavior is \"any\", which means rows with missing values in any column will be dropped.","timestamp":"1737785520.0","poster":"Souvik_79","comment_id":"1346354","upvote_count":"1"},{"timestamp":"1731641760.0","comment_id":"1211728","upvote_count":"2","content":"Selected Answer: D\nhttps://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.DataFrame.dropna.html","poster":"jtu363"}],"question_id":89,"choices":{"E":"storesDF.nadrop(\"all\")","A":"storesDF.na.drop()","B":"storesDF.dropna()","C":"storesDF.na.drop(\"all\", subset = \"sqft\")","D":"storesDF.na.drop(\"all\")"},"url":"https://www.examtopics.com/discussions/databricks/view/140675-exam-certified-associate-developer-for-apache-spark-topic-1/","unix_timestamp":1715736960,"timestamp":"2024-05-15 03:36:00"},{"id":"AET34b48MnpGkxKYyGTB","exam_id":161,"answer_images":[],"isMC":true,"discussion":[{"poster":"58470e1","timestamp":"1731707880.0","content":"Selected Answer: D\nhttps://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.explode.html?highlight=explode#pyspark.sql.functions.explode","comment_id":"1312824","upvote_count":"2"},{"poster":"Oks_An","comment_id":"1286314","timestamp":"1726747140.0","content":"Selected Answer: D\nBased on the condition \"column productCategories only has one word per row, resulting in a DataFrame with many more rows than DataFrame storesDF\" there should be an explode() function","upvote_count":"3"}],"unix_timestamp":1726747140,"url":"https://www.examtopics.com/discussions/databricks/view/147839-exam-certified-associate-developer-for-apache-spark-topic-1/","answers_community":["D (100%)"],"answer_ET":"D","answer":"D","answer_description":"","choices":{"E":"The split() operation does not accomplish the requested task. The array_distinct() operation should be used instead.","D":"The split() operation does not accomplish the requested task. The explode() operation should be used instead.","C":"The split() operation does not accomplish the requested task in the way that it is used. It should be used as a column object method instead.","A":"The split() operation does not accomplish the requested task in the way that it is used. It should be used provided an alias.","B":"The split() operation does not accomplish the requested task. The broadcast() operation should be used instead."},"timestamp":"2024-09-19 13:59:00","question_text":"The code block shown below contains an error. The code block is intended to return a new DataFrame where column productCategories only has one word per row, resulting in a DataFrame with many more rows than DataFrame storesDF. Identify the error and how to fix it.\n\nA sample of storesDF is displayed below:\n\n//IMG//\n\n\nstoresDF.withColumn(\"productCategories\", split(col(\"productCategories\")))","topic":"1","question_id":90,"question_images":["https://img.examtopics.com/certified-associate-developer-for-apache-spark/image22.png"]}],"exam":{"isImplemented":true,"numberOfQuestions":185,"isMCOnly":true,"lastUpdated":"12 Apr 2025","name":"Certified Associate Developer for Apache Spark","provider":"Databricks","isBeta":false,"id":161},"currentPage":18},"__N_SSP":true}