{"pageProps":{"questions":[{"id":"MeVqTX40PfqdEWAC711K","answer_description":"","discussion":[{"comment_id":"1099494","upvote_count":"7","content":"Selected Answer: B\nsys. path is a built-in variable within the sys module. It contains a list of directories that the interpreter will search in for the required module","timestamp":"1702885380.0","poster":"alexvno"},{"poster":"Sriramiyer92","comment_id":"1326015","timestamp":"1734066180.0","upvote_count":"1","content":"Selected Answer: B\nsys.path is a list in Python that contains the directories the interpreter searches for modules when importing them. It is initialized with the default paths when Python starts and can be modified during runtime if needed."},{"upvote_count":"1","timestamp":"1729231740.0","comment_id":"1299560","poster":"benni_ale","content":"Selected Answer: B\nsys.path is a built-in variable within the sys module. It contains a list of directories that the interpreter will search in for the required module."}],"question_images":[],"topic":"1","url":"https://www.examtopics.com/discussions/databricks/view/128880-exam-certified-data-engineer-professional-topic-1-question/","question_text":"Which Python variable contains a list of directories to be searched when trying to locate required modules?","isMC":true,"timestamp":"2023-12-18 08:43:00","answer_ET":"B","choices":{"A":"importlib.resource_path","C":"os.path","E":"pylib.source","B":"sys.path","D":"pypi.path"},"unix_timestamp":1702885380,"exam_id":163,"answer":"B","answer_images":[],"question_id":151,"answers_community":["B (100%)"]},{"id":"TTuKjKEcZbEEOQllsYtW","exam_id":163,"url":"https://www.examtopics.com/discussions/databricks/view/128881-exam-certified-data-engineer-professional-topic-1-question/","answer_ET":"C","question_text":"Incorporating unit tests into a PySpark application requires upfront attention to the design of your jobs, or a potentially significant refactoring of existing code.\nWhich statement describes a main benefit that offset this additional effort?","question_id":152,"answers_community":["C (100%)"],"isMC":true,"answer_images":[],"discussion":[{"upvote_count":"5","poster":"alexvno","timestamp":"1702885620.0","content":"Selected Answer: C\nUnit tests are small, isolated tests that are used to check specific parts of the code, such as functions or classes","comment_id":"1099499"},{"poster":"nedlo","comments":[{"comment_id":"1303258","poster":"nedlo","timestamp":"1729942500.0","upvote_count":"1","content":"i mean E is integration test B is E2E test"}],"content":"Selected Answer: C\nD is integration tests (how they relate to each other how connect), E is E2E test, C is \"testing individually\" which is only one fittign definition of unittest","upvote_count":"2","comment_id":"1303256","timestamp":"1729942440.0"},{"upvote_count":"1","comment_id":"1231034","poster":"jmjm21","content":"Selected Answer: C\nAnswer is C.","timestamp":"1718463840.0"}],"choices":{"E":"Ensures that all steps interact correctly to achieve the desired end result","D":"Yields faster deployment and execution times","B":"Validates a complete use case of your application","C":"Troubleshooting is easier since all steps are isolated and tested individually","A":"Improves the quality of your data"},"answer":"C","answer_description":"","timestamp":"2023-12-18 08:47:00","unix_timestamp":1702885620,"question_images":[],"topic":"1"},{"id":"0pcKzI21PdsGuSJ5JVkM","question_images":[],"topic":"1","isMC":true,"answer_ET":"A","choices":{"D":"Validates an application use case","E":"Validates behavior of individual elements of your application","B":"Requires an automated testing framework","C":"Requires manual intervention","A":"Validates interactions between subsystems of your application"},"answer_description":"","answers_community":["A (100%)"],"question_text":"Which statement describes integration testing?","discussion":[{"comment_id":"1269351","poster":"robodog","timestamp":"1724149920.0","content":"Selected Answer: A\nAnswer is A","upvote_count":"2"},{"timestamp":"1702885800.0","upvote_count":"4","comment_id":"1099503","poster":"alexvno","content":"Selected Answer: A\nIntegration testing is a type of software testing where components of the software are gradually integrated and then tested as a unified group"}],"url":"https://www.examtopics.com/discussions/databricks/view/128882-exam-certified-data-engineer-professional-topic-1-question/","answer_images":[],"unix_timestamp":1702885800,"question_id":153,"answer":"A","timestamp":"2023-12-18 08:50:00","exam_id":163},{"id":"ZlE8i3jg0gHzvdrBWkoq","discussion":[{"poster":"AlejandroU","upvote_count":"1","timestamp":"1734326340.0","content":"Selected Answer: E\nThe correct answer is E. /jobs/list, not C. /jobs/runs/get. Hereâ€™s why:\n/jobs/list: Provides a list of all jobs in the workspace along with their configurations, including task details like the notebooks assigned to each task. This makes it the best choice for reviewing notebooks configured as tasks in a multi-task job.\n/jobs/get: Can also be used if the goal is to review the tasks (and notebooks) of a specific job. However, the question does not limit the scope to a single job.","comment_id":"1327165"},{"timestamp":"1718402640.0","upvote_count":"2","poster":"imatheushenrique","comment_id":"1230681","content":"multi-task: /jobs/get\nsingle-task: /jobs/runs/get"},{"upvote_count":"1","comment_id":"1159661","poster":"hal2401me","content":"Selected Answer: D\nhttps://docs.databricks.com/api/workspace/jobs/get\nresponses/settings/tasks/notebook_task/notebook_path","timestamp":"1708949760.0"},{"poster":"divingbell17","content":"Selected Answer: D\nThe question asks for notebooks configured for a job, not a instance of a job run. D is correct.","upvote_count":"4","comment_id":"1110884","timestamp":"1704066120.0"},{"upvote_count":"1","poster":"alexvno","content":"Selected Answer: D\nGet\nMulti-task format jobs return an array of task data structures containing task settings.","comment_id":"1099508","timestamp":"1702886220.0"},{"content":"Selected Answer: D\n/jobs/get response under task array shows all the desired notebooks","comment_id":"1087777","poster":"hamzaKhribi","upvote_count":"1","timestamp":"1701708120.0"},{"poster":"arye777","comment_id":"1084515","upvote_count":"1","timestamp":"1701359460.0","content":"Selected Answer: B\nshould be B"}],"answer_ET":"D","isMC":true,"question_id":154,"question_images":[],"choices":{"A":"/jobs/runs/list","E":"/jobs/list","B":"/jobs/runs/get-output","C":"/jobs/runs/get","D":"/jobs/get"},"timestamp":"2023-11-30 16:51:00","question_text":"Which REST API call can be used to review the notebooks configured to run as tasks in a multi-task job?","answers_community":["D (78%)","11%","11%"],"exam_id":163,"url":"https://www.examtopics.com/discussions/databricks/view/127546-exam-certified-data-engineer-professional-topic-1-question/","unix_timestamp":1701359460,"answer_description":"","topic":"1","answer_images":[],"answer":"D"},{"id":"iIJr36zuKbUAwtjssoZo","answer_ET":"A","timestamp":"2023-08-24 04:24:00","answer_images":[],"question_images":[],"question_id":155,"topic":"1","question_text":"A Databricks job has been configured with 3 tasks, each of which is a Databricks notebook. Task A does not depend on other tasks. Tasks B and C run in parallel, with each having a serial dependency on task A.\nIf tasks A and B complete successfully but task C fails during a scheduled run, which statement describes the resulting state?","answer":"A","discussion":[{"upvote_count":"9","content":"Should be 'A' only, as ACID compliance is applicable at operation level. For example if task C is having 3 target delta table writes (in independent Notebook cells) then it could have after 1 write the task fails during 2nd write. In that case 1st write will still be persisted. The ACID compliance will be applicable for only the 2nd write.","timestamp":"1695454560.0","poster":"IT3008","comment_id":"1014736"},{"timestamp":"1702886460.0","upvote_count":"5","comment_id":"1099511","content":"Selected Answer: A\nA - for sure this is NOT ACID operations","poster":"alexvno"},{"content":"Selected Answer: A\nhttps://community.databricks.com/t5/data-engineering/does-cancelling-a-job-run-rollback-any-actions-performed-by/td-p/8135","comment_id":"1293863","timestamp":"1728221280.0","poster":"dd1192d","upvote_count":"2"},{"upvote_count":"2","content":"Correct answer should be B as Databricks is ACID compliant","comments":[{"upvote_count":"1","comment_id":"1335319","poster":"arekm","timestamp":"1735776840.0","content":"A single SQL command is ACID compliant, not a whole notebook."},{"content":"What if an operation of C is to delete a file, will the file be created after a roll back?","timestamp":"1693921920.0","comment_id":"999574","poster":"eli91","upvote_count":"2"}],"poster":"tkg13","timestamp":"1692843840.0","comment_id":"988789"}],"unix_timestamp":1692843840,"url":"https://www.examtopics.com/discussions/databricks/view/118942-exam-certified-data-engineer-professional-topic-1-question/","isMC":true,"answer_description":"","exam_id":163,"answers_community":["A (100%)"],"choices":{"B":"All logic expressed in the notebook associated with tasks A and B will have been successfully completed; any changes made in task C will be rolled back due to task failure.","E":"Unless all tasks complete successfully, no changes will be committed to the Lakehouse; because task C failed, all commits will be rolled back automatically.","A":"All logic expressed in the notebook associated with tasks A and B will have been successfully completed; some operations in task C may have completed successfully.","D":"Because all tasks are managed as a dependency graph, no changes will be committed to the Lakehouse until ail tasks have successfully been completed.","C":"All logic expressed in the notebook associated with task A will have been successfully completed; tasks B and C will not commit any changes because of stage failure."}}],"exam":{"numberOfQuestions":200,"isBeta":false,"isMCOnly":true,"name":"Certified Data Engineer Professional","id":163,"isImplemented":true,"provider":"Databricks","lastUpdated":"12 Apr 2025"},"currentPage":31},"__N_SSP":true}