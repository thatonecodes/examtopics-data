{"pageProps":{"questions":[{"id":"rGkP3h3op3fQrXe2VzHm","choices":{"D":"The Delta log is scanned for min and max statistics for the latitude column","A":"All records are cached to an operational database and then the filter is applied","B":"The Parquet file footers are scanned for min and max statistics for the latitude column","C":"The Hive metastore is scanned for min and max statistics for the latitude column"},"topic":"1","unix_timestamp":1733432040,"answer":"D","answers_community":["D (100%)"],"answer_images":[],"question_images":[],"url":"https://www.examtopics.com/discussions/databricks/view/152577-exam-certified-data-engineer-professional-topic-1-question/","question_id":96,"exam_id":163,"answer_ET":"D","timestamp":"2024-12-05 21:54:00","question_text":"A Delta table of weather records is partitioned by date and has the below schema:\n\ndate DATE, device_id INT, temp FLOAT, latitude FLOAT, longitude FLOAT\n\nTo find all the records from within the Arctic Circle, you execute a query with the below filter:\n\nlatitude > 66.3\n\nWhich statement describes how the Delta engine identifies which files to load?","discussion":[{"upvote_count":"2","comment_id":"1323962","poster":"Thameur01","timestamp":"1733737740.0","content":"Selected Answer: D\nAs per the documentation, I understand that the table statistics can be fetched through the delta log (eg min, max, count) in order to not read the underlying data of a delta table. This is the case for numerical types, and timestamp is supposed to be supported."},{"comment_id":"1322523","upvote_count":"2","content":"Selected Answer: D\nDelta Table's log consist statistics for columns","poster":"temple1305","timestamp":"1733432040.0"}],"isMC":true,"answer_description":""},{"id":"B9NUAzbbo6gLHRxTmJHP","answer_ET":"B","question_text":"A junior data engineer has been asked to develop a streaming data pipeline with a grouped aggregation using DataFrame df. The pipeline needs to calculate the average humidity and average temperature for each non-overlapping five-minute interval. Events are recorded once per minute per device.\nStreaming DataFrame df has the following schema:\n\"device_id INT, event_time TIMESTAMP, temp FLOAT, humidity FLOAT\"\nCode block:\n//IMG//\n\nChoose the response that correctly fills in the blank within the code block to complete this task.","answer_images":[],"unix_timestamp":1694086560,"question_id":97,"timestamp":"2023-09-07 13:36:00","discussion":[{"poster":"imatheushenrique","content":"B. window(\"event_time\", \"5 minutes\").alias(\"time\")\nIn Structured Streaming, expressing such windows on event-time is simply performing a special grouping using the window() function. For example, counts over 5 minute tumbling (non-overlapping) windows on the eventTime column in the event is as following.","timestamp":"1733029980.0","upvote_count":"4","comment_id":"1222466"},{"poster":"Jay_98_11","timestamp":"1720887780.0","upvote_count":"2","content":"Selected Answer: B\ncorrect B","comment_id":"1121947"},{"upvote_count":"1","comment_id":"1118608","timestamp":"1720612920.0","content":"Selected Answer: B\nB is correct","poster":"kz_data"},{"upvote_count":"2","comment_id":"1060815","content":"Selected Answer: B\nWindow of 5 mins","timestamp":"1714669080.0","poster":"BIKRAM063"},{"upvote_count":"2","timestamp":"1712821680.0","content":"Selected Answer: B\nB is correct:\nhttps://www.databricks.com/blog/2017/05/08/event-time-aggregation-watermarking-apache-sparks-structured-streaming.html","comment_id":"1040324","poster":"sturcu"},{"comment_id":"1013343","upvote_count":"2","content":"answer is B","poster":"Eertyy","timestamp":"1711053660.0"},{"upvote_count":"4","content":"Selected Answer: B\nCorrect, B.","comment_id":"1001477","poster":"thxsgod","timestamp":"1709818560.0"}],"question_images":["https://img.examtopics.com/certified-data-engineer-professional/image11.png"],"url":"https://www.examtopics.com/discussions/databricks/view/120176-exam-certified-data-engineer-professional-topic-1-question/","answer_description":"","isMC":true,"answer":"B","topic":"1","answers_community":["B (100%)"],"choices":{"E":"lag(\"event_time\", \"10 minutes\").alias(\"time\")","C":"\"event_time\"","B":"window(\"event_time\", \"5 minutes\").alias(\"time\")","A":"to_interval(\"event_time\", \"5 minutes\").alias(\"time\")","D":"window(\"event_time\", \"10 minutes\").alias(\"time\")"},"exam_id":163},{"id":"pKSF1v56p4M4zw9t2dDz","timestamp":"2024-12-05 22:00:00","question_images":["https://img.examtopics.com/certified-data-engineer-professional/image82.png"],"answer_images":[],"question_text":"A junior data engineer has configured a workload that posts the following JSON to the Databricks REST API endpoint 2.0/jobs/create.\n\n//IMG//\n\n\nAssuming that all configurations and referenced resources are available, which statement describes the result of executing this workload three times?","answers_community":["C (100%)"],"question_id":98,"answer_description":"","url":"https://www.examtopics.com/discussions/databricks/view/152579-exam-certified-data-engineer-professional-topic-1-question/","discussion":[{"timestamp":"1733516820.0","content":"Selected Answer: C\nC is the correct answer","comment_id":"1322906","poster":"Ayomidetolu_A","upvote_count":"1"},{"upvote_count":"2","poster":"divyapsingh","comment_id":"1322659","content":"Selected Answer: C\nC is the answer as 3 times call will create three jobs with same name but with different job id.","timestamp":"1733472000.0"},{"timestamp":"1733432400.0","comment_id":"1322525","content":"Selected Answer: C\nC correct, 3 jobs created, no executions","poster":"temple1305","upvote_count":"1"}],"answer":"C","choices":{"A":"The logic defined in the referenced notebook will be executed three times on the referenced existing all purpose cluster.","D":"One new job named \"Ingest new data\" will be defined in the workspace, but it will not be executed.","C":"Three new jobs named \"Ingest new data\" will be defined in the workspace, but no jobs will be executed.","B":"The logic defined in the referenced notebook will be executed three times on new clusters with the configurations of the provided cluster ID."},"answer_ET":"C","isMC":true,"topic":"1","exam_id":163,"unix_timestamp":1733432400},{"id":"u2MMMuckvN64axxtNdMh","url":"https://www.examtopics.com/discussions/databricks/view/152580-exam-certified-data-engineer-professional-topic-1-question/","answer_images":[],"topic":"1","timestamp":"2024-12-05 22:06:00","discussion":[{"content":"Selected Answer: D\nD - with the view it is always at query time. Once it is run, the engine reads the data - meaning the data state is from when the query was run.","poster":"arekm","timestamp":"1735824060.0","upvote_count":"1","comment_id":"1335565"},{"upvote_count":"1","poster":"benni_ale","content":"Selected Answer: D\nView does not write to disk","timestamp":"1733676000.0","comment_id":"1323638"},{"upvote_count":"2","poster":"divyapsingh","timestamp":"1733472180.0","content":"Selected Answer: D\nHere the view is getting created not the table. view is only saver select query which will get data from the valid version of the underlying table at the begining of the select statement made on view.","comment_id":"1322660"},{"content":"Selected Answer: B\nB is correct, view is just query without materialization and return result for moment of execution","poster":"temple1305","timestamp":"1733432760.0","upvote_count":"1","comments":[{"timestamp":"1733772120.0","poster":"carlosmps","upvote_count":"1","content":"but the option B is materialized stored the data on dbfs....","comment_id":"1324188"}],"comment_id":"1322528"}],"answers_community":["D (80%)","B (20%)"],"exam_id":163,"choices":{"A":"The versions of each source table will be stored in the table transaction log; query results will be saved to DBFS with each query.","C":"All logic will execute at query time and return the result of joining the valid versions of the source tables at the time the query finishes.","B":"All logic will execute when the table is defined and store the result of joining tables to the DBFS; this stored data will be returned when the table is queried.","D":"All logic will execute at query time and return the result of joining the valid versions of the source tables at the time the query began."},"unix_timestamp":1733432760,"question_images":["https://img.examtopics.com/certified-data-engineer-professional/image83.png"],"isMC":true,"answer":"D","question_text":"A view is registered with the following code:\n\n//IMG//\n\n\nBoth users and orders are Delta Lake tables.\n\nWhich statement describes the results of querying recent_orders?","question_id":99,"answer_ET":"D","answer_description":""},{"id":"V0ARoNS3VX2DAeGQdG4t","question_id":100,"timestamp":"2024-12-05 22:21:00","unix_timestamp":1733433660,"topic":"1","answer_description":"","answer_images":[],"answer":"D","choices":{"C":"userLookup.join(streamingDF, [\"user_id\"), how=\"inner\")","B":"streamingDF.join(userLookup, [\"user_id\"], how=\"inner\")","A":"userLookup.join(streamingDF, [\"user_id\"], how=\"right\")","D":"userLookup.join(streamingDF, [\"user_id\"], how=\"left\")"},"isMC":true,"question_images":[],"question_text":"A data engineer is performing a join operation to combine values from a static userLookup table with a streaming DataFrame streamingDF.\n\nWhich code block attempts to perform an invalid stream-static join?","url":"https://www.examtopics.com/discussions/databricks/view/152581-exam-certified-data-engineer-professional-topic-1-question/","answers_community":["D (100%)"],"discussion":[{"poster":"temple1305","comments":[{"content":"That is what the documentation says. We take all the records from the stream and join to the static table - left or right shows us where the stream in the join is. Static table-stream - right outer is supported, stream-static table - left outer is supported.","upvote_count":"1","timestamp":"1735824240.0","comment_id":"1335567","poster":"arekm"}],"timestamp":"1733433660.0","comment_id":"1322531","content":"Selected Answer: D\nD correct \nhttps://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#support-matrix-for-joins-in-streaming-queries\nStatic join stream - left join not supported","upvote_count":"6"}],"exam_id":163,"answer_ET":"D"}],"exam":{"provider":"Databricks","isImplemented":true,"name":"Certified Data Engineer Professional","numberOfQuestions":200,"id":163,"isBeta":false,"isMCOnly":true,"lastUpdated":"12 Apr 2025"},"currentPage":20},"__N_SSP":true}