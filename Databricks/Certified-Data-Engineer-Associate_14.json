{"pageProps":{"questions":[{"id":"Irf8QUGT0NLGS3dFBbHC","unix_timestamp":1680442140,"answer":"C","choices":{"A":"DROP","C":"MERGE","D":"APPEND","E":"INSERT","B":"IGNORE"},"timestamp":"2023-04-02 15:29:00","answer_description":"","question_id":66,"exam_id":162,"url":"https://www.examtopics.com/discussions/databricks/view/104863-exam-certified-data-engineer-associate-topic-1-question-16/","question_text":"Which of the following commands can be used to write data into a Delta table while avoiding the writing of duplicate records?","answer_images":[],"discussion":[{"comment_id":"1262402","timestamp":"1723104420.0","poster":"80370eb","upvote_count":"3","content":"Selected Answer: C\nC. MERGE\n\nThe MERGE command allows you to perform upserts (update and insert) into a Delta table, effectively avoiding duplicates by updating existing records and inserting new ones as needed."},{"poster":"BharaniRaj","upvote_count":"1","content":"Selected Answer: C\nC is the right answer","timestamp":"1716015840.0","comment_id":"1213173"},{"upvote_count":"1","poster":"benni_ale","comment_id":"1203174","timestamp":"1714230540.0","content":"Selected Answer: C\nC merge"},{"poster":"SerGrey","comment_id":"1113196","content":"Selected Answer: C\nCorrect answer is C","timestamp":"1704322500.0","upvote_count":"1"},{"content":"Selected Answer: C\nC is correct","poster":"awofalus","timestamp":"1699362240.0","comment_id":"1064802","upvote_count":"1"},{"content":"Selected Answer: C\nMerge is correct","upvote_count":"1","timestamp":"1697705520.0","poster":"J_1_2","comment_id":"1047724"},{"poster":"DavidRou","timestamp":"1696828680.0","comment_id":"1028518","upvote_count":"2","content":"MERGE INTO is the one to choose if you want to avoid duplicates."},{"poster":"chris_mach","comment_id":"1020507","content":"Selected Answer: C\nMerge is correct","upvote_count":"1","timestamp":"1695966840.0"},{"upvote_count":"1","poster":"KalavathiP","content":"Selected Answer: C\nMerge will avoid duplicates by comparing the results based on primary key columns","timestamp":"1695698160.0","comment_id":"1017354"},{"poster":"vctrhugo","upvote_count":"3","timestamp":"1693770360.0","comment_id":"997923","content":"Selected Answer: C\nC. MERGE\n\nThe MERGE command is used to write data into a Delta table while avoiding the writing of duplicate records. It allows you to perform an \"upsert\" operation, which means that it will insert new records and update existing records in the Delta table based on a specified condition. This helps maintain data integrity and avoid duplicates when adding new data to the table."},{"content":"C. MERGE\n\nTo write data into a Delta table while avoiding the writing of duplicate records, you can use the MERGE command. The MERGE command in Delta Lake allows you to combine the ability to insert new records and update existing records in a single atomic operation.\n\nThe MERGE command compares the data being written with the existing data in the Delta table based on specified matching criteria, typically using a primary key or unique identifier. It then performs conditional actions, such as inserting new records or updating existing records, depending on the comparison results.\n\nBy using the MERGE command, you can handle the prevention of duplicate records in a more controlled and efficient manner. It allows you to synchronize and reconcile data from different sources while avoiding duplication and ensuring data integrity.\n\nTherefore, option C, MERGE, is the correct command to use when writing data into a Delta table while avoiding the writing of duplicate records.","comment_id":"946000","poster":"Atnafu","upvote_count":"2","timestamp":"1688763960.0"},{"content":"Answer is C. AS DROP is used to remove a table or database\nIGNORE is used to skip errors while executing a query.\nINSERT will add new records but will not avoid duplication so Merge is right answer","poster":"softthinkers","timestamp":"1683190440.0","upvote_count":"2","comment_id":"889315"},{"upvote_count":"2","poster":"Varma_Saraswathula","comment_id":"876213","timestamp":"1682054220.0","content":"Ans - C\nhttps://docs.databricks.com/sql/language-manual/delta-merge-into.html"},{"poster":"naxacod574","comment_id":"875872","timestamp":"1682014320.0","content":"Option C","upvote_count":"1"},{"comment_id":"861295","comments":[{"content":"'C' is a correct answer. https://docs.databricks.com/sql/language-manual/delta-merge-into.html","poster":"Oleskie","comment_id":"862001","upvote_count":"4","comments":[{"content":"Thanks for the clarification","comment_id":"862187","poster":"XiltroX","upvote_count":"1","timestamp":"1680704700.0"}],"timestamp":"1680691980.0"}],"content":"Selected Answer: D\nWrong answer. The correct answer is D.","poster":"XiltroX","timestamp":"1680625920.0","upvote_count":"1"},{"comments":[{"poster":"knivesz","timestamp":"1680563940.0","upvote_count":"1","content":"Respuesta correcta C\nA) DROP: Elimina registros, B) IGNORE : NO existe C) MERGE: EN base a la data, registra, actualiza o elimina registros, D) NO existe E) Solo inserta","comment_id":"860434"}],"timestamp":"1680442140.0","content":"Selected Answer: C\nla unica opcion posible","upvote_count":"3","poster":"knivesz","comment_id":"858873"}],"answers_community":["C (94%)","6%"],"question_images":[],"answer_ET":"C","topic":"1","isMC":true},{"id":"xi85iH0ejppDMhZGUq77","topic":"1","discussion":[{"comment_id":"1322554","timestamp":"1733438280.0","poster":"Manish_Kum","upvote_count":"2","content":"Selected Answer: B\nB is correct"}],"question_images":[],"timestamp":"2024-12-05 23:38:00","exam_id":162,"answer_description":"","question_text":"A data organization leader is upset about the data analysis team’s reports being different from the data engineering team’s reports. The leader believes the siloed nature of their organization’s data engineering and data analysis architectures is to blame.\n\nWhich of the following describes how a data lakehouse could alleviate this issue?","question_id":67,"choices":{"A":"Both teams would respond more quickly to ad-hoc requests","D":"Both teams would be able to collaborate on projects in real-time","B":"Both teams would use the same source of truth for their work","C":"Both teams would reorganize to report to the same department"},"answers_community":["B (100%)"],"unix_timestamp":1733438280,"answer_ET":"B","url":"https://www.examtopics.com/discussions/databricks/view/152590-exam-certified-data-engineer-associate-topic-1-question-160/","answer":"B","isMC":true,"answer_images":[]},{"id":"JoxonN9nMR9NV4NYHAbp","answer_images":[],"answer":"C","exam_id":162,"answer_description":"","question_id":68,"question_text":"A data analyst has developed a query that runs against Delta table. They want help from the data engineering team to implement a series of tests to ensure the data returned by the query is clean. However, the data engineering team uses Python for its tests rather than SQL.\n\nWhich of the following operations could the data engineering team use to run the query and operate with the results in PySpark?","choices":{"C":"spark.sql","A":"SELECT * FROM sales","B":"spark.delta.table","D":"spark.table"},"answers_community":["C (100%)"],"answer_ET":"C","timestamp":"2024-12-05 23:39:00","url":"https://www.examtopics.com/discussions/databricks/view/152591-exam-certified-data-engineer-associate-topic-1-question-161/","unix_timestamp":1733438340,"question_images":[],"isMC":true,"topic":"1","discussion":[{"poster":"Manish_Kum","timestamp":"1733438340.0","comment_id":"1322555","content":"Selected Answer: C\nC is correct","upvote_count":"1"}]},{"id":"ORcvACP85uckLE1bLbvZ","question_images":[],"exam_id":162,"answer":"D","answers_community":["D (100%)"],"choices":{"A":"pyspark.sql.types.DateType","C":"pyspark.sql.types.TimestampType","D":"Cron syntax","B":"datetime"},"isMC":true,"topic":"1","answer_ET":"D","unix_timestamp":1734361200,"url":"https://www.examtopics.com/discussions/databricks/view/153060-exam-certified-data-engineer-associate-topic-1-question-162/","answer_description":"","answer_images":[],"question_id":69,"question_text":"A data engineer has a Job that has a complex run schedule, and they want to transfer that schedule to other Jobs.\n\nRather than manually selecting each value in the scheduling form in Databricks, which of the following tools can the data engineer use to represent and submit the schedule programmatically?","discussion":[{"poster":"duzi","timestamp":"1735901400.0","content":"Selected Answer: D\nQuestion is repeated. See details on https://learn.microsoft.com/en-us/azure/databricks/jobs/scheduled","comment_id":"1335986","upvote_count":"1"}],"timestamp":"2024-12-16 16:00:00"},{"id":"XyQAuPXru07NhesFdreT","question_text":"A data engineer and data analyst are working together on a data pipeline. The data engineer is working on the raw, bronze, and silver layers of the pipeline using Python, and the data analyst is working on the gold layer of the pipeline using SQL. The raw source of the pipeline is a streaming input. They now want to migrate their pipeline to use Delta Live Tables.\n\nWhich of the following changes will need to be made to the pipeline when migrating to Delta Live Tables?","isMC":true,"answer_images":[],"question_id":70,"discussion":[{"comment_id":"1409787","upvote_count":"1","timestamp":"1742846340.0","content":"Selected Answer: C\nDelta Live Tables (DLT) currently requires SQL or Python for defining data pipelines. However, for streaming data, SQL has become the primary language for defining Delta Live Tables pipelines in Databricks.","poster":"Billybob0604"},{"timestamp":"1741872900.0","upvote_count":"1","comment_id":"1388415","poster":"e872ce8","content":"Selected Answer: A\nA & C. The pipeline will need to be written entirely in Python (if using Python APIs for Delta Live Tables) The pipeline will need to be written entirely in SQL (if using SQL-based Delta Live Tables)Delta Live Tables (DLT) is a declarative ETL framework built on Databricks, designed to simplify pipeline development and management. It supports:\nPython-based pipelines using @dlt.table decorators\nSQL-based pipelines using CREATE LIVE TABLE\nSince the data engineer is using Python and the data analyst is using SQL, the pipeline will need to be rewritten in one of the two supported languages."},{"content":"Selected Answer: D\nNone of these options are currect","comment_id":"1366381","timestamp":"1741382700.0","upvote_count":"2","poster":"Kayceetalks"},{"comments":[{"content":"Sorry None if the options are correct - When migrating to Delta Live Tables, the pipeline does not need to be rewritten entirely in Python or SQL, nor does it need to stop using the medallion-based multi-hop architecture. Additionally, it does not need to switch from a streaming source to a batch source. Delta Live Tables supports both Python and SQL, and it can handle streaming data sources","poster":"MultiCloudIronMan","comment_id":"1329563","upvote_count":"4","timestamp":"1734713220.0"}],"poster":"MultiCloudIronMan","comment_id":"1328533","upvote_count":"2","timestamp":"1734528540.0","content":"Selected Answer: A\nThe correct response is A. None of these changes will need to be made. Delta Live Tables supports both Python and SQL, as well as streaming and batch sources. This means that the existing medallion-based multi-hop architecture can be maintained, and the pipeline can continue to use both Python and SQL for different layers. Therefore, no changes are necessary when migrating to Delta Live Tables."},{"poster":"Manish_Kum","comment_id":"1322557","upvote_count":"3","timestamp":"1733438580.0","content":"Selected Answer: D\nbest choice in this questions is D"}],"unix_timestamp":1733438580,"answers_community":["D (56%)","A (33%)","11%"],"answer_ET":"D","url":"https://www.examtopics.com/discussions/databricks/view/152592-exam-certified-data-engineer-associate-topic-1-question-163/","answer":"D","timestamp":"2024-12-05 23:43:00","exam_id":162,"topic":"1","answer_description":"","choices":{"C":"The pipeline will need to be written entirely in SQL","D":"The pipeline will need to use a batch source in place of a streaming source","A":"The pipeline will need to be written entirely in Python","B":"The pipeline will need to stop using the medallion-based multi-hop architecture"},"question_images":[]}],"exam":{"isMCOnly":true,"isImplemented":true,"lastUpdated":"12 Apr 2025","name":"Certified Data Engineer Associate","id":162,"provider":"Databricks","isBeta":false,"numberOfQuestions":169},"currentPage":14},"__N_SSP":true}