{"pageProps":{"questions":[{"id":"Z1Cid99sZCVRHWF32GIf","choices":{"B":"Push","C":"Pull","D":"Commit","A":"Merge","E":"Clone"},"answer_ET":"C","answer_description":"","url":"https://www.examtopics.com/discussions/databricks/view/124124-exam-certified-data-engineer-associate-topic-1-question-46/","topic":"1","question_images":[],"question_id":111,"isMC":true,"answer_images":[],"exam_id":162,"unix_timestamp":1697809680,"discussion":[{"timestamp":"1730187180.0","poster":"benni_ale","upvote_count":"2","comment_id":"1203815","content":"Selected Answer: C\nC is correct"},{"upvote_count":"1","poster":"[Removed]","comment_id":"1171819","content":"Selected Answer: C\nC is correct","timestamp":"1726150200.0"},{"upvote_count":"1","timestamp":"1714431900.0","content":"Selected Answer: C\nThis is more of a Git question.\n\nFrom the docs:\nIn Databricks Repos, you can use Git functionality to:\n Clone, push to, and pull from a remote Git repository.\n Create and manage branches for development work, including merging, rebasing, and resolving conflicts.\n Create notebooks&mdash;including IPYNB notebooks&mdash;and edit them and other files.\n Visually compare differences upon commit and resolve merge conflicts.\n\nSource: https://docs.databricks.com/en/repos/index.html","poster":"god_father","comment_id":"1057257"},{"comment_id":"1048837","timestamp":"1713620880.0","upvote_count":"2","poster":"kishanu","content":"Selected Answer: C\npull is required from the Databricks Repo to sync the changes b/w local and central repo."}],"question_text":"A data engineer is running code in a Databricks Repo that is cloned from a central Git repository. A colleague of the data engineer informs them that changes have been made and synced to the central Git repository. The data engineer now needs to sync their Databricks Repo to get the changes from the central Git repository.\n\nWhich of the following Git operations does the data engineer need to run to accomplish this task?","timestamp":"2023-10-20 15:48:00","answer":"C","answers_community":["C (100%)"]},{"id":"Ah1zfPeZa0h58h56PNy2","choices":{"A":"Cloud-specific integrations","C":"Ability to scale storage","B":"Simplified governance","D":"Ability to scale workloads","E":"Avoiding vendor lock-in"},"answer_ET":"E","answer_description":"","topic":"1","url":"https://www.examtopics.com/discussions/databricks/view/124066-exam-certified-data-engineer-associate-topic-1-question-47/","question_id":112,"question_images":[],"isMC":true,"answer_images":[],"exam_id":162,"discussion":[{"content":"Selected Answer: E\nBy embracing open-source technologies, the platform allows users to avoid being locked into a single vendor's ecosystem, offering flexibility and the ability to integrate with a wide range of tools and systems.","comment_id":"1263461","timestamp":"1723292760.0","poster":"80370eb","upvote_count":"2"},{"comment_id":"1203816","upvote_count":"1","poster":"benni_ale","timestamp":"1714368780.0","content":"Selected Answer: E\nE is correct"},{"poster":"UGOTCOOKIES","timestamp":"1706229720.0","comment_id":"1132177","upvote_count":"4","content":"Selected Answer: E\nE is correct as open-source is opposite of proprietary technology, so not being a proprietary means it is free of vendor lock in, if that makes sense."},{"upvote_count":"3","poster":"meow_akk","timestamp":"1697995440.0","comment_id":"1050925","content":"its avoiding vendor lock in : - https://double.cloud/blog/posts/2023/01/break-free-from-vendor-lock-in-with-open-source-tech/"},{"content":"Selected Answer: E\nE looks to be the correct one, as Databricks Lakeshouse platform supports Delta table which is an open-source format for storage.","poster":"kishanu","comment_id":"1048839","timestamp":"1697809860.0","upvote_count":"2"},{"comment_id":"1048187","content":"D is the correct answer","poster":"Rs1997","timestamp":"1697740560.0","upvote_count":"1"}],"unix_timestamp":1697740560,"question_text":"Which of the following is a benefit of the Databricks Lakehouse Platform embracing open source technologies?","answer":"E","timestamp":"2023-10-19 20:36:00","answers_community":["E (100%)"]},{"id":"FxlvXTITPDF3W5vgPALk","answer":"E","timestamp":"2023-10-22 19:23:00","answer_description":"","discussion":[{"timestamp":"1723292880.0","upvote_count":"2","comment_id":"1263462","content":"Selected Answer: E\nData Explorer in Databricks allows users to view and manage permissions for tables, schemas, and databases.","poster":"80370eb"},{"content":"Selected Answer: E\nE is correct","comment_id":"1203817","upvote_count":"1","poster":"benni_ale","timestamp":"1714368840.0"},{"timestamp":"1701892200.0","poster":"kz_data","comment_id":"1089721","upvote_count":"4","content":"Selected Answer: E\nE is correct answer"},{"timestamp":"1697995380.0","poster":"meow_akk","content":"E is correct Data explorer","comment_id":"1050924","upvote_count":"2"}],"answers_community":["E (100%)"],"answer_images":[],"isMC":true,"question_images":[],"question_text":"A data engineer needs to use a Delta table as part of a data pipeline, but they do not know if they have the appropriate permissions.\n\nIn which of the following locations can the data engineer review their permissions on the table?","unix_timestamp":1697995380,"answer_ET":"E","url":"https://www.examtopics.com/discussions/databricks/view/124368-exam-certified-data-engineer-associate-topic-1-question-48/","exam_id":162,"topic":"1","question_id":113,"choices":{"B":"Jobs","E":"Data Explorer","A":"Databricks Filesystem","C":"Dashboards","D":"Repos"}},{"id":"uY79pTpvuKhv9hGPxo0d","answer_ET":"A","timestamp":"2023-10-20 15:55:00","discussion":[{"upvote_count":"5","poster":"kishanu","content":"Selected Answer: A\nSingle node clusters can be used for interactive queries with small dataset","timestamp":"1713621300.0","comment_id":"1048841"},{"comment_id":"1203819","content":"Selected Answer: A\nA is correct","upvote_count":"1","timestamp":"1730187300.0","poster":"benni_ale"},{"upvote_count":"2","poster":"azure_bimonster","timestamp":"1721484420.0","content":"Selected Answer: A\nA seems correct for this","comment_id":"1127370"},{"content":"ans A : A Single Node cluster is a cluster consisting of an Apache Spark driver and no Spark workers. A Single Node cluster supports Spark jobs and all Spark data sources, including Delta Lake. A Standard cluster requires a minimum of one Spark worker to run Spark jobs.\nhttps://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwidg8mSsYqCAxUmg2oFHbkTDJsQFnoECA4QAw&url=https%3A%2F%2Fdocs.databricks.com%2Fen%2Fclusters%2Fsingle-node.html%23%3A~%3Atext%3DA%2520Single%2520Node%2520cluster%2520is%2Cworker%2520to%2520run%2520Spark%2520jobs.&usg=AOvVaw3PFq3_Qyt2gAAa4id0j6CS&opi=89978449","upvote_count":"4","comment_id":"1050929","poster":"meow_akk","timestamp":"1713806760.0"}],"answer":"A","answers_community":["A (100%)"],"exam_id":162,"question_text":"Which of the following describes a scenario in which a data engineer will want to use a single-node cluster?","choices":{"C":"When they are working with SQL within Databricks SQL","B":"When they are running automated reports to be refreshed as quickly as possible","A":"When they are working interactively with a small amount of data","E":"When they are manually running reports with a large amount of data","D":"When they are concerned about the ability to automatically scale with larger data"},"unix_timestamp":1697810100,"question_id":114,"answer_description":"","topic":"1","answer_images":[],"question_images":[],"isMC":true,"url":"https://www.examtopics.com/discussions/databricks/view/124125-exam-certified-data-engineer-associate-topic-1-question-49/"},{"id":"Lixh8bolLLxEXIYBiSV4","answer_images":[],"answers_community":["C (100%)"],"topic":"1","question_text":"Which of the following describes the storage organization of a Delta table?","choices":{"E":"Delta tables are stored in a single file that contains only the data stored within the table.","A":"Delta tables are stored in a single file that contains data, history, metadata, and other attributes.","B":"Delta tables store their data in a single file and all metadata in a collection of files in a separate location.","C":"Delta tables are stored in a collection of files that contain data, history, metadata, and other attributes.","D":"Delta tables are stored in a collection of files that contain only the data stored within the table."},"isMC":true,"answer_description":"","answer_ET":"C","timestamp":"2023-04-01 15:37:00","answer":"C","question_images":[],"unix_timestamp":1680356220,"url":"https://www.examtopics.com/discussions/databricks/view/104735-exam-certified-data-engineer-associate-topic-1-question-5/","question_id":115,"discussion":[{"timestamp":"1736553300.0","content":"Selected Answer: C\nDelta tables store data in a structured manner using Parquet files, and they also maintain metadata and transaction logs in separate directories. This organization allows for versioning, transactional capabilities, and metadata tracking in Delta Lake. Thank you for pointing out the error, and I appreciate your understanding.","comment_id":"1339009","upvote_count":"2","poster":"Tedet"},{"content":"Selected Answer: C\nDelta tables use a distributed storage format, where data, history, metadata, and other attributes are stored across multiple files. This includes data files (e.g., Parquet files) for the actual data and log files for transaction history and metadata, allowing Delta Lake to support version control, schema enforcement, and ACID properties.","upvote_count":"2","poster":"806e7d2","comment_id":"1312099","timestamp":"1731597600.0"},{"content":"Selected Answer: C\nC. Delta tables are stored in a collection of files that contain data, history, metadata, and other attributes.\n\nDelta tables store data in a structured manner using Parquet files, and they also maintain metadata and transaction logs in separate directories. This organization allows for versioning, transactional capabilities, and metadata tracking in Delta Lake. Thank you for pointing out the error, and I appreciate your understanding.","timestamp":"1727170140.0","upvote_count":"3","poster":"vctrhugo","comment_id":"997863"},{"timestamp":"1723102680.0","poster":"80370eb","comment_id":"1262386","content":"Selected Answer: C\nC. Delta tables are stored in a collection of files that contain data, history, metadata, and other attributes.","upvote_count":"1"},{"content":"Selected Answer: C\nThe answer is C!","poster":"mascarenhaslucas","timestamp":"1717965840.0","upvote_count":"1","comment_id":"1227524"},{"content":"Selected Answer: C\nGPT4: \nDelta tables in Databricks use: \nParquet format files for data storage. \nA _delta_log folder for JSON log files that track transactions. \nScheme enforcement in metadata to ensure consistency.\n Checkpoint files to speed up the rebuilding of the table state.","poster":"benni_ale","upvote_count":"4","comment_id":"1188491","timestamp":"1712123760.0"},{"comment_id":"1177168","timestamp":"1710840780.0","content":"Selected Answer: C\nC is correct","upvote_count":"1","poster":"Itmma"},{"poster":"SerGrey","comment_id":"1104699","upvote_count":"1","timestamp":"1703432160.0","content":"Selected Answer: C\nC is correct"},{"content":"Answer is C","upvote_count":"1","timestamp":"1696848540.0","comment_id":"1028759","poster":"VijayKula"},{"poster":"Sriramiyer92","timestamp":"1696175880.0","upvote_count":"2","comment_id":"1022440","content":"Reading Material:\n5 reasons to choose Delta format (on Databricks)\nhttps://medium.com/datalex/5-reasons-to-use-delta-lake-format-on-databricks-d9e76cf3e77d"},{"timestamp":"1695697800.0","poster":"KalavathiP","upvote_count":"1","comment_id":"1017340","content":"Selected Answer: C\nCorrect ans C"},{"timestamp":"1692163800.0","upvote_count":"2","content":"Selected Answer: C\nC is the right answer","poster":"andie123","comment_id":"982210"},{"timestamp":"1688853060.0","upvote_count":"2","comment_id":"946757","content":"C\nDelta tables in Databricks Delta Lake are stored in a collection of files organized in a directory structure. This directory structure includes data files, transaction log files, and metadata files. These files are stored in a specified location, typically in a distributed file system such as Hadoop Distributed File System (HDFS) or Amazon S3.","poster":"Atnafu"},{"content":"First selected D as I assumed the data to be stored in the Delta lake and the transaction log to be stored separately. However, documentation states when a user creates a Delta Lake table, that table’s transaction log is automatically created in the _delta_log subdirectory. The deltalog contains multiple files hence a collection of files. Answer C.","comment_id":"895823","timestamp":"1683886680.0","upvote_count":"3","poster":"prasioso"},{"upvote_count":"3","comment_id":"863842","content":"Selected Answer: C\nC is the right option","timestamp":"1680869880.0","poster":"Data_4ever"},{"content":"Selected Answer: C\nC , respuesta correcta","comment_id":"860308","upvote_count":"1","poster":"knivesz","timestamp":"1680552060.0"},{"comment_id":"857958","timestamp":"1680356220.0","content":"C is correct answer\nhttps://docs.delta.io/latest/delta-faq.html#:~:text=Delta%20Lake%20uses%20versioned%20Parquet,directory%20to%20provide%20ACID%20transactions.","upvote_count":"2","poster":"XiltroX"}],"exam_id":162}],"exam":{"isMCOnly":true,"id":162,"isBeta":false,"provider":"Databricks","lastUpdated":"12 Apr 2025","numberOfQuestions":169,"name":"Certified Data Engineer Associate","isImplemented":true},"currentPage":23},"__N_SSP":true}