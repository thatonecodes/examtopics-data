{"pageProps":{"questions":[{"id":"1Xo7yPAfSWW1XuAUrgYk","unix_timestamp":1699553520,"url":"https://www.examtopics.com/discussions/databricks/view/125679-exam-certified-associate-developer-for-apache-spark-topic-1/","question_images":[],"discussion":[{"content":"The correct method to perform a position-wise union (i.e., a union by name) between two DataFrames in PySpark is `unionByName`. The correct answer is the one that does not perform a position-wise union. \n\nThe code block that contains an error is:\n\n**A. concat(storesDF, acquiredStoresDF)**\n\nThe `concat` function does not exist in PySpark for DataFrame operations. Instead, you should use `union` or `unionByName`.","timestamp":"1723111020.0","poster":"65bd33e","comment_id":"1262436","upvote_count":"1"},{"comment_id":"1189325","content":"Selected Answer: E\nE is the right choice.","timestamp":"1712234820.0","poster":"SaiPavan10","upvote_count":"1"},{"timestamp":"1699553520.0","comment_id":"1066594","poster":"newusername","content":"could you please fix the question? It is missing part of it. Though the answer is correct","upvote_count":"3"}],"answer":"E","answers_community":["E (100%)"],"topic":"1","question_id":16,"isMC":true,"answer_ET":"E","answer_description":"","exam_id":161,"choices":{"A":"concat(storesDF, acquiredStoresDF)","E":"storesDF.union(acquiredStoresDF)","C":"union(storesDF, acquiredStoresDF)","B":"storesDF.unionByName(acquiredStoresDF)","D":"unionAll(storesDF, acquiredStoresDF)"},"answer_images":[],"timestamp":"2023-11-09 19:12:00","question_text":"The code block shown below contains an error. The code block is intended to return a new DataFrame that is the result of a position-wise union between DataFrame storesDF and DataFrame acquiredStoresDF."},{"id":"KUUlF82lEMkBbiBknEii","answers_community":["C (100%)"],"unix_timestamp":1712059200,"discussion":[{"timestamp":"1728046020.0","poster":"SaiPavan10","comment_id":"1189326","content":"Selected Answer: C\nit is C","upvote_count":"1"},{"upvote_count":"1","poster":"Sowwy1","comment_id":"1188009","content":"It's c","timestamp":"1727870400.0"}],"choices":{"B":"storesDF.write().mode(“overwrite”).parquet(filePath)","A":"storesDF.write(filePath, mode = “overwrite”)","D":"storesDF.write.option(“parquet”, “overwrite”).path(filePath)","E":"storesDF.write.mode(“overwrite”).path(filePath)","C":"storesDF.write.mode(“overwrite”).parquet(filePath)"},"answer":"C","answer_images":[],"topic":"1","question_id":17,"answer_ET":"C","url":"https://www.examtopics.com/discussions/databricks/view/137753-exam-certified-associate-developer-for-apache-spark-topic-1/","answer_description":"","timestamp":"2024-04-02 14:00:00","question_images":[],"isMC":true,"exam_id":161,"question_text":"Which of the following code blocks writes DataFrame storesDF to file path filePath as parquet overwriting any existing files in that location?"},{"id":"K5Ij5cwxdfjGCSxREFXi","timestamp":"2024-04-02 14:01:00","discussion":[{"content":"Selected Answer: C\nC is the right choice","timestamp":"1728046080.0","upvote_count":"1","poster":"SaiPavan10","comment_id":"1189327"},{"content":"It's C","timestamp":"1727870460.0","upvote_count":"1","poster":"Sowwy1","comment_id":"1188010"}],"question_id":18,"question_text":"Which of the following code blocks reads a CSV at the file path filePath into a Data Frame with the specified schema schema?","exam_id":161,"url":"https://www.examtopics.com/discussions/databricks/view/137754-exam-certified-associate-developer-for-apache-spark-topic-1/","answers_community":["C (100%)"],"answer_ET":"C","question_images":[],"choices":{"E":"spark.read().schema(schema).csv(filePath)","C":"spark.read.schema(schema).csv(filePath)","A":"spark.read().csv(filePath)","D":"spark.read.schema(“schema”).csv(filePath)","B":"spark.read().schema(“schema”).csv(filePath)"},"isMC":true,"answer_images":[],"answer_description":"","unix_timestamp":1712059260,"topic":"1","answer":"C"},{"id":"j00U6FGwQRyUBjf87dam","topic":"1","choices":{"A":"storesDF.filter(col(\"sqft\") <= 25000 and col(\"customerSatisfaction\") >= 30)","E":"storesDF.filter(sqft <= 25000) & customerSatisfaction >= 30)","C":"storesDF.filter(sqft) <= 25000 and customerSatisfaction >= 30)","B":"storesDF.filter(col(\"sqft\") <= 25000 or col(\"customerSatisfaction\") >= 30)","D":"storesDF.filter(col(\"sqft\") <= 25000 & col(\"customerSatisfaction\") >= 30)"},"exam_id":161,"timestamp":"2023-08-07 21:45:00","question_text":"Which of the following code blocks returns a DataFrame containing only the rows from DataFrame storesDF where the value in column sqft is less than or equal to 25,000 AND the value in column customerSatisfaction is greater than or equal to 30?","question_images":[],"url":"https://www.examtopics.com/discussions/databricks/view/117553-exam-certified-associate-developer-for-apache-spark-topic-1/","answer":"D","isMC":true,"answer_images":[],"discussion":[{"poster":"gaco","content":"in pyspark, all wrong as the conditions inside the filter should be wrapped inside parentesis. should be: D. storesDF.filter((col(\"sqft\") <= 25000) & (col(\"customerSatisfaction\") >= 30))","comment_id":"1271351","upvote_count":"5","timestamp":"1724429340.0"},{"upvote_count":"1","poster":"PushpakKothekar","timestamp":"1744127340.0","content":"Selected Answer: D\nFor dataframe we cannot AND, OR. This applicable for only spark.sql.\nhence correct answer is D.","comment_id":"1558983"},{"upvote_count":"2","content":"Selected Answer: D\n& is used as \"and\" in pyspark.","comment_id":"1346337","poster":"Souvik_79","timestamp":"1737783120.0"},{"timestamp":"1725364320.0","upvote_count":"2","poster":"Jgo1986","comment_id":"1277538","content":"The most similar is D, And and OR are not valid statements for filtering in pySpark"},{"content":"Selected Answer: D\nD is the answer","comment_id":"1266731","upvote_count":"1","poster":"65bd33e","timestamp":"1723763400.0"},{"poster":"deadbeef38","timestamp":"1719152040.0","upvote_count":"1","content":"Selected Answer: A\nA is right","comments":[{"timestamp":"1725364380.0","poster":"Jgo1986","content":"no its not, ...","comment_id":"1277539","upvote_count":"1"}],"comment_id":"1235844"},{"content":"It's D:\nhttps://sparkbyexamples.com/spark/spark-and-or-not-operators/\n\nPySpark Logical operations use the bitwise operators:\n\n& for and\n| for or\n~ for not","comment_id":"1188016","poster":"Sowwy1","upvote_count":"2","timestamp":"1712059500.0"},{"comment_id":"1079327","poster":"sionita","upvote_count":"1","content":"The answer should be E. In case of multiple conditions spark requires () such as:\ndf.filter( (cond1) & (cond2) )","timestamp":"1700836260.0"},{"upvote_count":"1","comment_id":"974942","timestamp":"1691437500.0","content":"Selected Answer: A\nA is the right answer.","comments":[{"content":"No, you do not use and but & in Pyspark \nD is correct","timestamp":"1699554240.0","poster":"newusername","upvote_count":"2","comment_id":"1066613"}],"poster":"MSH_6"}],"answers_community":["D (67%)","A (33%)"],"answer_ET":"D","question_id":19,"unix_timestamp":1691437500,"answer_description":""},{"id":"FH2f5Ok3x1WTQ9ljsDxO","question_text":"Which of the following sets of DataFrame methods will both return a new DataFrame only containing rows that meet a specified logical condition?","topic":"1","unix_timestamp":1712059680,"discussion":[{"upvote_count":"1","content":"Selected Answer: C\nC is the right choice","poster":"SaiPavan10","comment_id":"1189330","timestamp":"1728046260.0"},{"poster":"Sowwy1","upvote_count":"1","timestamp":"1727870880.0","content":"C is correct","comment_id":"1188019"}],"isMC":true,"answer":"C","choices":{"E":"filter(), drop()","D":"select(), where()","A":"drop(), where()","B":"filter(), select()","C":"filter(), where()"},"question_images":[],"timestamp":"2024-04-02 14:08:00","answer_ET":"C","answers_community":["C (100%)"],"url":"https://www.examtopics.com/discussions/databricks/view/137757-exam-certified-associate-developer-for-apache-spark-topic-1/","question_id":20,"exam_id":161,"answer_description":"","answer_images":[]}],"exam":{"isBeta":false,"provider":"Databricks","name":"Certified Associate Developer for Apache Spark","numberOfQuestions":185,"isMCOnly":true,"id":161,"isImplemented":true,"lastUpdated":"12 Apr 2025"},"currentPage":4},"__N_SSP":true}