{"pageProps":{"questions":[{"id":"zKEJBf3SPKfbegpva965","question_text":"A data engineer has been using a Databricks SQL dashboard to monitor the cleanliness of the input data to an ELT job. The ELT job has its Databricks SQL query that returns the number of input records containing unexpected NULL values. The data engineer wants their entire team to be notified via a messaging webhook whenever this value reaches 100.\nWhich of the following approaches can the data engineer use to notify their entire team via a messaging webhook whenever the number of NULL values reaches 100?","discussion":[{"upvote_count":"5","poster":"XiltroX","content":"Selected Answer: C\nCorrect answer.","comment_id":"859170","timestamp":"1696267620.0"},{"upvote_count":"4","content":"Selected Answer: C\nhttps://docs.databricks.com/en/lakehouse-monitoring/monitor-alerts.html \n\nMonitor alerts are created and used the same way as other Databricks SQL alerts. You create a Databricks SQL query on the monitor profile metrics table or drift metrics table. You then create a Databricks SQL alert for this query. You can configure the alert to evaluate the query at a desired frequency, and send a notification if the alert is triggered. By default, email notification is sent. You can also set up a webhook or send notifications to other applications such as Slack or Pagerduty.","poster":"AndreFR","timestamp":"1718842140.0","comment_id":"1101133"},{"content":"Selected Answer: C\nC is correct","upvote_count":"1","poster":"awofalus","comment_id":"1065508","timestamp":"1715154660.0"},{"comment_id":"998013","timestamp":"1709512980.0","upvote_count":"2","poster":"vctrhugo","content":"Selected Answer: C\nC. They can set up an Alert with a new webhook alert destination.\n\nTo notify their entire team via a messaging webhook whenever the number of NULL values reaches 100, the data engineer can set up an Alert in Databricks with a new webhook alert destination. This allows them to configure the alert to trigger when the specified condition (reaching 100 NULL values) is met, and the notification can be sent to the team's messaging webhook.\n\nOption C provides the specific approach to achieve the desired outcome of notifying the team via a messaging webhook when the condition is met."},{"upvote_count":"3","comment_id":"946571","content":"C\nAlerts allow you to be notified when something goes wrong in your Databricks environment. You can set up alerts to be notified by email, webhook, or Slack.\nWebhooks are a way to send data from one application to another. You can use a webhook to send data from Databricks to a messaging service, such as Slack or PagerDuty.\nOne-time notifications allow you to be notified only once when an alert is triggered. This is useful if you only want to be notified about a specific event.\nCustom templates allow you to customize the email or webhook notification that is sent when an alert is triggered. This is useful if you want to include additional information in the notification, such as the name of the alert or the value of the metric that triggered the alert.","poster":"Atnafu","timestamp":"1704733020.0"},{"comment_id":"862024","upvote_count":"4","poster":"4be8126","content":"Selected Answer: C\nThe approach the data engineer can use to notify their entire team via a messaging webhook whenever the number of NULL values reaches 100 is:\n\nC. They can set up an Alert with a new webhook alert destination.\n\nExplanation:\nTo achieve this, the data engineer can set up an Alert in the Databricks workspace that triggers when the query results exceed the threshold of 100 NULL values. They can create a new webhook alert destination in the Alert's configuration settings and provide the necessary messaging webhook URL to receive notifications. When the Alert is triggered, it will send a message to the configured webhook URL, which will then notify the entire team of the issue.","timestamp":"1696504740.0"}],"question_images":[],"answer_ET":"C","exam_id":162,"answer":"C","timestamp":"2023-04-02 19:27:00","question_id":106,"url":"https://www.examtopics.com/discussions/databricks/view/104900-exam-certified-data-engineer-associate-topic-1-question-41/","answers_community":["C (100%)"],"isMC":true,"answer_images":[],"answer_description":"","topic":"1","choices":{"A":"They can set up an Alert with a custom template.","D":"They can set up an Alert with one-time notifications.","B":"They can set up an Alert with a new email alert destination.","E":"They can set up an Alert without notifications.","C":"They can set up an Alert with a new webhook alert destination."},"unix_timestamp":1680456420},{"id":"Gpwu8viZOW1db0IhgJzh","url":"https://www.examtopics.com/discussions/databricks/view/105272-exam-certified-data-engineer-associate-topic-1-question-42/","exam_id":162,"answers_community":["C (88%)","13%"],"timestamp":"2023-04-05 13:22:00","answer_images":[],"question_id":107,"question_images":[],"isMC":true,"answer_ET":"C","answer":"C","question_text":"A single Job runs two notebooks as two separate tasks. A data engineer has noticed that one of the notebooks is running slowly in the Job’s current run. The data engineer asks a tech lead for help in identifying why this might be the case.\nWhich of the following approaches can the tech lead use to identify why the notebook is running slowly as part of the Job?","answer_description":"","topic":"1","choices":{"D":"There is no way to determine why a Job task is running slowly.","C":"They can navigate to the Runs tab in the Jobs UI and click on the active run to review the processing notebook.","B":"They can navigate to the Tasks tab in the Jobs UI and click on the active run to review the processing notebook.","A":"They can navigate to the Runs tab in the Jobs UI to immediately review the processing notebook.","E":"They can navigate to the Tasks tab in the Jobs UI to immediately review the processing notebook."},"discussion":[{"timestamp":"1740067080.0","upvote_count":"1","comment_id":"1359334","content":"Selected Answer: C\nC correct","poster":"e872ce8"},{"poster":"806e7d2","content":"Selected Answer: C\nIn Databricks, Jobs allow users to monitor the performance of tasks and troubleshoot issues with specific runs. When a notebook is running slowly as part of a Job, the tech lead can use the Runs tab in the Jobs UI to examine the task's performance.\n\nRuns tab in the Jobs UI: This tab shows a list of all runs associated with the Job. The tech lead can identify the specific run where the notebook is performing poorly and click on that run to access detailed information about its performance.\n\nOnce the tech lead selects the active run, they can inspect the logs, metrics, and other performance details associated with that task, which will help them identify the cause of the slowdown, such as resource contention, inefficient code, or insufficient compute.","upvote_count":"1","comment_id":"1314222","timestamp":"1731963780.0"},{"content":"Selected Answer: C\nc is correct","comment_id":"1203810","poster":"benni_ale","timestamp":"1714367280.0","upvote_count":"1"},{"content":"Selected Answer: C\nThe tech lead can navigate to the Runs tab in the Jobs UI and click on the active run to review the processing notebook (Option C). This will allow them to inspect the details of the job run, including the duration of each task, which can help identify potential performance issues.\n\nThere could be several reasons why a notebook is running slowly as part of a job. For instance, there might be a delay when the job cluster has to be spun up, or the table gets delta cached in memory and copies of files will be stored on local node’s storage. Even certain operations like pandas UDFs can be slow.\n\nPlease note that the exact process may vary depending on the specific configurations and permissions set up in your workspace. It’s always a good idea to consult with your organization’s IT or data governance team to ensure the correct procedures are followed.","timestamp":"1703914380.0","poster":"Garyn","upvote_count":"2","comment_id":"1109428"},{"upvote_count":"1","comment_id":"1108712","timestamp":"1703856360.0","poster":"csd","content":"C is correct answer as we monitor job and performance of task in same way in my current project .\nTask tab to add another task or edit existing one"},{"upvote_count":"1","comment_id":"1065537","poster":"awofalus","timestamp":"1699439100.0","content":"Selected Answer: C\nC is correct."},{"poster":"AndreFR","timestamp":"1692491460.0","comment_id":"985486","content":"Selected Answer: C\nThe job run details page contains job output and links to logs, including information about the success or failure of each task in the job run. You can access job run details from the Runs tab for the job. To view job run details from the Runs tab, click the link for the run in the Start time column in the runs list view. To return to the Runs tab for the job, click the Job ID value.\n\nIf the job contains multiple tasks, click a task to view task run details, including:\n\nthe cluster that ran the task\n\nthe Spark UI for the task\n\nlogs for the task\n\nmetrics for the task\n\nhttps://docs.databricks.com/en/workflows/jobs/monitor-job-runs.html#job-run-details","upvote_count":"4"},{"timestamp":"1688829480.0","poster":"Atnafu","comment_id":"946586","content":"C\nIn the Databricks Jobs UI, the Runs tab provides detailed information about the execution of each run in a Job. By clicking on the active run associated with the notebook running slowly, you can access the specific run details, including the notebook execution logs, execution duration, resource utilization, and any error messages or warnings.","upvote_count":"3"},{"content":"Selected Answer: C\n\"Job runs\" tab","poster":"Tickxit","timestamp":"1682591040.0","comment_id":"882507","upvote_count":"2"},{"comment_id":"862224","upvote_count":"2","poster":"XiltroX","content":"Selected Answer: C\nC is the correct answer. See link\nhttps://docs.databricks.com/workflows/jobs/jobs.html","timestamp":"1680707520.0"},{"comments":[],"comment_id":"862029","content":"Selected Answer: B\nB. They can navigate to the Tasks tab in the Jobs UI and click on the active run to review the processing notebook.\n\nThe Tasks tab in the Jobs UI provides detailed information about each task in the job, including the task's execution time, the task's logs, and the task's output. By clicking on the active run for the notebook that is running slowly, the tech lead can review the task's logs and output to identify any issues that might be causing the slowdown. The Runs tab provides an overview of all runs of the job, but it does not provide detailed information about each task in the job.","poster":"4be8126","timestamp":"1680693720.0","upvote_count":"2"}],"unix_timestamp":1680693720},{"id":"k0voGShsIvHWLCG5Elk4","answer_images":[],"unix_timestamp":1680456720,"url":"https://www.examtopics.com/discussions/databricks/view/104901-exam-certified-data-engineer-associate-topic-1-question-43/","topic":"1","question_id":108,"answers_community":["D (92%)","8%"],"exam_id":162,"timestamp":"2023-04-02 19:32:00","isMC":true,"question_images":[],"discussion":[{"poster":"Atnafu","upvote_count":"8","timestamp":"1688829660.0","comment_id":"946588","content":"D\nCluster pools are a way to pre-provision clusters that are ready to use. This can reduce the start up time for clusters, as they do not have to be created from scratch.\nAll-purpose clusters are not pre-provisioned, so they will take longer to start up.\nJobs clusters are a type of cluster pool, but they are not the best option for this use case. Jobs clusters are designed for long-running jobs, and they can be more expensive than other types of cluster pools.\nSingle-node clusters are the smallest type of cluster, and they will start up the fastest. However, they may not be powerful enough to run the Job's tasks.\nAutoscaling clusters can scale up or down based on demand. This can help to improve the start up time for clusters, as they will only be created when they are needed. However, autoscaling clusters can also be more expensive than other types of cluster pool"},{"comment_id":"1314225","timestamp":"1731963960.0","poster":"806e7d2","content":"Selected Answer: D\nUsing cluster pools can significantly improve the start-up time of clusters in Databricks. Here's why:\n\nCluster Pools: Cluster pools are a feature in Databricks that allow clusters to share a pool of pre-warmed, idle virtual machines (VMs). When a new cluster is created, instead of starting a new VM from scratch, it can quickly acquire a pre-warmed instance from the pool. This leads to faster cluster startup times, which is especially helpful for jobs with multiple tasks that are running nightly.","upvote_count":"1"},{"poster":"80370eb","comment_id":"1262779","timestamp":"1723182120.0","upvote_count":"1","content":"Selected Answer: D\nCluster pools help to reduce cluster startup times by maintaining a pool of pre-warmed clusters that can be quickly allocated when needed. This minimizes the overhead associated with starting a new cluster from scratch, thus improving the efficiency and speed of running tasks in the Job."},{"comment_id":"1203812","timestamp":"1714367400.0","poster":"benni_ale","upvote_count":"1","content":"Selected Answer: D\nto be fair B might seem correct but D is more appropriate for reducing start up times"},{"content":"Selected Answer: D\nD. They can use clusters that are from a cluster pool.\n\nExplanation:\n\nCluster Pools: Cluster pools in Databricks allow for the pre-creation and management of clusters in a pool that are readily available for use. With cluster pools, clusters are pre-initialized and kept in a ready state, minimizing the startup time when tasks need to run. This reduces the overhead of cluster initialization as the clusters are already provisioned and waiting for the tasks to be assigned.\n\nUsing clusters from a pool ensures that there is no wait time for cluster initialization when the tasks start running in the nightly Job. This approach significantly reduces the time taken for clusters to start, thereby improving the overall performance and efficiency of the tasks by minimizing the overhead of cluster startup delays.","comment_id":"1109433","timestamp":"1703914620.0","upvote_count":"3","poster":"Garyn"},{"timestamp":"1698857400.0","upvote_count":"3","content":"Selected Answer: D\nThey must use clusters from a pool if they want to reduce the startup time.","comment_id":"1059918","poster":"DavidRou"},{"comment_id":"998015","upvote_count":"3","content":"Selected Answer: D\nD. They can use clusters that are from a cluster pool.\n\nTo improve startup time for the clusters used for the Job, the data engineer can configure the clusters to be sourced from a cluster pool. Cluster pools are pre-allocated clusters that are kept in a running state, ready for use. This eliminates the need to start new clusters from scratch each time a Job runs, significantly reducing startup times.\n\nCluster pools are designed to optimize cluster reuse, making them an efficient choice for recurring jobs like the one described in the scenario.\n\nOption D provides a practical solution to address the slow cluster startup time issue.","poster":"vctrhugo","timestamp":"1693781100.0"},{"upvote_count":"3","content":"Selected Answer: D\nYou can minimize instance acquisition time by creating a pool for each instance type and Databricks runtime your organization commonly uses. \n\nSOURCE : https://docs.databricks.com/en/clusters/pool-best-practices.html","timestamp":"1692492000.0","poster":"AndreFR","comment_id":"985489"},{"poster":"TC007","timestamp":"1681235700.0","comment_id":"867560","content":"Selected Answer: D\nD: use clusters that are from a cluster pool.\n\nUsing clusters from a cluster pool can improve the start-up time for the clusters used in the Job because the pool contains preconfigured and pre-started clusters that can be used immediately. This can save time and resources compared to starting new clusters for each task.","upvote_count":"4"},{"timestamp":"1680693900.0","comment_id":"862030","poster":"4be8126","upvote_count":"4","content":"Selected Answer: D\nD. They can use clusters that are from a cluster pool. Cluster pools allow you to pre-create a pool of ready-to-use clusters that can be used for running jobs, thereby eliminating the need to start new clusters each time a job runs. This can greatly reduce the startup time for each task."},{"content":"Selected Answer: B\nB is the correct answer. Job clusters are best suited for automated tasks running on a schedule.","comments":[{"comments":[{"content":"D es la respuesta correcta","timestamp":"1680578700.0","upvote_count":"2","poster":"knivesz","comment_id":"860582"}],"timestamp":"1680538260.0","comment_id":"860117","poster":"t30730","content":"\"Cluster pools allow us to reserve VM's ahead of time, when a new job cluster is created VM are grabbed from the pool. Note: when the VM's are waiting to be used by the cluster only cost incurred is Azure. Databricks run time cost is only billed once VM is allocated to a cluster. Use Databricks cluser pools feature to reduce the startup time\"","upvote_count":"1"}],"comment_id":"859176","poster":"XiltroX","timestamp":"1680456720.0","upvote_count":"2"}],"choices":{"E":"They can configure the clusters to autoscale for larger data sizes","C":"They can configure the clusters to be single-node","A":"They can use endpoints available in Databricks SQL","B":"They can use jobs clusters instead of all-purpose clusters","D":"They can use clusters that are from a cluster pool"},"question_text":"A data engineer has a Job with multiple tasks that runs nightly. Each of the tasks runs slowly because the clusters take a long time to start.\nWhich of the following actions can the data engineer perform to improve the start up time for the clusters used for the Job?","answer_description":"","answer_ET":"D","answer":"D"},{"id":"dRn6hCKLQoev6vTzRP6F","question_id":109,"discussion":[{"upvote_count":"1","comment_id":"1359335","poster":"e872ce8","content":"Selected Answer: E\nE correct","timestamp":"1740067380.0"},{"poster":"806e7d2","timestamp":"1731964080.0","upvote_count":"1","content":"Selected Answer: E\nTo grant full privileges on a database in SQL, you would use the GRANT ALL PRIVILEGES command, which gives the specified user or group all available permissions on the database. This typically includes the ability to select, insert, update, delete, and modify the structure of the database (such as creating and dropping tables).\n\nIn this case, the command:\n\nsql\nCopy code\nGRANT ALL PRIVILEGES ON DATABASE customers TO team;\ngives the team full control over the customers database, which is what is needed for them to manage the ELT project.","comment_id":"1314226"},{"content":"Selected Answer: E\ne is correct","comment_id":"1203813","poster":"benni_ale","upvote_count":"1","timestamp":"1714367520.0"},{"timestamp":"1710655500.0","comments":[{"timestamp":"1710808920.0","upvote_count":"1","comment_id":"1176907","content":"i think the 99 questions have been relabelled as Q1-44 then Q1-45","poster":"akshirao"}],"upvote_count":"1","poster":"Viju_1","comment_id":"1175609","content":"Examtopics not showing all the questions and asking for contributor access. I can only see qestions till 44. Anyone is able to see all 99 questions??????"},{"comment_id":"1125891","upvote_count":"1","poster":"Skidmee","content":"E is correct","timestamp":"1705584900.0"},{"upvote_count":"4","poster":"csd","timestamp":"1703858580.0","comment_id":"1108744","content":"E is correct \nTemplate to give access-->\nGRANT Privilege ON Object <object-name> TO <user or group>\n\nALL PRIVILEGES = gives all privilege"},{"upvote_count":"2","poster":"awofalus","comment_id":"1065550","timestamp":"1699439700.0","content":"Selected Answer: E\nE is correct"},{"timestamp":"1698857520.0","upvote_count":"2","poster":"DavidRou","content":"Selected Answer: D\nRight answer is E.\nThe template to respect is the following: GRANT <privilege> ON <resource> TO <user/group>","comment_id":"1059922"},{"poster":"vctrhugo","upvote_count":"2","timestamp":"1693781160.0","comment_id":"998016","content":"Selected Answer: E\nE. GRANT ALL PRIVILEGES ON DATABASE customers TO team;\n\nTo grant full privileges on the database \"customers\" to the new data engineering team, you can use the GRANT ALL PRIVILEGES command as shown in option E. This command provides the team with all possible privileges on the specified database, allowing them to fully manage it.\n\nOption A is not correct because it grants only the USAGE privilege, which is not sufficient for full management.\n\nOption B has the syntax reversed, and it is attempting to grant privileges on the \"team\" database to the \"customers\" database, which is not the desired action.\n\nOption C contains incorrect syntax and should use \"team\" instead of \"teams.\"\n\nOption D has incorrect syntax and is not a valid SQL command for granting privileges in most database management systems."},{"comment_id":"946591","content":"E\nGRANT ALL PRIVILEGES ON DATABASE customers TO team;","poster":"Atnafu","upvote_count":"1","timestamp":"1688829840.0"},{"upvote_count":"2","poster":"rafahb","comment_id":"862123","timestamp":"1680699900.0","content":"Selected Answer: E\nOption E"},{"poster":"XiltroX","upvote_count":"3","content":"Selected Answer: E\nCorrect answer is E. Please take note of how the questions are worded to avoid confusion and not make the wrong choice.","timestamp":"1680456780.0","comment_id":"859178"}],"question_images":[],"answer_description":"","topic":"1","exam_id":162,"answers_community":["E (86%)","14%"],"isMC":true,"choices":{"C":"GRANT SELECT PRIVILEGES ON DATABASE customers TO teams;","A":"GRANT USAGE ON DATABASE customers TO team;","B":"GRANT ALL PRIVILEGES ON DATABASE team TO customers;","E":"GRANT ALL PRIVILEGES ON DATABASE customers TO team;","D":"GRANT SELECT CREATE MODIFY USAGE PRIVILEGES ON DATABASE customers TO team;"},"answer_ET":"E","answer_images":[],"answer":"E","url":"https://www.examtopics.com/discussions/databricks/view/104902-exam-certified-data-engineer-associate-topic-1-question-44/","timestamp":"2023-04-02 19:33:00","question_text":"A new data engineering team team. has been assigned to an ELT project. The new data engineering team will need full privileges on the database customers to fully manage the project.\nWhich of the following commands can be used to grant full permissions on the database to the new data engineering team?","unix_timestamp":1680456780},{"id":"bRON0jhGTbfv4UCPXQiU","isMC":true,"question_images":[],"question_text":"A new data engineering team has been assigned to work on a project. The team will need access to database customers in order to see what tables already exist. The team has its own group team.\nWhich of the following commands can be used to grant the necessary permission on the entire database to the new team?","topic":"1","answer_images":[],"unix_timestamp":1680445260,"answer_description":"","timestamp":"2023-04-02 16:21:00","answer_ET":"E","answers_community":["E (77%)","A (18%)","5%"],"url":"https://www.examtopics.com/discussions/databricks/view/104870-exam-certified-data-engineer-associate-topic-1-question-45/","answer":"E","discussion":[{"poster":"Data_4ever","content":"Selected Answer: E\nE is the correct answer.","upvote_count":"14","timestamp":"1680886080.0","comment_id":"864087"},{"comment_id":"1094863","timestamp":"1702408320.0","content":"Selected Answer: E\nGRANT USAGE, answer E is correct. I dont see such privilage as GRANT VIEW https://docs.databricks.com/en/sql/language-manual/sql-ref-privileges.html#privilege-types","poster":"nedlo","upvote_count":"7"},{"comment_id":"1266896","content":"E is correct\n\nA: GRANT VIEW ON CATALOG is not a valid syntax in many SQL environments for database-level access.\nB: GRANT CREATE ON DATABASE customers would grant the team the ability to create objects in the database, which is more than just viewing the existing tables.\nC: This command incorrectly reverses the order of the team and the customers database.\nD: This would grant creation privileges on the team's database to the customers group, which is not relevant to the scenario.","poster":"7a22144","timestamp":"1723793760.0","upvote_count":"1"},{"timestamp":"1718797980.0","comment_id":"1232859","content":"E is correct","upvote_count":"2","poster":"potaryxkug"},{"comment_id":"1175886","timestamp":"1710685800.0","poster":"rcpaudel","content":"Selected Answer: E\nThe question is asking \"The team will need access to database customers in order to see what tables already exist.\" The presumption is, hoever, the team already has usage privilege on the catalog containing the database.","upvote_count":"1"},{"upvote_count":"4","content":"Selected Answer: E\nCustomers is a Database and not a catalog. \nThe three-space naming convention has Catalog at the top level(catalog.database(schema).table). \nSo granting a usage on catalog will expose other objects.","comment_id":"1047395","poster":"kishanu","timestamp":"1697675640.0"},{"poster":"J_1_2","content":"Selected Answer: E\nOption A, \"GRANT VIEW ON CATALOG customers TO team,\" grants the privilege to view the catalog but not access the database's tables, so it might not fulfill the requirement of seeing the existing tables in the database.\nSo answer is E","upvote_count":"1","timestamp":"1697021760.0","comment_id":"1040539"},{"upvote_count":"3","timestamp":"1696484700.0","comment_id":"1025303","poster":"tocs","content":"E.\nIt can NOT be A.\nYou can GRANT SELECT, but you cannot GRANT VIEW.\nVIEW is a securable OBJECT and not a PRIVILEGE TYPE, so you cannot grant it.\nSee also https://learn.microsoft.com/en-us/azure/databricks/data-governance/unity-catalog/manage-privileges/privileges"},{"comment_id":"1004918","comments":[{"comment_id":"1027446","upvote_count":"1","timestamp":"1696688760.0","poster":"tocs","content":"There is no such thing as GRANT VIEW, so A is not a valid option"}],"content":"It's A....I got 100% on the Data Governance section...it's A","timestamp":"1694443860.0","poster":"Nina0609","upvote_count":"2"},{"comment_id":"998018","timestamp":"1693781280.0","content":"Selected Answer: A\nA. GRANT VIEW ON CATALOG customers TO team;\n\nTo grant the new data engineering team the necessary permission to view the tables that exist in the \"customers\" database, you can use the GRANT VIEW ON CATALOG command as shown in option A. This command allows the team to see the metadata and information about the tables in the specified catalog or database, which is what you want in this case.\n\nOption B grants the CREATE privilege on the \"customers\" database to the team, which is not necessary for simply viewing existing tables.\n\nOption C and Option D have the syntax reversed, attempting to grant permissions from the team to the \"customers\" database, which is not the desired action.\n\nOption E grants USAGE privilege on the \"customers\" database to the team, which allows them to use the database but may not provide the necessary view permissions to see existing tables.","poster":"vctrhugo","upvote_count":"1","comments":[{"comment_id":"1276830","timestamp":"1725288900.0","poster":"shaojunni","upvote_count":"1","content":"Wrong, customers is a database, not catalog."}]},{"comment_id":"985703","timestamp":"1692525600.0","content":"Selected Answer: B\nSOURCE : https://docs.databricks.com/en/sql/language-manual/security-grant.html\n\nThe perfect answer would be : GRANT SHOW METADATA ON DATABASE customers TO team\nBut because, it is not suggested, we need to find an impertect answer allowing listing tables on database customers for project team's group : team\n\nA. GRANT VIEW ON CATALOG customers TO team -- Incorrect : \"GRANT VIEW\" does not exist\nB. GRANT CREATE ON DATABASE customers TO team -- Correct : only possible answer by elimitation. \nC. GRANT USAGE ON CATALOG team TO customers -- Incorrect : \"GRANT USAGE\" does not allow listing tables\nD. GRANT CREATE ON DATABASE team TO customers -- Incorrect : \"team\" and \"customers\" are inverted\nE. GRANT USAGE ON DATABASE customers TO team -- Incorrect : \"GRANT USAGE\" does not allow listing tables","upvote_count":"2","poster":"AndreFR","comments":[{"content":"In addition to what was typed previously, I'm adding an extra source : https://docs.databricks.com/en/data-governance/table-acls/object-privileges.html#usage-privilege\n\nSo correct syntax for what I previously wrote is : \nGRANT SHOW READ_METADATA ON DATABASE customers TO team\nand not : \nGRANT SHOW METADATA ON DATABASE customers TO team","poster":"AndreFR","timestamp":"1692542940.0","comment_id":"985873","upvote_count":"1"}]},{"comment_id":"962585","poster":"Office2022","upvote_count":"2","timestamp":"1690280820.0","content":"The correct answer is E. GRANT ALL PRIVILEGES ON DATABASE customers TO team;\n\nThe GRANT statement is used to grant privileges on a database, table, or view to a user or role. The ALL PRIVILEGES option grants all possible privileges on the specified object, such as CREATE, SELECT, MODIFY, and USAGE. The syntax of the GRANT statement is:\n\nGRANT privilege_type ON object TO user_or_role;\n\nTherefore, to grant full permissions on the database customers to the new data engineering team, the command should be:\n\nGRANT ALL PRIVILEGES ON DATABASE customers TO team;\n\nOption A is incorrect because it only grants the USAGE privilege, which allows the team to access the database but not to create or modify any tables or views in it."},{"poster":"Atnafu","upvote_count":"1","timestamp":"1688873220.0","content":"E\nThe GRANT USAGE ON DATABASE command grants the USAGE privilege on the specified database to the specified group. The USAGE privilege allows the group to see the tables that exist in the database, but it does not allow them to do anything else with the database.\n\nThe other commands are incorrect. The GRANT VIEW ON CATALOG command grants the VIEW privilege on the specified catalog to the specified group. The CREATE privilege allows the group to create new tables in the database. The USAGE privilege on the CATALOG does not exist.","comment_id":"946864"},{"content":"The correct is GRANT both \"USAGE\" and \"SELECT\" on DATABASE CUSTOMERS TO TEAMS","timestamp":"1688222040.0","poster":"clownfishman","comment_id":"940064","upvote_count":"2"},{"upvote_count":"1","poster":"chays","comment_id":"912099","timestamp":"1685622900.0","content":"Selected Answer: E\ne is the right answer"},{"poster":"prasioso","upvote_count":"2","timestamp":"1683981780.0","content":"Selected Answer: E\nThink the Answer is E. \nThe privilege types are CREATE, MODIFY, READ_METADATA, SELECT and USAGE. There is no such thing as GRANT VIEW. (it can however be GRANT <p-type> ON VIEW TO <team>). For our use case we want to GRANT USAGE for reading the Database. C has wrong syntax.","comment_id":"896670"},{"comment_id":"894309","timestamp":"1683746340.0","poster":"Bob123456","content":"option A is correct .\n\nQuestion says that \"The team will need access to database customers in order to see what tables already exist\" this looks like they need view access","upvote_count":"1"},{"upvote_count":"2","timestamp":"1683459540.0","comment_id":"891345","content":"https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/sql-ref-privileges-hms\nIn this link you can see that E is the correct answer, as there is no `VIEW` previlage, basically view previlage is `SELECT` preveliage.\nThen why will we have a VIEW previlage?, just think on process of elimination as well when answering such questions.","poster":"chandra_157_447"},{"comment_id":"888006","timestamp":"1683068100.0","content":"A:\nIn Databricks, the \"GRANT VIEW ON CATALOG\" command is used to grant permission to a user or group to view metadata in the catalog. The catalog in Databricks is a metadata management service that provides information about the data and other resources that are available within a Databricks workspace.\n\nWhen a user is granted the \"VIEW ON CATALOG\" permission, they are able to view information about databases, tables, and other resources that are available within the Databricks workspace. This information can be useful for understanding the structure and relationships of data within the workspace.\nAfter the permission has been granted, the user will be able to view metadata in the catalog by running catalog commands, such as \"SHOW DATABASES\" or \"DESCRIBE TABLE\". Note that granting the \"VIEW ON CATALOG\" permission does not allow the user to modify or delete metadata in the catalog, only view it.","poster":"Majjjj","upvote_count":"1","comments":[{"content":"E: \nIn Databricks, the \"GRANT USAGE ON DATABASE\" command is used to grant a user or group the permission to use a specific database in a Databricks workspace. This command allows the user or group to perform read operations on the database, such as listing tables and running queries.","comment_id":"888010","timestamp":"1683068340.0","poster":"Majjjj","upvote_count":"1","comments":[{"comment_id":"888011","content":"So according to the question \"E\" is correct","poster":"Majjjj","upvote_count":"1","timestamp":"1683068340.0"}]}]},{"comment_id":"887221","content":"i think e is the right answer","upvote_count":"1","poster":"pargit35","timestamp":"1683023580.0"},{"poster":"Tickxit","upvote_count":"1","timestamp":"1682592720.0","content":"I don't see GRANT USAGE or GRANT VIEW in the docs? Can someone provide a doc link","comment_id":"882539","comments":[{"poster":"nathan_jobs","timestamp":"1702228260.0","upvote_count":"1","comment_id":"1092675","content":"https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/sql-ref-privileges-hms"}]},{"comment_id":"867561","upvote_count":"3","poster":"TC007","content":"Selected Answer: A\nA: GRANT VIEW ON CATALOG customers TO team;\n\nThe VIEW privilege allows a user or group to see metadata, including the existing tables in the specified database. By granting the VIEW privilege on the CATALOG to the new team, they will be able to see what tables already exist in the customers database.","timestamp":"1681235760.0"},{"timestamp":"1680445260.0","comments":[{"poster":"Data_4ever","timestamp":"1680886440.0","upvote_count":"5","content":"The previous question 44 was all options were about permissions for DATABASE. How come all of a sudden there is no such thing as DATABASE?? \nE is the right answer as USAGE is a permission type required for performing any actions on the securable item, in this case a database named Customers. \n\nOptions A, B, D are incorrect as there are no privileges named VIEW & CREATE exists. CREATE CATALOG, CREATE SCHEMA, CREATE TABLE etc., exists but not just CREATE. \nOption C has the users and database name misplaced and hence it is also incorrect.","comment_id":"864096"}],"upvote_count":"3","comment_id":"858909","content":"Selected Answer: A\nE is not the right answer. The correct answer is A. There is no such thing as DATABASE as a permission object in a GRANT statement so options B, D and E are automatically invalid. Which leaves us with A and C. If you look at Databricks documentation, the USAGE permission does absolutely nothing. So the final correct answer is A. Good luck everyone.","poster":"XiltroX"}],"exam_id":162,"question_id":110,"choices":{"A":"GRANT VIEW ON CATALOG customers TO team;","C":"GRANT USAGE ON CATALOG team TO customers;","E":"GRANT USAGE ON DATABASE customers TO team;","D":"GRANT CREATE ON DATABASE team TO customers;","B":"GRANT CREATE ON DATABASE customers TO team;"}}],"exam":{"isBeta":false,"isMCOnly":true,"name":"Certified Data Engineer Associate","provider":"Databricks","lastUpdated":"12 Apr 2025","isImplemented":true,"id":162,"numberOfQuestions":169},"currentPage":22},"__N_SSP":true}