{"pageProps":{"questions":[{"id":"bny9sFUl7tZjStnHEVA2","topic":"1","unix_timestamp":1726747740,"question_text":"Which of the following code blocks returns a DataFrame where column managerName from DataFrame storesDF is split at the space character into column managerFirstName and column managerLastName?\n\nA sample of DataFrame storesDF is displayed below:\n\n//IMG//","answer_description":"","answer_images":[],"answer":"A","answers_community":["A (100%)"],"discussion":[{"content":"Selected Answer: A\nExplanation:\nsplit(col(\"managerName\"), \" \"):\n\nThis splits the column managerName into an array of strings based on the space character.\nAccessing array elements:\n\nUsing [0] extracts the first element (first name) of the resulting array.\nUsing [1] extracts the second element (last name) of the resulting array.\nwithColumn:\n\nThe withColumn() method is used to create new columns (managerFirstName and managerLastName) in the DataFrame.","poster":"Souvik_79","comment_id":"1346357","timestamp":"1737785640.0","upvote_count":"1"},{"comment_id":"1312050","timestamp":"1731593940.0","poster":"thinkbang","upvote_count":"1","content":"Selected Answer: A\nbasic documentation"},{"timestamp":"1728907440.0","poster":"max_manfred","upvote_count":"2","comment_id":"1297509","content":"Right answer is A as the array returned by the split function is 0-based not 1-based. You can try yourself with the following code:\ndf = spark.createDataFrame([('John Doe',)], ['Person',])\ndf2 = df \\\n .withColumn('first_name', split(col('Person'), ' ')[0]) \\\n .withColumn('last_name', split(col('Person'), ' ')[1])\ndf2.show()"},{"timestamp":"1728241860.0","upvote_count":"1","comment_id":"1293931","content":"(storesDF.withColumn(\"managerFirstName\", split(col(\"managerName\"), \" \")[0])\n .withColumn(\"managerLastName\", split(col(\"managerName\"), \" \")[1]))","poster":"sofiess"}],"answer_ET":"C","isMC":true,"choices":{"A":"(storesDF.withColumn(\"managerFirstName\", split(col(\"managerName\"), \" \")[0])\n.withColumn(\"managerLastName\", split(col(\"managerName\"), \" \")[1]))","E":"(storesDF.withColumn(\"managerFirstName\", split(\"managerName\"), \" \")[0])\n.withColumn(\"managerLastName\", split(\"managerName\"), \" \")[1]))","D":"(storesDF.withColumn(\"managerFirstName\", col(\"managerName\").split(\" \")[0])\n.withColumn(\"managerLastName\", col(\"managerName\").split(\" \")[1]))","B":"(storesDF.withColumn(\"managerFirstName\", col(\"managerName\"). split(\" \")[1])\n.withColumn(\"managerLastName\", col(\"managerName\").split(\" \")[2]))","C":"(storesDF.withColumn(\"managerFirstName\", split(col(\"managerName\"), \" \")[1])\n.withColumn(\"managerLastName\", split(col(\"managerName\"), \" \")[2]))"},"timestamp":"2024-09-19 14:09:00","exam_id":161,"question_images":["https://img.examtopics.com/certified-associate-developer-for-apache-spark/image23.png"],"url":"https://www.examtopics.com/discussions/databricks/view/147840-exam-certified-associate-developer-for-apache-spark-topic-1/","question_id":91},{"id":"ArthYYVUH4ozi0KRYTFe","answer_description":"","answer_images":[],"answer":"D","isMC":true,"discussion":[{"upvote_count":"3","content":"Selected Answer: D\nscenario #1 uses a configuration with only 1 executor. If the worker node running that executor fails, the entire application will fail because there are no other executors available to continue processing the tasks.\nSpark needs redundancy across multiple worker nodes or executors to tolerate node failures. Since this configuration has only one executor, it lacks fault tolerance.","timestamp":"1726748340.0","poster":"Oks_An","comment_id":"1286320"}],"question_text":"Which of the following cluster configurations will fail to ensure completion of a Spark application in light of a worker node failure?\n\n//IMG//\n\n\nNote: each configuration has roughly the same compute power using 100GB of RAM and 200 cores.","answers_community":["D (100%)"],"answer_ET":"D","choices":{"D":"Scenario #1","C":"Scenario #6","E":"They should all ensure completion because worker nodes are fault tolerant","A":"Scenario #5","B":"Scenario #4"},"question_images":["https://img.examtopics.com/certified-associate-developer-for-apache-spark/image24.png"],"unix_timestamp":1726748340,"url":"https://www.examtopics.com/discussions/databricks/view/147841-exam-certified-associate-developer-for-apache-spark-topic-1/","topic":"1","exam_id":161,"question_id":92,"timestamp":"2024-09-19 14:19:00"},{"id":"wWVdP5TD3ilxbMKRGQMQ","choices":{"D":"storesDF.fillna(\"No Manager\", col(\"managerName\"))","C":"storesDF.na.fill(\"No Manager\", col(\"managerName\"))","A":"storesDF.na.fill(\"No Manager\", \"managerName\")","E":"storesDF.nafill(\"No Manager\", \"managerName\")","B":"storesDF.nafill(\"No Manager\", col(\"managerName\"))"},"topic":"1","question_id":93,"url":"https://www.examtopics.com/discussions/databricks/view/154608-exam-certified-associate-developer-for-apache-spark-topic-1/","answers_community":["A (100%)"],"question_images":["https://img.examtopics.com/certified-associate-developer-for-apache-spark/image25.png"],"question_text":"Which of the following code blocks returns a new DataFrame where column managerName from DataFrame storesDF has had its missing values replaced with the value \"No Manager\"?\n\nA sample of DataFrame storesDF is below:\n\n//IMG//","exam_id":161,"answer_description":"","answer_images":[],"unix_timestamp":1736971260,"answer_ET":"A","answer":"A","isMC":true,"discussion":[{"content":"Selected Answer: A\ncorrect\nhttps://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.fillna.html\nfillna (synonym) does not accept col objects","poster":"bp_a_user","timestamp":"1736971260.0","upvote_count":"1","comment_id":"1341239"}],"timestamp":"2025-01-15 21:01:00"},{"id":"z2he3P0MSuGQUClG4zjN","unix_timestamp":1726748520,"answer_images":[],"choices":{"E":"storesDF.filter(sqft <= 25000 and customerSatisfaction >= 30)","C":"storesDF.filter(col(\"sqft\") <= 25000 & col(\"customerSatisfaction\") >= 30)","B":"storesDF.filter(col(sqft) <= 25000 & col(customerSatisfaction) >= 30)","D":"storesDF.filter((col(\"sqft\") <= 25000) & (col(\"customerSatisfaction\") >= 30))","A":"storesDF.filter(col(\"sqft\") <= 25000 and col(\"customerSatisfaction\") >= 30)"},"question_text":"Which of the following code blocks returns a DataFrame containing only the rows from DataFrame storesDF where the value in column sqft is less than or equal to 25,000 AND the value in column customerSatisfaction is greater than or equal to 30?","topic":"1","timestamp":"2024-09-19 14:22:00","url":"https://www.examtopics.com/discussions/databricks/view/147842-exam-certified-associate-developer-for-apache-spark-topic-1/","answer":"D","exam_id":161,"answer_ET":"D","question_id":94,"answers_community":["D (100%)"],"isMC":true,"question_images":[],"answer_description":"","discussion":[{"content":"Selected Answer: D\nDear Exam Topics, why are you highlighting wrong answers?","upvote_count":"1","timestamp":"1741874520.0","comment_id":"1388778","poster":"ARUNKUMARKRISHNASAMY"},{"comment_id":"1364373","content":"Selected Answer: D\nD is correct","upvote_count":"1","poster":"Thameur01","timestamp":"1741001640.0"},{"comment_id":"1286322","content":"Selected Answer: D\nD. storesDF.filter((col(\"sqft\") <= 25000) & (col(\"customerSatisfaction\") >= 30)): This correctly uses the filter() method along with logical AND (&) to apply both conditions. Each condition is wrapped in parentheses to ensure proper evaluation.","poster":"Oks_An","timestamp":"1726748520.0","upvote_count":"1"}]},{"id":"GtbOxJ8OkC4dcDKmjbpu","answer_ET":"A","answer_images":[],"answer":"A","topic":"1","timestamp":"2024-09-19 14:23:00","exam_id":161,"choices":{"E":"Spark DataFrames have common Structured APIs.","A":"Spark DataFrames are the same as a data frame in Python or R.","C":"Spark DataFrames are immutable.","D":"Spark DataFrames are distributed.","B":"Spark DataFrames are built on top of RDDs."},"question_text":"Which of the following statements about Spark DataFrames is incorrect?","unix_timestamp":1726748580,"url":"https://www.examtopics.com/discussions/databricks/view/147843-exam-certified-associate-developer-for-apache-spark-topic-1/","discussion":[{"upvote_count":"4","timestamp":"1726748580.0","poster":"Oks_An","comment_id":"1286324","content":"Selected Answer: A\nA. Spark DataFrames are the same as a data frame in Python or R.: This statement is incorrect because Spark DataFrames, while conceptually similar to data frames in Python (e.g., pandas) or R, are not the same. Spark DataFrames are distributed, immutable, and built on top of RDDs, designed to handle large-scale data processing across a cluster. In contrast, data frames in Python (pandas) or R are typically in-memory, single-node constructs."}],"isMC":true,"question_images":[],"question_id":95,"answer_description":"","answers_community":["A (100%)"]}],"exam":{"numberOfQuestions":185,"id":161,"isBeta":false,"lastUpdated":"12 Apr 2025","provider":"Databricks","isMCOnly":true,"name":"Certified Associate Developer for Apache Spark","isImplemented":true},"currentPage":19},"__N_SSP":true}