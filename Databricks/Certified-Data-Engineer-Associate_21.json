{"pageProps":{"questions":[{"id":"P4gq703E7glyK9hJZhpC","choices":{"C":"They can create a new task in the existing Job and then add the original task as a dependency of the new task.","A":"They can clone the existing task in the existing Job and update it to run the new notebook.","D":"They can create a new job from scratch and add both tasks to run concurrently.","E":"They can clone the existing task to a new Job and then edit it to run the new notebook.","B":"They can create a new task in the existing Job and then add it as a dependency of the original task."},"answers_community":["B (65%)","C (35%)"],"question_id":101,"answer_ET":"B","question_images":[],"topic":"1","answer_images":[],"question_text":"A data engineer has a single-task Job that runs each morning before they begin working. After identifying an upstream data issue, they need to set up another task to run a new notebook prior to the original task.\nWhich of the following approaches can the data engineer use to set up the new task?","answer_description":"","timestamp":"2023-04-05 13:06:00","unix_timestamp":1680692760,"exam_id":162,"isMC":true,"url":"https://www.examtopics.com/discussions/databricks/view/105268-exam-certified-data-engineer-associate-topic-1-question-37/","discussion":[{"timestamp":"1681493640.0","poster":"Redwings538","content":"Selected Answer: B\nIt seems there is some confusion on what dependency means in this case. Option B is correct because adding the new task as a dependency of the original task means that the new task will run BEFORE the original task, which is the goal defined in the question.","upvote_count":"24","comments":[{"poster":"loyik65509","comment_id":"1402101","upvote_count":"2","content":"This means the original task must run first before the new task starts.\n\nThe original task will wait for the new task.\n\nThis is the wrong order because we need the new task to run first to fix upstream data issues before the original task executes.","timestamp":"1742698800.0"}],"comment_id":"870363"},{"content":"Selected Answer: B\nB is the right answer.","timestamp":"1680883440.0","comment_id":"864064","poster":"Data_4ever","upvote_count":"15"},{"poster":"Billybob0604","timestamp":"1742726520.0","upvote_count":"3","comment_id":"1402228","content":"Selected Answer: C\nThe new task should run before the original task, meaning the original task must depend on the new task"},{"content":"Selected Answer: B\nB as the new task runs first","timestamp":"1740273300.0","upvote_count":"1","comment_id":"1360336","poster":"pint414"},{"upvote_count":"1","content":"Selected Answer: C\nI think the confusion here is because it mentions \"as a dependency\" which to my opinion means following. if we go by that wording C is the correct answer because we want the original task to be run after the new task.","poster":"avidlearner","timestamp":"1739855460.0","comment_id":"1358131"},{"comment_id":"1338556","timestamp":"1736462700.0","upvote_count":"1","poster":"Usaha1","content":"Selected Answer: B\nB because when we add a task which is supposed to run after previous task then dependency (\"depends on\") gets added to the second job, not the first job."},{"upvote_count":"2","poster":"rohitrc8521","content":"Selected Answer: C\nAnswer is C, folks\nPlease pay solid attention to the wording. They deliberately have constructed the wordings of option B and C to confuse the audience.","timestamp":"1736330040.0","comment_id":"1337888"},{"timestamp":"1736280780.0","content":"Selected Answer: C\nI think the correct answer should be C and not B. \nAdding the new task as a dependency of the original task would mean that the original task runs first and then the new task runs. This is the opposite of what is desired in the question.","comment_id":"1337694","upvote_count":"3","poster":"danishanis"},{"poster":"brconejeros","upvote_count":"1","comment_id":"1332147","content":"Selected Answer: C\nBasically because on the sentence we have a prior: \"they need to set up another task to run a new notebook prior to the original task.\". So, the correct answer is C","timestamp":"1735256520.0"},{"content":"Selected Answer: B\nthe answer B\nas it need runs before start working","comment_id":"1330632","upvote_count":"1","poster":"Rifrif","timestamp":"1734913860.0"},{"comment_id":"1329482","timestamp":"1734702540.0","content":"Selected Answer: B\nB - Event without know anything about Databricks, answer B is how I would want to be able to handle this scenario, it makes the most sense.","poster":"sam_chalvet","upvote_count":"1"},{"content":"Selected Answer: B\nIn Databricks Jobs, you can manage task dependencies within a single job. If you want to add a new task that needs to run before the original task due to an upstream issue, the appropriate approach would be to:\n\nCreate a new task: This new task would run the notebook that addresses the upstream data issue.\nAdd it as a dependency of the original task: By making the new task dependent on the original task, you ensure that the new task runs first, and only after its successful completion will the original task run.\nThis approach ensures that the sequence of tasks is correctly managed in a single job, with dependencies explicitly defined.","poster":"806e7d2","comment_id":"1314210","upvote_count":"1","timestamp":"1731961860.0"},{"timestamp":"1727440680.0","comment_id":"1290029","content":"C. They can create a new task in the existing Job and then add the original task as a dependency of the new task.\n\nWhy this is correct: In Databricks, you can set up a task dependency chain by adding a new task and specifying that the original task depends on the new one. This ensures that the new task will run first, followed by the original task.","upvote_count":"1","poster":"Colje"},{"content":"Selected Answer: B\nBoth B and C involve dependencies between tasks, but the difference is in how the dependencies are structured:\n\nB: \"They can create a new task in the existing Job and then add it as a dependency of the original task.\"\n\nIn this case, the new task is added as a prerequisite (dependency) for the original task. This means the new task will run first, and once it's completed, the original task will run.\n\nC: \"They can create a new task in the existing Job and then add the original task as a dependency of the new task.\"\n\nIn this case, the original task is added as a dependency for the new task, meaning the new task will wait for the original task to finish before running.\n\nThe correct answer is B:\nYou want the new task (the one handling the upstream issue) to run before the original task, so it should be set as a dependency of the original task.","timestamp":"1727141460.0","poster":"tangerine141","comment_id":"1288366","upvote_count":"1"},{"poster":"Stefan94","timestamp":"1726816680.0","content":"Selected Answer: B\nB is correct as Redwings538 says","upvote_count":"1","comment_id":"1286700"},{"comment_id":"1276108","poster":"CID2024","content":"I think the Correct answer is C.\nBecause as per the statement in the question \"they need to set up another task to run a new notebook prior to the original task.\" i.e. original task should run AFTER the new task.\n\nSo, By creating a new task in the existing job and setting the original task as a dependency of the new task, the data engineer ensures that the new notebook runs first, followed by the original task. This approach maintains the sequence of execution required to address the upstream data issue.","upvote_count":"2","timestamp":"1725199980.0"},{"content":"Below is the info I am convinced after checking with AI.....\nHere's the break down the differences between options B and C:\n\nOption B:\n Create a new task in the existing Job and then add it as a dependency of the original task:\nResult: The new task will run after the original task.\n\nOption C:\nCreate a new task in the existing Job and then add the original task as a dependency of the new task:\n\nResult: The new task will run before the original task.\n\nSummary:\nOption B: Original task → New task\nOption C: New task → Original task\nIn your case, Option C is the correct choice because you need the new task to run first to resolve the upstream data issue before the original task executes.","poster":"9d4d68a","comment_id":"1272902","timestamp":"1724691000.0","upvote_count":"2"},{"comment_id":"1266880","content":"C is correct because it correctly handles the sequence of execution. By creating a new task in the existing Job and adding the original task as a dependency of the new task, the new task will run first, and once it completes successfully, the original task will run. This ensures that the upstream data issue is addressed before the original task runs.","poster":"7a22144","upvote_count":"1","timestamp":"1723792140.0"},{"comment_id":"1216596","content":"Selected Answer: B\nB is the right answer.","poster":"kokosz","upvote_count":"2","timestamp":"1716469740.0"},{"timestamp":"1714366560.0","comment_id":"1203803","poster":"benni_ale","upvote_count":"1","content":"Selected Answer: B\noriginal depends on new"},{"comment_id":"1166276","poster":"Mircuz","content":"Selected Answer: C\nC because the new task has to run prior the original one","upvote_count":"3","timestamp":"1709623260.0"},{"content":"Selected Answer: B\nJust got 100% on the test. B was correct.","comment_id":"1133115","timestamp":"1706339340.0","upvote_count":"6","poster":"Nika12"},{"timestamp":"1705587720.0","content":"This has become more of a English grammatical test as the word dependency is confusing people. When the Original task has a dependency on the new task this means the original task needs to depend on the new task. So it's Option C.","upvote_count":"3","comment_id":"1125950","poster":"Shaxxie"},{"comment_id":"1109414","timestamp":"1703913060.0","content":"Selected Answer: C\nThe data engineer can create a new task in the existing Job and then add the original task as a dependency of the new task (Option C). This way, the new task will run first, and once it’s completed, the original task will run. Here are the steps to do this:\n\nClick Workflows in the sidebar and click New and select Job.\nThe Tasks tab appears with the create task dialog.\nReplace Add a name for your job… with your job name.\nEnter a name for the task in the Task name field.\nIn the Type drop-down menu, select the type of task to run.\nConfigure the cluster where the task runs.\nTo add dependent libraries, click + Add next to Dependent libraries.\nYou can pass parameters for your task.\nPlease note that the exact process may vary depending on the specific configurations and permissions set up in your workspace. It’s always a good idea to consult with your organization’s IT or data governance team to ensure the correct procedures are followed.","poster":"Garyn","upvote_count":"4"},{"upvote_count":"5","comment_id":"1106573","timestamp":"1703652960.0","poster":"Tinendra","content":"Answer is C"},{"poster":"nedlo","content":"Selected Answer: B\nI am pretty sure its B - \"they need to set up another task to run a new notebook prior to the original task.\" - so NEW task need to run BEFORE ORIGINAL task. So NEW TASK should be DEPENDENCY of ORIGINAL TASK (or in other words: original task is dependent on new task)","comment_id":"1094611","timestamp":"1702391340.0","upvote_count":"1"},{"upvote_count":"5","comment_id":"1065601","timestamp":"1699444260.0","poster":"ObeOne","content":"\"A data engineer has a single-task Job that runs each morning before they begin working. After identifying an upstream data issue, they need to set up another task to run a new notebook prior to the original task.\"\n\nIn the tasks UI of the Job:\n1. Create a *new task*\n2. Select *original task*\n3. In *original task* for \"depends on\" enter *new task\" - as *new task* needs to run prior to *original task*, ie, original task has a dependency on new task\n\nfrom 1. create new task ..... from 3. original task has a dependency on new task\n\nAnswer is C ... They can *create a new task* in the existing Job and then add the *original task as a dependency of the new task*."},{"comments":[{"timestamp":"1703034960.0","poster":"AndreFR","comment_id":"1101105","content":"I disagree. \"the original task as a dependency of the new task\" means that the original task needs to run first.","upvote_count":"1"}],"content":"Selected Answer: C\nCorrect is C because original task will run after the newer, and then, depend on it","poster":"awofalus","comment_id":"1064897","timestamp":"1699368480.0","upvote_count":"2"},{"timestamp":"1698784860.0","poster":"ObeOne","upvote_count":"2","content":"C is correct","comment_id":"1059189"},{"poster":"DavidRou","upvote_count":"1","comment_id":"1058979","content":"Right answer: B\nWe need to add the new task as a dependency of the original one because the question says that it needs to be run before the original task.","timestamp":"1698765720.0"},{"upvote_count":"1","timestamp":"1697827020.0","comment_id":"1049033","content":"This is a Grammar issue not a Databricks issue: \nAdd A as a dependency of B means A must run before B.","poster":"kbaba101"},{"comments":[],"comment_id":"998006","content":"Selected Answer: C\nC. They can create a new task in the existing Job and then add the original task as a dependency of the new task.\n\nTo set up a new task that runs a new notebook prior to the original task in an existing Job, you can create a new task within the same Job and then set the original task as a dependency for the new task. This way, the new task will execute before the original task when the Job is triggered.","upvote_count":"3","timestamp":"1693780380.0","poster":"vctrhugo"},{"comment_id":"993228","timestamp":"1693323960.0","content":"Selected Answer: B\nB is the right answer","poster":"[Removed]","upvote_count":"2"},{"content":"Selected Answer: B\nB is correct. I misunderstood this question and initially thought it was C.","poster":"poTEYtoe_poTAHtoe","upvote_count":"2","comment_id":"990001","timestamp":"1692963480.0"},{"poster":"Atnafu","comment_id":"946522","timestamp":"1688823660.0","content":"B\nTo set up the new task to run a new notebook prior to the original task in a single-task Job, the data engineer can use the following approach:\n\nIn the existing Job, create a new task that corresponds to the new notebook that needs to be run.\n\nSet up the new task with the appropriate configuration, specifying the notebook to be executed and any necessary parameters or dependencies.\n\nOnce the new task is created, designate it as a dependency of the original task in the Job configuration. This ensures that the new task is executed before the original task.","upvote_count":"4"},{"comment_id":"928369","content":"Selected Answer: C\nC is the right answer.","timestamp":"1687258560.0","poster":"james_donquixote","upvote_count":"2"},{"content":"Selected Answer: C\noriginal task is dependent on the new task. So the new task must run before the original one. Hence C","upvote_count":"4","comment_id":"896695","poster":"prasioso","timestamp":"1683984660.0"},{"content":"it is really confusing - according to oxford dictionary, dependency means \"a dependent or subordinate thing\", so original task should be a dependency of new task. so C?","upvote_count":"1","poster":"austinoy","timestamp":"1683576000.0","comment_id":"892486"},{"comment_id":"889135","poster":"Majjjj","upvote_count":"3","content":"Selected Answer: C\nThe data engineer can create a new task in the existing Job and then add the original task as a dependency of the new task. This will ensure that the new task runs before the original task, and any upstream data issues are resolved before the original task begins. Option B suggests creating a new task and adding it as a dependency of the original task, which would not address the issue of running the new notebook before the original task.","timestamp":"1683172440.0"},{"upvote_count":"2","timestamp":"1681430520.0","comment_id":"869842","poster":"HoangHuy","content":"Selected Answer: B\nDefinitely option B, I tested!"},{"upvote_count":"2","comment_id":"867550","poster":"TC007","content":"Selected Answer: C\nThe approach that the data engineer can use to set up the new task is option C: create a new task in the existing Job and then add the original task as a dependency of the new task.\n\nBy creating a new task in the existing Job and adding the original task as a dependency, the new task will run before the original task, as it is dependent on the completion of the new task. This ensures that the new notebook is run prior to the original task, as required.","timestamp":"1681235100.0"},{"poster":"sdas1","upvote_count":"1","content":"Option C","timestamp":"1681017840.0","comment_id":"865304"},{"timestamp":"1680706620.0","comment_id":"862209","upvote_count":"3","poster":"XiltroX","content":"Selected Answer: C\nC is the right answer."},{"upvote_count":"4","comment_id":"862011","poster":"4be8126","comments":[{"timestamp":"1680883980.0","comments":[{"poster":"Inhaler_boy","upvote_count":"1","comments":[{"comment_id":"978618","poster":"Inhaler_boy","timestamp":"1691757420.0","upvote_count":"2","content":"Sorry, I mean the answers needs to be better formulated."}],"comment_id":"978612","content":"This one is difficult and dividing. It is kind of half-full, half-empty question. Dependency in the english language usually means on is dependent on the other, but it can also be used that there is dependency between two objects here. In my eyes both can be correct. The question needs to be better formulated.\n B and C gets my vote.","timestamp":"1691756760.0"}],"comment_id":"864070","upvote_count":"6","content":"No you are wrong. You need to carefully read the options. The expectation from the question is that new task should run prior to the original task. In order to achieve this, you have to follow the below steps.\n\nStep 1: Open the existing job from workflows page and add new task\nStep 2: Go to the Original task in the job and update the 'Depends on' with the new task created.\nStep 3: Now you will see the pictorial representation of job workflow clearly represents the new task will run first followed by the original task. You confirm that and click 'Save'.\n\nOnly option B is having these steps covered. Option C is incorrect as that will make the original task to run first instead of new task.","poster":"Data_4ever"}],"timestamp":"1680692760.0","content":"Selected Answer: B\nB. They can create a new task in the existing Job and then add it as a dependency of the original task.\n\nAdding a new task as a dependency to an existing task in the same Job allows the new task to run before the original task is executed. This ensures that the data engineer can run the new notebook prior to the original task without having to create a new Job from scratch. Cloning the existing task or creating a new Job would add unnecessary complexity to the pipeline."}],"answer":"B"},{"id":"6BSLaJ9rZfiTqHJnCqM9","question_images":[],"answer_images":[],"choices":{"B":"They can set the query’s refresh schedule to end after a certain number of refreshes.","C":"They cannot ensure the query does not cost the organization money beyond the first week of the project’s release.","E":"They can set the query’s refresh schedule to end on a certain date in the query scheduler.","A":"They can set a limit to the number of DBUs that are consumed by the SQL Endpoint.","D":"They can set a limit to the number of individuals that are able to manage the query’s refresh schedule."},"url":"https://www.examtopics.com/discussions/databricks/view/105269-exam-certified-data-engineer-associate-topic-1-question-38/","unix_timestamp":1680692940,"topic":"1","answer":"E","answers_community":["E (77%)","C (20%)","2%"],"timestamp":"2023-04-05 13:09:00","isMC":true,"answer_description":"","exam_id":162,"question_text":"An engineering manager wants to monitor the performance of a recent project using a Databricks SQL query. For the first week following the project’s release, the manager wants the query results to be updated every minute. However, the manager is concerned that the compute resources used for the query will be left running and cost the organization a lot of money beyond the first week of the project’s release.\nWhich of the following approaches can the engineering team use to ensure the query does not cost the organization any money beyond the first week of the project’s release?","answer_ET":"E","question_id":102,"discussion":[{"comment_id":"1133116","upvote_count":"16","timestamp":"1706339460.0","content":"Selected Answer: E\nJust got 100% on the test. E was correct. C was not in the available options.","poster":"Nika12"},{"comment_id":"879855","upvote_count":"10","content":"The query scheduler only gives the option on what the interval is to run the query. It does not provide a way to stop after x iterations or at a point in time. \nThe question is confusing. From what i found the only option is to limit users access to the query (and therefore query scheduler). \nhttps://docs.databricks.com/security/auth-authz/access-control/query-acl.html\nNot convinced how this would be helping the organization save money if no-one is manually stopping the schedule. \nAnswer C seems most correct\nAnswer D can be achieved using acl however how is this helpful in the use case described?","timestamp":"1682393820.0","poster":"BigDaddyAus"},{"upvote_count":"1","poster":"Usaha1","comment_id":"1339010","timestamp":"1736553480.0","content":"Selected Answer: E\nCron syntax can be used for scheduling"},{"content":"Selected Answer: E\nCalm down folks, the answer is E!!","timestamp":"1736330640.0","upvote_count":"1","poster":"rohitrc8521","comment_id":"1337895"},{"comment_id":"1312190","poster":"UrcoIbz","upvote_count":"1","timestamp":"1731605040.0","content":"Selected Answer: E\nOption E is correct. Although there in not an 'direct' option to select an end date, cron expressions allows run schedules on a specific time period (in this case a specific week)."},{"poster":"tmz1","comment_id":"1286237","timestamp":"1726734300.0","upvote_count":"2","content":"Answer is E. There is an option to specify schedule with CRON syntax which enables to set schedule for a chosen week. \nFor example, when you specify CRON: 0 0 0 23-29 SEP ? 2024, the query will be run At 12:00 AM, between day 23 and 29 of the month, only in September 2024."},{"upvote_count":"1","content":"E is correct because the engineering team can use the query scheduler in Databricks to set a specific end date for the query refresh schedule. This way, after the first week, the automatic refreshes will stop, and the associated compute costs will be avoided.","poster":"7a22144","comment_id":"1266883","timestamp":"1723792620.0"},{"content":"Selected Answer: E\nThe correct answer is E for this question.","comment_id":"1244559","upvote_count":"1","poster":"3fbc31b","timestamp":"1720469700.0"},{"content":"Answer is E","comment_id":"1216201","upvote_count":"1","timestamp":"1716438360.0","poster":"aspix82"},{"comment_id":"1160895","upvote_count":"4","poster":"data_arch","content":"Selected Answer: E\nAnswer is E\nIt´s true natively the query can´t be scheduled to stop, but the scheduler allow us to use cron syntax.\nSo we can define the year, month and days of the first week and the trigger won´t run after that","timestamp":"1709058420.0"},{"comment_id":"1118556","upvote_count":"2","timestamp":"1704891540.0","content":"Selected Answer: C\nThe query scheduler does not give option to have end date (or iterations). Dashboards might give one, but the question specifically mentions queries.\nhttps://learn.microsoft.com/en-gb/azure/databricks/sql/user/queries/schedule-query","poster":"Def21"},{"poster":"Garyn","comment_id":"1109421","timestamp":"1703913480.0","content":"Selected Answer: E\nE. They can set the query’s refresh schedule to end on a certain date in the query scheduler.\n\nExplanation:\n\nQuery Scheduler: Databricks offers a Query Scheduler that allows users to schedule the execution of SQL queries at specific intervals or for specific durations.\n\nSetting a Specific End Date: The team can configure the query's refresh schedule to conclude or end on a certain date. By specifying an end date within the first week of the project's release, the query will automatically stop refreshing after that date. This action ensures that compute resources aren't continuously utilized beyond the specified timeframe, preventing unnecessary costs.\n\nThis approach allows the team to control and limit the execution of the query to the required duration without incurring additional costs beyond the first week of the project's release.","upvote_count":"3"},{"poster":"mokrani","upvote_count":"1","comment_id":"1086862","timestamp":"1701613800.0","content":"C is the correct answer \n\nSource : https://docs.databricks.com/en/sql/user/queries/schedule-query.html"},{"comment_id":"1057245","timestamp":"1698626520.0","comments":[{"comment_id":"1118555","timestamp":"1704891480.0","content":"This is Dashboard, not SQL query.","poster":"Def21","upvote_count":"2"}],"poster":"god_father","content":"Selected Answer: E\nE is the correct answer.\n\nFrom the docs:\n\nIf a dashboard is configured for automatic updates, it has a Scheduled button at the top, rather than a Schedule button. To stop automatically updating the dashboard and remove its subscriptions:\n\n Click Scheduled.\n In the Refresh every drop-down, select Never.\n Click Save. The Scheduled button label changes to Schedule.\nSource: https://learn.microsoft.com/en-us/azure/databricks/sql/user/dashboards/","upvote_count":"2"},{"comment_id":"1055874","content":"Selected Answer: E\nOption E is correct answer","poster":"kishore1980","timestamp":"1698445800.0","upvote_count":"1"},{"content":"Selected Answer: B\nThe picker scrolls and allows you to choose:\nAn interval: 1-30 minutes, 1-12 hours, 1 or 30 days, 1 or 2 weeks\n\nSince the schedule picker allows to choose interval to refresh query every 1 or 2 weeks. If we choose 1 week the schedule ends after a week. So the answer is B.","comment_id":"1055869","comments":[],"timestamp":"1698445020.0","poster":"kishore1980","upvote_count":"1"},{"content":"Correct Answer E.","comment_id":"1000903","timestamp":"1694026560.0","poster":"damaldon","upvote_count":"1"},{"comment_id":"993231","timestamp":"1693324140.0","upvote_count":"1","content":"Selected Answer: C\nagree with BigDaddyAus","poster":"[Removed]"},{"upvote_count":"2","content":"Selected Answer: C\nAnswer is C. According to documentation it cant be scheduled up until a certain date. It has to be in intervals and then canceled manually. They don't mention end date. Only start date and intervals.\nhttps://docs.databricks.com/en/workflows/jobs/schedule-jobs.html","poster":"Inhaler_boy","comments":[{"comment_id":"981577","poster":"Inhaler_boy","content":"Also this link seems to verify C as the correct answer:\nhttps://docs.databricks.com/en/sql/user/queries/schedule-query.html","upvote_count":"1","timestamp":"1692098460.0"}],"timestamp":"1692098400.0","comment_id":"981575"},{"timestamp":"1688824380.0","poster":"Atnafu","upvote_count":"1","content":"E\nOption A: The query will still run, but it will be throttled if it exceeds the DBU limit.\nOption B:The query will still run, but it will only run a certain number of times before it stops.\nOption C: The engineering team can ensure \nOption D: The query will still run, but only the individuals who are authorized to manage the refresh schedule will be able to stop it.\nE-Answer \nTherefore, the correct answer is that the engineering team can set the query’s refresh schedule to end on a certain date in the query scheduler to ensure the query does not cost the organization any money beyond the first week of the project’s release.","comments":[{"upvote_count":"1","poster":"ashubhar09","content":"Refresh schedule doesn't have any option to expire. So E is not correct option. https://docs.databricks.com/en/sql/user/queries/schedule-query.html","comment_id":"1049093","timestamp":"1697832480.0"}],"comment_id":"946530"},{"timestamp":"1688357940.0","content":"Answer is E\nhttps://docs.databricks.com/sql/user/queries/schedule-query.html#schedule-a-query","poster":"LANDIS","comment_id":"941418","upvote_count":"2"},{"upvote_count":"2","comment_id":"912077","poster":"chays","timestamp":"1685622240.0","content":"Selected Answer: C\nagree with BigDaddyAus"},{"comment_id":"882494","poster":"Tickxit","content":"Selected Answer: C\nI agree with BigDaddyAus, I don't see any option to end the query scheduler.","upvote_count":"2","timestamp":"1682590200.0"},{"comment_id":"862015","timestamp":"1680692940.0","poster":"4be8126","content":"Selected Answer: E\nThe correct answer is E. They can set the query's refresh schedule to end on a certain date in the query scheduler.\n\nDatabricks SQL supports a query scheduler that enables users to schedule SQL queries to run at defined intervals. By default, scheduled queries run indefinitely. However, users can configure the scheduler to stop running queries at a specific time or after a specific number of runs. In this scenario, the engineering team can set the query's refresh schedule to end on a certain date, ensuring that the query does not run beyond the first week of the project's release and potentially cost the organization more money.","upvote_count":"4"}]},{"id":"dgP24CtMews8UDvFtvEQ","answer_description":"","answer_images":[],"choices":{"A":"They can increase the cluster size of the SQL endpoint.","D":"They can turn on the Serverless feature for the SQL endpoint.","E":"They can turn on the Serverless feature for the SQL endpoint and change the Spot Instance Policy to “Reliability Optimized.”","C":"They can turn on the Auto Stop feature for the SQL endpoint.","B":"They can increase the maximum bound of the SQL endpoint’s scaling range."},"answers_community":["B (57%)","A (36%)","6%"],"isMC":true,"question_id":103,"topic":"1","answer":"B","unix_timestamp":1680456240,"question_images":[],"discussion":[{"comment_id":"1000909","content":"Answer is B.\nAccording to databricks documentation:\n-Sequentially -> Increase cluster size\n-Concurrent --> Scale out cluster","poster":"damaldon","upvote_count":"31","timestamp":"1694027160.0"},{"comment_id":"1064700","upvote_count":"16","timestamp":"1699351860.0","poster":"mokrani","content":"Answer B is correct\n For those who's selected the same answer as the question 40 in the Databricks exam training, be careful becaue it's quite different:\n- Here the question is about simultaneously runs -> Scale Out clusters (involves adding more clusters)\n- In the Databricks exam training, the question is about \"sequentially run queries\" -> Scale Up (increasing the size of the nodes)\n\nPleas refer to the this accepted answer\nhttps://community.databricks.com/t5/data-engineering/sequential-vs-concurrency-optimization-questions-from-query/td-p/36696"},{"timestamp":"1736930520.0","poster":"andie123","upvote_count":"1","content":"Selected Answer: A\nWhen many users are running small queries simultaneously on a SQL warehouse (prior: endpoint), the database can become overloaded, causing slow query execution times. By increasing the clus\u0002ter size of the SQL warehouse, the database can handle more simultaneous queries, resulting in faster query execution times. -> A","comment_id":"1340745"},{"content":"Selected Answer: B\nThe issue described is related to query latency when multiple users are running queries simultaneously, all using the same SQL endpoint. This often leads to contention for resources, causing delays in query processing. To address this, the maximum scaling range of the SQL endpoint can be increased, which allows the endpoint to dynamically scale and handle more concurrent queries by adding more resources (e.g., additional nodes) as needed.\n\nIn Databricks SQL, SQL endpoints can be scaled horizontally (adding more nodes) to better handle concurrency. By increasing the maximum scaling range, the endpoint will be able to scale more aggressively during periods of high load, improving query performance for concurrent users.","upvote_count":"1","comment_id":"1314215","poster":"806e7d2","timestamp":"1731962340.0"},{"poster":"MohdAltaf19","comment_id":"1287501","upvote_count":"2","content":"Correct Answers B\nThrough put > Sequential > Scale Up\nPerformance > Concurrent > Scale Out","timestamp":"1726965180.0"},{"content":"B is correct because increasing the maximum bound of the SQL endpoint’s scaling range allows the endpoint to handle a larger number of queries by automatically scaling up the resources (e.g., adding more clusters). This approach addresses the issue of slow queries due to high concurrent usage, as more resources will become available to handle the increased load from simultaneous queries.","poster":"7a22144","upvote_count":"2","timestamp":"1723792740.0","comment_id":"1266887"},{"poster":"benni_ale","content":"Selected Answer: B\nsimultaneously probably means concurrently so scaling out the cluster is better","comment_id":"1203804","upvote_count":"1","timestamp":"1714366740.0"},{"timestamp":"1711972140.0","comment_id":"1187388","content":"Selected Answer: B\nB is correct","poster":"sakis213","upvote_count":"1"},{"comment_id":"1145253","timestamp":"1707456060.0","poster":"niharam2021","content":"A data analysis team has noticed that their Databricks SQL queries are running too slowly when connected to their always-on SQL endpoint. They claim that this issue is present when many members of the team are running small queries simultaneously4","upvote_count":"2"},{"content":"Answer is A , Q40 -- https://files.training.databricks.com/assessments/practice-exams/PracticeExam-DataEngineerAssociate.pdf","timestamp":"1706770860.0","upvote_count":"3","comments":[{"upvote_count":"1","comment_id":"1358143","poster":"avidlearner","timestamp":"1739856540.0","content":"In that Question they mention that the endpoint is not being used by any other user, which means it's a problem of scaling up, because queries from a single user are not performing which means it needs more processing power(vertical scaling). Hence the approach there would be to increase the cluster size, but in the above question the problem is there are several small queries run by multiple users, problem of concurrency which requires scaling out the cluster. In sql endpoint configuration , Scaling option you can mention min and max clusters. Which is a way to scale out your cluster by adding more units."},{"poster":"6aa83ae","upvote_count":"1","comment_id":"1280268","content":"differenct question","timestamp":"1725782520.0"},{"timestamp":"1707343920.0","upvote_count":"2","poster":"K_yamini","content":"the question on Practice set is slightly different if you look closely :-In the first scenario, the data analyst notes slow query performance for sequentially run queries on a SQL endpoint that isn't shared with other users. This suggests that the problem may be related to the configuration or performance of the SQL endpoint itself rather than contention with other users.\n\nIn the second scenario, the data analysis team experiences slow query performance when multiple team members are running queries simultaneously on the same SQL endpoint. This indicates potential resource contention or limitations on the SQL endpoint when handling concurrent queries from multiple users.\n\nGiven these differences, the approaches to address the issues may also differ:","comment_id":"1143855"}],"comment_id":"1137349","poster":"agAshish"},{"poster":"Nika12","comment_id":"1133119","timestamp":"1706339640.0","content":"Selected Answer: B\nJust got 100% on the exam. B was correct. Also, here is the link to good explanation:\nhttps://docs.databricks.com/en/compute/cluster-config-best-practices.html","upvote_count":"5"},{"timestamp":"1705261080.0","poster":"Ody__","comment_id":"1122783","upvote_count":"1","content":"Selected Answer: A\nA is correct"},{"comment_id":"1122137","upvote_count":"2","content":"Selected Answer: A\ncorrect answer is A\nQuestion 40: https://files.training.databricks.com/assessments/practice-exams/PracticeExam-DataEngineerAssociate.pdf","timestamp":"1705189380.0","poster":"Ody__","comments":[{"timestamp":"1735338780.0","poster":"AdamNowak","content":"the question is about concurrent small queries this one in pdf is about sequential","upvote_count":"1","comment_id":"1332661"},{"comment_id":"1282742","upvote_count":"1","content":"Completely different question","timestamp":"1726158180.0","poster":"CommanderBigMac"}]},{"poster":"SerGrey","content":"Selected Answer: B\nB is correct","comment_id":"1117096","timestamp":"1704754620.0","upvote_count":"2"},{"timestamp":"1702392420.0","poster":"nedlo","content":"Selected Answer: B\nits B because its \"simultanously by many users\" so you have to scale it horizontally by increasing number of nodes : https://community.databricks.com/t5/data-engineering/sequential-vs-concurrency-optimization-questions-from-query/td-p/36696","comment_id":"1094629","upvote_count":"3"},{"poster":"pc1337xd","timestamp":"1699881600.0","upvote_count":"5","comment_id":"1069328","content":"Selected Answer: B\nIssues occur when too many users are running queries at the same time -> Increase scaling so more clusters handle the queries"},{"upvote_count":"2","content":"Selected Answer: B\nIncreasing cluster size is for vertical scalability of query execution, while scaling out cluster is for horizontal scalability of query execution","poster":"god_father","comment_id":"1057251","timestamp":"1698627060.0"},{"upvote_count":"2","comment_id":"1008949","timestamp":"1694845260.0","content":"The correct answer is B\n(we can check this under databricks sql WH tool tip option. It is clearly mentioend that scaling is used to improve query \"LATANCY\")","poster":"saikot"},{"poster":"vctrhugo","timestamp":"1693780620.0","upvote_count":"1","comment_id":"998009","content":"Selected Answer: A\nA. They can increase the cluster size of the SQL endpoint.\n\nTo improve the latency of the team's queries when many members are running small queries simultaneously, you can increase the cluster size of the SQL endpoint. Increasing the cluster size allocates more compute resources to handle query execution, which can help reduce query execution times and improve overall performance, especially during periods of high query concurrency.\n\nOption B refers to adjusting scaling settings, which can also be beneficial, but increasing the cluster size (Option A) directly allocates more resources, making it a more direct approach to improving query performance.\n\nOptions C, D, and E relate to different features and configurations (Auto Stop, Serverless, and Spot Instance Policy), but they may not directly address the issue of improving query latency during high concurrency, which is the primary concern in this scenario."},{"upvote_count":"1","poster":"[Removed]","timestamp":"1693324200.0","comment_id":"993232","content":"Selected Answer: A\nagree with @AndreFR"},{"comment_id":"985481","upvote_count":"5","content":"Selected Answer: A\nquestion 40 in the official databricks training exam : https://files.training.databricks.com/assessments/practice-exams/PracticeExam-DataEngineerAssociate.pdf","comments":[{"comments":[{"content":"I agree, Answer A is incorrect. Correct answer is B, because : The key is simultanously. The autoscaling is triggered by jobs sitting in the queue, so databricks will increase number of workers because there is a queue. If queries were running sequencially, there wouldn’t be queue so increasing the cluster size would be the best choice.","upvote_count":"2","timestamp":"1703037240.0","comment_id":"1101123","poster":"AndreFR"}],"content":"but the question is different:\n\"is affecting all of their sequentially run queries.\"","timestamp":"1695250020.0","poster":"ezeik","comment_id":"1012646","upvote_count":"4"}],"poster":"AndreFR","timestamp":"1692489840.0"},{"timestamp":"1690749360.0","content":"Selected Answer: B\nhttps://community.databricks.com/t5/data-engineering/when-to-increase-maximum-bound-vs-when-to-increase-cluster-size/m-p/27880","poster":"miraFlores","upvote_count":"3","comment_id":"967498"},{"timestamp":"1689030000.0","comment_id":"948438","poster":"mehroosali","content":"Selected Answer: A\nsimilar question on official practice questions (Q40), based on that answer its A.","upvote_count":"4"},{"comments":[{"comment_id":"948391","poster":"Atnafu","upvote_count":"2","timestamp":"1689023700.0","content":"E IS NOT ANSWER\nhttps://docs.gcp.databricks.com/sql/admin/create-sql-warehouse.html#:~:text=Reliability%20Optimized%20uses%20only%20on,and%20dashboards%20against%20upcoming%20changes.","comments":[{"timestamp":"1689023760.0","content":"B IS ANSWER","poster":"Atnafu","comment_id":"948392","upvote_count":"2"}]},{"content":"The other options are not correct:\nA:Increasing the cluster size of the SQL endpoint will increase the number of nodes in the cluster, which can improve the latency of queries. However, this is a more expensive option than turning on the Serverless feature.\nB:Increasing the maximum bound of the SQL endpoint’s scaling range will allow the cluster to scale up to a larger size, which can improve the latency of queries. However, this is also a more expensive option than turning on the Serverless feature.\nC:Turning on the Auto Stop feature for the SQL endpoint will cause the cluster to be stopped when there is no activity. This can save money, but it will also increase the latency of queries.\nD:Turning on the Serverless feature for the SQL endpoint is a good option for improving the latency of queries. However, the Spot Instance Policy should also be set to “Reliability Optimized” to ensure that the endpoint is always available.","timestamp":"1688825400.0","poster":"Atnafu","upvote_count":"1","comment_id":"946542"}],"upvote_count":"2","comment_id":"946539","timestamp":"1688825400.0","content":"E. \nHere are the reasons why:\nServerless feature allows Databricks to automatically scale the cluster up and down based on the workload. This can help to improve the latency of queries, especially when many small queries are running simultaneously.\nSpot Instance Policy determines how Databricks uses Spot Instances for serverless SQL endpoints. The “Reliability Optimized” Spot Instance Policy is a good choice for SQL endpoints that require high availability.","poster":"Atnafu"},{"content":"If the queries are running sequentially then scale up (increase the size of the cluster from 2x small to 4x large)\nIf the queries are running concurrently or with many users then scale out (add more clusters. Increase the SQL endpoints scaling range)","comment_id":"904468","timestamp":"1684805400.0","upvote_count":"3","poster":"NavalYemul"},{"poster":"Majjjj","upvote_count":"4","comment_id":"889138","content":"Selected Answer: B\nOption B is the correct answer. The engineering team can set the query’s refresh schedule to end after a certain number of refreshes to ensure that it does not run and cost the organization any money beyond the first week of the project’s release. By setting a limit on the number of refreshes, the query will stop running automatically once the limit is reached. This approach allows the team to monitor the performance of the project for the first week with frequent updates, but also ensures that the query does not consume resources unnecessarily after that period. Options A, C, D, and E are incorrect as they do not provide a solution to the problem of controlling the query's runtime cost.","timestamp":"1683172740.0","comments":[{"content":"The question never mentions cost","upvote_count":"1","timestamp":"1683657900.0","poster":"Redwings538","comment_id":"893364","comments":[{"content":"it's for question 38, I mistakenly written here and couldn't find delete option here","upvote_count":"1","timestamp":"1683845460.0","comment_id":"895453","poster":"Majjjj"}]}]},{"comment_id":"887680","upvote_count":"2","poster":"pargit35","timestamp":"1683045060.0","content":"i think b"},{"poster":"TC007","comment_id":"867553","content":"Selected Answer: A\nA: increase the cluster size of the SQL endpoint.\n\nWhen many users are running small queries simultaneously on a SQL endpoint, the database can become overloaded, causing slow query execution times. By increasing the cluster size of the SQL endpoint, the database can handle more simultaneous queries, resulting in faster query execution times.","upvote_count":"2","timestamp":"1681235340.0"},{"content":"Option B","poster":"sdas1","upvote_count":"1","comment_id":"865312","timestamp":"1681020480.0"},{"poster":"4be8126","upvote_count":"3","timestamp":"1680693120.0","content":"Selected Answer: D\nD. They can turn on the Serverless feature for the SQL endpoint.\n\nThe issue with the always-on SQL endpoint is that it may not be optimized for handling many small queries simultaneously, which can lead to slow query performance. By turning on the Serverless feature for the SQL endpoint, the team can take advantage of a serverless compute model that scales automatically to meet the team’s query demands, providing them with more compute resources when they need it and only paying for what they use. This feature can help improve the latency of the team’s queries without increasing the cluster size or maximum bound of the SQL endpoint.","comments":[{"content":"I believe this explanation is correct, Serverless feature will work as the queries are run concurrently and not sequentially.","upvote_count":"2","comment_id":"896613","poster":"prasioso","timestamp":"1683976080.0"}],"comment_id":"862019"},{"timestamp":"1680582960.0","poster":"knivesz","content":"LA respuesta es B, ya que corren simultaneamente, por tal motivo se debe incremental scale out","upvote_count":"1","comment_id":"860621"},{"comment_id":"859164","timestamp":"1680456240.0","poster":"XiltroX","comments":[{"upvote_count":"5","comment_id":"860101","timestamp":"1680537360.0","content":"\"The question is looking to test your ability to know how to scale a SQL Endpoint(SQL Warehouse) and you have to look for cue words or need to understand if the queries are running sequentially or concurrently. if the queries are running sequentially then scale up(Size of the cluster from 2X-Small to 4X-Large) if the queries are running concurrently or with more users then scale out(add more clusters).\"","poster":"t30730","comments":[{"upvote_count":"1","comment_id":"862216","content":"Thanks for the clarification","timestamp":"1680706920.0","poster":"XiltroX"},{"upvote_count":"2","content":"BTW, this exact question appears in the practice exam on the Databricks academy website. In it, its option A (increase cluster size). Please refer to it if you want more clarification.","poster":"XiltroX","timestamp":"1680732840.0","comment_id":"862508","comments":[{"timestamp":"1683093120.0","content":"the question is the practice exam talks about sequently queries not concurrency","upvote_count":"2","poster":"pargit35","comment_id":"888195"},{"comment_id":"896611","content":"The one in the practice exam is about sequentially run queries. In that case, there is no query queue and increase the cluster size would help. The use case in this question is different, here they are talking about small simultaneously run queries i.e. concurrently","timestamp":"1683975780.0","upvote_count":"2","poster":"prasioso"}]},{"poster":"pargit35","upvote_count":"1","content":"then it should be b because when you increase the max bound you can add more clusters to the warehouse and run additional queries.\nwhen the queries are running concurrently then you need to add more clusters","comment_id":"888194","timestamp":"1683093060.0"}]}],"upvote_count":"1","content":"B is the wrong answer. The only way to solve this issue in the \"always-on\" SQL endpoint is to increase the cluster size. So the right choice is A."}],"answer_ET":"B","timestamp":"2023-04-02 19:24:00","question_text":"A data analysis team has noticed that their Databricks SQL queries are running too slowly when connected to their always-on SQL endpoint. They claim that this issue is present when many members of the team are running small queries simultaneously. They ask the data engineering team for help. The data engineering team notices that each of the team’s queries uses the same SQL endpoint.\nWhich of the following approaches can the data engineering team use to improve the latency of the team’s queries?","exam_id":162,"url":"https://www.examtopics.com/discussions/databricks/view/104898-exam-certified-data-engineer-associate-topic-1-question-39/"},{"id":"uAAwwhxaKBTI8TAsD6ni","timestamp":"2023-04-01 15:32:00","url":"https://www.examtopics.com/discussions/databricks/view/104733-exam-certified-data-engineer-associate-topic-1-question-4/","answer":"D","exam_id":162,"question_id":104,"answer_description":"","unix_timestamp":1680355920,"answers_community":["D (100%)"],"answer_images":[],"topic":"1","question_text":"Which of the following benefits of using the Databricks Lakehouse Platform is provided by Delta Lake?","question_images":[],"discussion":[{"comment_id":"997865","poster":"vctrhugo","upvote_count":"13","content":"Selected Answer: D\nD. The ability to support batch and streaming workloads\n\nDelta Lake is a key component of the Databricks Lakehouse Platform that provides several benefits, and one of the most significant benefits is its ability to support both batch and streaming workloads seamlessly. Delta Lake allows you to process and analyze data in real-time (streaming) as well as in batch, making it a versatile choice for various data processing needs.\n\nWhile the other options may be benefits or capabilities of Databricks or the Lakehouse Platform in general, they are not specifically associated with Delta Lake.","timestamp":"1693764720.0"},{"poster":"Basha1996","content":"Selected Answer: D\nD. The ability to support batch and streaming workloads\n\nAdding features such as ACID Properties are allowed which eliminate the drawbacks on DW and Data lake.","upvote_count":"1","comment_id":"1362817","timestamp":"1740717180.0"},{"comment_id":"1339008","timestamp":"1736553240.0","poster":"Tedet","content":"Selected Answer: D\nThe ability to support batch and streaming workloads - Key feature of lakehouse","upvote_count":"1"},{"timestamp":"1724861160.0","content":"Selected Answer: D\nD is correct","comment_id":"1274180","poster":"afzalmp40","upvote_count":"1"},{"timestamp":"1723102620.0","upvote_count":"1","comment_id":"1262385","content":"Selected Answer: D\nD. The ability to support batch and streaming workloads","poster":"80370eb"},{"timestamp":"1717965780.0","upvote_count":"1","poster":"mascarenhaslucas","comment_id":"1227523","content":"Selected Answer: D\nThe answer is D!"},{"comment_id":"1177167","poster":"Itmma","upvote_count":"2","timestamp":"1710840720.0","content":"Selected Answer: D\nD is correct"},{"comment_id":"1028756","content":"Selected Answer: D\nAnswer is D","timestamp":"1696848240.0","poster":"VijayKula","upvote_count":"1"},{"content":"Selected Answer: D\nCorrect and D","timestamp":"1695697680.0","poster":"KalavathiP","upvote_count":"1","comment_id":"1017339"},{"comment_id":"941033","poster":"nb1000","content":"D is correct","upvote_count":"1","timestamp":"1688313360.0"},{"content":"Selected Answer: D\nDelta Lake supports both Batch & Stream workloads","comment_id":"863838","timestamp":"1680869760.0","upvote_count":"4","poster":"Data_4ever"},{"upvote_count":"4","content":"Selected Answer: D\nRespuesta correcta es D","poster":"knivesz","comment_id":"860277","timestamp":"1680549240.0"},{"timestamp":"1680503940.0","upvote_count":"3","content":"Selected Answer: D\noption D","poster":"surrabhi_4","comment_id":"859602"},{"comment_id":"857955","poster":"XiltroX","upvote_count":"3","timestamp":"1680355920.0","content":"D is the right answer\nhttps://learn.microsoft.com/en-us/azure/databricks/delta/"}],"isMC":true,"answer_ET":"D","choices":{"A":"The ability to manipulate the same data using a variety of languages","C":"The ability to set up alerts for query failures","E":"The ability to distribute complex data operations","D":"The ability to support batch and streaming workloads","B":"The ability to collaborate in real time on a single notebook"}},{"id":"T5CAvKlX0QEteNkjSQKF","discussion":[{"upvote_count":"11","poster":"4be8126","comment_id":"862022","timestamp":"1680693360.0","content":"Selected Answer: C\nThe data engineer can use the Auto Stop feature to minimize the total running time of the SQL endpoint used in the refresh schedule of their dashboard. The Auto Stop feature allows the SQL endpoint to automatically shut down when there are no active connections, which will minimize the total running time of the SQL endpoint. By scheduling the dashboard to refresh once per day, the SQL endpoint will only be running for a short period of time each day, which will minimize the total running time and reduce costs."},{"content":"Why it can't be B ? . They can set up the dashboard’s SQL endpoint to be serverless. ? they can use a serverless endpoint and it will only be active when required.","timestamp":"1701387240.0","comments":[{"comment_id":"1308679","poster":"datatrigger","content":"Yes, B makes sense as well in my opinion.","upvote_count":"1","comments":[{"comment_id":"1358146","content":"because here your workload is know, server less is more suitable for unpredictable workload. Also cost consideration.","poster":"avidlearner","upvote_count":"1","timestamp":"1739856900.0"}],"timestamp":"1731056280.0"}],"upvote_count":"5","poster":"mokrani","comment_id":"1084835"},{"poster":"Khaled999","upvote_count":"1","timestamp":"1743000900.0","content":"Selected Answer: C\nc IS CORRECT","comment_id":"1410442"},{"upvote_count":"2","timestamp":"1723180620.0","content":"Selected Answer: C\nThe Auto Stop feature ensures that the SQL endpoint will automatically shut down when not in use, which helps in reducing unnecessary running time and associated costs. The endpoint will only be running when it's needed for refreshing the dashboard.","poster":"80370eb","comment_id":"1262774"},{"content":"Selected Answer: C\nC is correct","upvote_count":"1","timestamp":"1704754800.0","poster":"SerGrey","comment_id":"1117099"},{"poster":"awofalus","content":"Selected Answer: C\ncorrect : C","timestamp":"1699436040.0","comment_id":"1065493","upvote_count":"1"},{"upvote_count":"1","poster":"vikas555","timestamp":"1698650580.0","comment_id":"1057426","content":"C. They can turn on the Auto Stop feature for the SQL endpoint."},{"timestamp":"1693780800.0","content":"Selected Answer: C\nC. They can turn on the Auto Stop feature for the SQL endpoint.\n\nTo minimize the total running time of the SQL endpoint used in the refresh schedule of their dashboard while ensuring that it only runs when necessary, the data engineer can turn on the Auto Stop feature for the SQL endpoint. This feature will automatically stop the SQL endpoint when it is idle for a specified period, reducing costs by avoiding unnecessary running time.\n\nOption C allows you to efficiently manage the SQL endpoint's lifecycle, ensuring it's active only when needed, which aligns with the goal of minimizing running time and associated costs.\n\nOption B (setting the dashboard's SQL endpoint to be serverless) can also be a valid approach, as it allows the SQL endpoint to be provisioned on-demand and incurs costs only when queries are executed. However, it depends on the specific requirements of your dashboard and queries.\n\nOptions A, D, and E do not directly address the goal of minimizing the SQL endpoint's running time while ensuring it runs when necessary.","comment_id":"998011","poster":"vctrhugo","upvote_count":"2"},{"comment_id":"992321","content":"C is correct.","poster":"ArindamNath","upvote_count":"1","timestamp":"1693234740.0"},{"timestamp":"1692525420.0","content":"Selected Answer: C\nhttps://docs.databricks.com/en/clusters/clusters-manage.html#automatic-termination","comment_id":"985700","upvote_count":"1","poster":"AndreFR"},{"comment_id":"946547","content":"C\nThe Auto Stop feature automatically terminates the compute resources (cluster) associated with the SQL endpoint after a specified period of inactivity. By enabling this feature, the SQL endpoint will be automatically stopped when it is no longer needed, reducing the total running time and associated costs.","upvote_count":"2","poster":"Atnafu","timestamp":"1688825640.0"},{"content":"Selected Answer: C\nCorrect answer","timestamp":"1680456300.0","poster":"XiltroX","upvote_count":"4","comment_id":"859167"}],"topic":"1","question_text":"A data engineer wants to schedule their Databricks SQL dashboard to refresh once per day, but they only want the associated SQL endpoint to be running when it is necessary.\nWhich of the following approaches can the data engineer use to minimize the total running time of the SQL endpoint used in the refresh schedule of their dashboard?","answer":"C","url":"https://www.examtopics.com/discussions/databricks/view/104899-exam-certified-data-engineer-associate-topic-1-question-40/","isMC":true,"answers_community":["C (100%)"],"choices":{"D":"They can reduce the cluster size of the SQL endpoint.","E":"They can ensure the dashboard’s SQL endpoint is not one of the included query’s SQL endpoint.","C":"They can turn on the Auto Stop feature for the SQL endpoint.","A":"They can ensure the dashboard’s SQL endpoint matches each of the queries’ SQL endpoints.","B":"They can set up the dashboard’s SQL endpoint to be serverless."},"unix_timestamp":1680456300,"question_id":105,"exam_id":162,"question_images":[],"timestamp":"2023-04-02 19:25:00","answer_ET":"C","answer_description":"","answer_images":[]}],"exam":{"isBeta":false,"isImplemented":true,"lastUpdated":"12 Apr 2025","numberOfQuestions":169,"id":162,"provider":"Databricks","isMCOnly":true,"name":"Certified Data Engineer Associate"},"currentPage":21},"__N_SSP":true}