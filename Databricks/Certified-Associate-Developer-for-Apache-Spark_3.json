{"pageProps":{"questions":[{"id":"hB7tq8KOLLcCEjih6zTf","answer_ET":"E","question_text":"The code block shown below should cache DataFrame storesDF only in Spark's memory. Choose the response that correctly fil ls in the numbered blanks within the code block to complete this task.\n\nCode block:\n\n__1__.__2__(__3__).count()","isMC":true,"question_id":11,"question_images":[],"choices":{"A":"1. storesDF\n2. cache\n3. StorageLevel.MEMORY_ONLY","C":"1. storesDF\n2. cache\n3. Nothing","D":"1. storesDF\n2. persist\n3. Nothing","B":"1. storesDF\n2. storageLevel\n3. cache","E":"1. storesDF\n2. persist\n3. StorageLevel.MEMORY_ONLY"},"discussion":[{"content":"E: df.persist(StorageLevel.MEMORY_ONLY).count()","timestamp":"1732726680.0","poster":"Ahmadkt","upvote_count":"2","comment_id":"1081803"}],"unix_timestamp":1701104280,"exam_id":161,"url":"https://www.examtopics.com/discussions/databricks/view/127342-exam-certified-associate-developer-for-apache-spark-topic-1/","answers_community":[],"answer":"E","answer_description":"","topic":"1","answer_images":[],"timestamp":"2023-11-27 17:58:00"},{"id":"o519QucRo6cIwQqzR9yA","answer_ET":"D","answer_images":[],"url":"https://www.examtopics.com/discussions/databricks/view/137749-exam-certified-associate-developer-for-apache-spark-topic-1/","answer_description":"","topic":"1","answers_community":["D (100%)"],"discussion":[{"timestamp":"1728045540.0","upvote_count":"3","poster":"SaiPavan10","comment_id":"1189317","content":"Selected Answer: D\nD is the right choice"},{"upvote_count":"2","comment_id":"1188004","content":"It s D","poster":"Sowwy1","timestamp":"1727870160.0"}],"question_text":"Which of the following code blocks returns a DataFrame containing a column month, an integer representation of the day of the year from column openDate from DataFrame storesDF.\n\nNote that column openDate is of type integer and represents a date in the UNIX epoch format – the number of seconds since midnight on January 1st, 1970.\n\nA sample of storesDF is displayed below:\n\n//IMG//\n\n\nCode block:\n\nstored.withColumn(“openTimestamp”, col(“openDate”).cast(__1__))\n.withColumn(__2__, __3__(__4__))","exam_id":161,"answer":"D","isMC":true,"question_images":["https://img.examtopics.com/certified-associate-developer-for-apache-spark/image13.png"],"unix_timestamp":1712058960,"choices":{"B":"1. “Timestamp”\n2. month\n3. “month”\n4. col(“openTimestamp”)","D":"1. “Timestamp”\n2. “month”\n3. month\n4. col(“openTimestamp”)","A":"1. “Data”\n2. month\n3. “month”\n4. “openTimestamp”","C":"1. “Timestamp”\n2. month\n3. getMonth\n4. col(“openTimestamp”)"},"question_id":12,"timestamp":"2024-04-02 13:56:00"},{"id":"xBwlOtq2vFlKgysF1RH3","topic":"1","exam_id":161,"question_id":13,"question_images":[],"answers_community":[],"url":"https://www.examtopics.com/discussions/databricks/view/116693-exam-certified-associate-developer-for-apache-spark-topic-1/","answer_images":[],"answer":"A","timestamp":"2023-07-28 19:40:00","discussion":[{"timestamp":"1722188400.0","content":"Explanation:\nIn cluster mode, the driver runs on the master node, while in client mode, the driver runs on a virtual machine in the cloud.\n\nThis is wrong, since execution modes do not specify whether workloads are run in the cloud or on-premise.\n\nIn cluster mode, each node will launch its own executor, while in client mode, executors will exclusively run on the client machine.\n\nWrong, since in both cases executors run on worker nodes.\n\nIn cluster mode, the driver runs on the edge node, while the client mode runs the driver in a worker node.\n\nWrong C in cluster mode, the driver runs on a worker node. In client mode, the driver runs on the client machine.\n\nIn client mode, the cluster manager runs on the same host as the driver, while in cluster mode, the cluster manager runs on a separate node.\n\nNo. In both modes, the cluster manager is typically on a separate node C not on the same host as the driver. It only runs on the same host as the driver in local execution mode. More info: Learning Spark, 2nd Edition, Chapter 1, and Spark: The Definitive Guide, Chapter 15. ()","comment_id":"965727","upvote_count":"5","poster":"zozoshanky"}],"unix_timestamp":1690566000,"question_text":"Which of the following describes the difference between cluster and client execution modes?","choices":{"A":"The cluster execution mode runs the driver on a worker node within a cluster, while the client execution mode runs the driver on the client machine (also known as a gateway machine or edge node).","E":"The cluster execution mode distributes executors across worker nodes in a cluster, while the client execution mode submits a Spark job from a remote machine to be run on a remote, unconfigurable cluster.","C":"The cluster execution mode distributes executors across worker nodes in a cluster, while the client execution mode runs a Spark job entirely on one client machine.","D":"The cluster execution mode runs the driver on the cluster machine (also known as a gateway machine or edge node), while the client execution mode runs the driver on a worker node within a cluster.","B":"The cluster execution mode is run on a local cluster, while the client execution mode is run in the cloud."},"isMC":true,"answer_description":"","answer_ET":"A"},{"id":"KoDbObPSWv00ILG7CsP5","question_images":[],"unix_timestamp":1690998660,"answer":"A","exam_id":161,"question_id":14,"answers_community":["A (100%)"],"answer_ET":"A","answer_images":[],"answer_description":"","topic":"1","timestamp":"2023-08-02 19:51:00","discussion":[{"timestamp":"1732055040.0","content":"Selected Answer: A\nNot sure why C was selected as it's indicating INNER which is the the default for Dataframe.join and requires a string column name)","comment_id":"1314956","upvote_count":"1","poster":"58470e1"},{"content":"I don't see any error in the code other than a typo","comment_id":"1235572","timestamp":"1719084660.0","poster":"deadbeef38","upvote_count":"1"},{"content":"Selected Answer: A\nsince the default join is inner so key column should be \"StoreId\"","comment_id":"1189319","poster":"SaiPavan10","timestamp":"1712234460.0","upvote_count":"2"},{"comment_id":"1188006","timestamp":"1712059020.0","upvote_count":"2","poster":"Sowwy1","content":"A is correct"},{"content":"A is right","comment_id":"1138460","poster":"saryu","timestamp":"1706871780.0","upvote_count":"1"},{"poster":"newusername","comment_id":"1066591","timestamp":"1699553160.0","upvote_count":"2","content":"The answer (C) is just the most wrong that could have been here"},{"upvote_count":"1","content":"I think the question is corrupt. The most plausible answer is A, even though the column name is already presented as a string.","comments":[],"poster":"cookiemonster42","timestamp":"1690998660.0","comment_id":"970426"}],"url":"https://www.examtopics.com/discussions/databricks/view/117151-exam-certified-associate-developer-for-apache-spark-topic-1/","choices":{"B":"The key column storeId needs to be specified in an expression of both Data Frame columns like storesDF.storeId ===employeesDF.storeId.","A":"The key column storeId needs to be a string like “storeId”.","C":"The default argument to the joinType parameter is “inner” - an additional argument of “left” must be specified.","D":"There is no DataFrame.join() operation - DataFrame.merge() should be used instead.","E":"The key column storeId needs to be wrapped in the col() operation."},"question_text":"The code block shown below contains an error. The code block intended to return a new DataFrame that is the result of an inner join between DataFrame storesDF and DataFrame employeesDF on column storeId. Identify the error.\n\nCode block:\n\nStoresDF.join(employeesDF, Seq(\"storeId\")","isMC":true},{"id":"QQNGO2LqhtMUMbufIml1","topic":"1","exam_id":161,"question_id":15,"question_images":[],"answers_community":[],"url":"https://www.examtopics.com/discussions/databricks/view/137751-exam-certified-associate-developer-for-apache-spark-topic-1/","answer":"B","answer_images":[],"timestamp":"2024-04-02 13:58:00","discussion":[{"upvote_count":"2","comment_id":"1204827","poster":"Alucard069","timestamp":"1730436360.0","content":"Will option D work? I have never seen this way of accessing columns in a dataframe : \ndf(\"column\") , it should be either df.column or col(\"a.column\") [ considering a as an alias of df]"},{"comment_id":"1188007","upvote_count":"1","content":"I think it s B","timestamp":"1727870280.0","poster":"Sowwy1"}],"unix_timestamp":1712059080,"question_text":"Which of the following pairs of arguments cannot be used in DataFrame.join() to perform an inner join on two DataFrames, named and aliased with \"a\" and \"b\" respectively, to specify two key columns column1 and column2?","choices":{"C":"All of these options can be used to perform an inner join with two key columns.","A":"joinExprs = col(“a.column1”) === col(“b.column1”) and col(“a.column2”) === col(“b.column2”)","B":"usingColumns = Seq(col(“column1”), col(“column2”))","D":"joinExprs = storesDF(“column1”) === employeesDF(“column1”) and storesDF(“column2”) === employeesDF (“column2”)","E":"usingColumns = Seq(“column1”, “column2”)"},"isMC":true,"answer_description":"","answer_ET":"B"}],"exam":{"numberOfQuestions":185,"id":161,"provider":"Databricks","name":"Certified Associate Developer for Apache Spark","isBeta":false,"lastUpdated":"12 Apr 2025","isMCOnly":true,"isImplemented":true},"currentPage":3},"__N_SSP":true}