{"pageProps":{"questions":[{"id":"lXAaKfD2sYx87MBHTDF0","answer_description":"","answer_ET":"B","url":"https://www.examtopics.com/discussions/databricks/view/105312-exam-certified-data-engineer-associate-topic-1-question-1/","unix_timestamp":1680703920,"discussion":[{"poster":"prasioso","timestamp":"1683883860.0","comment_id":"895789","upvote_count":"10","content":"Databricks Lakehouse enables using data as the single source of truth. Duplicating data often results in data silos in organizations. Correct answer B."},{"upvote_count":"1","timestamp":"1736552640.0","content":"Selected Answer: B\nLakehouse - Single, unified platform for both analytical and data engineering workflows","poster":"Tedet","comment_id":"1339003"},{"timestamp":"1731770280.0","upvote_count":"1","comment_id":"1313098","poster":"NzmD","content":"Selected Answer: B\nCorrect answer is B."},{"upvote_count":"2","timestamp":"1731594060.0","poster":"806e7d2","comment_id":"1312053","content":"Selected Answer: B\nA data lakehouse is designed to integrate the benefits of data lakes and data warehouses by providing a single, unified platform for both analytical and data engineering workflows. By combining structured and unstructured data in one place, a lakehouse enables both data engineers and data analysts to access and work from the same source of truth. This eliminates data silos, reducing discrepancies in reports that can arise from each team working with different datasets or versions of data.\n\nWhile options A, D, and E describe some advantages that a data lakehouse might offer, they don’t directly address the issue of inconsistent reports. Option C is more about organizational structure than technical architecture."},{"upvote_count":"1","comment_id":"1305427","timestamp":"1730378940.0","poster":"Gusberg","content":"Selected Answer: B\nCorrect answer is: B. Both teams would use the same source of truth for their work"},{"content":"Selected Answer: B\nCLEAR ANSWER","poster":"gtriarhos","comment_id":"1289718","timestamp":"1727383380.0","upvote_count":"1"},{"content":"Selected Answer: B\nB is correct","comment_id":"1274178","upvote_count":"1","poster":"afzalmp40","timestamp":"1724861040.0"},{"content":"Selected Answer: B\nThe answer is B!","poster":"mascarenhaslucas","timestamp":"1717965420.0","comment_id":"1227517","upvote_count":"1"},{"timestamp":"1716377880.0","poster":"poo_san","upvote_count":"1","comment_id":"1215698","content":"Selected Answer: A\nB is correct"},{"comment_id":"1193427","poster":"bettermakeme","timestamp":"1712809800.0","content":"B is correct answer, I got 100%. all questions came from https://www.udemy.com/course/practice-exams-databricks-certified-data-engineer-associate-t/?couponCode=APR2024","upvote_count":"1"},{"content":"Selected Answer: B\nB is correct","upvote_count":"1","comment_id":"1177150","timestamp":"1710839280.0","poster":"Itmma"},{"timestamp":"1710839220.0","upvote_count":"1","content":"B is correct","poster":"Itmma","comment_id":"1177149"},{"timestamp":"1704446340.0","content":"Selected Answer: B\nB is correct","upvote_count":"1","poster":"shyemko","comment_id":"1114388"},{"content":"Selected Answer: B\nCorrect is B","timestamp":"1703431560.0","comment_id":"1104687","upvote_count":"1","poster":"SerGrey"},{"poster":"VijayKula","timestamp":"1696845960.0","content":"Selected Answer: B\nCorrect is B","comment_id":"1028729","upvote_count":"1"},{"timestamp":"1696340760.0","upvote_count":"1","poster":"oscar_nadie","content":"Selected Answer: B\nCorrect is B","comment_id":"1023990"},{"comment_id":"1017336","poster":"KalavathiP","content":"Selected Answer: B\nCorrect ans B","upvote_count":"1","timestamp":"1695697560.0"},{"timestamp":"1695623820.0","poster":"d_b47","upvote_count":"1","content":"Selected Answer: B\nBoth teams would use the same source of truth for their work","comment_id":"1016519"},{"timestamp":"1693984200.0","poster":"vpraja03","upvote_count":"4","comment_id":"1000323","content":"There are 2 versions in Databricks Certified Data Engineer Associate, which version we need to pick for this exam ?"},{"comment_id":"997855","poster":"vctrhugo","timestamp":"1693764300.0","upvote_count":"3","content":"B. Both teams would use the same source of truth for their work\n\nA data lakehouse is designed to unify the data engineering and data analysis architectures by integrating features of both data lakes and data warehouses. One of the key benefits of a data lakehouse is that it provides a common, centralized data repository (the \"lake\") that serves as a single source of truth for data storage and analysis. This allows both data engineering and data analysis teams to work with the same consistent data sets, reducing discrepancies and ensuring that the reports generated by both teams are based on the same underlying data.\n\nOption B addresses the issue of data consistency and alignment between the two teams, which is a common challenge in organizations with separate data engineering and data analysis architectures. By using the same source of truth, the data lakehouse helps alleviate this issue and promotes better collaboration and data integrity."},{"timestamp":"1687255920.0","poster":"james_donquixote","upvote_count":"2","comment_id":"928338","content":"Selected Answer: B\nCorrect letter B"},{"content":"Selected Answer: B\nUnity Catalog in Databricks helps to eliminate Data Silos in an organization by having one single source of truth data.","poster":"Data_4ever","upvote_count":"4","comment_id":"863826","timestamp":"1680869460.0"},{"comment_id":"862177","timestamp":"1680703920.0","poster":"XiltroX","upvote_count":"1","content":"Selected Answer: B\nCorrect answer is B"}],"answer_images":[],"choices":{"B":"Both teams would use the same source of truth for their work","A":"Both teams would autoscale their work as data size evolves","C":"Both teams would reorganize to report to the same department","E":"Both teams would respond more quickly to ad-hoc requests","D":"Both teams would be able to collaborate on projects in real-time"},"timestamp":"2023-04-05 16:12:00","isMC":true,"question_images":[],"question_id":1,"exam_id":162,"answers_community":["B (96%)","4%"],"question_text":"A data organization leader is upset about the data analysis team’s reports being different from the data engineering team’s reports. The leader believes the siloed nature of their organization’s data engineering and data analysis architectures is to blame.\nWhich of the following describes how a data lakehouse could alleviate this issue?","topic":"1","answer":"B"},{"id":"F7tlPMBJZ6GDtGuOpfb6","answer_description":"","isMC":true,"timestamp":"2023-04-01 15:54:00","discussion":[{"upvote_count":"12","poster":"Majjjj","timestamp":"1683159900.0","comment_id":"889063","content":"Selected Answer: B\nWhile both Databricks Notebooks versioning and Databricks Repos allow for version control of code, Databricks Repos provides the additional benefit of supporting the use of multiple branches. This allows for multiple versions of a notebook or project to be developed in parallel, facilitating collaboration among team members and simplifying the process of merging changes into a single main branch."},{"comment_id":"1275698","upvote_count":"1","timestamp":"1725125520.0","content":"I read, Legacy notebook Git integration support was removed on January 31st, 2024. \nso , it means the git notebook integration not supported now. AM I correct?","poster":"md_sultan"},{"timestamp":"1723103160.0","comment_id":"1262392","upvote_count":"1","content":"Selected Answer: B\nB. Databricks Repos supports the use of multiple branches\n\nThis feature allows for more advanced version control and collaborative development workflows, enabling multiple branches for different features or experiments.","poster":"80370eb"},{"comment_id":"1203168","content":"Selected Answer: B\nb , multiple branches are not supported at all without a git integration and databricks repos have built in UI for governing such a thing","timestamp":"1714230060.0","upvote_count":"1","poster":"benni_ale"},{"content":"Selected Answer: B\nB is correct","comment_id":"1189111","timestamp":"1712209680.0","upvote_count":"1","poster":"benni_ale"},{"upvote_count":"1","timestamp":"1710841500.0","comment_id":"1177185","content":"Selected Answer: B\nB is correct","poster":"Itmma"},{"upvote_count":"1","comment_id":"1113189","timestamp":"1704321840.0","poster":"SerGrey","content":"Selected Answer: B\nCorrect answer is B"},{"content":"Selected Answer: B\nCorrect : B","timestamp":"1699360320.0","upvote_count":"1","comment_id":"1064778","poster":"awofalus"},{"timestamp":"1695697980.0","poster":"KalavathiP","content":"Selected Answer: B\nB is correct","comment_id":"1017348","upvote_count":"1"},{"poster":"vctrhugo","upvote_count":"3","timestamp":"1693765020.0","content":"Selected Answer: B\nB. Databricks Repos supports the use of multiple branches.\n\nAn advantage of using Databricks Repos over the built-in Databricks Notebooks versioning is the ability to work with multiple branches. Branching is a fundamental feature of version control systems like Git, which Databricks Repos is built upon. It allows you to create separate branches for different tasks, features, or experiments within your project. This separation helps in parallel development and experimentation without affecting the main branch or the work of other team members.\n\nBranching provides a more organized and collaborative development environment, making it easier to merge changes and manage different development efforts. While Databricks Notebooks versioning also allows you to track versions of notebooks, it may not provide the same level of flexibility and collaboration as branching in Databricks Repos.","comment_id":"997870"},{"upvote_count":"1","content":"B\nbuilt in databricks notebook versioning does not allow multiple branches.","poster":"hany_ds","timestamp":"1691776860.0","comment_id":"978872"},{"upvote_count":"2","content":"B\nAn advantage of using Databricks Repos over the Databricks Notebooks versioning is that Databricks Repos supports the use of multiple branches. With Databricks Repos, you can create and manage multiple branches of your codebase, enabling parallel development, collaboration, and the ability to work on different features or bug fixes simultaneously.","poster":"Atnafu","comment_id":"946763","timestamp":"1688853540.0"},{"poster":"Varma_Saraswathula","timestamp":"1682052540.0","content":"B. Databricks Repos supports the use of multiple branches","comment_id":"876197","upvote_count":"1"},{"poster":"sdas1","content":"Option B","upvote_count":"2","comment_id":"860624","timestamp":"1680583200.0"},{"timestamp":"1680506400.0","content":"Selected Answer: B\noption B","upvote_count":"2","comment_id":"859628","poster":"surrabhi_4"},{"timestamp":"1680357240.0","content":"Selected Answer: B\nCorrect answer is B","upvote_count":"2","poster":"XiltroX","comment_id":"857981"}],"question_text":"A data engineer needs to determine whether to use the built-in Databricks Notebooks versioning or version their project using Databricks Repos.\nWhich of the following is an advantage of using Databricks Repos over the Databricks Notebooks versioning?","topic":"1","exam_id":162,"unix_timestamp":1680357240,"answers_community":["B (100%)"],"answer":"B","answer_images":[],"answer_ET":"B","choices":{"C":"Databricks Repos allows users to revert to previous versions of a notebook","D":"Databricks Repos provides the ability to comment on specific changes","B":"Databricks Repos supports the use of multiple branches","A":"Databricks Repos automatically saves development progress","E":"Databricks Repos is wholly housed within the Databricks Lakehouse Platform"},"question_id":2,"question_images":[],"url":"https://www.examtopics.com/discussions/databricks/view/104744-exam-certified-data-engineer-associate-topic-1-question-10/"},{"id":"Nivbbemf6xtNU80QBVKM","question_images":[],"url":"https://www.examtopics.com/discussions/databricks/view/141232-exam-certified-data-engineer-associate-topic-1-question-100/","answer":"A","question_text":"A data engineer has been given a new record of data:\n\nid STRING = 'a1'\nrank INTEGER = 6\nrating FLOAT = 9.4\n\nWhich SQL commands can be used to append the new record to an existing Delta table my_table?","unix_timestamp":1716660780,"exam_id":162,"question_id":3,"timestamp":"2024-05-25 20:13:00","answer_ET":"A","topic":"1","discussion":[{"poster":"MDWPartners","content":"Repeated, correct.","comment_id":"1218488","upvote_count":"4","timestamp":"1732565580.0"}],"choices":{"D":"UPDATE VALUES ('a1', 6, 9.4) my_table","C":"UPDATE my_table VALUES ('a1', 6, 9.4)","B":"INSERT VALUES ('a1', 6, 9.4) INTO my_table","A":"INSERT INTO my_table VALUES ('a1', 6, 9.4)"},"answer_images":[],"answers_community":[],"isMC":true,"answer_description":""},{"id":"ptrq1JUozHIE9tFNLYdW","unix_timestamp":1716660780,"topic":"1","answer_images":[],"question_text":"A data engineer has realized that the data files associated with a Delta table are incredibly small. They want to compact the small files to form larger files to improve performance.\n\nWhich keyword can be used to compact the small files?","timestamp":"2024-05-25 20:13:00","discussion":[{"content":"Selected Answer: A\nOPTIMIZE to compact multiple small files into larger ones","comment_id":"1360190","poster":"Soori567","timestamp":"1740244740.0","upvote_count":"1"},{"poster":"kim32","timestamp":"1718729880.0","comment_id":"1232538","upvote_count":"2","content":"The OPTIMIZE command is used to compact small files into larger ones, which helps improve the performance of Delta Lake tables. It consolidates small files into fewer larger files to reduce the overhead associated with having many small files. This process is often referred to as \"compaction\" but the specific keyword in Databricks Delta Lake is OPTIMIZE."},{"content":"Repeated, correct.","comment_id":"1218490","timestamp":"1716660780.0","upvote_count":"1","poster":"MDWPartners"}],"answers_community":["A (100%)"],"exam_id":162,"question_images":[],"isMC":true,"choices":{"B":"VACUUM","C":"COMPACTION","D":"REPARTITION","A":"OPTIMIZE"},"answer_ET":"A","question_id":4,"answer_description":"","answer":"A","url":"https://www.examtopics.com/discussions/databricks/view/141233-exam-certified-data-engineer-associate-topic-1-question-101/"},{"id":"RUwDmePtTGCi3d7DRPat","answer_ET":"A","question_images":[],"url":"https://www.examtopics.com/discussions/databricks/view/142913-exam-certified-data-engineer-associate-topic-1-question-102/","exam_id":162,"question_id":5,"timestamp":"2024-06-25 15:10:00","answer_images":[],"answers_community":["A (50%)","C (50%)"],"question_text":"A data engineer wants to create a data entity from a couple of tables. The data entity must be used by other data engineers in other sessions. It also must be saved to a physical location.\n\nWhich of the following data entities should the data engineer create?","answer_description":"","isMC":true,"unix_timestamp":1719321000,"topic":"1","choices":{"A":"Table","C":"View","D":"Temporary view","B":"Function"},"answer":"A","discussion":[{"content":"Selected Answer: A\nYou can create a table using CTAS:\nCREATE TABLE AS\nSELECT\n...\nFROM\n...\nand the results will be saved to a physical location.","comment_id":"1387325","upvote_count":"1","timestamp":"1741682160.0","poster":"kowal02"},{"timestamp":"1740368100.0","upvote_count":"1","comment_id":"1360856","poster":"SrinivasR","content":"Selected Answer: C\ncorrect Answer is C View , as question say wants to create entity using couple of tables and that's needs to used by others, so i think Answer is C View."},{"upvote_count":"3","content":"VIEW will not be physically like Meterialized VIEW. Answer is Table","comment_id":"1290980","timestamp":"1727594580.0","poster":"Yuvazz"},{"comment_id":"1287511","timestamp":"1726969680.0","poster":"MohdAltaf19","upvote_count":"2","content":"Correct Answer is C\nAs View is persited they are physically stored and accessable across cluster even when restarted or detactched ."},{"comment_id":"1236917","poster":"Dip1994","timestamp":"1719321000.0","content":"A is the correct answer as the question is asking for physical location","upvote_count":"3"}]}],"exam":{"isMCOnly":true,"numberOfQuestions":169,"name":"Certified Data Engineer Associate","lastUpdated":"12 Apr 2025","isBeta":false,"id":162,"provider":"Databricks","isImplemented":true},"currentPage":1},"__N_SSP":true}