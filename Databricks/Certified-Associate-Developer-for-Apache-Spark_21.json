{"pageProps":{"questions":[{"id":"ireRCx64s8QkfM6Oasr6","timestamp":"2023-04-26 08:43:00","answer_description":"","exam_id":161,"answers_community":["B (100%)"],"question_id":101,"unix_timestamp":1682491380,"answer":"B","topic":"1","url":"https://www.examtopics.com/discussions/databricks/view/107538-exam-certified-associate-developer-for-apache-spark-topic-1/","discussion":[{"comment_id":"1253678","timestamp":"1721741040.0","upvote_count":"1","poster":"jds0","content":"Selected Answer: B\nAnswer is B but with a typo: \nSee code below (Spark 3.5.1):\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, cast\nfrom pyspark.sql.types import StringType\n\nspark = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n\ndata = [\n (0, 3, 20000, \"A\"),\n (1, 1, 50000, \"A\"),\n (2, 2, 70000, \"A\"),\n ]\nstoresDF = spark.createDataFrame(data, [\"storeID\", \"customerSatisfaction\", \"sqft\", \"division\"])\n\nstoresDF.withColumn(\"storeId\", col(\"storeId\").cast(StringType())).printSchema()\n# root\n# |-- storeId: string (nullable = true)\n# |-- customerSatisfaction: long (nullable = true)\n# |-- sqft: long (nullable = true)\n# |-- division: string (nullable = true)"},{"upvote_count":"2","comment_id":"1056509","poster":"DataEngine","timestamp":"1698538860.0","content":"Anwer is B but it has a typo"},{"upvote_count":"1","content":"cast is a method belongs to class pyspark.sql.column\ntherefore, A C E are wrong. it should be dataframe.column.cast() or col('col_name').cast()\nB is correct, with small typo","comment_id":"916479","timestamp":"1686070020.0","poster":"ZSun"},{"poster":"dduque10","upvote_count":"3","content":"Selected Answer: B\nAll answers are wrong because the first argument does not have the closing quotes :D, apart from that, it is B","comment_id":"898266","timestamp":"1684153500.0"},{"poster":"4be8126","upvote_count":"2","timestamp":"1682491380.0","content":"Selected Answer: B\nThe correct code block to return a new DataFrame from DataFrame storesDF where column storeId is of the type string is:\n\nstoresDF.withColumn(\"storeId\", col(\"storeId\").cast(StringType()))\nOption A has an extra quotation mark after \"storeId\" and is missing a closing parenthesis for the cast() function.\n\nOption B correctly uses the cast() function to change the data type, but has a typo where \"storeId\" is repeated inside the string argument for the withColumn() function.\n\nOption C is missing the col() function to reference the storeId column, and also has a typo with the closing parentheses for the cast() function.\n\nOption D correctly references the storeId column using col(), but has a typo with the quotation marks and parentheses.\n\nOption E has a syntax error where the cast() function is inside the quotation marks, and is also missing the col() function to reference the storeId column.\n\nTherefore, the correct answer is B.\n\nstoresDF.withColumn(\"storeId\", col(\"storeId\").cast(StringType()))","comment_id":"881193"}],"answer_ET":"B","choices":{"D":"storesDF.withColumn(\"storeId, col(storeId).cast(StringType)","A":"storesDF.withColumn(\"storeId, cast(col(\"storeId\"), StringType()))","C":"storesDF.withColumn(\"storeId, cast(storeId).as(StringType)","E":"storesDF.withColumn(\"storeId, cast(\"storeId\").as(StringType()))","B":"storesDF.withColumn(\"storeId, col(\"storeId\").cast(StringType()))"},"answer_images":[],"question_text":"Which of the following code blocks returns a new DataFrame from DataFrame storesDF where column storeId is of the type string?","question_images":[],"isMC":true},{"id":"8mOfFcsyKkQChkcxyFW7","answer_ET":"A","question_images":[],"topic":"1","question_id":102,"choices":{"E":"storesDF.withColumn(col(\"employeesPerSqft\"), col(\"numberOfEmployees\") / col(\"sqft\"))","C":"storesDF.select(\"employeesPerSqft\", \"numberOfEmployees\" / \"sqft\")","D":"storesDF.select(\"employeesPerSqft\", col(\"numberOfEmployees\") / col(\"sqft\"))","B":"storesDF.withColumn(\"employeesPerSqft\", \"numberOfEmployees\" / \"sqft\")","A":"storesDF.withColumn(\"employeesPerSqft\", col(\"numberOfEmployees\") / col(\"sqft\"))"},"exam_id":161,"question_text":"Which of the following code blocks returns a new DataFrame with a new column employeesPerSqft that is the quotient of column numberOfEmployees and column sqft, both of which are from DataFrame storesDF? Note that column employeesPerSqft is not in the original DataFrame storesDF.","answer_images":[],"answer_description":"","timestamp":"2023-04-26 08:48:00","isMC":true,"url":"https://www.examtopics.com/discussions/databricks/view/107539-exam-certified-associate-developer-for-apache-spark-topic-1/","discussion":[{"comment_id":"1253681","upvote_count":"2","content":"Selected Answer: A\nAnswer: A\nAll other options do not work\n\nCode:\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col\n\nspark = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n\ndata = [\n (0, 3, 20, \"A\"),\n (1, 1, 50, \"A\"),\n (2, 2, 70, \"A\"),\n ]\nstoresDF = spark.createDataFrame(data, [\"storeID\", \"numberOfEmployees\", \"sqft\", \"division\"])\n\nstoresDF.withColumn(\"employeesPerSqft\", col(\"numberOfEmployees\") / col(\"sqft\")) # A.","poster":"jds0","timestamp":"1721741460.0"},{"timestamp":"1694431260.0","comment_id":"1004673","poster":"newusername","upvote_count":"1","content":"Selected Answer: A\nTest:\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col\n\n# Initializing Spark session (if not already initialized)\nspark = SparkSession.builder.appName(\"databricks_example\").getOrCreate()\n\n# Creating some synthetic data for storesDF\ndata = [\n {\"storeId\": 1, \"numberOfEmployees\": 10, \"sqft\": 500},\n {\"storeId\": 2, \"numberOfEmployees\": 15, \"sqft\": 750},\n {\"storeId\": 3, \"numberOfEmployees\": 8, \"sqft\": 400}\n]\n\nstoresDF = spark.createDataFrame(data)\n\n\n# Option A:\ntry:\n df_a = storesDF.withColumn(\"employeesPerSqft\", col(\"numberOfEmployees\") / col(\"sqft\"))\n df_a.show()\n print(\"Option A works\")\nexcept Exception as e:\n print(\"Option A doesn't work:\", str(e))"},{"timestamp":"1684132320.0","comment_id":"898084","content":"Selected Answer: A\nC, D are wrong as exmployeesPerSqft cannot be selected, it doesn't exist. Also, that is not proper select syntax anyway. B does not select existing columns using col(), and E refers to employeesPerSqft as an existing column; also, it cannot be the first argument for withColumn().","upvote_count":"2","poster":"SonicBoom10C9"},{"upvote_count":"1","timestamp":"1682491860.0","poster":"4be8126","content":"storesDF.select(\"employeesPerSqft\", col(\"numberOfEmployees\") / col(\"sqft\"))\n\nThis code block selects the columns \"employeesPerSqft\" and the quotient of \"numberOfEmployees\" and \"sqft\" from the DataFrame storesDF. However, since \"employeesPerSqft\" is not a column in the original storesDF, this code block would throw an error.\n\nTo create a new column \"employeesPerSqft\" in the resulting DataFrame, we need to use the withColumn() method instead of select(). Here's the corrected code block:\n\nstoresDF.withColumn(\"employeesPerSqft\", col(\"numberOfEmployees\") / col(\"sqft\"))\n\nThis code block adds a new column \"employeesPerSqft\" to the storesDF DataFrame. The new column is created by dividing the values in column \"numberOfEmployees\" by the values in column \"sqft\".","comment_id":"881203"},{"poster":"4be8126","upvote_count":"1","comment_id":"881199","timestamp":"1682491680.0","content":"The correct code block to return a new DataFrame with a new column employeesPerSqft that is the quotient of column numberOfEmployees and column sqft from DataFrame storesDF is:\n\nstoresDF.withColumn(\"employeesPerSqft\", col(\"numberOfEmployees\") / col(\"sqft\"))\n\nOption A correctly uses the withColumn() function to create a new column employeesPerSqft by dividing column numberOfEmployees by column sqft.\n\nOption B has a syntax error because it uses quotation marks to reference column names instead of the col() function.\n\nOption C also has a syntax error because it uses quotation marks to reference column names instead of the col() function, and also uses the select() function instead of withColumn() to create a new column.\n\nOption D correctly references column names using col() and uses the select() function to return a DataFrame with only the two selected columns.\n\nOption E has a syntax error where col() is used as a first argument instead of a second argument for the withColumn() function.\n\nTherefore, the correct answer is A.\n\nstoresDF.withColumn(\"employeesPerSqft\", col(\"numberOfEmployees\") / col(\"sqft\"))"}],"answer":"A","answers_community":["A (100%)"],"unix_timestamp":1682491680},{"id":"Ivi1o2PdufOlWf5GeCB0","answers_community":["C (100%)"],"url":"https://www.examtopics.com/discussions/databricks/view/107542-exam-certified-associate-developer-for-apache-spark-topic-1/","answer_ET":"C","question_id":103,"question_images":[],"discussion":[{"content":"Selected Answer: C\nAnswer is C\nCode:\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import lit\n\nspark = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n\ndata = [\n (0, 3, 20, \"A\"),\n (1, 1, 50, \"A\"),\n (2, 2, 70, \"A\"),\n ]\nstoresDF = spark.createDataFrame(data, [\"storeID\", \"numberOfEmployees\", \"sqft\", \"division\"])\n\nstoresDF.withColumn(\"modality\", lit(\"PHYSICAL\"))","poster":"jds0","upvote_count":"1","comment_id":"1253685","timestamp":"1721741820.0"},{"timestamp":"1694433120.0","upvote_count":"1","poster":"newusername","comment_id":"1004724","content":"Selected Answer: C\nCorrect"},{"comment_id":"881213","content":"lit and col are two functions in PySpark that are used to create or reference columns in a DataFrame.\n\nlit: This function is used to create a column with a literal value. It returns a Column expression of literal value. For example, lit(2) creates a Column with a value of 2. It can be useful when you want to add a new column to a DataFrame with a constant value for all rows.\n\ncol: This function is used to reference an existing column in a DataFrame. It returns a Column expression that represents a column. For example, col(\"age\") returns a Column expression that represents the \"age\" column in a DataFrame. It can be useful when you want to select, filter or transform an existing column in a DataFrame.\n\nIn short, lit is used to create a new column with a constant value, while col is used to reference an existing column in a DataFrame.","upvote_count":"1","timestamp":"1682492280.0","poster":"4be8126"},{"comment_id":"881212","upvote_count":"2","timestamp":"1682492220.0","content":"Selected Answer: C\nOption C is the correct answer. Here's why:\n\nThe withColumn function is used to add a new column to the DataFrame based on an existing column or a constant value. The first blank (_1_) should be replaced with withColumn to indicate that we want to add a new column.\n\nThe second blank (_2_) should be replaced with the name of the column we want to add. In this case, we want to add a column called modality.\n\nThe third blank (_3_) should be replaced with a function that will create the values for the new column. In this case, we want to create a column that has the constant value \"PHYSICAL\". The lit function can be used to create a column with a literal value.\n\nFinally, the fourth blank (_4_) should be replaced with the actual value we want to use for the new column. Since we want to use the string \"PHYSICAL\", it should be wrapped in quotation marks to indicate that it is a string.\n\nTherefore, option C correctly fills in the blanks to give us the following code block:\n\nstoresDF.withColumn(\"modality\", lit(\"PHYSICAL\"))","poster":"4be8126"}],"answer_images":[],"topic":"1","choices":{"C":"1. withColumn\n2. \"modality\"\n3. lit\n4. \"PHYSICAL\"","B":"1. withColumn\n2. \"modality\"\n3. lit\n4. PHYSICAL","E":"1. newColumn\n2. modality\n3. SrtringType\n4. PHYSICAL","A":"1. withColumn\n2. \"modality\"\n3. col\n4. \"PHYSICAL\"","D":"1. withColumn\n2. \"modality\"\n3. SrtringType\n4. \"PHYSICAL\""},"timestamp":"2023-04-26 08:57:00","answer_description":"","exam_id":161,"question_text":"The code block shown below should return a new DataFrame from DataFrame storesDF where column modality is the constant string \"PHYSICAL\", Assume DataFrame storesDF is the only defined language variable. Choose the response that correctly fills in the numbered blanks within the code block to complete this task.\nCode block:\nstoresDF. _1_(_2_,_3_(_4_))","unix_timestamp":1682492220,"answer":"C","isMC":true},{"id":"grPwHIoQIFxcvuGAw2qe","question_text":"Which of the following code blocks returns a DataFrame where column storeCategory from DataFrame storesDF is split at the underscore character into column storeValueCategory and column storeSizeCategory?\nA sample of DataFrame storesDF is displayed below:\n//IMG//","url":"https://www.examtopics.com/discussions/databricks/view/105644-exam-certified-associate-developer-for-apache-spark-topic-1/","timestamp":"2023-04-09 07:20:00","question_images":["https://img.examtopics.com/certified-associate-developer-for-apache-spark/image2.png"],"exam_id":161,"answer_description":"","choices":{"E":"(storesDF.withColumn(\"storeValueCategory\", col(\"storeCategory\").split(\"_\")[1])\n.withColumn(\"storeSizeCategory\", col(\"storeCategory\").split(\"_\")[2]))","B":"(storesDF.withColumn(\"storeValueCategory\", col(\"storeCategory\").split(\"_\")[0])\n.withColumn(\"storeSizeCategory\", col(\"storeCategory\").split(\"_\")[1]))","D":"(storesDF.withColumn(\"storeValueCategory\", split(\"storeCategory\", \"_\")[0])\n.withColumn(\"storeSizeCategory\", split(\"storeCategory\", \"_\")[1]))","A":"(storesDF.withColumn(\"storeValueCategory\", split(col(\"storeCategory\"), \"_\")[1])\n.withColumn(\"storeSizeCategory\", split(col(\"storeCategory\"), \"_\")[2]))","C":"(storesDF.withColumn(\"storeValueCategory\", split(col(\"storeCategory\"), \"_\")[0])\n.withColumn(\"storeSizeCategory\", split(col(\"storeCategory\"), \"_\")[1]))"},"topic":"1","answer":"C","unix_timestamp":1681017600,"answer_images":[],"question_id":104,"discussion":[{"poster":"ronfun","timestamp":"1681017600.0","content":"Both C or D are correct. Function split accepts both col and str.\nhttps://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.split.html?highlight=split#pyspark.sql.functions.split","upvote_count":"8","comments":[{"content":"Both C or D are correct!","comment_id":"939934","timestamp":"1688215560.0","poster":"NickWerbung","upvote_count":"2"},{"timestamp":"1682493060.0","poster":"4be8126","comment_id":"881223","upvote_count":"3","content":"Option D is not correct because the split function should be used with the col function to split the values in a column. In option D, the split function is used with a string literal rather than a column, which will result in an error."}],"comment_id":"865301"},{"timestamp":"1737299040.0","poster":"bp_a_user","content":"Selected Answer: C\nOnly C is correct\npyspark.sql.functions.split(str, pattern, limit=-1)\nThe exam is about Spark 3.0, the option to also use col is now existing (3.5, but not in 3.0)","comments":[{"upvote_count":"1","timestamp":"1737299100.0","poster":"bp_a_user","content":"sry, only D is correct","comment_id":"1343049"}],"upvote_count":"1","comment_id":"1343048"},{"poster":"jds0","timestamp":"1721747100.0","upvote_count":"1","content":"Selected Answer: C\nBoth C or D work in Spark 3.5.1, but C is probably better for backward compatibility.\nSee code example below:\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import split, col\n\nspark = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n\ndata = [\n (0, True, 10020, \"VALUE_MEDIUM\"),\n (1, True, 10050, \"MAINSTREAM_SMALL\"),\n (2, False, 10070, \"PREMIUM_LARGE\"),\n ]\nstoresDF = spark.createDataFrame(data, [\"storeID\", \"open\", \"openDate\", \"storeCategory\"])\n\n(storesDF.withColumn(\"storeValueCategory\", split(col(\"storeCategory\"), \"_\")[0]).withColumn(\"storeSizeCategory\", split(col(\"storeCategory\"), \"_\")[1])).show()\n(storesDF.withColumn(\"storeValueCategory\", split(\"storeCategory\", \"_\")[0]).withColumn(\"storeSizeCategory\", split(\"storeCategory\", \"_\")[1])).show()","comment_id":"1253735"},{"poster":"newusername","comment_id":"1004817","upvote_count":"2","content":"Selected Answer: C\nC\nyou can check, by running the code below: \n\nfrom pyspark.sql import SparkSession\n\n# Initialize Spark session\nspark = SparkSession.builder.appName(\"split_test\").getOrCreate()\n\n# Create synthetic data\ndata = [\n {\"storeCategory\": \"value1_size1\"},\n {\"storeCategory\": \"value2_size2\"},\n {\"storeCategory\": \"value3_size3\"},\n]\n\nstoresDF = spark.createDataFrame(data)\nstoresDF.show()\n\nfrom pyspark.sql.functions import split, col\n\n# Option C\n\n\nnewDF = (storesDF.withColumn(\"storeValueCategory\", split(col(\"storeCategory\"), \"_\")[0])\n.withColumn(\"storeSizeCategory\", split(col(\"storeCategory\"), \"_\")[1]))\nnewDF.show()","timestamp":"1694437020.0"},{"timestamp":"1690724580.0","poster":"zozoshanky","comment_id":"967176","content":"c is correct","upvote_count":"1"},{"upvote_count":"2","content":"Selected Answer: C\nOption C returns a DataFrame where column storeCategory from DataFrame storesDF is split at the underscore character into column storeValueCategory and column storeSizeCategory.\n\nThe correct code is:\n\n(storesDF.withColumn(\"storeValueCategory\", split(col(\"storeCategory\"), \"_\")[0])\n.withColumn(\"storeSizeCategory\", split(col(\"storeCategory\"), \"_\")[1]))\n\nExplanation:\n\nsplit(col(\"storeCategory\"), \"_\") splits the values in column storeCategory by the \"_\" character and returns an array of strings.\n\n[0] gets the first element of the resulting array and assigns it to the new column storeValueCategory.\n\n[1] gets the second element of the resulting array and assigns it to the new column storeSizeCategory.\n\nwithColumn is used to create the new columns and returns a new DataFrame.","timestamp":"1682493120.0","comment_id":"881224","poster":"4be8126"}],"isMC":true,"answer_ET":"C","answers_community":["C (100%)"]},{"id":"4s1Q067D3Davn4y2f4aa","discussion":[{"timestamp":"1721801520.0","upvote_count":"1","comment_id":"1254158","content":"Selected Answer: A\nBoth option A and E work with spark 3.5.1.\nBut A is better for backward compatibility.\nSee code example below:\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, explode\n\nspark = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n\ndata = [\n (0, [\"value 1\", \"value 2\", \"value 3\"]),\n (1, [\"value 1\", \"value 2\", \"value 3\"]),\n (2, [\"value 1\", \"value 2\", \"value 3\"]),\n ]\nstoresDF = spark.createDataFrame(data, [\"storeID\", \"productCategories\"])\n\nstoresDF.withColumn(\"productCategories\", explode(col(\"productCategories\"))).show() # A. \nstoresDF.withColumn(\"productCategories\", explode(\"productCategories\")).show() # E.","poster":"jds0"},{"poster":"bettermakeme","comment_id":"1188484","upvote_count":"1","timestamp":"1712123040.0","content":"A and E are correct"},{"poster":"arturffsi","timestamp":"1709823000.0","content":"Selected Answer: E\nBoth A and E are correct according to the new version","upvote_count":"1","comment_id":"1168108"},{"poster":"newusername","comment_id":"1004891","content":"Selected Answer: A\nA is correct, use below code to test:\nfrom pyspark.sql import SparkSession\n\n# Initializing Spark session\nspark = SparkSession.builder.appName(\"test\").getOrCreate()\n\n# 1. Creating DataFrame with an array column\ndata_array = [\n (1, [\"electronics\", \"clothes\", \"toys\"]),\n (2, [\"groceries\", \"electronics\"]),\n (3, [\"books\", \"clothes\"]),\n]\n\nstoresDF = spark.createDataFrame(data_array, [\"ID\", \"productCategories\"])\nstoresDF.show()\n\ndf_array = storesDF.withColumn(\"productCategories\", explode(col(\"productCategories\")))\ndf_array.show()","upvote_count":"3","comments":[{"comment_id":"1004896","upvote_count":"2","content":"But E works as well, sadly. What has to be chosen then?\nfrom pyspark.sql import SparkSession\n\n# Initializing Spark session\nspark = SparkSession.builder.appName(\"test\").getOrCreate()\n\n# 1. Creating DataFrame with an array column\ndata_array = [\n (1, [\"electronics\", \"clothes\", \"toys\"]),\n (2, [\"groceries\", \"electronics\"]),\n (3, [\"books\", \"clothes\"]),\n]\n\nstoresDF = spark.createDataFrame(data_array, [\"ID\", \"productCategories\"])\nstoresDF.show()\n\n#df_array = storesDF.withColumn(\"productCategories\", explode(col(\"productCategories\")))\n#df_array.show()\n\n\n#check E\ndf_array = storesDF.withColumn(\"productCategories\", explode(\"productCategories\"))\ndf_array.show()","timestamp":"1694442000.0","poster":"newusername"},{"content":"E for 3.0","upvote_count":"1","poster":"newusername","comment_id":"1064005","timestamp":"1699285320.0"}],"timestamp":"1694441460.0"},{"upvote_count":"4","poster":"NickWerbung","comment_id":"939944","content":"Both A and E are correct.","timestamp":"1688215860.0"},{"poster":"mhaskins","timestamp":"1684768740.0","content":"Selected Answer: A\nWhile the Explode function allows for a str or Column input, this requires the col() wrapper because it is used in a withColumn() call, where the 2nd parameter requires the column object.\n\nhttps://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.withColumn.html?highlight=withcolumn#pyspark.sql.DataFrame.withColumn","comment_id":"904170","upvote_count":"2"},{"content":"Selected Answer: A\nOption A is correct: storesDF.withColumn(\"productCategories\", explode(col(\"productCategories\"))).\n\nExplanation:\n\nThe explode function is used to transform a column of arrays or maps into multiple rows, one for each element in the array or map. In this case, productCategories is a column with arrays of strings.\n\nThe withColumn function is used to add a new column or update an existing column. The first argument is the name of the new or existing column, and the second argument is the expression that defines the values for the column.","upvote_count":"1","comment_id":"881236","poster":"4be8126","timestamp":"1682493720.0"}],"url":"https://www.examtopics.com/discussions/databricks/view/107544-exam-certified-associate-developer-for-apache-spark-topic-1/","exam_id":161,"question_id":105,"unix_timestamp":1682493720,"answer_description":"","timestamp":"2023-04-26 09:22:00","topic":"1","answer_images":[],"answer_ET":"A","question_text":"Which of the following code blocks returns a new DataFrame where column productCategories only has one word per row, resulting in a DataFrame with many more rows than DataFrame storesDF?\nA sample of storesDF is displayed below:\n//IMG//","choices":{"C":"storesDF.withColumn(\"productCategories\", col(\"productCategories\").explode())","B":"storesDF.withColumn(\"productCategories\", split(col(\"productCategories\")))","E":"storesDF.withColumn(\"productCategories\", explode(\"productCategories\"))","D":"storesDF.withColumn(\"productCategories\", col(\"productCategories\").split())","A":"storesDF.withColumn(\"productCategories\", explode(col(\"productCategories\")))"},"answer":"A","answers_community":["A (88%)","13%"],"isMC":true,"question_images":["https://img.examtopics.com/certified-associate-developer-for-apache-spark/image3.png"]}],"exam":{"isMCOnly":true,"name":"Certified Associate Developer for Apache Spark","provider":"Databricks","isBeta":false,"lastUpdated":"12 Apr 2025","numberOfQuestions":185,"id":161,"isImplemented":true},"currentPage":21},"__N_SSP":true}