{"pageProps":{"questions":[{"id":"7a0bEcuXEibNWTDo22be","choices":{"D":"1. storesDF\n2. first\n3. getAs\n4. “sqft”","C":"1. storesDF\n2. first()\n3. getAs\n4. col(“sqft”)","B":"1. storesDF\n2. first\n3. getAs\n4. sqft","A":"1. storesDF\n2. first()\n3. getAs()\n4. “sqft”"},"isMC":true,"discussion":[{"content":"Selected Answer: A\nA - correct - storesDF.first().getAs[Int](\"sqft\")\nD - Incorrect","upvote_count":"1","poster":"ARUNKUMARKRISHNASAMY","comment_id":"1388087","timestamp":"1741813260.0"},{"timestamp":"1741216920.0","upvote_count":"1","poster":"ARUNKUMARKRISHNASAMY","content":"Selected Answer: D\nstoresDF.first().getAs[Int](\"sqft\")","comment_id":"1365621"},{"content":"This is part of the official databricks exam samples.\nThis is the correct answer:\n\nD.1. storesDF 2. first 3. getAs 4. \"sqft\"","comment_id":"1190487","poster":"Sowwy1","timestamp":"1712419440.0","upvote_count":"2"},{"comment_id":"1066500","poster":"newusername","timestamp":"1699543500.0","upvote_count":"1","content":"could anyone show working test case ?"},{"comments":[{"comment_id":"1235442","timestamp":"1719067140.0","content":"on scala works","comments":[{"poster":"carlosmps","comment_id":"1235443","timestamp":"1719067200.0","upvote_count":"1","content":"the using of first without parentheses"}],"upvote_count":"1","poster":"carlosmps"}],"poster":"thanab","content":"A\n\nA is correct. D is incorrect.\nOption D is incorrect because it uses the first method without parentheses. The first method is a method of a DataFrame and must be called with parentheses to return the first row of the DataFrame. Here’s the corrected code block:\n```\nstoresDF.first().getAsInt\n```","upvote_count":"2","comment_id":"1001114","timestamp":"1694053800.0"},{"upvote_count":"2","comment_id":"970378","content":"Selected Answer: D\ncorrect. we can use first and first() interchangeably, getAs works as getAs[int](\"col_name\")","timestamp":"1690994280.0","poster":"cookiemonster42"}],"answer":"D","question_images":[],"question_text":"The code block shown below should extract the integer value for column sqft from the first row of DataFrame storesDF. Choose the response that correctly fills in the numbered blanks within the code block to complete this task.\n\nCode block:\n\n__1__.__2__.__3__[Int](__4__)","answer_description":"","answers_community":["D (75%)","A (25%)"],"question_id":6,"exam_id":161,"answer_ET":"D","unix_timestamp":1690994280,"topic":"1","url":"https://www.examtopics.com/discussions/databricks/view/117144-exam-certified-associate-developer-for-apache-spark-topic-1/","timestamp":"2023-08-02 18:38:00","answer_images":[]},{"id":"fDk2ld3NaFJxzYr9Du4h","choices":{"C":"1. storesDF\n2. getAs[str]","A":"1. storesDF\n2. printSchema(“all”)","B":"1. storesDF\n2. schema","E":"1. storesDF\n2. printSchema","D":"1. storesDF\n2. printSchema(true)"},"isMC":true,"discussion":[{"content":"B & E results an output. But using df.schema gives you the schema in more detail, df.printSchema just gives the columns that are present in the dataframe. df.printSchema() gives the detailed schema.","timestamp":"1728044400.0","poster":"SaiPavan10","comment_id":"1189303","upvote_count":"1"},{"upvote_count":"2","timestamp":"1728044100.0","content":"It is df.printSchema().","poster":"SaiPavan10","comment_id":"1189299"},{"content":"I think it's B.","upvote_count":"1","poster":"Sowwy1","timestamp":"1727869620.0","comment_id":"1187998"},{"poster":"Gluemr","content":"E is correct. This question is for scala not python","comment_id":"1124643","upvote_count":"1","timestamp":"1721175780.0"},{"timestamp":"1706900580.0","poster":"cookiemonster42","comment_id":"970407","upvote_count":"1","comments":[{"timestamp":"1715261640.0","comment_id":"1066505","poster":"newusername","content":"interesting case, either the answer E is indeed not complete () is missing or it is B, though B doesn't print schema but returns schema object","upvote_count":"1"}],"content":"should be B\nfor printSchema() is should be DataFrame.printSchema() with parenthesis"}],"question_images":[],"answer":"E","question_text":"The code block shown below should print the schema of DataFrame storesDF. Choose the response that correctly fills in the numbered blanks within the code block to complete this task.\n\nCode block:\n\n__1__.__2__","answer_description":"","question_id":7,"answers_community":[],"answer_ET":"E","exam_id":161,"unix_timestamp":1690995780,"topic":"1","url":"https://www.examtopics.com/discussions/databricks/view/117147-exam-certified-associate-developer-for-apache-spark-topic-1/","timestamp":"2023-08-02 19:03:00","answer_images":[]},{"id":"sUl1XB9DAPuXYGkuTSmb","choices":{"A":"The customerSatisfaction column cannot be called twice inside the SQL statement.","B":"Registered UDFs cannot be applied inside of a SQL statement.","E":"There is no sql() operation - the DataFrame API must be used to apply the UDF assessPerformance().","C":"The order of the arguments to spark.udf.register() should be reversed.","D":"The wrong SQL function is used to compute column result - it should be ASSESS_PERFORMANCE instead of assessPerformance."},"url":"https://www.examtopics.com/discussions/databricks/view/116821-exam-certified-associate-developer-for-apache-spark-topic-1/","answer_images":[],"answers_community":["D (75%)","C (25%)"],"question_id":8,"answer_ET":"D","isMC":true,"timestamp":"2023-07-30 21:20:00","answer_description":"","exam_id":161,"topic":"1","unix_timestamp":1690744800,"answer":"D","question_images":[],"question_text":"The code block shown below contains an error. The code block is intended to create and register a SQL UDF named “ASSESS_PERFORMANCE” using the Scala function assessPerformance() and apply it to column customerSatisfaction in the table stores. Identify the error.\n\nCode block:\n\nspark.udf.register(“ASSESS_PERFORMANCE”, assessPerforance)\nspark.sql(“SELECT customerSatisfaction, assessPerformance(customerSatisfaction) AS result FROM stores”)","discussion":[{"upvote_count":"1","comment_id":"1244445","poster":"cd6a625","content":"Selected Answer: D\nD is the correct answer","timestamp":"1720452000.0"},{"upvote_count":"1","poster":"SaiPavan10","content":"Selected Answer: C\nD is the right choice.","timestamp":"1712233380.0","comment_id":"1189306"},{"poster":"veli4ko","upvote_count":"2","content":"D is correct","comment_id":"1020582","timestamp":"1695973080.0"},{"upvote_count":"1","timestamp":"1694054340.0","comment_id":"1001116","poster":"thanab","content":"D\nThe error in the code block is D. The wrong SQL function is used to compute column result - it should be ASSESS_PERFORMANCE instead of assessPerformance."},{"comment_id":"983774","timestamp":"1692286680.0","content":"Selected Answer: D\nyup D is correct","poster":"Ram459","upvote_count":"2"},{"content":"D is the answer","upvote_count":"2","timestamp":"1690744800.0","poster":"zozoshanky","comment_id":"967449"}]},{"id":"qTapFD93m6DULaouShkB","choices":{"E":"UDFs can only be applied via SQL and not through the Data Frame API.","D":"The assessPerformanceUDF() must first be defined as a Scala function and then converted to a UDF.","B":"The return type of assessPerformanceUDF() must be specified.","A":"The input type of customerSatisfaction is not specified in the udf() operation.","C":"The withColumn() operation is not appropriate here - UDFs should be applied by iterating over rows instead."},"isMC":true,"answers_community":[],"url":"https://www.examtopics.com/discussions/databricks/view/137746-exam-certified-associate-developer-for-apache-spark-topic-1/","answer_ET":"B","answer":"B","answer_images":[],"question_id":9,"answer_description":"","topic":"1","question_images":["https://img.examtopics.com/certified-associate-developer-for-apache-spark/image12.png"],"question_text":"The code block shown below contains an error. The code block is intended to create the Scala UDF assessPerformanceUDF() and apply it to the integer column customers1t1sfaction in Data Frame storesDF. Identify the error.\n\nCode block:\n\n//IMG//","discussion":[{"poster":"beds2898","content":"these dumps is for python or scala?","timestamp":"1723481460.0","comment_id":"1264732","upvote_count":"1"},{"timestamp":"1718931300.0","content":"Ans. B\nval assessPerformanceUDF = udf((customerSatisfaction: Int) => {\n customerSatisfaction match {\n case x if x < 20 => 1\n case x if x > 80 => 3\n case _ => 2\n }\n}, IntegerType)\n\n// Apply the UDF to the DataFrame\nval resultDF = storesDF.withColumn(\"result\", assessPerformanceUDF(col(\"customerSatisfaction\")))\nresultDF.show()","comments":[{"upvote_count":"2","poster":"deadbeef38","content":"But you also gave a type for the customerSatisfaction input parameter. I think the answer is A","timestamp":"1719083220.0","comment_id":"1235565"}],"upvote_count":"1","comment_id":"1234136","poster":"carlosmps"},{"content":"I think it's B","timestamp":"1712058540.0","upvote_count":"1","comment_id":"1188000","poster":"Sowwy1"}],"exam_id":161,"timestamp":"2024-04-02 13:49:00","unix_timestamp":1712058540},{"id":"ibOGFLTl5j8WdBwbptY9","discussion":[{"poster":"Sowwy1","comments":[{"comment_id":"1235570","timestamp":"1719084060.0","content":"I think C is correct, but the result is a DataFrame with a single row whose value is a list of Integers, not a row for each element in the list. None of the other choices makes sense though.","poster":"deadbeef38","upvote_count":"1"},{"content":"It's part of official databricks questions:\nQuestion 44 Which of the following code blocks creates a single-column DataFrame from Scala Listyears which is made up of integers? A. spark.createDataset(years).toDF B. spark.createDataFrame(years, IntegerType) C. spark.createDataset(years) D. spark.DataFrame(years, IntegerType) E. spark.createDataFrame(years) --> and the answer here is A.","poster":"Sowwy1","comments":[{"content":"spark.createDataset(years).toDF, to avoid confuse, it's answer C here, and answer A on official databruicks questions. :)","upvote_count":"1","timestamp":"1719061800.0","poster":"carlosmps","comment_id":"1235400"}],"comment_id":"1193183","upvote_count":"2","timestamp":"1712770020.0"}],"timestamp":"1712058780.0","upvote_count":"2","content":"I think it's C\nC. 1. spark\n2. createDataset\n3. List(years)\n4. toDF\n\nit says \"Scala list\"","comment_id":"1188003"}],"url":"https://www.examtopics.com/discussions/databricks/view/137748-exam-certified-associate-developer-for-apache-spark-topic-1/","question_images":[],"answer_images":[],"timestamp":"2024-04-02 13:53:00","question_id":10,"unix_timestamp":1712058780,"isMC":true,"question_text":"The code block shown below should create a single-column DataFrame from Scala list years which is made up of integers. Choose the response that correctly fills in the numbered blanks within the code block to complete this task.\n\nCode block:\n\n__1__.__2__(__3__).__4__","answer_description":"","choices":{"D":"1. spark\n2. createDataFrame\n3. List(years)\n4. IntegerType","B":"1. spark\n2. createDataset\n3. years\n4. IntegerType","A":"1. spark\n2. createDataFrame\n3. years\n4. IntegerType","C":"1. spark\n2. createDataset\n3. List(years)\n4. toDF"},"exam_id":161,"topic":"1","answer_ET":"A","answer":"A","answers_community":[]}],"exam":{"provider":"Databricks","id":161,"name":"Certified Associate Developer for Apache Spark","lastUpdated":"12 Apr 2025","isMCOnly":true,"numberOfQuestions":185,"isBeta":false,"isImplemented":true},"currentPage":2},"__N_SSP":true}