{"pageProps":{"questions":[{"id":"tH0sOO9ypFBP7qoTOFtn","choices":{"E":"","D":"","B":"It is not possible to deploy a scikit-learn model on a Spark DataFrame.","C":"","A":""},"question_text":"A machine learning engineer has developed a random forest model using scikit-learn, logged the model using MLflow as random_forest_model, and stored its run ID in the run_id Python variable. They now want to deploy that model by performing batch inference on a Spark DataFrame spark_df.\nWhich of the following code blocks can they use to create a function called predict that they can use to complete the task?","question_images":[],"timestamp":"2023-12-19 01:46:00","exam_id":164,"answer_ET":"E","discussion":[{"comment_id":"1337548","content":"Selected Answer: A\nA. mlflow.pyfunc.spark_udf(spark_df...)","upvote_count":"1","poster":"ricorosol","timestamp":"1736253960.0"},{"comment_id":"1245325","upvote_count":"1","poster":"Mircuz","content":"Selected Answer: E\nYou need the spark env","timestamp":"1720592040.0"},{"poster":"64934ca","timestamp":"1720279500.0","comment_id":"1243426","upvote_count":"1","content":"Selected Answer: E\nThe spark session is passed as the first argument to mlflow.pyfunc.spark_udf to provide the necessary context for creating and executing the UDF within the Spark environment. The model_uri is passed as the second argument to specify which MLflow model to load and use for predictions. This order is required by the function's design to ensure proper integration with Spark."},{"upvote_count":"3","comment_id":"1138863","content":"Selected Answer: E\nE is correct","timestamp":"1706910480.0","poster":"spaceexplorer"},{"upvote_count":"2","poster":"JaydeepT","comment_id":"1137141","content":"Selected Answer: A\nspark_df is the frame to be used for variable evaluation in runtime","timestamp":"1706743800.0"},{"comment_id":"1100142","content":"E.\nimport mlflow\nlogged_model = 'runs:/e905f5759d434a131bbe1e54a2b/best-model'\n\n# Load model as a Spark UDF.\nloaded_model = mlflow.pyfunc.spark_udf(spark, model_uri=logged_model)\n\n# Predict on a Spark DataFrame.\ndf.withColumn('predictions', loaded_model(*columns)).collect()","timestamp":"1702946760.0","comments":[{"upvote_count":"2","timestamp":"1705657500.0","comments":[{"upvote_count":"4","comment_id":"1128664","timestamp":"1705929540.0","content":"My bad, it is E. Because the spark_udf function expects the SparkSession as first paramenter, not the DataFrame!","poster":"victorcolome"}],"comment_id":"1126566","poster":"victorcolome","content":"Must be A, not E, as the question states that the variable is called \"spark_df\"."}],"upvote_count":"2","poster":"BokNinja"}],"topic":"1","url":"https://www.examtopics.com/discussions/databricks/view/128937-exam-certified-machine-learning-professional-topic-1/","unix_timestamp":1702946760,"question_id":36,"answers_community":["E (63%)","A (38%)"],"answer_images":[],"answer":"E","isMC":true,"answer_description":""},{"id":"oBqzOsLjSwjNeILyt0zQ","timestamp":"2023-12-19 01:52:00","answer":"E","question_text":"Which of the following describes the purpose of the context parameter in the predict method of Python models for MLflow?","answer_description":"","url":"https://www.examtopics.com/discussions/databricks/view/128938-exam-certified-machine-learning-professional-topic-1/","topic":"1","question_id":37,"exam_id":164,"choices":{"B":"The context parameter allows the user to document the performance of a model after it has been deployed","C":"The context parameter allows the user to include relevant details of the business case to allow downstream users to understand the purpose of the model","A":"The context parameter allows the user to specify which version of the registered MLflow Model should be used based on the given application's current scenario","E":"The context parameter allows the user to provide the model access to objects like preprocessing models or custom configuration files","D":"The context parameter allows the user to provide the model with completely custom if-else logic for the given application's current scenario"},"question_images":[],"unix_timestamp":1702947120,"discussion":[{"content":"Selected Answer: E\nThe context parameter is typically used to provide additional context or resources to the model during prediction, such as preprocessing models or custom configuration files. This allows the model to make use of relevant information or dependencies necessary for accurate predictions.","comment_id":"1133599","poster":"hugodscarvalho","upvote_count":"5","timestamp":"1706382120.0"},{"timestamp":"1719469440.0","upvote_count":"1","poster":"Joy999","comment_id":"1237912","content":"Selected Answer: A\nimport mlflow.pyfunc\n\nclass MyModel(mlflow.pyfunc.PythonModel):\n def load_context(self, context):\n # Load model artifacts during initialization\n self.model = load_model(context.artifacts[\"model_file\"])\n\n def predict(self, context, model_input):\n # Access artifacts and metadata during prediction\n model_version = context.metadata.get(\"version\")\n\n # Use the loaded model for prediction\n predictions = self.model.predict(model_input)\n return predictions\nClearly, Context is for \" Artifacts \" and \" Version \" not Preprocessin etc."},{"poster":"BokNinja","comment_id":"1100144","content":"The correct answer is E. The context parameter allows the user to provide the model access to objects like preprocessing models or custom configuration files","timestamp":"1702947120.0","upvote_count":"1"}],"isMC":true,"answers_community":["E (83%)","A (17%)"],"answer_images":[],"answer_ET":"E"},{"id":"r8uxLYA0oRNJjgQXAMVG","answer_description":"","isMC":true,"answer_ET":"E","timestamp":"2023-12-19 01:55:00","unix_timestamp":1702947300,"choices":{"D":"df = fs.get_missing_features(spark_df)\nfs.score_batch(model_uri, df)","E":"fs.score_batch(model_uri, spark_df)","A":"df = fs.get_missing_features(spark_df, model_uri)\nfs.score_model(model_uri, df)","C":"df = fs.get_missing_features(spark_df, model_uri)\nfs.score_batch(model_uri, df)","B":"fs.score_model(model_uri, spark_df)"},"answers_community":["E (100%)"],"answer":"E","question_images":[],"topic":"1","question_text":"A machine learning engineer has developed a model and registered it using the FeatureStoreClient fs. The model has model URI model_uri. The engineer now needs to perform batch inference on customer-level Spark DataFrame spark_df, but it is missing a few of the static features that were used when training the model. The customer_id column is the primary key of spark_df and the training set used when training and logging the model.\nWhich of the following code blocks can be used to compute predictions for spark_df when the missing feature values can be found in the Feature Store by searching for features by customer_id?","question_id":38,"answer_images":[],"exam_id":164,"url":"https://www.examtopics.com/discussions/databricks/view/128939-exam-certified-machine-learning-professional-topic-1/","discussion":[{"comment_id":"1128409","upvote_count":"4","poster":"victorcolome","content":"Selected Answer: E\nThe answer is E. See score_batch in https://api-docs.databricks.com/python/feature-store/latest/feature_store.client.html.\n\"Additional features required for model evaluation will be automatically retrieved from Feature Store.\"\nBesides, methods \"get_missing_features\" and \"score_model\" do not appear in the documentation.","timestamp":"1721627880.0"},{"poster":"IT3008","timestamp":"1721055480.0","content":"Right answer is E - there is no API info called 'get_missing_features' in the doc.","upvote_count":"1","comment_id":"1123532"},{"content":"The correct answer is C. df = fs.get_missing_features(spark_df, model_uri) fs.score_batch(model_uri, df).\n\nIn this code snippet, fs.get_missing_features(spark_df, model_uri) is used to retrieve the missing features from the Feature Store using the customer_id as the key. The resulting DataFrame df contains the original data along with the retrieved features. Then, fs.score_batch(model_uri, df) is used to perform batch inference on the DataFrame df using the model specified by model_uri.","comment_id":"1100148","timestamp":"1718751300.0","upvote_count":"1","poster":"BokNinja","comments":[{"content":"Except - I could not find a method called get_missing_features in FeatureStoreClient APIs. E is right answer.","upvote_count":"1","comment_id":"1219671","poster":"inet777","timestamp":"1732730820.0"}]}]},{"id":"bvHRy4Z7ZnKmL3xtwQGf","question_id":39,"discussion":[{"comment_id":"1237920","upvote_count":"1","poster":"Joy999","content":"Selected Answer: E\nReal Time should be ...","timestamp":"1719470220.0"},{"content":"If we want it ASAP and data arrives on the go it's real time. Streaming is used in real time (ex Spark Streaming & Auto loader). Would go with E","comment_id":"1209277","poster":"ThoBustos","timestamp":"1715329800.0","upvote_count":"1"}],"isMC":true,"question_text":"A machine learning engineer needs to select a deployment strategy for a new machine learning application. The feature values are not available until the time of delivery, and results are needed exceedingly fast for one record at a time.\nWhich of the following deployment strategies can be used to meet these requirements?","answer_ET":"E","choices":{"B":"Streaming","E":"Real-time","D":"Batch","A":"Edge/on-device","C":"None of these strategies will meet the requirements."},"question_images":[],"unix_timestamp":1715329800,"topic":"1","answer":"E","url":"https://www.examtopics.com/discussions/databricks/view/140282-exam-certified-machine-learning-professional-topic-1/","answers_community":["E (100%)"],"answer_images":[],"exam_id":164,"timestamp":"2024-05-10 10:30:00","answer_description":""},{"id":"4fPxEzctZ9dzx4KlEhQX","topic":"1","discussion":[{"upvote_count":"2","timestamp":"1722090420.0","comment_id":"1133482","content":"Selected Answer: C\nThis change ensures that the DataFrame is being read as a streaming DataFrame from the stream source.","poster":"hugodscarvalho"},{"comment_id":"1108705","poster":"mozuca","timestamp":"1719660120.0","upvote_count":"1","content":"Selected Answer: C\nAgree with trendy01"},{"content":"Selected Answer: C\nC. Replace spark.read with spark.readStream","poster":"trendy01","comment_id":"1106641","timestamp":"1719466140.0","upvote_count":"3"}],"answer":"C","question_text":"A machine learning engineer is using the following code block as part of a batch deployment pipeline:\n//IMG//\n\nWhich of the following changes needs to be made so this code block will work when the inference table is a stream source?","answers_community":["C (100%)"],"choices":{"E":"Replace predict with a stream-friendly prediction function","C":"Replace spark.read with spark.readStream","A":"Replace \"inference\" with the path to the location of the Delta table","D":"Replace format(\"delta\") with format(\"stream\")","B":"Replace schema(schema) with option(\"maxFilesPerTrigger\", 1)"},"answer_images":[],"url":"https://www.examtopics.com/discussions/databricks/view/129433-exam-certified-machine-learning-professional-topic-1/","question_images":["https://img.examtopics.com/certified-machine-learning-professional/image19.png"],"answer_description":"","timestamp":"2023-12-27 08:29:00","isMC":true,"exam_id":164,"unix_timestamp":1703662140,"question_id":40,"answer_ET":"C"}],"exam":{"id":164,"lastUpdated":"12 Apr 2025","isImplemented":true,"isBeta":false,"isMCOnly":true,"numberOfQuestions":60,"name":"Certified Machine Learning Professional","provider":"Databricks"},"currentPage":8},"__N_SSP":true}