{"pageProps":{"questions":[{"id":"2o6NH0MHvNPsfsoZHcpn","unix_timestamp":1697946180,"answer_ET":"E","choices":{"E":"Replace spark.read with spark.readStream","B":"Replace schema(schema) with option (\"maxFilesPerTrigger\", 1)","A":"Replace predict with a stream-friendly prediction function","D":"Replace format(\"delta\") with format(\"stream\")","C":"Replace \"transactions\" with the path to the location of the Delta table"},"question_text":"A data engineer is using the following code block as part of a batch ingestion pipeline to read from a composable table:\n\n//IMG//\n\n\nWhich of the following changes needs to be made so this code block will work when the transactions table is a stream source?","isMC":true,"answer":"E","url":"https://www.examtopics.com/discussions/databricks/view/124307-exam-certified-data-engineer-associate-topic-1-question-78/","answers_community":["E (100%)"],"question_images":["https://img.examtopics.com/certified-data-engineer-associate/image40.png"],"answer_images":[],"answer_description":"","question_id":146,"discussion":[{"timestamp":"1730189100.0","upvote_count":"2","poster":"benni_ale","content":"Selected Answer: E\nE is ok","comment_id":"1203854"},{"content":"Selected Answer: E\nhttps://docs.databricks.com/en/structured-streaming/tutorial.html#use-auto-loader-to-read-streaming-data-from-object-storage","upvote_count":"2","poster":"AndreFR","comment_id":"1101644","timestamp":"1718887140.0"},{"timestamp":"1717076820.0","upvote_count":"4","comments":[{"comment_id":"1086085","poster":"in89_io_90","timestamp":"1717318800.0","content":"have you cleared the exam","upvote_count":"2"}],"poster":"55f31c8","comment_id":"1084511","content":"Selected Answer: E\nExample from https://docs.databricks.com/en/structured-streaming/delta-lake.html\n\nspark.readStream.table(\"table_name\")\n\nspark.readStream.load(\"/path/to/table\")"},{"timestamp":"1713757380.0","upvote_count":"3","comment_id":"1050185","poster":"meow_akk","content":"Ans E; for streaming source you use readstream.\n\nhttps://docs.databricks.com/en/structured-streaming/delta-lake.html"}],"timestamp":"2023-10-22 05:43:00","exam_id":162,"topic":"1"},{"id":"yQC9PZHxOUVrea9Jxt7X","exam_id":162,"discussion":[{"poster":"mokrani","content":"Selected Answer: E\nanswer E: Raw to Bronze is simply an integration of source data in the lakehouse without any schema needed nor extra operationss (e;g filtering, aggregation, joins etc..)\nPlease refer to this Medaillon Architecture article\nhttps://www.databricks.com/glossary/medallion-architecture","comment_id":"1064854","timestamp":"1699365840.0","upvote_count":"6","comments":[{"comment_id":"1248823","timestamp":"1721126160.0","upvote_count":"1","content":"Yes E is correct. But There are filtering or aggregation in silver layer . We need to check if it have readstream and writestream","poster":"HelixAbdu"}]},{"comment_id":"1203857","content":"Selected Answer: E\nE is ok , all others are incorrect","upvote_count":"1","timestamp":"1714370760.0","poster":"benni_ale"},{"content":"sourcename is “rawSalesLocation” (bronze tables contain raw data) and code includes “readStream” to indicate that it is a streaming hop","upvote_count":"2","comment_id":"1101648","poster":"AndreFR","timestamp":"1703083440.0"},{"content":"Selected Answer: E\nhttps://docs.databricks.com/en/lakehouse/medallion.html#ingest-raw-data-to-the-bronze-layer","comment_id":"1084513","timestamp":"1701359400.0","upvote_count":"2","poster":"55f31c8"},{"comments":[{"comment_id":"1248828","poster":"HelixAbdu","content":"I think we should have read stream and writestream that should the important point","timestamp":"1721126460.0","upvote_count":"1"},{"comment_id":"1062458","poster":"hsks","timestamp":"1699139040.0","content":"Answer should be E. Filtering and cleaning usually happens from bronze to silver layer","upvote_count":"4"}],"timestamp":"1699075500.0","poster":"sodere","upvote_count":"1","comment_id":"1061912","content":"Answer is B"}],"answer_ET":"E","isMC":true,"unix_timestamp":1699075500,"question_id":147,"answer_images":[],"timestamp":"2023-11-04 06:25:00","question_text":"Which of the following queries is performing a streaming hop from raw data to a Bronze table?","answer":"E","answers_community":["E (100%)"],"choices":{"D":"","E":"","A":"","C":"","B":""},"topic":"1","question_images":[],"answer_description":"","url":"https://www.examtopics.com/discussions/databricks/view/125329-exam-certified-data-engineer-associate-topic-1-question-79/"},{"id":"FrR59kSDWjqPw8LYP5lc","answer_images":[],"answer_description":"","url":"https://www.examtopics.com/discussions/databricks/view/104737-exam-certified-data-engineer-associate-topic-1-question-8/","question_images":[],"exam_id":162,"unix_timestamp":1680356520,"discussion":[{"comments":[{"poster":"Tedet","timestamp":"1736555820.0","comment_id":"1339015","content":"Not a valid question anymore since, Databricks Repos can now perform:\n• Clone, push to, and pull from a remote Git repository.\n• Create and manage branches for development work, including merging, rebasing, and resolving conflicts.\n• Create notebooks (including IPYNB notebooks) and edit them and other files.\n• Visually compare differences upon commit and resolve merge conflicts.","upvote_count":"2"}],"timestamp":"1686687720.0","content":"According to the most recent one, all command is feasible in Repos","poster":"ZSun","comment_id":"922506","upvote_count":"24"},{"timestamp":"1693476540.0","comment_id":"994992","content":"Not valid anymore... \nhttps://docs.databricks.com/en/repos/ci-cd-techniques-with-repos.html","upvote_count":"18","poster":"NickWerbung"},{"comment_id":"1411231","poster":"devbila","content":"Selected Answer: E\nIt is E","upvote_count":"1","timestamp":"1743151740.0"},{"poster":"chinhuy","content":"Selected Answer: E\nhttps://docs.databricks.com/aws/en/repos/","upvote_count":"1","comment_id":"1365866","timestamp":"1741262520.0"},{"timestamp":"1736674860.0","comment_id":"1339435","content":"Selected Answer: D\nClone us correct","upvote_count":"2","poster":"sakis213"},{"comment_id":"1334379","poster":"danishanis","timestamp":"1735589340.0","upvote_count":"2","content":"Selected Answer: D\nOption D - Clone. \nThe Clone operation must be performed outside of Databricks Repos. Cloning a repository involves creating a copy of an existing remote repository to a local machine. In the context of Databricks, you would typically clone the repository to your local development environment first and then connect it to the Databricks repos"},{"comment_id":"1328147","timestamp":"1734469260.0","upvote_count":"3","content":"Selected Answer: D\nThe reason D. Clone is the correct answer is because cloning a repository involves creating a copy of the entire repository, including all of its history, branches, and files, on your local machine. This operation is typically performed outside of Databricks Repos, using Git commands in a terminal or a Git client.\n\nOn the other hand, operations like Commit, Pull, Push, and Merge can be performed within Databricks Repos, as they involve interacting with the repository's content and history that is already cloned and available in the Databricks environment.","poster":"MultiCloudIronMan"},{"comment_id":"1303998","content":"For clarity, is the consensus that you can do all of the options, therefore making this an invalid question?","timestamp":"1730124720.0","upvote_count":"1","poster":"peadar_pa"},{"content":"D. Clone\n\nCloning a repository creates a local copy of the repository on your machine and must be done using a local Git client or command line. Once the repository is cloned, you can work with it in Databricks Repos, but the initial clone operation itself is outside the Databricks interface. Other operations like commit, pull, push, and merge can be managed within Databricks Repos or through other Git tools.","comment_id":"1272800","upvote_count":"4","poster":"9d4d68a","timestamp":"1724683680.0"},{"comment_id":"1262390","timestamp":"1723102980.0","upvote_count":"2","content":"Selected Answer: D\nD: Cloning a repository is typically done outside of Databricks Repos, often using a Git client or command line interface before the repository is linked to Databricks Repos.","poster":"80370eb"},{"comment_id":"1202790","poster":"Isio05","timestamp":"1714159860.0","content":"Confirmed on live environment - merging is now possible directly in Databricks Repos","upvote_count":"4"},{"upvote_count":"1","content":"Selected Answer: E\nE is correct","poster":"Itmma","comment_id":"1177171","timestamp":"1710840900.0"},{"content":"Why not option B Pull\n\nThe following tasks are not supported by Databricks Repos, and must be performed in your Git provider:\nCreate a pull request\nDelete branches\nMerge and rebase branches *","upvote_count":"1","comment_id":"1156957","poster":"Bob123456","timestamp":"1708671660.0","comments":[{"poster":"Isio05","timestamp":"1714159920.0","upvote_count":"3","comment_id":"1202791","content":"Pull is not the same as pull request. Pulls are updating local version of the repo to the one present on remote. And it's surely feasible in Databricks repos."}]},{"timestamp":"1704631440.0","content":"The new answer is F - Delete .","poster":"vvg130","upvote_count":"7","comment_id":"1115828"},{"poster":"SerGrey","comment_id":"1104707","content":"Selected Answer: E\nE is correct","timestamp":"1703432460.0","upvote_count":"1"},{"content":"i think it supports merge now \nhttps://docs.databricks.com/en/repos/git-operations-with-repos.html\n\"If an operation such as pull, rebase, or merge causes a merge conflict, the Repos UI shows a list of files with conflicts and options for resolving the conflicts.\n\nYou have two primary options:\n\n Use the Repos UI to resolve the conflict.\"","upvote_count":"1","comment_id":"1085129","timestamp":"1701424980.0","poster":"nedlo"},{"timestamp":"1700230860.0","poster":"Huroye","comment_id":"1073385","content":"E is the correct answer given the selections. You can clone.","upvote_count":"1"},{"timestamp":"1698676200.0","upvote_count":"2","poster":"mokrani","comment_id":"1057877","content":"According to the recent version, all commands are supported under Repos !"},{"poster":"KalavathiP","timestamp":"1695697860.0","comment_id":"1017344","content":"Selected Answer: E\nE is correct","upvote_count":"2"},{"upvote_count":"2","content":"Selected Answer: E\nMerge is the correct answer","timestamp":"1686048120.0","poster":"fred_camargo","comment_id":"916151"},{"comment_id":"889039","poster":"Majjjj","timestamp":"1683157320.0","content":"Selected Answer: E\nFor following tasks, work in your Git provider:\n\nCreate a pull request.\nResolve merge conflicts.\nMerge or delete branches.\nRebase a branch.\n\nhttps://docs.databricks.com/repos/index.html","upvote_count":"2"},{"comment_id":"876195","poster":"Varma_Saraswathula","timestamp":"1682052360.0","content":"Merge - A","upvote_count":"1"},{"timestamp":"1682013480.0","poster":"naxacod574","content":"merge is not supported","comment_id":"875851","upvote_count":"1"},{"poster":"SireeJ","content":"Option: C","upvote_count":"1","timestamp":"1681225560.0","comment_id":"867432"},{"upvote_count":"3","comment_id":"863859","poster":"Data_4ever","content":"Selected Answer: E\nMERGE is the only git operation that is listed in the options that cannot be performed with Databricks repos. CLONE is absolutely possible","timestamp":"1680870540.0"},{"content":"Selected Answer: E\nwrong answer, Clone can be done in Databricks Repo. Merge not in Repos, need to be in Git. Link here: https://learn.microsoft.com/en-us/azure/databricks/repos/","comment_id":"861149","poster":"upliftinghut","timestamp":"1680617580.0","upvote_count":"3","comments":[{"comment_id":"861286","content":"Isn't that what the question is about? What operation you have to do outside of Repo. In the link provided by you, it clearly says for \"MERGE\" go to Github.","poster":"XiltroX","upvote_count":"2","timestamp":"1680625380.0"}]},{"upvote_count":"1","content":"option E","poster":"sdas1","timestamp":"1680582840.0","comment_id":"860618"},{"comment_id":"859452","content":"Selected Answer: E\nLa correcta es la E, Databricks Repose no tiene soporte para MERGE","poster":"knivesz","timestamp":"1680483180.0","upvote_count":"3"},{"poster":"XiltroX","upvote_count":"1","comment_id":"857963","comments":[{"content":"Databricks no tiene soporte para MERGE : https://docs.databricks.com/repos/index.html","poster":"knivesz","comments":[{"poster":"XiltroX","timestamp":"1680625260.0","upvote_count":"1","comment_id":"861285","content":"Thank you for the clarification."}],"upvote_count":"2","comment_id":"860264","timestamp":"1680548940.0"}],"timestamp":"1680356520.0","content":"Correct answer"}],"choices":{"B":"Pull","A":"Commit","D":"Clone","E":"Merge","C":"Push"},"isMC":true,"topic":"1","timestamp":"2023-04-01 15:42:00","answer_ET":"E","question_text":"Which of the following Git operations must be performed outside of Databricks Repos?","question_id":148,"answers_community":["E (68%)","D (32%)"],"answer":"E"},{"id":"7F5ka1vah4isfsQVpQLz","answer_images":[],"topic":"1","isMC":true,"choices":{"B":"Records that violate the expectation cause the job to fail.","D":"Records that violate the expectation are added to the target dataset and recorded as invalid in the event log.","E":"Records that violate the expectation are added to the target dataset and flagged as invalid in a field added to the target dataset.","C":"Records that violate the expectation are dropped from the target dataset and loaded into a quarantine table.","A":"Records that violate the expectation are dropped from the target dataset and recorded as invalid in the event log."},"answer":"B","answer_ET":"B","question_text":"A dataset has been defined using Delta Live Tables and includes an expectations clause:\n\nCONSTRAINT valid_timestamp EXPECT (timestamp > '2020-01-01') ON VIOLATION FAIL UPDATE\n\nWhat is the expected behavior when a batch of data containing data that violates these constraints is processed?","question_id":149,"timestamp":"2023-10-22 05:46:00","unix_timestamp":1697946360,"question_images":[],"discussion":[{"comment_id":"1282234","content":"Selected Answer: B\nB is the way","upvote_count":"1","timestamp":"1726070460.0","poster":"CommanderBigMac"},{"upvote_count":"1","poster":"benni_ale","content":"Selected Answer: B\nb is ok","comment_id":"1203859","timestamp":"1714370820.0"},{"upvote_count":"2","timestamp":"1701360480.0","content":"Selected Answer: B\nhttps://docs.databricks.com/en/delta-live-tables/sql-ref.html#sql-properties\nON VIOLATION\nOptional action to take for failed rows:\nFAIL UPDATE: Immediately stop pipeline execution.\nDROP ROW: Drop the record and continue processing.","comment_id":"1084529","poster":"55f31c8"},{"timestamp":"1699403280.0","poster":"Bakhtiyor","content":"ON VIOLATION\nFAIL UPDATE: Immediately stop pipeline execution.\nDROP ROW: Drop the record and continue processing.","upvote_count":"2","comment_id":"1065250"},{"poster":"meow_akk","timestamp":"1697946360.0","comment_id":"1050187","content":"Ans B : delta live tables data quality expectations . - https://docs.databricks.com/en/delta-live-tables/expectations.html\nAction\n\nResult\n\nwarn (default)\n\nInvalid records are written to the target; failure is reported as a metric for the dataset.\n\ndrop\n\nInvalid records are dropped before data is written to the target; failure is reported as a metrics for the dataset.\n\nfail\n\nInvalid records prevent the update from succeeding. Manual intervention is required before re-processing.","upvote_count":"4"}],"answer_description":"","exam_id":162,"url":"https://www.examtopics.com/discussions/databricks/view/124308-exam-certified-data-engineer-associate-topic-1-question-80/","answers_community":["B (100%)"]},{"id":"C8IDYeCMeQrnzfxljjrT","discussion":[{"poster":"CommanderBigMac","timestamp":"1726070520.0","comment_id":"1282237","upvote_count":"1","content":"Selected Answer: D\nSilver tables are used to clean the raw imported data from a bronze table"},{"upvote_count":"1","timestamp":"1714370820.0","comment_id":"1203860","content":"Selected Answer: D\nd is ok","poster":"benni_ale"},{"upvote_count":"2","comment_id":"1127424","timestamp":"1705772100.0","poster":"azure_bimonster","content":"Selected Answer: D\nD is the right answer"},{"timestamp":"1697946420.0","poster":"meow_akk","content":"Ans D : medallion arch databricks\nhttps://www.databricks.com/glossary/medallion-architecture","comment_id":"1050188","upvote_count":"2"}],"timestamp":"2023-10-22 05:47:00","question_images":[],"isMC":true,"url":"https://www.examtopics.com/discussions/databricks/view/124309-exam-certified-data-engineer-associate-topic-1-question-81/","question_text":"Which of the following statements regarding the relationship between Silver tables and Bronze tables is always true?","answers_community":["D (100%)"],"answer_images":[],"choices":{"A":"Silver tables contain a less refined, less clean view of data than Bronze data.","C":"Silver tables contain more data than Bronze tables.","B":"Silver tables contain aggregates while Bronze data is unaggregated.","E":"Silver tables contain less data than Bronze tables.","D":"Silver tables contain a more refined and cleaner view of data than Bronze tables."},"question_id":150,"exam_id":162,"unix_timestamp":1697946420,"answer":"D","topic":"1","answer_description":"","answer_ET":"D"}],"exam":{"lastUpdated":"12 Apr 2025","id":162,"isBeta":false,"isMCOnly":true,"numberOfQuestions":169,"provider":"Databricks","name":"Certified Data Engineer Associate","isImplemented":true},"currentPage":30},"__N_SSP":true}