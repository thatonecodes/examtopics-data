{"pageProps":{"questions":[{"id":"APNewqvzdgkPndRXuDoF","question_text":"When evaluating the Ganglia Metrics for a given cluster with 3 executor nodes, which indicator would signal proper utilization of the VM's resources?","answer":"B","question_id":81,"isMC":true,"unix_timestamp":1717204860,"answer_description":"","answer_images":[],"question_images":[],"exam_id":163,"answer_ET":"B","discussion":[{"poster":"imatheushenrique","content":"B.\nThis level of CPU utilization indicates that the cluster is being used without being underutilized.","timestamp":"1733023260.0","upvote_count":"3","comment_id":"1222410"}],"answers_community":[],"topic":"1","url":"https://www.examtopics.com/discussions/databricks/view/141704-exam-certified-data-engineer-professional-topic-1-question/","choices":{"C":"Network I/O never spikes","D":"Total Disk Space remains constant","B":"CPU Utilization is around 75%","A":"The five Minute Load Average remains consistent/flat"},"timestamp":"2024-06-01 03:21:00"},{"id":"IzjBnSE4i7eJq7L832mS","isMC":true,"url":"https://www.examtopics.com/discussions/databricks/view/141561-exam-certified-data-engineer-professional-topic-1-question/","answers_community":["C (86%)","14%"],"exam_id":163,"answer":"C","question_images":[],"discussion":[{"poster":"RuiCarvalhoDEV","upvote_count":"1","timestamp":"1732178760.0","content":"Selected Answer: C\nis MEMORY_ONLY","comment_id":"1315727"},{"content":"Selected Answer: C\nC is correct","comment_id":"1257426","upvote_count":"2","timestamp":"1722252960.0","poster":"Hadiler"},{"poster":"03355a2","content":"Selected Answer: C\nIt's simple, if MEMORY_ONLY is used, anything spilled to disk would indicate a problem.","timestamp":"1719495000.0","upvote_count":"1","comments":[{"comment_id":"1238186","content":"The RDD answer is incorrect for this question due to the fact that while this indicates a failure to cache, it is more specific to identifying individual blocks that failed to cache rather than providing a general signal of a suboptimal performance for the entire cached table.","timestamp":"1719495120.0","upvote_count":"1","poster":"03355a2"}],"comment_id":"1238184"},{"content":"Selected Answer: C\nC is correct here","comment_id":"1229350","timestamp":"1718211420.0","upvote_count":"2","poster":"hpkr"},{"comment_id":"1222919","comments":[{"comment_id":"1227736","content":"*THE CORRECT ANSWER IS: C*\nPLEASE IGNORE MY PREVIOUS ANSWER. \n\nLong story short, B is correct in the context of non-functional requirement, but the question is based in functional requirement, and sorry for the confusion.","upvote_count":"3","poster":"Freyr","timestamp":"1718006040.0"}],"timestamp":"1717277580.0","upvote_count":"1","poster":"Freyr","content":"Selected Answer: B\nCorrect Answer: B\nOption B, is the most correct and relevant choice for an indicator that a cached table is not performing optimally in a MEMORY_ONLY scenario. If an RDD block includes a \"?\" annotation, it strongly suggests issues with caching, which would directly impact the performance and expected behavior of MEMORY_ONLY caching. This indication points to a failure to cache the data entirely in memory, which is what MEMORY_ONLY intends to do.\n\nOption C, could also be a relevant indicator in general caching scenarios (e.g., MEMORY_AND_DISK), but it contradicts the MEMORY_ONLY setting directly. Therefore, Option B is chosen based on the specific storage level described."},{"content":"B.\nThis annotation says that some partitions of the cached data have been spilled to disk because there wasn't enough memory to keep them.","timestamp":"1717204440.0","poster":"imatheushenrique","upvote_count":"1","comment_id":"1222408"},{"poster":"MDWPartners","content":"I would say C","timestamp":"1717006560.0","comment_id":"1221178","upvote_count":"2"}],"question_id":82,"answer_ET":"C","answer_description":"","question_text":"The data engineer is using Spark's MEMORY_ONLY storage level.\n\nWhich indicators should the data engineer look for in the Spark UI's Storage tab to signal that a cached table is not performing optimally?","choices":{"A":"On Heap Memory Usage is within 75% of Off Heap Memory Usage","B":"The RDD Block Name includes the “*” annotation signaling a failure to cache","D":"The number of Cached Partitions > the number of Spark Partitions","C":"Size on Disk is > 0"},"timestamp":"2024-05-29 20:16:00","unix_timestamp":1717006560,"answer_images":[],"topic":"1"},{"id":"ILMDoLROtbBiqkZ11jiE","answer":"B","isMC":true,"url":"https://www.examtopics.com/discussions/databricks/view/141703-exam-certified-data-engineer-professional-topic-1-question/","discussion":[{"comment_id":"1300614","upvote_count":"1","content":"Selected Answer: B\nThe final error clearly states that such column name can not be resolved in the source dataframe schema/structure","poster":"m79590530","timestamp":"1729445880.0"}],"question_id":83,"exam_id":163,"answer_ET":"B","timestamp":"2024-05-31 23:44:00","choices":{"C":"There is a type error because a column object cannot be multiplied.","A":"There is a syntax error because the heartrate column is not correctly identified as a column.","B":"There is no column in the table named heartrateheartrateheartrate","D":"There is a type error because a DataFrame object cannot be multiplied."},"question_images":["https://img.examtopics.com/certified-data-engineer-professional/image75.png"],"question_text":"Review the following error traceback:\n\n//IMG//\n\n\nWhich statement describes the error being raised?","answer_images":[],"answer_description":"","unix_timestamp":1717191840,"topic":"1","answers_community":["B (100%)"]},{"id":"8gdvOFDAHUWPskUuL7GW","timestamp":"2024-05-31 23:43:00","exam_id":163,"choices":{"C":"Use %pip install in a notebook cell","B":"Install libraries from PyPI using the cluster UI","A":"Run source env/bin/activate in a notebook setup script","D":"Use %sh pip install in a notebook cell"},"answers_community":["C (100%)"],"question_text":"What is a method of installing a Python package scoped at the notebook level to all nodes in the currently active cluster?","question_id":84,"question_images":[],"isMC":true,"topic":"1","unix_timestamp":1717191780,"discussion":[{"timestamp":"1729446300.0","upvote_count":"1","content":"Selected Answer: C\nC is correct as '%sh pip install ...' runs only on the driver node and the Cluster UI PyPi or other library installs are not scoped to a specific notebook only but to all spark sessions in all notebooks on all cluster nodes.","poster":"m79590530","comment_id":"1300623"},{"poster":"imatheushenrique","upvote_count":"1","content":"Is necessary just run %pip install some_library inside a notebook cell\nC.\nOBS:\nFor the last update of a library can be executed %pip install some_library -U","timestamp":"1717191780.0","comment_id":"1222349"}],"answer":"C","answer_images":[],"url":"https://www.examtopics.com/discussions/databricks/view/141702-exam-certified-data-engineer-professional-topic-1-question/","answer_ET":"C","answer_description":""},{"id":"Fo1XqOAEzyJJi4Esz2pJ","exam_id":163,"timestamp":"2024-05-31 23:41:00","isMC":true,"unix_timestamp":1717191660,"question_text":"What is the first line of a Databricks Python notebook when viewed in a text editor?","choices":{"B":"// Databricks notebook source","C":"# Databricks notebook source","D":"-- Databricks notebook source","A":"%python"},"discussion":[{"timestamp":"1724804400.0","upvote_count":"2","comment_id":"1273721","content":"Selected Answer: C\nThe correct answer is:\n\nC. # Databricks notebook source\n\nThis is the comment line that appears at the beginning of a Databricks Python notebook when viewed in a text editor.","poster":"minhhnh"},{"poster":"imatheushenrique","comment_id":"1222348","timestamp":"1717191660.0","upvote_count":"2","content":"C. # Databricks notebook source\nThe commentary in the first like will indicate a magic command for a notebook source."}],"answer_ET":"C","answer":"C","question_id":85,"topic":"1","answers_community":["C (100%)"],"answer_description":"","question_images":[],"url":"https://www.examtopics.com/discussions/databricks/view/141701-exam-certified-data-engineer-professional-topic-1-question/","answer_images":[]}],"exam":{"provider":"Databricks","isBeta":false,"numberOfQuestions":200,"isMCOnly":true,"name":"Certified Data Engineer Professional","isImplemented":true,"lastUpdated":"12 Apr 2025","id":163},"currentPage":17},"__N_SSP":true}