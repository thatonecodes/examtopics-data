{"pageProps":{"questions":[{"id":"3pi0WrMqGmK0JvVJYq6C","question_images":[],"exam_id":161,"answer_description":"","answer":"A","timestamp":"2024-04-10 17:59:00","topic":"1","question_id":76,"isMC":true,"url":"https://www.examtopics.com/discussions/databricks/view/138364-exam-certified-associate-developer-for-apache-spark-topic-1/","answer_images":[],"unix_timestamp":1712764740,"choices":{"C":"1. filter\n2. (col(\"sqft\") <= 25000)\n3. and\n4. (col(\"customerSatisfaction\") >= 30)","A":"1. filter\n2. (col(\"sqft\") <= 25000)\n3. &\n4. (col(\"customerSatisfaction\") >= 30)","D":"1. drop\n2. (col(sqft) <= 25000)\n3. &\n4. (col(customerSatisfaction) >= 30)","B":"1. filter\n2. (col(\"sqft\") <= 25000\n3. &\n4. col(\"customerSatisfaction\") >= 30","E":"1. filter\n2. col(\"sqft\") <= 25000\n3. and\n4. col(\"customerSatisfaction\") >= 30"},"answers_community":[],"question_text":"The code block shown below should return a DataFrame containing only the rows from DataFrame storesDF where the value in column sqft is less than or equal to 25,000 AND the value in column customerSatisfaction is greater than or equal to 30. Choose the response that correctly fills in the numbered blanks within the code block to complete this task.\n\nCode block:\n\nstoresDF.__1__(__2__ __3__ __4__)","answer_ET":"A","discussion":[{"comment_id":"1193136","poster":"Sowwy1","content":"A. 1. filter\n2. (col(\"sqft\") <= 25000)\n3. &\n4. (col(\"customerSatisfaction\") >= 30)","upvote_count":"1","timestamp":"1728575940.0"}]},{"id":"YXTQ8rSppnu4SKwBjNUO","answers_community":["C (100%)"],"answer_description":"","topic":"1","url":"https://www.examtopics.com/discussions/databricks/view/137494-exam-certified-associate-developer-for-apache-spark-topic-1/","discussion":[{"poster":"Thameur01","comment_id":"1363964","upvote_count":"1","content":"Selected Answer: C\nC and D, regexp_replace can take both string and column type object","timestamp":"1740923340.0"},{"timestamp":"1737282180.0","content":"Selected Answer: C\nboth works: C+D\n\ntested it","upvote_count":"1","poster":"bp_a_user","comment_id":"1342951"},{"poster":"Sowwy1","timestamp":"1728576000.0","upvote_count":"1","comment_id":"1193137","content":"It's C. https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regexp_replace.html"},{"comment_id":"1185627","poster":"sionita","comments":[{"timestamp":"1732359720.0","comment_id":"1216411","upvote_count":"1","content":"yes,D also works. disregard my previous comment.","poster":"jtu363"},{"content":"needs a col object","comment_id":"1216407","timestamp":"1732359360.0","upvote_count":"1","poster":"jtu363"}],"upvote_count":"1","timestamp":"1727628960.0","content":"Why C and nod D ?"}],"question_images":["https://img.examtopics.com/certified-associate-developer-for-apache-spark/image21.png"],"answer":"C","exam_id":161,"isMC":true,"choices":{"C":"storesDF.withColumn(\"storeSlogan\", regexp_replace(col(\"storeSlogan\"), \"’\", \"\\\"\"))","E":"storesDF.withColumn(\"storeSlogan\", regexp_extract(col(\"storeSlogan\"), \"’\", \"\\\"\"))","A":"storesDF.withColumn(\"storeSlogan\", col(\"storeSlogan\").regexp_replace(\"’\" \"\\\"\"))","B":"storesDF.withColumn(\"storeSlogan\", regexp_replace(col(\"storeSlogan\"), \"’\"))","D":"storesDF.withColumn(\"storeSlogan\", regexp_replace(\"storeSlogan\", \"’\", \"\\\"\"))"},"unix_timestamp":1711738560,"question_id":77,"question_text":"Which of the following code blocks returns a DataFrame with column storeSlogan where single quotes in column storeSlogan in DataFrame storesDF have been replaced with double quotes?\n\nA sample of DataFrame storesDF is below:\n\n//IMG//","answer_ET":"C","timestamp":"2024-03-29 19:56:00","answer_images":[]},{"id":"qcZBFWi6YZJfT71vYJZQ","answer":"A","answer_ET":"A","isMC":true,"answer_images":[],"answer_description":"","question_images":[],"exam_id":161,"question_text":"Which of the following object types cannot be contained within a column of a Spark DataFrame?","unix_timestamp":1687014300,"discussion":[{"timestamp":"1722484980.0","content":"A. Spark DataFrames do not directly support containing other DataFrames as columns. A DataFrame column can only have one of the supported data types, such as primitive types (e.g., IntegerType, StringType, DoubleType, etc.) or complex types (e.g., ArrayType, MapType, StructType, etc.), but it cannot contain an entire DataFrame as a column.","comment_id":"968705","upvote_count":"3","poster":"singh100"},{"upvote_count":"2","comment_id":"926071","content":"Selected Answer: A\nSpark DataFrames are designed to store structured data, where each column has a specific data type. While DataFrames can contain various data types such as strings (option B), arrays (option C), null values (option D), and vectors (option E), they cannot directly contain other DataFrames (option A) as a column.","poster":"TmData","timestamp":"1718636700.0"}],"answers_community":["A (100%)"],"choices":{"E":"Vector","A":"DataFrame","B":"String","C":"Array","D":"null"},"url":"https://www.examtopics.com/discussions/databricks/view/112464-exam-certified-associate-developer-for-apache-spark-topic-1/","timestamp":"2023-06-17 17:05:00","topic":"1","question_id":78},{"id":"C3het2UuHmhWEqQRoo4O","question_text":"Which of the following operations can be used to rename and replace an existing column in a DataFrame?","answer_ET":"B","discussion":[{"content":"B. DataFrame.withColumnRenamed()","upvote_count":"1","comment_id":"1193139","poster":"Sowwy1","timestamp":"1728576060.0"}],"choices":{"D":"col()","C":"DataFrame.wlthColumn()","A":"DataFrame.renamedColumn()","B":"DataFrame.withColumnRenamed()","E":"DataFrame.newColumn()"},"question_images":[],"timestamp":"2024-04-10 18:01:00","topic":"1","isMC":true,"unix_timestamp":1712764860,"question_id":79,"answer_description":"","answer":"B","answers_community":[],"answer_images":[],"url":"https://www.examtopics.com/discussions/databricks/view/138365-exam-certified-associate-developer-for-apache-spark-topic-1/","exam_id":161},{"id":"3pPINLfO9rPPdMHre8Nj","question_text":"The code block shown below should print the schema of DataFrame storesDF. Choose the response that correctly fills in the numbered blanks within the code block to complete this task.\n\nCode block:\n\n__1__.__2__(__3__)","answer_ET":"D","choices":{"B":"1. storesDF\n2. str\n3. schema","C":"1. storesDF\n2. printSchema\n3. True","A":"1. storesDF\n2. schema\n3. Nothing","E":"1. storesDF\n2. printSchema\n3. \"all\"","D":"1. storesDF\n2. printSchema\n3. Nothing"},"discussion":[{"timestamp":"1737785160.0","content":"Selected Answer: D\nThe correct answer is:\n\nD. 1. storesDF 2. printSchema 3. Nothing\n\nExplanation:\n\nprintSchema() is the correct method to print the schema of a DataFrame in PySpark.\nThis method does not take any arguments (i.e., \"Nothing\" in this context), so no additional argument is needed.","poster":"Souvik_79","comment_id":"1346347","upvote_count":"1"},{"comment_id":"1193141","poster":"Sowwy1","upvote_count":"1","timestamp":"1728576120.0","content":"D. 1. storesDF\n2. printSchema\n3. Nothing"}],"question_images":[],"timestamp":"2024-04-10 18:02:00","topic":"1","isMC":true,"unix_timestamp":1712764920,"question_id":80,"answer_description":"","answer":"D","answers_community":["D (100%)"],"answer_images":[],"url":"https://www.examtopics.com/discussions/databricks/view/138366-exam-certified-associate-developer-for-apache-spark-topic-1/","exam_id":161}],"exam":{"isMCOnly":true,"name":"Certified Associate Developer for Apache Spark","id":161,"provider":"Databricks","isBeta":false,"lastUpdated":"12 Apr 2025","numberOfQuestions":185,"isImplemented":true},"currentPage":16},"__N_SSP":true}