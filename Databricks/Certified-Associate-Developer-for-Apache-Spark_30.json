{"pageProps":{"questions":[{"id":"Cb3k3jd4I4xdyc9VE1K0","exam_id":161,"answer_ET":"A","question_text":"Which of the following Spark properties is used to configure whether skewed partitions are automatically detected and subdivided into smaller partitions when joining two DataFrames together?","choices":{"B":"spark.sql.adaptive.coalescePartitions.enable","E":"spark.sql.shuffle.skewHints.enabled","C":"spark.sql.adaptive.skewHints.enabled","A":"spark.sql.adaptive.skewedJoin.enabled","D":"spark.sql.shuffle.partitions"},"answer":"A","answers_community":["A (100%)"],"topic":"1","question_images":[],"question_id":146,"answer_images":[],"url":"https://www.examtopics.com/discussions/databricks/view/113000-exam-certified-associate-developer-for-apache-spark-topic-1/","timestamp":"2023-06-22 21:43:00","answer_description":"","discussion":[{"poster":"Larrave","content":"Selected Answer: A\nAnswer should be A, but the config is skewJoin not skewedJoin","timestamp":"1703281380.0","comment_id":"930973","upvote_count":"5"},{"content":"Selected Answer: A\nA is correct","upvote_count":"1","comment_id":"1130895","poster":"amirshaz","timestamp":"1721833620.0"},{"content":"A\n\nThe Spark property used to configure whether skewed partitions are automatically detected and subdivided into smaller partitions when joining two DataFrames together is `spark.sql.adaptive.skewJoin.enabled`. This feature dynamically handles skew in sort-merge join by splitting (and replicating if needed) skewed tasks into roughly evenly sized tasks. It takes effect when both `spark.sql.adaptive.enabled` and `spark.sql.adaptive.skewJoin.enabled` configurations are enabled.","upvote_count":"3","poster":"thanab","timestamp":"1710376320.0","comment_id":"1006998"}],"isMC":true,"unix_timestamp":1687462980},{"id":"gvDtQ7Fk9PugliVDS9Ug","question_images":[],"choices":{"A":"Spark DataFrames are mutable unless they've been collected to the driver.","C":"Spark DataFrames cannot be distributed into partitions.","D":"A Spark DataFrame is a tabular data structure that is the most common Structured API in Spark.","E":"A Spark DataFrame is exactly the same as a data frame in Python or R.","B":"A Spark DataFrame is rarely used aside from the import and export of data."},"unix_timestamp":1707427980,"answer":"D","answer_images":[],"answer_description":"","answer_ET":"D","exam_id":161,"question_text":"Which of the following statements about the Spark DataFrame is true?","question_id":147,"url":"https://www.examtopics.com/discussions/databricks/view/133404-exam-certified-associate-developer-for-apache-spark-topic-1/","topic":"1","isMC":true,"discussion":[{"upvote_count":"1","comment_id":"1145050","timestamp":"1723145580.0","content":"Selected Answer: D\nD seems correct here","poster":"azure_bimonster"}],"answers_community":["D (100%)"],"timestamp":"2024-02-08 22:33:00"},{"id":"O7vIVZ5qH2WdnBf5et1G","question_id":148,"timestamp":"2023-08-28 18:43:00","isMC":true,"answers_community":["C (67%)","B (33%)"],"answer_images":[],"topic":"1","answer_description":"","choices":{"A":"storesDF.filter()","C":"storesDF.drop()","D":"storesDF.subset()","B":"storesDF.select()","E":"storesDF.dropColumn()"},"discussion":[{"timestamp":"1731031860.0","comment_id":"1065290","upvote_count":"1","content":"Selected Answer: C\nIts C not B","poster":"mehroosali"},{"content":"Selected Answer: C\nyou should be careful; with the question. The specified columns should not be in the new DF \ntherefore it is drop , you specify in drop what you want to remove and they won't be in the new DF","upvote_count":"1","comment_id":"1064884","poster":"newusername","timestamp":"1730990280.0"},{"timestamp":"1724863380.0","comment_id":"992402","upvote_count":"1","poster":"cookiemonster42","content":"Selected Answer: B\nin select you can use * instead of the column names"}],"url":"https://www.examtopics.com/discussions/databricks/view/119255-exam-certified-associate-developer-for-apache-spark-topic-1/","exam_id":161,"question_images":[],"answer":"C","answer_ET":"C","question_text":"Which of the following operations can be used to return a new DataFrame from DataFrame storesDF without columns that are specified by name?","unix_timestamp":1693240980},{"id":"wAuxSzlRQoimAaKg6nBw","answer":"D","topic":"1","discussion":[{"comment_id":"1301589","upvote_count":"1","content":"Selected Answer: D\nAnswer is D","poster":"5523042","timestamp":"1729602540.0"}],"isMC":true,"answer_description":"","question_id":149,"answer_images":[],"url":"https://www.examtopics.com/discussions/databricks/view/150062-exam-certified-associate-developer-for-apache-spark-topic-1/","exam_id":161,"choices":{"A":"storesDF.where(storesDF[sqft] > 25000)","C":"storesDF.filter(\"sqft\" <= 25000)","D":"storesDF.filter(col(\"sqft\") <= 25000)","B":"storesDF.filter(sqft > 25000)","E":"storesDF.where(sqft > 25000)"},"unix_timestamp":1729602540,"question_images":[],"answers_community":["D (100%)"],"timestamp":"2024-10-22 15:09:00","answer_ET":"D","question_text":"Which of the following code blocks returns a DataFrame containing only the rows from DataFrame storesDF where the value in column sqft is less than or equal to 25,000?"},{"id":"aofZlR9KOPqjT20BYHSu","answer":"B","discussion":[{"timestamp":"1720165920.0","comment_id":"1114407","upvote_count":"9","poster":"Akash567890978","content":"I dont think even B is correct the conditions should be inside parenthesis as well"},{"upvote_count":"1","content":"Selected Answer: B\nCorrect usage of col and \"|\"","comment_id":"1331602","poster":"JahanzebBehan","timestamp":"1735138380.0"}],"topic":"1","isMC":true,"answer_description":"","question_id":150,"answer_images":[],"url":"https://www.examtopics.com/discussions/databricks/view/130400-exam-certified-associate-developer-for-apache-spark-topic-1/","exam_id":161,"choices":{"A":"storesDF.filter(col(\"sqft\") <= 25000 and col(\"customerSatisfaction\") >= 30)","B":"storesDF.filter(col(\"sqft\") <= 25000 | col(\"customerSatisfaction\") >= 30)","C":"storesDF.filter(col(sqft) <= 25000 or col(customerSatisfaction) >= 30)","D":"storesDF.filter(sqft <= 25000 | customerSatisfaction >= 30)","E":"storesDF.filter(col(\"sqft\") <= 25000 or col(\"customerSatisfaction\") >= 30)"},"unix_timestamp":1704448320,"answers_community":["B (100%)"],"question_images":[],"timestamp":"2024-01-05 10:52:00","answer_ET":"B","question_text":"Which of the following code blocks returns a DataFrame containing only the rows from DataFrame storesDF where the value in column sqft is less than or equal to 25,000 OR the value in column customerSatisfaction is greater than or equal to 30?"}],"exam":{"name":"Certified Associate Developer for Apache Spark","isMCOnly":true,"id":161,"isBeta":false,"isImplemented":true,"provider":"Databricks","lastUpdated":"12 Apr 2025","numberOfQuestions":185},"currentPage":30},"__N_SSP":true}