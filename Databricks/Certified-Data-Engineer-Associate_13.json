{"pageProps":{"questions":[{"id":"lU4e7bafmAstjStV9FrR","question_images":[],"answer_images":[],"question_text":"In which of the following scenarios should a data engineer select a Task in the Depends On field of a new Databricks Job Task?","answers_community":["B (100%)"],"discussion":[{"content":"Selected Answer: B\nThe correct answer is B. When another task needs to successfully complete before the new task begins. Selecting a task in the \"Depends On\" field ensures that the new task will only start after the specified task has successfully completed, maintaining the correct sequence and dependencies in the workflow","timestamp":"1734356040.0","upvote_count":"1","comment_id":"1327395","poster":"MultiCloudIronMan"}],"url":"https://www.examtopics.com/discussions/databricks/view/153048-exam-certified-data-engineer-associate-topic-1-question-155/","choices":{"B":"When another task needs to successfully complete before the new task begins","D":"When another task needs to use as little compute resources as possible","C":"When another task has the same dependency libraries as the new task","A":"When another task needs to be replaced by the new task"},"unix_timestamp":1734356040,"answer":"B","question_id":61,"isMC":true,"timestamp":"2024-12-16 14:34:00","answer_ET":"B","answer_description":"","exam_id":162,"topic":"1"},{"id":"sYl3h2Cr2ujyxxkkfN5s","answer_description":"","answer":"B","question_id":62,"choices":{"C":"CREATE TABLE all_transactions AS\nSELECT * FROM march_transactions\nOUTER JOIN SELECT * FROM april_transactions;","A":"CREATE TABLE all_transactions AS\nSELECT * FROM march_transactions\nINNER JOIN SELECT * FROM april_transactions;","B":"CREATE TABLE all_transactions AS\nSELECT * FROM march_transactions\nUNION SELECT * FROM april_transactions;","D":"CREATE TABLE all_transactions AS\nSELECT * FROM march_transactions\nINTERSECT SELECT * from april_transactions;"},"answer_images":[],"url":"https://www.examtopics.com/discussions/databricks/view/153053-exam-certified-data-engineer-associate-topic-1-question-156/","topic":"1","answers_community":["B (100%)"],"exam_id":162,"discussion":[{"comment_id":"1327435","poster":"MultiCloudIronMan","timestamp":"1734360660.0","content":"Selected Answer: B\nThe correct answer is B. CREATE TABLE all_transactions AS SELECT * FROM march_transactions UNION SELECT * FROM april_transactions. The UNION operator combines the results of two queries and removes duplicate records, ensuring that the new table all_transactions contains all unique records from both march_transactions and april_transactions.","upvote_count":"2"}],"timestamp":"2024-12-16 15:51:00","unix_timestamp":1734360660,"question_text":"A data engineering team has two tables. The first table march_transactions is a collection of all retail transactions in the month of March. The second table april_transactions is a collection of all retail transactions in the month of April. There are no duplicate records between the tables.\n\nWhich of the following commands should be run to create a new table all_transactions that contains all records from march_transactions and april_transactions without duplicate records?","isMC":true,"answer_ET":"B","question_images":[]},{"id":"uEuKrTAjpsA7mk0S7j50","question_text":"How can Git operations must be performed outside of Databricks Repos?","answer_description":"","question_images":[],"url":"https://www.examtopics.com/discussions/databricks/view/153054-exam-certified-data-engineer-associate-topic-1-question-157/","isMC":true,"answer_images":[],"answer_ET":"C","timestamp":"2024-12-16 15:53:00","exam_id":162,"answer":"C","discussion":[{"content":"Selected Answer: C\nC. Merge:\nMerging branches is not natively supported within Databricks Repos. While you can switch branches and commit changes, the act of merging two branches (e.g., resolving conflicts or combining histories) requires a Git client outside of Databricks or handling it in the remote Git hosting service (e.g., creating a pull request on GitHub). Databricks documentation indicates that merge operations, especially those involving conflicts, are outside its scope, pushing users to external tools.\nVerdict: Aligns with the questionâ€”merge operations must be performed outside Databricks","comment_id":"1400837","timestamp":"1742428260.0","upvote_count":"1","poster":"45a1d55"},{"timestamp":"1738009380.0","upvote_count":"1","content":"Selected Answer: C\nIt should be MERGE","comment_id":"1347554","poster":"IulianRo"},{"content":"Selected Answer: C\nMerge happen outside of DB","comment_id":"1343073","timestamp":"1737302520.0","upvote_count":"1","poster":"shinypriti23"},{"content":"Selected Answer: C\nMerge needs to happen outside of DB","comment_id":"1337145","poster":"CoolSmartDude","upvote_count":"1","timestamp":"1736167680.0"},{"content":"Selected Answer: C\nSee https://docs.databricks.com/en/repos/git-operations-with-repos.html\n\"The article describes how to perform common Git operations in your Databricks workspace using Git folders, including cloning, branching, committing, and pushing.\"\nSee also Question 8.","poster":"duzi","upvote_count":"2","comment_id":"1335980","timestamp":"1735900200.0"},{"comment_id":"1327437","poster":"MultiCloudIronMan","timestamp":"1734360780.0","comments":[{"content":"Clone is done inside Databricks from external Git Repo, i don't get your answer.\n\nIn other side, MERGing a Pull request with a branch cannot be done inside Databricks repo.\n\nI see that MERGE is the only Git Operation that can be done outside Databricks Repo. \n\nAns : C","poster":"CaoMengde09","comment_id":"1334114","upvote_count":"2","timestamp":"1735561920.0"}],"upvote_count":"1","content":"Selected Answer: D\nThe correct answers are A. Commit and D. Clone. These Git operations must be performed outside of Databricks Repos."}],"answers_community":["C (86%)","14%"],"topic":"1","unix_timestamp":1734360780,"choices":{"C":"Merge","B":"Pull","A":"Commit","D":"Clone"},"question_id":63},{"id":"5eD4YA2cjOIkGu15ValL","url":"https://www.examtopics.com/discussions/databricks/view/153055-exam-certified-data-engineer-associate-topic-1-question-158/","choices":{"D":"The customers table is a reference to a Structured Streaming query on a PySpark DataFrame.","C":"The customers table is a streaming live table.","B":"The data in the customers table has been updated since its last run.","A":"The STREAM function is not needed and will cause an error."},"timestamp":"2024-12-16 15:55:00","isMC":true,"unix_timestamp":1734360900,"answer":"C","topic":"1","answer_images":[],"question_id":64,"discussion":[{"content":"Selected Answer: C\nThe correct answer is C. The customers table is a streaming live table. The STREAM function is used to indicate that the customers table is a streaming live table, which means it is continuously updated with new data. This allows the loyal_customers table to be created as a streaming live table that processes data incrementally as it arrives.","timestamp":"1734360900.0","comment_id":"1327441","upvote_count":"3","poster":"MultiCloudIronMan"}],"answer_ET":"C","question_images":[],"answers_community":["C (100%)"],"question_text":"A data engineer has joined an existing project and they see the following query in the project repository:\n\nCREATE STREAMING LIVE TABLE loyal_customers AS\n\nSELECT customer_id -\nFROM STREAM(LIVE.customers)\nWHERE loyalty_level = 'high';\n\nWhich of the following describes why the STREAM function is included in the query?","answer_description":"","exam_id":162},{"id":"LSkeCEdhvOTL6gRpOcKL","timestamp":"2024-12-05 23:36:00","question_images":[],"answer_ET":"D","answers_community":["D (75%)","B (25%)"],"answer_description":"","answer_images":[],"discussion":[{"upvote_count":"1","comment_id":"1324349","poster":"datareport_AZ","content":"Selected Answer: B\nB performs aggregation","timestamp":"1733800080.0"},{"comment_id":"1322912","content":"Selected Answer: D\nSilver table contains filtered, cleaned augmented data. Gold table contains aggregated data","upvote_count":"1","poster":"b41de50","timestamp":"1733518920.0"},{"poster":"Manish_Kum","timestamp":"1733438160.0","upvote_count":"2","content":"Selected Answer: D\naggregation is performed in Silver to Gold hop. also outputmode will be \"complete\"","comment_id":"1322551"}],"question_text":"Which Structured Streaming query is performing a hop from a Silver table to a Gold table?","exam_id":162,"isMC":true,"url":"https://www.examtopics.com/discussions/databricks/view/152588-exam-certified-data-engineer-associate-topic-1-question-159/","unix_timestamp":1733438160,"answer":"D","choices":{"C":"","B":"","A":"","D":""},"topic":"1","question_id":65}],"exam":{"isMCOnly":true,"id":162,"numberOfQuestions":169,"provider":"Databricks","name":"Certified Data Engineer Associate","isBeta":false,"isImplemented":true,"lastUpdated":"12 Apr 2025"},"currentPage":13},"__N_SSP":true}