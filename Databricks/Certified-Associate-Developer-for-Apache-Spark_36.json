{"pageProps":{"questions":[{"id":"KV2Lf7OxdeNtWxCBj162","discussion":[{"content":"Selected Answer: B\nthis is the right one","upvote_count":"2","timestamp":"1723206540.0","poster":"azure_bimonster","comment_id":"1145548"},{"upvote_count":"4","poster":"Raju_Bhai","comment_id":"1041419","content":"correct syatx=> df.join(x, KEY, 'inner'), so option B","timestamp":"1712902320.0"},{"timestamp":"1710255780.0","poster":"thanab","upvote_count":"4","comment_id":"1005773","content":"B is correct."},{"content":"Selected Answer: B\nB looks to be right","comment_id":"982503","poster":"Ram459","upvote_count":"4","timestamp":"1708091400.0"},{"timestamp":"1706647380.0","content":"B is correct","poster":"zozoshanky","comments":[{"comment_id":"969552","poster":"cookiemonster42","timestamp":"1706845140.0","content":"agreed, mate, it's B, the type is the last argument","upvote_count":"2"}],"upvote_count":"4","comment_id":"967415"}],"answer":"B","answers_community":["B (100%)"],"exam_id":161,"answer_description":"","question_id":176,"topic":"1","answer_ET":"B","isMC":true,"question_images":[],"url":"https://www.examtopics.com/discussions/databricks/view/116815-exam-certified-associate-developer-for-apache-spark-topic-1/","answer_images":[],"unix_timestamp":1690742580,"timestamp":"2023-07-30 20:43:00","choices":{"D":"1. join\n2. employeesDF\n3. \"inner\"\n4. \"storeId\"","A":"1. join\n2. employeesDF\n3. \"inner\"\n4. storesDF.storeId === employeesDF.storeId","B":"1. join\n2. employeesDF\n3. \"storeId\"\n4. \"inner\"","C":"1. merge\n2. employeesDF\n3. \"storeId\"\n4. \"inner\"","E":"1. join\n2. employeesDF\n3. \"inner\"\n4. \"storeId\""},"question_text":"The code block shown below should return a new DataFrame that is the result of an inner join between DataFrame storeDF and DataFrame employeesDF on column storeId. Choose the response chat correctly fills in the numbered blanks within the code block to complete this task.\n\nCode block:\n\nstoresDF.__1__(__2__, __3__, __4__)"},{"id":"ALGanJP9ySbaIeLz4VQg","question_text":"The code block shown below should return a new DataFrame that is the result of an outer join between DataFrame storesDF and DataFrame employeesDF on column storeId. Choose the response that correctly fills in the numbered blanks within the code block to complete this task.\n\nCode block:\n\nstoresDF.__1__(__2__, __3__, __4__)","discussion":[{"timestamp":"1724166780.0","content":"Selected Answer: E\nIt's E but th is question is for scala since Seq is not a python data type.","upvote_count":"1","poster":"6546a53","comment_id":"1269569"},{"content":"Correct","upvote_count":"2","timestamp":"1690940460.0","comment_id":"969553","poster":"cookiemonster42"}],"url":"https://www.examtopics.com/discussions/databricks/view/117034-exam-certified-associate-developer-for-apache-spark-topic-1/","answers_community":["E (100%)"],"question_id":177,"exam_id":161,"unix_timestamp":1690940460,"answer_ET":"E","timestamp":"2023-08-02 03:41:00","choices":{"A":"1. join\n2. employeesDF\n3. \"outer\"\n4. Seq(\"storeId\")","E":"1. join\n2. employeesDF\n3. Seq(\"storeId\")\n4. \"outer\"","C":"1. join\n2. employeesDF\n3. \"outer\"\n4. storesDF.storeId === employeesDF.storeId","B":"1. merge\n2. employeesDF\n3. \"outer\"\n4. Seq(\"storeId\")","D":"1. merge\n2. employeesDF\n3. Seq(\"storeId\")\n4. \"outer\""},"question_images":[],"answer_images":[],"topic":"1","answer":"E","answer_description":"","isMC":true},{"id":"VTVRL1plqaeYNwAurtW8","choices":{"C":"storesDF.join(employeesDF, storesDF(\"storeId\") === employeesDF(\"storeId\") and storesDF(\"employeeId\") === employeesDF(\"employeeId\"))","A":"storesDF.join(employeesDF, Seq(col(\"storeId\"), col(\"employeeId\")))","B":"storesDF.join(employeesDF, Seq(\"storeId\", \"employeeId\"))","D":"storesDF.join(employeesDF, Seq(\"storeId\", \"employeeId\"), \"inner\")","E":"storesDF.alias(\"s\").join(employeesDF.alias(\"e\"), col(\"s.storeId\") === col(\"e.storeId\") and col(\"s.employeeId\") === col(\"e.employeeId\"))"},"unix_timestamp":1699533060,"url":"https://www.examtopics.com/discussions/databricks/view/125670-exam-certified-associate-developer-for-apache-spark-topic-1/","answer":"B","topic":"1","isMC":true,"question_id":178,"exam_id":161,"question_images":[],"timestamp":"2023-11-09 13:31:00","answers_community":["B (33%)","A (33%)","C (33%)"],"answer_images":[],"discussion":[{"content":"Selected Answer: C\nThe correct answer is: C. \nstoresDF.join(employeesDF, storesDF(\"storeId\") === employeesDF(\"storeId\") and storesDF(\"employeeId\") === employeesDF(\"employeeId\"))\n\nExplanation:\nThis code block contains an issue because the and operation should be replaced with && in Spark SQL for combining conditions. The and keyword is not valid in Spark's DataFrame API; you need to use && (which is a logical operator for combining conditions in Spark).","poster":"ARUNKUMARKRISHNASAMY","timestamp":"1741655820.0","upvote_count":"1","comment_id":"1387236"},{"content":"A, because col keyword is not needed while joining","upvote_count":"2","timestamp":"1727597880.0","comment_id":"1185350","poster":"237f4d0"},{"upvote_count":"1","comment_id":"1163906","content":"Selected Answer: A\nSorry A, no col","poster":"tangerine141","timestamp":"1725242640.0"},{"upvote_count":"1","timestamp":"1725241500.0","content":"Selected Answer: B\nstoresDF.join(employeesDF, Seq(\"storeId\", \"employeeId\"))","poster":"tangerine141","comment_id":"1163897"}],"answer_description":"","answer_ET":"A","question_text":"Which of the following code blocks fails to return a new DataFrame that is the result of an inner join between DataFrame storesDF and DataFrame employeesDF on column storeId and column employeeId?"},{"id":"Kyc7t6v9dExV0ogtndAs","answer":"A","exam_id":161,"topic":"1","isMC":true,"answers_community":["A (100%)"],"question_id":179,"answer_ET":"A","discussion":[{"upvote_count":"8","content":"Correct answer is A. storesDF is smaller and should be broadcasted.","comment_id":"931662","comments":[{"upvote_count":"1","poster":"cookiemonster42","content":"Agreed!","timestamp":"1706846820.0","comment_id":"969572"}],"timestamp":"1703346000.0","poster":"ryanmu"},{"content":"Selected Answer: A\nI would go with A as storesDF is smaller and right one to broadcast","comment_id":"1145556","upvote_count":"1","poster":"azure_bimonster","timestamp":"1723207200.0"},{"content":"–ê is the correct answer!","timestamp":"1711703880.0","comment_id":"1020566","poster":"veli4ko","upvote_count":"2"},{"poster":"thanab","content":"A\nThe correct answer is:\n\nA. 1. employeesDF\n2. broadcast\n3. storesDF\n\nSo the correct code would be:\n\n```scala\nemployeesDF.join(broadcast(storesDF), \"storeId\")\n```\n\nThis code will perform a broadcast join of the DataFrame `storesDF` (which is smaller) with the much larger DataFrame `employeesDF` using the key column `storeId`. The `broadcast()` function is used to mark a DataFrame to be broadcast when performing a join operation. The smaller DataFrame `storesDF` is broadcasted to all nodes, where it's joined with the larger DataFrame `employeesDF`.","upvote_count":"1","comment_id":"1004678","timestamp":"1710163440.0"},{"upvote_count":"2","content":"Selected Answer: A\nsmaller dataset needs to be broadcasted","timestamp":"1708109400.0","comment_id":"982785","poster":"Ram459"}],"unix_timestamp":1687527600,"answer_description":"","question_text":"The code block shown below should efficiently perform a broadcast join of DataFrame storesDF and the much larger DataFrame employeesDF using key column storeId.\n\nChoose the response that correctly fills in the numbered blanks within the code block to complete this task.\n\nCode block:\n\n__1__.join(__2__(__3__), \"storeId\")","answer_images":[],"question_images":[],"url":"https://www.examtopics.com/discussions/databricks/view/113099-exam-certified-associate-developer-for-apache-spark-topic-1/","choices":{"C":"1. broadcast\n2. employeesDF\n3. storesDF","E":"1. broadcast(storesDF)\n2. broadcast\n3. employeesDF","A":"1. employeesDF\n2. broadcast\n3. storesDF","D":"1. storesDF\n2. broadcast\n3. employeesDF","B":"1. broadcast(employeesDF)\n2. broadcast\n3. storesDF"},"timestamp":"2023-06-23 15:40:00"},{"id":"f0jKP5GULwhxUc6aP2O6","choices":{"C":"The standalone crossJoin() function","A":"DataFrame.join()","B":"The standalone join() function","D":"DataFrame.crossJoin()","E":"DataFrame.merge()"},"timestamp":"2024-04-01 10:13:00","answer_description":"","answers_community":["D (100%)"],"question_id":180,"url":"https://www.examtopics.com/discussions/databricks/view/137681-exam-certified-associate-developer-for-apache-spark-topic-1/","unix_timestamp":1711959180,"question_text":"Which of the following operations performs a cross join on two DataFrames?","answer":"D","isMC":true,"question_images":[],"topic":"1","discussion":[{"content":"Selected Answer: D\nD - https://api-docs.databricks.com/python/pyspark/latest/pyspark.sql/api/pyspark.sql.DataFrame.crossJoin.html","poster":"f728f7f","upvote_count":"1","comment_id":"1243783","timestamp":"1720348200.0"},{"content":"D. DataFrame.crossJoin()","upvote_count":"1","timestamp":"1711959180.0","poster":"Sowwy1","comment_id":"1187302"}],"answer_ET":"D","exam_id":161,"answer_images":[]}],"exam":{"id":161,"isImplemented":true,"name":"Certified Associate Developer for Apache Spark","provider":"Databricks","lastUpdated":"12 Apr 2025","isBeta":false,"numberOfQuestions":185,"isMCOnly":true},"currentPage":36},"__N_SSP":true}