{"pageProps":{"questions":[{"id":"4K8d2aEB3Ca4Y25DGA1x","discussion":[{"upvote_count":"1","comment_id":"1253493","poster":"jds0","content":"Selected Answer: E\nOption E is correct.\nCode example below:\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, asc, desc\nfrom pyspark.errors import PySparkTypeError\n\nspark = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n\ndata = [\n (0, 43161, \"A\"),\n (1, 51200, \"A\"),\n (2, None, \"B\"),\n (3, 78367, \"B\"),\n (4, None, \"C\"),\n ]\nstoresDF = spark.createDataFrame(data, [\"storeID\", \"sqft\", \"division\"])\n\nstoresDF.printSchema()\n# root\n# |-- storeID: long (nullable = true)\n# |-- sqft: long (nullable = true)\n# |-- division: string (nullable = true)","timestamp":"1721721600.0"},{"timestamp":"1682946000.0","comment_id":"886252","upvote_count":"3","poster":"4be8126","content":"Selected Answer: E\nE. The printSchema member of DataFrame is an operation and needs to be followed by parentheses.\n\nThe correct code block should be storesDF.printSchema() with parentheses to indicate that it's a method call."}],"exam_id":161,"isMC":true,"answers_community":["E (100%)"],"question_text":"The code block shown below contains an error. The code block is intended to print the schema of DataFrame storesDF. Identify the error.\nCode block:\nstoresDF.printSchema","answer_images":[],"question_images":[],"answer_ET":"E","answer":"E","choices":{"D":"There is no printSchema member of DataFrame – the schema() operation should be used instead.","E":"The printSchema member of DataFrame is an operation and needs to be followed by parentheses.","A":"There is no printSchema member of DataFrame – schema and the print() function should be used instead.","C":"There is no printSchema member of DataFrame – the getSchema() operation should be used instead.","B":"The entire line needs to be a string – it should be wrapped by str()."},"topic":"1","timestamp":"2023-05-01 15:00:00","url":"https://www.examtopics.com/discussions/databricks/view/108118-exam-certified-associate-developer-for-apache-spark-topic-1/","question_id":121,"unix_timestamp":1682946000,"answer_description":""},{"id":"1sGTmDVbMggchUO6dS3g","exam_id":161,"choices":{"E":"1. udf\n2. register\n3. ASSESS_PERFORMANCE\n4. assessPerformance\n5. ASSESS_PERFORMANCE","D":"1. register\n2. udf\n3. \"ASSESS_PERFORMANCE\"\n4. assessPerformance\n5. \"ASSESS_PERFORMANCE\"","C":"1. udf\n2. register\n3.\"ASSESS_PERFORMANCE\"\n4. assessPerformance\n5. \"ASSESS_PERFORMANCE\"","B":"1. udf\n2. register\n3. assessPerformance\n4. \"ASSESS_PERFORMANCE\"\n5. \"ASSESS_PERFORMANCE\"","A":"1. udf\n2. register\n3. \"ASSESS_PERFORMANCE\"\n4. assessPerformance\n5. ASSESS_PERFORMANCE"},"answer_description":"","timestamp":"2023-05-01 15:01:00","topic":"1","answers_community":["A (100%)"],"url":"https://www.examtopics.com/discussions/databricks/view/108119-exam-certified-associate-developer-for-apache-spark-topic-1/","unix_timestamp":1682946060,"question_text":"The code block shown below should create and register a SQL UDF named \"ASSESS_PERFORMANCE\" using the Python function assessPerformance() and apply it to column customerSatisfaction in table stores. Choose the response that correctly fills in the numbered blanks within the code block to complete this task.\nCode block:\nspark._1_._2_(_3_, _4_)\nspark.sql(\"SELECT customerSatisfaction, _5_(customerSatisfaction) AS result FROM stores\")","discussion":[{"comment_id":"1254336","content":"Selected Answer: A\nAnswer: A\nSee code example below with Spark 3.5.1:\n\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n\ndata = [\n (0, 43161, \"A\"),\n (1, 51200, \"A\"),\n (3, 78367, \"B\"),\n ]\nstoresDF = spark.createDataFrame(data, [\"storeID\", \"sqft\", \"division\"])\n\ndef assess_performance(x):\n return \"Large\" if x > 50000 else \"Small\"\n\nspark.udf.register(\"ASSESS_PERFORMANCE\", assess_performance, \"STRING\")\n\nstoresDF.createOrReplaceTempView(\"stores\")\n\ndf = spark.sql(\"SELECT StoreID, ASSESS_PERFORMANCE(sqft) AS performance FROM stores\")\ndf.show()","poster":"jds0","upvote_count":"2","timestamp":"1721818620.0"},{"upvote_count":"2","poster":"azurearch","timestamp":"1709840880.0","content":"def assessperformance():\n return 'Good'\n\nspark.udf.register(\"assessperformance\",assessperformance)\ndf = spark.sql(\"SELECT assessperformance()\")\ndf.show()\n\nA","comment_id":"1168315"},{"timestamp":"1682946060.0","poster":"4be8126","comment_id":"886254","upvote_count":"2","content":"Selected Answer: A\nAnswer: A\n\nExplanation:\n\nudf: create a user-defined function (UDF) in PySpark\nregister: register the UDF with Spark so it can be used in SQL queries\n\"ASSESS_PERFORMANCE\": name the UDF \"ASSESS_PERFORMANCE\"\nassessPerformance: specify the Python function to use for the UDF\nASSESS_PERFORMANCE: use the registered UDF in the SQL query to apply the assessPerformance() function to the customerSatisfaction column."}],"question_id":122,"answer_images":[],"isMC":true,"question_images":[],"answer_ET":"A","answer":"A"},{"id":"FnLGqlPAsykbMYoOWUaR","unix_timestamp":1682946300,"answers_community":["D (70%)","A (30%)"],"exam_id":161,"answer":"D","answer_description":"","timestamp":"2023-05-01 15:05:00","question_id":123,"question_images":[],"question_text":"The code block shown below contains an error. The code block is intended to create a Python UDF assessPerformanceUDF() using the integer-returning Python function assessPerformance() and apply it to column customerSatisfaction in DataFrame storesDF. Identify the error.\nCode block:\nassessPerformanceUDF – udf(assessPerformance)\nstoresDF.withColumn(\"result\", assessPerformanceUDF(col(\"customerSatisfaction\")))","url":"https://www.examtopics.com/discussions/databricks/view/108120-exam-certified-associate-developer-for-apache-spark-topic-1/","answer_ET":"D","answer_images":[],"choices":{"B":"The withColumn() operation is not appropriate here – UDFs should be applied by iterating over rows instead.","A":"The assessPerformance() operation is not properly registered as a UDF.","E":"The assessPerformance() operation should be used on column customerSatisfaction rather than the assessPerformanceUDF() operation.","D":"The return type of the assessPerformanceUDF() is not specified in the udf() operation.","C":"UDFs can only be applied vie SQL and not through the DataFrame API."},"topic":"1","isMC":true,"discussion":[{"upvote_count":"11","timestamp":"1686086160.0","poster":"ZSun","content":"The right answer is D.\npyspark.sql.functions.udf(f=None, returnType=StringType)\nThe default return type is string, but this question requires integer returning.\nso it should be D. \"The return type of the assessPerformanceUDF() is not specified in the udf() operation.\"","comments":[{"poster":"jds0","comment_id":"1254337","upvote_count":"2","content":"Good explanation for Answer being D. Thank you!","timestamp":"1721818860.0"}],"comment_id":"916651"},{"content":"Selected Answer: D\nD is the right answer as otherwise the return type is the default StringType().\nTest code below:\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, udf\nfrom pyspark.sql.types import IntegerType\n\nspark = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n\ndata = [\n (0, 3, \"A\"),\n (1, 1, \"A\"),\n (2, 2, \"A\"),\n ]\nstoresDF = spark.createDataFrame(data, [\"storeID\", \"customerSatisfaction\", \"division\"])\n\ndef assessPerformance(x):\n return 1 if x > 3 else 0\n\nprint(\"IntegerType()\")\nassessPerformanceUDF = udf(assessPerformance, IntegerType())\ndf = storesDF.withColumn(\"result\", assessPerformanceUDF(col(\"customerSatisfaction\")))\ndf.printSchema()\n\nprint(\"Default\")\nassessPerformanceUDF = udf(assessPerformance)\ndf = storesDF.withColumn(\"result\", assessPerformanceUDF(col(\"customerSatisfaction\")))\ndf.printSchema()","comment_id":"1254338","timestamp":"1721819040.0","upvote_count":"3","poster":"jds0"},{"comment_id":"1237511","content":"correct answer is D","upvote_count":"1","timestamp":"1719410880.0","poster":"Raheel_te"},{"poster":"juliom6","upvote_count":"1","timestamp":"1698936120.0","comment_id":"1060626","content":"Selected Answer: D\nIt is necessary to inform the return type as IntegerType().\n\nfrom pyspark.sql.functions import udf, col\nfrom pyspark.sql.types import IntegerType\n\nstoresDF = spark.createDataFrame([('1', '123'), ('2', '234')], ['id', 'customerSatisfaction'])\nassessPerformance = lambda x: int(x)\n\nassessPerformanceUDF = udf(assessPerformance, IntegerType())\nstoresDF.withColumn('result', assessPerformanceUDF(col('customerSatisfaction'))).printSchema()"},{"content":"| 1. When `f` is a Python function:\n | \n | `returnType` defaults to string type and can be optionally specified. The produced\n | object must match the specified type. In this case, this API works as if\n | `register(name, f, returnType=StringType())`.","comment_id":"1021250","poster":"Singh_Sumit","upvote_count":"2","timestamp":"1696048620.0"},{"comment_id":"1008844","upvote_count":"2","content":"Selected Answer: D\nThe error in the code block is that the return type of the assessPerformanceUDF() is not specified in the udf() operation. In PySpark, when you register a Python function as a UDF, you should also specify the return type. This is important because Spark SQL needs to understand the return type to properly handle the UDF. Therefore, the correct answer is:","timestamp":"1694838300.0","poster":"thanab"},{"poster":"cookiemonster42","timestamp":"1691073540.0","comment_id":"971212","content":"Selected Answer: D\nif they mean that - is =, then we need a second parameter, the output type. so, D is the answe","upvote_count":"1"},{"comment_id":"945717","upvote_count":"2","content":"Right answer is D, return type has to be specified into udf() or it will return StringType by default, the code should be : \nfunction_UDF = udf(function, returnType=IntegerType())","timestamp":"1688736120.0","poster":"Deuterium"},{"upvote_count":"3","content":"Selected Answer: A\nThe error in the code block is A. The function assessPerformance() needs to be passed as a parameter to the udf() operation in order to create a UDF from it. The correct code block should be:\n\nassessPerformanceUDF = udf(assessPerformance)\nstoresDF.withColumn(\"result\", assessPerformanceUDF(col(","comments":[{"poster":"ZSun","content":"what is the difference between your code and question itsefl?\nassessPerformanceUDF – udf(assessPerformance)\nassessPerformanceUDF = udf(assessPerformance)\nchanging \"-\" to \"=\"?","comment_id":"916650","timestamp":"1686086040.0","upvote_count":"3"}],"poster":"4be8126","timestamp":"1682946300.0","comment_id":"886261"}]},{"id":"NsnPeMeVKpjhqUTuvVZv","choices":{"B":"The sql() operation should be accessed via the spark variable rather than DataFrame storesDF.","D":"This cannot be accomplished using SQL – the DataFrame API should be used instead.","C":"There is the sql() operation in DataFrame storesDF. The operation query() should be used instead.","E":"The createOrReplaceTempView() operation should be accessed via the spark variable rather than DataFrame storesDF.","A":"The createOrReplaceTempView() operation does not make a Dataframe accessible via SQL."},"question_id":124,"isMC":true,"answer_images":[],"question_images":[],"question_text":"The code block shown below contains an error. The code block is intended to use SQL to return a new DataFrame containing column storeId and column managerName from a table created from DataFrame storesDF. Identify the error.\nCode block:\nstoresDF.createOrReplaceTempView(\"stores\")\nstoresDF.sql(\"SELECT storeId, managerName FROM stores\")","answer_ET":"B","unix_timestamp":1682947020,"answers_community":["B (100%)"],"answer_description":"","exam_id":161,"discussion":[{"content":"Selected Answer: B\nB is correct. 'storeDF' has not attribute or method `sql`\nTest code below:\n\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n\ndata = [\n (0, 3, \"John\"),\n (1, 1, \"Jane\"),\n (2, 2, \"Jack\"),\n ]\nstoresDF = spark.createDataFrame(data, [\"storeID\", \"customerSatisfaction\", \"managerName\"])\n\nstoresDF.createOrReplaceTempView(\"stores\")\ntry:\n storesDF.sql(\"SELECT storeId, managerName FROM stores\")\nexcept AttributeError as e:\n print(e)\nfinally:\n spark.sql(\"SELECT storeId, managerName FROM stores\").show()","upvote_count":"2","poster":"jds0","comment_id":"1254339","timestamp":"1721819220.0"},{"upvote_count":"2","timestamp":"1698936720.0","comment_id":"1060632","poster":"juliom6","content":"Selected Answer: B\nB is correct:\n\nstoresDF = spark.createDataFrame([('1', 'juan'), ('2', 'perez')], ['storeId', 'managerName'])\nstoresDF.createOrReplaceTempView(\"stores\")\nspark.sql(\"SELECT storeId, managerName FROM stores\").show()"},{"content":"Selected Answer: B\nOption B is correct because the sql() function is not a method of a DataFrame object. It is actually a method of the SparkSession object spark. Therefore, the correct way to execute a SQL statement using Spark SQL is to call sql() on the SparkSession object as follows:\n\nspark.sql(\"SELECT storeId, managerName FROM stores\")\n\nIn the code block provided in the question, sql() is called on a DataFrame object, which will result in a DataFrame object without executing the SQL statement. Therefore, option B correctly identifies the error in the code block.","poster":"4be8126","timestamp":"1682947020.0","comment_id":"886279","upvote_count":"2"}],"url":"https://www.examtopics.com/discussions/databricks/view/108121-exam-certified-associate-developer-for-apache-spark-topic-1/","answer":"B","topic":"1","timestamp":"2023-05-01 15:17:00"},{"id":"8QWWePqoEDhxF4GgXxzK","choices":{"B":"1. DataFrame\n2. create\n3. [years]\n4. IntegerType","D":"1. spark\n2. createDataFrame\n3. [years]\n4. IntegertType()","E":"1. spark\n2. createDataFrame\n3. years\n4. IntegertType()","A":"1. spark\n2. createDataFrame\n3. years\n4. IntegerType","C":"1. spark\n2. createDataFrame\n3. [years]\n4. IntegertType"},"answer_images":[],"question_id":125,"isMC":true,"question_images":[],"question_text":"The code block shown below should create a single-column DataFrame from Python list years which is made up of integers. Choose the response that correctly fills in the numbered blanks within the code block to complete this task.\nCode block:\n_1_._2_(_3_, _4_)","answer_ET":"E","unix_timestamp":1681411260,"answers_community":["E (100%)"],"answer_description":"","exam_id":161,"discussion":[{"timestamp":"1681411260.0","upvote_count":"10","poster":"peekaboo15","content":"The answer should be E because Year is already a python list.","comment_id":"869667"},{"content":"Selected Answer: E\nit uses spark.createDataFrame correctly with the Python list years and the appropriate data type IntegerType(). All other options have errors either in syntax or the use of PySpark methods and types.","poster":"zic00","timestamp":"1724688720.0","comment_id":"1272890","upvote_count":"1"},{"poster":"jds0","timestamp":"1721819400.0","content":"Selected Answer: E\nE is the right answer\nSee code below:\n\n# Create a DataFrame from a list of integers\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import IntegerType\n\nspark = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n\nyears = [2017, 2018, 2019]\ndf = spark.createDataFrame(years, IntegerType())\n\ndf.show()\ndf.printSchema()","upvote_count":"4","comment_id":"1254342"},{"upvote_count":"1","comment_id":"1154523","content":"Selected Answer: E\nE is the most suitable, but it also contains an error.\n\nIn PySpark, the correct class name for the integer data type is IntegerType (not \"IntegertType\").","poster":"znets","timestamp":"1708412160.0"},{"content":"e is the right","comment_id":"1110452","timestamp":"1704018480.0","upvote_count":"1","poster":"mahmoud_salah30"},{"poster":"juliom6","upvote_count":"1","content":"Selected Answer: E\nE is correct:\n\nfrom pyspark.sql.types import IntegerType\nyears = [2023, 2024]\nprint(type(years))\nstoresDF = spark.createDataFrame(years, IntegerType())\nstoresDF.show()\n\n<class 'list'>\n+-----+\n|value|\n+-----+\n| 2023|\n| 2024|\n+-----+","timestamp":"1698937500.0","comment_id":"1060636"},{"upvote_count":"1","content":"D\n\nfrom pyspark.sql.types import IntegerType\nspark.createDataFrame([1991,2023],IntegerType()).show()\n\n+-----+\n|value|\n+-----+\n| 1991|\n| 2023|\n+-----+","poster":"juadaves","comment_id":"1048022","timestamp":"1697726460.0","comments":[{"content":"it's E. years is already a list","comment_id":"1235435","poster":"carlosmps","upvote_count":"2","timestamp":"1719066600.0"}]},{"upvote_count":"1","timestamp":"1694841180.0","comment_id":"1008895","content":"Selected Answer: E\n1. spark\n2. createDataFrame\n3. years\n4. IntegertType()","poster":"thanab"},{"poster":"cookiemonster42","upvote_count":"1","content":"Selected Answer: E\nif years is variable, it works, just tested it: years = [1, 3, 4, 5 , 9]\ndf7 = spark.createDataFrame(years, IntegerType())\ndf7.show()\n\nthis works as well: df7 = spark.createDataFrame([1, 3, 4, 5 , 9], IntegerType())\ndf7.show()\n\nthis won't work:\ndf7 = spark.createDataFrame([years], IntegerType())\ndf7.show()\n\nso, the answer is E","timestamp":"1691074620.0","comment_id":"971227"},{"upvote_count":"1","content":"E. D is giving an error .","comment_id":"968903","poster":"singh100","timestamp":"1690880220.0"},{"timestamp":"1690733400.0","comment_id":"967271","poster":"zozoshanky","upvote_count":"1","content":"D throws a big error.\n/usr/local/spark/python/pyspark/sql/types.py in verify_acceptable_types(obj)\n 1291 # subclass of them can not be fromInternal in JVM\n 1292 if type(obj) not in _acceptable_types[_type]:\n-> 1293 raise TypeError(new_msg(\"%s can not accept object %r in type %s\"\n 1294 % (dataType, obj, type(obj))))\n 1295 \n\nTypeError: field value: IntegerType can not accept object [1, 2, 3, 4, 5] in type <class 'list'>\n\nE is correct answer \n\nfrom pyspark.sql.types import IntegerType\na = [1,2,3,4,5]\nspark.createDataFrame(a, IntegerType()).show()"},{"upvote_count":"2","comment_id":"880764","content":"Two responses\n1. D is an error. E will split the array into rows\n2. spark.createDataFrame([arraryVar_name],ArrayType(IntegerType())) will store the whole array as a row","poster":"Indiee","timestamp":"1682448180.0"},{"poster":"Indiee","upvote_count":"1","timestamp":"1682447940.0","content":"Agreed","comment_id":"880758"}],"url":"https://www.examtopics.com/discussions/databricks/view/106136-exam-certified-associate-developer-for-apache-spark-topic-1/","answer":"E","topic":"1","timestamp":"2023-04-13 20:41:00"}],"exam":{"provider":"Databricks","name":"Certified Associate Developer for Apache Spark","numberOfQuestions":185,"lastUpdated":"12 Apr 2025","isImplemented":true,"isMCOnly":true,"isBeta":false,"id":161},"currentPage":25},"__N_SSP":true}