{"pageProps":{"questions":[{"id":"TkgrjU4LH7WTUo7kTbgX","answers_community":["B (100%)"],"timestamp":"2023-10-21 20:07:00","url":"https://www.examtopics.com/discussions/databricks/view/124255-exam-certified-data-engineer-professional-topic-1-question/","answer_ET":"B","discussion":[{"timestamp":"1716317880.0","comment_id":"1076666","poster":"aragorn_brego","content":"Selected Answer: B\nIn systems that support atomic transactions, such as Delta Lake, when a batch operation encounters a record that violates a CHECK constraint, the entire operation fails, and no records are inserted, including those that do not violate the constraint. This is to ensure the atomicity of the transaction, meaning that either all the changes are committed, or none are, maintaining data integrity. The record with a longitude of 212.67 violates the constraint because longitude values must be between -180 and 180 degrees.","upvote_count":"5"},{"comment_id":"1141684","timestamp":"1722901260.0","content":"Selected Answer: B\nIn Delta Lake, when a batch job attempts to insert records into a table that has a CHECK constraint, if any record violates the constraint, the entire write operation fails. This is because Delta Lake enforces strong transactional guarantees, which means that either all changes in a transaction are saved, or none are.","upvote_count":"5","poster":"vctrhugo"},{"content":"Selected Answer: B\nB is correct","upvote_count":"1","comment_id":"1131751","poster":"spaceexplorer","timestamp":"1721910600.0"},{"comment_id":"1066288","content":"B is the answer","timestamp":"1715239620.0","upvote_count":"4","poster":"Dileepvikram"},{"upvote_count":"4","comment_id":"1053489","poster":"sturcu","timestamp":"1714024200.0","content":"Selected Answer: B\nB is the answer"},{"upvote_count":"3","content":"B is the ans","timestamp":"1713722820.0","comment_id":"1049724","poster":"PearApple"}],"answer_images":[],"answer":"B","isMC":true,"choices":{"E":"The write will insert all records except those that violate the table constraints; the violating records will be reported in a warning log.","B":"The write will fail completely because of the constraint violation and no records will be inserted into the target table.","D":"The write will include all records in the target table; any violations will be indicated in the boolean column named valid_coordinates.","C":"The write will insert all records except those that violate the table constraints; the violating records will be recorded to a quarantine table.","A":"The write will fail when the violating record is reached; any records previously processed will be recorded to the target table."},"question_images":["https://img.examtopics.com/certified-data-engineer-professional/image44.png"],"question_text":"A CHECK constraint has been successfully added to the Delta table named activity_details using the following logic:\n\n//IMG//\n\n\nA batch job is attempting to insert new records to the table, including a record where latitude = 45.50 and longitude = 212.67.\n\nWhich statement describes the outcome of this batch insert?","answer_description":"","topic":"1","unix_timestamp":1697911620,"question_id":181,"exam_id":163},{"id":"mEBacLIbj9unFhLMHvNr","timestamp":"2023-10-25 07:55:00","url":"https://www.examtopics.com/discussions/databricks/view/124600-exam-certified-data-engineer-professional-topic-1-question/","answer_description":"","topic":"1","discussion":[{"comment_id":"1166171","upvote_count":"3","timestamp":"1725496560.0","content":"Selected Answer: A\ndid a test. \"group cannot be owner\" is displayed.","poster":"hal2401me"},{"poster":"vctrhugo","comment_id":"1141682","content":"Selected Answer: A\nIn Databricks, each job must have exactly one owner, which is typically the user who created the job. This “Owner” privilege allows the user to perform any action on the job, including modifying its settings or deleting it. However, this privilege cannot be assigned to a group. If you want to allow multiple users or a group of users to manage a job, you can use ACLs (Access Control Lists) to grant them the necessary permissions. But the “Owner” privilege will still remain with the individual user who created the job.","timestamp":"1722901080.0","upvote_count":"1"},{"poster":"sturcu","comment_id":"1053495","upvote_count":"4","timestamp":"1714024500.0","content":"Selected Answer: A\nCorrect\nA job cannot have more than one owner. A job cannot have a group as an owner"}],"exam_id":163,"choices":{"A":"Databricks jobs must have exactly one owner; \"Owner\" privileges cannot be assigned to a group.","D":"A user can only transfer job ownership to a group if they are also a member of that group.","B":"The creator of a Databricks job will always have \"Owner\" privileges; this configuration cannot be changed.","E":"Only workspace administrators can grant \"Owner\" privileges to a group.","C":"Other than the default \"admins\" group, only individual users can be granted privileges on jobs."},"unix_timestamp":1698213300,"answer_ET":"A","question_text":"A junior data engineer has manually configured a series of jobs using the Databricks Jobs UI. Upon reviewing their work, the engineer realizes that they are listed as the \"Owner\" for each job. They attempt to transfer \"Owner\" privileges to the \"DevOps\" group, but cannot successfully accomplish this task.\n\nWhich statement explains what is preventing this privilege transfer?","answer":"A","isMC":true,"answer_images":[],"answers_community":["A (100%)"],"question_images":[],"question_id":182},{"id":"dsw2t6OuXp5324bZGsmK","discussion":[{"upvote_count":"13","comment_id":"1056080","content":"Selected Answer: E\nI think answer E is correct, as by default partitionning by a column will create a separate folder for each subset data linked to the partition","timestamp":"1698485100.0","poster":"mouad_attaqi"},{"timestamp":"1733394660.0","upvote_count":"2","comment_id":"1322320","content":"Selected Answer: E\nPartitioning by topic field let delete queries leverage partioning boundaries","poster":"benni_ale"},{"timestamp":"1729574700.0","upvote_count":"1","poster":"benni_ale","comment_id":"1301420","content":"Selected Answer: E\nE E E E E"},{"content":"Selected Answer: D\ni think it's best to isolate the storage to avoid mistakenly deleting tables in the same storage so I go with D","comment_id":"1150989","timestamp":"1708001400.0","upvote_count":"1","poster":"ojudz08"},{"upvote_count":"1","poster":"spaceexplorer","comment_id":"1131758","timestamp":"1706193360.0","content":"Selected Answer: E\nE is correct"},{"timestamp":"1703485260.0","comment_id":"1105054","content":"Selected Answer: E\nE is correct","poster":"ervinshang","upvote_count":"2"},{"timestamp":"1700600520.0","comment_id":"1076677","poster":"aragorn_brego","content":"Selected Answer: E\nPartitioning data by the topic field would allow the data engineering team to apply access control lists (ACLs) to restrict access to the partition containing the \"registration\" topic, which holds PII. Furthermore, the team can set up automated deletion policies that specifically target the partition with PII data to delete records after 14 days, without affecting the data in other partitions. This approach meets both the privacy requirements for PII and the data retention goals for non-PII information.","upvote_count":"2"},{"upvote_count":"3","poster":"Dileepvikram","content":"I think answer is E","comment_id":"1066299","timestamp":"1699522560.0"},{"upvote_count":"1","content":"Selected Answer: B\nThe solution that meets the requirements is: B. Data should be partitioned by the registration field, allowing ACLs and delete statements to be set for the PII directory.\n\nPartitioning the data by the registration field allows the directory containing PII records to be isolated and access restricted via ACLs. Additionally, the data retention requirements can be met by setting up a separate job or process to remove PII records that are 14 days old. For non-PII records, they can be retained indefinitely utilizing Delta Lake's time travel functionality.","comments":[{"comment_id":"1056975","poster":"mouad_attaqi","content":"There is no such thing as Registration field, it's a distinct topic","upvote_count":"2","timestamp":"1698597360.0"},{"timestamp":"1698650280.0","comment_id":"1057422","poster":"sturcu","upvote_count":"1","content":"you cannot restricts privileges. with ACLs on a partition. Documentations states that Securable objects in the Hive metastore are: DB, Tables, Views, Functions: https://docs.databricks.com/en/data-governance/table-acls/object-privileges.html#securable-objects"}],"timestamp":"1698561060.0","poster":"[Removed]","comment_id":"1056614"},{"timestamp":"1698213480.0","comments":[],"upvote_count":"1","comment_id":"1053501","poster":"sturcu","content":"Selected Answer: D\nCorrect"}],"question_id":183,"isMC":true,"question_images":[],"answer":"E","exam_id":163,"timestamp":"2023-10-25 07:58:00","url":"https://www.examtopics.com/discussions/databricks/view/124601-exam-certified-data-engineer-professional-topic-1-question/","answers_community":["E (88%)","8%"],"choices":{"A":"All data should be deleted biweekly; Delta Lake's time travel functionality should be leveraged to maintain a history of non-PII information.","E":"Data should be partitioned by the topic field, allowing ACLs and delete statements to leverage partition boundaries.","D":"Separate object storage containers should be specified based on the partition field, allowing isolation at the storage level.","C":"Because the value field is stored as binary data, this information is not considered PII and no special precautions should be taken.","B":"Data should be partitioned by the registration field, allowing ACLs and delete statements to be set for the PII directory."},"question_text":"All records from an Apache Kafka producer are being ingested into a single Delta Lake table with the following schema:\n\nkey BINARY, value BINARY, topic STRING, partition LONG, offset LONG, timestamp LONG\n\nThere are 5 unique topics being ingested. Only the \"registration\" topic contains Personal Identifiable Information (PII). The company wishes to restrict access to PII. The company also wishes to only retain records containing PII in this table for 14 days after initial ingestion. However, for non-PII information, it would like to retain these records indefinitely.\n\nWhich of the following solutions meets the requirements?","answer_images":[],"answer_description":"","answer_ET":"E","topic":"1","unix_timestamp":1698213480},{"id":"TOyKVMPJNKo6t2yskOZE","isMC":true,"discussion":[{"upvote_count":"6","poster":"sturcu","content":"Selected Answer: D\nUsage and Select ....sa abasically they can only select","comment_id":"1053503","timestamp":"1698213780.0"},{"poster":"benni_ale","upvote_count":"1","comment_id":"1306946","timestamp":"1730723640.0","content":"Selected Answer: D\nD is ok"},{"timestamp":"1709002320.0","poster":"Curious76","comment_id":"1160226","content":"Selected Answer: D\nD is correct","upvote_count":"1"},{"timestamp":"1707182700.0","upvote_count":"1","content":"Selected Answer: D\nThe GRANT statements provided in the logic grant the USAGE privilege, allowing the group members to see the existence of the database, and the SELECT privilege, allowing them to query tables and views. However, they do not have permissions to create or edit anything in the database. Therefore, the correct description is that group members can query all tables and views in the prod database but cannot create or edit any objects in the database.","poster":"vctrhugo","comment_id":"1141673"},{"upvote_count":"1","timestamp":"1704148920.0","comment_id":"1111476","poster":"divingbell17","content":"Selected Answer: D\nD is correct assuming unity catalog is not enabled"},{"poster":"aragorn_brego","comment_id":"1076686","timestamp":"1700600760.0","upvote_count":"3","content":"Selected Answer: D\nThe GRANT USAGE ON DATABASE statement gives the eng group the ability to access the prod database. This means they can enter the database context and list the tables. The GRANT SELECT ON DATABASE statement additionally grants them permission to perform SELECT queries on all existing tables and views within the prod database. However, these privileges do not include creating new tables or views, modifying existing tables, or assigning permissions to other users or groups."},{"timestamp":"1699523160.0","comment_id":"1066311","poster":"Dileepvikram","content":"D is answer","upvote_count":"4"}],"question_id":184,"url":"https://www.examtopics.com/discussions/databricks/view/124602-exam-certified-data-engineer-professional-topic-1-question/","answers_community":["D (100%)"],"answer":"D","answer_description":"","choices":{"C":"Group members are able to query and modify all tables and views in the prod database, but cannot create new tables or views.","B":"Group members are able to list all tables in the prod database but are not able to see the results of any queries on those tables.","D":"Group members are able to query all tables and views in the prod database, but cannot create or edit anything in the database.","A":"Group members have full permissions on the prod database and can also assign permissions to other users or groups.","E":"Group members are able to create, query, and modify all tables and views in the prod database, but cannot define custom functions."},"timestamp":"2023-10-25 08:03:00","unix_timestamp":1698213780,"question_text":"The data architect has decided that once data has been ingested from external sources into the\nDatabricks Lakehouse, table access controls will be leveraged to manage permissions for all production tables and views.\n\nThe following logic was executed to grant privileges for interactive queries on a production database to the core engineering group.\n\nGRANT USAGE ON DATABASE prod TO eng;\nGRANT SELECT ON DATABASE prod TO eng;\n\nAssuming these are the only privileges that have been granted to the eng group and that these users are not workspace administrators, which statement describes their privileges?","answer_ET":"D","topic":"1","answer_images":[],"exam_id":163,"question_images":[]},{"id":"6fZfhPy9TtiCd3Y1AyoH","choices":{"E":"Executor's log file","C":"Ganglia","A":"Workspace audit logs","B":"Driver's log file","D":"Cluster Event Log"},"topic":"1","question_images":[],"isMC":true,"answer_images":[],"answers_community":["D (100%)"],"url":"https://www.examtopics.com/discussions/databricks/view/124604-exam-certified-data-engineer-professional-topic-1-question/","discussion":[{"timestamp":"1724720160.0","comment_id":"1160227","content":"Selected Answer: D\nThe Cluster Event Log provides detailed information about various events affecting the cluster throughout its lifecycle, including cluster creation, restarts, termination, and resizing events. It displays the timestamp, event type (e.g., \"CLUSTER_RESIZED\"), and relevant details for each event, allowing the administrator to review the timeline for cluster scaling behavior and identify potential patterns related to user activity or resource-intensive queries.","upvote_count":"3","poster":"Curious76"},{"poster":"vctrhugo","upvote_count":"1","timestamp":"1722900120.0","content":"Selected Answer: D\nThe timeline for cluster resizing events can be reviewed in the Cluster Event Log. This log provides information about cluster scaling events, including when the cluster is scaled up or down. You can access this information to understand the reasons behind autoscaling events and whether they are triggered by many concurrent users or resource-intensive queries.","comment_id":"1141672"},{"poster":"alexvno","upvote_count":"2","timestamp":"1718771160.0","content":"Selected Answer: D\nCluster event log","comment_id":"1100375"},{"upvote_count":"2","timestamp":"1716318540.0","comment_id":"1076691","poster":"aragorn_brego","content":"Selected Answer: D\nThe Cluster Event Log in Databricks will show the timeline for cluster resizing events, including details about when and why a cluster was resized (scaled up or down). This log would help the workspace administrator determine the causes of cluster scaling, whether due to many concurrent users submitting jobs or a few users running resource-intensive queries.\n\nless suitable:\nC. Ganglia provides metrics on system-level performance, such as CPU and memory usage, but does not log specific cluster scaling events."},{"timestamp":"1714952700.0","comment_id":"1063455","poster":"PearApple","content":"cluster event log. D","upvote_count":"2"},{"upvote_count":"3","timestamp":"1714025820.0","comment_id":"1053510","content":"Selected Answer: D\nCluster Event Log","poster":"sturcu"}],"question_id":185,"answer_ET":"D","answer":"D","unix_timestamp":1698214620,"answer_description":"","exam_id":163,"timestamp":"2023-10-25 08:17:00","question_text":"A distributed team of data analysts share computing resources on an interactive cluster with autoscaling configured. In order to better manage costs and query throughput, the workspace administrator is hoping to evaluate whether cluster upscaling is caused by many concurrent users or resource-intensive queries.\n\nIn which location can one review the timeline for cluster resizing events?"}],"exam":{"isImplemented":true,"numberOfQuestions":200,"isBeta":false,"isMCOnly":true,"lastUpdated":"12 Apr 2025","name":"Certified Data Engineer Professional","id":163,"provider":"Databricks"},"currentPage":37},"__N_SSP":true}