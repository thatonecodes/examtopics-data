{"pageProps":{"questions":[{"id":"ghbaHcPaGQAYeTtYBYu2","question_id":71,"url":"https://www.examtopics.com/discussions/databricks/view/141710-exam-certified-data-engineer-professional-topic-1-question/","question_images":[],"choices":{"C":"Only workspace administrators can grant \"Owner\" privileges to a group.","D":"A user can only transfer job ownership to a group if they are also a member of that group.","A":"Databricks jobs must have exactly one owner; \"Owner\" privileges cannot be assigned to a group.","B":"The creator of a Databricks job will always have \"Owner\" privileges; this configuration cannot be changed."},"exam_id":163,"answer_ET":"A","topic":"1","answer":"A","answer_description":"","discussion":[{"timestamp":"1719493860.0","content":"Selected Answer: A\nThis is the correct answer for this question in a past Databricks version, however now you can indeed add a group as a owner to a job.","poster":"03355a2","upvote_count":"5","comment_id":"1238165"},{"poster":"imatheushenrique","upvote_count":"1","comment_id":"1222428","content":"A. Databricks jobs must have exactly one owner; \"Owner\" privileges cannot be assigned to a group.\nIt's only possivel that a databricks JOB has an owner, not a group.","timestamp":"1717207380.0"}],"question_text":"A junior data engineer has manually configured a series of jobs using the Databricks Jobs UI. Upon reviewing their work, the engineer realizes that they are listed as the \"Owner\" for each job. They attempt to transfer \"Owner\" privileges to the \"DevOps\" group, but cannot successfully accomplish this task.\n\nWhich statement explains what is preventing this privilege transfer?","answer_images":[],"answers_community":["A (100%)"],"isMC":true,"unix_timestamp":1717207380,"timestamp":"2024-06-01 04:03:00"},{"id":"Qb4qn2yMUDK0p3nAoqjx","timestamp":"2024-05-29 19:57:00","isMC":true,"answer_images":[],"unix_timestamp":1717005420,"exam_id":163,"answer_description":"","choices":{"D":"All columns will be displayed normally for those records that have an age greater than 18; records not meeting this condition will be omitted.","C":"All values for the age column will be returned as null values, all other columns will be returned with the values in user_ltv.","A":"All columns will be displayed normally for those records that have an age greater than 17; records not meeting this condition will be omitted.","B":"All age values less than 18 will be returned as null values, all other columns will be returned with the values in user_ltv."},"answer_ET":"A","question_id":72,"answer":"A","topic":"1","url":"https://www.examtopics.com/discussions/databricks/view/141558-exam-certified-data-engineer-professional-topic-1-question/","question_images":["https://img.examtopics.com/certified-data-engineer-professional/image71.png"],"answers_community":["A (100%)"],"discussion":[{"upvote_count":"3","comment_id":"1230603","timestamp":"1718388180.0","content":"Selected Answer: A\nSurely, it's an A","poster":"Isio05"},{"upvote_count":"2","content":"Selected Answer: A\noption A is correct","timestamp":"1718210580.0","comment_id":"1229325","poster":"hpkr"},{"timestamp":"1717845960.0","poster":"BrianNguyen95","comment_id":"1226709","upvote_count":"2","content":"Selected Answer: A\nGreater than 17"},{"upvote_count":"1","comment_id":"1222905","timestamp":"1717276500.0","poster":"Freyr","content":"Selected Answer: A\nCorrect Answer: A\n(>17) qual to (>=18). So, all records above 17 years will get in result and other records will be omitted."},{"comment_id":"1222427","content":"A. All columns will be displayed normally for those records that have an age greater than 17; records not meeting this condition will be omitted.\n\nBecause the condition of age>=18 only is respected in option A.","upvote_count":"1","timestamp":"1717206960.0","poster":"imatheushenrique"},{"timestamp":"1717005420.0","content":"Selected Answer: A\nNope, A greater than 18 is 19. D is incorrect.","upvote_count":"1","poster":"MDWPartners","comment_id":"1221171"}],"question_text":"A table named user_ltv is being used to create a view that will be used by data analysts on various teams. Users in the workspace are configured into groups, which are used for setting up data access using ACLs.\n\nThe user_ltv table has the following schema:\n\nemail STRING, age INT, ltv INT\n\nThe following view definition is executed:\n\n//IMG//\n\n\nAn analyst who is not a member of the auditing group executes the following query:\n\nSELECT * FROM user_ltv_no_minors\n\nWhich statement describes the results returned by this query?"},{"id":"OMBF6p3aCn26Wx4ZKTOL","discussion":[{"poster":"hpkr","upvote_count":"2","comment_id":"1229327","content":"Selected Answer: C\nC is correct","timestamp":"1718210580.0"},{"upvote_count":"1","poster":"imatheushenrique","timestamp":"1717206780.0","content":"C.\nPartitioning the data by the topic field allows the company to apply different access control policies and retention policies for different topics. Althought there is a performance optmization gain because of the read in the partition path.","comment_id":"1222425"}],"question_id":73,"unix_timestamp":1717206780,"timestamp":"2024-06-01 03:53:00","url":"https://www.examtopics.com/discussions/databricks/view/141709-exam-certified-data-engineer-professional-topic-1-question/","choices":{"A":"All data should be deleted biweekly; Delta Lake's time travel functionality should be leveraged to maintain a history of non-PII information.","C":"Data should be partitioned by the topic field, allowing ACLs and delete statements to leverage partition boundaries.","B":"Data should be partitioned by the registration field, allowing ACLs and delete statements to be set for the PII directory.","D":"Separate object storage containers should be specified based on the partition field, allowing isolation at the storage level."},"answer_description":"","exam_id":163,"topic":"1","question_text":"All records from an Apache Kafka producer are being ingested into a single Delta Lake table with the following schema:\n\nkey BINARY, value BINARY, topic STRING, partition LONG, offset LONG, timestamp LONG\n\nThere are 5 unique topics being ingested. Only the \"registration\" topic contains Personal Identifiable Information (PII). The company wishes to restrict access to PII. The company also wishes to only retain records containing PII in this table for 14 days after initial ingestion. However, for non-PII information, it would like to retain these records indefinitely.\n\nWhich solution meets the requirements?","answers_community":["C (100%)"],"answer":"C","question_images":[],"answer_ET":"C","isMC":true,"answer_images":[]},{"id":"fyl6VplQahCgrakimcQY","timestamp":"2024-06-01 03:45:00","exam_id":163,"url":"https://www.examtopics.com/discussions/databricks/view/141708-exam-certified-data-engineer-professional-topic-1-question/","question_id":74,"discussion":[{"comment_id":"1300603","timestamp":"1729444620.0","poster":"m79590530","content":"Selected Answer: B\nDefault Delta Lake time travel retention is 7 days so records deleted are still accessible via previous table versions up to 7 days later unless somebody changes this default setting to less days and runs VACUUM on the table earlier.","upvote_count":"1"},{"poster":"imatheushenrique","timestamp":"1717206300.0","upvote_count":"3","comment_id":"1222423","content":"B. No; files containing deleted records may still be accessible with time travel until a VACUUM command is used to remove invalidated data files."}],"answer":"B","choices":{"D":"Yes; Delta Lake ACID guarantees provide assurance that the DELETE command succeeded fully and permanently purged these records.","A":"No; the Delta Lake DELETE command only provides ACID guarantees when combined with the MERGE INTO command.","C":"No; the change data feed only tracks inserts and updates, not deleted records.","B":"No; files containing deleted records may still be accessible with time travel until a VACUUM command is used to remove invalidated data files."},"answer_description":"","answers_community":["B (100%)"],"isMC":true,"answer_images":[],"question_text":"The data governance team is reviewing code used for deleting records for compliance with GDPR. The following logic has been implemented to propagate delete requests from the user_lookup table to the user_aggregates table.\n\n//IMG//\n\n\nAssuming that user_id is a unique identifying key and that all users that have requested deletion have been removed from the user_lookup table, which statement describes whether successfully executing the above logic guarantees that the records to be deleted from the user_aggregates table are no longer accessible and why?","question_images":["https://img.examtopics.com/certified-data-engineer-professional/image72.png"],"unix_timestamp":1717206300,"answer_ET":"B","topic":"1"},{"id":"vgSrvrJl7Dp87ncVbdXW","unix_timestamp":1717005720,"answers_community":["D (90%)","10%"],"answer_ET":"D","question_text":"An external object storage container has been mounted to the location /mnt/finance_eda_bucket.\n\nThe following logic was executed to create a database for the finance team:\n\n//IMG//\n\n\nAfter the database was successfully created and permissions configured, a member of the finance team runs the following code:\n\n//IMG//\n\n\nIf all users on the finance team are members of the finance group, which statement describes how the tx_sales table will be created?","timestamp":"2024-05-29 20:02:00","url":"https://www.examtopics.com/discussions/databricks/view/141559-exam-certified-data-engineer-professional-topic-1-question/","answer_images":[],"question_id":75,"isMC":true,"exam_id":163,"answer_description":"","topic":"1","discussion":[{"poster":"a85becd","upvote_count":"1","comment_id":"1555897","content":"Selected Answer: B\nThe table cannot be a **managed table**:\n- If a database specifies a `LOCATION`, all tables created inside it inherit that `LOCATION`, and they are **external tables**.\n- Managed tables cannot exist in a database where the storage location has been explicitly specified, as the managed table lifecycle is tied to Databricks' internal storage system.\n-Even if you don't explicitly define the table as external, the **database's external location forces all tables** to behave as external tables.","timestamp":"1743906300.0"},{"poster":"Sriramiyer92","comment_id":"1326688","upvote_count":"1","timestamp":"1734235020.0","content":"Selected Answer: D\nD. Managed tables - Since Location is not mentioned. \nmounted to /mnt/finance_eda_bucket - This is where our database is created as per first query and in second query we are using it to create the table further."},{"content":"Selected Answer: D\nIt will be created in database location, but it will be managed table (missing LOCATION keyword in CREATE TABLE).","upvote_count":"3","comment_id":"1230606","timestamp":"1718388300.0","poster":"Isio05"},{"poster":"hpkr","comment_id":"1229342","timestamp":"1718211180.0","upvote_count":"2","content":"Selected Answer: D\nD is correct"},{"poster":"Freyr","comment_id":"1222909","upvote_count":"2","timestamp":"1717277040.0","content":"Selected Answer: D\nCorrect Answer: D\nThe table is still managed by Spark SQL in terms of metadata, but the data files are stored in the specified path due to the database’s location setting.\n\nGiven the inherited location from the database, if the CREATE TABLE statement had explicitly used USING EXTERNAL or specified a LOCATION, it would definitely be an external table. However, since it inherits the database's location without these specifications, it creates a managed table."},{"upvote_count":"1","timestamp":"1717005720.0","comment_id":"1221172","content":"Selected Answer: D\nSeems D","poster":"MDWPartners"}],"answer":"D","question_images":["https://img.examtopics.com/certified-data-engineer-professional/image73.png","https://img.examtopics.com/certified-data-engineer-professional/image74.png"],"choices":{"B":"An external table will be created in the storage container mounted to /mnt/finance_eda_bucket.","C":"A managed table will be created in the DBFS root storage container.","D":"An managed table will be created in the storage container mounted to /mnt/finance_eda_bucket.","A":"A logical table will persist the query plan to the Hive Metastore in the Databricks control plane."}}],"exam":{"isMCOnly":true,"id":163,"lastUpdated":"12 Apr 2025","provider":"Databricks","name":"Certified Data Engineer Professional","isImplemented":true,"numberOfQuestions":200,"isBeta":false},"currentPage":15},"__N_SSP":true}