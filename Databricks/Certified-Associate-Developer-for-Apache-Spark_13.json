{"pageProps":{"questions":[{"id":"xKrhWtVeVhcI1s0uBNHK","question_text":"The code block shown below should return a new DataFrame where rows in DataFrame storesDF containing at least one missing value have been dropped. Choose the response that correctly fills in the numbered blanks within the code block to complete this task.\n\nCode block:\n\nStoresDF.__1__.__2__(__3__ = __4__)","unix_timestamp":1712753100,"isMC":true,"question_id":61,"discussion":[{"upvote_count":"1","timestamp":"1728564300.0","content":"D. 1. na\n2. drop\n3. how\n4. \"any\"","poster":"Sowwy1","comment_id":"1192991"}],"choices":{"B":"1. na\n2. drop\n3. how\n4. \"all\"","C":"1. na\n2. drop\n3. subset\n4. \"all\"","A":"1. na\n2. drop\n3. subset\n4. \"any\"","D":"1. na\n2. drop\n3. how\n4. \"any\"","E":"1. drop\n2. na\n3. how\n4. \"any\""},"timestamp":"2024-04-10 14:45:00","answer":"D","question_images":[],"url":"https://www.examtopics.com/discussions/databricks/view/138344-exam-certified-associate-developer-for-apache-spark-topic-1/","answer_description":"","answers_community":[],"answer_images":[],"topic":"1","exam_id":161,"answer_ET":"D"},{"id":"pzW40sb0NWMF3Z82TiR3","answers_community":[],"unix_timestamp":1712772000,"isMC":true,"discussion":[{"timestamp":"1728583200.0","comment_id":"1193196","content":"B. mean()","upvote_count":"1","poster":"Sowwy1"}],"answer_description":"","timestamp":"2024-04-10 20:00:00","topic":"1","answer_images":[],"answer_ET":"B","question_id":62,"choices":{"B":"mean()","E":"approxMean()","C":"agg()","A":"simpleAvg()","D":"average()"},"question_text":"Which of the following operations calculates the simple average of a group of values, like a column?","exam_id":161,"question_images":[],"url":"https://www.examtopics.com/discussions/databricks/view/138376-exam-certified-associate-developer-for-apache-spark-topic-1/","answer":"B"},{"id":"vu5BoR5WY8qMarPY326C","question_images":[],"answer_description":"","answer_images":[],"question_text":"Which of the following code blocks fails to return the number of rows in DataFrame storesDF for each distinct combination of values in column division and column storeCategory?","timestamp":"2024-02-18 12:29:00","unix_timestamp":1708255740,"answers_community":["B (75%)","D (25%)"],"answer_ET":"B","choices":{"D":"storesDF.groupBy(\"division\", \"storeCategory\").count()","B":"storesDF.groupBy(\"division\").groupBy(\"storeCategory\").count()","C":"storesDF.groupBy([\"division\", \"storeCategory\"]).count()","E":"storesDF.groupBy(col(\"division“), col(\"storeCategory\")).count()","A":"storesDF.groupBy((col(\"division\"), col(\"storeCategory\")]).count()"},"question_id":63,"answer":"B","topic":"1","discussion":[{"comment_id":"1559026","content":"Selected Answer: B\nB is correct","upvote_count":"1","timestamp":"1744134420.0","poster":"PushpakKothekar"},{"content":"Selected Answer: B\nB is the right choice. I tested with my dataframe option B threw this error\nAttributeError: 'GroupedData' object has no attribute 'groupBy'","timestamp":"1727985540.0","comment_id":"1188879","upvote_count":"2","poster":"SaiPavan10"},{"content":"Selected Answer: D\nD is correct !","upvote_count":"1","comments":[{"content":"it is possible to run in pyspark - storesDF.groupBy(\"division\", \"storeCategory\").count()\nCorrect answer is B","upvote_count":"2","comment_id":"1160820","poster":"Ahlo","timestamp":"1724769360.0"}],"timestamp":"1723973340.0","comment_id":"1153220","poster":"YiJiaSu"}],"exam_id":161,"isMC":true,"url":"https://www.examtopics.com/discussions/databricks/view/134140-exam-certified-associate-developer-for-apache-spark-topic-1/"},{"id":"17uorwu2hUtEMtBwAVfx","question_images":[],"answer_description":"","answer_images":[],"question_text":"The code block shown below contains an error. The code block is intended to return a collection of summary statistics for column sqft in Data Frame storesDF. Identify the error.\n\nCode block:\n\nstoresDF.describes(col(\"sgft \"))","timestamp":"2024-02-27 17:39:00","unix_timestamp":1709051940,"answers_community":[],"answer_ET":"D","choices":{"D":"The describe() operation does not accept a Column object as an argument — the column name string \"sqft\" should be specified instead.","C":"The describe() operation does not accept a Column object as an argument outside of a list — the list [col(\"sqft\")] should be specified instead.","B":"The column sqft should be subsetted from DataFrame storesDF prior to computing summary statistics on it alone.","E":"The describe() operation doesn't compute summary statistics for numeric columns — the sumwary() operation should be used instead.","A":"The describe() operation doesn't compute summary statistics for a single column — the summary() operation should be used instead."},"question_id":64,"answer":"D","topic":"1","exam_id":161,"isMC":true,"discussion":[{"comment_id":"1160825","upvote_count":"1","poster":"Ahlo","timestamp":"1724769540.0","content":"Answer D correct\nhttps://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.describe.html"}],"url":"https://www.examtopics.com/discussions/databricks/view/134766-exam-certified-associate-developer-for-apache-spark-topic-1/"},{"id":"nm0Qgu8MtTWFbu9kDhee","topic":"1","answer":"C","question_text":"The code block shown below should return a 25 percent sample of rows from DataFrame storesDF with reproducible results. Choose the response that correctly fills in the numbered blanks within the code block to complete this task.\n\nCode block:\n\nStoresDF.__1__(__2__ = __3__, __4__ = __5__)","unix_timestamp":1712758020,"answer_description":"","answer_ET":"C","choices":{"B":"1. sample\n2. withReplacement\n3. True\n4. seed\n5. True","C":"1. sample\n2. fraction\n3. 0.25\n4. seed\n5. 1234","E":"1. sample\n2. withReplacement\n3. True\n4. seed\n5. 1234","D":"1. sample\n2. fraction\n3. 0.15\n4. seed\n5. 1234","A":"1. sample\n2. fraction\n3. 0.25\n4. seed\n5. True"},"url":"https://www.examtopics.com/discussions/databricks/view/138352-exam-certified-associate-developer-for-apache-spark-topic-1/","answer_images":[],"discussion":[{"content":"C. 1. sample\n2. fraction\n3. 0.25\n4. seed\n5. 1234","timestamp":"1728569220.0","poster":"Sowwy1","upvote_count":"1","comment_id":"1193050"}],"question_images":[],"timestamp":"2024-04-10 16:07:00","question_id":65,"isMC":true,"answers_community":[],"exam_id":161}],"exam":{"id":161,"lastUpdated":"12 Apr 2025","numberOfQuestions":185,"isImplemented":true,"isBeta":false,"isMCOnly":true,"name":"Certified Associate Developer for Apache Spark","provider":"Databricks"},"currentPage":13},"__N_SSP":true}